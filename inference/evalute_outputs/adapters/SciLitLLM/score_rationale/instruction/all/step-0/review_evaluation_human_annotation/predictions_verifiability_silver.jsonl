{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not delve into the theoretical aspects of the proposed algorithm, specifically the convergence properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting the inclusion of theoretical analysis or references to relevant literature. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of theoretical analysis, specifically the convergence properties of the proposed algorithm. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors can infer that it relates to the theoretical section, the comment lacks specificity in detailing what needs to be addressed or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that it does not provide a theoretical analysis of the proposed algorithm, specifically regarding its convergence properties. This feedback is valuable as it highlights an area where the authors can enhance the depth and rigor of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending relevant literature or methods to explore the convergence properties. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, implying that the current method is flawed. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or revise their description of HIERENC. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, noting that using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that using the average of all instantiations of context filled by every possible entity in the vocabulary is a poor approach. The reviewer argues that only one instantiation should be correct, implying that the current method introduces noise. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the current approach is flawed. This makes the claim 3, as the authors would need to further investigate the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, implying that the current method is flawed. This feedback is clear and actionable, as it provides a specific area for improvement and offers a logical reasoning for why the current approach might be problematic. However, the comment could be more helpful if it suggested alternative approaches or provided more detailed guidance on how to address the issue. Overall, the comment is 4 as it directs the authors to a critical area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While the comment implies that the authors should explain their rationale for this selection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in questioning the selection process and its impact on the results, but without explicit grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. However, it does not provide any supporting evidence, reasoning, or examples to justify why this selection might affect the results. The comment lacks specific details or references that would help the authors understand the significance of this question or how to address it. As a result, the claim is 1, as it does not provide sufficient information for the authors to understand or address the issue.", "helpfulness_rationale": "The review comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it identifies a specific area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or improve their analysis. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a discrepancy in the description of the data selection process, suggesting that the authors should revise their description to clarify that the data is a subset of Li et al. (2019a)\"s dataset. The comment explicitly states that the description can be revised by mentioning Li et al. (2019a) earlier, providing a clear and concrete action for the authors to take. This guidance is specific and actionable, allowing the authors to make a direct improvement to their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 226238\" and \"Line 242244,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue by pointing out the discrepancy in the description of the data selection process, suggesting that the authors should revise their description to clarify that the data is a subset of Li et al. (2019a)\"s dataset. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point identifies a discrepancy in the description of the data selection process, suggesting that the authors should revise their description to clarify that the data is a subset of Li et al. (2019a)\"s dataset. The reviewer provides a logical reasoning by pointing out the inconsistency in the description and suggests a revision to make it clear and precise. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to verify the claim by reviewing the original sources or the data selection process described in the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the description of the data selection process, suggesting that the authors should revise their description to clarify that the data is a subset of Li et al. (2019a)\"s dataset. The reviewer provides a clear and actionable suggestion by recommending that the authors mention Li et al. (2019a) earlier to make the description more precise and accurate. This feedback is specific and provides a direct way for the authors to improve the clarity and precision of their draft, making it 4. However, it could be more helpful if it included additional suggestions or examples to further enhance the clarity of the description. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the purpose of the average duration reported in Table 1 and requests an explanation. It does not explicitly instruct the authors to provide this explanation, but it does imply that they should include a supporting explanation. The action is implicit, as the authors can infer that they need to clarify the purpose of the average duration, but it lacks concrete details on how to implement this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of the average duration reported in the table and requests an explanation, including whether it includes time spent by the user waiting for the model to generate a response. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the purpose of the average duration reported in Table 1, without any claim or suggestion that requires verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the purpose of the average duration reported in Table 1 and requests an explanation. This feedback is 3 as it prompts the authors to clarify the meaning and context of the reported duration, which could be important for understanding the results or methodology. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what additional information might be needed. To be more helpful, the comment could suggest including a detailed explanation or justification for the reported duration. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A for Chinese MOSQ and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the interpretation. The comment lacks concrete details or suggestions, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues to be addressed, such as the interpretation of results regarding the comparison of NVSB with GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification on the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A for Chinese MOSQ and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOSV. While the comment identifies areas where clarification is needed, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the interpretation of their results. The feedback lacks actionable advice, leaving the authors with a general understanding of what needs clarification but without clear steps to take. Therefore, the comment is 3, as it highlights areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the formatting of Table 2 and Table 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This affects the overall appearance and readability of the tables. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to correct the formatting or improve the tables\" appearance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the formatting, noting the presence of spaces between accuracy and standard deviation in some items but not in others. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue with the formatting of Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is factual and does not require any supporting evidence or reasoning. It is a straightforward statement of an issue that can be easily verified by examining the tables themselves. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific formatting issue in Tables 2 and 3, noting that some items have spaces between accuracy and standard deviation, while others do not. This observation is clear and actionable, as it points out a potential inconsistency that could affect the appearance and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending a consistent formatting style or explaining why this issue is important. While it highlights a specific area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a grammatical error regarding the phrase \"both tasks\" and suggests that the references should be checked for formatting issues, such as capitalization and bibliographic details. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to correct the grammatical error or how to ensure proper formatting of the references. The action is implicit, as the authors can infer that they need to check and correct the references, but it lacks concrete guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a grammatical error in the phrase \"both tasks\" and suggests checking the references for formatting issues, such as capitalization and bibliographic details. However, it does not specify which part of the paper contains the grammatical error or which references need to be checked. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention. The comment is weakly grounded because it does not provide explicit references or sections, and it is not specific enough to guide the authors on how to address the issue. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point identifies a grammatical error in the phrase \"both tasks\" and suggests checking the references for formatting issues, such as capitalization and bibliographic details. However, the comment does not provide specific examples or references to support the claim about the grammatical error or the need for formatting corrections. This lack of detailed evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a grammatical error in the phrase \"both tasks\" and suggests checking the references for formatting issues, such as capitalization and bibliographic details. While it points out a specific error, the comment lacks depth and does not provide detailed guidance on how to correct the error or improve the formatting of the references. The feedback is 3 as it highlights a specific area for improvement, but it could be more comprehensive by offering suggestions or examples on how to address these issues. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently by dedicating separate paragraphs to each of the lexical and sentencelevel features. This provides a clear and direct action for the authors to take, which is to reorganize the section to improve clarity. The suggestion is concrete, as it specifies the action of adding separate paragraphs, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current organization of the section, suggesting that more separate paragraphs should be dedicated to each of the lexical and sentencelevel features to improve coherence. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently. However, the comment does not provide specific examples or detailed reasoning to support why the current organization is confusing or how the suggested changes would improve clarity. Without additional context or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of explanations in Section 3.2, noting that the current structure is confusing. It provides a clear and actionable suggestion to improve coherence by dedicating separate paragraphs to each of the lexical and sentencelevel features. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and organization of their paper, making it 4. However, it could be more helpful if it included specific examples of how the current structure is confusing or suggested how the new organization might look. Overall, the comment provides a solid foundation for improvement but could be further enhanced with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment explicitly suggests including more baselines, it does not provide specific guidance on which baselines to include or how to implement them. The action is somewhat explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The comment also recommends including more baselines based on related work to strengthen the paper. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the comparison of models and the discussion of baselines. The comment is specific in detailing what needs to be addressed regarding the comparison and the inclusion of additional baselines. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that the MST baseline is an appropriate comparison. The suggestion to include more baselines is logical but not fully substantiated with evidence or examples. Therefore, the comment is 3, as it provides a basis for the claim but requires additional details to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by questioning the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. This feedback is clear and actionable, as it provides a specific suggestion for improvement by comparing the proposed models to a relevant baseline. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or which specific baselines to consider. Overall, the comment is 4 as it directs the authors to a specific area for enhancement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect. The comment lacks specific instructions or examples of what the authors should do to address the issue, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the selection of frame similarity factors and attributes similarity factors, which are specific elements of the paper. However, it does not specify which part of the paper discusses these factors, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the selection of these factors, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the clarity of the selection of frame similarity factors and attributes similarity factors, but it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors, which is a critical aspect of the paper. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect. Without actionable feedback or specific recommendations, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential issue but does not provide sufficient guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN. It also questions how the stable points in probabilistic metric space are obtained, implying that this information is crucial for readers to understand and replicate the results. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to include more detailed discussions, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more detailed explanations on the convergence process and the derivation of stable points. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. This feedback is 3 as it identifies a gap in the paper\"s explanation, which could be crucial for readers to understand and replicate the results. However, the comment lacks specific guidance on how to address this issue or what aspects of the convergence process should be discussed. To be more helpful, the comment could provide examples or references to similar works that address this topic, offering a clearer path for the authors to improve their draft. Therefore, the comment is rated as 3, as it points out an area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using the same terminology for the model in Tables 1 and 2. The comment also raises a question about why the authors did not mention objects in the context of \"latent in verbs.\" These actions are clear and specific, providing the authors with a detailed roadmap for improving their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"681\" and \"778,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as discussing the results for the task of inferring knowledge on objects and including results for model (B). Additionally, it raises a question about why objects are not mentioned in the context of \"latent in verbs.\" This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should discuss the results for the task of inferring knowledge on objects and include results for model (B). It also questions why objects are not mentioned in the context of \"latent in verbs.\" While the comment provides specific suggestions for improvement, it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion to use the same terminology for the model in Tables 1 and 2 is also made without further explanation. Therefore, the comment is 3, as it provides some guidance but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment provides specific and actionable feedback to the authors. It highlights the need to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using the same terminology for the model in Tables 1 and 2, which is a practical suggestion for consistency. The comment also raises a question about why objects are not mentioned in the context of \"latent in verbs,\" prompting the authors to clarify or expand on this aspect. This feedback is clear and provides the authors with a clear direction for improvement, making it 4. However, it could be more helpful if it offered additional guidance or examples on how to address these issues. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for additional baselines, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings. However, it does not specify which part of the paper this extension is discussed in, making it difficult for the authors to identify the exact section that needs further development. The comment is specific in suggesting additional baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings. However, the comment does not provide any specific reasoning or evidence to support why these additional baselines are necessary or how they would enhance the paper. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper\"s extension of existing retrofitting work is straightforward and recommends including additional baselines, such as character embeddings, to provide a more comprehensive comparison. While the comment identifies a potential area for improvement by suggesting additional baselines, it lacks specific guidance or examples on how these baselines should be incorporated or why they are important. The feedback is 3 as it points out a potential enhancement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliance on supplemental space to contain the paper, noting that this makes the paper less independent. It specifically mentions references to Sup. Fig. 6 in section 3.1 and later references to model comparison and other details of the span vs. sentence investigation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and vague, as the authors are left to infer that they need to find a way to make the paper more independent, but the comment does not offer concrete steps or examples of how to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the reliance on supplemental space to contain the paper, specifically mentioning references to Sup. Fig. 6 in section 3.1 and later references to model comparison and other details of the span vs. sentence investigation. This provides some grounding as it allows the authors to identify the relevant sections of the paper, but it does not specify exactly what needs to be addressed or improved in these sections. The comment is specific in pointing out the issue with the reliance on supplemental space, but it lacks detailed guidance on how to resolve it. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space to contain the paper, making it less independent. This claim is 3 as it points out specific references to Sup. Fig. 6 in section 3.1 and later references to model comparison and other details of the span vs. sentence investigation. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact issues from the references provided, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s reliance on supplemental space to contain certain information, such as references to Sup. Fig. 6 in section 3.1 and later references to model comparison and other details of the span vs. sentence investigation. This feedback highlights a potential problem with the paper\"s independence and comprehensibility. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as recommending ways to integrate the information into the main text or providing alternative solutions. While it points out a significant concern, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is limited to an extremely lowresource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method has potential for use in more NLP tasks. However, the comment does not provide explicit guidance on how the authors should address these weaknesses or improve the experiments. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to enhance their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is limited to an extremely lowresource regime and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks, which was unfortunately not shown. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The feedback is specific in identifying the limitations of the experiments and suggesting potential improvements, but without explicit references to sections, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are weak due to the limited setting to an extremely lowresource regime and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks but was not demonstrated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claim. Therefore, the comment is categorized as 3, as it provides some justification but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\"s length but should be stronger. It points out that the setting is limited to an extremely lowresource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method has potential for use in more NLP tasks. However, the comment lacks specific suggestions or guidance on how the authors might address these weaknesses or improve the experiments. While it highlights areas for improvement, the feedback is 3 as it provides some insight into potential enhancements but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a detailed set of questions that the authors should address to improve their draft. It explicitly instructs the authors to describe the traits of the experts, justify the need for expert annotation, and provide context on whether the experts were linguistic or domain experts. The comment also asks about the differences between expert and nonexpert annotation and whether it introduced linguistic challenges. These questions are clear and specific, guiding the authors on what information to include and how to address the points raised. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions for the authors to consider, such as describing the traits of the experts, justifying the need for expert annotation, and addressing differences between expert and nonexpert annotation. The comment also raises questions about linguistic challenges introduced by expert annotation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the traits of the experts and the necessity of expert annotation, suggesting that the authors should provide more context. However, it does not provide specific evidence or references to support the claim that expert annotation is necessary or that it introduces linguistic challenges. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment provides a detailed set of questions that the authors should address to improve their draft. It prompts the authors to describe the traits of the experts and justify why annotation must be carried out by experts, even if it has commercial value. The comment also asks about the expertise of the annotators and whether their annotation introduces linguistic challenges. This feedback is clear and actionable, offering specific areas for the authors to consider and improve upon. However, it could be more helpful if it provided suggestions on how to address these points or examples of how to justify the need for expert annotation. Overall, the comment is 4 as it guides the authors in enhancing their draft with detailed and constructive feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate these examples. The action is implicit and somewhat vague, as the authors need to infer that they should include examples of the system in action. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system applied to actual texts, which implies that it addresses the methodology or results section of the paper. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in its suggestion to include examples of the system on actual texts, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this would be beneficial or how it could enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. This feedback is 3 as it provides a specific suggestion for improvement, which could enhance the paper by offering a more concrete understanding of the system\"s application. However, the comment lacks depth and does not provide detailed guidance on how to incorporate these examples or what specific texts should be used. To be more helpful, the comment could include examples of how such examples could be integrated or what kind of texts would be most illustrative. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but these hypotheses are not studied or discussed again. The reviewer suggests that the paper is misleading and would have preferred a deeper exploration of these topics. However, the comment does not provide specific guidance on how the authors should address this issue or what additional steps they should take to study these hypotheses. The action is implicit and vague, as the authors are left to infer that they need to conduct further research or analysis on the hypotheses, but without concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 078086, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the hypotheses, noting that they are not studied or discussed again, which is misleading. The comment further suggests that the paper should go deeper into these topics, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but these hypotheses are not studied or discussed again. The reviewer finds this misleading and suggests that the paper should go deeper into these topics. However, the comment does not provide specific examples or references to support the claim that the hypotheses are not studied or discussed, nor does it offer detailed reasoning or evidence to substantiate the suggestion that the paper should delve deeper into these topics. As a result, the claim is 3, as it lacks sufficient evidence or justification to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s hypotheses regarding multilinguality and country/languagespecific bias, noting that they are not studied or discussed again after being raised in lines 078086. The reviewer finds this misleading and suggests that the paper should go deeper into these topics, at least to some extent. This feedback is clear and actionable, as it points out a critical gap in the paper\"s analysis and provides a specific direction for improvement. However, the comment could be more helpful if it offered suggestions on how to address this issue or what specific aspects of the hypotheses could be explored further. Overall, the comment is 4, as it effectively guides the authors towards a more comprehensive analysis of their hypotheses."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the use of the Challenge Set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the use of the Challenge Set, which is a specific aspect of the paper. The authors can infer that it relates to the methodology or evaluation section, but the comment does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. This feedback is 3 as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, it lacks depth and does not provide specific guidance on how to address the issue or improve the clarity of the paper. The authors are left with a general suggestion to clarify the use of the Challenge Set, but without additional details or examples, the feedback remains 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It suggests that the authors should provide a better understanding of the gap between the performance of the clustering approach and the oracle GAP for PPDBClus. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the draft. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the performance gap, but the comment lacks concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"nouns\" and \"parts of speech,\" allowing the authors to accurately identify the specific areas being addressed. It also specifies the issue by questioning the generalizability of the clustering approach and the performance gap between TWSI and PPDBClus. The comment is specific in detailing what needs to be addressed, such as understanding the gap in performance and clarifying the generalizability claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim that the clustering approach is generalizable to all parts of speech. The comment provides a logical reasoning based on the observed performance gap, suggesting that the authors should provide a better understanding of this gap. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach across all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim that the clustering approach is generalizable. This feedback is clear and actionable, as it directs the authors to address the performance gap and clarify the generalizability claim. However, the comment could be more helpful if it provided suggestions on how to investigate and address these issues, such as proposing specific analyses or experiments to better understand the performance differences. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly requests the authors to provide examples of spurious structures to clarify why the new model is better than MH. This is a clear and direct action, giving the authors a specific task to perform. The comment also specifies what needs to be addressed, making it 5. The authors know exactly what information is needed to improve their draft, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is its abstract nature and the lack of clarity on why the new model is better than MH. The request for examples of spurious structures provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 5.2 is abstract and lacks clarity on why the new model is better than MH. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion that the discussion is abstract or unclear. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion in section 5.2, noting that it is abstract and lacks clarity on why the new model is better than MH. It provides a clear and actionable suggestion by asking the authors to provide examples of spurious structures. This feedback is valuable as it directs the authors to a specific area for improvement, offering a concrete way to enhance the clarity and understanding of their work. However, the comment could be more helpful if it included additional guidance or examples of what constitutes spurious structures. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. This is an explicit action that the authors can take to improve their draft. The comment provides a clear and concrete suggestion, specifying what needs to be added to the table. This level of detail and specificity makes the action actionable, aligning with a score of 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. While it does not explicitly mention \"Table 1,\" the context and the specific suggestion imply that the authors can infer which part of the paper this comment pertains to. The comment is specific in its request to include the hard prompt baseline, providing a clear direction for improvement. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. This is a request for additional information, not a claim or opinion. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to demonstrate the performance increase of each method. This is a specific and actionable suggestion that could enhance the clarity and comprehensiveness of the results section. By adding this baseline, the authors can provide a more detailed comparison of their methods, which could be beneficial for readers and reviewers alike. However, the comment does not provide additional context or reasoning for why this inclusion would be particularly valuable, which could make it more helpful. Overall, the comment is 4 as it offers a clear direction for improvement but lacks depth in its explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the absence of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. While the comment implies that the authors should include numerical results to demonstrate the method\"s effectiveness, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide numerical results to address the reviewer\"s curiosity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights the lack of numerical results and expresses curiosity about applying the method to popular algorithms and comparing their performance with existing differential privacy (DP) algorithms. However, it does not specify which part of the paper lacks numerical results or where the authors should include them. This makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not reference specific sections or parts of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses curiosity about the lack of numerical results and the application of the method to popular algorithms. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual statement seeking clarification or additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment highlights a significant gap in the paper by noting the absence of numerical results. It expresses curiosity about how the method could be applied to popular algorithms and compared with existing differential privacy (DP) algorithms. While the comment identifies a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a missing element but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the experimental comparisons are not comprehensive enough and recommends including results for wider backbones like ResNet50 (2x) and ResNet50 (4x) for methods like MoCo and SimCLR. This feedback is explicit, as it directly instructs the authors to expand their experimental comparisons. The action is concrete, as it specifies which methods and backbones to include. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are not comprehensive enough and recommends including results for wider backbones like ResNet50 (2x) and ResNet50 (4x) for methods like MoCo and SimCLR. While it does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the experimental results or comparisons section. The comment is specific in suggesting which methods and backbones to include, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experimental comparisons are not comprehensive enough, specifically mentioning methods like MoCo and SimCLR that test results with wider backbones like ResNet50 (2x) and ResNet50 (4x). The reviewer recommends including these wider backbones for the proposed InvP method. This claim is 3 as it provides a specific suggestion for improvement but lacks detailed reasoning or examples of why these wider backbones are important. The authors would need to infer the significance of these backbones and how they might affect the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental comparisons, suggesting that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2x) and ResNet50 (4x) to provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to expand their experimental setup to include these wider backbones, which could enhance the robustness and relevance of their results. By addressing this suggestion, the authors can strengthen their paper\"s experimental validation and provide a more thorough analysis of their method\"s performance. Therefore, the comment is rated as 5, as it offers a specific and actionable improvement to the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the callout to Table 5 should be directed to Table 3, and it also points out that the figure 6 callout is not directing properly. This provides clear and specific actions for the authors to take, namely, to correct the table reference and ensure proper direction of the figure callout. The feedback is explicit and concrete, giving the authors a clear path to follow for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, including \"table 5,\" \"table 3,\" and \"figure 6,\" allowing the authors to accurately identify the sections being addressed. It also specifies the issue, which is the incorrect direction of the callouts, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about the incorrect direction of callouts in the paper, specifically mentioning \"table 5\" and \"table 3\" and \"figure 6.\" These are clear and specific observations that do not require any additional justification or evidence. The comment is factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two errors in the paper: the incorrect direction of callouts in Table 5 and Figure 6. It clearly specifies that the callout to Table 5 should be directed to Table 3, and it points out that the figure 6 callout is not directing properly. This feedback is clear and actionable, allowing the authors to make direct corrections to improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional guidance on how to ensure proper direction of callouts in the future. Overall, the comment is 4 as it provides clear guidance for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern with the experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It also suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue with the experiments, it does not provide explicit guidance on how the authors should address this concern or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer that they should expand their comparisons and provide an explanation for the selfcomparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the lack of comparisons with external work like SketchRNN. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which experiments are being referred to or what specific comparisons are missing. The comment is specific in suggesting that comparisons with SketchRNN could be performed, but it lacks detailed guidance on how to implement these comparisons. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s experiments are a concern because they only report selfcomparisons and lack an explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue with the experiments, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with SketchRNN provides some direction, but the comment could be strengthened by explaining why this comparison would be beneficial or how it would address the lack of motivation. Therefore, the comment is 3, as it provides a general direction for improvement but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant concern with the experiments section of the paper, specifically noting that only selfcomparisons are reported and that there is no explanation for this choice. It also points out the lack of motivation, suggesting that comparisons with external work like SketchRNN could be performed in a generative setting. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a clear suggestion for enhancing the paper\"s motivation and experimental rigor. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate these comparisons or what specific aspects of the experiments should be expanded upon. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might clarify or improve the confusing parts, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not specify which parts of the paper are confusing or what aspects need clarification. This makes it difficult for the authors to pinpoint the exact sections that require attention. The comment is weakly grounded because it does not provide specific guidance on where to focus, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the paper is confusing. Without additional context or explanation, the authors may find it challenging to understand and address the issues mentioned. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any details or examples of these confusing parts, nor does it offer suggestions or guidance on how the authors might address these issues. Without actionable feedback or specific examples, the comment lacks the depth and clarity needed to be helpful. As a result, it is rated as 2, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point challenges the claim that there is no corresponding set of tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not explicitly instruct the authors to include these references or to address the claim in their draft. While the action is implicit, it is concrete because the authors know what needs to be done to refute the claim. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment challenges a claim about the absence of corresponding tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or conclusion section, but this inference is not explicit. The comment is specific in identifying the claim as false and providing references to support this, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point challenges a claim by providing references to support the assertion that there are indeed corresponding tools for the reinforcement learning setting. This provides a clear and specific counterpoint, making the claim 5. The references offer concrete evidence to substantiate the claim, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment challenges a claim made in the paper, specifically questioning the assertion that there is no corresponding set of tools for the reinforcement learning setting. By providing references from both the submitted paper and external sources, the comment offers a clear and specific counterpoint, effectively verifying the claim. This feedback is 5 as it not only corrects a potential misperception but also provides the authors with a basis for further exploration and potential inclusion of relevant tools or references in their work. The comment is actionable, as it directs the authors to consider revising their claim and supports their efforts to improve the draft. Therefore, it aligns with a score of 5, indicating 5 feedback."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that the results are based on standard techniques but notes that they are not obvious a priori and require a fair degree of technical competency. While it highlights a potential issue with the results, it does not provide explicit guidance or suggestions on how the authors might address this concern. The comment lacks actionable details or concrete steps for improvement, leaving the authors uncertain about what specific aspects of the results need clarification or elaboration. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the results section, indicating that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, it does not specify which part of the paper this observation pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the results being not obvious a priori, it lacks grounding as it does not clearly identify the part of the paper being discussed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the results are based on \"standard\" techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges that the results are based on \"standard\" techniques but notes that they are not obvious a priori, requiring a fair degree of technical competency. This observation highlights a potential issue with the clarity and accessibility of the results, suggesting that the techniques may be more complex than initially apparent. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their results. While it identifies a potential area for improvement, the feedback is 3 as it points out a limitation but does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two, given the small difference in performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their conclusion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or justification for their conclusions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two, given the small difference in performance. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the experimental results or discussion, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the issue with the conclusion, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point raises a concern about the amount of data used to train the text disambiguation model compared to the endtoend system. It questions the conclusion that the direct model is the better of the two, given the small difference in performance. However, the comment does not provide specific evidence or reasoning to support this claim, such as detailed comparisons or statistical analysis. The lack of supporting details or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the conclusion that the direct model is the better of the two proposed systems, given the small difference in performance and the amount of data used for training. It raises a valid concern about the reliability of the conclusion based on the limited data used for training the text disambiguation model. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important point, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the paper: the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation. It explicitly states that the paper does not provide evidence or justification for GaRare\"s advantages over GaLore based on theoretical analysis. Additionally, it suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback is explicit and provides concrete actions for the authors to take, such as providing theoretical justification and enhancing the algorithmic presentation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GaRare\" and \"GaLore,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide a clear motivation for using GaRare and lacks evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion for a more detailed algorithmic presentation is somewhat vague, as it does not specify what aspects of the algorithm should be clarified. Therefore, the comment is 3, as it provides some guidance but requires additional elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the paper does not provide a clear motivation for using GaRare, suggesting that it lacks evidence or justification for its advantages over GaLore based on theoretical analysis. This feedback is actionable as it directs the authors to strengthen the motivation for their choice of method. Second, the comment highlights the need for a more detailed algorithmic presentation, particularly to clarify the process of recovering updated parameters from projected gradients. This suggestion is also actionable, as it provides a specific area for the authors to enhance the clarity and comprehensiveness of their work. Overall, the comment is 4 as it identifies clear areas for improvement and provides actionable feedback, but it could be more comprehensive by offering specific examples or references to support the suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model. It specifically mentions the performance of the \"ATT(+H)\" model in Figure 4, asking for the result if the model did not consider attention retrieval from the attention memory. This request provides a clear and explicit action for the authors to take, as it specifies the dataset and model to be tested and the exact aspect to investigate. The comment also offers a specific question that the authors can address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"visDial dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting an ablation study on the visDial dataset and asking for the result of a specific experiment involving the \"ATT(+H)\" model. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further support the proposed visual reference resolution model. It specifically mentions a particular experiment involving the \"ATT(+H)\" model in Figure 4. While the comment provides a clear suggestion for additional analysis, it lacks detailed reasoning or evidence to fully substantiate the need for this ablation study. The request for the result of the experiment if the model did not consider attention retrieval from the attention memory is a specific inquiry that could be addressed with additional data or analysis. However, the comment does not provide explicit justification or references to support the claim that this ablation study is necessary. Therefore, the comment is 3, as it offers a suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to conduct an ablation study on the visDial dataset to further support the proposed visual reference resolution model. It specifically mentions a particular experiment involving the \"ATT(+H)\" model in Figure 4, asking for the result if the model did not consider attention retrieval from the attention memory. This feedback is 5 as it directs the authors to a specific area for improvement and provides a clear path for enhancing the robustness and validity of their findings. By addressing this suggestion, the authors can strengthen their paper\"s contribution and provide a more comprehensive evaluation of their model\"s performance. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their approach. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses a personal belief about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it may make the approach less dataefficient and harder to train models using gradient descent. However, it does not specify which part of the paper this critique pertains to, nor does it provide detailed guidance on how the authors might address this issue. The lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and how to improve it. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a personal belief that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples, references, or detailed explanations to substantiate the assertion. Without additional context or justification, the claim remains 1, as it does not provide the authors with a clear understanding of the basis for the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses a personal belief that the need for reinforcement learning in a static VQA task may be a potential weakness, making the approach less dataefficient and harder to train models using gradient descent. However, it does not provide any specific evidence, examples, or reasoning to support this claim. Without actionable feedback or suggestions for improvement, the comment lacks depth and does not offer the authors a clear path to address the issue. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete actions for the authors to take, making the comment 5. The authors know exactly what needs to be done to address the feedback, which is to include a specific table and provide an explanation. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. This provides clear guidance on what needs to be revised, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, and that the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths and explaining how the dataset is balanced across categories. While the comment identifies a potential issue with the paper, it lacks specific examples or references to support the claim that the distribution is crucial for robustness assessment. The suggestion to include a table and explain the dataset\"s balance is a logical response but lacks detailed justification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a more detailed analysis of the distribution of video lengths within the benchmark dataset. It highlights the importance of this information for assessing reasoning ability and robustness, which is a crucial aspect of the paper\"s methodology. The comment suggests including a table to show the distribution of video lengths and explains how the authors should ensure a balanced representation across the 11 categories. This feedback is clear and actionable, offering the authors a specific way to enhance the transparency and comprehensiveness of their work. However, it could be more helpful if it provided additional guidance on how to present this information effectively or if it suggested specific examples of how this could impact the results. Overall, the comment is 4, as it provides valuable insights and actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should take a cautious approach regarding their contribution until the promised dataset is made publicly available. However, it does not provide explicit guidance on how the authors should proceed or what actions they should take to address this issue. The comment lacks concrete details or suggestions on how to implement this advice, leaving the authors uncertain about how to respond. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the dataset not being publicly available, which is a concern regarding the contribution. However, it does not specify which part of the paper discusses the dataset or how it is relevant to the contribution. The authors can infer that it relates to the dataset section or discussion, but this inference is not explicit. The comment is specific in identifying the issue of dataset availability, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the dataset promised in the paper is not yet publicly available, suggesting a cautious approach until the dataset is openly accessible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a significant issue with the paper, noting that the promised dataset is not yet publicly available. This is an important point that the authors should address, as it could impact the credibility and reproducibility of their work. However, the comment lacks specific guidance or suggestions on how the authors might proceed or what actions they could take to address this issue. While it identifies a critical concern, it does not provide actionable advice or detailed feedback, making it 3. The authors are left with a clear understanding of the problem but without clear steps to resolve it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as AB, which aim to adapt to outofdistribution data. It also questions how to prove that data processing is superior to model parameter adjustment. While the comment implies that a comparison should be made based on experimental results, it does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison and understand how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as AB, which aim to adapt to outofdistribution data. It questions how to prove that data processing is superior to model parameter adjustment. However, the comment does not specify which part of the paper should include this comparison or where the discussion of data processing and model parameter adjustment is located. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in its critique, it lacks full grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks a comparison with testtime adaptation (TTA) methods, such as AB, which aim to adapt to outofdistribution data. The reviewer questions how to prove that data processing is superior to model parameter adjustment. While the comment identifies a potential gap in the paper\"s analysis, it lacks specific examples or references to support the claim that a comparison is necessary. The reasoning is somewhat vague, as it does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. Therefore, the comment is 3, as it provides a general suggestion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, such as AB, which aim to adapt to outofdistribution data. It questions how the paper can prove that data processing is superior to model parameter adjustment. This feedback is 3 as it highlights an area for improvement and prompts the authors to consider a comparison that could strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to conduct this comparison or what aspects should be emphasized. Overall, the comment offers a direction for improvement but lacks depth and detail, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies an error in the first expression for J(\u03b8) in Section 3.2.1, specifying that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This provides a clear and direct action for the authors to take, namely to correct the expression. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first expression for J(\u03b8), suggesting that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This is a factual statement that does not require verification, as it is a matter of correcting a specific mathematical expression. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific error in the mathematical expression for J(\u03b8) in Section 3.2.1, suggesting that it should be corrected to Q(s_t0, \u03c0_\u03b8(s_t0)). This feedback is clear and actionable, providing the authors with a direct correction to make. By highlighting this error, the reviewer helps the authors improve the accuracy and clarity of their work. However, the comment could be more helpful if it explained why this correction is necessary or provided additional context on the importance of the expression. Overall, the comment is 4 as it guides the authors in making a specific improvement, but it could be more comprehensive with additional explanation."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should correct the capitalization of various words in the references, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This is a clear and explicit action that the authors can take to improve the formatting of their references. The second part of the comment provides specific examples of references that need capitalization, which further clarifies the action. The second part of the comment is 3, as it suggests a specific correction but does not provide detailed guidance on how to apply the action. Overall, the comment is 4 due to the explicit nature of the first part and the specific examples provided in the second part.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"p.8,\" \"p. 13, supplement, Fig,\" and references, allowing the authors to accurately identify the areas being addressed. It is also specific because it provides detailed feedback on the capitalization of words in the references and suggests corrections for specific examples, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This level of detail helps the authors understand what needs to be addressed and how to make the necessary corrections. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests that the authors should correct the capitalization of various words in the references, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This is a clear and explicit suggestion that does not require any additional justification or evidence. The second part of the comment provides specific examples of references that need capitalization, which further supports the claim. Therefore, the comment is 5, as it provides clear and specific guidance on what needs to be corrected, making it a 5.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct aspects of the paper. First, it suggests that the authors should correct the capitalization of various words in the references, such as \"ai,\" \"bayesian,\" and \"Advances in neural information processing systems.\" This is a clear and direct suggestion that can significantly improve the formatting and professionalism of the references. Second, the comment points out a typographical error in the reference \"Dusenberry et al. (2020) was published in ICML 2020 Osawa et al. (2019) was published in NeurIPS 2019 Swiatkowski et al. (2020) was published in ICML 2020 p. 13, supplement, Fig.\" This feedback is specific and helps the authors correct a potential oversight in their reference list. Overall, the comment is 5 as it provides clear and actionable suggestions for improving the paper, making it a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the parameter values used in the paper, specifically asking for clarification on the model parameters for task 1, the choice of lambda for the Boltzmann policy, and how the parameters were chosen. While the comment does not explicitly instruct the authors to provide this information, the questions are clear and specific, indicating that the authors know what information is missing and how to address it. The request for maximum likelihood estimates adds a concrete detail on how the parameters were chosen, further enhancing the actionability. Therefore, the comment is 4, as it provides explicit guidance on what needs to be clarified and how to address it.", "grounding_specificity_rationale": "The comment raises questions about specific parameter values and their selection, particularly regarding the Boltzmann policy. However, it does not specify which part of the paper these questions relate to, such as a particular section or table where these parameters are discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its requests for clarification on parameter values and their estimation, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific parameter values and their selection, such as the model parameters for task 1 and the choice of lambda for the Boltzmann policy. It also asks how the parameters were chosen, specifically mentioning maximum likelihood estimates. However, the comment does not contain any claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises several specific questions about the parameter values used in the paper, particularly regarding the Boltzmann policy. It asks for clarification on the model parameters for task 1 and the choice of lambda, as well as how the parameters were chosen. This feedback is clear and actionable, providing the authors with specific areas to address and questions to answer. However, the comment could be more helpful if it offered suggestions on how to present this information or if it pointed out the potential impact of these parameters on the results. Overall, the comment is 4 as it directs the authors\" attention to important details that need clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of applying Conditional Batch Norm (CBN) to different layers in the model, specifically mentioning Table 2. It asks the authors to provide an explanation for why this might be happening. While the comment implies that the authors should clarify their findings, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and refers to the specific layers (2, 3, and 4) being discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the performance impact of applying Conditional Batch Norm to different layers and asks for an explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, specifically mentioning Table 2. It does not contain any subjective claims, opinions, or suggestions that require verification. Instead, it is a request for clarification or an observation that requires further explanation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance impact of applying Conditional Batch Norm (CBN) to different layers in the model, as observed in Table 2. It highlights a potential issue with the model\"s performance when CBN is applied to layer 2 in addition to layers 3 and 4, compared to when it is applied to layers 4 and 3 only. The comment is 3 as it identifies a specific area for further investigation and encourages the authors to provide an explanation. However, it lacks detailed guidance or suggestions on how the authors might address this issue or what additional analysis could be conducted. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, noting that it defers this problem to future work. It then questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method to handle headpose. The action is implicit and vague, as the authors are left to infer that they need to explore ways to incorporate headpose conditioning into their NeRF model. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method, namely its inability to handle headpose, and references a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, it does not specify which part of the paper discusses the headpose issue or how the proposed method is supposed to handle it. The authors can infer that it relates to the method section or experimental results, but this inference is not explicit. The comment is specific in questioning the inability to condition headpose parameters in the NeRF model, but it lacks full grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s inability to handle headpose, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. The reviewer questions why it is not possible to condition the headpose parameters in the NeRF model, similar to the referenced work. However, the comment lacks specific details or examples of how the proposed method could be improved or adapted to handle headpose, making it difficult for the authors to fully understand and address the issue. While the reference to a previous work provides some context, the lack of detailed reasoning or specific suggestions limits the verifiability of the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed method, namely its inability to handle headpose, and notes that this issue is deferred to future work. It then questions why it is not possible to condition the headpose parameters in the NeRF model, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. This feedback is 3 as it highlights a potential area for improvement and provides a reference for the authors to consider. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this limitation or adapt their method to handle headpose. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the similarity between spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that they are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The comment implies that the authors should consider the impact of these rare spurious examples on the trained model. However, it does not explicitly instruct the authors to take any specific action, such as addressing the impact of these triggers or providing a detailed analysis. The action is implicit and somewhat vague, as the authors can infer the need for further investigation but lack concrete guidance on how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, referencing previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The comment specifies the issue of rare spurious examples having a large impact on the trained model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, which are artificial patterns appearing a few times in the training set. It references previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers. The claim is supported by logical reasoning and references to external works, providing a clear and detailed explanation of the issue. This makes the claim 5, as it offers both logical reasoning and specific references to substantiate the assertion. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the spurious features in Sections 3.1 and 3.2, noting their similarity to backdoor triggers. It provides references to previous works by Chen et al. (2017) and Gu et al. (2019) that use similar triggers, highlighting the potential impact of rare spurious examples on the trained model. This feedback is 3 as it points out a relevant area for consideration and provides references to existing literature. However, it could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue or further explore the impact of these triggers. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the structural optimization is emphasized as a main component but notes that the optimization algorithm is directly from previous works, which can be confusing and reduces the contribution. While the comment identifies a potential issue with the originality of the optimization algorithm, it does not provide explicit guidance on how the authors should address this concern. The feedback lacks concrete suggestions or actions for the authors to take, such as recommending a specific way to differentiate their work or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the structural optimization component, which is mentioned several times in the paper, indicating that it is a main component. However, it does not specify which part of the paper this component is discussed in, making it weakly grounded. The comment is specific in pointing out that the optimization algorithm seems to be directly from previous works, which is confusing and reduces the contribution. This provides a clear direction for the authors to consider revising their presentation of the optimization algorithm to enhance its originality. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the structural optimization is emphasized as a main component but notes that the optimization algorithm is directly from previous works, which is confusing and reduces the contribution. The comment provides a logical reasoning by pointing out the inconsistency between the emphasis on structural optimization and the lack of originality in the optimization algorithm. However, it lacks specific references or examples to support the claim, making it 3. The authors would need to infer the exact nature of the confusion and the potential impact on the contribution, which could be challenging without additional context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the structural optimization component, noting that it is emphasized as a main component but seems to be directly from previous works. This observation highlights a lack of originality, which could be confusing for the reader and potentially reduce the contribution of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a potential problem but lacks depth and actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the pipeline style method with two models does not provide better average results for both XVNLI and MaRVL, and the baseline models in the experiments are not well introduced. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to improve the performance of their models or provide a more detailed explanation of the baseline models. However, the lack of concrete suggestions or steps makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of a pipeline style method with two models, noting that it does not provide better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these models or the experiments, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issues with the performance and the lack of introduction of baseline models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline style method with two models does not provide better average results for both XVNLI and MaRVL, and that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the pipeline style method with two models does not provide better average results for both XVNLI and MaRVL, and the baseline models in the experiments are not well introduced. This feedback is clear and actionable, as it points out areas where the authors need to improve their methodology and presentation. However, the comment could be more helpful if it provided suggestions on how to enhance the performance of the models or offered guidance on how to better introduce the baseline models. Overall, the comment is 4 as it directs the authors to address critical aspects of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors primarily focus on SSC and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. While the comment implies that the authors should include these comparisons to provide a more comprehensive analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons to enhance their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the discussion or comparison of methods, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting that the authors should include comparisons with these methods, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, the comment does not provide specific examples or references to support the claim that these methods are computationally efficient or come with similar guarantees. Without detailed evidence or reasoning, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the authors primarily focus on a single method, namely SSC, and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is valuable as it encourages the authors to broaden their analysis and provide a more comprehensive comparison of their method with existing literature. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these comparisons or what aspects of these methods should be highlighted. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights the small contributions of the paper compared to previous methods, such as NCNet 6 and Sparse NCNet 21. It also notes that the paper seems to be mostly engineeringfocused and performs similarly to its predecessors. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the identified issues or improve their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific references to previous methods, such as NCNet 6 and Sparse NCNet 21, which provides some grounding as it allows the authors to identify the context of the discussion. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the paper\"s contributions and performance, but without explicit grounding, it is challenging for the authors to fully address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s contributions are small compared to previous methods, such as NCNet 6 and Sparse NCNet 21, and that the paper is mostly engineeringfocused. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or analysis to substantiate the assertion that the contributions are small or that the paper is mostly engineeringfocused. Without explicit references or detailed explanations, the claim remains 1, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights the small contributions of the paper compared to previous methods, such as NCNet 6 and Sparse NCNet 21. It also notes that the paper seems to be mostly engineeringfocused and performs similarly to its predecessors. However, the comment lacks specific suggestions or actionable feedback on how the authors might address these issues or improve their work. Without detailed guidance or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not provide actionable insights for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. It suggests that the statements about semantic segmentation being a lowlevel cue should be removed from the paper. This feedback is clear and direct, providing the authors with a specific action to take: removing the statements about semantic segmentation being a lowlevel cue. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the terminology used in the paper, specifically regarding the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, which implies that the authors should reconsider their statements about semantic segmentation being a lowlevel cue. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The feedback is specific in identifying the need to remove statements about semantic segmentation being a lowlevel cue, but without explicit grounding, the authors may struggle to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. This claim is 3 as it provides a logical reasoning for why the term \"semantic\" segmentation is not lowlevel, based on the specific nature of the segmentation. However, the comment lacks detailed examples or references to support the claim fully. The authors would need to infer the exact reasoning behind the claim, which makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, specifically regarding the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, which implies that the term \"semantic\" segmentation is not lowlevel. This feedback is clear and actionable, as it provides the authors with a specific area to address by removing statements about semantic segmentation being a lowlevel cue. However, the comment could be more helpful if it offered suggestions on how to rephrase or restructure the paper to accurately reflect the nature of semantic segmentation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies a gap in the presentation of the results, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include these cases in the tables, but the comment lacks concrete instructions on how to implement this change. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the ablation experiment, specifically mentioning the performance without reinforcement learning and the lack of listing cases where dependency tree and RL are not used. This provides some grounding as it refers to a specific part of the paper, but it does not specify which tables or sections are affected. The comment is specific in identifying the issue with the tables, but the lack of explicit mention of the sections makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without dependency tree, and the two tables do not list the cases where dependency tree and RL are not used. This claim is 3 as it points out a specific issue with the presentation of results in the tables. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the issue and how to address it, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is 3 as it highlights a gap in the presentation of results, which could be addressed by including these cases in the tables. However, the comment lacks detailed guidance on how to present this information or suggestions for improving the clarity of the experiment. While it provides a starting point for the authors to consider, it could be more helpful with additional context or specific recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It also points out that previous work has considered multiple vulnerabilities simultaneously. The reviewer suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment highlights potential issues and suggests areas for clarification, it does not provide explicit guidance on how the authors should address these concerns or improve the methodology. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously. The comment also raises concerns about the interpretability of the results. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issues with the methodology and the comparison to previous work, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously. The reviewer suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment provides a logical basis for questioning the methodology, it lacks specific references or examples to fully substantiate the claim. The suggestion to consider multiple vulnerabilities at a time is a reasonable point, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the comment is 3, as it provides a basis for questioning but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously and suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case. The comment also points out that the results are difficult to interpret and may be marginal improvements at best. While the comment identifies a potential issue with the methodology and provides some insight into the limitations, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is 3 as it highlights an area for improvement but could be more actionable with additional details or recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It also points out that Theorems 1 and 2 prove the relationship between GCL and a clearer community structure, but the connection between degree bias and this relationship is not intuitive. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or what kind of explanations are needed. The authors are left to infer that they should provide more detailed explanations or examples to clarify the relationship between degree bias and the community structure. Therefore, the comment is 3, as it highlights a need for clarification but lacks concrete steps for the authors to take.", "grounding_specificity_rationale": "The comment addresses the need for more explanations regarding how a small degree of bias can be achieved from a clear community structure. It specifically mentions Theorems 1 and 2, which provide evidence of GCL conforming to a clearer community structure. However, the comment does not specify which part of the paper these theorems are located in, making it weakly grounded. The comment is specific in identifying the need for more detailed explanations about the relationship between degree bias and the community structure. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which prove the relationship between GCL and a clearer community structure, but questions the intuition behind the connection between degree bias and this relationship. While the comment identifies a gap in the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer that more detailed explanations are needed, but the comment does not provide explicit guidance on what those explanations should include. Therefore, the comment is 3, as it highlights a potential area for improvement but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding how a small degree of bias can be achieved from a clear community structure. It references Theorems 1 and 2, which provide evidence of GCL conforming to a clearer community structure, but questions the intuition behind the relationship with degree bias. This feedback is 3 as it points out a gap in the paper\"s explanation and suggests that more detailed explanations are needed. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this issue, such as additional examples or detailed explanations. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to clarify this aspect in their paper, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it points out a potential area for clarification but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 182183\" and \"Figure 2.c,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the construction of clean exemplar manifolds for nonstochastic networks and how the denominator of Figure 2.c is computed for ResNet50 and ATResNet50 networks. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their methodology. By addressing this question, the authors can improve the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue. Overall, the comment is 4 as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point states that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the originality of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the originality of the paper, stating that the main idea of variable splitting is not new and that the algorithm is also not new. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity in detailing what aspects of the originality are limited or how the authors might address this issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the originality of the paper by pointing out that the main idea of variable splitting is not new and that the algorithm is also not new. This feedback is clear and identifies a significant issue with the paper\"s contribution. However, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. While it highlights a critical area for improvement, the comment could be more helpful if it provided actionable advice or examples of how to differentiate the paper from existing work. Therefore, the comment is 3, as it points out a significant weakness but does not fully support the authors in addressing it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. The comment implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it would provide a better understanding of the stateoftheart. While the comment explicitly states that the paper should be discussed, it does not provide detailed guidance on how to integrate this paper into the draft or what specific aspects should be compared. The action is implicit but concrete, as the authors know what to do but may need some additional direction on how to implement it. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. It implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it would provide a better understanding of the stateoftheart. However, the comment does not specify which part of the paper this related work should be discussed in, making it weakly grounded. The comment is specific in suggesting a related work to consider, but without explicit mention of the paper\"s relevance to specific sections, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, is a related work that was possibly missed by the authors. The comment suggests that this paper deals with hypergraph data and tensors, and it should be discussed and compared against to provide a better understanding of the stateoftheart. However, the comment does not provide specific details or examples of how this paper relates to the current work or what aspects should be compared. This lack of detailed justification or examples makes the claim 3, as the authors would need to independently verify the relevance and potential impact of the suggested paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential oversight in the literature review by suggesting that the authors may have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati. The comment highlights that this paper deals with hypergraph data and tensors, which are relevant to the current work. By suggesting that the authors discuss and compare this paper, the comment provides a clear and actionable suggestion for improving the draft. It offers a specific reference that could enhance the authors\" understanding of the stateoftheart in the field. However, the comment could be more helpful if it provided additional context or guidance on how to integrate this paper into the discussion. Overall, the feedback is 4 as it directs the authors to a relevant piece of literature that could enrich their analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in following the experimental procedures and evaluations in the paper, indicating that the authors may need to clarify or simplify these sections. However, the comment does not provide specific guidance on how to improve the clarity or structure of the experimental section. The authors are left with a general understanding of the issue but without concrete steps to address it. Therefore, the comment is 3, as it identifies a problem but lacks detailed instructions on how to resolve it.", "grounding_specificity_rationale": "The comment expresses difficulty in following the experimental procedures and evaluations in the paper, indicating that the authors may need to clarify or simplify these sections. However, it does not specify which part of the paper is causing the confusion, making it weakly grounded. The comment is specific in its feedback, as it clearly identifies the issue of difficulty in following the experimental procedures and evaluations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is \"extremely hard to follow,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the difficulty and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a significant issue with the paper, noting that it was \"extremely hard to follow\" and that the authors had difficulty understanding the experimental procedures and evaluations. This feedback is valuable as it identifies a critical area for improvement, indicating that the authors need to clarify or simplify the sections in question. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending ways to improve clarity or structure. While it points out a significant problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a claim in section 2 of the paper and questions its validity, stating that it is true but not an advantage. The reviewer suggests that a model capable of handling only a single time series data is almost useless. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2\" and provides a specific claim about the content of that section. It also specifies the issue by questioning the claim that INRs operate on a perdatainstance basis and suggesting that this is not an advantage because the model cannot handle multiple time series data. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"INRs operate on a perdatainstance basis\" is true but not an advantage. The reviewer provides a logical reasoning by suggesting that a model capable of handling only a single time series data is almost useless. This reasoning is clear and supported by the reviewer\"s assertion, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the notion of a model\"s usefulness. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim in section 2 of the paper and questions its validity, suggesting that the claim is true but not an advantage. The reviewer provides a logical reasoning by pointing out that a model capable of handling only a single time series data is almost useless. This feedback is clear and actionable, as it prompts the authors to reconsider the significance of their claim and potentially revise their draft to address this concern. However, the comment could be more helpful if it offered suggestions on how to reframe the claim or provide additional context to support the argument. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their work that needs further clarification or revision."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation in the experiments, specifically noting that most of the experiments are limited to RoBERTabase and do not generalize to other models adopting learnable APEs. It suggests that the authors should investigate the generalizability of their results to differences in model size, objective function, and architecture, including the GPT2 model. The comment provides a specific example of what could be included, such as the results of Figure 2 for GPT2. This feedback is explicit and provides concrete guidance on what additional experiments or analyses the authors should consider, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Most of the experiments (excluding Section 4.1.1) are limited to RoBERTabase only,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the generalizability of results to other models adopting learnable APEs, differences in model size, objective function, and architecture, including the GPT2 model. The comment provides a clear and specific direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and do not generalize to other models adopting learnable APEs. It suggests that the authors should investigate the generalizability of their results to differences in model size, objective function, and architecture, including the GPT2 model. The comment provides a specific example of what could be included, such as the results of Figure 2 for GPT2. While the suggestion is clear, it lacks detailed reasoning or references to support the claim that the results cannot be generalized. The authors are left to infer the importance of this generalizability, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, specifically noting that most of the experiments are limited to RoBERTabase and do not generalize to other models adopting learnable APEs. It highlights the importance of investigating the generalizability of results to differences in model size, objective function, and architecture, including the GPT2 model. The comment provides a specific suggestion by asking for more analysis and discussion for GPT2, such as including the results of Figure 2 for this model. This feedback is clear and actionable, offering the authors a concrete direction for improving the generalizability of their findings. However, it could be more helpful if it provided additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4, as it effectively directs the authors to address a significant limitation in their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the authors should explore these areas, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to demonstrate generalizability. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the parameters in Table 1 are only applicable to image data and ViT models, suggesting that the authors should consider applying the same principles to other areas such as NLP or simpler models in the image domain (CNNs). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs). While the comment implies that the method might not generalize to these areas, it does not provide specific examples or references to support this claim. The suggestion is based on a logical assumption about the potential limitations of the method, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the method beyond image data and ViT models. It suggests that the authors should consider applying the same principles to other areas, such as NLP or simpler models in the image domain (CNNs), to demonstrate the method\"s generalizability. This feedback is valuable as it encourages the authors to expand their experimental scope and potentially enhance the applicability and impact of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct these additional experiments. Overall, the comment is 4 as it directs the authors to an important area for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer suggests that this condition may lead to unreasonably large learning rates when working with largescale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors might address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the scalability of the learning rate condition. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the required condition on the learning rate, noting that it is not scalable and may lead to unreasonably large learning rates when working with largescale datasets. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in identifying the issue with the scalability of the learning rate condition and its potential impact on largescale datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and unrealistic. The reviewer provides a logical reasoning by stating that in practice, step sizes do not grow with the sample size, which could lead to unreasonably large learning rates when dealing with largescale datasets. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide more detailed evidence or examples to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic in practice. The reviewer points out that step sizes typically do not grow with the sample size, which could lead to unreasonably large learning rates when working with largescale datasets. This feedback is clear and actionable, as it highlights a potential limitation of the current approach and suggests that the authors need to reconsider the scalability of the learning rate condition. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative approaches to consider. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect that needs improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit feedback on the abstract, stating that it does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address these issues or what specific changes should be made. The authors are aware of what needs to be improved but may need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the abstract lacks description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract lacks description of how the idea was evaluated and what the outcome was, and mentions minor language issues. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that it provides a good explanation of the proposed idea but lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include more information about the evaluation process and outcomes. Additionally, the comment mentions minor language issues, which could be addressed to improve the clarity of the abstract. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to enhance the abstract further. Therefore, the comment is 4, as it provides clear direction for improvement but could be more comprehensive with additional suggestions. This aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses skepticism about the experimental results and questions the lack of experiments on the POMDP problem with nonconvex value functions, specifically mentioning examples like surveillance in museums with thresholded rewards and privacy preserving data collection. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments should be conducted. The action is implicit and vague, as the authors are left to infer that they need to conduct additional experiments, but without detailed instructions on what those experiments should entail. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of experiments on the POMDP problem with nonconvex value functions, particularly in the context of the examples provided. The reviewer questions why there are no experiments on these settings, even in a simulated context, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings, even in a simulated context. However, the comment lacks specific examples or detailed reasoning to support the claim that the experiments are not useful. The absence of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the experimental results, specifically questioning the lack of experiments on the POMDP problem with nonconvex value functions, despite mentioning examples of such settings. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings, even in a simulated context. This feedback is 3 as it identifies a gap in the experimental validation of the paper\"s claims. However, it lacks specific suggestions or guidance on how the authors might conduct these experiments or what additional experiments would be beneficial. The comment provides a direction for improvement but does not offer detailed actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It suggests that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it implies that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment provides a clear direction for potential improvements, it does not explicitly instruct the authors to include this analysis in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider adding this analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion about the potential benefits of epochwise analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint where to incorporate this suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. However, the comment does not provide specific examples or references to support the claim that epochwise analysis would be beneficial. While the suggestion is logical and could be supported by further evidence, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that epochwise analysis could provide valuable insights into the behavior of optimization algorithms, particularly in finite sum settings. It implies that this analysis could help investigate the effects of batch size and different sampling strategies on the progress of algorithms after every full pass of the data. Additionally, it suggests that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment identifies a potential area for improvement, it does not provide specific guidance on how to implement this analysis or what aspects to focus on. The feedback is 3 as it offers a direction for enhancing the paper\"s analysis, but it lacks depth and actionable details, leaving the authors with a general idea of what could be improved but without concrete steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the differentiation between the 3 classes of extreme speech and questions the classification of a specific instance. It suggests that the authors need to clarify why the instance \"I support it 100/% #\u092e\u0941\u0938\u094d\u0932\u093f\u092e\u094b_\u0915\u093e_\u0938\u0902\u092a\u0942\u0930\u094d\u0923_\u092c\u0939\u093f\u0937\u094d\u0915\u093e\u0930\" is categorized as exclusionary extreme speech rather than derogatory extreme speech. The comment also questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies specific areas for clarification and suggests potential issues, it does not provide explicit guidance on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to clarify the classification and the role of local regulation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Paper Summary\" and references specific lines (438441) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the differentiation between the 3 classes of extreme speech and the classification of a particular instance. The comment is specific in detailing what needs to be addressed, namely, the differentiation between classes and the role of local regulation in annotations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the differentiation between the 3 classes of extreme speech and questions the classification of a specific instance. It suggests that the authors need to clarify why the instance \"I support it 100/% #\u092e\u0941\u0938\u094d\u0932\u093f\u092e\u094b_\u0915\u093e_\u0938\u0902\u092a\u0942\u0930\u094d\u0923_\u092c\u0939\u093f\u0937\u094d\u0915\u093e\u0930\" is categorized as exclusionary extreme speech rather than derogatory extreme speech. The comment also questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment identifies specific areas for clarification, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the specific issues and how to address them, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the differentiation between the 3 classes of extreme speech, particularly the distinction between derogatory and exclusionary extreme speech. It raises a question about the classification of a particular instance and suggests that the authors need to clarify why it is categorized as exclusionary extreme speech. Additionally, the comment questions the role of local regulation in annotations and its impact on zeroshot crosscountry classification. While the comment highlights important areas for clarification and improvement, it could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the feedback is 3 as it prompts the authors to consider and potentially revise their classification criteria and the role of local regulation, but it lacks detailed guidance on implementation. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This action is clear and direct, providing a specific and concrete step for the authors to take to address the issue of understanding whether the performance improvement is solely due to the network design or the nature of ImageNet. The comment also highlights the importance of this analysis and provides a rationale for why it is necessary. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides clear guidance on what specific aspect of the paper needs to be addressed. The comment also specifies the importance of understanding whether the performance improvement is solely due to the network design or the nature of ImageNet, which adds specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. The rationale provided explains the importance of this graph in understanding whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet. The comment also highlights the potential unfair advantage of algorithms that skip layers or channels. While the reasoning is clear, the comment could be strengthened by providing specific examples or references to support the claim about the potential unfair advantage. Therefore, the comment is 4, as it provides a logical argument but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This is important for understanding whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet. The comment also highlights the potential unfair advantage of algorithms that skip layers or channels, which adds depth to the feedback. By addressing this suggestion, the authors can gain valuable insights into the factors contributing to their results, enhancing the robustness and interpretability of their work. However, the comment could be more helpful if it provided additional guidance on how to interpret the results or what specific insights the graph should reveal. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the text needs to be changed to be mathematically correct, implying that the authors should revise the content to ensure it aligns with mathematical standards. It also questions the notation \"L_l\" and suggests that it should be introduced beforehand. However, the comment does not provide specific guidance on how to make these changes or what aspects of the mathematical content need to be corrected. The action is implicit and somewhat vague, as the authors can infer the need for revision but lack detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" and \"mathematically correct,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the notation \"L_l\" and suggests that it should be introduced beforehand. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the text needs to be changed to be mathematically correct, implying that the current formulation is incorrect. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the mathematical error. Additionally, the comment questions the notation \"L_l\" and suggests it should be introduced beforehand, but it lacks detailed reasoning or examples to substantiate this claim. Without explicit evidence or detailed reasoning, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the mathematical correctness of the text, suggesting that it needs to be revised to align with mathematical standards. It also questions the notation \"L_l\" and recommends introducing it beforehand. However, the comment lacks specific guidance on how to correct the mathematical errors or improve the notation, leaving the authors with a general direction but no detailed steps to follow. While it points out an area for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the evaluation of the timeaware model, suggesting that the effectiveness of the proposed methods might be questionable when the training and evaluation timesteps are the same. It implies that the authors should consider evaluating the model under different timestep scenarios to better understand its performance. However, the comment does not explicitly instruct the authors to conduct such evaluations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for additional evaluations and how to conduct them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation of the timeaware model, noting that the effectiveness of the proposed methods is questionable when the training and evaluation timesteps are the same. The comment suggests considering different timestep scenarios to better understand the model\"s performance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed methods is questionable when the training and evaluation timesteps are the same, as Figure 5 shows similar performance between the baseline and timeaware models. The reviewer suggests that the proposed method might make more sense under different timestep scenarios. While the comment provides a logical reasoning for questioning the effectiveness of the methods, it lacks specific examples or references to support the claim fully. The suggestion to consider different timestep scenarios is a reasonable point, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation of the timeaware model, noting that similar performance is observed between the baseline and timeaware models when trained and evaluated with the same timestep. This observation raises questions about the effectiveness of the proposed methods under these conditions. The comment suggests that the authors should consider evaluating the model under different timestep scenarios to better understand its performance. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation methodology. However, the comment could be more helpful if it offered additional guidance on how to conduct these evaluations or what specific scenarios to consider. Overall, the comment is 4, as it directs the authors to a critical area for improvement and provides a clear path for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the clarity of how disentanglement is guaranteed in the paper. It notes that the \"Broader Impacts and Limitations\" section mentions a limitation regarding obtaining fully disentangled latent vectors but does not provide details on how this is realized or guaranteed. The comment explicitly suggests that the authors should clarify this aspect, indicating a clear action for the authors to take. However, it does not provide specific guidance on how to address this issue, such as which sections or methods should be revised. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the realization and guarantee of disentanglement, but without full grounding, it is challenging for the authors to pinpoint the exact sections to revise. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not provide specific examples or detailed reasoning to support the claim that the disentanglement is not clear. The reference to the \"Broader Impacts and Limitations\" section provides some context, but it does not offer sufficient evidence or explanation to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment raises a concern about the clarity of how disentanglement is guaranteed in the paper. It notes that while the \"Broader Impacts and Limitations\" section mentions a limitation regarding obtaining fully disentangled latent vectors, it does not provide details on how this is realized or guaranteed. This feedback is 3 as it identifies a specific area where the paper could be improved by offering more clarity on the disentanglement process. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or offered examples of how other works have handled similar challenges. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This action is clear and direct, providing the authors with a specific task to perform. The comment also specifies the purpose of this inclusion, which is to determine whether the mean teacher accelerates or slows down learning. This level of detail and specificity makes the action concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the left graph in fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is including a learning curve for a model without mean teacher or pi regularization for comparison. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This is a request for additional information to provide context for the learning curve presented in the graph. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity and interpretability of Figure 3 by including a learning curve for a model without mean teacher or pi regularization. This addition would help the authors determine whether the mean teacher accelerates or slows down learning, offering a valuable insight into the model\"s performance. The feedback is clear and actionable, guiding the authors on how to enhance their draft with additional data that could strengthen their analysis. However, it could be more helpful if it included a rationale for why this comparison is important or how it could impact the interpretation of the results. Despite this, the comment is 4 as it offers a concrete step for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and present their solutions in the paper. It also mentions that the citation seems disordered. While the comment implies that the authors should address the issue of input handling and improve the citation order, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address these issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the handling of different types of inputs and the order of citations. However, it does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in suggesting that the authors discuss how to deal with different types of inputs and present their solutions, and it also notes that the citation order seems disordered. However, without explicit references to sections or figures, the authors may struggle to pinpoint where these issues are discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and provides a suggestion for improvement by mentioning the need to present solutions in the paper. However, it does not provide specific examples or detailed reasoning to support why this is important or how it could be addressed. The comment also mentions that the citation seems disordered, but without further explanation or examples, it remains vague. Therefore, the claim is 3, as it provides a suggestion for improvement but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors should discuss how to handle different types of inputs, such as biomedical signals or speech, and present their solutions. This feedback is valuable as it highlights a potential gap in the paper\"s discussion and provides a clear direction for enhancing the content. Additionally, the comment notes that the citation order seems disordered, which is another area that could be improved. While the comment does not provide detailed guidance on how to address these issues, it effectively directs the authors\" attention to important aspects that need further development. Therefore, the comment is 4, as it offers actionable feedback that can significantly improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two separate issues. First, it questions whether Eq. 4 stands, implying that the authors should clarify or address this concern. Second, it points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, specifically mentioning the marginal improvement on OfficeHome. However, the comment does not provide explicit guidance on how to address these issues or what actions the authors should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue regarding the improvement of the designed solutions, particularly on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the validity of Eq. 4, suggesting that it implies a specific outcome for u^l in Eq. 3. This is a factual observation that does not require verification. The second part discusses the improvement of the designed solutions in Table 5, noting that the improvement is marginal on some datasets, such as OfficeHome. This part is 3 as it provides a specific example of a marginal improvement, but it lacks detailed reasoning or references to support the claim about the significance of the improvement. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment raises two separate issues. First, it questions the validity of Eq. 4, suggesting that it implies a specific outcome for u^l in Eq. 3. This raises a potential inconsistency that the authors should address. Second, it points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, particularly mentioning the marginal improvement on the OfficeHome dataset. This feedback is 3 as it identifies areas where the authors might need to clarify or provide more detailed explanations. However, it lacks specific suggestions or guidance on how to address these issues, such as recommending additional analyses or comparisons. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generalization or what steps to take to mitigate the problem. As a result, the authors are left without a clear understanding of what changes or actions are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to question answering, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the question answering process, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issue with generalization, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process requires template mapping to transform questions into masked statements, which might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Whtypes\" or not transformable. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization of their approach. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps or examples for the authors to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that utilizing a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform 1 as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of a volumetric representation in the deformation field, referencing VolumeDeform 1 as an example. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or related work section, but this inference is not explicit. The comment is specific in identifying the use of volumetric grids for encoding geometry and motion, but it lacks grounding as it does not mention specific sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform 1 as an example. This claim is 3 as it provides a specific reference to VolumeDeform, which could be used to support the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim. The authors would need to explore VolumeDeform 1 to understand the context and relevance of the claim, which adds to the complexity of the verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out that the use of a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform 1 as an example. This feedback is 3 as it identifies a potential lack of novelty in the approach and provides a specific reference for the authors to consider. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their work. As it stands, the comment provides a starting point for the authors to consider, but it lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to discuss or acknowledge it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the impact of the ICLHAR on accuracy scores, specifically mentioning the drop from 70.4 to 55.6 on TRIP. However, it does not specify which part of the paper discusses the ICLHAR or the accuracy scores, making it weakly grounded. The comment is specific in detailing the issue with the ICLHAR\"s impact on accuracy, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but negatively impacts accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It specifically mentions a drop in accuracy scores from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment highlights a critical point, it does not provide specific guidance on how to discuss or acknowledge this issue, leaving the authors with a general direction but no actionable steps. Therefore, the comment is 3, as it points out a significant concern but lacks depth and specificity in its feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limitations of the innovations in network architecture design and constraint embedding, noting that the performance is limited by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these limitations or improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the limitations of the innovations in network architecture design and constraint embedding, noting that the performance is limited by the performance of the oracle expert. However, it does not specify which part of the paper discusses these innovations or where the limitations are most apparent. The authors may have an idea of where these aspects are discussed, but the comment lacks explicit references to specific sections, making it weakly grounded. The comment is specific in identifying the limitations of the innovations, but without grounding, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovations in network architecture design and constraint embedding are limited, suggesting that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the innovations of network architecture design and constraint embedding, noting that the performance is constrained by the performance of the oracle expert. While it points out a potential area for improvement, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance their work. Without actionable feedback or detailed advice, the authors may find it challenging to use this comment to improve their draft. Therefore, the comment is 3, as it highlights a potential issue but does not provide enough depth or direction for the authors to effectively address it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several actions for the authors to consider. It explicitly recommends that related studies conduct calibration curves to demonstrate the agreement between predicted scores and actual risk, and it encourages proving the feasibility of the generated scoring system. Additionally, it suggests discussing the difference between the traditional method and the proposed method in the paper. These actions are clear and provide specific guidance on what the authors should do to improve their draft. The feedback is explicit and concrete, allowing the authors to understand exactly what needs to be done to address the suggestions. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the model\"s discriminant ability and suggests that the model\"s AUC should be assessed. It also mentions the importance of calibration curves to demonstrate the agreement between predicted scores and actual risk, particularly in the context of clinical scoring systems. However, the comment does not specify which part of the paper discusses the model\"s discriminant ability or the calibration curves, making it weakly grounded. The suggestion to prove the feasibility of the generated scoring system and discuss the difference between traditional and proposed methods is specific, but the lack of grounding limits the score. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model\"s AUC may not fully demonstrate its consistency with the actual risk, which is crucial for clinical scoring systems. It recommends conducting calibration curves to show this agreement and suggests proving the feasibility of the generated scoring system. The comment provides a logical reasoning for the importance of calibration curves and the need to prove the feasibility of the scoring system, making it 4. However, it could be strengthened by providing specific examples or references to support the claim about the importance of calibration curves in clinical contexts. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s discriminant ability, specifically the difficulty in demonstrating consistency between predicted scores and actual risk. It suggests that related studies should conduct calibration curves to address this issue and prove the feasibility of the generated scoring system. Additionally, it recommends discussing the difference between the traditional method and the proposed method in the paper. These suggestions are clear and provide actionable feedback for the authors to improve their draft by addressing the identified weaknesses and enhancing the clarity of their work. However, the comment could be more helpful if it offered specific guidance on how to conduct the calibration curves or detailed examples of how to discuss the differences between the traditional and proposed methods. Overall, the comment is 4, as it provides valuable insights and suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4\" and \"Lemma 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the conditions for DICE are not well discussed, particularly regarding how to ensure that DICE meets the conditions of Lemma 2 and the lack of discussion on the impact of sparsification on the range of ID and OOD. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD is not significantly changed by sparsification, and that Lemma 2 requires approximately identical mean as the assumption. However, the comment does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, including the lack of discussion on how to ensure that DICE meets the conditions of Lemma 2 and the observation that the range of ID and OOD is not significantly changed by sparsification. This feedback is 3 as it points out areas where the paper could be improved by providing more detailed explanations or discussions. However, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address these issues. To be more helpful, the comment could include examples, references, or detailed recommendations for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several concerns about the experimental setup and the comparison with baselines. It suggests that the experiments are not strong or fair, questioning the use of position kernels as baselines and recommending the use of default settings. Additionally, it points out missing baselines related to Bayesian optimization with discrete and categorical variables and suggests comparing the proposed approach with these baselines. The comment also mentions the need to discuss the limitations and societal impacts of the proposed approach. While the comment provides a clear direction for improvement, it does not specify how to address each issue or provide detailed guidance on the changes needed. The actions are implicit but concrete, as the authors can infer what needs to be done and have a clear idea of how to implement the suggestions. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses several specific issues with the paper, including the experimental setup, the use of position kernels as baselines, the absence of certain baselines, and the need to discuss limitations and societal impacts. However, it does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of default settings and the inclusion of missing baselines. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises concerns about the experimental setup and the use of position kernels as baselines, suggesting that the experiments are not strong or fair. It questions why the default settings of the baselines are not used and mentions the absence of certain baselines related to Bayesian optimization with discrete and categorical variables. The comment also points out the need to discuss limitations and societal impacts. While the reviewer provides a logical basis for their claims, such as questioning the fairness of the experiments and the relevance of the baselines, the comment lacks specific references or detailed examples to fully substantiate the claims. This makes the claim 3, as it provides a general direction for improvement but requires more detailed justification or evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the experimental setup, the use of position kernels as baselines, the absence of certain baselines related to Bayesian optimization with discrete and categorical variables, and the need to discuss limitations and societal impacts. The comment provides specific suggestions for enhancing the paper, such as recommending the use of default settings for baselines and comparing the proposed approach with relevant baselines. However, the comment could be more helpful if it offered more detailed guidance or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point observes a drop in correlation after a short period of training, which then increases with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this observation or what steps to consider. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft based on this observation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions a \"drop of correlation\" after a short period of training, which then increases with more training iterations. However, it does not specify which part of the paper this observation is based on, such as a specific section, figure, or table. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in describing the observed trend but lacks grounding, making it weakly grounded. Therefore, the comment aligns with a score of 2.", "verifiability_rationale": "The review point describes an observation of a correlation drop after a short period of training, which then increases with more training iterations. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this observation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment observes a drop in correlation after a short period of training, which then increases with more training iterations. While this observation is interesting, it does not provide any actionable feedback or suggestions for the authors to address or improve upon. Without specific guidance or recommendations, the authors are left without a clear understanding of how to incorporate this observation into their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests that the presentation of bits should be clarified as representation bits in Section 4.3. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action to clarify the presentation is somewhat vague, as it does not specify how to rephrase or restructure the content. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. Additionally, it suggests clarifying the presentation of \"bits\" as \"representation bits.\" This provides clear guidance on what needs to be addressed in the section, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance of sparsity patterns and suggests that there is a lack of insight into why they perform similarly. It also questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a lack of insight into why all sparsity patterns perform similarly, questioning whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also points out a specific issue with the terminology \"presentation bits\" in Section 4.3, suggesting that it should be clarified as \"representation bits.\" While the comment highlights an important area for clarification and improvement, it lacks depth and does not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out a potential area of confusion but does not offer detailed advice on how to resolve it. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4, and it suggests that this should be shown in a rigorous way or that the paper should mention it. This provides a clear and direct action for the authors to take, which is to include the temperature \u03c4 in a rigorous manner or to mention it in the paper. The feedback is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the temperature \u03c4 in a rigorous manner or mentioning it in the paper. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 is missing the temperature \u03c4, and it suggests that this should be shown in a rigorous way or that the paper should mention it. This is a factual observation rather than a subjective claim or suggestion. It does not require verification as it is a clear statement of a missing element in the derivation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the derivation from Eqn. 3 to Eqn. 4, noting that the temperature \u03c4 is missing. It provides a clear and actionable suggestion for improvement by recommending that the temperature \u03c4 should be shown in a rigorous way or that the paper should mention it. This feedback is valuable as it directs the authors to a specific area that needs clarification, helping them to improve the clarity and rigor of their work. However, the comment could be more helpful if it provided additional context or guidance on how to incorporate the temperature \u03c4 in a rigorous manner. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with more detailed suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add a citation on differential privacy, specifically mentioning a standard work like 2. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is specific and concrete, as it specifies the type of citation needed and provides a reference for the authors to follow. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the addition of a citation on differential privacy, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy, specifically mentioning a standard work like 2. This is a factual statement that does not contain any subjective opinions, judgments, or suggestions. It is a request for additional information, which is a normal statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, suggesting that the authors should include a citation on differential privacy, specifically mentioning a standard work like 2. This feedback provides a specific and direct way for the authors to enhance their paper by adding relevant references, which can improve the comprehensiveness and credibility of their work. However, the comment could be more helpful if it explained why differential privacy is relevant to the paper or how the addition of this citation would benefit the readers. Despite this, the feedback is 4 as it offers a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two parts. First, it questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is that the test set is drawn from the same distribution as the query set, which is a common assumption in machine learning. This part provides a clear and explicit action for the authors to consider revising their claim. Second, it identifies a specific error in the inequality on line 310, pointing out that it has the wrong sign and suggesting a comparison with inequality line 227. This part is also explicit and provides a concrete action for the authors to correct the error. Overall, the comment is 5 as it provides clear and specific guidance on both the theoretical claim and the mathematical error, allowing the authors to make direct improvements to their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and \"line 310,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on both the theoretical claim and the mathematical error. The reviewer questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is the natural assumption of the test set being drawn from the same distribution as the query set. Additionally, it identifies a specific error in the inequality on line 310 and provides a comparison with inequality line 227. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the claim that the methodology requires significant additional assumptions, suggesting that the only additional assumption is the natural assumption of the test set being drawn from the same distribution as the query set. This is a logical and reasonable argument, supported by common knowledge in machine learning. The second part identifies a specific error in the inequality on line 310, comparing it with inequality line 227. This provides a clear and verifiable correction, making the comment 4. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim about the additional assumptions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides valuable feedback by questioning the claim that the methodology requires significant additional assumptions. It points out that the only additional assumption is the natural assumption of the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This critique is constructive as it challenges the authors to reconsider their claim and potentially revise it to reflect a more accurate assessment of the assumptions involved. Additionally, the comment identifies a specific error in the inequality on line 310, suggesting a comparison with inequality line 227. This feedback is actionable and provides clear guidance for the authors to correct the error, enhancing the overall helpfulness of the comment. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. Additionally, it recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. While the comment explicitly states these actions, it does not provide specific guidance on how to conduct these comparisons or discuss the advantages and disadvantages. The authors are left with a clear understanding of what needs to be done but without detailed instructions on how to implement these suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for experimental comparisons with methods like CaCE and raw gradients, as well as a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. It also recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the comparison with CaCE or raw gradients. The suggestion for a discussion on the advantages and disadvantages of different methods is a general recommendation that could be improved with more detailed examples or references. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s argument for using Shapely value explanations over other methods. It suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their choice. Additionally, the comment recommends including a discussion on the advantages and disadvantages of different methods for transforming highdimensional data to a lowdimensional latent space. This feedback is clear and actionable, as it provides specific steps for the authors to take to strengthen their argument and improve the paper\"s comprehensiveness. By addressing these suggestions, the authors can enhance the rigor and depth of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a clear and direct action for the authors to take, which is to improve the clarity of the representation in Appendix A.2. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. By pointing out this lack of clarity, the comment provides a clear and actionable feedback for the authors to improve the presentation of this information. However, it does not offer suggestions on how to enhance the clarity or provide specific examples of what could be done differently. While it highlights a critical area for improvement, the feedback could be more helpful if it included actionable advice or examples. Therefore, the comment is 3, as it directs the authors to a specific area needing attention but lacks depth in its guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach for largerscale problems. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in identifying the issue of scalability, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this assertion, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation of the authors\" approach, stating that it is only applicable to small or mediumscale problems and will be overwhelmed by truly large problems. This feedback is 3 as it points out a potential issue that the authors need to consider when scaling their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve their approach for largerscale problems. Without actionable advice or examples, the feedback is incomplete, leaving the authors with a general understanding of the problem but no clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the motivation for using characteristic function regularization. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify their motivation or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the motivation for using characteristic function regularization, but it does not specify which part of the paper this issue is addressed in. The authors cannot confidently determine which section or part of the paper the comment refers to, making it weakly grounded. However, the comment is specific in identifying the issue of unclear motivation, which provides some guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation for using characteristic function regularization is not clear, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity in the motivation for using characteristic function regularization. This feedback is valuable as it points out a potential weakness in the paper that the authors should address. However, the comment does not provide any suggestions or guidance on how the authors might clarify their motivation or improve the explanation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, which are standard in contextual linear bandits. The reviewer notes that the combination of these techniques is not surprising and suggests that the contribution may be incremental. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the paper\"s combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). This provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies that the combination of these techniques is not surprising, suggesting that the contribution may be incremental. However, it does not provide specific guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s results are a combination of existing techniques, which is not surprising and may suggest that the contribution is incremental. However, the comment does not provide specific examples or references to support the claim that these techniques are indeed standard or widely known. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that the results appear to be a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that the combination of these techniques is not surprising and may indicate that the contribution is incremental. While the comment highlights a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or enhance their contribution. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for improvement, leaving the authors with limited direction on how to strengthen their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights severe writing issues in the paper, including grammatical errors, misuse of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The authors are left without clear instructions on where to focus their efforts or how to correct the identified problems. As a result, the comment lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment mentions severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which sections or parts of the paper contain these issues, making it difficult for the authors to identify the exact areas needing improvement. Without specific references or examples, the authors cannot effectively address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address the feedback. Without concrete evidence or references, the claim remains 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies severe writing issues in the paper, including grammatical errors, misuse of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues, leaving the authors without actionable feedback. While the comment highlights important areas for improvement, it lacks depth and detail, making it 2. The authors are left to infer which parts of the paper need attention, but without specific examples or suggestions, they may struggle to effectively address the feedback. Therefore, the comment is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests that the figures should include results for untrained networks and clarifies the meaning of \"Random data\" in Figure 3c and Figure 3. The comment also requests examples of random data in the appendix. These actions are clear and concrete, giving the authors a specific set of tasks to perform to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3c\" and \"Figure 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be clarified, such as the meaning of \"Random data\" and whether the nonrandom data is normalized. Additionally, it requests examples of random data in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of requests for clarification and additional experiments. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comments are factual and descriptive, making them \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two areas where the paper could be improved. It suggests that the figures should include results for untrained networks, which is a clear and direct action for the authors to take. Additionally, the comment clarifies the meaning of \"Random data\" in Figure 3c and Figure 3, prompting the authors to clarify whether the network was trained on random data or unaltered data evaluated with random data. It also requests examples of random data in the appendix, which is another actionable suggestion. This feedback is detailed and provides the authors with clear steps to enhance the clarity and completeness of their draft. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the small improvement over previous methods and the lack of statistical significance analysis in the results. It suggests repeating the experiments and conducting statistical significance analysis to address these concerns. While the comment explicitly states the actions to be taken, it does not provide detailed guidance on how to conduct the statistical analysis or what specific improvements are needed. The authors are given a clear direction but may need additional information to fully implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses two specific issues: the small improvement over previous methods and the lack of statistical significance analysis in the results. It explicitly mentions \"Table 1 and Fig. 5,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment also specifies what needs to be addressed, such as repeating the experiments and conducting statistical significance analysis. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, with a range of 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to determine statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis. However, the comment lacks specific examples or references to support the claim about the small improvement or the lack of statistical analysis. While the suggestion to repeat the experiments and conduct statistical analysis is reasonable, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the small improvement over previous methods and the lack of statistical significance analysis in the results. It suggests repeating the experiments and conducting statistical significance analysis to address these concerns. This feedback is clear and actionable, providing the authors with a concrete path to improve their draft by ensuring that their results are statistically significant. However, the comment could be more helpful if it offered additional guidance on how to conduct the statistical analysis or what specific improvements are needed to enhance the novelty of the paper. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the \"approach section is missing in the main paper\" and suggests that the supplementary material should be used as additional information rather than an extension to the paper. The reviewer provides a specific reference to a previous comment and indicates that the score has been increased from 3 to 5. This feedback is clear and provides a direct action for the authors to take, which is to ensure that the approach section is included in the main paper and that the supplementary material is used appropriately. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"approach section\" and the \"main paper,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by noting that the approach section is missing and suggesting that the supplementary material should be used as additional information rather than an extension to the paper. The comment further references a previous comment and indicates that the score has been increased from 3 to 5. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"approach section is missing in the main paper,\" which is a factual statement that does not require verification. The reviewer also suggests that the supplementary material should be used as additional information rather than an extension to the paper, providing a logical reasoning for this claim. However, the comment lacks specific examples or references to support the suggestion that the supplementary material should be used as additional information. While the reasoning is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"approach section is missing in the main paper.\" This is a clear and actionable feedback that highlights a critical omission in the manuscript. The reviewer also provides guidance on how the supplementary material should be used, suggesting it should serve as additional information rather than an extension to the paper. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a clear direction for improvement. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate the approach section into the main paper. Overall, the comment is 4, as it effectively guides the authors towards addressing a significant gap in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it may be too weak. It points out that backpropagation is widely accepted as biologically implausible. However, the comment does not provide specific guidance on how the authors should address this issue or improve the statement. The action is implicit, as the authors need to infer that they should strengthen the statement or provide additional context, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, citing the widespread acceptance of backpropagation as biologically implausible. This claim is supported by common knowledge and general understanding in the field, making it 4. However, the comment could be strengthened by providing specific references or examples to substantiate the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement in the introduction regarding the biological plausibility of backpropagation, noting that it is widely accepted as biologically implausible. This feedback is valuable as it points out a common misunderstanding or misrepresentation in the literature, which could be misleading for readers. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or clarify the statement. Overall, the comment is 3 as it highlights an important area for improvement but lacks detailed guidance for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should expand their analysis to other NLP tasks, but it lacks concrete details or actionable steps on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on contrastive learning in code search tasks and suggests that it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper discusses the proposed method or how it could be expanded to other tasks. The authors can infer that the discussion on the proposed method is relevant, but the comment lacks specificity in identifying the exact sections or aspects that need further exploration. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is relevant as it highlights an area where the authors could expand their analysis to enhance the generalizability of their results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, such as which other NLP tasks could be explored or how to structure this additional analysis. While it points out an important area for improvement, the feedback could be more actionable and comprehensive to be considered 5. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include real data, as barycenters can be used in a range of problems. While the comment implies that the authors should consider including real data in their experiments, it does not provide explicit instructions on how to do so or what specific real data should be used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include real data, indicating that the current focus on toy data is limited. However, it does not specify which part of the paper discusses the experiments or where the authors should make this expansion. This lack of explicit grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in suggesting the inclusion of real data, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are limited to toy data and proposes expanding them to include real data where barycenters can be used. This claim is 3 as it provides a logical reasoning for the suggestion, indicating that realworld data could offer a more comprehensive evaluation of the method. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the scope and potential impact of this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the current experimental setup, noting that the experiments are limited to toy data. It suggests that the authors should expand their experiments to include real data, as barycenters can be used in a range of problems. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and applicability of their method. By addressing this suggestion, the authors can significantly improve the relevance and impact of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should conduct additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. It provides specific references to related work, including 1 MoBiNet, 2 Dynamic Channel Pruning, and 3 Learning Dynamic Routing. This feedback is explicit and provides concrete guidance on what additional experiments should be conducted to strengthen the paper. The authors are given clear instructions on how to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests conducting additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet. It provides references to specific works, including 1 MoBiNet, 2 Dynamic Channel Pruning, and 3 Learning Dynamic Routing. This provides full grounding as the authors can accurately identify the sections of the paper where these references are relevant. The comment is also specific because it clearly specifies what additional experiments are needed to strengthen the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that additional experiments on deeper networks and other network structures are needed to strengthen the paper. It provides references to specific works, such as 1 MoBiNet, 2 Dynamic Channel Pruning, and 3 Learning Dynamic Routing, which can serve as a basis for the additional experiments. This provides a clear and specific rationale for the claim, making it 5. The references to related work support the suggestion, allowing the authors to understand the context and potential benefits of the proposed experiments. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on deeper networks, such as ResNet50, and other network structures, like MobileNet, to further strengthen the paper. It provides specific references to related works, including 1 MoBiNet, 2 Dynamic Channel Pruning, and 3 Learning Dynamic Routing, which can serve as a basis for these experiments. This feedback is 5 as it offers clear and actionable guidance for the authors to enhance their study by expanding the scope of their experiments. By following this suggestion, the authors can provide a more comprehensive analysis of their approach and potentially contribute to the field with new insights. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the sample selection mechanism need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. However, it does not provide any supporting evidence, reasoning, or examples to justify the claim that the mechanism is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the proposed sample selection mechanism and its impact on preserving the label distribution. While it identifies a potential area of confusion, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing the draft. Therefore, it is rated as 2, as it highlights a concern but does not offer meaningful assistance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. While it acknowledges the thoroughness of the analysis, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The comment lacks specific instructions or recommendations for expanding the evaluation to include more or newer models, which would help the authors improve their draft. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the evaluation of results and analysis, specifically noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the results or analysis sections, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the issue of limited model evaluation, but without clear guidance on how to address it, it remains underspecific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. This claim is 3 as it highlights a potential limitation in the evaluation process. However, the comment lacks specific examples or references to support the claim that the models are \"old\" or \"small,\" making it difficult for the authors to fully understand and address the issue. Additionally, the comment does not provide suggestions on how to expand the evaluation or improve the analysis, which would further enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of results and analysis, noting that only two relatively old and small models are evaluated. While it points out a specific area for improvement, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this limitation. Without additional context or recommendations, the authors may find it challenging to effectively improve their draft based on this feedback. Therefore, the comment is 3, as it highlights an area for enhancement but does not fully support the authors in making the necessary improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or incorporate it into their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific claim about the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in detailing the conditions under which KD and LS are equivalent, but without explicit references to the paper, the authors may struggle to pinpoint the exact context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a rationale for this claim by explaining that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS become equivalent. This explanation offers a logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to support the equivalence of KD and LS under these conditions. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides a nuanced perspective on the relationship between these two techniques, which could be valuable for the authors to consider. However, the comment lacks actionable guidance or suggestions on how this insight could be integrated into the paper or what implications it might have for the research. Without specific recommendations or detailed feedback, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to provide an explanation for the degradation in performance when using additional information about missing, wrong, or redundant data in the FBN results (table 5). This is a clear and direct action, as it specifies what information the authors need to include to address the issue. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance degradation when using additional information about missing, wrong, or redundant data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any claims, opinions, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the FBN results (table 5) and requests clarification on why the performance degrades when using additional information about missing, wrong, or redundant data. This feedback is clear and actionable, as it prompts the authors to provide a detailed explanation or analysis of the performance degradation. However, the comment could be more helpful if it suggested potential causes or methods for addressing the issue. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that they should be roughly the same size as the manuscript text. This provides a clear and direct action for the authors to take, which is to ensure that the text in the figure is legible without zooming. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the text inside the figure and the labels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the text is too small to read without zooming, and suggests that it should be roughly the same size as the manuscript text. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming, suggesting that they should be roughly the same size as the manuscript text. This is a subjective observation that requires the authors to make a judgment about the legibility of the text. However, the comment does not provide any supporting evidence, such as specific measurements or examples, to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the text inside the figure and labels, noting that they are too small to be legible without zooming. It provides a clear and actionable suggestion by recommending that the text should be roughly the same size as the manuscript text. This feedback is valuable as it helps the authors improve the accessibility and clarity of their figures, which is an important aspect of effective communication in scientific writing. However, the comment could be more helpful if it included specific recommendations on how to achieve this size or if it discussed the potential impact of this issue on the overall presentation of the results. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, making it a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the intuition behind including multiple local prompts, noting that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section or discussion. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity in detailing what aspects of the paper need to be addressed or improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. This observation highlights a potential area for improvement or clarification in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the paper need further exploration. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left with a general insight but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a clear and explicit action for the authors to improve the presentation of their model in section 4. It suggests replacing some natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This feedback is concrete and provides specific steps for the authors to take, making it 5. The authors know exactly what changes to make to enhance the clarity and comprehensibility of their presentation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the presentation, suggesting the use of notation and breakout diagrams to illustrate attention mechanisms. This detailed feedback gives the authors a clear understanding of what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the model is complicated and requires careful reading, possibly with reference to the supplement. It proposes improvements by suggesting the use of notation and breakout diagrams to illustrate attention mechanisms. However, the comment lacks specific examples or detailed reasoning to support the claim that the model is complicated or how the suggested improvements would enhance clarity. The mention of the supplement provides some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a general suggestion but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the model\"s presentation in section 4, noting that it is somewhat complicated and requires careful reading. It provides actionable suggestions for improvement, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. These suggestions are clear and provide the authors with a concrete path to enhance the clarity and comprehensibility of their presentation. However, the comment could be more helpful if it included specific examples of where these improvements could be made or how they would enhance the paper. Overall, the feedback is 4 as it offers valuable guidance for improving the draft, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only conducts experiments on a limited number of molecules and provides indistribution testing for these samples. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding their experiments to a broader range of molecules or exploring alternative methods to address the training issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental setup, specifically mentioning the limited number of molecules and the indistribution testing provided. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the limitation of the method, suggesting that it might be limited if it requires training for each molecule individually. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s value would be limited if it requires training for each molecule individually, suggesting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s experimental setup, specifically noting that the experiments are conducted on a limited number of molecules and only provide indistribution testing. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or expand their experiments. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that the symbols used in the paper are complicated and take a long time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or improve their clarity, nor are there suggestions for alternative approaches. As a result, the authors are left without any actionable steps to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that symbols are complicated and take a long time to understand, but it does not specify which part of the paper these symbols are used in or provide any context about what these symbols represent. This lack of grounding makes it difficult for the authors to identify the specific sections or elements that need attention. The comment is specific in its critique of the complexity of the symbols, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that symbols are complicated and take a long time to understand, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or examples, the authors are left without guidance on how to address the issue or improve the clarity of the symbols. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of symbols used in the paper, noting that they take a long time to understand. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might simplify or clarify the symbols. Without actionable feedback or detailed advice, the comment does not offer the authors a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly questions the origin of the test data used in Figure 3 and asks for clarification on the existence of a ground truth. This provides a clear and direct action for the authors to take, which is to explain the source of the test data and whether a ground truth is available. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line, questioning where the test data comes from and whether a ground truth is available. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions regarding the origin of the test data used in Figure 3 and the existence of a ground truth. These questions are factual in nature and do not express an opinion, judgment, or suggestion that requires verification. They are straightforward inquiries seeking clarification, which do not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with Figure 3, questioning the origin of the test data and the existence of a ground truth. This feedback prompts the authors to clarify these aspects, which is important for ensuring the transparency and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to address these concerns or offered additional context to better understand the issue. Overall, the comment provides some guidance but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests comparing the results of a model that cannot capture periodic relationships with those of an explicitly compositional model. However, the comment does not provide explicit instructions or concrete steps for the authors to follow. The action is implicit and somewhat vague, as the authors need to infer that they should conduct this comparison and analyze the results. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests comparing a model that cannot capture periodic relationships with an explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as a specific experiment or section. The authors might infer that it relates to the experimental results or discussion, but this inference is not explicit. The comment is specific in its question about the comparison of models, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests comparing a model that cannot capture periodic relationships with an explicitly compositional model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this concern. Without additional context or justification, the claim remains 1, as it lacks the necessary details for the authors to understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests comparing a model that cannot capture periodic relationships with an explicitly compositional model, which is a relevant and insightful observation. However, the comment lacks specific guidance or suggestions on how the authors might conduct this comparison or what aspects of the results should be analyzed. While it identifies an important area for exploration, the feedback could be more helpful if it provided actionable steps or detailed suggestions for the authors to follow. Therefore, the comment is 3, as it points out a potential area for improvement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the 10 subtasks are simplistic for bAbi and that the authors should provide more discussions. While the comment implies that the authors should address this issue by adding more discussions, it does not specify what kind of discussions are needed or how they should be structured. The action is implicit and somewhat vague, as the authors know they need to provide more discussions but are not given clear guidance on what those discussions should entail. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the simplicity of the 10 subtasks in the bAbi task and suggests that more discussions are needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the simplicity of the subtasks and the need for more discussions, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the 10 subtasks are simplistic for the bAbi task and suggests that the authors should provide more discussions. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the subtasks are simplistic or why more discussions are necessary. Without additional context or justification, the claim remains 1, as it lacks the necessary details to help the authors understand and address the issue.", "helpfulness_rationale": "The review comment identifies a potential issue with the simplicity of the 10 subtasks in the bAbi task and suggests that more discussions are needed. While it points out a potential weakness in the experimental setup, it lacks specific guidance or suggestions on how to address this issue or what kind of discussions would be beneficial. The comment provides a general direction for improvement but does not offer detailed feedback or actionable steps, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. While the comment implies that the authors should consider this limitation and potentially address it, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the possibility of extending the approach to longer subsequences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in questioning the limitation and suggesting an extension, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is a purely factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitation of using triplets or a sliding window of length 3, asking whether this is a fundamental limitation of the approach or if an extension to longer subsequences is straightforward. This question prompts the authors to consider the scope of their approach and whether it can be extended to accommodate longer subsequences without a sliding window. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this limitation. The feedback is 3 as it encourages the authors to explore the possibility of extending their approach, but it lacks detailed actionable advice, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two issues: first, it asks for clarification on the term \"sequence of episodes\" and whether practice and evaluation are the two types of this sequence. Second, it points out that the paper lacks related work, despite the subject matter being closely related. While the comment explicitly requests clarification on the term and highlights the need for related work, it does not provide specific guidance on how to address these issues. The authors are left with a general understanding of what needs to be clarified or added, but without detailed instructions on how to implement these changes. Therefore, the comment is 3, as it identifies specific areas for improvement but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking for clarification on the term \"sequence of episodes\" and whether practice and evaluation are the two types of this sequence. Additionally, it points out the absence of related work, which is a specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the term \"sequence of episodes\" and whether practice and evaluation are the two types of this sequence. It also points out the absence of related work, suggesting that the subject matter is closely related to existing work. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed justification or evidence makes the claim 3, as it provides a basis for inquiry but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment raises two important points. First, it asks for clarification on the term \"sequence of episodes,\" which is crucial for understanding the context and methodology of the paper. This request for clarification is valuable as it helps the authors ensure that their terminology is clear and consistent throughout the paper. Second, the comment points out the absence of related work, suggesting that the subject matter is closely related to existing work. This feedback is important as it highlights the need for the authors to situate their work within the broader context of existing research. While the comment identifies these issues, it does not provide specific guidance on how to address them, such as suggesting relevant references or how to integrate related work into the paper. Therefore, the comment is 3, as it points out areas for improvement but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the characterization of the study as an \"ablation\" study, stating that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should reframe their study or what specific aspects need to be addressed. The comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the characterization of a study as an \"ablation\" study, specifically questioning whether it involves removing a component of the method. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. The authors may infer that it relates to the methodology or results section, but this inference is not explicit. The comment is specific in its critique of the study\"s characterization, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the study about different subdomain sizes is an \"ablation\" study, as it does not involve removing a component of the method. However, the comment lacks specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the characterization of a study as an \"ablation\" study, questioning whether it involves removing a component of the method. While it identifies a potential issue with the study\"s classification, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their study design. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential issue but does not offer actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. While the comment implies that the authors should consider this idea, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they should explore this possibility, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. However, it does not provide any reasoning, evidence, or references to support why this suggestion is necessary or beneficial. The lack of justification or examples makes it difficult for the authors to understand the basis of the claim and how it could improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests including and learning AccNet as part of a larger predictor, such as for semantic segmentation, which utilizes similar operators. This feedback is 3 as it provides a potential direction for expanding the scope of the work by integrating AccNet into a more comprehensive system. However, the comment lacks specific guidance on how to implement this suggestion or what benefits it might bring to the research. To be more helpful, the comment could include details on how this integration could enhance the model\"s performance or functionality. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the new proposed metric is only tested on a single dataset, implying that the authors should consider testing it on additional datasets to validate its effectiveness. However, the comment does not explicitly instruct the authors to do so or provide guidance on which datasets to use. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further testing. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed metric, noting that it has only been tested on a single dataset. This provides some grounding as it refers to the testing of the metric, but it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional testing, as it suggests that the authors should consider testing the metric on multiple datasets to validate its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset, implying that the authors should consider testing it on additional datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without further explanation or justification, the authors may find it challenging to understand the basis of the suggestion or how it could be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed metric, noting that it has only been tested on a single dataset. This feedback is valuable as it highlights a potential limitation in the evaluation of the metric, suggesting that the authors should consider testing it on multiple datasets to validate its effectiveness. However, the comment lacks depth and does not provide specific guidance on which additional datasets to use or how to conduct the testing. While it points out an important area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific issues: the lack of definition for the abbreviation \"NE\" on line 73 and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to relevant literature, such as 1 S. Zhang et al, 2 Z. Ding et al, and 3 T. Wang et al, which could be used as examples for proper referencing and definition. However, the comment does not explicitly instruct the authors to define these abbreviations or provide specific guidance on how to address these issues. While the authors can infer that they need to define these abbreviations, the lack of explicit instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"NE\" on L73 and superscript notation in Eq 6, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on the lack of definition for these abbreviations and the absence of definition for superscript notation until much later in the text, which hinders understanding. Additionally, the comment includes references to relevant literature, such as 1 S. Zhang et al, 2 Z. Ding et al, and 3 T. Wang et al, which could be used as examples for proper referencing and definition. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point identifies two specific issues: the lack of definition for the abbreviation \"NE\" on line 73 and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to relevant literature, such as 1 S. Zhang et al, 2 Z. Ding et al, and 3 T. Wang et al, which could be used as examples for proper referencing and definition. This provides a clear and detailed justification for the claim, making the comment 5. Therefore, the comment is categorized as 5.", "helpfulness_rationale": "The review comment identifies two specific issues with the draft: the lack of definition for the abbreviation \"NE\" on line 73 and the absence of definition for superscript notation in Eq 6 until much later in the text. It also provides references to relevant literature, such as 1 S. Zhang et al, 2 Z. Ding et al, and 3 T. Wang et al, which could be used as examples for proper referencing and definition. This feedback is clear and actionable, as it guides the authors to address these issues by providing references and definitions, thereby enhancing the clarity and comprehensibility of the draft. However, the comment could be more helpful if it offered suggestions on how to integrate these references or definitions into the text. Overall, the comment is 4, as it provides valuable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the evaluation or what specific steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a concern about the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the issue with the baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation is weak because the baselines used in the paper are not designed for fair classification. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. This feedback is valuable as it highlights a potential weakness in the methodology that could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the evaluation. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the setting in the first three paragraphs of section 2 needs to be clarified. It suggests that the authors may be implying a greater generality than what is actually presented, which could be confusing. This feedback provides a clear and direct action for the authors to take, which is to clarify the setting. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first three paragraphs, which is the need for clearer explanation of the setting. The comment highlights a potential issue with the authors\" claim of doing something in greater generality than what is presented, which provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first three paragraphs of section 2 need to be clarified because the authors seem to be implying a greater generality than what is actually presented. This claim is 3 as it provides a logical reasoning for the claim, suggesting that the authors may be misleading the reader by implying a broader scope than what is actually discussed. However, the comment lacks specific examples or references to support the claim fully. The authors would need to infer the exact parts of the text that are unclear or misleading, which makes the comment 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It points out that the authors may be implying a greater generality than what is actually presented, which could confuse the reader. This feedback is clear and actionable, as it directs the authors to clarify the setting to avoid any potential confusion. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or examples of what could be done to improve the exposition. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the convincing nature of the experiments, specifically questioning the choice of the old baseline like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment implies that the authors should explore these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the experiments being not quite convincing, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, namely the choice of baselines and the comparison to more recent approaches. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experiments being not quite convincing, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. While the comment provides a logical reasoning for considering these alternatives, it lacks specific references or examples to support the claim fully. The suggestion to compare the proposed method to these approaches is a reasonable one, but the comment could be strengthened by providing more detailed reasoning or evidence to support the need for this comparison. Therefore, the comment is 3, as it provides a basis for the claim but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment raises a concern about the convincing nature of the experiments, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. This feedback is 4 as it provides clear and actionable suggestions for improvement, encouraging the authors to explore more recent and efficient baselines. However, the comment could be more helpful if it included specific recommendations or examples of how to implement these suggestions. Overall, the comment offers valuable guidance for enhancing the experimental section of the paper, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on how the attention module is attached to the ResNet20 architecture and how many attention modules are used. It also inquires about their placement, whether after each block or stage. This feedback provides a clear and direct action for the authors to take, which is to clarify these aspects in their draft. The request is specific and actionable, as it outlines what information needs to be added or clarified to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"ResNet20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the attention module is attached to the backbone architecture, including questions about the number of attention modules and their placement. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the implementation of the attention module within the ResNet20 architecture. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information to enhance the clarity of the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the implementation of the attention module within the ResNet20 architecture. It asks for clarification on the number and placement of attention modules, which is crucial for understanding the methodology and reproducibility of the work. By highlighting this gap in the paper, the comment provides clear and actionable feedback that can help the authors improve the clarity and completeness of their draft. However, it could be more helpful if it suggested ways to address the issue or provided examples of how to clarify this aspect. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions the precision of the bitrate range used for BDrate comparison, and second, it suggests a related work for discussion or comparison. The first part of the comment is 3 as it prompts the authors to clarify the specific bitrate range used in their comparison. However, the second part is more explicit and concrete, as it provides a specific suggestion for additional discussion or comparison. Overall, the comment is 4, as it offers a clear direction for the authors to address the first issue and a specific suggestion for the second issue.", "grounding_specificity_rationale": "The comment addresses the proposed method\"s performance at different bitrates, specifically noting that it performs better at high bitrates but is close to the baselines at low bitrates. It also suggests a related work for discussion or comparison, mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. However, the comment does not specify which part of the paper discusses the bitrate comparison or the related work, making it weakly grounded. The suggestion for discussion or comparison is specific, but the lack of grounding makes it challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the precision of the bitrate range used for BDrate comparison, suggesting that the authors clarify this aspect. Second, it recommends a related work for discussion or comparison, specifically mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. While the comment provides a specific suggestion for additional discussion or comparison, it lacks detailed reasoning or evidence to fully substantiate the claim about the precision of the bitrate range. The suggestion for related work is clear and specific, but the initial claim about the precision of the bitrate range is not fully supported. Therefore, the comment is 3, as it provides a clear suggestion but lacks comprehensive justification for the first part.", "helpfulness_rationale": "The review comment raises two points for the authors to consider. First, it questions the precision of the bitrate range used for BDrate comparison, suggesting that the authors clarify this aspect. This feedback is 3 as it prompts the authors to ensure clarity in their methodology, which is important for reproducibility and understanding. Second, the comment suggests a related work for discussion or comparison, specifically mentioning Guo Lu\"s paper on content adaptive algorithm in learned video compression. This suggestion provides a valuable direction for the authors to enhance their paper by incorporating relevant literature. However, the comment could be more helpful if it included specific details on how the suggested work could be integrated or what aspects of the proposed method could be compared with the referenced paper. Overall, the comment is 4 as it identifies areas for improvement and provides a clear suggestion for additional discussion or comparison."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While the comment implies that the authors should make this distinction, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide specific guidance on how to achieve this distinction. The authors may have an idea of where this distinction could be relevant, but the comment lacks explicit grounding and specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this distinction is necessary or how it would impact the paper. Without additional context or explanation, the claim remains 1, as the authors may not understand the significance of the distinction or how it relates to their work. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish between the allornothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While this is a valid point, the comment lacks specificity and does not provide detailed guidance on how the authors should make this distinction or why it is important. Without additional context or examples, the authors may find it challenging to understand the significance of this distinction and how it could improve their work. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal and suggests that further analysis beyond the main experiments is not sufficient. However, it does not provide specific guidance or suggestions on what additional analysis or improvements the authors should undertake. The action is implicit and vague, as the authors are left to infer that they need to conduct more analysis or improvements, but without concrete details on what aspects to focus on. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the improvements made by the paper over previous works and selfimplemented baselines, stating that the improvements are marginal. However, it does not specify which tasks or experiments are being discussed, making it difficult for the authors to identify the exact part of the paper being critiqued. Additionally, the comment lacks specificity regarding what further analysis or improvements are needed beyond the main experiments. Without clear grounding or detailed feedback, the authors may struggle to understand and address the issues effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. However, the comment does not provide any specific examples, data, or reasoning to support this claim. Without detailed evidence or analysis, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out that the improvements over previous works and selfimplemented baselines are marginal, suggesting that further analysis beyond the main experiments is not sufficient. While it identifies a potential issue with the paper\"s results, it lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. The comment provides a general direction for further investigation but does not offer actionable steps or detailed feedback. As a result, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. While it identifies a specific issue with the clarity of the proof, it does not provide explicit guidance on how the authors should address this problem. The comment lacks concrete suggestions or actions for the authors to take, such as recommending ways to improve the clarity of the proof or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the theorem is buried in the appendix and its proof is not clear enough. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and suggests that the authors should clarify or improve the clarity of the proof. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative ways to present the proof or suggesting improvements to enhance its clarity. As a result, the feedback is 3, as it highlights a critical area for improvement but does not fully support the authors in making the necessary changes."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should present the average results on the test set with error bars under different random seeds, which is a clear and direct action. It also provides specific guidance on what should be included in the presentation, making the action concrete. This level of detail and specificity ensures that the authors know exactly what changes to make to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the current presentation of results, suggesting that the authors should present the average results on the test set with error bars under different random seeds. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should present the average results on the test set with error bars under different random seeds, suggesting that the current results on the dev set are not convincing. The reviewer provides a logical reasoning by stating that presenting average results on the test set with error bars would provide a more robust and convincing evaluation. This reasoning is clear and supports the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to similar studies that have used this approach, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Tables 1 and 2, noting that the authors report the best results on the dev set with hyperparameter search and model selection on the same set. This is considered insufficient to be convincing. The reviewer provides a clear and actionable suggestion by recommending that the authors present the average results on the test set with error bars under different random seeds. This feedback is detailed and constructive, offering a specific way to enhance the robustness and reliability of the results presented in the paper. By following this advice, the authors can significantly improve the clarity and credibility of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the dataset used in the study, including the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment does not explicitly instruct the authors to provide this information, the questions are clear and specific, allowing the authors to infer that they need to include this information in their paper. The action is concrete, as it specifies what needs to be addressed, but it is implicit because it is not explicitly stated. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the dataset used in the study, specifically regarding the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment does not explicitly mention specific sections of the paper, it is clear that it pertains to the dataset description and analysis sections. The authors can infer that it relates to the methodology or results sections, but they cannot pinpoint the exact part of the paper being addressed. The comment is specific in detailing what information is missing or unclear, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the dataset used in the study, including the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also requests that the main paper describe the number of documents in the train/test sets and the vocabulary size. While the comment does not contain an opinion or suggestion that requires verification, it is a request for additional information. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions about the dataset used in the study, specifically regarding the number of topics, the source of topicword parameters, and the size of the AG news dataset. It also suggests that the main paper should describe the number of documents in the train/test sets and the vocabulary size. While the comment identifies areas where the paper lacks clarity and provides specific questions for the authors to address, it does not offer detailed guidance or suggestions on how to improve the draft. The feedback is 3 as it highlights important aspects that need clarification, but it could be more comprehensive by providing additional insights or suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to expand their analysis to include more NAS approaches, but the comment lacks concrete suggestions on which specific approaches to include or how to conduct the additional comparisons. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment addresses the analysis on BRPNAS, specifically mentioning that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which sections or figures are affected. The comment is specific in pointing out the lack of comparison with other NAS approaches, which is a clear area for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. However, the comment does not provide specific examples or references to support the claim that these other approaches are relevant or necessary. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the analysis of BRPNAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like supernet/oneshot methods. This feedback is clear and actionable, as it directs the authors to expand their analysis to include a broader range of NAS approaches. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these additional approaches or what aspects of the analysis should be expanded. Overall, the comment is 4 as it highlights a significant gap in the analysis and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or whether it should be included or removed. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the zeroshot version and its connection to density estimation, suggesting that they are somewhat distracting to the main point of the paper, which is learning to produce good prototypes for fewshot learning. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the distraction caused by the zeroshot version and its connection to density estimation, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the zeroshot version and its connection to density estimation, suggesting they are somewhat distracting to the main point of the paper. However, the comment lacks specific reasoning or evidence to support why these aspects are considered distracting or how they impact the main point. The claim is based on the reviewer\"s subjective perception, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential distraction in the paper, specifically the zeroshot version and its connection to density estimation, which may divert attention from the main point of learning to produce good prototypes for fewshot learning. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the focus of their paper. While it highlights a potential problem, it lacks actionable feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should enhance the experiment results with additional attacks and threshold variations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors might infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, namely the inclusion of different attacks and thresholds, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results can be enriched by including attacks with different strengths and exploring how different thresholds affect detection performance. However, the comment does not provide specific examples or references to support the claim that these additions would be beneficial. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion and how it would improve their work. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies two specific areas where the experiment results could be enriched: the inclusion of attacks with different strengths and the exploration of how different thresholds affect detection performance. This feedback is 3 as it points out potential enhancements that could improve the robustness and comprehensiveness of the experimental evaluation. However, the comment lacks detailed guidance on how to implement these suggestions or what specific thresholds or strengths should be considered. To be more helpful, the comment could provide examples or references to similar studies that have addressed these issues, offering a clearer path for the authors to follow. Therefore, the comment is rated as 3, as it provides some actionable feedback but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a specific action for the authors to take to evaluate their claim of reducing exposure bias. It explicitly states that training a discriminator on generations from the learned model is needed to confirm this claim, similar to the approach depicted in Figure 1. The comment also clarifies that this is different from Figure 4, where the discriminator is coadapting with the generator during training. This provides clear guidance on what the authors should do to substantiate their claim, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that training a discriminator on generations from the learned model is needed to confirm the claim of reducing exposure bias, similar to Figure 1. This provides clear guidance on how to improve the evaluation section of the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific action for the authors to take to evaluate their claim of reducing exposure bias. It implies that training a discriminator on generations from the learned model is necessary to confirm this claim, similar to the approach depicted in Figure 1. However, the comment does not provide detailed reasoning or examples to support why this approach is necessary or how it would substantiate the claim. The lack of specific evidence or detailed explanation makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for evaluating the claim of reducing exposure bias. It specifies that training a discriminator on generations from the learned model is necessary to confirm this claim, similar to the approach depicted in Figure 1. This feedback is specific and offers a concrete method for the authors to substantiate their claim, making it 5. By following this suggestion, the authors can significantly improve the evaluation section of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to know the extent of the performance difference resulting from using different image sizes and different variations of ResNets. While the comment implies that the authors should investigate and report this difference, it does not provide explicit instructions on how to conduct this analysis or what specific metrics or methods should be used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is understanding the performance difference resulting from using different image sizes and ResNet variations. This provides clear guidance on what the authors should investigate and report. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for more information, specifically asking for clarification on the performance difference resulting from using different image sizes and ResNet variations. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is 3 as it identifies a specific area where the authors could provide more information, namely the performance difference resulting from using different image sizes and ResNet variations. This feedback encourages the authors to include this information, which could enhance the comprehensiveness of their analysis. However, the comment lacks depth and does not provide specific guidance on how to measure or report this difference, leaving the authors with a general suggestion rather than a detailed action plan. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that a runtime comparison is necessary and how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. However, it does not specify which part of the paper discusses the use of Chebyshev polynomials or where the runtime comparison should be included. This makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in suggesting a runtime comparison, but the lack of grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. However, the comment does not provide any reasoning, examples, or references to support why such a comparison would be beneficial or how it could be conducted. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper\"s mention of using Chebyshev polynomials for speedup should be accompanied by a runtime comparison at test time. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a specific comparison that could enhance the paper\"s analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. To be more helpful, the comment could include specific suggestions or examples of how to implement the runtime comparison. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the applicability of the proposed method beyond digit or text images, specifically questioning its use on natural images like CIFAR10. While the comment highlights a potential limitation, it does not provide explicit guidance or suggestions on how the authors might address this issue or expand the method\"s applicability. The action is implicit and vague, as the authors are left to infer that they should explore the method\"s applicability to natural images. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the proposed method, specifically questioning whether it can be used on natural images like CIFAR10. However, it does not specify which part of the paper discusses the method\"s applicability or where this limitation is addressed. The authors might infer that it relates to the experimental results or methodology sections, but this is not explicitly mentioned. The comment is specific in its question about the method\"s applicability, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the proposed method, specifically questioning whether it can be used on natural images like CIFAR10. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the proposed method, specifically questioning whether it can be used on natural images like CIFAR10, which have broader realworld applications. This feedback highlights an important aspect that the authors should consider when evaluating the scope and potential impact of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand the method\"s applicability. While it identifies a critical area for improvement, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, as it points out a relevant issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. This feedback is clear and direct, providing the authors with a specific action to take: to clarify the figures and ensure that all modules are labeled correctly. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the figures are not clear due to confusion in the relation of subfigures and the absence of labels for certain modules, such as CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning figure 2 and the confusion regarding the relation of 3 subfigures. It also notes that some modules are not labeled, such as CMAF, L_BT, and VoLTA. This feedback is based on the observation of the figures and the identification of specific issues, which provides some level of justification. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to address the issues mentioned to improve the clarity of the figures, but the feedback could be strengthened with more detailed examples or explanations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific issues with the clarity of the figures, particularly in figure 2, where the relation of 3 subfigures is confusing and some modules are unlabeled. This feedback is clear and actionable, as it provides the authors with a specific area to address in their draft. By highlighting these issues, the comment helps the authors improve the clarity and effectiveness of their figures, which is crucial for enhancing the overall understanding of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the figures or provided examples of how to label the modules effectively. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies questionable design choices, specifically mentioning the use of perplexity as a measure of semantic information retention after finetuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not provide explicit guidance on how to control these factors or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should address the control of domain drift. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific design choices, particularly the use of perplexity as a measure of semantic information retention after finetuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not explicitly mention which part of the paper discusses these design choices, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not precise. The comment is specific in detailing what needs to be addressed regarding the control of domain drift, providing clear guidance on the issue. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of perplexity as a measure of semantic information retention after finetuning, questioning how factors like domain drift are controlled. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that perplexity is an appropriate measure or that domain drift is not adequately controlled. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of perplexity as a measure of semantic information retention after finetuning. It questions how factors like domain drift are controlled, suggesting that the authors should address this issue. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how to control domain drift or improve the measure of semantic information retention. The feedback is 3 as it points out a potential weakness in the methodology, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: (1) How does the number of images impact the model performance, and (2) whether more training images make the performance worse or better. It also suggests that BYOL should be explained in the abstract for its first appearance. While the questions provide some guidance, they are not explicit about how the authors should address these issues. The suggestion to explain BYOL in the abstract is somewhat vague, as it does not specify how the authors should explain it. Therefore, the comment is 3, as it provides some direction but lacks concrete details on how to implement the suggestions.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questions, providing clear guidance on what the authors need to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions and a suggestion for clarification. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions and provides a suggestion for clarification. The first question asks about the impact of the number of images on model performance, which is a relevant inquiry for understanding the model\"s behavior. The second question seeks an explanation of BYOL in the abstract, which is important for readers who may not be familiar with the concept. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues or provide the necessary explanations. The feedback is 3 as it points out areas that need clarification but does not offer detailed advice on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors might address this concern, such as suggesting additional data collection or analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify the sufficiency of their dataset or consider expanding it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of dataset size, specifically questioning whether 44k dialogues are sufficient to capture a wide range of user traits and personalities across different content topics. It also questions the adequacy of the dataset to cover varied domains, given that LLMs are typically trained on trillions of tokens. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the dataset or experimental setup sections, but this is not explicitly mentioned. The comment is specific in detailing the concern about dataset size and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer provides a logical reasoning by comparing the dataset size to the scale of typical LLM training data, suggesting that the dataset needs to be massive to cover varied domains. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to conduct further analysis or provide additional context to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains, which is a valid point. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as expanding the dataset or conducting further analysis. While it identifies a potential weakness, the feedback could be more helpful with actionable advice. Therefore, the comment is 3, as it provides insight but lacks depth and actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors use other metrics, such as BERTScore, to evaluate the results. While the action is explicit, it does not provide specific guidance on how to implement this suggestion or which metrics to consider in addition to BERTScore. The authors are left with a clear direction but without detailed instructions on how to execute it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not specify which part of the paper this suggestion pertains to, such as the Results section or specific experimental results. Without explicit references to the sections or figures, the authors may find it challenging to determine where to apply this suggestion. Additionally, the comment lacks specificity regarding which metrics should be used or why BERTScore is preferred. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests using other metrics, such as BERTScore, to evaluate the results. However, it does not provide any reasoning, examples, or references to support why BERTScore is more appropriate or why other metrics should be considered. Without this justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using other metrics, such as BERTScore, to evaluate the results. While this is a specific and actionable suggestion, it does not provide any context or reasoning for why BERTScore might be more appropriate or why other metrics should be considered. The comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what other metrics might be relevant. As a result, the feedback is 3, as it provides a direction for improvement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. It also questions the conditions under which SynTextBench should be used over other metrics. While the comment implies that the authors should conduct these comparisons, it does not provide explicit instructions on how to perform them or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and references \"other metrics proposed in the literature,\" such as MMLU and Big Bench. This allows the authors to accurately identify the part of the paper being addressed, which is the comparison of SynTextBench to other metrics. The comment is also specific because it clearly specifies what needs to be addressed, namely, understanding the conditions under which SynTextBench should be used over other metrics. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there has been a large amount of work on LLM evaluation and that some metrics do not satisfy the proposed desiderata. It suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. The comment provides a logical reasoning by pointing out the existence of other metrics and suggesting a comparison to SynTextBench. However, it lacks specific references or examples to fully substantiate the claim about the other metrics that do not satisfy the desiderata. This makes the claim 3, as it provides a basis for the suggestion but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, for language generation tasks. This feedback is valuable as it provides a specific direction for the authors to enhance the comprehensiveness of their evaluation. By comparing SynTextBench to other metrics, the authors can better understand the conditions under which SynTextBench should be used over other metrics. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement but lacks depth in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses dissatisfaction with the writing and annotations, stating that they are \"a little hard to follow.\" However, it does not provide specific suggestions or guidance on how the authors might improve their writing or annotations. Without actionable advice or examples of what needs to be changed, the authors are left without a clear understanding of how to address the issue. As a result, the comment lacks actionable guidance, making it 1.", "grounding_specificity_rationale": "The comment mentions \"Poor writing and annotations,\" but it does not specify which sections or parts of the paper are affected. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. The comment is specific in its critique of the writing and annotations, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a subjective observation about the writing and annotations being \"a little hard to follow.\" It does not contain any claims, opinions, or suggestions that require verification or evidence. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the writing and annotations, noting that they are \"a little hard to follow.\" However, it lacks actionable feedback or suggestions on how the authors might improve the clarity of their writing or annotations. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the writing or annotations need improvement. As a result, the comment is 2, as it provides a general observation but does not offer actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed method, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under the \"Twitter2017 $\rightarrow$ Twitter2015\" setting, while not achieving the best F1 score in all single types. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this problem or what specific improvements are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and explain the discrepancies in the evaluation metrics. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that only 8 out of 14 evaluation metrics achieve SOTA performances and questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 in all single types. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s performance in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 in all single types. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to support the claim that the proposed method does not perform well in all metrics. The authors are left to infer the significance of these observations, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method\"s performance in Table 2, noting that only 8 out of 14 evaluation metrics achieve SOTA performances. It also questions the reason for the proposed method achieving the best overall F1 score under a specific setting while not achieving the best F1 in all single types. This feedback is 3 as it highlights a potential weakness in the evaluation and encourages the authors to investigate and explain the discrepancies in the performance metrics. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered insights into improving the evaluation methodology. Overall, the comment provides some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative approach they should consider. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to respond or improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the rationale behind the decision, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle if all reports were included. This feedback prompts the authors to reconsider their methodology or data selection, encouraging them to explore the implications of their current approach. However, the comment does not provide specific guidance or suggestions on how to address this issue or what alternative approaches might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests several improvements to the results presentation, including labeling the yaxis in Figure 2 and 3 as \"performance,\" which is ambiguous, and not representing the runtime in those figures. It also recommends using a scatter plot with x/y axes being runtime/performance to help readers better understand and interpret the results. Additionally, the comment suggests highlighting the best results in tables. These suggestions are explicit and provide concrete guidance on how the authors can improve their results presentation. The authors know exactly what changes to make and how to implement them, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 and 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as labeling the yaxis as \"performance,\" representing the runtime, and using a scatter plot with x/y axes being runtime/performance. Additionally, it suggests highlighting the best results in tables. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests improvements to the results presentation, such as labeling the yaxis in Figures 2 and 3 as \"performance,\" which is ambiguous, and not representing the runtime in those figures. It also recommends using a scatter plot with x/y axes being runtime/performance to help readers better understand and interpret the results. Additionally, it suggests highlighting the best results in tables. These suggestions are based on logical reasoning and common sense, as they aim to enhance the clarity and interpretability of the results. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on improving the presentation of results in the paper. It identifies two main issues: the ambiguity of the yaxis label in Figures 2 and 3, and the lack of representation of runtime in those figures. The reviewer suggests using a scatter plot with x/y axes being runtime/performance to enhance the clarity and interpretability of the results. Additionally, it recommends highlighting the best results in tables. This feedback is clear and provides concrete steps for the authors to improve their results presentation, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the impact of the base node, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion or complexity in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or improve their understanding of the topic. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential area for clarification but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2, specifically why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). The reviewer implies that the authors should clarify or justify this choice, but the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation or justification for the direction of the arrow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and why it is from a Gaussian space into the latent space rather than from the latent space to n^(i). The comment clearly specifies what needs to be addressed, namely the rationale behind the chosen direction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the direction of the arrow in Figure 2, specifically why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). The reviewer suggests that the main purpose is to influence n^(i), implying a potential inconsistency or lack of clarity in the figure. However, the comment lacks specific reasoning or evidence to support why this direction is problematic or how it affects the understanding of the figure. The absence of detailed justification or examples makes it difficult for the authors to address the issue effectively. Therefore, the comment is considered 2, as it provides a logical question but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2, questioning why it is from a Gaussian space into the latent space instead of from the latent space to n^(i). This feedback is 3 as it prompts the authors to clarify or justify their choice of direction, which could impact the reader\"s understanding of the figure. However, the comment lacks depth and does not provide suggestions for how the authors might address this issue or improve the clarity of their explanation. To be more helpful, the comment could include suggestions for alternative explanations or ways to enhance the figure\"s clarity. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, particularly the abbreviation \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. While the comment points out the lack of definition for abbreviations, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to define all abbreviations used in the paper, but the comment lacks concrete steps or examples of how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that many abbreviations lack definition and provides a specific example of \"AR\" standing for domain adaptation tasks and algorithms. This level of detail and specificity makes it clear what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and provides a specific example of \"AR\" in Table 5 standing for domain adaptation tasks and algorithms. This provides a clear and specific example of the issue, making the claim 3. However, the comment could be strengthened by providing additional examples or explaining why the lack of definition is problematic. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in the paper, noting that many abbreviations lack definition and causing confusion. It provides a clear example by pointing out that \"AR\" in Table 5 stands for domain adaptation tasks and algorithms. This feedback is actionable as it directs the authors to ensure that all abbreviations are defined to avoid confusion. However, the comment could be more helpful if it suggested how to define the abbreviations or provided examples of other abbreviations that need clarification. Overall, the comment is 4 as it highlights a critical issue and offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it does not provide explicit guidance or suggestions for the authors to follow. The comment implies that the authors should consider other technical aspects when using advantage, but it does not specify what these aspects might be or how they should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it does not explicitly mention a specific part of the paper, the authors can infer that it relates to the methodology or analysis section. The comment is specific in questioning the technical basis for using advantage, which provides some guidance on what needs to be addressed. However, the lack of explicit mention of a section or part of the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. It acknowledges that using advantage is more common in practice but seeks clarification on other technical aspects that might influence this choice. The comment does not make a claim or express an opinion, as it is purely inquisitive. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it seeks clarification on other technical aspects that might influence this choice. This feedback is 3 as it prompts the authors to consider additional factors that could be relevant to their analysis. However, it lacks depth and does not provide specific guidance or suggestions for addressing the question, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3, as it identifies an area for further investigation but does not fully support the authors in improving their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the setting of Unsupervised Online Adaptation, noting that it seems strange because the model requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the description of the setting. The action is implicit and vague, as the authors are left to infer that they need to clarify or reframe the description of the adaptation process. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the setting of Unsupervised Online Adaptation, noting that the model requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting of Unsupervised Online Adaptation is strange because it requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. The comment provides a logical reasoning by pointing out the contradiction between the unsupervised nature of the setting and the need for annotations in the training set. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the issue and how to address it, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the description of the Unsupervised Online Adaptation setting, noting that it seems strange because the model requires a training set with annotations, which implies that the adaptation process is not truly unsupervised. This feedback is 3 as it points out a specific area of confusion or misinterpretation in the paper. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might clarify or reframe the description to better align with the intended unsupervised nature of the adaptation process. Therefore, the comment is rated as 3, as it provides a starting point for improvement but does not fully address the authors\" needs for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights an issue with the fairness of the performance comparison in Table 1, specifically noting that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This comment implies that the authors should consider adjusting the comparison to ensure fairness, but it does not explicitly instruct them to do so. The action is implicit, as the authors need to infer that they should address the fairness of the comparison. However, the comment provides a clear and specific issue to address, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most compared baselines set all sample weights as 1. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to differences in sample weights used by VINS compared to other baselines. The reviewer provides a specific observation about the sample weights, which supports the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the comparison to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance comparison in Table 1, noting that the comparison is unfair due to differences in sample weights used by VINS compared to other baselines. This feedback is clear and actionable, as it highlights a potential weakness in the evaluation methodology that the authors should address. By pointing out this discrepancy, the comment provides a concrete direction for improvement, making it 4. However, it could be more helpful if it suggested how the authors might adjust the comparison to ensure fairness. Overall, the comment is valuable in guiding the authors towards enhancing the rigor of their evaluation, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative approaches or optimizations. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not specify which part of the paper discusses the reply buffer or the time complexity, making it weakly grounded. The comment is specific in identifying the potential issue with the time complexity, but without explicit references to the paper, the authors may struggle to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, \"PRMRL: Longrange Robotic Navigation Tasks by Combining Reinforcement Learning and Samplingbased Planning.\" However, the comment does not provide detailed reasoning or evidence to support why this is a concern or how it affects the paper. The reference to another paper is a step towards verification, but it lacks specific examples or detailed analysis to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. This is a relevant observation that could impact the practicality and efficiency of the proposed method. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the algorithm\"s efficiency. Without actionable advice or detailed feedback, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is 3, as it points out a potential problem but does not provide enough detail to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a clear direction for improvement, it does not specify which baselines should be included or how the authors should incorporate these perspectives. The action is explicit but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting ways to improve the performance display, but without grounding, the authors may struggle to identify the exact sections where this improvement is needed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific references or examples of these baselines, making it difficult for the authors to understand the exact suggestions or how to implement them. The lack of detailed references or examples makes the claim 3, as the authors would need to conduct additional research to fully understand the suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a clear direction for improvement by suggesting specific areas to explore and compare with existing work. However, the comment lacks detailed guidance on which baselines to include or how to incorporate these perspectives, which could limit its effectiveness. The authors would need to conduct additional research to fully address this suggestion, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a brief conclusion of the article and a summary of the paper\"s contributions need to be provided. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to improve the draft. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion of the article and a summary of the paper\"s contributions need to be provided. However, it does not specify which part of the paper these should be included in, making it weakly grounded. The comment is specific in its request for a conclusion and summary, but without explicit references to sections, it is challenging for the authors to pinpoint where these should be added. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and summary of the paper\"s contributions are needed. However, it does not provide any reasoning, examples, or references to support why these additions are necessary or how they would enhance the paper. Without specific justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that a brief conclusion and a summary of the paper\"s contributions need to be provided. This feedback is clear and actionable, as it directs the authors to include these elements in their draft to enhance its completeness and clarity. However, the comment could be more helpful if it provided examples of how a conclusion and summary could be structured or what specific points should be included. Despite this, the feedback is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include a comparison with a method designed to defend against multiple attacks, which provides some guidance on what the authors could do to improve their paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This claim is 3 as it provides a logical suggestion for improvement, but it lacks specific examples or references to existing methods that could be used for comparison. The comment implies that the current comparison with APEGAN is not comprehensive enough, but it does not provide detailed reasoning or evidence to support this claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This is a constructive suggestion that could enhance the paper\"s relevance and impact by providing a more comprehensive comparison. The comment also acknowledges the paper\"s interest in defending against increasing malicious perturbations, which adds value to the feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this comparison. Overall, the feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to define the bounds for \u03c7_i^l, which is crucial for understanding the timewarp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is defining the bounds for \u03c7_i^l to improve understanding of the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification, asking the authors to define the bounds for \u03c7_i^l. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, providing a specific request for the authors to define the bounds for \u03c7_i^l. This is important for understanding the timewarp function, which is a critical aspect of the paper. By addressing this request, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional context or suggestions on how to define these bounds or why they are important. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While it points out these issues, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to revise the text to fix these errors, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not specify which part of the paper these errors are found in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment highlights specific issues, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, the comment does not provide any reasoning or context to explain why these errors are problematic or how they affect the clarity or professionalism of the paper. Without additional explanation or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While it points out these errors, it does not provide any guidance on how to correct them or why they are problematic. The comment lacks depth and actionable advice, leaving the authors with a list of errors to fix but no insight into how to improve the overall clarity and professionalism of their writing. Therefore, the comment is 2, as it provides some information but does not offer meaningful feedback for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first sentence of the abstract needs to be rewritten, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it gives the authors a specific task to perform to improve the abstract. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first sentence of the abstract, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the action needed, which is to rewrite the sentence. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for a specific action, namely to rewrite the first sentence of the abstract. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it directly instructs the authors to rewrite the first sentence of the abstract. This feedback provides a clear direction for improvement, which is valuable for the authors to enhance the clarity and effectiveness of their abstract. However, the comment does not offer additional guidance or suggestions on how to rewrite the sentence, which could further enhance its helpfulness. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the method is more complex than necessary and implies that there might be a simpler principle behind the quality gains. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the method or identify the underlying principle. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the method is more involved than necessary and implies that there might be a simpler principle behind the quality gains. However, it does not specify which part of the paper this observation pertains to, such as a specific section or method description. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion that the method could be simplified, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 1 and specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the method is more complex than necessary and implies that there might be a simpler principle behind the quality gains. However, it does not provide any specific evidence, examples, or references to support this claim. The comment lacks detailed reasoning or references to substantiate the assertion that the method is overly complex or that there is a simpler principle. Without additional context or justification, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the method is more complex than necessary and implies that there might be a simpler principle behind the quality gains. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how to simplify the method or identify the underlying principle. Without detailed suggestions or examples, the authors are left without a clear path to address the issue. Therefore, the comment is 2, as it provides a general observation but does not offer actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses dissatisfaction with the hGRU architecture, stating it is \"adhoc\" and \"not very well motivated.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the architecture or what specific aspects need clarification. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the hGRU architecture, stating it is \"adhoc\" and \"not very well motivated.\" However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the architecture are adhoc or not wellmotivated, leaving the authors without clear guidance on how to address the issue. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture is \"adhoc\" and \"not very well motivated.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses dissatisfaction with the hGRU architecture, describing it as \"adhoc\" and \"not very well motivated.\" However, it does not provide any specific feedback or suggestions on how the authors might improve the architecture or clarify its motivation. Without actionable guidance or detailed critique, the comment lacks the depth and specificity needed to be helpful. The authors are left without a clear understanding of what aspects of the architecture need improvement or how to address the critique. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. First, it suggests a correction in the algorithm description, specifically questioning the use of \"s_t\" instead of \"s_n\" on Line 8. This is an explicit and concrete action for the authors to take, as it provides a direct correction to the draft. Second, it raises a curiosity about the asymptotic performance of the proposed method and suggests that the authors provide average return results with more environment steps. This part is also explicit, as it gives a clear request for additional information. Overall, the comment is 5 because it provides specific and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of \"s_n\" instead of \"s_t\" and raises a curiosity about the asymptotic performance of the proposed method. Additionally, it provides a link to a GitHub repository for further reference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the use of \"s_n\" instead of \"s_t\" in Algorithm 1, Line 8, which is a factual observation that does not require verification. The second part raises a curiosity about the asymptotic performance of the proposed method and requests additional results. This part is 3 as it provides a specific question but lacks detailed reasoning or evidence to fully substantiate the curiosity. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with the algorithm description, suggesting a correction in the use of \"s_n\" instead of \"s_t\" on Line 8. This provides a clear and actionable feedback for the authors to address. Additionally, the comment raises a curiosity about the asymptotic performance of the proposed method and requests additional results, which could be valuable for further analysis. However, the comment could be more helpful if it provided more context or reasoning about why the correction is important or how the additional results might impact the study. Overall, the feedback is 4 as it directs the authors to a specific area for improvement and suggests additional analyses that could enhance the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between their approach and Zhang et al. While the comment implies that the authors should provide a detailed explanation, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to clarify the challenges, but it lacks concrete guidance on how to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the analysis of Adam under the (L0,L1)smoothness condition. It raises a question about the challenges involved and suggests that the authors should explain these challenges, particularly in relation to Zhang et al. This provides some level of grounding as it refers to a specific part of the paper, but it does not specify which section or part of the analysis is being discussed. The comment is specific in its suggestion to explain the challenges and the difference between the authors\" approach and Zhang et al., but it lacks full grounding due to the lack of explicit section references. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the challenges when analyzing Adam under the (L0,L1)smoothness condition. It suggests that the authors should explain these challenges, particularly in relation to Zhang et al. The comment implies that the analysis could be improved by providing a more detailed explanation of the challenges involved, but it does not provide specific examples or references to support this claim. The reasoning is based on the reviewer\"s perception of the lack of clarity, which is not fully substantiated with evidence or examples. Therefore, the comment is 3, as it provides a logical suggestion but lacks detailed justification or references to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the analysis of Adam under the (L0,L1)smoothness condition. It points out that the challenges in this analysis are not clearly explained and suggests that the authors should provide a detailed explanation, particularly in relation to Zhang et al. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing aspect of their analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to address the challenges or differentiate the authors\" approach from Zhang et al.\"s work. Overall, the comment is 4 as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point mentions that most person reID methods are based on pedestrian detectors and that there are endtoend methods that combine detection and reID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate this information into their work or whether it is relevant to their research. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment discusses the methods used in person reID, mentioning that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. However, it does not specify which part of the paper this information is relevant to, nor does it provide specific guidance on how the authors should address this point. The authors may infer that it relates to the methodology section, but without explicit mention, it remains unclear. The comment lacks specificity in detailing what needs to be addressed or improved, making it 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point makes a factual statement about the methods used in person reID, mentioning that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. This statement is descriptive and does not express an opinion, judgment, or suggestion that requires verification. It is a factual observation that does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a factual observation about the methods used in person reID, noting that most methods are based on pedestrian detectors and that there are also endtoend methods that combine detection and reID. However, it does not offer any specific guidance or suggestions on how this information might be relevant to the authors\" work or how it could be incorporated into their research. Without actionable feedback or insights, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests adding a first sentence to introduce the content of Section 3.2. This is a clear and direct action for the authors to take, as it specifies what needs to be done to improve the clarity of the section. The suggestion is concrete, as it provides a specific step for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly suggests adding a first sentence to introduce the content of the section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2, which is a clear and direct suggestion. However, it does not provide any reasoning or justification for why this addition is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification.", "helpfulness_rationale": "The review comment is clear and actionable, suggesting that the authors add a first sentence to introduce Section 3.2. This is a straightforward and specific piece of feedback that can help the authors improve the clarity and organization of their paper. By providing a direct action, the comment is 4, as it guides the authors in making a specific improvement to their draft. However, it could be more helpful if it explained why adding a first sentence is important or how it would enhance the section. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded with additional context."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what steps to consider. As a result, the authors are left without a clear understanding of what action to take or how to improve their draft based on this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what aspect of the paper needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the claim or justify why this is a concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the meaning of \"initial rationale selector is perfect\" in line 44. It suggests that if the rationale selector were perfect, no additional work would be needed. This feedback is 3 as it prompts the authors to clarify the meaning of this term and consider whether it is accurate or if there are additional aspects that need to be addressed. However, the comment lacks depth and does not provide specific guidance or suggestions for improvement. The authors are left with a general question but without actionable steps to enhance their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, and second, it asks about the number of questions created for the zeroshot intent classifier and the accuracy of the system. While the comment explicitly mentions these areas of concern, it does not provide specific guidance or suggestions on how the authors should address these issues. The questions are clear and direct, but the lack of actionable advice or concrete steps for improvement makes the comment 3. The authors know what information is needed but not how to obtain it or how to incorporate it into their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues to be addressed, such as questioning the use of domain ontologies to avoid placeholders and asking about the number of questions and accuracy of the zeroshot intent classifier. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual questions seeking clarification on specific aspects of the paper, such as the use of domain ontologies and the accuracy of the zeroshot intent classifier. These questions do not express an opinion, judgment, or suggestion that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions that are relevant to the paper\"s methodology and evaluation. The first question asks about the use of domain ontologies to avoid placeholders in the evaluated responses, which is a critical aspect of the experimental setup. The second question seeks clarification on the number of questions created for the zeroshot intent classifier and the accuracy of the system. These questions provide clear and actionable feedback, prompting the authors to clarify and potentially expand upon their experimental methodology and results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4 as it directs the authors to important areas for clarification and improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. While the comment implies that such a comparison would be beneficial, it does not provide explicit instructions on which specific methods to include or how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result section. The authors may infer that it relates to the comparison section or the introduction, but this inference is not explicit. The comment is specific in its suggestion to compare with noncontrastive methods, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the work with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any reasoning, evidence, or examples to support why such a comparison would be beneficial or how it would enhance the paper. Without specific justification or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with other selfsupervised learning methods that are not based on contrastive learning. This feedback is 3 as it provides a direction for the authors to expand their analysis and potentially strengthen their paper by including a broader range of comparisons. However, the comment lacks specificity regarding which specific noncontrastive methods should be considered or how the comparison should be structured. To be more helpful, the comment could include examples of such methods or provide guidance on how to conduct the comparison. Therefore, the comment is rated as 3, as it offers a direction for improvement but lacks detailed guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. It explicitly requests clarification on this aspect. While the comment does not provide a direct action, it clearly identifies a specific area that needs further explanation. The authors are given a clear direction to address the issue, making the comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the difference between the abstention process and a decision threshold used by the models, and it requests clarification on this distinction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the abstention process, asking how it differs from a decision threshold used by the models. This question is relevant and prompts the authors to clarify a potentially confusing aspect of their work. By addressing this question, the authors can provide a more detailed explanation of their abstention process, which could enhance the clarity and understanding of their paper. However, the comment does not offer suggestions or guidance on how to improve the clarity of the abstention process or provide additional context. While it identifies a specific area for clarification, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a lack of meaningful baselines in the paper, noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare their work with a chainofthought prompting approach. This feedback is clear and provides a specific action for the authors to take, which is to include more meaningful baselines in their comparisons. The suggestion is concrete and actionable, as it gives the authors a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of meaningful baselines and suggests a comparison with a chainofthought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors could compare their work with a chainofthought prompting approach. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with a chainofthought prompting approach provides some direction but does not fully explain why this comparison would be meaningful or how it would enhance the paper. Therefore, the comment is 3, as it provides a suggestion but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s lack of meaningful baselines, noting that the authors limit their comparisons to simple naive baselines. It provides a specific suggestion by recommending the inclusion of a comparison with a chainofthought prompting approach, which could enhance the paper\"s comprehensiveness and validity. This feedback is clear and actionable, offering the authors a concrete direction for improvement. However, the comment could be more helpful if it provided additional context or examples of how the chainofthought prompting approach could be integrated. Overall, the comment is 4 as it guides the authors towards a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment does not explicitly instruct the authors to make a change, it does provide a clear question that prompts them to clarify their pretraining methodology and its implications for generalization. The action is implicit but concrete, as the authors can directly address the question by providing the necessary information. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the pretraining process and its implications for generalization, providing clear guidance on what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking about the pretraining process of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. The comment does not contain any claims or opinions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is 3 as it prompts the authors to consider the implications of their pretraining methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any explicit or implicit actions for the authors to take. The questions are openended and do not offer guidance on how the authors should address these concerns or what steps they should take to improve their draft. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not specify which part of the paper these questions pertain to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to identify the exact areas needing attention. The comment is specific in its questions about the accuracy of the ground truth and the significance of the differences, but without clear grounding, it is challenging for the authors to address the issues effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. They are straightforward inquiries seeking clarification or evidence, which do not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any context, analysis, or suggestions on how the authors might address these concerns or improve their draft. The questions are openended and lack actionable guidance, leaving the authors without a clear direction for improvement. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that no new evaluation metrics are proposed and that existing metrics are only linearly combined. It also suggests that there should be an indepth exploration of the reasons behind the experimental results in the analysis section. While the comment identifies areas for improvement, it does not explicitly instruct the authors to propose new metrics or provide specific guidance on how to explore the reasons for the results. The action is implicit and somewhat vague, as the authors can infer the need for new metrics and deeper analysis but lack concrete steps on how to implement these suggestions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the linear combination of existing metrics, specifically mentioning the experimental analysis section. This provides some grounding as it directs the authors to the relevant part of the paper. However, it does not specify which specific evaluation metrics are missing or how the existing metrics should be combined, leaving the authors with a general idea of what needs to be addressed but without detailed guidance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that no new evaluation metrics are proposed and that existing metrics are only linearly combined. This is a factual statement that does not require verification. However, it lacks specific examples or references to support the claim that the existing metrics are insufficient or that new metrics are necessary. The suggestion to explore the reasons for the experimental results is also a general observation without detailed reasoning or evidence. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of new evaluation metrics and the reliance on linearly combining existing metrics. It highlights the need for an indepth exploration of the reasons behind the experimental results, suggesting that the authors should provide a more detailed analysis. While the comment points out a critical area for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without detailed steps or examples to follow. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue. It lacks actionable advice, such as suggesting alternative notations or recommending a consistent use of \"K.\" As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This provides some grounding as it refers to specific lines in the paper (L166 and L176), allowing the authors to identify the parts of the paper being addressed. However, the comment lacks specificity as it does not explain why this ambiguity is problematic or suggest how the authors might resolve it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the notation \"K\" is abused in the paper, being used ambiguously to represent both a known kernel function and the number of layers. This is a factual observation that does not require verification, as it is based on the reviewer\"s understanding of the text. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This is a clear and actionable observation that highlights a potential source of confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending alternative notations or suggesting ways to clarify the usage of \"K.\" While it points out a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the practical relevance of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical nature of the weak recovery problem and questions the practical impact of the AMP algorithm, particularly in nonGaussian problems. However, it does not specify which part of the paper this critique pertains to, such as a specific section or result. The authors might infer that it relates to the discussion of the weak recovery problem or the AMP algorithm, but this inference is not explicit. The comment is specific in its critique of the practical impact, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. However, the comment does not provide specific evidence, examples, or references to support this claim. The reasoning is based on a general observation about the theoretical nature of the problem, but without detailed justification or examples, it is difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the practical relevance of the weak recovery problem studied, questioning whether the AMP algorithm is useful for nonGaussian problems. This feedback is 3 as it highlights a potential limitation of the work, which could be important for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the practical applicability of their findings. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" acknowledgment of the problem\"s reductionist nature and the absence of mechanisms like bargaining and negotiation. The reviewer suggests that the authors clarify their stance on this and provides a specific example of a behavioral economist who might consider these aspects. However, the comment does not explicitly instruct the authors to make these clarifications or provide specific references for comparison. While the action is implicit, it is concrete as it outlines what needs to be addressed. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the problem being studied and the authors\" acknowledgment of its reductionist nature. It also references specific elements, such as the absence of bargaining and negotiation mechanisms, which allows the authors to accurately identify the part of the paper being addressed. The comment is specific because it questions the relevance of connections to human cognition and suggests that the authors need to provide more citation for comparison against \"previously appreciated\" aspects. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" acknowledgment of the problem\"s reductionist nature and the absence of mechanisms like bargaining and negotiation. The reviewer suggests that the authors clarify their stance on this and provides a specific example of a behavioral economist who might consider these aspects. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim that the authors\" perspective is unclear. While the suggestion for more citation is a step towards verification, the lack of detailed justification makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a critical question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\" acknowledgment of the problem\"s reductionist nature and the absence of mechanisms like bargaining and negotiation, which are commonly used by humans. The comment suggests that the authors clarify their stance on this and provides a specific example of a behavioral economist who might consider these aspects. This feedback is clear and actionable, as it prompts the authors to address a potential gap in their argument and provides a direction for further exploration. However, the comment could be more helpful if it offered specific suggestions or examples of how to incorporate these aspects into the paper. Overall, the comment is 4, as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant. However, it does not provide specific guidance on how to address this issue or suggest alternative wording. The authors are left without clear instructions on how to improve the phrasing or tone of their writing. As a result, the comment is vague and lacks actionable details, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of exaggerated wording in the conclusion, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" This provides some grounding as it refers to a specific part of the paper, but it does not specify which sections or sentences are affected by this issue. The comment is specific in identifying the problem with the word choice, but it lacks full grounding because it does not pinpoint the exact location of the exaggerated wording. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant. This feedback is 3 as it points out a potential problem with the writing style, but it lacks depth and does not provide specific suggestions on how to improve the phrasing or tone. The authors are left with a general understanding of the issue but without actionable guidance on how to address it. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, specifying what needs to be done and how to implement it. The feedback is concrete and actionable, allowing the authors to understand exactly what modifications are necessary to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison should be emphasized or how the results should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any reasoning, examples, or references to support why this comparison is necessary or how it would benefit the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and offers a concrete way for the authors to enhance their work by providing a comparative analysis. However, the comment could be more helpful if it included additional guidance on how to structure the ablation experiments or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors towards a meaningful improvement in their draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of comparison to simple feature acquisition baselines, such as expected utility, which is a significant weakness of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment also mentions writing style and other issues, but these are not elaborated upon. As a result, the authors are left without clear instructions on how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment also mentions writing style and other issues, but these are not elaborated upon, leaving the authors without specific guidance on how to address them. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility, which is a significant weakness. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\"s credibility and impact. However, the comment does not provide specific suggestions or guidance on how the authors might conduct these comparisons or which baselines would be most appropriate. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. First, it suggests that the authors should address the strangeness of Fig. 5a by providing more explanations. Additionally, it asks for clarification on how the authors dealt with DVS input when the input is in aer format. Lastly, it recommends analyzing energy consumption, similar to what reference 15 did, to make the paper more solid. These actions are clear and specific, giving the authors a clear path to follow for improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5a,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing more explanations for the strangeness of Fig. 5a and clarifying how the authors dealt with DVS input when the input is in aer format. Additionally, it suggests analyzing energy consumption as reference 15 did to strengthen the paper. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions and suggestions for improvement, such as asking for more explanations about Fig. 5a and clarifying how the authors dealt with DVS input when the input is in aer format. It also suggests that analyzing energy consumption as reference 15 did would make the paper more solid. However, the comment does not contain any claims or opinions that require verification. It is purely descriptive and seeks clarification or guidance, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improvement. It highlights specific areas that need clarification, such as Fig. 5a and the handling of DVS input when the input is in aer format. Additionally, it offers a constructive suggestion to analyze energy consumption as reference 15 did, which could enhance the paper\"s solidness. These points are clear and provide the authors with concrete steps to improve their draft, making the comment 4. However, it could be more helpful if it included more detailed guidance or examples for the suggested improvements. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these additional experiments. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed guidance on how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this is not explicitly mentioned. The comment is specific in detailing the concerns and suggestions for further experimentation, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments do not adequately address these issues. The authors are left with a general concern that needs further exploration, but without concrete evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important concerns about the potential impact of similarityaware positive sample selection on GNNbased encoder oversmoothing and the generalization performance of the model. It highlights a specific area of concern regarding the training of similar nodes or graphs with features that converge excessively, potentially discarding their unique features. Additionally, it questions the effectiveness of selecting positive samples without introducing perturbation noise, which could lead to lower generalization performance. The comment suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the feedback identifies critical areas for improvement, it lacks specific guidance on how to design or conduct these additional experiments. The authors are left with a clear understanding of what needs to be addressed but may need to develop their own strategies for implementing the suggested improvements. Therefore, the comment is 3, as it provides valuable insights but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded. As a result, the authors are left without a clear understanding of what changes or additions are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide any specific guidance on what aspects of the discussion should be expanded. The authors may have an idea of where this discussion could fit, but the comment lacks explicit grounding and specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question and an expression of desire for more discussion on the power of different architectures. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or what aspects of the discussion should be expanded. Without detailed suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it provides some insight but does not offer actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors should clarify these concepts or where in the paper they should make these clarifications. Without specific instructions or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations/social norms (e.g., physical/psychological safety) in the main paper. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in identifying the issue, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, noting that the types of situations/social norms (e.g., physical/psychological safety) are not clear. This feedback is valuable as it highlights a potential gap in the paper\"s clarity, which could impact the reader\"s understanding. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as providing additional explanations or examples. While it points out a critical area for improvement, the lack of specific advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to define the dashed lines in figures 2AB and 4B. This is a clear and direct action that the authors can take to address the comment. By specifying which figures need clarification, the comment provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"fig. 2AB and 4B,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment is also specific as it clearly requests the definition of the dashed lines in these figures. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the definition of dashed lines in specific figures. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it explicitly requests the authors to define the dashed lines in specific figures (fig. 2AB and 4B). This feedback provides a direct and specific direction for improvement, allowing the authors to address a potential source of confusion or misinterpretation in their figures. By following this suggestion, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define the dashed lines effectively. Overall, the comment is 4 as it guides the authors toward improving their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the comparability of their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not specify which part of the paper discusses the results or the proposed methods, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in detailing what aspects of the results are not comparable or what specific methods are being referred to. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods may lack significance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or comparisons to existing methods, the authors are left without guidance on how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the comparability of the results to existing methods, suggesting that the proposed methods may lack significance. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential problem but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment suggests that this limitation could restrict the applicability of the results. However, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the scope of their results. The action is implicit and vague, as the authors are left to infer that they should consider broader kernel classes or discuss the implications of this limitation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific limitation in the paper regarding the assumption of a subgaussian spectrum for kernels, particularly mentioning the exclusion of Matern kernels due to their polynomial decay spectrum. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which section or part of the paper this limitation is discussed in. The comment is specific in detailing the issue with the assumption and the potential restriction of the results, but it lacks full grounding due to the absence of explicit section references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s results are limited because the authors assume a subgaussian spectrum for kernels, which is reasonable for popular Gaussian kernels but excludes other popular kernels like Matern kernels. The reviewer provides a logical reasoning for this claim, explaining that the assumption is valid for Gaussian kernels but not for Matern kernels, which decay polynomially. This reasoning is clear and provides a basis for understanding the limitation. However, the comment could be strengthened by providing specific examples or references to Matern kernels to further substantiate the claim. Overall, the comment is 4 due to its logical reasoning and potential for further elaboration with specific examples.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s results, specifically the assumption that the spectrum of a kernel is subgaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. This observation highlights a potential restriction in the applicability of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand the scope of their results. While it points out an important issue, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance gain. It suggests that the authors should focus more on the pretraining method in the main paper. While the comment explicitly states the action of focusing more on the pretraining method, it does not provide specific guidance on how to implement this suggestion, such as which aspects of the pretraining method should be emphasized or how to structure the discussion. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining in the main paper and suggesting that it is more important than other modules presented in the paper. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4. However, it lacks specific examples or detailed reasoning to support why this is the case. The comment also suggests that the main paper does not discuss unsupervised pretraining, which is a problem, and compares it to the ablation study in Table 5, where unsupervised pretraining is more important than other modules. While the comparison provides some context, the lack of detailed evidence or examples makes the claim 3. The authors would need to provide more specific information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance gain. It highlights that the unsupervised pretraining is more important than other modules presented in the paper, as indicated by the data in Table 4 and the ablation study in Table 5. The comment provides a clear suggestion for improvement by recommending that the authors focus more on the pretraining method in the main paper. This feedback is actionable and provides a specific direction for the authors to enhance their draft, making it 4. However, it could be more helpful if it offered additional guidance on how to structure the discussion or what aspects of the pretraining method should be emphasized. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment raises an important consideration, it does not explicitly instruct the authors to address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of this choice and potentially adjust their methodology accordingly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the issue with the choice of ELM and the need for accuracy calculation after using a gender detection model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, which is a logical point. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the relevance of this point to their work and consider the implications of the suggested approach. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker\"s gender beforehand, particularly at inference time. It points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker\"s identity. This feedback is valuable as it highlights an important consideration that could impact the accuracy and reliability of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored the implications of this choice on the methodology. Overall, the comment is 4 as it identifies a significant area for improvement and encourages the authors to consider the impact of their choices, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to 31. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how the authors might improve the technical depth or substance of their work, nor are there suggestions for alternative approaches or additions. As a result, the authors are left without any actionable steps to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to 31. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the paper are lacking in terms of technical depth or substance. Without specific references or examples, the authors cannot confidently determine which parts of the paper need improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, as it only adds a new loss to 31. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper is incremental and lacks technical depth, as it only adds a new loss to 31. However, it does not provide any specific details or examples of what aspects of the paper are lacking in terms of technical substance or how the new loss contributes to the field. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the difference between Eqs. (7) and (10), specifically why one uses X and the other uses H^(1). While the comment raises a valid concern about the inconsistency in notation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify or unify the notation used in these equations. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqs. (7) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the inconsistency in notation, specifically why one equation uses \"X\" and the other uses \"H^(1). This provides clear guidance on what needs to be addressed in terms of notation consistency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inconsistency in notation between Eqs. (7) and (10), specifically why one uses \"X\" and the other uses \"H^(1). This is a factual observation rather than a claim or suggestion, as it does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the inconsistency in notation between Eqs. (7) and (10), questioning why one uses \"X\" and the other uses \"H^(1). This feedback is clear and actionable, as it prompts the authors to clarify or unify the notation used in their equations. However, the comment does not provide suggestions on how to address this issue or offer additional context that could further enhance the draft. While it identifies a potential area for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the applicability of the model to realworld diffusion processes and suggests that the authors provide empirical evidence to demonstrate the model\"s ability to capture diffusion phenomena in realworld scenarios. While the comment implies that the authors should include empirical evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to obtain or present this evidence. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors provide empirical evidence to demonstrate the model\"s ability to capture diffusion phenomena. However, it does not specify which part of the paper this concern relates to, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to provide empirical evidence, but without grounding, it is challenging for the authors to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that empirical evidence is needed to demonstrate the model\"s ability to capture diffusion phenomena. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the applicability of the model to realworld diffusion processes, which is a significant aspect of the paper\"s relevance and impact. It suggests that the authors provide empirical evidence to demonstrate the model\"s ability to capture diffusion phenomena in realworld scenarios. This feedback is clear and actionable, as it guides the authors to include empirical evidence that would strengthen the paper\"s claims and enhance its practical relevance. However, the comment could be more helpful if it provided specific suggestions on how to obtain or present this evidence. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is explicit, it is somewhat vague as it does not specify which additional datasets should be used or how many datasets are needed for a comprehensive evaluation. The authors are given a clear direction to improve their work, but the lack of specific guidance on the number or types of datasets limits the level of detail. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper discusses the method or the datasets used, making it weakly grounded. The comment is specific in its suggestion to test on more datasets, but without grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any specific reasoning, examples, or references to support why more datasets are necessary or how they would improve the evaluation. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. While this is a logical and constructive suggestion, it lacks specificity and does not provide guidance on which additional datasets should be considered or how many datasets are needed for a comprehensive evaluation. The comment identifies a potential area for improvement but does not offer actionable advice or detailed feedback, making it 3. The authors are given a direction to improve their work, but the lack of specific guidance limits the comment\"s effectiveness. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the main contribution of combining attention with other linear mechanisms is not novel and mentions that alternatives exist. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their contribution. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the novelty of combining attention with other linear mechanisms, noting that it is not novel and that alternatives exist. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the novelty or alternatives should be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the main contribution of combining attention with other linear mechanisms is not novel and that alternatives exist. While it identifies a potential issue with the novelty of the approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve their contribution. The comment provides a general observation but does not offer actionable feedback or constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a plot showing how different weights of the model move, specifically suggesting a plot of relative weight change after unlearning to identify which layers are most affected. This is a clear and direct action for the authors to take, providing them with a specific and concrete task to improve their draft. The feedback is actionable because it gives a clear direction on what needs to be included in the paper to enhance its clarity and understanding. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Since the method is applied on each layer,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting the authors provide a plot of how different weights of the model move, such as plotting the relative weight change after unlearning to identify which layers are most affected. This provides clear guidance on what additional information is needed to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a plot showing how different weights of the model move, specifically after unlearning. This is a request for additional analysis or visualization, which is a logical suggestion based on the method\"s application on each layer. However, the comment does not provide specific examples or references to support why this plot is necessary or how it would enhance the paper. The lack of detailed reasoning or examples makes the claim 3, as the authors would need to infer the importance of the suggested plot themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper. It identifies a specific area where the authors can enhance their analysis by suggesting the inclusion of a plot showing how different weights of the model move, particularly after unlearning. This feedback is valuable as it offers a concrete way for the authors to visualize and potentially explain the impact of unlearning on different layers of the model. By following this suggestion, the authors can provide a more comprehensive understanding of their method\"s behavior, which could be beneficial for both the paper\"s clarity and the readers\" comprehension. However, the comment could be more helpful if it included specific examples or references to similar plots in other works, which would further guide the authors in implementing this suggestion. Overall, the comment is 4, as it provides a clear direction for improvement but could be enhanced with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere but not mentioned in the paper. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the domain of the inputs in their paper. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, specifically noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact location where this information should be included. While the comment is specific in questioning the domain of the inputs, it lacks grounding as it does not provide explicit references to the paper\"s sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. This feedback is 3 as it highlights a potential gap in the paper\"s description, prompting the authors to clarify this aspect. However, the comment lacks depth and does not provide guidance on how to address this issue or what specific information should be included to resolve it. Therefore, the comment is rated as 3, as it identifies a gap but does not fully support the authors in closing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a specific example, mentioning \"Z'\" and suggesting that taking it to be the empty set would imply independence between x and y given W, which contradicts Eq. (7). This feedback is explicit in pointing out the inconsistency and provides a clear action for the authors to address the conflict. However, it does not specify how to resolve the conflict or what changes should be made to the draft. While the action is clear, the lack of detailed guidance on implementation makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Second rule in Lemma 2,\" \"Eq (7),\" and \"the definition of minimal conditional dependence,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the potential conflict between the second rule and the definition, suggesting a specific example involving \"Z'\" and its implications. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, as illustrated by a specific example involving \"Z'.\" The reviewer provides a clear explanation of the issue, making the claim 3. However, the comment could be strengthened by providing additional context or references to support the claim fully. The authors would benefit from more detailed reasoning or examples to fully understand and address the conflict. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the paper, pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a clear example involving \"Z'\" and suggests that taking it to be the empty set would imply independence between x and y given W, which contradicts Eq. (7). This feedback is clear and actionable, as it directs the authors to a specific area of the paper that requires clarification or correction. However, the comment could be more helpful if it suggested how the authors might resolve the conflict or provided additional guidance on how to address it. Overall, the comment is 4 as it highlights a critical issue and offers a starting point for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the visual presentation of the data in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific guidance on how to improve the visual presentation, such as suggesting changes to the font size, style, or layout. While the action is implied, the lack of concrete details makes it vague. Therefore, the comment is 3, as it identifies an area for improvement but does not provide explicit instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the visual presentation, particularly the subscripts, could be enhanced for better readability and aesthetic appeal. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the visual presentation of data in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support this claim, such as suggesting particular aspects of the visual presentation that need improvement. Without additional context or evidence, the comment lacks sufficient detail to fully substantiate the claim. Therefore, it is classified as \"2,\" as it provides some support but requires more elaboration to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the presentation of data in Figure 3, noting that the visual presentation, particularly the subscripts, could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a specific area for the authors to focus on to improve the clarity and effectiveness of their visual data presentation. However, the comment could be more helpful if it offered suggestions or examples of how to enhance the visual presentation. Overall, the comment is 4 as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the update of archetype positions after initialization in Algorithm 2. It explicitly requests the authors to comment on this aspect, providing a clear and direct action for the authors to take. The comment is explicit and concrete, as it specifies exactly what information is needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the archetype positions are updated after initialization. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the update of archetype positions after initialization in Algorithm 2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the update of archetype positions after initialization in Algorithm 2. It provides a clear and direct question, asking the authors to clarify this aspect. This feedback is actionable as it prompts the authors to address a potential gap in their explanation, which could improve the clarity and understanding of their work. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should describe and compare the processing efficiency of training and testing with existing work. It explicitly states that the shape model is trained in a pixel level and independently on all font images and characters, and that the parsing model is a highorder factor graph with four types of factors. However, the comment does not provide specific guidance on how to improve the efficiency or which existing work to compare with. While the action is explicit, the lack of detailed instructions on how to implement the suggested improvements makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the shape model training and the parsing model, which is a highorder factor graph with four types of factors. It suggests that the processing efficiency of training and testing should be described and compared with existing work. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methods or results sections, but this is not explicit. The comment is specific in detailing the issue of processing efficiency and the need for comparison with existing work, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the shape model is trained in a pixel level and independently on all font images and characters, which is timeconsuming. It also mentions that the parsing model is a highorder factor graph with four types of factors, which could affect processing efficiency. However, the comment does not provide specific evidence, examples, or references to support these claims or explain how they impact the efficiency of training and testing. Without detailed reasoning or references, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the shape model training and the parsing model, which is a highorder factor graph with four types of factors. It suggests that the authors should describe and compare the processing efficiency of training and testing with existing work. This feedback is 3 as it points out a potential area for improvement in terms of efficiency and suggests a direction for comparison with other methods. However, the comment lacks specific guidance on how to improve efficiency or which existing work to compare with, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses difficulty in understanding the motivation of the paper and describes it as an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the motivation or address the perceived incremental nature of the work. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and describes it as an incremental engineering paper. However, it does not specify which part of the paper is being discussed or what aspects of the motivation are unclear. This lack of grounding makes it difficult for the authors to identify the specific sections or elements that need clarification. The comment is specific in its critique of the paper\"s motivation and incremental nature, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation of the paper is difficult to follow and describes it as an incremental engineering paper. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment expresses difficulty in following the motivation of the paper and describes it as an incremental engineering paper. While it identifies a potential issue with the clarity of the motivation, it lacks specific details or suggestions on how the authors might improve the clarity or address the perceived incremental nature of the work. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the motivation need clarification or how to enhance the paper\"s originality. Therefore, the comment is 2, as it provides a general observation but does not offer actionable insights for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a critical weakness in the paper, namely the lack of novelty and incremental nature of the work. It highlights that the paper addresses a specific problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or incremental nature of the work, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions the problem addressed, which is the design of semantic parsers for TexttoSQL, and highlights the design of a new dataset as a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, based on the work addressing a particular problem of column operations in designing semantic parsers for TexttoSQL. It mentions the design of a new dataset as a different train/test split of an existing dataset SQUALL and another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim that these elements lack novelty or are incremental. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the critique. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It points out that the paper addresses a particular problem of column operations in designing semantic parsers for TexttoSQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without specific guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides two explicit actions for the authors to take. First, it suggests adding a few more sentences explaining the experimental setting for continual learning. Second, it asks for clarification on Fig 3, specifically requesting an explanation of the correspondence between the learning curves and MPHATE, as well as why the authors want the reviewer to look at the learning curves. It also questions whether worseperforming models always result in structural collapse and asks for the accuracy number for the last task. These actions are clear and concrete, providing the authors with specific guidance on what needs to be addressed. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 3\" and \"continual learning,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on what needs to be addressed, such as adding more explanation for the experimental setting in continual learning and clarifying the correspondence between the learning curves and MPHATE in Fig 3. The comment also raises questions about the accuracy number and the structural collapse, providing clear guidance on what additional information is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests adding more explanation for the experimental setting in continual learning, which is a request for additional information. The second part questions the correspondence between the learning curves and MPHATE in Fig 3, asking for clarification on why the authors want the reviewer to look at the learning curves and whether worseperforming models always result in structural collapse. This part of the comment is 3 as it raises questions that require further explanation or evidence from the authors. However, it lacks specific examples or references to support the claim about the correspondence between the learning curves and MPHATE, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides two specific actions for the authors to take. First, it suggests adding more explanation for the experimental setting in continual learning, which is a clear and actionable suggestion. Second, it raises questions about Fig 3, specifically asking for clarification on the correspondence between the learning curves and MPHATE, as well as why the authors want the reviewer to look at the learning curves. It also questions whether worseperforming models always result in structural collapse and asks for the accuracy number for the last task. These questions and suggestions are clear and provide the authors with specific areas to address, making the comment 4. However, it could be more helpful if it offered additional guidance or examples to support the suggestions. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training. The reviewer provides references to existing works in the field, such as \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could guide the authors in exploring this idea further. However, the comment does not explicitly instruct the authors to incorporate labeled data into their consistency training or suggest specific steps to do so. While the suggestion is clear, it lacks concrete guidance on how to implement it, making the comment 4.", "grounding_specificity_rationale": "The comment raises a question about the use of labeled data for consistency training in graph anomaly detection, specifically mentioning the potential benefits of using exact labels. It references two external works, \"Graph Contrastive Learning Automated\" and \"Graph Contrastive Learning with Adaptive Augmentation,\" which could provide context for the discussion. However, the comment does not specify which part of the paper this question pertains to, such as a particular section or method. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to consider using labeled data for consistency training, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, referencing two external works. While the comment provides references to support the idea, it lacks detailed reasoning or specific examples of how using labeled data could enhance consistency training. The references are relevant to the topic, but the comment does not fully substantiate the claim with detailed analysis or evidence. Therefore, the claim is 3, as it provides a starting point for the authors to explore but lacks comprehensive justification.", "helpfulness_rationale": "The review comment raises an interesting question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data, with exact labels, could provide effective information for consistency training. The comment provides references to existing works in the field, which could guide the authors in exploring this idea further. However, the comment does not offer specific guidance or suggestions on how to incorporate labeled data into the consistency training process or what aspects of the current approach might be improved by doing so. While it identifies a potential area for enhancement, the feedback lacks depth and actionable advice, making it 3. The authors would benefit from more detailed guidance on how to implement this suggestion effectively."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental part needs to be reorganized and improved, and it provides specific guidance on what should be included in the experimental suggestions. This includes highlighting the superiority of the method and suggesting the inclusion of certain characteristics. The feedback is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"experimental part\" and \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be improved, such as reorganizing the content to better highlight the superiority of the method. This provides full grounding and specificity, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the experimental section needs to be reorganized and improved because the content does not effectively highlight the superiority of the method. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or references leaves the claim 3, as it requires the authors to infer the nature of the improvements needed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section of the paper, suggesting that it needs to be reorganized and improved to better highlight the superiority of the method. It provides a clear and actionable suggestion by specifying what should be included in the experimental suggestions, such as highlighting the characteristics of the article. This feedback is valuable as it offers a concrete direction for the authors to enhance the clarity and effectiveness of their experimental presentation. However, the comment could be more helpful if it provided additional guidance on how to reorganize the content or what specific aspects should be emphasized. Overall, the comment is 4, as it directs the authors toward a specific area for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper\"s claim about the flexibility of SGC should be supported with a plot comparing its performance with LoRA. It explicitly instructs the authors to include a plot with sparsity on the xaxis and performance on the yaxis, providing a clear and concrete action for improvement. This guidance gives the authors a specific task to perform, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the flexibility of SGC and the comparison with LoRA, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action needed, which is to include a plot comparing the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that SGC offers a more flexible, finegrained tradeoff, but it does not provide specific examples or references to support this claim. The suggestion to include a plot comparing SGC with LoRA is a logical step to substantiate the claim, but without detailed reasoning or evidence, the claim remains 3. The authors would need to infer the basis of the claim from the suggestion, making it 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the applicability of the paper\"s claims regarding the flexibility of SGC compared to PEFT methods. It suggests that the claim of finegrained control may not be practical in computeconstrained scenarios, which is a relevant point for the authors to consider. The comment provides a specific suggestion for improvement by recommending the inclusion of a plot comparing SGC with LoRA, which would visually demonstrate the practical performance benefits of SGC at different sparsity levels. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and impact of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not provide explicit instructions on how to address the question or what specific aspects of the training time should be examined. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the training time and potentially publish the code. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, it does not specify which part of the paper this question pertains to, such as a specific experiment or section. The authors can infer that it relates to the experiments section, but this inference is not explicit. The comment is specific in questioning the training time and suggesting code publication, but it lacks grounding as it does not pinpoint a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. However, the comment does not provide any specific reasoning or evidence to support the claim that the training time is unreasonable or to justify the suggestion to publish the code. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the experiments. It suggests that the authors should publish the code to support their findings. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address the issue or what aspects of the training time should be examined. The feedback is 3 as it prompts the authors to consider publishing the code, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. It suggests that this makes the human baseline considerably weaker than the model baseline, apart from other factors mentioned in Section 4.1. Additionally, the comment points out a potential misrepresentation in the abstract regarding the human baseline\"s performance. However, the comment does not provide specific guidance on how the authors should address this issue or improve the presentation of the human baseline. The feedback is explicit in identifying the problem but lacks concrete suggestions on how to resolve it, making it 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. This provides full grounding as it explicitly mentions the human baseline and the specific discrepancy. The comment is also specific because it highlights the impact of this discrepancy on the human baseline\"s performance and mentions a potential misrepresentation in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the human baseline is considerably weaker than the model baseline due to the human only following a little more than 1 hour of speech recordings compared to the full 15 hours. This claim is 3 as it provides a specific comparison between the amount of speech recordings used by the human and the model, which could be a factor in the baseline\"s performance. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as data or analysis demonstrating the impact of the difference in speech recordings on performance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. This highlights a potential discrepancy in the baseline performance, which is important for the authors to address. The comment also points out a potential misrepresentation in the abstract regarding the human baseline\"s performance. However, the feedback could be more helpful if it provided suggestions on how the authors might address this issue or improve the presentation of the human baseline. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the related work section, noting that it discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they should include these methods as baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the related work section, specifically mentioning the discussion of methods for training NMT models beyond MLE, such as RL methods. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the issue of none of these methods being used as baselines, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the related work section discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This claim is 3 as it identifies a gap in the literature review, but it lacks specific examples or references to support the claim fully. The authors would need to provide more detailed information or examples to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the related work section, noting that while it discusses methods for training NMT models beyond MLE, such as RL methods, none of these methods are used as baselines. This feedback is 3 as it points out a potential weakness in the paper\"s literature review. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending which RL methods to include as baselines or how to integrate them into the study. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding whether the authors are referring to a specific efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" is not a recognized entity, implying that the authors may be referring to a general concept of efficient proxies. However, the comment does not provide explicit guidance on how the authors should clarify this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term \"Efficient Proxy\" or provide a more precise definition of what is meant by \"efficient proxies.\" Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It points out that the term is unclear, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. However, the comment does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in identifying the ambiguity of the term \"Efficient Proxy,\" but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the term \"Efficient Proxy,\" suggesting that it could refer to a specific efficient proxy or a family of efficient proxies. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of terminology in the paper, specifically regarding the term \"Efficient Proxy.\" It points out that the term is ambiguous, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. This feedback is clear and actionable, as it provides a specific area for the authors to clarify in their draft. However, the comment could be more helpful if it offered suggestions on how to resolve the ambiguity or provided examples of how to clarify the term. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the methods used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Grouplearning setting, and the subsequent use of a classical method, DBSCAN, for clustering. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or improve their methodology. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions specific methods, \"Mirzasoleiman et al., 2020\" and \"Grouplearning setting,\" which allows the authors to identify the part of the paper being addressed. However, it does not specify what aspect of these methods or the use of DBSCAN is problematic or needs improvement. Without further details or context, the authors may find it challenging to understand exactly what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the methods are stacked from Mirzasoleiman et al., 2020 and the Grouplearning setting, and then use a classical method, DBSCAN, for clustering. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim or how it relates to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the methods used in the paper, noting that the methods from Mirzasoleiman et al., 2020 and the Grouplearning setting are stacked and then clustered using a classical method, DBSCAN. However, the comment does not provide any further details or suggestions on how the authors might address this issue or improve their methodology. Without additional guidance or actionable feedback, the authors are left without a clear path for improvement. Therefore, the comment is 2, as it highlights a potential problem but lacks actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that the authors consider the resilience of the metric to the choice of random projection. It implies that the authors should investigate the potential for pathological projection matrices to skew the MFTMA capacity and width scores. While the comment explicitly states the need for further exploration, it does not provide specific guidance on how to conduct this investigation or what aspects to focus on. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the results, namely the variability in results with the chosen random projection matrix. It suggests that the authors consider the resilience of the metric to the choice of random projection, which is a relevant concern. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or the appendix, but this is not clearly specified. The comment is specific in detailing the concern about the potential for pathological projection matrices to skew the scores, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that the authors consider the resilience of the metric to the choice of random projection. The reviewer implies that there might be a risk of pathological projection matrices skewing the scores, which is a valid concern. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it 3. The authors would need to investigate further to address this concern fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the variability in results with the chosen random projection matrix and suggests that the authors consider the resilience of the metric to the choice of random projection. It points out the possibility of pathological projection matrices skewing the MFTMA capacity and width scores, which is an important aspect to address for the robustness of the results. However, the comment could be more helpful if it provided specific guidance on how to investigate this issue or suggested methods for testing the resilience of the metric. Overall, the comment is 3 as it identifies a potential weakness in the study but lacks detailed actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It requests an example of what kind of data could look like synthetic data, asking for clarification on the meaning of \"support data\" and \"predicted training count data\" in Figure 1. Additionally, it suggests explicitly mentioning the model used in the paper, which could be added to the appendix. These actions are clear and concrete, providing the authors with specific steps to follow to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking for examples of synthetic data, clarification on the meaning of \"support data\" and \"predicted training count data,\" and the explicit mention of the model used. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions and requests for clarification regarding the synthetic data, the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and the explicit mention of the model used. These are factual inquiries that do not express an opinion, judgment, or suggestion. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas of confusion in the paper, such as the nature of synthetic data, the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and the explicit mention of the model used. By asking for clarification and examples, the comment provides actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, it could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4 as it directs the authors to clarify important aspects of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that the model is simple, which can be both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the simplicity of the model or whether it should be considered a feature or a bug. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model\"s simplicity are problematic or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify why the model is considered simple or why it is both a feature and a bug. Without specific details or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the model is simple, describing it as both a feature and a bug. While it identifies a potential issue with the model\"s simplicity, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the model. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it provides some insight but does not offer the level of detail or actionable steps needed for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the scope of their work. The comment lacks actionable guidance, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the focus of the work, specifically mentioning that it is narrow in terms of the task (climate change QA) and the language (Arabic). However, it does not specify which part of the paper discusses this focus, making it weakly grounded. The comment is specific in identifying the narrow scope of the work, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it affects the broader impact of their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the work, noting that it is focused on a narrow task (climate change QA) in a specific language (Arabic). This observation is relevant as it highlights a scope that may limit the broader impact of the research. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without specific recommendations or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it points out a potential issue but does not provide detailed feedback or actionable steps for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the originality of the paper, specifically regarding the use of the winnertakeall property, which has been widely used in previous works. It questions the novelty of the paper\"s contribution in understanding this behavior, especially given the simplified settings and findings that have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the originality of their work. The action is implicit and vague, as the authors are left to infer that they need to demonstrate the novelty of their contribution or clarify the originality of their approach. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the originality of the paper, specifically questioning the novelty of the winnertakeall property, which has been widely used in previous works. It highlights that most of the findings have been reported in previous works, particularly in Sec 5. However, the comment does not specify which part of the paper discusses the winnertakeall property or the findings in Sec 5, making it weakly grounded. The comment is specific in questioning the originality of the paper\"s contribution, but without explicit references to sections or findings, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the winnertakeall property has been widely used in previous works, questioning the originality of the paper\"s contribution. It suggests that most of the findings have been reported elsewhere, particularly in Sec 5. However, the comment lacks specific references or examples to substantiate the claim about the widespread use of the winnertakeall property or the exact findings that have been reported in previous works. This makes the claim 3, as the authors would need to conduct further research to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the originality of the paper, specifically regarding the use of the winnertakeall property, which has been widely used in previous works. It questions the novelty of the paper\"s contribution in understanding this behavior, especially given the simplified settings and findings that have been reported in previous works. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. While it identifies a potential issue, it lacks actionable feedback, making it 3. The authors are left to infer that they need to demonstrate the novelty of their contribution or clarify the originality of their approach, but without detailed guidance, the feedback remains incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends providing a rough example of some runtimes in the experiments, which would be useful for readers looking to apply the method. These suggestions are explicit and provide clear guidance on what the authors should include in their draft to enhance its motivation and applicability. The actions are concrete, as they specify exactly what information should be added and how it can be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests mentioning the negligible computational cost of CHR in the main paper and provides a suggestion for a rough example of runtimes. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to include the computational cost and provide an example, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location for these additions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it may be beneficial to mention the negligible computational cost of CHR in the main paper and provides a suggestion for a rough example of runtimes. This is a subjective suggestion based on the reviewer\"s opinion that such information could enhance the motivation for the method. However, the comment does not provide specific reasoning or evidence to support why this information is crucial or how it would impact the paper\"s motivation. Without detailed justification or examples, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper, which could help motivate the method. Additionally, it recommends providing a rough example of some runtimes in the experiments, which would be useful for readers looking to apply the method. These suggestions are clear and actionable, offering specific ways to enhance the motivation and applicability of the method. By addressing these points, the authors can improve the clarity and impact of their work. Therefore, the comment is 4, as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly recommends that the authors provide greater detail on the EEG token quantization process, particularly regarding the ambiguity in interpreting Figure 3. It suggests that the authors should elucidate this procedure and understand the role of the spatial arrangement of EEG sensors in the process. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be done to improve their draft, which is to provide more detailed explanations and insights into the procedure. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the ambiguity in interpreting the EEG topography plots and suggesting that the authors elucidate the procedure in greater detail. The comment further specifies the need to understand the role of the spatial arrangement of EEG sensors in the process. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 3 presents ambiguity in interpreting EEG topography plots for both input and output during the EEG token quantization process. The reviewer suggests that the authors elucidate this procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. While the comment identifies a potential issue with the clarity of the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to elucidate the procedure is a logical step to address the ambiguity, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that it presents ambiguity in interpreting EEG topography plots for both input and output during the EEG token quantization process. It provides a clear and actionable suggestion for the authors to elucidate this procedure in greater detail, particularly regarding the role of the spatial arrangement of EEG sensors. This feedback is valuable as it guides the authors on how to improve the clarity and interpretability of their results, which is crucial for enhancing the overall understanding of the paper. However, the comment could be more helpful if it offered specific suggestions or examples of how to elucidate the procedure or what aspects of the spatial arrangement are relevant. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement and provides a clear path forward. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not address the problem in a direct way. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the complexity of checking on the Witness oracle, specifically mentioning that it is \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to identify the exact section being discussed. The comment is specific in pointing out the issue with the approach but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors are leveraging the complexity of checking on the Witness oracle, which is polynomial time in the tabular case, but it does not address the problem in a direct way. However, the comment lacks specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach taken by the authors, specifically regarding the complexity of checking on the Witness oracle, which is polynomial time in the tabular case. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed insights, the comment does not effectively support the authors in enhancing their draft. Therefore, it is rated as 2, as it provides some insight but lacks the depth and specificity needed for meaningful improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their code completion task with existing commercial applications like Copilot. It provides a specific example of a stateoftheart code completion system and recommends testing on a smaller subset of the RepoEval dataset. This feedback is clear and direct, giving the authors a concrete action to take in improving their draft. The suggestion is specific and provides a clear path for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their code completion task with existing commercial applications like Copilot. It provides a specific suggestion for a baseline to include in the comparison, which is helpful. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a comparison with stateoftheart code completion systems, but without explicit grounding, it is challenging for the authors to fully understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their code completion task with existing commercial applications like Copilot. This is a logical suggestion based on the current state of the field, as it provides a benchmark for evaluating the performance of the proposed method. However, the comment does not provide specific examples or references to support the claim that Copilot is a stateoftheart code completion system or that it is essential to include it in the comparison. This makes the claim 3, as it lacks detailed justification or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include additional baselines in their code completion task. It specifically recommends comparing with existing commercial applications like Copilot, which is a stateoftheart code completion system. This feedback is valuable as it guides the authors to a relevant and meaningful comparison that can enhance the comprehensiveness of their evaluation. The suggestion is specific and provides a concrete direction for improvement, making it 4. However, it could be more helpful if it included additional details on how to integrate this comparison into the paper or what specific aspects of the comparison would be most informative. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB) and suggests that the authors should clarify the criteria behind this selection. It also implies that other tasks or datasets might provide different insights, which could be valuable information for the authors to consider. However, the comment does not explicitly instruct the authors to provide this clarification or explore other tasks or datasets. The action is implicit and somewhat vague, as the authors need to infer that they should address the generalizability issue and explore alternative benchmarks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB), which is a specific part of the paper. This provides full grounding, as the authors can accurately identify the section being addressed. The comment also specifies the issue by questioning the generalizability of the evaluation and suggesting that the authors clarify the criteria behind the selection and explore other tasks or datasets for different insights. This level of detail makes the comment specific, as it clearly outlines what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and explore other tasks or datasets for different insights. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about generalizability. The suggestion to explore other tasks or datasets is a logical extension of the concern, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and explore other tasks or datasets for different insights. This feedback is constructive as it points out a potential limitation in the evaluation process and encourages the authors to consider broader aspects of their work. However, the comment could be more helpful if it provided specific suggestions or examples of alternative tasks or datasets that could be evaluated. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the performance of the model and baselines on test samples from the observational (in) distribution. It suggests that the authors should demonstrate the performance of their model and baselines on test samples from the observational distribution. This feedback is explicit and provides a clear action for the authors to take, which is to include this performance analysis in their draft. The suggestion is concrete, as it specifies what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of the performance of the model and baselines on test samples from the observational (in) distribution, specifically in the context of the shiftedMNIST dataset. It questions why shift=0 is much better than shift~ N ( 0 , \u03c3 2 ) , given that both cases incorporate a domain shift. The comment is fully grounded as it explicitly mentions the shiftedMNIST dataset and the specific issue regarding the performance on test samples from the observational distribution. It is also specific because it clearly identifies the need for the authors to demonstrate the performance of their model and baselines on these samples. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the model and baselines on test samples from the observational (in) distribution, specifically in the context of the shiftedMNIST dataset. It questions why shift=0 is much better than shift~ N ( 0 , \u03c3 2 ) , given that both cases incorporate a domain shift. The comment suggests that the authors should demonstrate the performance of their model and baselines on test samples from the observational distribution. However, the comment does not provide specific examples or references to support the claim that shift=0 is better or why it should be demonstrated. This lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance of the model and baselines on test samples from the observational (in) distribution, specifically in the context of the shiftedMNIST dataset. It points out that it is not clear why shift=0 is much better than shift~ N ( 0 , \u03c3 2 ) , given that both cases incorporate a domain shift. The comment suggests that the authors should demonstrate the performance of their model and baselines on test samples from the observational distribution. This feedback is clear and actionable, as it provides a specific area for the authors to address and improve their draft by including this performance analysis. However, the comment could be more helpful if it offered additional guidance or examples on how to conduct this analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima produced by Algorithm 1, including the approximation ratio under certain assumptions. While the comment implies that this analysis would be beneficial, it does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but lack detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis of the quality of local minima produced by the algorithm, including the approximation ratio under certain assumptions. This provides clear guidance on what the authors should focus on improving in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima produced by Algorithm 1, including the approximation ratio under certain assumptions. However, the comment does not provide specific examples or references to support the claim that this analysis is necessary or beneficial. The suggestion is based on a logical assumption that the quality of local minima is an important aspect to consider, but without detailed reasoning or evidence, it remains somewhat vague. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the analysis of Algorithm 1 should include an examination of the quality of local minima, specifically the approximation ratio under certain assumptions. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis and potentially improve the robustness of their findings. However, the comment could be more helpful if it included additional details or examples to guide the authors in conducting this analysis. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It specifically asks for clarification on how this redundancy is built into these algorithms. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this question or what specific details they should include to clarify the implementation. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms, specifically referring to a sentence that discusses the robustness of Cans. However, it does not specify which part of the paper this sentence is located in, making it difficult for the authors to pinpoint the exact section being addressed. While the authors can infer that it relates to the algorithms mentioned, the comment lacks full grounding. It is specific in asking for clarification on the implementation of information redundancy, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question seeking clarification on the implementation of information redundancy in the Fill, Propagate, and Decode algorithms. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the implementation of information redundancy in the Fill, Propagate, and Decode algorithms, specifically referring to a sentence that discusses the robustness of Cans. While the comment identifies a gap in the paper\"s explanation, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their explanation. The feedback lacks actionable advice or specific recommendations, leaving the authors with a vague understanding of what needs to be clarified. Therefore, the comment is 2, as it highlights a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of the model\"s design choice involving multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what specific experiments or analyses could be conducted to explore this issue. The action is implicit and vague, as the authors are left to infer that they should conduct additional experiments or analyses to determine the importance of the design choice. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific feature of the model, the use of multiple INs at different speeds in the dynamics predictor, which is a novel aspect of the model. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the importance of this design choice and whether one IN would suffice, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is important or why it might be better to use a single IN. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. This feedback is 3 as it prompts the authors to consider the significance of their design choice and potentially conduct further analysis or experimentation to justify its necessity. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue, such as proposing alternative experiments or analyses. Therefore, the comment is rated as 3, as it identifies a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experimental results that exclude the mixup technique from the proposed method. This action is clear and direct, as it specifies what needs to be done to demonstrate the pure contribution of the proposed method. The comment provides a concrete and actionable suggestion, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results that exclude the mixup technique to demonstrate the pure contribution of their proposed method. This is a logical suggestion based on the information provided in the paper, specifically in Section 4.2, where the mixup technique is mentioned. However, the comment does not provide specific examples or references to support the need for these additional experiments, which could make the claim 3. The authors would need to infer the importance of these additional results, making the comment 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to include additional experimental results that exclude the mixup technique from their proposed method. This is done to demonstrate the pure contribution of the proposed method, which is a valuable piece of feedback. By following this suggestion, the authors can better understand the impact of the mixup technique on their results and potentially improve the robustness of their findings. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the object detectionbased attention process, specifically asking whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment does not explicitly instruct the authors to clarify these points, the questions are clear and specific, providing a direct action for the authors to take. The authors can infer that they need to address these questions to provide a clearer explanation of their methodology. Therefore, the comment is 4, as it provides concrete guidance on what needs to be clarified but does not explicitly instruct the authors to do so.", "grounding_specificity_rationale": "The comment raises questions about the object detectionbased attention process, specifically asking whether it is performed on the image or a convolutional feature map, and whether rescaling is done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or experimental setup. The authors can infer that it relates to the sections where these processes are described, but the comment does not provide explicit references. The comment is specific in detailing what needs to be clarified, making it somewhat grounded and specific. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the methodology, such as whether the object detectionbased attention is performed on the image or a convolutional feature map, and whether rescaling is done based on the receptive field. These questions are logical and seek clarification on technical details, but they do not contain any claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the object detectionbased attention process, specifically asking whether it is performed on the image or a convolutional feature map, and whether rescaling is done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their methodology. By addressing this question, the authors can provide a more detailed and accurate explanation of their approach, which could enhance the clarity and understanding of their work. However, the comment could be more helpful if it included suggestions on how to clarify these points or provided examples of how to implement the clarification. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue regarding the methodology, specifically questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes need to be made. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the methodology or experimental setup, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the methodology of the paper, specifically asking for details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the inputoutput mapping. This feedback is 3 as it highlights a potential gap in the paper\"s explanation, prompting the authors to clarify or elaborate on this aspect. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending additional details or references. As a result, while it identifies a potential area for improvement, it does not fully support the authors in enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks for clarification about the experiment setup in Section 3.3, specifically regarding data augmentation methods, learning rate, and other relevant details. This request provides a clear and direct action for the authors to take, as it specifies what information needs to be included or clarified in their draft. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the experiment setup, including data augmentation methods and learning rate. This provides clear guidance on what aspects of the paper require clarification or elaboration. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically regarding data augmentation methods and learning rate. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that requires clarification, namely the experiment setup in Section 3.3. It prompts the authors to provide details on data augmentation methods, learning rate, and other relevant aspects. However, the comment lacks depth and does not offer suggestions on how to improve the clarity or presentation of this information. While it points out a gap in the paper, it does not provide actionable guidance or specific examples of how to enhance the experiment setup. Therefore, the comment is 3, as it highlights an area for improvement but lacks comprehensive feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about potential errors in the initial calibration steps of the algorithm, which might explain the speed disparities observed between the RSPs and FDs. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to investigate and correct any potential errors. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section III\" of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about potential errors in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. This provides clear guidance on what the authors need to investigate and address in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there might be an error in the initial calibration steps of the algorithm, which could explain the speed disparities observed between the RSPs and FDs. However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for the authors to revisit the original algorithm described in Section III of the \"Recognition and Velocity Computation of Large Moving Objects in Images\" paper. It raises a concern about potential errors in the initial calibration steps (steps 1 & 2) that might explain the speed disparities observed between the RSPs and FDs. This feedback is actionable and provides a clear direction for the authors to investigate and potentially correct any issues in their algorithm. However, the comment could be more helpful if it offered suggestions on how to verify or address these potential errors. Overall, the comment is 4 as it directs the authors to a specific area for improvement but lacks detailed guidance on how to proceed."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve their work based on this observation. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment discusses the comparison between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or discussion. The authors may infer that it relates to the comparison of methods or results, but this inference is not explicit. The comment lacks specificity in detailing what aspects of the comparison are arguable or why it is not more significant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the critique or address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the similarity between artificial networks trained using ASAP and biological networks, suggesting that this similarity is arguable and not necessarily more significant than other techniques like backpropagation. However, it does not provide any specific evidence, examples, or reasoning to support this claim. The comment lacks actionable feedback or suggestions for the authors to address this issue or improve their work. As a result, the comment is not helpful, as it does not offer any guidance or insights that could aid the authors in enhancing their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the closeness of the numbers when comparing the proposed method with baselines and suggests that the authors might have performed a statistical significance test. However, the comment does not explicitly instruct the authors to conduct a statistical significance test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform a statistical significance test but are not given specific instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, it does not specify which part of the paper this comparison is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to perform a statistical significance test, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that a statistical significance test is necessary. Without further elaboration or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. This feedback is 3 as it points out a potential issue that could affect the interpretation of the results. However, the comment lacks specificity and does not provide guidance on how the authors might conduct a statistical significance test or what specific results might be affected. To be more helpful, the comment could include suggestions on how to perform the test or what specific results might be affected by the closeness of the numbers. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a specific area of inquiry, it does not provide explicit guidance or suggestions on how the authors should address this question or what additional information or analysis is needed. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of nonparametric emission distributions on inference tasks. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the discussion of HMMs and their inference tasks. The authors can infer that it relates to the sections where these topics are discussed, but the comment lacks explicit references to specific sections or figures. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference tasks in HMMs. It asks which common inference tasks can be computed exactly or approximately with an NPSPECHMM. While the comment does not contain an explicit claim or suggestion, it poses a logical inquiry that requires the authors to clarify or expand upon their work. The comment does not make a subjective judgment or request for change, fitting the criteria for a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the impact of nonparametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NPSPECHMM. This question is valuable as it prompts the authors to clarify and potentially expand their discussion on the capabilities of their model. However, the comment does not provide specific guidance or suggestions on how the authors might address this question or what additional analysis or discussion is needed. While it identifies an area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results to understand the reasons behind the observed performance. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a deeper analysis but are not given concrete steps on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the analysis, namely the lack of analysis of the underlying reasons for the poor performance of the scope prompting method on GPT3.5turbo. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a specific issue with the analysis but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide more context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the analysis of experimental results is insufficient, noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to conduct a more detailed analysis to understand the reasons behind the observed performance. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider comparing these methods in the remaining 110 datasets. However, the comment does not explicitly instruct the authors to do so, nor does it provide guidance on how to conduct these additional comparisons. The action is implicit and somewhat vague, as the authors can infer that more comparisons are needed but lack specific instructions on how to implement this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It implies that the authors should consider comparing these methods in the remaining 110 datasets. However, the comment does not specify which part of the paper this discussion is related to, such as a specific section or table where the comparison is mentioned. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in questioning the rationale behind the dataset selection, but without explicit grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It does not provide any specific reasoning or evidence to support the claim that these methods should be compared in the remaining 110 datasets. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion and how to address it. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind only considering 10 out of 120 datasets for comparison between batch and greedy methods. It suggests that the authors should consider comparing these methods in the remaining 110 datasets. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct these additional comparisons or what aspects to focus on. The feedback is 3 as it prompts the authors to consider a broader dataset analysis, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation in the introduction about lowrank factorization is unnecessary, given that the main result is about polytopes. It also requests that the implications of the result for lowrank matrix factorization be explicitly discussed. While the comment implies that the authors should remove the unnecessary motivation and discuss the implications, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address both the unnecessary motivation and the implications for lowrank matrix factorization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation section in the introduction, specifically mentioning the lowrank factorization and its relevance to the main result about polytopes. It suggests that the motivation is unnecessary if the result does not have implications for lowrank matrix factorization and requests that these implications be discussed explicitly. However, the comment does not specify which part of the introduction this feedback pertains to, making it weakly grounded. The feedback is specific in its critique and suggestion, providing clear guidance on what the authors should address. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation in the introduction about lowrank factorization is unnecessary given that the main result is about polytopes. It also suggests that the implications of the result for lowrank matrix factorization should be discussed explicitly. The comment provides a logical reasoning by pointing out the relevance of the main result to lowrank matrix factorization, which could be a significant aspect of the work. However, the comment lacks specific examples or references to support the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the introduction, suggesting that the motivation about lowrank factorization is unnecessary given the main result about polytopes. It also provides a constructive suggestion by asking the authors to explicitly discuss the implications of their result for lowrank matrix factorization. This feedback is clear and actionable, as it guides the authors to focus on the most relevant aspects of their work and provides a direction for enhancing the clarity and impact of their introduction. However, the comment could be more helpful if it offered specific examples or guidance on how to discuss the implications effectively. Overall, the comment is 4, as it provides valuable insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to clarify the labels for each dataset in Section 4.1, specifically questioning whether they come from the dataset itself or from other sources. The comment provides a clear and direct action for the authors to take, which is to explicitly state the origin of the labels. This guidance is concrete and actionable, as it gives the authors a specific task to perform to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the origin of the labels for each dataset mentioned in that section. The authors are prompted to clarify whether the labels come from the dataset itself or from other sources, such as the generated datasets or parts of the dataset. This provides clear guidance on what information is missing or needs clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the origin of labels for specific datasets mentioned in Section 4.1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to clarify the origin of the labels for specific datasets mentioned in Section 4.1. This is a specific and important detail that could impact the understanding and reproducibility of the study. By addressing this question, the authors can provide more context and transparency about their dataset, which is beneficial for the clarity and completeness of their work. However, the comment could be more helpful if it suggested how this clarification might affect the analysis or results. Overall, the comment is 4 as it directs the authors to a specific area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the paper is incremental with respect to 31 and describes the adaptation of the existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this incremental nature or improve their work. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions \"with respect to 31,\" indicating that it is referring to a specific work or reference. However, it does not specify which part of the paper this comment pertains to, such as a particular section, figure, or table. This makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment is specific in describing the incremental nature of the paper with respect to the reference 31, detailing the adaptation of the existing architecture for the multiperson case. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its description of the issue. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that the paper is incremental with respect to 31, suggesting that the authors have adapted an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s incremental nature, suggesting that it adapts an existing architecture for the multiperson case, producing identity/tag heatmaps with joint heatmaps. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. Therefore, it is rated as 2, as it points out a potential area for improvement but does not offer actionable steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: the sensitivity of performance and sample efficiency to the lambda parameters, and the lack of understanding of how lambda is computed. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, including 1, 2, and 3, which could help the authors address these issues. However, the comment does not explicitly instruct the authors to use these references or provide specific guidance on how to improve their understanding or explanation. While the feedback is informative, it lacks explicit and concrete actions for the authors to take, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific page numbers and line numbers, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the sensitivity of performance and sample efficiency to lambda parameters and the lack of understanding of how lambda is computed. Additionally, it questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment and provides references to relevant literature. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to the lambda parameters and the computation of lambda. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The comment provides references to relevant literature, such as 1, 2, and 3, which could help the authors address these issues. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claims about the sensitivity of performance and sample efficiency to lambda. While the references provide a basis for further exploration, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas of concern: the sensitivity of performance and sample efficiency to the lambda parameters, and the lack of understanding of how lambda is computed. It also questions the explanation of why ELLA does not increase sample efficiency in a COMBO environment. The reviewer provides references to relevant literature, which could be beneficial for the authors to explore and potentially incorporate into their work. However, the comment lacks detailed guidance or suggestions on how the authors might address these issues or improve their understanding. While it highlights important areas for clarification, the feedback could be more actionable with specific recommendations or examples. Therefore, the comment is 3, as it provides valuable insights but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the specific method used for solving the minmin problem, which is mentioned as an alternating direction method. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify which specific method is being used, provide more details about the method, or explore alternative methods. Without any actionable advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"minmin problem\" and the \"alternating direction method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to solve the minmin problem, providing clear guidance on what needs to be clarified or elaborated upon. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the specific method used to solve the minmin problem, which is mentioned as an alternating direction method. While it identifies a gap in the paper\"s description, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, it is rated as 2, as it highlights a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this comprehensiveness or generalization. The authors are left to infer that they need to expand the scope of their experiments or consider more diverse baselines, but the comment lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not specify which parts of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to address the limitations of the model size and baselines, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, the comment does not provide specific examples or detailed reasoning to support why these limitations are problematic or how they could be addressed. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to improve their work. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. This feedback is 3 as it identifies a specific area for improvement, namely the need for more extensive experimentation. However, the comment lacks detailed guidance on how to achieve this comprehensiveness or generalization, such as suggesting additional experiments or baselines to consider. Without specific actionable steps, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for the authors to elaborate on the fact that Hoeffding\"s bound holds true for any w, given that the samples are drawn independently. It also mentions that stochastic algorithms impose conditioning on the previous iterate, further guaranteeing the validity of Hoeffding inequality. While the comment does not explicitly instruct the authors to elaborate on this point, it clearly indicates what aspect of the paper could be expanded upon. The action is implicit but concrete, as the authors know exactly what information needs to be added to address the comment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 124125,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is elaborating on the fact that Hoeffding\"s bound holds true for any w, given the independence of samples and the conditioning on the previous iterate in stochastic algorithms. This provides clear guidance on what additional explanation or elaboration is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Hoeffding\"s bound holds true for any w, given that the samples are drawn independently and stochastic algorithms impose conditioning on the previous iterate. The comment provides a logical explanation for why this is the case, which is a reasonable claim. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to infer the relevance of this claim to their work and how it could be addressed. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, focusing on the explanation of Hoeffding\"s bound and its application in stochastic algorithms. It provides a clear and actionable suggestion for the authors to elaborate on this topic, which could enhance the clarity and depth of their discussion. By offering a specific point for expansion, the comment is 4 as it guides the authors toward improving their draft. However, it could be more helpful if it included additional context or examples to further support the suggestion. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. While the comment implies that the authors should consider incorporating these approaches, it does not provide explicit instructions on how to do so or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should include these approaches in the table. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not specify which part of the paper this table is in or provide any context about the table itself. The authors cannot confidently determine which part of the paper the comment addresses, nor do they know what specific aspects of the table need to be improved. This lack of grounding and specificity makes it difficult for the authors to understand and address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, the comment does not provide any justification or reasoning for why these approaches should be included or how they would improve the table. Without specific examples or explanations, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. This feedback is 3 as it provides a specific suggestion for enhancing the content of the table. However, it lacks detail on why these approaches would be beneficial or how they could be integrated into the table. The comment could be more helpful if it included additional context or reasoning about the potential benefits of these approaches. Overall, the feedback offers a direction for improvement but could be more comprehensive and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, emphasizing that causality is distinct from temporal relationships. This feedback is clear and direct, providing a specific action for the authors to take in their draft. It gives them a clear understanding of what needs to be addressed and how to correct it, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1\" and \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms, noting that causality is different from temporal relationships and suggesting the need for careful usage. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"causality is different from temporal relationship\" and suggests that the authors should use these terms carefully. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by pointing out a potential confusion in terminology regarding \"causal mechanisms\" and \"causality.\" It emphasizes the distinction between causality and temporal relationships, instructing the authors to use these terms carefully. This feedback is valuable as it helps the authors ensure the accuracy and clarity of their terminology, which is crucial for the integrity of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to distinguish between these concepts in the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the strength of the demonstration of capability, specifically regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their demonstration. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence from the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. The reviewer raises a valid concern about the evidence provided, which helps the authors understand what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. While it identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their demonstration. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the results in section 4, stating that they apply only to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or what steps they should consider to expand the scope of their results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a limitation in the results, stating that they apply only to shallow fullyconnected ReLU networks. This provides clear guidance on what aspect of the results needs further exploration or clarification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the results presented in section 4, specifically noting that they are restricted to shallow fullyconnected ReLU networks. This feedback is 3 as it points out a potential scope limitation that the authors should consider. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their results. Without actionable advice or further elaboration, the comment provides only a partial insight into the areas that need improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. While the comment implies that the authors should include results, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide results, but the comment lacks specific guidance on how to present these results or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the discussion of using sequential MCB vs a single MCT layers for the decision head. It is fully grounded as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it requests additional information about what was observed in this discussion, providing clear guidance on what the authors need to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. This feedback is clear and actionable, as it directs the authors to include results that would enhance the discussion and provide more insight into the topic. However, the comment could be more helpful if it offered suggestions on how to present these results or what specific aspects to focus on. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify their choice of distribution sets and consider the impact of selecting a limited number of them. However, the comment lacks concrete details on how to implement these clarifications, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table where this choice is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the choice of distribution sets and their impact, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for clarification or the potential impact of the choice of distribution sets. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it relates to the overall quality of the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area of concern regarding the experimental setup, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it prompts the authors to consider the implications of their choice of distribution sets, but it does not provide actionable steps or detailed suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should showcase their approach using transformerbased (masked) language models instead of the obsolete ngram HMM and RNN models. This action is clear and concrete, as it provides a specific direction for the authors to improve their draft by aligning it with current NLP trends. The comment offers a clear and actionable suggestion, making it 5.", "grounding_specificity_rationale": "The comment addresses the use of perplexity experiments with obsolete language models, specifically mentioning ngram HMM and RNN. It suggests that the authors should showcase their approach using transformerbased (masked) language models to better align with current NLP trends. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the use of perplexity experiments. The comment is also specific because it clearly specifies the need to use transformerbased models to improve alignment with current trends. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the use of perplexity experiments with obsolete language models (ngram HMM and RNN) is outdated and recommends using transformerbased (masked) language models to better align with current NLP trends. The comment provides a logical reasoning for the suggestion, as transformerbased models are more prevalent and effective in the current NLP landscape. However, it lacks specific references or examples to further substantiate the claim, making it 3. The authors would need to conduct additional research or provide specific examples to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the use of perplexity experiments with obsolete language models (ngram HMM and RNN). It suggests that the authors should showcase their approach using transformerbased (masked) language models, which are more aligned with current NLP trends. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the relevance and currency of their work. By following this suggestion, the authors can significantly improve the alignment of their research with contemporary practices in the field. However, the comment could be more helpful if it included additional context or examples to further support the recommendation. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical or toy experiments should be conducted to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result from Kaplan et al. 2020. This feedback provides clear and concrete actions for the authors to take, such as conducting additional experiments and referencing specific work. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment addresses the sufficiency of the experiments, suggesting that more empirical or toy experiments are needed to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result from Kaplan et al. 2020. However, the comment does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, such as additional experiments and references to existing work. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests additional empirical or toy experiments to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. The comment provides a logical reasoning by suggesting that more experiments are needed to support the claims made in the theoretical analysis. However, it lacks specific examples or references to external works that could further substantiate the claim. While the suggestion is reasonable, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the current experimental setup, noting that the experiments are insufficient. It provides a clear and actionable suggestion by recommending additional empirical or toy experiments to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. The comment also references a specific work (Kaplan et al. 2020) for potential citations, which adds depth to the feedback. This constructive criticism empowers the authors to enhance their draft by conducting more comprehensive experiments, thereby improving the paper\"s rigor and credibility. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to clarify the estimation of mu. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the estimation of mu, which is the proportion of missing observations. It raises a question about how mu can be estimated, indicating that the authors need to clarify this aspect. However, the comment does not specify which part of the paper discusses mu or how it is estimated, making it weakly grounded. The authors can infer that it relates to the discussion of mu, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in questioning the estimation of mu, but the lack of grounding makes it difficult for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the estimation of mu, which is the proportion of missing observations. The comment questions the clarity of how mu can be estimated, suggesting that it is not entirely clear. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the estimation of mu, which is the proportion of missing observations. It points out that it is not entirely clear how mu can be estimated, suggesting a potential area for clarification or improvement. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what steps they could take to improve the clarity of their discussion. While it identifies a potential weakness, it lacks actionable feedback, making it 3. The authors are left with a general understanding of the issue but without clear direction on how to resolve it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests a specific method for evaluating the sensitivity of the performance to initialization. It proposes presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, by randomly sampling matrices M^0 and reporting the performance accordingly. The reviewer provides a clear and concrete action, specifying the method and the expected outcome (mean error and variance increases as the quality of initialization decreases). This level of detail and specificity makes the action explicit and actionable, allowing the authors to directly implement the suggested method. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests a specific method for evaluating the sensitivity of the performance to initialization, which is a relevant aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing the method for evaluating sensitivity, including the use of a distance metric and the expected outcome. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests a method for evaluating the sensitivity of performance to initialization, which is a relevant and specific suggestion. However, the comment does not provide any evidence, reasoning, or references to support why this method is necessary or how it would improve the paper. Without additional justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for evaluating the sensitivity of the performance to initialization. It proposes presenting the performance as a function of the distance of initialization M^0 to the groundtruth M^*, by randomly sampling matrices M^0 and reporting the performance accordingly. This method allows for a more nuanced understanding of how the quality of initialization affects the results. The comment is clear and actionable, offering a concrete way for the authors to improve their analysis and presentation. However, it could be more helpful if it included a discussion on why this method is beneficial or how it could be integrated into the paper. Overall, the comment is 4 as it provides a valuable suggestion for enhancing the paper\"s analysis and presentation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the absolute value operation in the definition of the Frobenius norm is unnecessary since tensor entries are real numbers. This observation is explicit and provides a clear action for the authors to take, which is to remove the absolute value operation. The comment is concrete, as it specifies exactly what needs to be changed and how to implement the correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the absolute value operation in the definition of the Frobenius norm, noting that it is unnecessary since tensor entries are real numbers. This provides clear guidance on what needs to be revised. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that aligns with common mathematical knowledge. The reviewer provides a clear explanation of why the absolute value operation is redundant, which is a wellsupported argument. However, the comment could be strengthened by providing a specific reference or example to further substantiate the claim. Therefore, the comment is 4, as it is wellsupported but lacks some additional evidence or references. This aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a minor issue with the definition of the Frobenius norm, specifically noting that the absolute value operation is unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the accuracy and clarity of their definition. By removing the unnecessary absolute value operation, the authors can enhance the precision of their mathematical notation. However, the comment could be more helpful if it explained why this correction is important or provided additional context on the implications of the change. Despite this, the feedback is 4 as it guides the authors toward a straightforward improvement in their draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors consider providing highprobability bounds instead of only bounds in expectation. It implies that using ensemble methods, as demonstrated in the experiments, could be a way to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment explicitly states these actions, it does not provide detailed guidance on how to implement them, such as which specific ensemble methods to use or how to calculate error bars. The authors are given a clear direction but may need to further explore the suggested methods to fully implement the changes. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"highprobability bounds\" and \"ensemble methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the use of ensemble methods to achieve highprobability bounds and adding measures of robustness like error bars or standard deviation to the experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that only bounds in expectation are provided and questions whether highprobability bounds could be obtained. It proposes using ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific references or detailed examples of how ensemble methods or robustness measures have been successfully applied in similar contexts. This makes the claim 3, as the authors would need to explore the suggested methods further to fully understand and implement the changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting that only bounds in expectation are provided, suggesting that highprobability bounds could be more informative. It offers a specific suggestion to use ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with concrete steps to improve their work. By addressing these suggestions, the authors can enhance the robustness and reliability of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point expresses a concern about the paper\"s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. The reviewer\"s excitement is dampened by the realization that the model does not include a diversity term. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a concern about the paper\"s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. However, it does not specify which part of the paper this concern relates to, such as the introduction, methodology, or results sections. The authors might infer that it pertains to the methodology or results, but this is not explicitly stated. The comment is specific in detailing the issue with the lack of explicit diversity enforcement, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper\"s focus on diversity is not reflected in the model, despite the title suggesting otherwise. However, the comment does not provide specific examples or evidence to support this claim, such as detailed comparisons between the title and the model\"s actual implementation. Without additional context or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient evidence to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a significant concern with the paper\"s focus on diversity, as indicated by the title, but the lack of explicit diversity enforcement in the model. This feedback is clear and actionable, as it highlights a critical gap between the paper\"s claims and its actual methodology. By pointing out this inconsistency, the reviewer provides the authors with a clear direction for improvement, namely to ensure that the model\"s diversity is explicitly addressed. However, the comment could be more helpful if it offered suggestions on how to achieve this, such as proposing specific methods or techniques to enforce diversity. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that some experiments are missing, specifically mentioning \"contrastive learning and adversarial learning.\" This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the absence of certain experiments, specifically mentioning \"contrastive learning and adversarial learning.\" However, it does not specify which part of the paper these experiments are supposed to be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning \"contrastive learning and adversarial learning.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence impacts the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks completeness by pointing out the absence of certain experiments, such as contrastive learning and adversarial learning. This feedback is clear and actionable, as it directs the authors to include these experiments to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these experiments effectively. Overall, the comment is 4 as it highlights a critical gap in the paper, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what to include in their comparisons, making it 5. The authors know exactly what changes to make to enhance their work based on the feedback provided.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of FIDs and DinoV2 Frechet Distances, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the use of DinoV2 Frechet Distances in addition to the FID metric for comparisons. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that FIDs are being widely used for evaluation but have clear flaws, and suggests using DinoV2 Frechet Distances instead. However, the comment does not provide specific examples or references to support the claim about the flaws in FIDs or the superiority of DinoV2 Frechet Distances. This lack of detailed evidence or examples makes the claim 3, as the authors would need to independently verify the claims to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of FIDs (Frechet Inception Distances) as a metric for evaluation, noting that there have been clear flaws associated with them and the simplicity of the Inception network. It suggests using DinoV2 Frechet Distances as an alternative, which is a specific and actionable recommendation. This feedback is valuable as it provides the authors with a clear direction for improving their evaluation metrics, enhancing the robustness and reliability of their results. However, the comment could be more helpful if it included further explanation or justification for the superiority of DinoV2 Frechet Distances over FIDs. Overall, the comment is 4 as it offers a clear suggestion for improvement, but it could be more comprehensive with additional context or reasoning."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests an additional experiment where the image is occluded, simulating irregularities in neural/behavioral data and allowing the authors to inspect the model\"s longrange inference capacity. The reviewer provides a clear rationale for why this experiment is important and notes that it is a reasonable addition to the study. The comment also indicates that these experiments should be included in the final version unless the authors have a compelling reason not to. This provides a direct and concrete action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment suggests an additional experiment involving occluding images to simulate irregularities in neural/behavioral data, such as keypoint detection failures. It also mentions the need to inspect the model\"s longrange inference capacity. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental section or a discussion of the model\"s capabilities. The authors can infer that it relates to the experimental design or results, but the comment lacks explicit references to specific parts of the paper. The suggestion is specific, as it provides a clear direction for additional experiments. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests an additional experiment involving occluding images to simulate irregularities in neural/behavioral data. The rationale for this experiment is twofold: (a) to simulate the irregularity often present in such data, and (b) to allow the authors to inspect the model\"s longrange inference capacity. The reviewer acknowledges that these experiments are reasonable and should be included in the final version unless the authors have a compelling reason not to. While the comment provides a clear rationale for the suggested experiment, it lacks specific references or examples to fully substantiate the claim. This makes the claim 3, as it provides a logical basis but could benefit from additional evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an additional experiment involving the occlusion of images to simulate irregularities in neural/behavioral data, such as keypoint detection failures. This experiment is proposed to allow the authors to inspect the model\"s longrange inference capacity, which is a valuable addition to the study. The reviewer acknowledges that these experiments are reasonable and should be included in the final version unless the authors have a compelling reason not to. This feedback is clear and actionable, providing a specific suggestion for enhancing the experimental design and potentially improving the model\"s evaluation. However, it could be more helpful if it included more detailed guidance on how to conduct the experiment or what specific outcomes to expect. Overall, the comment is 4, as it offers a clear direction for enhancing the study\"s experimental rigor and impact."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue in the abstract, noting that the statement \"ensure that with a lowrank feature subspace, a small number of attacked samples, and other mild assumptions\" is unclear. It suggests that the abstract should be more highlevel and that technicalities are not necessary. While the comment points out a specific area of confusion, it does not provide explicit guidance on how to clarify the statement or what aspects of the abstract should be made more highlevel. The action is implicit and somewhat vague, as the authors need to infer that they should simplify the abstract without providing detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which is its unclear nature due to the technicalities mentioned. The comment provides a clear direction for improvement by suggesting that the abstract should be more highlevel and that technicalities are not necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in the abstract is unclear and suggests that the abstract should be more highlevel. The comment provides a rationale by stating that technicalities are not necessary for a highlevel understanding, which supports the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the technicalities that are unclear, which limits the clarity of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the abstract, noting that a statement about ensuring a lowrank feature subspace and other mild assumptions is unclear. It suggests that the abstract should be more highlevel and that technicalities are not necessary. This feedback is clear and actionable, as it provides a specific area for improvement and offers guidance on how to simplify the abstract. By addressing this feedback, the authors can enhance the clarity and accessibility of their work. Therefore, the comment is rated as 4, as it effectively directs the authors to improve the clarity of their abstract without fully addressing all aspects of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be beneficial to include results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, it does not provide explicit guidance on how to incorporate these results or what specific languagerelated tasks should be considered. The comment is vague and lacks concrete details on how to implement the suggested changes, making it 3. The authors can infer that they should explore additional modalities, but the lack of specific guidance on how to do so limits the actionability.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore additional modalities and the importance of OOD performance, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be beneficial to include results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. However, the comment does not provide specific examples or references to support the claim that OOD performance is more relevant for language tasks. The suggestion is somewhat vague and lacks detailed reasoning or evidence, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from including results in other modalities, such as languagerelated tasks, and mentions that people care about outofdistribution (OOD) performance for language tasks. This feedback is 3 as it provides a direction for expanding the scope of the paper\"s results and highlights a potential area of interest for the authors. However, the comment lacks specific guidance on which languagerelated tasks to include or how to measure OOD performance, which limits its usefulness. The authors are given a general direction but not enough detail to fully implement the suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the motivation of the work should be further justified, particularly in the context of fewshot learning. It points out that the paper defines and creates a fewshot situation for graph link prediction but does not consider how to effectively use \"fewshot\" or how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to justify the motivation and consider the use of \"fewshot\" more effectively, but they are not given concrete steps to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fewshot learning\" and \"graph link prediction,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the motivation, noting that the paper does not consider how to effectively use \"fewshot\" and how to guarantee the trained model can be generalized well to new tasks. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, particularly in the context of fewshot learning. It suggests that the paper does not consider how to effectively use \"fewshot\" and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. While the comment identifies a potential issue, it lacks specific examples or references to support the claim. The authors are left to infer the nature of the justification needed, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper\"s motivation, specifically in the context of fewshot learning. It points out that while the paper defines a fewshot situation for graph link prediction, it does not consider how to effectively utilize this concept or how to guarantee the trained model\"s generalizability to new tasks with 0/few training steps. This feedback is clear and actionable, as it directs the authors to address a significant gap in their work. By providing specific areas for improvement, the comment offers valuable guidance that can help the authors enhance the clarity and impact of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved in this part. However, it does not provide specific guidance on how to improve the writing or which ablations are particularly challenging to find. The action is implicit and somewhat vague, as the authors need to infer which sections to focus on and how to improve the writing. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved in this part. However, it does not specify which sections or ablations are problematic, making it difficult for the authors to identify the exact areas needing improvement. The comment lacks specificity and does not provide clear guidance on what needs to be addressed, leaving the authors with a vague understanding of what is required. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some ablations mentioned in previous sections are difficult to locate in the following contents, implying that the writing could be improved. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact issues and how to address them. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s writing, noting that some ablations mentioned in previous sections are difficult to locate in the following contents. This feedback is 3 as it points out a potential area for improvement in terms of clarity and organization. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the writing or locate the ablations. To be more helpful, the comment could include examples of where the ablations are difficult to find or offer tips on how to enhance the clarity of the writing. Therefore, the comment is rated as 3, as it provides a starting point for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think more clearly about it. It also recommends that the online algorithm and robustness be highlighted as novel and interesting, and that the experimental results in the appendix be moved to the main paper. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need to be revised or how to implement these suggestions. The action is explicit but somewhat vague, as the authors know what needs to be done but may not have a clear idea of how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the differential privacy application, suggesting that it is \"halfbaked\" and recommending that the authors think more clearly about it. It also mentions the online algorithm and robustness as novel and interesting, and suggests moving the experimental results from the appendix to the main paper. However, the comment does not specify which part of the paper these elements are discussed in, making it weakly grounded. The authors can infer that the comment pertains to the sections related to differential privacy and the online algorithm, but this inference is not explicit. The comment is specific in detailing what needs to be addressed regarding the differential privacy application and the experimental results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think more clearly about it. It also recommends moving the experimental results from the appendix to the main paper. However, the comment does not provide specific examples or detailed reasoning to support the claim that the application is \"halfbaked\" or why the experimental results should be moved to the main paper. Without additional context or evidence, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a concern about the differential privacy application, suggesting that it is \"halfbaked\" and recommending that the authors think more clearly about it. It also highlights the novelty and interest of the online algorithm and robustness, recommending that the experimental results be moved to the main paper. While the comment provides some insight into areas for improvement, it lacks specific suggestions or guidance on how to enhance the differential privacy application or present the experimental results more effectively. The feedback is 3 as it points out a potential issue but does not offer detailed advice on how to address it, leaving the authors with a general direction to consider."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this comparison or what specific aspects of the multilingual chainofthought could be improved. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not specify which part of the paper this comparison is based on, nor does it provide any details on what aspects of the multilingual chainofthought are incremental or how they compare to the villa chainofthought. Without specific references or detailed information, the authors cannot confidently determine which part of the paper this comment pertains to, nor do they have a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the comparison or how it impacts their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment compares the contribution of multilingual chainofthought to the villa chainofthought, suggesting that the former is incremental. However, it does not provide any specific details or examples to support this claim, nor does it offer suggestions on how the authors might address this comparison or improve their contribution. Without actionable feedback or guidance, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, as it provides a general observation but fails to offer meaningful insights or actionable steps for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation in general would be more appropriate. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details or actions for the authors to take, such as recommending specific changes or providing examples of alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation in general would be more appropriate. However, it does not specify which part of the paper this concern relates to, such as a particular section or methodology description. The authors may have to infer that it pertains to the methodology section, but this inference is not explicit. The comment is specific in its critique of the methodology\"s applicability, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the specificity of the proposed methodology, suggesting that it may not be specific to bimanual manipulation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is tailored to bimanual manipulation or if robotic manipulation in general would be more appropriate. While it identifies a potential issue, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern. Without actionable feedback or detailed examples, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, as it points out a potential weakness but does not offer constructive feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the consistency of UNIFORM\"s advantage over other procedures, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this scenario. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a theoretical explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of UNIFORM\"s advantage over other procedures, specifically mentioning the tables that show UNIFORM\"s performance in the 1shot setting. It also suggests that the authors should provide a theory to explain why the method is not as effective in this scenario. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the results and theory sections. The comment is specific in detailing what needs to be addressed, namely, providing a theory for the method\"s performance in the 1shot setting. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as shown in the tables. It suggests that the authors should provide a theory to explain why the method is not as effective in the 1shot setting. While the comment highlights a potential issue with the method\"s performance, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to provide a theory is a logical step but is not fully supported by the evidence provided. Therefore, the comment is 3, as it identifies a potential issue but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of UNIFORM\"s advantage over other procedures, particularly in the 1shot setting. It highlights that the tables show a lack of clear advantage for UNIFORM in this scenario. The comment suggests that the authors should provide a theory to explain why the method is not as effective in the 1shot setting. This feedback is clear and actionable, as it directs the authors to address a potential weakness in their work by offering a theoretical explanation. However, the comment could be more helpful if it provided additional guidance on how to develop this theory or what aspects of the method might be contributing to its performance issues. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, and whether there is existing linguistic theory that could explain this. It implies that incorporating such theory could strengthen the paper. However, the comment does not explicitly instruct the authors to include this theory or provide specific guidance on how to integrate it. The action is implicit and somewhat vague, as the authors need to infer that they should look for existing linguistic theory and consider incorporating it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 7\" and \"page 8,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it suggests that the authors consider existing linguistic theory to explain why information value is a stronger predictor for dialogue. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider existing linguistic theory to explain why information value is a stronger predictor for dialogue. However, it does not provide specific references or examples of such theories, making it difficult for the authors to understand or address the suggestion. The lack of detailed support or references makes the claim 3, as the authors would need to conduct additional research to find relevant theories themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider existing linguistic theory to explain why information value is a stronger predictor for dialogue. This feedback is 3 as it points out a potential area for improvement by suggesting the inclusion of relevant linguistic theory. However, the comment lacks specific guidance on which theories to consider or how to integrate them into the paper, leaving the authors with a general direction but no detailed actionable steps. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should spend more time discussing the potential benefits of using AutoML approaches, such as extracting hints that can be reused in the design of new network architectures. It implies that the authors should provide more detailed comments on the findings of the AutoML approach, particularly regarding the most significant takeaways from the discovered architecture. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed comments on the findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in its suggestion to discuss the biggest takeaways from the found architecture, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper, suggesting that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. This feedback is 3 as it points out a specific aspect that could enhance the paper\"s value and contribution. However, the comment lacks depth and does not provide specific guidance or examples on how the authors might address this issue. To be more helpful, the comment could include suggestions on what aspects of the findings are most relevant or how the authors might structure their discussion to effectively communicate these insights. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This implies that the authors should clarify or redefine T_a(t) in Section 3.1 to ensure consistency and proper understanding. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the inconsistency. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a discrepancy in the usage and definition of T_a(t) in the paper. It specifies that T_a(t) is used in Section 3.1 but only defined in Section 4. This provides full grounding as the authors can accurately identify the sections being addressed. The comment is also specific because it clearly details the issue with the inconsistency in usage and definition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4. This observation is factual and does not require any supporting evidence or justification. It is a straightforward statement of a potential issue in the paper, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the usage and definition of T_a(t) in the paper. It notes that T_a(t) is used in Section 3.1 but only defined in Section 4, which could lead to confusion for readers. This feedback is clear and actionable, as it highlights a potential inconsistency that the authors should address to improve the clarity and coherence of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the issue, such as recommending the redefinition of T_a(t) in Section 3.1 or clarifying its usage throughout the paper. Overall, the comment is 4 as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests additional clarification on the empirical analysis in Figure 3, specifically asking for an explanation of how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also seeks an explanation of why these adjustments are effective in enhancing the model\"s performance. Additionally, the comment points out that Equations (9) and (10) have large spacing from the preceding text, suggesting that the authors should address this formatting issue. These requests provide clear and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely, the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score and why these adjustments are effective in enhancing the model\"s performance. The mention of Equations (9) and (10) provides additional context, but the main focus is on the empirical analysis in Figure 3. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the empirical analysis in Figure 3 and requests additional clarification. It suggests that the authors provide an explanation of how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The comment also questions the effectiveness of these adjustments and mentions the spacing issue with Equations (9) and (10). While the comment identifies areas for improvement, it does not provide specific examples or detailed reasoning to support the claim that the empirical analysis is confusing. The references provided, such as 1 Liu, Yong, et al., \"Nonstationary transformers: Exploring the stationarity in time series forecasting,\" Advances in Neural Information Processing Systems 35 (2022): 98819893, could potentially provide additional context or support, but they are not explicitly referenced in the comment. Therefore, the claim is 3, as it provides some guidance but lacks detailed justification or specific references.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely, the empirical analysis in Figure 3. It requests additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This feedback is actionable as it provides a clear direction for the authors to enhance the clarity of their analysis. Additionally, the comment points out the spacing issue with Equations (9) and (10), suggesting that the authors should address this formatting issue. Overall, the comment is 4 as it provides specific and actionable feedback that can significantly improve the clarity and presentation of the paper. However, it could be more helpful if it included suggestions on how to improve the explanation or provide more detailed reasoning behind the effectiveness of the adjustments. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the recent related work CoCoOp 1 should be compared in the experiments. It provides a clear and direct action for the authors to take, which is to include CoCoOp in their experiments. This feedback is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"the recent related work CoCoOp 1 is not compared in the experiments,\" which provides full grounding as it clearly identifies the specific part of the paper being addressed\u2014the experiments. It also specifies what needs to be addressed by suggesting that the authors should compare with CoCoOp, which is a recent related work. This level of detail and specificity allows the authors to accurately understand the feedback and make the necessary changes. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp 1 should be compared in the experiments, despite being a CVPR\"22 work that is published after the NeurIPS deadline. The reviewer provides a specific reference to CoCoOp, which is a recent related work, and suggests that it is necessary to include it in the experiments. This claim is supported by the mention of a specific work and its relevance to the field, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples of why CoCoOp is relevant or important to include in the experiments. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by noting that the recent related work CoCoOp 1 is not compared in the experiments, despite being a CVPR\"22 work that is published after the NeurIPS deadline. The reviewer provides a clear and actionable suggestion by recommending that the authors include CoCoOp in their experiments. This feedback is valuable as it highlights a potential oversight and offers a specific direction for improvement, enabling the authors to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it provided additional context or reasoning about why CoCoOp is relevant or important to include. Overall, the comment is 4, as it effectively guides the authors towards a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 could be improved by providing a better representation of the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. It also mentions the need to show where model training is being used to optimize the selection modules. While the comment implies that these improvements should be made, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact modifications required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the figure, such as enhancing the representation of the processing pipeline, including prompt generation, manual checks, demonstration selection, and automatic scoring. Additionally, it suggests showing where model training is being used to optimize the selection modules. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved by providing a better representation of the processing pipeline, including various components such as prompt generation, manual checks, demonstration selection, and automatic scoring. However, the comment does not provide specific examples or detailed reasoning to support why these improvements are necessary or how they would enhance the figure. Without additional context or justification, the claim lacks sufficiency, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting ways to improve Figure 1, which is crucial for illustrating the processing pipeline. It highlights the need for better representation of key components such as prompt generation, manual checks, demonstration selection, and automatic scoring, as well as the inclusion of model training to optimize selection modules. This feedback is clear and detailed, offering the authors a clear path to enhance the clarity and effectiveness of their visual representation. However, the comment could be more helpful if it included specific suggestions on how to improve the figure or examples of how these components could be better integrated. Overall, the comment is 4 as it provides valuable insights for improving the draft, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that abbreviations like \"MoCo\" should not appear in the section header, as a reader might not know what it means. This provides a clear and direct action for the authors to take, which is to avoid using abbreviations in section headers that are not selfexplanatory. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of abbreviations like \"MoCo\" in the section header, suggesting that they should be avoided to prevent confusion for the reader. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that abbreviations like \"MoCo\" should not appear in the section header because a reader might not know what it means. This is a subjective claim as it relies on the assumption that the abbreviation is not selfexplanatory and could cause confusion for the reader. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some reasoning but lacks detailed justification or evidence.", "helpfulness_rationale": "The comment identifies a specific issue with the use of abbreviations like \"MoCo\" in the section header, noting that a reader might not know what it means. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending that abbreviations should be avoided in section headers to prevent confusion. However, the comment could be more helpful if it offered alternative suggestions for how to present the information or provided examples of how to clarify the abbreviation. Overall, the comment is 4 as it guides the authors in addressing a potential source of confusion in their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses concerns about the trivial improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not provide specific guidance or suggestions on how the authors might address these concerns or enhance the novelty of their work. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. As a result, the feedback is 1.", "grounding_specificity_rationale": "The comment critiques the improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not reference specific sections, tables, or figures, and it is not specific about what aspects of the paper need improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment expresses concerns about the trivial improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. While it identifies a potential issue with the paper\"s contribution, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. The feedback is vague and does not provide actionable steps for improvement, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. While the comment points out a potential issue with the performance claims, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their results. The action is implicit and vague, as the authors are left to infer that they need to clarify or substantiate their performance claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance improvements over baselines, noting that they are marginal and mostly within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not specify which part of the paper this analysis is based on, such as a specific section or table where these results are presented. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in detailing the issue with the performance claims, but without clear grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. The comment provides a logical reasoning based on the observed performance metrics, which is supported by the data presented. However, it lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is clear, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the performance claims, noting that the improvements over baselines are marginal and mostly within the error bar range. It highlights that the error range is high, suggesting that the performance differences between some methods are not very significant. This feedback is 3 as it points out a critical area for improvement, namely the need to substantiate the performance claims and ensure that the results are robust. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their results. To be more helpful, the comment could provide examples of how to narrow the error range or suggest additional analyses that could strengthen the performance claims. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative than the previous method, and it questions how to select representative images. While the comment identifies a specific area of improvement, it does not provide explicit guidance or suggestions on how to achieve this diversity or representativeness. The authors are left to infer that they need to find ways to enhance the diversity and representativeness of the evaluation set, but the comment lacks concrete steps or examples to follow. Therefore, the comment is 3, as it points out a specific area for improvement but does not offer detailed guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses the issue of making the new proposed evaluation set more diverse and representative than the previous method, but it does not specify which part of the paper this evaluation set is discussed in. The authors can infer that it relates to the evaluation section, but this inference is not explicit. The comment is specific in questioning how to select representative images, but it lacks grounding as it does not mention a specific section or part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the diversity and representativeness of the new proposed evaluation set compared to the previous method, but it does not provide any specific evidence, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the proposed evaluation set, questioning its diversity and representativeness compared to the previous method. It highlights a lack of clarity on how to select representative images, which is a critical aspect of evaluating the proposed method. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending specific criteria for diversity or suggesting methods for selecting representative images. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it directs the authors\" attention to an important area for improvement but does not offer detailed guidance on how to achieve it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include a background section on the RL framework, specifically mentioning the MDP, trajectories, and policy, to clarify the context. It also suggests providing an overview of the original DPO algorithm to make the modifications in the methods section more distinguishable. These actions are clear and direct, providing the authors with explicit guidance on what needs to be added or clarified. The comment is concrete in its suggestions, making it 5.", "grounding_specificity_rationale": "The comment suggests including a background section on the RL framework and provides specific elements to include, such as the MDP, trajectories, and policy. It also recommends providing an overview of the original DPO algorithm to clarify the modifications in the methods section. This level of detail and specificity allows the authors to accurately identify the parts of the paper that need revision and understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a background section on the RL framework and provide an overview of the original DPO algorithm to clarify the context and distinguish the proposed modifications. While the comment identifies areas that could improve the paper\"s clarity, it does not provide specific examples or references to support the claim that these additions are necessary. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of these suggestions based on their own understanding of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include a background section on the RL framework to clarify the context being considered. This is particularly important as it would help readers understand the basis of the subsequent sections. Additionally, the comment recommends providing an overview of the original DPO algorithm, which would make the modifications proposed in the methods section more distinguishable. These suggestions are specific and would significantly enhance the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it offered additional guidance on how to structure the background section or provided examples of how to present the information. Overall, the feedback is 4, as it directs the authors to improve the clarity of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should clarify this point, provide additional context, or address the relevance of the term. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim, providing a clear direction for the authors to consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it relates to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or why it is important. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it highlights a potential area for clarification but does not offer actionable advice or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the experiments, noting that they are limited to MNIST and a single realworld dataset. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand their experiments. The comment lacks actionable guidance, leaving the authors without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the experiments, noting that they are limited to MNIST and a single realworld dataset. However, it does not specify which part of the paper discusses the experiments or where this limitation is most apparent. The authors may infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in identifying the limitation but lacks grounding, as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited to MNIST and a single realworld dataset, suggesting that the authors should expand their experiments to include more datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are limited to MNIST and a single realworld dataset. This feedback is 3 as it points out a potential area for improvement, suggesting that the authors should consider expanding their experiments to include more datasets. However, the comment lacks specific guidance or suggestions on how to address this limitation, such as which additional datasets might be relevant or how to structure the expansion of the experiments. Without more detailed advice, the authors may find it challenging to fully utilize this feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. It suggests that the kernel height/width remaining the same would result in more parameters. The reviewer agrees that efficiency could be improved due to the quadratic FLOP on the activation side length but requests more details on the parameters. While the comment identifies a potential issue and suggests an area for improvement, it does not provide explicit guidance on how to address this concern or what specific details are needed. The action is implicit and somewhat vague, as the authors can infer that more details on parameters are expected, but they may not know exactly what specific information is required. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"S2D structure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the number of parameters not changing despite the increase in depth, and it suggests that the kernel height/width remaining the same would result in more parameters. The comment also points out the need for more details on parameters and acknowledges the potential for efficiency improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically why the number of parameters does not change despite the increase in depth. The reviewer agrees that efficiency could be improved due to the quadratic FLOP on the activation side length but requests more details on the parameters. While the comment identifies a potential issue and suggests an area for improvement, it lacks specific reasoning or evidence to fully substantiate the claim. The reviewer agrees with the potential for efficiency improvement but does not provide detailed reasoning or examples to support this claim. Therefore, the comment is 3, as it provides a logical basis for the concern but requires additional evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment raises a specific question about the S2D structure, questioning why the number of parameters does not change despite the increase in depth. It points out that if the kernel height/width remains the same, the depth would increase, leading to more parameters. The reviewer acknowledges that efficiency could be improved due to the quadratic FLOP on the activation side length but suggests that more details on the parameters are needed. This feedback is clear and actionable, as it identifies a potential area for improvement and provides a specific suggestion for the authors to address. However, it could be more helpful if it offered additional guidance or examples on how to improve the parameter count or efficiency. Overall, the comment is 4, as it provides valuable insights and actionable advice for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the proposed method and another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. It questions why 10 cannot use these side information. While the comment implies that the authors should consider this possibility, it does not explicitly instruct them to do so or provide concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment compares the proposed method to another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is relevant to, making it weakly grounded. The comment is specific in questioning why 10 cannot use these side information, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is similar in spirit to another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. However, the comment lacks specific reasoning or evidence to support why this is the case, such as detailed comparisons or examples. The claim is based on a comparison to another work, but without further elaboration, it remains vague and difficult for the authors to understand or address. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment highlights a similarity between the proposed method and another approach, suggesting that the method in 10 could also be equipped with scoring causal predictions and interventional data. This observation raises a question about why the method in 10 cannot use these side information. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance their method. The feedback is 3 as it points out a potential limitation, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. It suggests that this could lead to an increasing number of factors and increased computation with more tasks. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest alternative approaches to mitigate it. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider adding a sparsity constraint or exploring other methods to address this concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method, namely the lack of a sparsity constraint in the number of factors used by subsequent tasks. It provides a clear explanation of how this could lead to an increasing number of factors and increased computation with more tasks. However, the comment does not specify which part of the paper discusses the proposed method or the sparsity constraint, making it weakly grounded. The authors can infer that it relates to the method section, but this inference is not explicit. The comment is specific in detailing the issue with the lack of a sparsity constraint and its potential impact, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint in the number of factors used by subsequent tasks, which could lead to an increasing number of factors and increased computation with more tasks. The comment provides a logical reasoning based on the comparison with a factorized model with an IBP prior, suggesting that the proposed method might not be incentivized to use fewer factors. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the implications of this lack of sparsity constraint on the model\"s performance and computational efficiency. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. It explains that this could lead to an increasing number of factors and increased computation with more tasks. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the model\"s efficiency. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional insights or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. While the comment explicitly states what needs to be addressed, it does not provide detailed guidance on how to reiterate this point or what specific aspects should be emphasized. The action is clear but somewhat vague, as it lacks concrete steps on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation, which is the lack of comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not favorable to the authors because they do not comment on why the GPC (benchmark) performs better than BPC (their method). The reviewer suggests that this is due to the use of bandit feedback and not the form of the cost function. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors should comment on this aspect. While the suggestion is logical, the lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides a general suggestion but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should reiterate that the better performance is due to bandit feedback and not the form of the cost function. This feedback is clear and actionable, as it provides a specific area for improvement and offers a clear direction for the authors to enhance their explanation. By addressing this point, the authors can better clarify their results and improve the clarity of their presentation. Therefore, the comment is rated as 4, as it effectively guides the authors towards improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the claim \"ReLU does not work very well in very deep or in convolutional networks\" should be quantified and clarified. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is explicit and provides a clear action for the authors to take, namely to quantify and clarify the claim. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests quantifying and clarifying a claim about ReLUs not working well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides full grounding as it explicitly mentions the AlexNet paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely quantifying and clarifying the claim about ReLUs. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests quantifying and clarifying a claim about ReLUs not working well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides a clear and specific reference to support the claim, making it 4. However, the comment could be strengthened by including additional examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests quantifying and clarifying a claim about ReLUs not working well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is actionable and provides a clear direction for the authors to improve their draft by offering a specific example and suggesting a method to quantify and clarify the claim. However, the comment could be more helpful if it included additional guidance on how to quantify the claim or what specific aspects should be clarified. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, as it specifies what additional experiments are required to improve the evaluation. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include additional experiments, but without grounding, the authors may struggle to identify the exact sections that need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the evaluation section, suggesting that experiments on distributed deployment and a larger model are needed. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work. By addressing these suggestions, the authors can strengthen their evaluation and potentially improve the overall quality of their paper. However, the comment could be more helpful if it included specific guidance on how to conduct these experiments or what aspects to focus on. Despite this, the feedback is 4 as it directs the authors toward meaningful enhancements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the authors should provide a brief discussion on why rooted patterns are important and how they are chosen, or if nonrooted patterns are sufficient. It suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment specifies what needs to be addressed and offers a concrete suggestion on how to implement it, ensuring the authors know exactly how to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"rooted patterns\" and references the concept of \"orbit counting in GSN,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of explanation regarding why rooted patterns are important and how they are chosen. Additionally, it suggests that a brief discussion should be included in the main text or, alternatively, in the supplementary material. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should provide a brief discussion on why rooted patterns are important and how they are chosen, or if nonrooted patterns are sufficient. The comment suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. However, the comment does not provide specific examples or references to support why this discussion is necessary or how it would enhance the paper. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the claim. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a brief discussion on why rooted patterns are important and how they are chosen. It suggests that this discussion should be included in the main text or, alternatively, in the supplementary material. This feedback is clear and actionable, offering the authors a concrete way to enhance the clarity and depth of their work. By addressing this suggestion, the authors can improve the comprehensibility and impact of their paper. Therefore, the comment is rated as 5, as it provides valuable guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide more explanations regarding the consistency between training and inference, which is mentioned in the paper. While the comment implies that more detailed explanations are needed, it does not explicitly instruct the authors to do so or provide specific guidance on what aspects should be elaborated upon. The action is implicit and somewhat vague, as the authors can infer the need for more explanations but may not know exactly how to implement this suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) in the paper where the authors discuss the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is providing more explanations on the consistency between training and inference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper could benefit from more explanations regarding the consistency between training and inference due to the smoothness of neural models. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by suggesting that more explanations are needed regarding the consistency between training and inference, particularly in relation to the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to provide additional context or elaboration on this topic. However, the comment could be more helpful if it offered specific suggestions or examples of what kind of explanations would be beneficial. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue with the hyperparameters, it does not provide explicit guidance on how to address this problem or suggest specific actions to take. The authors are left to infer that they need to consider the availability of the environment or a good OPE method for finetuning, but the comment lacks concrete steps or suggestions on how to implement this. Therefore, the comment is 3, as it provides a direction but lacks detailed guidance.", "grounding_specificity_rationale": "The comment addresses the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or how they are introduced. The authors can infer that it relates to the experimental setup or methodology sections, but this inference is not explicit. The comment is specific in identifying the need for finetuning and the potential dependencies, but it lacks grounding as it does not pinpoint the exact sections or elements being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method for this finetuning. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or improve their methodology. While it points out a potential area for improvement, it does not offer detailed suggestions or examples that could help the authors enhance their draft. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. While the comment implies that an ablation study would be beneficial, it does not explicitly instruct the authors to perform the study or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is necessary and how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful to clarify its necessity. However, it does not specify which part of the paper discusses this encoding, making it weakly grounded. The comment is specific in its request for an ablation study to address the question of the base layer GNN encoding. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. However, the comment does not provide any specific reasoning or evidence to support why this encoding is unclear or unnecessary. It lacks detailed justification or examples, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 2, as it provides a suggestion but lacks sufficient evidence or explanation to fully support the need for an ablation study.", "helpfulness_rationale": "The review comment raises a question about the necessity of the base layer GNN encoding in the proposed method and suggests conducting an ablation study to clarify this. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the ablation study or what aspects to focus on. The suggestion is 3 as it points out a potential weakness in the methodology, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to \"explicitly add the upper bounds of counting and potentially elaborate on empirical runtimes.\" This provides a clear and direct action for the authors to take, specifying what needs to be added or elaborated upon. The comment also suggests a specific area for improvement, namely the computational complexity of counting homomorphisms, which is not adequately discussed in the current draft. This level of detail and specificity makes the comment 5, as it gives the authors a clear path to follow for improving their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L 145,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of computational complexity, suggesting that the authors should add upper bounds and elaborate on empirical runtimes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, despite making brief statements about it. The reviewer suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that the current discussion is insufficient. The suggestion to add upper bounds and discuss empirical runtimes provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification or evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing a more detailed discussion of the computational complexity of counting homomorphisms. It highlights that the current discussion is brief and suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs further development. By addressing this suggestion, the authors can enhance the depth and comprehensiveness of their paper. Therefore, the comment is rated as 4, as it provides valuable guidance for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It identifies specific errors in the text, such as correcting the letter \"f\" to \"g\" in line 108 and removing the extra period in line 115. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question implies that the authors should provide more details or evidence to support their claim of convergence. The feedback is clear and actionable, guiding the authors on what specific corrections and clarifications are needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (line 108 and line 115), allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as correcting the letter \"f\" to \"g\" and removing the extra period, providing clear guidance on what needs to be revised. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured convergence of the networks. This question adds specificity to the feedback, as it prompts the authors to provide additional details or evidence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of three parts: a correction of a typographical error, a suggestion for removing an extra period, and a question about the convergence of networks in the baseline MCL with deep learning. The first two parts are factual statements that do not require verification. The third part is a question seeking clarification, which does not contain a claim or suggestion that requires verification. Therefore, the overall comment is composed of factual statements and a question, making it \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying two typographical errors in the manuscript: the correction of a letter \"f\" to \"g\" in line 108 and the removal of an extra period in line 115. This level of detail is helpful for the authors to correct these errors and improve the clarity of their text. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question prompts the authors to provide more information or evidence regarding the convergence of their networks, which is a critical aspect of their work. Overall, the comment is 4 as it offers clear guidance on correcting typographical errors and encourages the authors to address a potential weakness in their methodology. However, it could be more helpful if it provided additional suggestions or examples for ensuring network convergence. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that the authors should compare their method\"s inference speed to previous topdown and bottomup pose estimation methods. While the action is implicit, it is clear that the authors need to conduct this comparison to provide a comprehensive evaluation of their method. The comment provides a specific direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that the authors should compare their method\"s inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or result. The authors can infer that it relates to the discussion or results section, but this inference is not explicit. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that the authors should compare their method\"s inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not provide specific examples or references to support the claim that inference time is important or how it should be compared. This lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the importance of inference time and how to conduct the comparison themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that the authors should compare their method\"s inference speed to previous topdown and bottomup pose estimation methods. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a relevant comparison to make. By addressing this suggestion, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it included specific guidance on how to conduct the inference time study or which previous methods to compare with. Overall, the comment is 4, as it directs the authors to a meaningful area for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions about the Theorem A.3 proof. The first question asks how the input x has two indices when it is a vector, not a matrix. The second question questions the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. These questions are explicit and provide clear guidance on what the authors need to address in their draft. The authors are directed to revisit the proof and clarify the notation or provide a correction. The feedback is concrete and actionable, allowing the authors to directly address the issues raised. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the notation and the correctness of the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions regarding the Theorem A.3 proof. The first question questions the notation of the input x, suggesting it should be a vector rather than a matrix. The second question challenges the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. These questions are based on logical reasoning and common knowledge of mathematical notation and equations, making the claim 4. However, the comment could be strengthened by providing specific references or examples to support the suggested corrections. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two specific issues in the Theorem A.3 proof. It questions the notation of the input x, suggesting it should be a vector rather than a matrix, and challenges the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d, suggesting it should be d instead. This feedback is clear and actionable, providing the authors with specific points to address in their draft. By correcting these issues, the authors can improve the clarity and accuracy of their proof. However, the comment could be more helpful if it offered suggestions on how to resolve these issues or provided additional context. Overall, the comment is 4, as it directs the authors to specific areas needing attention but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the accuracy of the results and the plausibility of the entities and relationships used in the experiments. It questions the reliability of the beam search results and the percentage of correct entities/relationships. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their results. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3 and 4.4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the concerns regarding the accuracy of the results and the plausibility of the entities and relationships used in the experiments. The reviewer questions the reliability of the beam search results and the percentage of correct entities/relationships, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the accuracy of the results and the plausibility of the entities and relationships used in the experiments. It questions the reliability of the beam search results and the percentage of correct entities/relationships, especially when no ground truth is available. However, the comment lacks specific examples or detailed reasoning to support these concerns, making it difficult for the authors to fully understand and address the issues. The claim is 3, as it points out a potential issue but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the accuracy of the results in sections 4.3 and 4.4, questioning the reliability of the beam search results and the percentage of correct entities/relationships when no ground truth is available. This feedback is 3 as it highlights an important area for improvement, but it lacks depth and actionable suggestions on how the authors might address this issue. The comment points out a potential weakness in the experimental results but does not provide guidance on how to investigate or resolve this concern. Therefore, the comment is rated as 3, as it provides some insight but does not fully support the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the reliance of FedPCL on the selection of pretrained models, which limits its applications. It also notes that the model accuracy is sensitive to these models. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or improve the robustness of their framework. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the reliance of FedPCL on pretrained models and the sensitivity of model accuracy to these models, as demonstrated in Table 4. It also mentions the authors\" efforts to develop a lightweight federated learning framework and integrate pretrained models for federated aggregation. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as a specific section or table. While the authors can infer that it relates to the discussion of pretrained models and their impact on performance, the lack of explicit reference makes it weakly grounded. The comment is specific in detailing the issue of model sensitivity and the authors\" response, but without full grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the performance of FedPCL is heavily reliant on the selection of pretrained models, limiting its applications to more widespread areas. It also notes that the model accuracy is sensitive to the pretrained models, as demonstrated in Table 4. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The mention of \"adequately addressed\" suggests that the authors have attempted to mitigate this limitation, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the performance of FedPCL, which is heavily reliant on the selection of pretrained models, limiting its applications to more widespread areas. It also notes that the model accuracy is sensitive to these models, as demonstrated in Table 4. The comment acknowledges that the authors have addressed this limitation by developing a lightweight federated learning framework and integrating pretrained models for federated aggregation. However, the feedback lacks specific suggestions or guidance on how the authors might further improve the robustness of their framework or address the sensitivity to pretrained models. While it highlights an important issue, the comment could be more helpful with actionable advice or examples. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to include the tentative attention maps in the qualitative figures, in addition to the retrieved and final attention maps. While the comment implies that the authors should consider including these maps, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to include the tentative attention maps, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which is a specific request for additional content. However, it does not specify which figures or sections of the paper should include these maps, making it weakly grounded. The comment is specific in its request for additional content, but without explicit references to the figures or sections, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to include tentative attention maps in the qualitative figures, but it does not provide any justification or reasoning for why this would be beneficial or necessary. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. Without additional context or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to include tentative attention maps in the qualitative figures, in addition to the retrieved and final attention maps. This feedback provides a specific suggestion for enhancing the qualitative figures, which could potentially offer more insights into the attention mechanisms used in the study. However, the comment does not explain why including tentative attention maps would be beneficial or how they could be incorporated into the figures. While it identifies a potential area for improvement, the lack of detailed guidance or explanation limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides a list of minor comments and suggestions for improvement. It explicitly suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide specific guidance on how the authors can improve their draft. The comments are explicit and concrete, allowing the authors to directly address each point. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses several minor points, including the organization of the main contributions, the description of the layerwise attention mechanism, and the referencing of tricks like normalization or feature scaling. While the comment does not explicitly mention specific sections or parts of the paper, it provides clear guidance on how to improve the organization and clarity of the content. The authors can infer that the suggestions relate to sections 2.3 and 2.4, where the layerwise attention mechanism is discussed. However, the comment does not specify which parts of these sections need to be addressed, making it weakly grounded. The suggestions are specific, as they provide clear guidance on how to improve the organization and clarity of the content. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of suggestions for improving the organization and clarity of the paper, such as recommending the separation of contributions and the description of attention mechanisms. These suggestions are based on logical reasoning and common sense, as they aim to enhance the clarity and structure of the paper. However, the comment does not provide specific examples or references to support these suggestions, making it 3. The authors would need to infer the exact changes needed to improve the organization and clarity of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a list of minor suggestions for improving the organization and clarity of the paper. It suggests that the main contributions of introducing two types of attention for deep VAEs should be described in a separate section, followed by a description of the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and actionable, offering the authors specific ways to enhance the structure and clarity of their draft. While the comment does not delve into detailed feedback or provide extensive guidance, it effectively directs the authors\" attention to areas that need improvement, making it 4. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the issue or what specific changes need to be made. The comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that either the reviewer does not understand the figure or that the labels are incorrect. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not contain any claims, opinions, or suggestions that require verification. Instead, it presents a factual observation about the figure, which is descriptive and does not require evidence or justification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, either stating that the reviewer does not understand it or that the labels are incorrect. This feedback is clear and actionable, as it highlights a potential area of confusion or error that the authors need to address. By pointing out this issue, the reviewer provides the authors with a clear direction for improvement, making the comment 4. However, it could be more helpful if it offered suggestions on how to clarify the figure or correct the labels. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of supervised baselines in the experiments, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images. It further recommends including a supervised baseline to provide a comparison with selfsupervised methods. While the comment explicitly states the need for a supervised baseline, it does not provide specific guidance on how to implement this addition or which supervised methods to use. The action is clear but lacks concrete details on execution, making it 3.", "grounding_specificity_rationale": "The comment addresses the absence of supervised baselines in the experiments, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images. It provides a rationale for including a supervised baseline, which is a specific suggestion for improvement. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the comment is specific in its suggestion to include a supervised baseline for comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the absence of supervised baselines is a significant issue, especially given the scale of the datasets used in the experiments. The reviewer provides a logical reasoning by noting that datasets of scale ~100k images are reasonable to assume full annotation in practice, even if it is not always the case. This reasoning supports the claim that including a supervised baseline would be informative. However, the comment could be strengthened by providing specific examples of supervised baselines that could be included or references to similar studies. Overall, the comment is 4 due to its logical reasoning and the suggestion for improvement, but it lacks detailed examples or references, which would make it 5. Therefore, the comment aligns with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines, which is crucial for a comprehensive evaluation of the selfsupervised methods. It provides a logical rationale for including such baselines, noting that datasets of scale ~100k images are reasonable to assume full annotation in practice. This feedback is clear and actionable, as it suggests a specific improvement that would enhance the paper\"s comprehensiveness and utility. However, the comment could be more helpful if it provided examples of supervised baselines or references to similar studies. Overall, the comment is 4 as it guides the authors towards a meaningful enhancement of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and second, it questions why BEAR is missing from the baselines. The first question implies that the authors should provide an explanation for the method\"s benefit in deterministic environments, while the second question suggests that the authors should include BEAR as a baseline for comparison. However, the comment does not provide explicit instructions or concrete guidance on how to address these questions or what specific actions to take. The authors are left to infer the need for clarification and inclusion of BEAR, but without detailed instructions, the feedback remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and second, it questions why BEAR is missing from the baselines. While the comment does not explicitly mention specific parts of the paper, it is clear that it pertains to the discussion of the method\"s performance and the choice of baselines. The authors can infer that it relates to the experimental results or methodology sections, but the comment does not provide explicit references to specific sections. The questions are specific in that they seek clarification on the method\"s benefit and the inclusion of BEAR as a baseline. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: first, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and second, it asks why BEAR is missing from the baselines. The comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address these concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two important questions that could help the authors improve their draft. First, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This feedback encourages the authors to expand their experimental evaluation, which could provide valuable insights into the method\"s applicability. Second, the comment questions why BEAR is missing from the baselines, which could be a significant oversight that affects the comprehensiveness of the comparison. By addressing these points, the authors can enhance the robustness and relevance of their work. However, the comment could be more helpful if it provided specific suggestions on how to evaluate the method on nondeterministic domains or how to include BEAR as a baseline. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, such as the example of introducing a sports celebrity. It suggests that the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. While the comment identifies a potential weakness, it does not provide explicit guidance on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a potential issue with the proposed method\"s ability to detect hallucinations in openended responses, specifically mentioning the example of introducing a sports celebrity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the challenge of identifying shared information for consistency checking in openended responses. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, such as the example of introducing a sports celebrity. The comment provides a specific example to illustrate the challenge, which helps to ground the claim. However, it lacks detailed reasoning or references to support why this might be a significant issue or how it could be addressed. The claim is 3 as it provides a clear example but lacks comprehensive justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method, specifically its ability to detect hallucinations in openended responses. It provides a specific example, \"introduce a sports celebrity to me,\" to illustrate the challenge of identifying shared information for consistency checking. This feedback is 3 as it highlights a critical area for improvement, but it could be more helpful if it offered suggestions on how the authors might address this issue or enhance their method\"s capabilities. Overall, the comment provides a clear direction for the authors to consider, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors verify the conclusion about the label noise and model size on MNIST and CNN. This is an explicit action that provides a clear direction for the authors to take. It specifies what needs to be verified and where to focus, making the comment 5. The authors know exactly what needs to be done to address the issue, which is to conduct the verification on the specified datasets and models. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the theoretical findings are unclear in relation to realworld deep learning models. It specifically mentions the need to verify the conclusion about label noise and model size on MNIST and CNN. This provides a clear and specific direction for the authors to address, making the comment fully grounded. The authors can accurately identify the part of the paper being addressed and understand what needs to be clarified or verified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the theoretical findings are unclear in relation to realworld deep learning models and recommends verifying the conclusion about label noise and model size on MNIST and CNN. However, the comment does not provide specific examples or detailed reasoning to support why this verification is necessary or how it would clarify the theoretical findings. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the significance of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key area of concern regarding the theoretical findings and their relevance to realworld deep learning models. It suggests that the authors verify their conclusions about label noise and model size on specific datasets like MNIST and CNN. This feedback is clear and actionable, providing a specific direction for the authors to improve the clarity and applicability of their theoretical findings. By addressing this suggestion, the authors can enhance the practical relevance and credibility of their work. Therefore, the comment is rated as 5, as it offers a clear and actionable way for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part acknowledges the paper\"s good organization and writing, which is not actionable. The second part identifies specific weaknesses and suggestions for improvement. It suggests drawing a table to compare different CoT prompting methods across dimensions and questions the assumption about \"questions of all the wrong demonstrations fall into the same frequenterror cluster.\" It also questions the selection criteria in section 4.2 and asks why certain questions and rationales are chosen. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors on how to implement these suggestions. The authors can infer that they need to address these points, but the guidance is not as clear as it could be. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.2\" and \"questions with more than 60 tokens and rationales with more than 5 reasoning steps,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the writing, suggesting the inclusion of a table to compare CoT prompting methods and questioning the assumptions and selection criteria in section 4.2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part is a subjective opinion that the writing is good and most of the content is clear, which is not a claim requiring verification. The second part, however, raises specific questions and concerns about the writing and methodology. It suggests drawing a table to compare different CoT prompting methods and questions the assumptions and selection criteria in section 4.2. While the questions are logical and could be addressed, they do not provide explicit evidence or references to support the claim. Therefore, the comment is 4, as it provides some reasoning but lacks detailed justification or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides a mix of positive and constructive feedback. It acknowledges the paper\"s good organization and writing, which is a positive aspect. However, it also identifies specific areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods and questioning the assumptions and selection criteria in section 4.2. The comment provides clear and actionable suggestions for enhancing the paper, such as drawing a table and clarifying assumptions. However, it could be more helpful if it offered more detailed guidance or examples on how to improve the writing and methodology. Overall, the comment is 4 as it provides valuable feedback that can guide the authors in refining their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their results. The comment lacks concrete suggestions or actions for the authors to take, making it 1. The authors are left without a clear understanding of how to address the identified problem, leaving them without a path forward for improvement.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with weight decay and the observation that cosine similarities for large weight decay strengths are not reported. However, it lacks explicit references to specific sections or figures, which could help the authors pinpoint the exact part of the paper being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the application of weight decay to all layers might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, the comment lacks specific evidence, examples, or references to support this claim. The reviewer mentions that cosine similarities for large weight decay strengths are not reported, but this observation does not provide a logical or empirical basis for the claim. Without further justification or evidence, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. The comment points out that cosine similarities for such large weight decay strengths are not reported, and the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is 3 as it highlights a specific area where the authors might need to investigate further or clarify in their paper. However, the comment lacks detailed guidance or suggestions on how the authors could address this issue or improve their results. To be more helpful, the comment could provide specific recommendations or examples of how to handle this problem or present the data differently. Therefore, the comment is rated as 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific issues with the experimental section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods, and the absence of comparison with other stateoftheart methods that might not rely on gyrostructures. While the comment highlights these areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more interpretive insights and compare their methods with a broader range of stateoftheart techniques. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issues with the related discussion, such as the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparison with other stateoftheart methods. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the related discussion lacks interpretive insights into why the proposed gyrostructures outperform existing methods and that the paper lacks comparison with other stateoftheart methods. The comment provides a logical reasoning by suggesting that the absence of such comparisons makes it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact nature of the comparison that should be made, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper\"s experimental section. It points out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods, suggesting that more detailed explanations are needed. Additionally, the comment notes the absence of comparison with other stateoftheart methods that might not rely on gyrostructures, which could provide a more comprehensive evaluation of the proposed approach. By highlighting these gaps, the comment offers clear and actionable feedback that can help the authors enhance the interpretability and robustness of their results. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues. Overall, the feedback is 4 as it guides the authors towards improving the clarity and comprehensiveness of their experimental analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 5 is difficult to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study focuses only on Englishcentric datasets and recommends extending CATER to other languages in the future. This feedback is clear and provides specific actions for the authors to take, such as adding more details about the baselines and considering the extension to other languages. The comments are explicit and concrete, guiding the authors on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is hard to comprehend and suggesting the need for more details about the two baselines presented. Additionally, it points out the limitation of the study focusing only on Englishcentric datasets and recommends extending CATER to other languages. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests that the authors provide more details about the two baselines presented in the figure. It also points out that the study focuses only on Englishcentric datasets and recommends extending CATER to other languages. While the comment provides a logical reasoning for the need for more details and suggests an extension, it lacks specific examples or references to support the claim fully. The suggestion to extend CATER to other languages is a reasonable recommendation but could be strengthened with more detailed reasoning or evidence. Therefore, the comment is 3, as it provides some support but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend. It provides a clear suggestion for improvement by recommending that the authors provide more details about the two baselines presented in the figure. Additionally, the comment points out a limitation in the study\"s focus on Englishcentric datasets and suggests extending CATER to other languages. This feedback is actionable and provides the authors with a clear direction for enhancing the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions on how to improve the figure or extend CATER to other languages. Overall, the comment is 4, as it guides the authors in addressing a specific weakness and expanding their work\"s scope."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the literature review needs improvement, specifically noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It suggests that the paper should provide a more explicit and comparative analysis of related work. This feedback is clear and direct, giving the authors a specific action to take: to enhance the clarity and comparative analysis of the literature review. The comment provides concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"literature review\" and specifies the issue with it, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly outlines what needs to be improved, such as providing a more explicit and comparative analysis of related work. This level of detail helps the authors understand exactly what aspects of the literature review need attention. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and lacks clarity on the main contribution of the proposed method and its distinction from existing work. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact issues and how to address them. This lack of detailed justification or evidence makes the claim 3, as it provides a general direction but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it lacks clarity on the main contribution of the proposed method and its distinction from existing work. It provides a clear and actionable suggestion for improvement by recommending that the paper should provide a more explicit and comparative analysis of related work. This feedback is valuable as it directs the authors to a specific area for enhancement, offering a clear path for improving the clarity and impact of their literature review. However, the comment could be more helpful if it provided examples of how to achieve this improvement or suggested specific references for comparison. Overall, the comment is 4, as it effectively guides the authors towards enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests eliminating section 3.2, stating that readers are presumed to know about the GumbelSoftmax/Concrete distribution. While the comment implies that the section is redundant, it does not provide explicit guidance on how to eliminate it or what to include instead. The action is implicit and somewhat vague, as the authors need to infer that they should remove the section and possibly restructure the paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests eliminating section 3.2, implying that readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, it does not specify which part of the paper this section is in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestion to eliminate the section, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. However, the comment does not provide any reasoning or evidence to support why this section is unnecessary or redundant. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that section 3.2 can be eliminated because readers are presumed to know about the GumbelSoftmax/Concrete distribution. While this feedback identifies a potential redundancy in the paper, it lacks specific guidance or suggestions on how to improve the content or structure of the paper. The comment does not provide any alternative suggestions or detailed reasoning for why this section is unnecessary, leaving the authors with limited actionable feedback. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides two explicit actions for the authors to take. The first action suggests adding performance metrics on word similarity and sentence translation tasks, as seen in the MUSE paper and others, to enhance the credibility of the framework\"s robustness and effectiveness. The second action recommends including experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which is a minor suggestion. Both actions are clear and provide specific guidance on how the authors can improve their experiments. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as adding performance on word similarity and sentence translation tasks and including experiments with morphologically rich and lowresource languages. This provides detailed guidance on what the authors need to address in their experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two suggestions for improving the paper\"s experiments. The first suggestion is to include performance metrics on word similarity and sentence translation tasks, which is a common practice in the field and could enhance the credibility of the framework\"s robustness and effectiveness. The second suggestion is to include experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which is a minor point. These suggestions are based on common practices and are supported by logical reasoning, making them 4. However, the comment could be strengthened by providing specific references or examples of similar studies that have included these tasks or languages, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides two actionable suggestions for improving the paper\"s experiments. The first suggestion is to include performance metrics on word similarity and sentence translation tasks, which would enhance the credibility of the framework\"s robustness and effectiveness. This is a clear and specific recommendation that could significantly strengthen the paper\"s experimental validation. The second suggestion is to include experiments with morphologically rich languages like Finnish and Hebrew, as well as lowresource languages, which is a minor but relevant point. Both suggestions are constructive and provide the authors with clear directions for enhancing their work. Therefore, the comment is rated as 5, as it offers valuable insights and actionable steps for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of selfsupervised learning on 360 video data with spatial audio. It implies that the authors should provide more insights into why this approach is valuable. However, the comment does not explicitly instruct the authors to include these insights or suggest specific ways to address the question. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and questions the necessity of selfsupervised learning on 360 video data with spatial audio. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area needing attention. The comment is specific in questioning the need for selfsupervised learning on this type of data, but without grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of selfsupervised learning on 360 video data with spatial audio, suggesting that more insights are needed. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is valuable or why more insights are required. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of explanation regarding the necessity of selfsupervised learning on 360 video data with spatial audio. It questions why this approach is valuable and suggests that more insights are needed. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of insights are required. While it identifies a gap in the paper, it lacks actionable advice, making it 3. The authors are given a direction to consider but are left to their own devices in terms of implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and direct action for the authors to take, as it provides a specific step to improve the robustness and reliability of their results. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or result section. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting a method to improve the results, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This is a logical and reasonable suggestion, as it aligns with common practices in statistical analysis to ensure the reliability of results. However, the comment does not provide specific examples or references to support the claim, which could make it more robust. The lack of detailed reasoning or evidence makes the claim 3, as it provides a general suggestion but without extensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a valuable piece of feedback as it highlights a common practice in statistical analysis to ensure the reliability and robustness of results. By averaging over multiple runs, the authors can better assess the variability and confidence in their results. However, the comment could be more helpful if it provided specific guidance on how to implement this suggestion, such as the number of runs to average or the statistical methods to use. Overall, the comment is 4 as it identifies an important aspect for improvement but lacks detailed guidance, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks about the impact of the SR model\"s capacity on the FID, and second, it mentions unexpected artifacts in the proposed pipelining method. While the questions provide some guidance on what aspects to consider, they do not offer explicit instructions or concrete steps for the authors to take. The authors are left to infer that they need to investigate the impact of the SR model\"s capacity on the FID and address any unexpected artifacts in the pipelining method. However, the lack of specific guidance or detailed suggestions makes the action implicit and somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises two questions: first, about the impact of the SR model\"s capacity on the FID, and second, about unexpected artifacts in the proposed pipelining method. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address these issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions regarding the impact of the SR model\"s capacity on the FID and the presence of unexpected artifacts in the proposed pipelining method. These questions are factual statements seeking clarification and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: first, it asks about the impact of the SR model\"s capacity on the FID, and second, it mentions unexpected artifacts in the proposed pipelining method. While these questions are relevant and could lead to valuable insights, they are not accompanied by specific guidance or suggestions on how the authors might address these issues. The comment lacks actionable advice or detailed feedback, leaving the authors with a general understanding of what to investigate but without clear steps to take. Therefore, the comment is 3, as it identifies areas for improvement but does not provide comprehensive guidance. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues: the lack of content in Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It questions whether Proposition B.1 is merely illustrative of the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. Additionally, it points out that the authors\" \"proof\" is missing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should include content in Appendix A and clarify the purpose of Proposition B.1, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Proposition B.1 in Appendix B,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of content in Appendix A and the unclear purpose of Proposition B.1, which is meant to illustrate the classic partitioning principle of Kmeans. Additionally, it points out the missing \"proof.\" This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. It suggests that the proposition may only illustrate the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. However, the comment lacks specific examples or references to support the claim that the \"proof\" is missing. While the comment identifies potential issues, it does not provide detailed reasoning or evidence to fully substantiate the claim, making it 3. The authors would need to infer the exact nature of the missing content or proof, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the appendices of the paper. It points out that Appendix A is left blank, which is a significant oversight, and that the purpose of Proposition B.1 in Appendix B is unclear. The comment also questions whether the proposition is merely illustrative of the classic partitioning principle of Kmeans, which is a wellknown concept in machine learning. Additionally, it notes that the authors\" \"proof\" is missing. This feedback is clear and actionable, as it provides specific areas for improvement and suggests that the authors should include content in Appendix A and clarify the purpose of Proposition B.1. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the appendices or provided examples of how to address these issues. Overall, the comment is 4, as it directs the authors\" attention to critical areas that need attention and provides a starting point for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, as they are explicitly told what types of experiments are needed to improve the draft. The comment is specific in identifying the types of experiments that should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the types of experiments that are missing, but without grounding, the authors may struggle to pinpoint where these experiments should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide any specific examples or references to support the claim, nor does it explain why these experiments are necessary or how they would improve the paper. Without detailed justification or evidence, the claim remains 1, as it lacks the necessary support to guide the authors in addressing the issue.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly informs the authors of specific areas where their work could be strengthened. By highlighting these missing components, the comment provides a clear direction for the authors to enhance the depth and robustness of their experimental evaluation. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or what specific results to expect from them. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors need to conduct a more careful analysis, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through the \"data curation\" process. It also recommends providing more details about the evaluation procedures. While the comment implies that the authors should conduct a more thorough analysis and provide additional information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed model on various benchmarks, specifically mentioning that it demonstrates impressive performance. However, it does not specify which benchmarks are being referred to or which part of the paper discusses these results. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment suggests a need for more detailed analysis, particularly for \"old\" benchmarks, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the model\"s impressive performance on benchmarks might be due to data curation, implying that the data might have been indirectly seen by the model. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s performance on \"old\" benchmarks, suggesting that the data might have been indirectly seen by the model through the \"data curation\" process. This observation is relevant and could prompt the authors to consider whether their model is overfitting or if there are other factors influencing its performance. However, the comment lacks specific guidance or suggestions on how to address this concern, such as recommending additional analyses or experiments to mitigate the issue. While it highlights an important area for consideration, the feedback is 3 as it provides a direction for further investigation but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide comments on the differences between the two sets of evaluation methods in Figure 4 and Figure 5. While the comment implies that the authors should address the differences between the methods, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to clarify the differences, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4 and Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the differences between the two sets of evaluation methods in different OPE methods. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the paper should provide comments on the differences between the two sets of evaluation methods in Figure 4 and Figure 5. However, it does not provide any specific reasoning, examples, or references to support why these differences are important or how they might impact the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper\"s experimental section, noting that the methods used in Figure 4 and Figure 5 are quite different for different OPE methods. It suggests that the authors should provide comments on these differences. While the comment highlights an area that needs clarification, it does not offer specific guidance or suggestions on how the authors might address this issue or what kind of comments would be beneficial. This limits the comment\"s helpfulness, as it provides a general direction but lacks actionable details. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It suggests that the comparison is unfair because it requires two representation models learned for each dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their experimental setup. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the extra complexity and cost of their method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method does not have an advantage over the SOTA without prior information and that the comparison is unfair due to the extra complexity and cost involved. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison of the proposed method with the SOTA is unfair because it requires two representation models learned for each dataset, which adds extra complexity and cost. The reviewer provides a logical reasoning for this claim, explaining that the proposed method does not have an advantage without prior information and that the comparison is unfair due to the additional complexity. However, the comment could be strengthened by providing specific examples or references to support the claim about the extra complexity and cost. Despite this, the reasoning is clear and mostly supports the claim, making it 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It highlights that the comparison is unfair because it requires two representation models learned for each dataset, which adds extra complexity and cost. This feedback is clear and actionable, as it points out a specific weakness in the experimental setup that the authors should consider. By addressing this issue, the authors can improve the fairness and robustness of their comparison. However, the comment could be more helpful if it suggested ways to mitigate the complexity or provided alternative approaches to ensure a fair comparison. Overall, the comment is 4, as it provides valuable insights for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. While the comment implies that the authors should consider including collaborative games in their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experimental setup to include collaborative games. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment does not provide any specific reasoning or evidence to support why collaborative games are important or how they would enhance the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by noting the absence of collaborative games in the experiments. It suggests that including collaborative games would be interesting and could provide valuable insights into how the evaluated methods behave in different settings. This feedback is 3 as it points out a gap in the current experimental design and offers a suggestion for improvement. However, it could be more helpful if it provided specific guidance on how to incorporate collaborative games or what aspects of the methods\" behavior might be particularly interesting to explore in such settings. Overall, the comment offers a direction for enhancing the paper but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. This provides a clear and direct action for the authors to take, which is to include the experimental settings for these figures. The comment is explicit and concrete, giving the authors a straightforward task to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by noting that the experimental settings are missing, which makes the figures difficult to be convincing. This level of detail is specific, as it clearly outlines what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the experimental settings for Figures 1 to 9 are missing, which makes the figures difficult to be convincing. This feedback is clear and actionable, as it directly points out a gap in the presentation of results that could impact the paper\"s credibility. By highlighting this omission, the authors are given a clear direction to improve their draft by including the necessary experimental settings. However, the comment could be more helpful if it provided suggestions on how to present the experimental settings or examples of how other studies have addressed similar issues. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the regularization term appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics and justify their choice. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, specifically mentioning the lack of theoretical support and suggesting the use of other statistics like the median. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to explore alternative statistics, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term appears adhoc and lacks theoretical support, suggesting that other statistics could be used to replace the mean and standard deviation. The reviewer provides a specific suggestion, such as using the median, which is not sensitive to outlier values. However, the comment lacks detailed reasoning or references to support why these statistics are more appropriate or why the current approach is insufficient. The suggestion is 3 as it offers a specific alternative, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, noting that it lacks theoretical support and suggesting alternative statistics like the median that could be used. This feedback is 3 as it points out a specific area for improvement and provides a suggestion for enhancing the theoretical foundation of the regularization. However, the comment could be more helpful if it included specific references or examples of how these alternative statistics could be applied or if it offered guidance on how to integrate them into the regularization process. Overall, the comment provides a direction for improvement but lacks depth and detail, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit actions for the authors to take, making it 5. It instructs the authors to report the average over multiple runs in the experimental section, as the results are very close together and it is difficult to favor one method. Additionally, it suggests a discussion on why the decision boundaries look the way they do in Section 3.1, given that it is a toy dataset. Finally, it asks for clarification on the information contained in Fig. 9 middle and right in Section 3.3. Each of these actions is clear and specific, providing the authors with a detailed roadmap for improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1\" and \"Sec. 3.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific guidance on what needs to be addressed in each section. For instance, it suggests reporting the average over multiple runs in the experimental section and asks for a discussion on the decision boundaries in Section 3.1. Additionally, it inquires about the information in Fig. 9 middle and right in Section 3.3. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of three separate suggestions for improvement, each of which is based on logical reasoning and common sense. The first suggestion to report the average over multiple runs is a straightforward recommendation to enhance the reliability of the results. The second suggestion to discuss why the decision boundaries look as they do in the toy dataset is a request for additional context or explanation, which is a reasonable request for clarity. The third suggestion to clarify the information in Fig. 9 middle and right is also a logical request for more detailed information. Each suggestion is supported by clear reasoning and does not require external references or specific examples, making the claims 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the experimental section, suggesting improvements to enhance the clarity and robustness of the results. It explicitly instructs the authors to report the average over multiple runs, which is a common practice to ensure the reliability of results. Additionally, it recommends a discussion on why the decision boundaries look the way they do in the toy dataset, which could provide additional insights into the model\"s performance. Finally, it asks for clarification on the information in Fig. 9 middle and right, which is a direct request for more detailed information. This feedback is clear and provides the authors with concrete steps to improve their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The reviewer is asking why the metric was found useful in this specific context and what the authors meant by their earlier statement. While the comment implies that the authors should clarify their reasoning, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 8082\" and \"Figure 4 A&B,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating earlier that it was not insightful for discriminating model defenses. The comment clearly specifies what needs to be addressed, which is the rationale behind the use of this metric in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating earlier that it was not insightful for discriminating model defenses. The reviewer is asking for clarification on why the metric was found useful in this specific context. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the claim or the authors\" decision. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the authors\" decision to use the center correlation metric in Figure 4 A&B, despite stating earlier that it was not insightful for discriminating model defenses. This feedback is 3 as it prompts the authors to clarify their reasoning and provide a rationale for their choice. However, the comment could be more helpful if it offered suggestions on how to address the perceived lack of insight or provided additional context to support the use of the metric. Overall, the comment provides a starting point for the authors to consider but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to make this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L240 and L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification regarding the meaning of \"is sufficient\" and the authors\" intention to explain the sum of the \"optimistic\" hoped for rewards being close to the expected actual rewards. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how to address this issue. The comment lacks depth and actionable advice, making it 3. The authors are given a direction to clarify their statement, but without additional context or examples, the feedback remains incomplete. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It specifically questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior, and whether it offers an \"explanation\" for how these nonlinear models attain solutions through optimization. While the comment highlights a potential gap in the paper, it does not provide explicit guidance or suggestions on how the authors might address this issue. The action is implicit and vague, as the authors are left to infer that they need to clarify the scientific insight or provide additional explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the model and formalism, questioning whether it provides a scientific insight over prior approaches. The comment highlights the lack of explanation regarding the model\"s approximation to nonlinear RNN models and the \"explanation\" for how these models attain solutions through optimization. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 is a prototype approximation to nonlinear RNN models with emergent behavior and whether it offers an \"explanation\" for how these nonlinear models attain solutions through optimization. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to support the claim. The reasoning is based on logical questioning, but without detailed evidence or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scientific insight provided by the model and formalism compared to prior taskoptimized approaches. It questions whether the model in Section 2.3 offers a unique or significant contribution, particularly in terms of being a prototype approximation to nonlinear RNN models with emergent behavior. The comment highlights the need for a clearer explanation of how the model provides an \"explanation\" for the nonlinear models\" solutions. While the comment identifies a significant area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential weakness in the paper\"s contribution, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It explicitly asks how the groundtruths are built and why the network parts responsible for each part can predict all keypoints. However, it does not provide specific guidance or suggestions on how the authors should address these questions or what changes they should make to their draft. The comment lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.2 of the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It points out a potential inconsistency in the training process described in Eq. 2 of the supplementary material. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or references leaves the claim 3, as it requires the authors to infer the nature of the inconsistency themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the construction of groundtruths and the network\"s ability to predict all keypoints of the pose. It points out a potential inconsistency in the training process described in Eq. 2 of the supplementary material, questioning how the network parts responsible for each part can predict all keypoints. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and potentially revise their approach. However, the comment could be more helpful if it provided suggestions on how to address the issue or offered alternative approaches. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect of their methodology that needs clarification."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to make the texts in legends and axis labels larger, and to ensure that the captions and legend\"s font size is similar to the text size in Figures 2 and 3. This provides clear and concrete guidance on what needs to be done to improve the draft. The action is direct and specific, allowing the authors to easily implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the beginning of page 6, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the text in legends and axis labels being too small and suggests that the captions and legend\"s font size should be larger and similar to the text size in Figures 2 and 3. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the texts in legends and axis labels should be larger and that the captions and legend\"s font size should be similar to the text size in Figures 2 and 3. However, the comment does not provide any reasoning or evidence to support why these changes are necessary or how they would improve the readability of the figures. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the texts in legends and axis labels should be larger and that the captions and legend\"s font size should be similar to the text size in Figures 2 and 3. This guidance is clear and directly addresses a formatting issue that could improve the readability and clarity of the figures. However, the comment could be more helpful if it included additional suggestions or examples of how to achieve this formatting change. Overall, the feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a specific comparison for the counterfactual experiments, recommending a comparison against Journey TRAK at a particular step of the sampling trajectory. It references a specific figure (Figure 2) from the paper, which provides a clear and concrete action for the authors to take. The comment also specifies what aspect of the comparison should be emphasized, namely the larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This level of detail and specificity makes the action explicit and concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and references a specific comparison against Journey TRAK, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the comparison against Journey TRAK at a particular step of the sampling trajectory, and references a specific figure (Figure 2) that illustrates the effect of removing highscoring images. This provides clear guidance on what needs to be included or improved in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific comparison for the counterfactual experiments, referencing a comparison against Journey TRAK. It provides a reference to a specific figure (Figure 2) that illustrates the effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This provides a clear and specific basis for the claim, making it 4. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the counterfactual experiments by recommending a comparison against Journey TRAK at a particular step of the sampling trajectory. It references a specific figure (Figure 2) that illustrates the effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is clear and actionable, offering the authors a concrete way to enhance their experimental analysis and results. By following this suggestion, the authors can strengthen their paper with a more comprehensive comparison, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the VAD description, suggesting that the current approach of discarding TF bins with a magnitude less than epsilon is not consistent with the definition of a VAD. The reviewer points out that a VAD is typically defined over time and not frequency, and that it should be used to detect the presence of speech rather than just energy. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to revise their VAD description to align with the correct definition, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, which involves discarding TF bins with a magnitude less than epsilon, questioning whether this constitutes a VAD. The comment further explains that a VAD is typically defined over time and should be used to detect the presence of speech, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the VAD description, questioning the approach of discarding TF bins with a magnitude less than epsilon. The reviewer suggests that this approach is not consistent with the definition of a VAD, which is typically defined over time and should detect the presence of speech rather than just energy. The comment provides a logical explanation of why the current approach might be problematic, but it lacks specific references or examples to fully substantiate the claim. While the reasoning is clear, the absence of detailed evidence or external references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the VAD description, pointing out that the current approach of discarding TF bins with a magnitude less than epsilon is not consistent with the definition of a VAD. The reviewer clarifies that a VAD is typically defined over time and should detect the presence of speech, not just energy. This feedback is clear and actionable, as it provides a specific point of confusion and suggests a correction to align with the correct definition. However, the comment could be more helpful if it offered suggestions on how to revise the VAD description or provided examples of how to implement this change. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is explicit and provides concrete guidance on what needs to be added to the discussion section. The authors are given a clear direction on how to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is fully grounded as it explicitly mentions the discussion section and provides specific details on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. This feedback is based on logical reasoning and specific examples, making it 4. However, it could be strengthened by providing references or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the discussion section should include a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed one as in Section 4.2. It provides specific examples of what should be discussed, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S_t vary with time. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their discussion section. By addressing this suggestion, the authors can provide a more comprehensive and insightful analysis of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of their presentation. The comment lacks actionable details, such as recommending specific sections to clarify or suggesting ways to enhance the experimental design. As a result, the authors are left without a clear understanding of what changes are needed to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not specify which parts of the paper are unclear or lack intuition, nor does it provide specific suggestions for improvement. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not provide enough detail to guide the authors in addressing the issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is difficult to follow due to a lack of clear intuition and insufficient experiments. This feedback is valuable as it highlights a critical area for improvement, which can help the authors enhance the clarity and comprehensiveness of their work. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending ways to improve the intuition or structure of the presentation or suggesting additional experiments that could provide more context. While it points out a problem, it does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment explicitly requests additional metrics, it does not provide specific guidance on how to calculate or present these metrics. The action is clear but somewhat vague, as the authors know they need to provide additional metrics but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the training of the student and refinement networks simultaneously and questions the fairness of the comparison. It suggests providing KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses the training of these networks or where the comparison is made, making it weakly grounded. The comment is specific in its request for additional metrics, but without grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. However, the comment does not provide any specific reasoning or evidence to support why the comparison might be unfair or how the metrics would improve the fairness. The request for additional metrics is a logical suggestion but lacks detailed justification or examples, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment identifies a potential issue with the comparison, it lacks specific guidance on how to improve the fairness of the comparison or what additional metrics might be relevant. The feedback is 3 as it points out a potential weakness in the paper\"s methodology but does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they might need to consider scaling the refined vector, but they are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the scaling of the refined region vector in the paper. It points out that the attention weight is in 0, 1 and sums up to 1 for all image regions, suggesting that the refined vector would only scale the most important regions by a factor of two before global pooling. The comment then suggests that having a scaling variable before the attention weight might be beneficial. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this change. The authors are left with a question but without actionable steps to address it. Therefore, the comment is 3, as it prompts the authors to consider an improvement but does not fully guide them in making it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate in the presence of ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ALFRED benchmark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of goal misspecification, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\"s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This feedback is 3 as it highlights a critical area for improvement, but it lacks depth and actionable suggestions. The authors are informed of a potential weakness in their work but are not provided with guidance on how to address it or improve their approach. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. While the comments provide suggestions for analysis and exploration, they do not explicitly instruct the authors on how to conduct these analyses or what specific aspects to focus on. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. However, the comment does not specify which part of the paper these concerns relate to, such as the results section or the discussion. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment provides specific suggestions for analysis, the lack of grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This claim is 3 as it provides a logical reasoning for the authors to investigate the distribution of disparities, but it lacks specific examples or references to support the claim fully. Second, the comment raises a concern about the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. This is a more general observation that does not provide specific evidence or reasoning, making it difficult to fully verify. Overall, the comment is 3 due to the first part, but the second part lacks sufficient support, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises two concerns regarding the improvement of the method over SOTA methods like IGEV and the difficulty of SamplingGaussian to significantly improve frameworks similar to IGEV. It suggests that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This feedback is 3 as it provides a direction for further analysis and suggests a specific area for investigation. However, the comment could be more helpful if it offered more detailed guidance or examples on how to conduct the analysis or what specific aspects to focus on. Overall, the comment is 3, as it provides some insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper could benefit from a deeper investigation into how specific models behave differently when using ReGuide. It explicitly mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides a clear and concrete action for the authors to take, as they are directed to focus on specific models and present relevant data. The comment also offers a specific area for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ModelSpecific Insights,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular area for improvement by recommending a deeper investigation into how specific models behave differently when using ReGuide. The comment specifies the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper could benefit from a deeper investigation into how specific models behave differently when using ReGuide. It provides a specific example of comparing false positive rates (FPR) between models with and without ReGuide. This suggestion is based on a logical reasoning that adding such specific insights could enhance the paper\"s conclusions. However, the comment lacks detailed examples or references to support the claim, making it 3. The authors would need to conduct additional research or analysis to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that a deeper investigation into how specific models behave differently when using ReGuide could add nuance to the conclusions. It provides a specific example of comparing false positive rates (FPR) between models with and without ReGuide, which could enhance the paper\"s analysis. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft. By addressing this suggestion, the authors could strengthen their paper\"s conclusions and provide a more comprehensive understanding of the impact of ReGuide on different models. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus the pretrained language models. It provides a clear and concrete suggestion for the authors to include results using the GCPG model without pretrained initializations. This feedback is direct and provides specific guidance on what needs to be added to the paper to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"results\" and \"GCPG model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of ablation studies to clarify the contribution of the task formulation versus pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations provides a concrete action for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus pretrained language models. The comment suggests including results using the GCPG model without pretrained initializations. While the suggestion is clear, it lacks specific examples or references to support the claim that ablation studies are necessary. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper\"s analysis by pointing out the absence of ablation studies. It highlights that the results do not provide clarity on the contribution of the task formulation versus the use of pretrained language models. The comment is specific and actionable, as it suggests including results using the GCPG model without pretrained initializations to address this issue. This feedback is valuable as it guides the authors on how to enhance the robustness and interpretability of their results, making it 5 for improving the draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any explicit guidance on how to achieve this or what specific aspects of the results should be emphasized. The action is implicit and vague, as the authors are left to infer that they should include ImageNet results but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result, making it weakly grounded. The comment is specific in its suggestion to include ImageNet results, but without grounding, the authors may struggle to identify the exact context in which this suggestion should be applied. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any specific reasoning, examples, or references to support why ImageNet results would be particularly relevant or how they would enhance the method\"s credibility. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including results on ImageNet could make the proposed method more convincing. However, it does not provide any specific guidance on how to achieve this or what aspects of the results should be emphasized. The feedback is vague and lacks actionable advice, leaving the authors without a clear path to improve their draft. As a result, the comment is 2, as it identifies a potential area for enhancement but does not offer detailed or constructive suggestions. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. It suggests that the paper could be more insightful or provide possible solutions. While the comment identifies a gap in the study, it does not explicitly instruct the authors on how to address this issue or what specific aspects to focus on. The feedback is somewhat vague, as it provides a general direction but lacks concrete guidance on how to enhance the contribution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the insufficiency of the contribution, particularly regarding the lack of exploration into leveraging the connection between complementary and model robustness to improve robustness. It highlights that the paper could be more insightful or provide possible solutions. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. The feedback is specific in identifying the need for more insightful findings or solutions, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. The reviewer suggests that the conclusion could be easily and intuitively obtained, and it is expected to see more insightful findings or possible solutions. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the contribution is insufficient. While the reviewer provides a general direction for improvement, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the insufficiency of the contribution, specifically noting that the authors have studied the connection between complementary and model robustness but have not explored how to leverage these characteristics to improve robustness. The reviewer acknowledges that the paper could be the first to study this connection but suggests that the conclusion is easily and intuitively obtained. The comment highlights the need for more insightful findings or possible solutions, which is a valuable insight for the authors to consider. However, the feedback could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is 4 as it directs the authors\" attention to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, it does not provide explicit guidance on how the authors should make this shift or what specific aspects of the representation should be analyzed. The comment implies that the authors should reframe their approach, but it lacks concrete details or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, it does not specify which part of the paper this critique pertains to, such as a particular section or analysis. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique, as it clearly identifies a potential issue with the focus of the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this shift is necessary or how it would improve the paper. Without specific examples or logical reasoning, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the focus of the paper, suggesting that it should shift from evaluating the \"best\" clusters to examining the differences in representation between them. This feedback is 3 as it identifies a potential area for improvement in the paper\"s focus and methodology. However, the comment lacks specificity and does not provide detailed guidance on how the authors should reframe their approach or what specific aspects of the representation should be analyzed. To be more helpful, the comment could include suggestions on how to explore these differences or what specific differences are important to consider. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and actionable details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This provides a clear and direct action for the authors to take, which is to make the necessary change to the caption. The comment is explicit and concrete, as it specifies exactly what needs to be done and how to implement the change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, suggesting that it should be corrected from \"Node Dynamics\" to \"Edge Dynamics.\" This provides clear guidance on what needs to be revised, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual correction regarding the caption of Figure 7, suggesting that it should be changed from \"Node Dynamics\" to \"Edge Dynamics.\" This is a straightforward correction based on the content of the figure, and it does not require any additional justification or evidence. Therefore, the claim is 5, as it is based on a clear and accurate observation. The comment is classified as \"5.\"", "helpfulness_rationale": "The review comment is 5 and specific, as it identifies a clear error in the caption of Figure 7 and provides a direct correction. By specifying that the caption should be changed from \"Node Dynamics\" to \"Edge Dynamics,\" the comment offers a straightforward and impactful suggestion for improvement. This feedback is valuable as it helps the authors ensure the accuracy and clarity of their figures, which is crucial for effective communication in scientific papers. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to clarify the motivation. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it relates to the evaluation or discussion of the DCI framework, but this inference is not explicit. The comment is specific in detailing what needs to be clarified regarding the motivation for considering explicitness(E) and size(S) as extra evaluations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific examples or references to support the claim that the DCI framework already considers these factors. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the traditional DCI framework, suggesting that it may already consider explicitness(E) and size(S) as evaluation factors. It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the motivation for considering these factors as extra evaluations. While it identifies a potential area for improvement, the feedback is 3 as it provides some insight but does not offer actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This is a clear and direct action for the authors to take, providing them with a specific task to address. The comment also highlights the issue of not providing the standard deviation after multiple experiments, which is another actionable point. The feedback is concrete and provides clear guidance on what needs to be done to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section\" of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with not providing the standard deviation after multiple experiments and suggests that the improvement brought by SoRA may be due to random fluctuations. The comment further directs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided in the paper, which may lead to uncertainty about the improvement brought by SoRA compared to the baseline. The reviewer suggests that the improvement could be due to random fluctuations. However, the comment lacks specific examples or references to support the claim that the improvement is limited or that random fluctuations are the cause. Without additional evidence or detailed reasoning, the claim remains 3, as it provides a logical inference but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper\"s experimental section, noting that the standard deviation after multiple experiments is not provided. This omission could lead to uncertainty about the reliability of the results and the extent of the improvement brought by the SoRA method compared to the baseline. The comment suggests that the improvement may be due to random fluctuations, which is a valid concern. By pointing out this gap and recommending clarification, the comment provides actionable feedback that can help the authors improve the transparency and robustness of their experimental results. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to present the standard deviation. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment does not provide specific guidance on how to address these issues or suggest concrete steps for improvement. The authors are left with a general understanding of what needs to be fixed but without clear instructions on how to implement the changes. Therefore, the comment is 3, as it highlights areas for improvement but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. These are clear references to specific parts of the paper, providing full grounding. The comment also specifies what needs to be addressed, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized and identifies specific issues with the layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. However, the comment lacks detailed reasoning or examples to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of specific guidance or references to justify the claims reduces the verifiability of the comment. Therefore, it is rated as 2.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s organization and layout, such as the font size of annotations in Figures 1 and 2 being small, the figures not being drawn explicitly enough, and Table 2 being inserted incorrectly. This feedback is clear and actionable, providing the authors with concrete areas to address and improve. However, the comment could be more helpful if it offered suggestions on how to correct these issues or provided examples of better organization or layout. Despite this, the comment is 4 as it directs the authors\" attention to critical areas for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider whether the types of interventions included in the paper are practical and safe for querying in the real world. While the comment implies that the authors should evaluate the practicality and safety of their interventions, it does not provide specific guidance on how to conduct this evaluation or what aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the types of interventions included in the paper, suggesting that they are reasonable computationally but questioning their practicality and safety for querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to consider the practicality and safety of the interventions, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the types of interventions included in the paper are reasonable computationally but questions their practicality and safety for querying in the real world. However, the comment does not provide specific examples or evidence to support the claim that the interventions are not practical or safe. Without detailed reasoning or references, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the practicality and safety of the interventions discussed in the paper. It suggests that while the interventions may be computationally reasonable, they should also be evaluated for their practicality and safety in realworld querying. This feedback is 3 as it points out an important aspect that the authors should consider, but it lacks specific guidance or examples on how to assess the practicality and safety of the interventions. The comment could be more helpful with additional details or suggestions on how to evaluate these aspects, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the idea that images and their augmentations should be treated separately, suggesting that they could be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what changes they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment questions the idea that images and their augmentations should be treated separately, suggesting they could be interchangeable. However, it does not specify which part of the paper this idea is discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding what aspects of the paper\"s approach or methodology are being questioned. Without clear grounding or detailed feedback, the authors cannot effectively address the concern. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the idea that images and their augmentations should be treated separately, suggesting they could be interchangeable. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the idea that images and their augmentations should be treated separately, suggesting they could be interchangeable. While it identifies a potential issue with the methodology, it lacks specific details or examples to support the claim or provide guidance on how the authors might address this concern. Without actionable feedback or suggestions for improvement, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as 2, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. This feedback is explicit and provides a clear action for the authors to take, namely to conduct separate evaluations of each component. The suggestion is concrete, as it specifies the type of evaluation needed. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the clarity of the proposed method, specifically questioning which component contributes to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or results section where the performance gains are discussed. The authors can infer that it relates to the sections where these components are described, but the comment does not provide exact references. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that it is unclear which component of the proposed method contributes to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. While the comment identifies a potential issue with the clarity of the method\"s contribution, it lacks specific examples or detailed reasoning to substantiate the claim. The suggestion to evaluate separately is a logical step, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically questioning the contribution of each component to the performance gain. It suggests evaluating the generative shape model and the word parsing model separately to better support the claim. This feedback is clear and actionable, providing a specific direction for the authors to improve the clarity and robustness of their work. By addressing this concern, the authors can enhance the transparency and credibility of their results. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to improve the clarity of their explanation. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors might infer that it relates to a specific section or discussion, the lack of explicit grounding makes it challenging to determine the exact area of concern. The comment is specific in its focus on the Lipschitz Hessian assumption, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how the method behaves without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how the method behaves without the Lipschitz Hessian assumption. This is a valid point that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not offer meaningful guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some pieces of the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. It suggests that the authors should provide more clarity by checking the original paper. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the presentation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the presentation of existing methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (12)\" and \"pieces,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the presentation of these methods is vague and can only be understood after checking the original paper. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that some pieces of the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of existing methods, such as equation (12), noting that the presentation is vague and requires checking the original paper for clarity. While it highlights a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might clarify the presentation or improve the understanding of these methods. This limits the usefulness of the feedback, as it does not offer actionable steps for the authors to take to enhance their draft. Therefore, the comment is 3, as it points out a potential issue but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Table 4 is incomplete and should include the results for all four datasets. This provides a clear and direct action for the authors to take, which is to ensure that the table is complete by including the missing results. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the table is incomplete and should include results for all four datasets. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete, stating that it should include results for all four datasets. This is a factual statement that does not require verification or evidence. It is a clear and direct request for the authors to include additional data, which is a straightforward and verifiable comment. Therefore, it aligns with a score of 4, as it provides a clear and logical claim that is supported by the request for additional data.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct and specific task to address in their draft. By highlighting this omission, the comment helps the authors improve the completeness and accuracy of their results presentation. However, it could be more helpful if it suggested how the inclusion of these results might impact the analysis or interpretation of the data. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the technical contribution of the work, stating that the proposed pipeline is incremental and not particularly novel. It suggests that the work seems to be a collection of tricks to improve defense evaluation. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve the novelty of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the work, stating that the proposed pipeline is incremental and not particularly novel. It suggests that the work seems to be a collection of tricks to improve defense evaluation. However, the comment does not specify which part of the paper this critique pertains to, such as the methodology, results, or discussion sections. This lack of grounding makes it difficult for the authors to identify the specific areas needing improvement. The comment is specific in its critique of the novelty and incremental nature of the work, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the technical contribution of the work is incremental and that the proposed pipeline is not particularly novel or impressive. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the technical contribution of the work, stating that the proposed pipeline is incremental and not particularly novel. It suggests that the work seems to be a collection of tricks to improve defense evaluation. However, the comment lacks specificity and does not provide actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the critique or enhance the novelty of their work. As a result, the comment is not helpful, as it does not offer meaningful insights or directions for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the tuplelike structure of triples denoted as $(e_1, r, e_2)$ in line 122. This feedback is clear and direct, providing a specific action for the authors to take. It does not require the authors to infer the action, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of the tuplelike structure of triples denoted as $(e_1, r, e_2)$. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the triples denoted as $(e_1, r, e_2)$ should be presented as tuplelike structures rather than sets. This is a factual observation without any subjective claims or opinions. It does not require verification or evidence, as it is a matter of stylistic preference or clarity. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment provides a specific and actionable suggestion to clarify the presentation of triples denoted as $(e_1, r, e_2)$, indicating that they should be presented as tuplelike structures rather than sets. This feedback is clear and directly addresses a potential issue in the paper, offering a straightforward way for the authors to improve the clarity and consistency of their presentation. However, it could be more helpful if it included an explanation of why this change is important or how it might impact the overall understanding of the paper. Despite this, the comment is 4 as it provides a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the scalability of optimal quantization, noting that it is costly in terms of both the number of data points (N) and the dimensionality (M). It also points out that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. The reviewer suggests that the quantization is a bottleneck for the method, questioning its relevance. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to find a way to mitigate the scalability problem without being given concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the scalability issue of optimal quantization, which is mentioned in the paper. It points out that even with clustering, the quantization process is costly in terms of both the number of data points (N) and the dimensionality (M). The comment also highlights that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. However, it questions whether the quantization is a bottleneck for the method, suggesting that it may lose its relevance. While the comment mentions specific parts of the paper, such as the abstract and introduction, it does not explicitly refer to a particular section or figure. The authors can infer that it relates to the scalability of the method, but the comment lacks full grounding. The specificity is clear as it identifies the scalability issue and its relevance to the paper\"s goals. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, which is mentioned in the paper. It further explains that even with clustering, the quantization process is costly in terms of both the number of data points (N) and the dimensionality (M). The comment also highlights that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. However, it questions whether the quantization is a bottleneck for the method, suggesting that it may lose its relevance. While the comment provides some reasoning and context, it lacks specific examples or references to support the claim fully. This makes the claim 3, as the authors would need to further explore the scalability issue and its implications for the paper\"s goals. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the scalability of optimal quantization, noting that it is costly in terms of both the number of data points (N) and the dimensionality (M). It also points out that the paper aims to speed up variational inference (VI) by fast convergence, which is crucial for big data and big model settings. The comment questions whether the quantization is a bottleneck for the method, suggesting that it may lose its relevance. This feedback is 3 as it highlights a significant limitation of the method and prompts the authors to consider alternative approaches or optimizations. However, the comment could be more helpful if it provided specific suggestions or examples on how to address the scalability issue or improve the method\"s relevance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment implies that the authors should provide a gradient comparison between KL and PCC to address this concern. While the action is implicit, it is concrete as it specifies the type of comparison needed. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing a gradient comparison between KL and PCC. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point challenges the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment is 4 as it offers a logical explanation and an example to support its claim, but it could be strengthened by providing more detailed comparisons or references to existing literature. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It provides a logical explanation by suggesting that the constraint strength of a loss function is defined by its gradient distribution, and offers an example to illustrate this point. The comment is 4 as it highlights a specific area for improvement and provides a clear direction for the authors to address this issue by comparing the gradients of KL and PCC. However, it could be more helpful if it included specific suggestions on how to conduct this comparison or what aspects of the gradient distributions should be examined. Overall, the feedback is actionable and provides valuable insights for enhancing the paper, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests the need for additional measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the possibility of GPI with noise reproducing data similarly well and suggests additional measures to demonstrate this. The comment further specifies the need for a discussion on the suitability of the approach for modeling pattern separation tasks, which is relevant to the paper\"s focus. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate this. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests a discussion on this. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims or suggestions. The lack of detailed evidence or justification makes it difficult for the authors to fully understand and address the points raised. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient support.", "helpfulness_rationale": "The review comment raises several questions and suggestions for improvement. It questions the possibility of GPI with noise added reproducing data similarly well and suggests additional measures to demonstrate this. It also points out the suitability of the approach for modeling pattern separation tasks and recommends a discussion on this. While the comment identifies areas for improvement, it lacks specific guidance or detailed suggestions on how to address these points. The authors are given some direction but would benefit from more detailed feedback to fully understand and implement the changes. Therefore, the comment is 3, as it provides some insight but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that if the authors have the resources, they should conduct a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to perform the comparison or provide guidance on how to execute it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the comparison and understand the context of the \"small learning rate for attention parameters\" benchmark. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not specify which part of the paper this benchmark is discussed in or how it relates to the proposed approach. The authors may have an idea of where this benchmark is mentioned, but the comment lacks explicit references to specific sections or figures, making it weakly grounded. The comment is specific in suggesting a comparison, but without grounding, it is difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. However, it does not provide any reasoning, evidence, or context to support why this comparison would be beneficial or how it would contribute to the paper. Without specific justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a potential comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While this suggestion is 3, it lacks specificity and does not provide detailed guidance on how to conduct the comparison or what aspects should be considered. The authors are left with a general idea of what could be compared but without actionable steps or insights into how this comparison might enhance their work. Therefore, the comment is 3, as it offers a potential direction for improvement but lacks depth and clarity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should reproduce the results of the compared methods using the same settings as the proposed method, specifically mentioning the use of AdamW with cosine lr for training. This action is clear and concrete, as it provides a specific step for the authors to take to ensure a fair comparison. The comment also highlights the importance of using the same settings as the compared methods, which is a logical and actionable suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses a specific issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. It suggests that the direct comparison is unfair and recommends reproducing the results of the compared methods using the same settings as the proposed method. This feedback is fully grounded as it explicitly mentions the comparison of methods and the specific training settings, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the issue with the comparison and provides a solution. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the direct comparison of methods is unfair because the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests reproducing the results of the compared methods using the same settings as the proposed method to ensure fairness. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a solution to address it. However, it lacks specific examples or references to support the claim about the unfairness of the comparison, which could strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of methods in the paper. It points out that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests that this difference in training settings could make the comparison unfair. They recommend reproducing the results of the compared methods using the same settings as the proposed method to ensure a fair comparison. This feedback is clear and actionable, as it provides a specific suggestion for improving the fairness of the comparison. However, it could be more helpful if it included additional guidance on how to reproduce the results or what specific aspects of the results should be compared. Overall, the comment is 4 as it directs the authors to a critical area for improvement and provides a clear path forward."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it suggests an area of interest, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might investigate or address this curiosity, nor is there any suggestion for how to incorporate this information into their draft. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in its curiosity about the performance of a particular method, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric, but it does not contain any claims, opinions, or suggestions that require verification. It is a purely factual statement of interest, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric. While it identifies an area of interest, it does not provide any actionable feedback or suggestions for the authors to improve their draft. The comment lacks depth and does not offer any guidance on how the authors might explore or address this curiosity. As a result, it is not helpful to the authors in terms of improving their work. Therefore, the comment is rated as 1, indicating it is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. It suggests that the plots should be much clearer, which is a direct and explicit action for the authors to take. The comment provides concrete guidance on what needs to be improved, such as increasing the size of the plots, improving color differentiation, and clarifying axis labels. This level of detail and specificity makes the action clear and actionable for the authors. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"plots,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. This provides clear guidance on what needs to be improved. However, the comment does not specify which specific plots are affected, which could be addressed with more detailed references. Despite this, the comment is specific in detailing the issues with the plots. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors. This level of detail and specificity makes the claim 4, as it provides clear reasoning and examples to support the assertion. However, the comment could be strengthened by including references to best practices or examples of welldesigned plots for further justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. By pointing out these problems, the reviewer provides clear and actionable feedback that can help the authors improve the clarity and effectiveness of their experimental results presentation. The comment also explains why these issues are problematic, linking them to the clarity of the paper. This level of detail and specificity makes the feedback 5, as it guides the authors in making significant improvements to their draft. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the performance gains, noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance gains of the different metrics, but it does not specify which metrics are being discussed or which part of the paper these metrics are presented in. This makes it difficult for the authors to identify the exact section of the paper being critiqued. While the comment is specific in terms of the performance gains being less than 1%, it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the performance gains are not very high, with the difference between the baseline and the best approach being less than 1% for most metrics. However, the comment does not provide any supporting evidence, such as specific metrics or examples, to substantiate this claim. Without detailed information or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a concern about the performance gains, noting that the difference between the baseline and the best approach is less than 1% for most metrics. This feedback is specific and identifies a potential issue with the paper\"s results. However, it does not provide any suggestions or guidance on how the authors might address this concern or improve their performance. Without actionable advice or further elaboration, the comment is 3 as it points out a potential weakness but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network. It asks the authors to compare the performance with and without certain types of information, specifically the information about incorrect phrase/corrected phrase and the type of mistake. While the comment implies that the authors should conduct these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific experiments to perform. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of specific information on the performance of the feedback network, specifically regarding the information about incorrect phrase/corrected phrase and the type of mistake. However, it does not specify which part of the paper this information is discussed in, making it weakly grounded. The comment is specific in its inquiry about the performance with and without these types of information, providing a clear direction for the authors to explore. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of specific information on the performance of the feedback network, asking for a comparison between the performance with and without certain types of information. However, it does not provide any evidence, reasoning, or references to support the claim that this information is crucial or how it might affect the network\"s performance. Without such support, the claim is difficult for the authors to address effectively, making it 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the impact of specific information on the performance of the feedback network. It asks the authors to compare the performance with and without certain types of information, specifically the information about incorrect phrase/corrected phrase and the type of mistake. This feedback is 3 as it prompts the authors to conduct a specific analysis that could reveal insights into the effectiveness of their approach. However, the comment could be more helpful if it provided additional guidance or suggested specific metrics or methods for evaluating the performance. Overall, the comment offers a direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. It also provides specific guidance on what needs to be addressed, such as including standard deviations in the table. This feedback is clear and direct, giving the authors a concrete action to take. The comment is 5 as it provides explicit instructions on how to improve the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the table does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. This includes including standard deviations in the table. The comment is specific in detailing what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. However, the comment lacks specific examples or references to support the claim that including standard deviations would enhance the submission. The suggestion to include more extensive experiments is not elaborated, leaving the authors without clear guidance on how to improve the draft. Therefore, the claim is 3, as it provides a general direction but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also provides a clear suggestion for improvement by stating that the submission would be stronger if the experiments were more extensive, including the inclusion of standard deviations. This feedback is actionable and provides the authors with a clear direction for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to incorporate standard deviations or suggested specific areas where more extensive experiments could be conducted. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that this would be beneficial, it does not explicitly instruct the authors to conduct these additional experiments or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the introduction. The authors might infer that it relates to the experimental setup, but this inference is not explicit. The comment is specific in its suggestion to explore additional architectures and tasks, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. However, the comment does not provide any reasoning, evidence, or examples to support why this expansion would be beneficial or how it could enhance the paper. Without specific justification or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. This feedback is 3 as it identifies a potential area for improvement in the paper\"s scope and methodology. However, the comment lacks specific guidance on which additional architectures or tasks to explore or how this expansion could enhance the paper. To be more helpful, the comment could provide examples of other architectures or tasks that could be included or suggest how this expansion might contribute to the paper\"s findings. Therefore, the comment is 3, as it points out a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need to clarify the impact of the mitigation strategies on the overall performance of the model. It suggests that there might be a tradeoff between reducing a particular behavior and maintaining high performance, and questions whether these strategies significantly impair the model\"s utility. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the impact of the mitigation strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies significantly impair the model\"s utility. However, it does not specify which part of the paper discusses these strategies or how they are implemented, making it weakly grounded. The comment is specific in its concern about the tradeoff between reducing a particular behavior and maintaining high performance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a tradeoff between reducing a particular behavior and maintaining high performance. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The suggestion that these strategies might impair the model\"s utility is not substantiated with evidence or references, leaving the authors without a clear path to improve their draft. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation strategies proposed in the paper, specifically questioning their impact on the overall performance of the model. It highlights the tradeoff between reducing a particular behavior and maintaining high performance, which is a critical consideration for the authors to address. The comment suggests that these strategies might significantly impair the model\"s utility, which could deter their adoption. While the comment points out an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to consider the potential impact of their mitigation strategies, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two issues with the results presented in Table 2: the proposed approaches only outperform the baselines in one setup out of three, and there is no consistent trend in the results. It suggests that additional experiments or more indepth analysis are necessary to better justify the claims in the paper. While the comment implies that the authors should conduct additional experiments or analysis, it does not provide specific guidance on which experiments to conduct or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the results, noting that the proposed approaches only outperform the baselines in one setup and that there is no consistent trend in the results. This provides clear guidance on what needs to be addressed, such as conducting additional experiments or more indepth analysis to justify the claims in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods due to the lack of consistent trends and the outperformance of the baselines in only one setup. The reviewer suggests that additional experiments or more indepth analysis are necessary to justify the claims in the paper. While the comment identifies a potential issue with the results, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for additional experiments provides a direction for improvement but does not offer a comprehensive justification for the need for these experiments. Therefore, the comment is 3, as it provides a logical basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. This feedback is clear and actionable, as it highlights a critical area where the authors need to provide more evidence to support their claims. The comment suggests that additional experiments or more indepth analysis are necessary to justify the benefits of the proposed methods. This feedback is valuable as it guides the authors in improving the robustness and credibility of their results, making it 4. However, it could be more helpful if it provided specific suggestions on how to conduct these additional experiments or analysis. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. While the comment implies that a detailed comparison is needed, it does not provide explicit instructions on how to conduct this comparison or which specific aspects should be compared. The action is somewhat implicit, as the authors can infer that they need to include a more detailed comparison, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in its suggestion to include a detailed comparison of time complexity and competitiveness, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on time complexity and competitiveness. This feedback is 3 as it identifies a specific area for improvement that could enhance the paper\"s comprehensiveness and relevance. However, the comment lacks depth and does not provide specific guidance on how to conduct this comparison or which aspects of related work should be compared. To be more helpful, the comment could include examples of relevant works or suggest specific metrics to consider. Therefore, the comment is rated as 3, as it points out a potential area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the method ODA, which is used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the improvement in performance and computation speed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific method, ODA, and its application in solving the MOIP problem. It highlights a gap in the explanation regarding how the presented method improves performance and computation speed compared to using ODA alone. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely, the lack of clarity on the improvement over ODA. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method ODA, used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves performance and computation speed compared to using ODA alone. The comment provides a logical reasoning by pointing out the lack of clarity in the explanation, which is a valid observation. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the exact areas where clarification is needed, which limits the comment\"s verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the method ODA, which is used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves performance and computation speed compared to using ODA alone. This feedback is clear and actionable, as it directs the authors to clarify the improvement in performance and computation speed. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how other methods have improved performance. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the logic behind the comparison of the proposed method with 9 and 16 and the rationale for comparing computational cost with only 9. It suggests that there is no further discussion about this aspect in the paper, leaving the authors with a vague understanding of what needs to be addressed. While the comment identifies specific areas for clarification, it does not provide explicit guidance on how to improve the draft or what specific actions to take. The authors are left with a general sense of what needs to be addressed but without concrete steps to take, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the logic behind the comparison of the proposed method with 9 and 16 and the rationale for comparing computational cost with only 9. It also questions whether the computational cost is a significant contribution to the paper and whether it is a big issue in a practical scenario. However, the comment does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The authors can infer that the questions relate to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing the issues with the comparison and the need for further discussion, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the logic behind the comparison of the proposed method with 9 and 16 and the rationale for comparing computational cost with only 9. It suggests that there is no further discussion about this aspect in the paper, leaving the authors with a vague understanding of what needs to be addressed. However, the comment does not provide specific examples or references to support the claim that the comparison is illogical or lacks depth. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the issue, making the claim 2.", "helpfulness_rationale": "The review comment raises several questions about the logic behind the comparison of the proposed method with 9 and 16 and the rationale for comparing computational cost with only 9. It also questions whether the computational cost is a significant contribution to the paper and whether it is a big issue in a practical scenario. While the comment identifies areas for clarification and suggests that there is no further discussion about these aspects, it does not provide specific guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it prompts the authors to consider and potentially expand their discussion on these topics, but it lacks depth and actionable advice, leaving the authors with a general sense of what needs to be addressed. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to compare the PL condition used in their work with the PL conditions proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This request is explicit and provides a clear action for the authors to take, which is to compare their PL condition with the one in the referenced paper. The comment also specifies where the comparison should be made, namely, with the PL conditions proposed in the referenced work. This level of detail and specificity makes the action concrete, allowing the authors to understand exactly what needs to be done to address the comment. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"PL condition\" and references a specific paper, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This provides clear guidance on which part of the paper the comment pertains to, allowing the authors to accurately identify the section being addressed. The comment is also specific because it asks for a comparison between the PL condition used in the paper and the one proposed in the referenced work. This provides a clear direction for the authors to improve their draft by understanding how their PL condition compares with existing literature. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks for a comparison between the PL condition used in the paper and the one proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This request is clear and specific, as it identifies a particular aspect of the paper that needs further exploration or clarification. However, the comment does not provide any additional context, reasoning, or examples to support why this comparison is necessary or how it might impact the paper. Without further elaboration, the claim is 3, as it suggests a comparison but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with the one proposed in a specific reference, \"Global Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions,\" which is available on arXiv. This feedback is 3 as it prompts the authors to consider the relevance and differences between their PL condition and the one proposed in the referenced work. However, the comment lacks depth and does not provide specific guidance on how to conduct this comparison or what aspects should be emphasized. To be more helpful, the comment could include suggestions on how to approach the comparison or what specific aspects of the PL conditions should be highlighted. Therefore, the comment is rated as 3, as it identifies an area for improvement but lacks detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant gap in the paper\"s analysis, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline. The comment is clear and direct, giving the authors a specific action to take: to include an analysis of the impact of additional parameters and computational effort. This guidance is concrete and actionable, allowing the authors to understand exactly what needs to be addressed to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly mentions \"the impact of adding additional parameters and additional computational effort due to the multistage training and the multiple discriminators,\" which provides full grounding as it clearly identifies the specific part of the paper being addressed. The comment is also specific because it specifies what needs to be addressed, namely the analysis of the impact of additional parameters and computational effort. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This claim is 3 as it identifies a specific area where the paper is lacking, but it does not provide detailed reasoning or examples to fully substantiate the claim. The mention of \"baseline 31, 33, * implies that the authors should compare their work with existing literature, but without specific references or detailed analysis, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis, specifically the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It provides a clear and actionable suggestion for the authors to include this analysis for a fair comparison with the baseline. By highlighting this omission, the comment offers valuable guidance on how the authors can enhance the comprehensiveness and rigor of their work. This feedback is clear and actionable, making it 4 for the authors to improve their draft. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming. It questions whether this trend holds across different model architectures and lacks theoretical evidence. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the analysis. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or theoretical evidence. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, specifically questioning the trend across different model architectures and the absence of theoretical evidence. However, it does not specify which part of the paper this analysis is found in, making it weakly grounded. The comment is specific in its critique, as it identifies a gap in the analysis and suggests the need for more detailed evidence. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, questioning whether this trend holds across different model architectures and lacking theoretical evidence. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It questions whether this trend holds across different model architectures and lacks theoretical evidence. This feedback is 3 as it points out a potential weakness in the analysis, prompting the authors to consider whether their findings are robust and generalizable. However, the comment could be more helpful if it provided suggestions on how to address these concerns or offered guidance on how to strengthen the analysis. Overall, the comment provides a starting point for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their analysis. The questions posed are more of an inquiry than a direct action, leaving the authors without clear direction on how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.2\" and \"L114,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the potential information leakage in AutoAugment\"s policy and the implications of the authors\" conclusion regarding the importance of matching pretraining and target datasets for linear classification. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence makes the claim 3, as it requires the authors to infer the implications and potential solutions on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the potential information leakage in AutoAugment\"s policy, which is obtained by supervised training on ImageNet. It also questions the authors\" conclusion regarding the importance of matching the pretraining dataset with the target dataset for linear classification. The comment provides a logical inquiry that challenges the authors\" assumptions and suggests a potential area for further investigation. However, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their analysis. While it prompts the authors to consider important aspects of their work, the feedback could be more actionable with additional details or recommendations. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a clear and explicit action for the authors to take: \"add more analysis about the multilingual alignment of entity representations\" and suggests that \"it would be better to have visualizations or case studies for different types of languages such as language family.\" Additionally, it raises a specific question about the alignment of entities from lowresourced languages with highresourced ones. The comment is concrete, as it specifies what additional analysis and visualizations are needed, and it provides a clear direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the analysis of entity representations, specifically the alignment of entity representations across different languages. It suggests that the paper lacks a thorough analysis of this aspect and recommends adding more analysis, particularly focusing on multilingual alignment. The comment also suggests including visualizations or case studies for different types of languages, such as language families. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the analysis or discussion sections where entity representations are discussed. The suggestion to include visualizations or case studies provides a clear direction for improvement, making the comment somewhat specific. Therefore, this comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper has weak analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests that the authors should add more analysis and provides specific recommendations, such as including visualizations or case studies for different types of languages. While the comment provides a clear direction for improvement, it lacks detailed reasoning or evidence to fully substantiate the claim that the analysis is weak. The suggestion to include visualizations or case studies is a logical step but could be strengthened with examples or references to support the claim. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the analysis of the alignment of entity representations across different languages. It suggests that the paper lacks a thorough analysis of this aspect, particularly in the context of multilingual alignment. The comment provides a clear and actionable suggestion for the authors to enhance their analysis by adding more detailed examination of multilingual alignment. Additionally, it recommends including visualizations or case studies to illustrate the alignment process for different types of languages, such as language families. This feedback is specific and provides a clear direction for the authors to improve their draft, making it 4. However, it could be more helpful if it included examples or detailed guidance on how to implement these suggestions. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While the action is explicit, it lacks concrete guidance on what specific details should be included or how they should be presented. The authors are aware of the need for more information on attention, but the comment does not provide detailed instructions on how to implement this suggestion. Therefore, the comment is 3, as it identifies a need for additional information but does not specify how to address it.", "grounding_specificity_rationale": "The comment suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in its suggestion to include more details on attention, but without grounding, the authors may struggle to identify the exact sections where this information should be added. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While this feedback acknowledges the need for additional information, it lacks specificity and does not provide guidance on what specific details should be included or how they might enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, as it identifies an area for improvement but does not offer detailed guidance or actionable steps."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out two issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This provides clear and direct actions for the authors to take, such as removing duplicates and ensuring that all publications include their respective venues and years. The feedback is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment identifies specific issues with the references list, such as duplicates and missing publication venues and years. However, it does not specify which references are duplicates or which papers lack publication details, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. While the authors can infer that the references section is being addressed, the comment lacks full grounding due to the lack of specific references or details. It is specific in identifying the issues but not fully grounded, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This feedback is clear and actionable, providing the authors with a straightforward task to address. By correcting these issues, the authors can improve the accuracy and completeness of their reference list, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it offered suggestions on how to avoid duplicates or provided examples of how to include publication venues and years. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning that the model can work well for various image noise types. While the comment implies that the authors should provide results for other types of noise, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their results to include other types of noise. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper\" and \"images corrupted using Gaussian noise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model\"s ability to handle various image noise types. This provides clear guidance on what aspect of the paper needs further clarification or expansion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model\"s ability to handle various image noise types. This is a logical question that seeks clarification on the authors\" rationale. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest why this is a concern. As a result, the comment is considered 1, as it lacks the necessary justification or evidence to support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why only results on images corrupted with Gaussian noise are shown, given the claim that the model can handle various image noise types. This feedback prompts the authors to consider expanding their experimental setup to include other types of noise, which could enhance the robustness and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as which other types of noise to include or how to structure the additional experiments. While it identifies a potential weakness, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a convoluted description of results and suggests that the authors need to simplify their language. It also provides specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and checking for useful communication. The comment includes links to external references, which can guide the authors in addressing the issue. However, while the suggestions are concrete, they do not explicitly instruct the authors to make these changes themselves. The authors are left with a clear direction but without direct instructions on how to implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the convoluted description of results, specifically mentioning the phrase \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" This provides some grounding as it refers to a specific part of the paper, but it does not explicitly mention which section or figure this description is found in. The comment is specific in suggesting that the authors simplify their language and provides references to related work for further context. However, without explicit references to sections or figures, the comment is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the convoluted description of results, suggesting that it could be simplified. It provides a specific example of a convoluted statement and offers suggestions for improvement, such as referencing related work on speakerlistener communication and checking for useful communication. The comment also includes links to external references, which can help the authors understand the context and potential improvements. However, the comment could be strengthened by providing more detailed reasoning or examples of how the convoluted description affects the clarity of the results. Despite this, the overall feedback is 4 due to the provision of specific suggestions and references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the convoluted description of results, providing a clear example of a confusing statement. It suggests simplifying the language and offers a related idea from the literature to guide the authors in improving their communication. The comment also provides references to external works that can help the authors understand the context and potential improvements. However, while the feedback is specific and actionable, it could be more helpful if it included detailed guidance on how to simplify the language or if it pointed out other areas in the paper that might benefit from similar improvements. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a starting point for revision."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add missing details about the division of the dataset into training and test sets, including the numbers involved and the method used for division (e.g., random or other considerations). This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what information needs to be added to improve the draft, ensuring a high level of actionability.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"division to train and test sets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, such as the numbers involved and the method used for division. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the draft lacks detail, namely the division of the dataset into training and test sets. It points out that the numbers and the method used for division are missing, which is crucial information for understanding the experimental setup. By suggesting that these details should be added, the comment provides clear and actionable feedback that can help the authors improve the clarity and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how it could be included. Overall, the feedback is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions that the longtext input could restrict the scalability of the framework. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The action is implicit and vague, as the authors are left to infer that they need to explore alternative approaches or formats for text descriptions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the challenges and potential limitations, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to longtext input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant challenge in the paper, which is the need for human labor in building text descriptions for each task. It also points out the lack of an optimal textual format for policy learning, which varies from task to task and model to model. Additionally, the comment raises a concern about the scalability of the framework due to longtext input. While the comment highlights important issues, it lacks specific suggestions or actionable steps for the authors to address these challenges. The feedback is 3 as it provides insight into potential areas for improvement but does not offer detailed guidance or concrete recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out several issues with the experimental validation, including the consideration of only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also mentions a minor issue regarding the paper\"s positioning with respect to related works. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their experimental setup to include deeper networks and provide more details on the optimization strategy. The suggestion about layer redundancy is specific but does not offer detailed guidance on how to incorporate this into the paper. Therefore, the comment is 3, as it provides some direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment addresses several specific issues with the paper, including the experimental validation, the consideration of only shallow networks, the lack of description of the optimization strategy, and the limited positioning with respect to related works. It also provides a specific reference to a related work on layer redundancy. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that these issues pertain to the experimental section or related work section, but the lack of explicit references makes it difficult to pinpoint the exact location. Despite this, the comment is specific in detailing what needs to be addressed, such as expanding the experimental setup and providing more details on the optimization strategy. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the experimental validation, including the consideration of only shallow networks and the lack of description of the optimization strategy, including the grid search strategy for hyperparameters selection. It also notes a minor issue regarding the paper\"s positioning with respect to related works, mentioning layer redundancy as a relevant concept. While the comment provides specific references to related work, it does not offer detailed reasoning or evidence to fully substantiate the claims about the experimental validation. The references to related work provide some context but do not fully address the concerns raised about the experimental setup and optimization strategy. Therefore, the comment is 3, as it provides some support but lacks comprehensive justification.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically regarding the experimental validation. It points out that only shallow networks (2 or 3 layers) are considered, which may limit the scope of the study. Additionally, the comment notes that the optimization strategy, including the grid search strategy for hyperparameters selection, is not described, which is crucial for replicating the results. The comment also highlights a minor issue with the paper\"s positioning with respect to related works, mentioning layer redundancy as a relevant concept. While the comment provides specific examples and references to related work, it does not offer detailed guidance on how to address these issues or improve the paper. The feedback is 3 as it identifies areas for improvement but lacks comprehensive suggestions for implementation, leaving the authors with a general understanding of what needs to be addressed but without specific steps to take."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they could take to prove new theoretical results. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the claim that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not specify which part of the paper this claim pertains to, such as the methodology, results, or discussion sections. The authors may have to infer that it relates to the theoretical contributions or results sections, but this inference is not explicit. The comment is specific in pointing out the lack of new theoretical results, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or references to existing literature, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment points out a potential issue with the paper\"s theoretical contributions, noting that the use of a novel type of loss in a specific setting does not result in any new theoretical results. This observation is relevant and could prompt the authors to reconsider the novelty of their work or provide a more detailed explanation of how their approach contributes to the field. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the theoretical aspects of their work. While it identifies a potential weakness, it does not offer actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more evidence. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. However, the comment does not specify which part of the paper this hypothesis relates to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact area needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point presents a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, suggesting that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion to provide more evidence is a request for additional information, which is not inherently verifiable. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment identifies a potential area for exploration and suggests a hypothesis, it lacks specific guidance or actionable steps for the authors to follow. The feedback is 3 as it prompts the authors to consider additional evidence or analysis, but it could be more comprehensive and detailed to be fully beneficial. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the model\"s testing on other tasks in the bAbI dataset, given that it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to other tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1 of bAbI. This provides some grounding as it allows the authors to identify the part of the paper being addressed, which is the testing methodology or results. However, the comment does not specify what needs to be addressed or improved in terms of testing on other tasks. It lacks specificity regarding the details of the testing or the potential issues that might arise from only testing on a single supporting fact dataset. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. However, it does not provide any evidence, reasoning, or references to support the claim that only Task 1 was tested or that testing on other tasks is necessary. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer any insights or recommendations for expanding the testing or exploring other tasks, leaving the authors with a general question that may not be fully actionable. Therefore, the comment is 3, as it points out a potential area for further investigation but lacks detailed guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several issues and suggestions for improvement. It highlights the need for a more detailed discussion on the limitations of evolutionary methods, particularly regarding leveraging state, reactiveness, and learning during an episode. The reviewer suggests being honest and direct in the paper, which is a clear and explicit action. Additionally, the comment critiques the title as being too generic and vague, suggesting that the authors should be more precise. The reviewer also questions the meaning of \"brittle convergence properties\" and provides a comparison with DeepRL methods being widely adopted. While the comment provides specific suggestions for improvement, it does not offer concrete guidance on how to address these issues or what specific changes to make. The authors are aware of the need for more detailed discussion and precision, but the lack of explicit instructions on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the limitations of evolutionary methods, specifically mentioning the need for a more detailed discussion on leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and vague, suggesting that the authors should be more precise. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in its critique of the title and the need for more detailed discussion, but without explicit references to sections, it lacks full grounding. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises several claims and suggestions. It claims that the limitations of evolutionary methods are not fully addressed, suggesting that there are deeper aspects to consider regarding leveraging state, reactiveness, and learning during an episode. The reviewer also critiques the title as being too generic and vague, suggesting that the authors should be more precise. Additionally, the comment questions the meaning of \"brittle convergence properties\" and provides a comparison with DeepRL methods being widely adopted. While the comment provides some reasoning and references to the landscape of DeepRL methods, it lacks specific examples or detailed explanations to fully support the claims. The suggestion to be more precise and direct is a logical inference but lacks explicit evidence or references. Therefore, the comment is 3, as it provides some support but requires more detailed justification to be fully convincing.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically regarding the limitations of evolutionary methods and the need for a more detailed discussion on leveraging state, reactiveness, and learning during an episode. It suggests being honest and direct in the paper, which is a clear and actionable feedback. Additionally, the comment critiques the title as being too generic and vague, suggesting that the authors should be more precise. The reviewer also questions the meaning of \"brittle convergence properties\" and provides a comparison with DeepRL methods being widely adopted. While the comment provides valuable insights and suggestions for improvement, it could be more helpful if it offered specific examples or detailed guidance on how to address these issues. Overall, the comment is 4 as it directs the authors\" attention to important areas for enhancement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. While the comment does not explicitly instruct the authors to provide this information, it clearly indicates what needs to be addressed. The authors can infer that they need to include details on these aspects in their paper. However, the comment lacks specific guidance on how to present this information, such as suggesting the inclusion of a detailed explanation or example. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the synthesis process and edge handling, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification on specific aspects of the paper, such as the synthesis of the focal stack and the handling of edges with depth discontinuities. These questions are not claims but rather requests for information or clarification. Therefore, they do not fit the criteria for a claim and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. These are critical aspects that could significantly impact the understanding and evaluation of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their presentation. While it identifies areas for improvement, it lacks actionable feedback, making it 3. The authors are given a direction to explore but without detailed guidance on how to implement the changes, limiting the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide empirical justification for their claim that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces. While the comment implies that such justification is necessary, it does not explicitly instruct the authors to include this information or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include empirical evidence to support their claim. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the first claimed contribution of the paper, which is that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces. However, it does not specify which part of the paper this contribution is made, making it weakly grounded. The comment suggests that empirical justification is needed for this claim, but it does not provide specific guidance on what kind of empirical evidence would be necessary. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s first contribution is that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces, which is a departure from existing algorithms. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed evidence or comparisons to existing work, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential contribution of the paper, specifically that the proposed algorithm does not require as many points or apriori knowledge about dimensions of subspaces, which is a departure from existing algorithms. However, the comment suggests that the authors should provide empirical justification for this claim. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to substantiate the claim with empirical evidence. This limits the usefulness of the feedback, as the authors are left with a general idea of what is needed but without detailed instructions on how to achieve it. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify which previous works are missing or what aspects of the discussion are lacking. This lack of detail makes it difficult for the authors to understand exactly what needs to be addressed or how to improve their draft. Without explicit guidance or concrete suggestions, the authors are left without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of comprehensive discussion of previous work on the topic, but it does not specify which part of the paper this issue is addressed in. This makes it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment does not provide specific details on what aspects of the discussion are missing or how they should be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not give a comprehensive discussion of previous work on the topic, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that the authors do not provide a comprehensive discussion of previous work on the topic. This feedback is important as it highlights an area where the authors can enhance the depth and context of their work. However, the comment lacks specificity and does not provide guidance on which specific previous works are missing or how the authors might address this issue. Without actionable suggestions or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the OT sample selection process and its iterative nature, as well as the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. While the comment implies that more details and a flow chart could be added to clarify the process, it does not explicitly instruct the authors to include these elements. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details and a flow chart to enhance clarity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of the paper, such as the OT sample selection process and the iterative nature of the EP module during training. It also questions the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. However, it does not explicitly mention which section of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing more details and a flow chart to clarify the process, and asking for the runtime information. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the OT sample selection process and its iterative nature, as well as the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. The comment suggests that adding more details and a flow chart would help readers understand the process better. However, it does not provide specific evidence, examples, or references to support the claim that these aspects are unclear or need clarification. The lack of detailed reasoning or references makes the claim 3, as the authors would need to infer the need for additional information based on the reviewer\"s questions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the OT sample selection process and its iterative nature, as well as the runtime for solving the entropic regularized discrete OT problem and the OT sample selection. It suggests that adding more details and a flow chart would help readers understand the process better. This feedback is 4 as it identifies specific areas where the paper could be improved for clarity and comprehensibility. However, it could be more helpful if it provided suggestions on how to present this information or examples of similar approaches. Overall, the comment provides clear guidance on what needs to be addressed to enhance the paper\"s clarity, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the discussion of KG handling continuous tasks and the lack of experiments with continuous tasks. It also questions the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. The comment implies that the authors should include these experiments to provide a more comprehensive evaluation of their methods. However, it does not explicitly instruct the authors to include these experiments or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should include these experiments and understand how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of experiments with continuous tasks despite discussing KG\"s handling of continuous tasks, and the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. The authors can identify the relevant sections of the paper, as the comment explicitly mentions \"Section 7 in the appendix,\" providing full grounding. The comment is also specific because it clearly outlines what needs to be addressed: the inclusion of experiments with continuous tasks and the comparison of empirical performance to ConBO. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two claims. First, it questions why there are no experiments with continuous tasks despite discussing KG\"s handling of continuous tasks. Second, it asks why entropy methods for conditional optimization, which are derived in Section 7 of the appendix, are not included in the experiments. The reviewer provides a logical reasoning for the first claim by pointing out the inconsistency between the discussion and the lack of experiments. However, the second claim lacks specific examples or references to support the comparison with ConBO, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that while the authors discuss how KG handles continuous tasks, there are no experiments conducted to validate this claim. This is a critical oversight that the authors should address to provide empirical evidence for their claims. Second, the comment questions the absence of experiments involving entropy methods for conditional optimization, which are derived in Section 7 of the appendix. It suggests that the authors should include these experiments to compare their empirical performance with ConBO. The feedback is clear and actionable, providing the authors with specific areas to focus on for improvement. However, it could be more helpful if it offered suggestions on how to conduct these experiments or what specific results to expect. Overall, the comment is 4, as it guides the authors toward necessary enhancements to strengthen their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it implies that the authors should provide a more detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between these concepts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, which is the introduction of the importance of unsupervised feature selection from a diffusion perspective. It also raises a question about the difference between similarity and exit times in nature. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the difference between similarity and exit times, providing a clear direction for the authors to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their explanation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as 2, as it provides some insight but does not offer detailed or constructive feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not provide explicit guidance or suggestions on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should explore the capabilities of the framework in different contexts. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate this inquiry. The comment lacks specific examples or references to external works that might address this concern, making it difficult for the authors to understand the basis of the question. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. This inquiry prompts the authors to consider the scope and applicability of their framework, which is an important aspect of evaluating its utility. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or explore these areas further. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and provides a specific direction for the authors to improve their experiments. The action is explicit and concrete, as it outlines exactly what additional experiments need to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments\" and \"sentence similarity tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors should conduct experiments on more types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE. This provides clear guidance on what additional experiments need to be performed to enhance the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited because they only evaluate on sentence similarity tasks and open domain QA tasks, without mentioning other tasks involving sentence pairs. The reviewer suggests that the authors should conduct experiments on more types of sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This claim is 3 as it provides a logical reasoning for the need to expand the experimental scope, but it lacks specific examples or references to support the claim fully. The authors would need to conduct additional research or provide more detailed justification to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental scope of the paper, specifically noting that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that the authors should expand their experiments to include other types of sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the comprehensiveness and relevance of their experimental results. By addressing this suggestion, the authors can improve the robustness and applicability of their findings. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for enhancing the paper\"s contribution and impact."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about setting the parameter S, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address this issue or what steps to consider when setting the parameter S. Without specific suggestions or directions, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about setting the parameter S, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper this comment addresses, making it weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of setting the parameter S, leaving the authors without clear direction. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about setting the parameter S, but it does not provide any specific reasoning, examples, or references to support why this is a problem or how it affects the paper. Without additional context or evidence, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue related to setting the parameter S, which is a critical aspect of the paper. However, it lacks actionable guidance or suggestions on how the authors might address this problem or improve their approach. Without additional context or specific advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a potential weakness but does not provide actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. While the comment implies that the authors should consider including a human evaluation, it does not explicitly instruct them to do so or provide guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include a human evaluation and understand how to integrate it into their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, it does not specify which part of the paper this evaluation should be included in or how it should be integrated. The authors can infer that it relates to the evaluation section, but the comment lacks specificity in terms of what needs to be addressed or how to implement the suggestion. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying on automatic evaluation metrics, which can be misleading. However, the comment does not provide specific examples or references to support the claim that automatic metrics are misleading. While the suggestion is logical, it lacks detailed justification or evidence to fully substantiate the claim. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics, which can be misleading. This feedback is 3 as it identifies a potential limitation in the current evaluation approach and provides a suggestion for improvement. However, the comment lacks specific guidance on how to conduct a human evaluation or what aspects should be considered. To be more helpful, the comment could include details on how to implement a human evaluation or what criteria should be used. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the triviality of the convergence proof, noting that the theoretical proof appears straightforward due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. It suggests that the convergence proof lacks substantial novelty and rigor. However, the comment does not provide specific guidance on how the authors might address this issue or improve the proof. The action is implicit and vague, as the authors are left to infer that they need to enhance the proof\"s novelty and rigor but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Theoretical proof for convergence\" and references \"Assumption 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the convergence proof, noting that the proof appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. The comment further explains how the proof lacks novelty and rigor by referencing Modification 1 in Appendix C and suggesting that previous theorems could be adapted with straightforward modifications. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. It provides a logical explanation by referencing Assumption 4.1 and suggesting that the convergence proof lacks novelty and rigor. The comment supports its claim by referencing Modification 1 in Appendix C and indicating that previous theorems could be adapted with straightforward modifications. This provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof for convergence, noting that it appears trivial due to the i.i.d. assumption for $X$ and the covariance matrix for $Z$. It provides a detailed explanation of how the proof lacks novelty and rigor, referencing specific assumptions and modifications. This feedback is 5 as it not only points out a critical weakness in the paper but also offers a clear and actionable suggestion for improvement by suggesting that the authors might need to enhance the proof\"s novelty and rigor. The comment provides a specific direction for the authors to consider, making it a valuable contribution to the draft. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to mention that the experimental setup borrowed from 2 is only semireal, as multinode seed cascades are artificially created by merging singlenode seed cascades. This provides a clear and direct action for the authors to take, ensuring that they address this issue in their draft. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experimental setup borrowed from 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental setup, noting that it is only semireal due to the artificial creation of multinode seed cascades by merging singlenode seed cascades. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is 3 as it provides a logical explanation for why the setup is not fully realistic. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This feedback is clear and actionable, as it provides a direct suggestion for the authors to clarify this aspect in their paper. By addressing this point, the authors can enhance the transparency and credibility of their experimental methodology. However, the comment could be more helpful if it offered additional guidance on how to present this information or suggested ways to mitigate the limitations of the semireal setup. Overall, the comment is 4 as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on stateoftheart generative models like GPT. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their dataset and model coverage to include other biases and stateoftheart generative models. However, the comment lacks concrete details on how to implement these changes, such as suggesting specific datasets or models to include. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on other important biases and stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what is missing, such as other biases and stateoftheart models, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also mentions the absence of assessments on stateoftheart generative models like GPT. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the significance of these omissions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on stateoftheart generative models like GPT. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered suggestions on how to expand the dataset or model coverage or provided examples of other biases and datasets that could be included. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation of the metrics or citing them. While the comment implies that the authors should include more information about the metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details or citations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the description of metrics in the paper, suggesting that it is limited and recommending either an explanation of the metrics or a citation to them. However, it does not specify which part of the paper this issue is related to, such as a specific section or table where the metrics are discussed. This makes it difficult for the authors to pinpoint the exact area needing improvement. The comment is specific in its suggestion to provide more information about the metrics, but the lack of grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends either providing an explanation or citing the metrics. However, the comment does not provide specific examples or references to support the claim that the metrics are insufficiently described. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that either an explanation of the metrics or a citation to them would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by clarifying the metrics used. However, the comment could be more helpful if it offered additional guidance on how to explain the metrics or suggested specific references for the authors to consider. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the empirical analysis uses static datasets and recommends that the problem should be better motivated for the paper to be useful. While the comment implies that the authors should provide a more compelling motivation for their work, it does not explicitly instruct them to do so or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should include a more detailed motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for the problem considered in the paper, specifically the need for fast label aggregation algorithms in a streaming setting. It points out that the empirical analysis uses static datasets and suggests that the problem should be better motivated for the paper to be useful. However, the comment does not specify which part of the paper lacks motivation or where the motivation should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections that need revision. The comment is specific in its critique of the lack of motivation and the need for a more compelling justification for the problem considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the problem it addresses, specifically the need for fast label aggregation algorithms in a streaming setting. The reviewer supports this claim by noting that the empirical analysis uses static datasets, which may not align with the streaming setting. However, the comment lacks specific examples or references to substantiate the claim that the problem is not wellmotivated. The suggestion to provide a more compelling motivation for the problem is logical but lacks detailed evidence or examples to fully support the claim. Therefore, the comment is 3, as it provides a logical basis for the claim but requires additional support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s motivation and relevance. It points out that the paper\"s objective of designing fast label aggregation algorithms for a streaming setting is not adequately supported by a clear motivation for why such algorithms are needed. Additionally, the comment notes that the empirical analysis uses static datasets, which may not align with the streaming setting. This feedback is valuable as it highlights a critical gap in the paper\"s presentation and suggests that the authors should provide a more compelling motivation for their work. However, the comment could be more helpful if it offered specific suggestions on how to improve the motivation or examples of relevant applications. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While the comment implies that the authors should clarify or discuss this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this connection in their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection between the mention of tensor decomposition being harder in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the mention of tensor decomposition being harder in the symmetric case in the introduction and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This question prompts the authors to clarify or discuss this connection, which could be an important aspect to address in their draft. However, the comment does not provide specific guidance or suggestions on how to improve the connection or what aspects to focus on. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. It also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. This feedback is explicit and concrete, giving the authors a clear direction on what to include in their paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this is not explicitly mentioned. The comment is specific in its suggestion to conduct error analysis and provide detailed explanations, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\"s performance under different scenarios. This feedback is logical and provides a clear rationale for why error analysis is important, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim that error analysis is essential for guiding improvements in the field of ERC research. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues in the paper. It provides a clear and actionable suggestion for the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their analysis and improve the robustness of their findings. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct the error analysis or what aspects to focus on. Overall, the comment is 4 as it directs the authors towards a significant improvement in their work, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the proposed method\"s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain comes from specific modules or is simply due to more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not explicitly instruct the authors on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more thorough ablation study to clarify the contributions of each module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the complexity of the proposed method and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters. However, it does not specify which part of the paper this concern relates to, such as the methodology section or the results section. The authors can infer that it pertains to the method description or the ablation study, but this inference is not explicit. The comment is specific in detailing the issue with the current ablation study, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, it lacks specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. The authors are left to infer that the study needs to be more comprehensive, but without explicit guidance or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the proposed method, specifically the complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters, highlighting a gap in the current ablation study. This feedback is valuable as it points out a significant area for improvement, suggesting that the authors need to conduct a more thorough ablation study to clarify the contributions of each module. However, the comment could be more helpful if it provided specific suggestions on how to design a more comprehensive ablation study or examples of how to address this issue. Overall, the comment is 4 as it directs the authors to a critical area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA 1 as an alternative. While the comment identifies a potential issue and suggests a solution, it does not provide explicit instructions on how to address the concern or integrate ULiRA into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should consider using ULiRA and understand how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness and suggests that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also recommends the use of ULiRA 1 as an alternative. However, the comment does not specify which part of the paper discusses MIA testing or unlearning effectiveness, making it weakly grounded. The comment is specific in identifying the issue with MIA testing and suggesting an alternative, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA (Membership Inference Attack) testing is not robust for privacy guarantees and suggests using ULiRA 1 as an alternative. However, the comment does not provide specific evidence or reasoning to support why MIA testing is not robust or why ULiRA is a better alternative. The lack of detailed justification or references makes the claim 3, as the authors would need to independently verify the claim or seek additional information to address the concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reliance on MIA (Membership Inference Attack) testing as a metric for unlearning effectiveness, noting that the effectiveness of MIA testing itself is not robust for privacy guarantees. It also suggests using ULiRA 1 as an alternative. While the comment highlights a critical concern, it does not provide specific guidance on how to address the issue or integrate ULiRA into the paper. The feedback is 3 as it points out a potential weakness but lacks depth and actionable suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the paper, including qualitative explanations, minimal description of procedures in simulations or experiments, confusing figures, and the lack of statistical inferences with error bars or pvalues. It suggests adding more details to the paper or supplementary information to clarify the procedures and results. However, the comment does not provide specific guidance on how to improve these aspects, such as which sections to focus on or how to present the additional details. While the authors can infer that they need to enhance the clarity and detail of their explanations, the lack of concrete steps makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, questioning the clarity of the \"sample count\" label. Additionally, it provides specific suggestions for improvement, such as adding more details to the paper or supplementary information and including error bars and pvalues for statistical inferences. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the explanations are qualitative and that the procedures in simulations or experiments are described minimally or not at all. It also notes that some figures are confusing, specifically questioning the clarity of the \"sample count\" in Figure 2. The reviewer suggests adding more details to the paper or supplementary information to clarify the procedures and results. However, the comment lacks specific examples or detailed reasoning to support the claim that the explanations are qualitative or that the procedures are described minimally. The suggestion to include error bars and pvalues for statistical inferences is a logical extension but does not provide direct evidence or examples of where these are missing. Therefore, the comment is 3, as it provides some guidance but lacks detailed justification and specific examples.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically noting that the explanations are qualitative and that the procedures in simulations or experiments are described minimally or not at all. It also points out confusing figures, such as the unclear \"sample count\" in Figure 2. The reviewer suggests adding more details to the paper or supplementary information to clarify the procedures and results. Additionally, it recommends including error bars and pvalues for statistical inferences. These suggestions are clear and actionable, providing the authors with specific steps to enhance the clarity and rigor of their work. However, the comment could be more helpful if it offered additional guidance on how to present the additional details or examples of how to incorporate error bars and pvalues. Overall, the feedback is 4 as it directs the authors to improve the clarity and robustness of their paper."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an unclear aspect regarding the generalizability of the biases discussed in the paper. It mentions specific examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1), but questions the extent to which these situations are generalizable. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or clarify the generalizability of the biases. The action is implicit and vague, as the authors are left to infer that they need to provide more context or evidence to support the generalizability of these situations. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the unclear generalizability of the biases discussed in these sections. The comment provides a clear direction for the authors to address this concern, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the biases discussed in the paper, specifically mentioning section 3.2 and Theorem 1. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the biases are not generalizable. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the generalizability of the biases discussed in the paper. It highlights that while the paper presents examples of biases in target statistics and prediction shift, it does not provide clarity on the extent to which these situations are generalizable. This feedback is 3 as it points out a potential gap in the paper\"s analysis, prompting the authors to consider whether their findings are applicable beyond the specific examples provided. However, the comment could be more helpful if it suggested ways for the authors to address this issue or provided additional context to support the generalizability of the biases. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide specific guidance on which datasets would be most useful or how they should be incorporated into the study. The action is implicit, as the authors need to infer that they should add more datasets, and it is vague because it lacks concrete details on what datasets to include or how to implement this suggestion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not specify which datasets are currently being used or which additional datasets would be most relevant. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs improvement. While the comment implies that the datasets section or methodology should be addressed, it does not provide clear guidance on what specific datasets should be added or how they would enhance the study. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. However, it does not provide any specific examples or reasoning to support why additional datasets are necessary or how they would enhance the study. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that including more datasets would be beneficial, particularly for evaluating crosstask transferability. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which datasets would be most relevant or how they could be incorporated into the study. The feedback is 3 as it points out a potential enhancement, but it does not offer actionable advice or detailed suggestions, leaving the authors with limited guidance on how to address this issue. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows the previous work, Luciddreamer. While it implies that the authors should clarify or correct this impression, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details or evidence to support the novelty of their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the section on 3D Gaussians generation is novel or follows previous work, Luciddreamer. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows previous work, specifically Luciddreamer. The comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the section on 3D Gaussians generation, specifically in relation to the previous work, Luciddreamer. It prompts the authors to clarify whether there are any additional novel efforts or contributions in this part of the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The feedback is 3 as it directs the authors to consider the novelty of their work, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the tractability of MMD DRO compared to phidivergence or Wasserstein uncertainty sets. It also critiques the upper bound provided in Theorem 3.1, noting that it is crude due to the loss function belonging to the RKHS. However, the comment does not provide specific guidance or suggestions on how the authors might address these issues or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the paper, such as the tractability of MMD DRO compared to other uncertainty sets and the limitations of the upper bound provided in Theorem 3.1. It also critiques the assumption that the loss function belongs to the RKHS. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the sections discussing MMD DRO and Theorem 3.1, but this inference is not direct. The comment is specific in detailing the issues with the upper bound and the assumption about the loss function, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that MMD DRO does not have a tractable exact equivalent reformulation, which is a severe drawback. It also critiques the upper bound provided in Theorem 3.1, noting that it is crude and drops the nonnegative constraint on the distribution, requiring further approximation. The reviewer further points out that the assumption that the loss function belongs to the RKHS is restrictive. While the comment provides specific examples of issues, it lacks detailed reasoning or references to support the claim that MMD DRO is not tractable or that the upper bound is crude. The critique is based on the authors\" own observations, but without additional evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the tractability of MMD DRO compared to other uncertainty sets like phidivergence or Wasserstein uncertainty sets. It points out that the upper bound provided in Theorem 3.1 is crude, particularly because it drops the nonnegative constraint on the distribution, and further approximation is still needed. Additionally, the comment highlights the restrictive assumption that the loss function belongs to the RKHS. While the comment effectively points out these issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is 3 as it provides insight into potential weaknesses, but it could be more beneficial with actionable advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It also inquires about the impact of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints on the algorithm\"s relevance. Additionally, it asks whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment raises important questions, it does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific aspects of the framework should be clarified or expanded upon. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p.3, binary classification,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues regarding the relevance of the framework to nonconvex losses and nonnorm type defenses, as well as the impact of the nonvanishing duality gap and maximization over nonnorm type constraints. The comment also raises questions about the algorithm\"s relevance and potential intuitions on the risk upperbound, as well as the use of the true mean for defense design. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It asks whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant or whether it still provides intuitions on the risk upperbound. The comment also questions whether the true mean being known through an oracle can be used to design a better defense. While the questions are logical and could prompt the authors to consider these aspects, the comment does not provide specific examples, references, or detailed reasoning to support the claims. This makes the claim 3, as the authors would need to explore these questions further to fully address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the relevance of the framework to problems involving nonconvex losses and nonnorm type defenses. It inquires about the impact of the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints on the algorithm\"s relevance. Additionally, it asks whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment identifies areas for clarification and potential improvements, it lacks specific suggestions or guidance on how the authors might address these questions or enhance their draft. The feedback is 3 as it prompts the authors to consider important aspects of their work but does not provide detailed actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This is an explicit suggestion that provides a clear direction for the authors to explore. However, the comment does not specify how to implement this action or what specific aspects of the sparsification process should be considered. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular action\u2014sparsifying the trained models and comparing their accuracy to the proposed model. This provides clear guidance on what needs to be done to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. However, the comment does not provide any reasoning, evidence, or references to support why this action might be beneficial or necessary. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This feedback is 3 as it provides a specific direction for the authors to explore, potentially leading to improvements in the model\"s performance or understanding. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of sparsification should be considered. To be more helpful, the comment could include additional context, such as the potential benefits of sparsification or how it might impact the model\"s performance. Therefore, the comment is rated as 3, as it provides a starting point for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the paper\"s reproducibility, noting that while the pseudocode is provided in the supplementary material, it does not feel like the paper is written to be reproduced. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback implies that the authors should include these missing details to enhance the reproducibility of their work. However, the comment does not explicitly instruct the authors to add these details, leaving the action somewhat implicit. The authors can infer that they need to provide additional information, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of reproducibility, specifically mentioning the lack of details about the RNN implementation, such as the number of units. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for additional details to enhance reproducibility, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not written to be reproduced, despite the presence of pseudocode in the supplementary material. The reviewer suggests that more details are required, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This claim is 3 as it points out a specific issue with the paper\"s reproducibility, but it lacks detailed examples or references to support the claim fully. The authors would need to infer the exact details that are missing, making the comment 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s reproducibility, noting that while pseudocode is provided in the supplementary material, the paper does not feel written to be reproduced. The reviewer highlights the need for additional details, such as specific implementation details like the number of units in an RNN, which are neither provided in the paper nor the supplementary material. This feedback is clear and actionable, as it directs the authors to include these missing details to enhance the reproducibility of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to include these details. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars and more random trials. This feedback provides a clear and explicit action for the authors to take, which is to include error bars and more random trials in the figure. The suggestion is concrete, as it specifies what needs to be added to improve the figure. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of error bars and more random trials to strengthen the figure. This provides clear guidance on how to improve the figure, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger if it included error bars and more random trials. This is a logical suggestion based on the common practice of including error bars to indicate variability and random trials to reduce the impact of random fluctuations. The comment provides a clear rationale for the suggestion, making it 4. However, it could be strengthened by providing specific examples of how error bars and additional trials would improve the figure, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving Figure 1 by recommending the inclusion of error bars and more random trials. This feedback is clear and directly addresses the potential weaknesses in the figure, offering a concrete way for the authors to enhance the visual representation of their results. By suggesting these additions, the comment empowers the authors to make meaningful improvements to their draft, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section. It also points out a specific issue in Figure 1, where it is unclear which points correspond to different learning rates in the left graph and different steps in the right graph. The comment is explicit in its suggestions, providing clear guidance on what the authors need to do to improve their draft. It also specifies the areas that need attention, making the feedback actionable. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of clarity in the figure regarding the correspondence of points to different learning rates and steps. The comment is specific in detailing what needs to be addressed, providing clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section and mentions a specific issue with Figure 1 regarding the correspondence of points to different learning rates and steps. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides two actionable suggestions. First, it suggests that the authors include a brief introduction to energy models in the related work section, which could enhance the context and understanding of the paper. Second, it points out a specific issue in Figure 1, where it is unclear which points correspond to different learning rates and steps. This feedback is clear and provides concrete steps for the authors to improve their draft, making it 4. However, it could be more helpful if it offered additional guidance or examples on how to address these issues. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to clarify this point. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the model\"s capabilities, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s ability to generate novel knowledge or testable hypotheses about neuron data. While it identifies a potential area of concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the model\"s capabilities. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors present a simplified version of theorem 2 for the general audience, similar to theorem 1. While the comment implies that the current presentation of definition 2 and theorem 2 is difficult to understand, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should simplify theorem 2. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"definition 2 and theorem 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding these sections for the general audience. The comment provides a clear direction for improvement by suggesting a simplified version of theorem 2. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the presentation of definition 2 and theorem 2 is difficult for the general audience to understand, similar to theorem 1. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of theorem 2, suggesting that it might be difficult for the general audience to understand, similar to theorem 1. This feedback is 3 as it points out a potential accessibility issue that the authors should consider. However, the comment lacks specific suggestions or guidance on how to simplify theorem 2 or make it more accessible. Without actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the KeyQN section, specifically asking what the \"keypoint mask averaged feature vector\" is and whether it is obtained by multiplying each feature map elementwise by H_psi. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify this aspect in their draft. However, the comment is 3 because it points out a specific area that needs clarification, but it lacks concrete details on how to implement the suggested action. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the calculation of the \"keypoint mask averaged feature vector\" and asks whether it is obtained by multiplying each feature map elementwise by H_psi. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about a specific aspect of the paper, namely the calculation of the \"keypoint mask averaged feature vector.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the calculation of the \"keypoint mask averaged feature vector\" in the KeyQN section. It asks whether this vector is obtained by multiplying each feature map elementwise by H_psi. This feedback is clear and actionable, as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, the comment could be more helpful if it provided additional context or suggested how this clarification might impact the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to a specific area that needs clarification, which is beneficial for improving the draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors make use of styles, such as dashed lines, or add color to the curves in Figure 2 to improve their distinguishability. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is concrete, as it specifies the type of stylistic elements that could be used to enhance the figure. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, suggesting that the curves are difficult to distinguish and recommending the use of styles or color to improve readability. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the curves in Figure 2 are difficult to distinguish and recommends using styles or color to improve readability. This is a subjective observation that lacks specific reasoning or evidence to support why the curves are difficult to distinguish. The suggestion is vague and does not provide detailed guidance on how to implement these changes, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between the different curves. It provides a clear and actionable suggestion by recommending the use of styles, such as dashed lines, or adding color to enhance the figure\"s readability. This feedback is valuable as it offers a concrete way for the authors to improve the clarity and effectiveness of their visual representation. However, the comment could be more helpful if it included specific examples of how these stylistic elements could be applied or if it discussed the potential impact of these changes on the overall understanding of the data presented. Despite this, the feedback is 4 as it directs the authors toward a specific and effective way to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should tone down their claims in the introduction and not label the task as language learning, as it is more accurately described as a feedbackdriven QA in the form of a dialog. This feedback is clear and provides a direct action for the authors to take, making it 5. The reviewer offers a specific suggestion on how to address the issue, which is to change the labeling of the task. This level of detail and specificity ensures that the authors know exactly what changes to make to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claims made in the introduction, suggesting that the task is more accurately described as a feedbackdriven QA rather than language learning. The reviewer provides a clear and actionable suggestion to tone down the claims and change the labeling of the task. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not accurate, as they are far from what has been achieved by the tasks and models. The reviewer suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog, rather than language learning. This claim is 3 as it provides a logical reasoning for the discrepancy between the claims and the actual task evaluation. However, the comment lacks specific examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are not aligned with the actual task and evaluation. It suggests that the task is more accurately described as a feedbackdriven QA rather than language learning, providing a clear and actionable feedback for the authors to consider. By recommending that the authors tone down their claims and change the labeling of the task, the comment offers a specific and constructive suggestion that can help the authors improve the clarity and accuracy of their draft. This feedback is valuable as it guides the authors in revising their introduction to better reflect the nature of the task and its evaluation. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the paper\"s approach to proving lower bounds for round complexity, suggesting that the results follow easily from a reduction to collaborative ranking. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the approach to proving lower bounds for round complexity in the context of batched ranking problems. It mentions the exploitation of an easy reduction from the problem of collaborative ranking, which implies that the authors are using a known result to derive their lower bound results. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the use of an easy reduction and the resulting corollary, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a major part of the work involved in proving results for batched ranking problems, and that the paper exploits an easy reduction from the problem of collaborative ranking. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s approach to proving lower bounds for round complexity in the context of batched ranking problems. It points out that the paper exploits an easy reduction from the problem of collaborative ranking, which may lead to a less challenging proof. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are given some insight into a potential area for improvement but are left without clear steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and fails to fully utilize the potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. While the comment implies that the authors should consider using more sophisticated prompting techniques, it does not provide specific guidance on how to implement this suggestion or what constitutes a \"carefully curated\" prompt. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their prompting technique. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of a basic prompting technique in the study, suggesting that it fails to leverage the full potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or how it could be improved. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to use carefully curated prompts, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of large language models (LLMs). However, the comment does not provide specific examples or evidence to support this claim, such as comparisons with other studies or detailed explanations of how the current technique limits the potential of LLMs. Without such evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study\"s use of a basic prompting technique, suggesting that it fails to fully leverage the capabilities of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. While the comment highlights an area for improvement, it lacks specific guidance or examples on how to implement the suggested changes. The authors are left with a general idea of what needs to be improved but without detailed steps or suggestions for implementation. Therefore, the comment is 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting additional experiments on larger datasets, noting that compute might be an issue. It also acknowledges the authors\" response and agrees that the concerns have been addressed well. However, the comment does not provide explicit instructions or concrete guidance on how to implement these additional experiments or address the compute issue. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct these experiments but without detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests additional experiments on larger datasets, noting that compute might be an issue. It also acknowledges the authors\" response and agrees that the concerns have been addressed well. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments and acknowledges the authors\" response, but without explicit references to the paper, the authors may struggle to pinpoint the exact section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests additional experiments on larger datasets, noting that compute might be an issue. It also acknowledges the authors\" response and agrees that the concerns have been addressed well. However, the comment does not provide specific reasoning or evidence to support the claim that additional experiments would be beneficial or that compute might be an issue. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting additional experiments on larger datasets, noting that compute might be an issue. This feedback is 3 as it provides a direction for further investigation and acknowledges the authors\" response. However, the comment lacks specificity regarding the exact nature of the additional experiments or how they might address the compute issue. It also does not provide detailed guidance on how to implement these experiments or what specific results to expect. While it offers a suggestion for improvement, the feedback could be more actionable and comprehensive to be rated higher. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the performance of the models in Table 4, noting that the performance on REC and RES is behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT. However, the comment does not explicitly instruct the authors to make any changes or improvements to their models or results. The action is implicit, as the authors can infer that they need to address the performance gap, but it lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the performance on REC and RES, comparing it to more recent models like GLaMM and UNINEXT. The comment provides specific examples of the performance achieved by these models, which helps the authors understand the scope of the problem. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES is behind more recent models, providing specific examples of other models that achieve better results. This claim is supported by references to GLaMM and UNINEXT, which provide concrete examples of the performance gap. The inclusion of specific references and examples makes the claim 4, as it offers a clear basis for the authors to understand and address the issue. However, the comment could be strengthened by providing more detailed comparisons or analysis of the performance differences, which would make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models in Table 4, noting that the results on REC and RES are behind more recent models. It provides examples of other models that achieve better results, such as GLaMM and UNINEXT, which helps the authors understand the scope of the problem. However, the comment does not offer actionable suggestions or guidance on how to improve the performance of the models or address the identified gap. While it highlights a critical area for improvement, the lack of specific advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory, with only a minor difference in the mask source. While the comment identifies a potential issue with the novelty, it does not provide explicit guidance or suggestions on how the authors might address this limitation or enhance the novelty of their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed video storyboarding approach, specifically noting that it relies on framewise SDSA, which mirrors the approach used in ConsiStory. However, it does not specify which part of the paper this critique pertains to, such as the methodology section or the introduction. This makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in detailing the limitations of the approach, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the innovation of the proposed video storyboarding approach is limited, as it largely mirrors the approach used in ConsiStory, with only a minor difference in the mask source. The reviewer provides a specific comparison to ConsiStory, which supports the claim by highlighting the similarities between the two approaches. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Overall, the comment is 4, as it provides a logical basis for the claim but lacks comprehensive evidence or references to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed video storyboarding approach, noting that it largely mirrors the approach used in ConsiStory, with only a minor difference in the mask source. While the comment highlights a specific area for improvement, it lacks depth and actionable suggestions on how the authors might enhance the novelty of their approach or address the limitations. The feedback provides a clear direction for the authors to consider, but it could be more helpful if it included specific recommendations or examples of how to differentiate their work from existing methods. Therefore, the comment is 3, as it points out a potential issue but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the weakness of the method might be more pronounced in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment does not specify which part of the paper this observation pertains to, such as a specific section or experiment. The authors can infer that it relates to the method\"s performance or evaluation, but without explicit grounding, it is challenging to pinpoint the exact area. The comment is specific in its suggestion to compare the approach with previous work, but it lacks grounding, making it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification on such datasets. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that the method\"s weakness would be more pronounced in these scenarios. Without detailed justification or references, the claim remains 1, as it lacks the necessary support to be understood or acted upon by the authors. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method, suggesting that its performance might be more challenging in images with multiple objects or cluttered scenes. It also proposes a comparison with previous approaches on fewshot classification in such datasets, which could provide valuable insights. However, the comment lacks specific guidance or suggestions on how to address this issue or conduct the proposed comparison. While it points out an area for improvement, it does not offer actionable steps or detailed feedback, making it 3. The authors are given a direction for further exploration but without explicit instructions on how to implement it, which limits its helpfulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the detailed explanation of implementing kernels with OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. While the comment implies that the authors should consider revising their explanation, it does not explicitly instruct them to do so or provide guidance on how to simplify the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should streamline the explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the implementation of kernels with OpenAI\"s Triton, suggesting that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not specify which part of the paper this explanation is in, making it weakly grounded. The comment is specific in its suggestion to simplify the explanation, but without explicit references to the paper, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the implementation of kernels with OpenAI\"s Triton is wellknown and does not require a fullpage explanation. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim, making it difficult to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the detailed explanation of implementing kernels with OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. While the comment identifies a potential area for simplification, it does not provide specific guidance or suggestions on how to streamline the explanation or what aspects of the implementation are particularly noteworthy. The feedback lacks depth and actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it points out a potential area for simplification but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It suggests that the authors clarify why the experiments are considered zeroshot and address the issue of transferability between tasks. The comment provides specific examples of tasks (Walkerrun and manipulation scenarios) and highlights the need for clarity in the paper. However, it does not explicitly instruct the authors to make these clarifications or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides specific examples of tasks (Walkerrun and manipulation scenarios) and suggests that the authors clarify why the experiments are considered zeroshot and address the issue of transferability between tasks. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or figures. While the authors can infer that it relates to the experimental setup or results, this inference is not as clear as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides specific examples of tasks (Walkerrun and manipulation scenarios) to illustrate the point. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim about the zeroshot nature of the experiments or the limitations of transferability. While the examples provide some context, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the zeroshot nature of the experiments and the potential limitations of transferability due to task difficulty. It provides specific examples of tasks (Walkerrun and manipulation scenarios) to illustrate the point and suggests that the authors clarify why the experiments are considered zeroshot and address the issue of transferability between tasks. This feedback is clear and actionable, as it guides the authors to make necessary clarifications in their paper to avoid misleading readers. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context for the authors to consider. Overall, the comment is 4, as it provides valuable insights and actionable feedback for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to test the method on larger backbones. The action is implicit and vague, as the authors are left to infer that they should explore the method\"s performance on larger models. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL. However, the comment does not specify which part of the paper discusses the experimental results or the proposed methods, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issue with the relative gains and suggesting a potential area for further exploration. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed methods are not very strong, particularly on a small backbone ResNet50, where only a 1% gain is achieved. The reviewer suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL due to its global pooling structure. However, the comment lacks specific evidence or detailed reasoning to support the claim that the method would perform better on larger backbones. The suggestion is based on a logical assumption about the structure of the proposed method, but without concrete examples or references, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the relative gains of the proposed methods, noting that they only achieve a 1% gain on a small backbone ResNet50. It suggests that the proposed method might be more effective on larger backbone models like SwinB or SwinL due to its global pooling structure. This feedback is 3 as it points out a limitation in the current experimental setup and suggests a direction for further exploration. However, the comment could be more helpful if it provided specific recommendations or guidance on how to test the method on larger backbones or what aspects of the method might be contributing to the observed performance. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the analysis of neural networks contributes less and suggests that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback lacks actionable details, leaving the authors uncertain about what specific changes or additions are needed to enhance their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the analysis of neural networks, specifically mentioning \"Section 3.2, 3.3,\" which provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies the issue by pointing out that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This level of detail allows the authors to understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less and that the work bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the analysis of neural networks, suggesting that the work contributes less and bypasses the core problem of overparametrized neural networks by only considering easy wide fullyconnected neural networks. This feedback is 3 as it points out a specific area where the paper could be improved. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or enhance their analysis. The comment could be more helpful with additional context, examples, or specific recommendations for improvement. Therefore, it aligns with a score of 3, indicating that the comment is 3 but incomplete."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation. It also mentions that some datasets might be too large for certain algorithms. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. However, the comment does not explicitly instruct the authors to take any specific action, such as adding more datasets or explaining the rationale behind the dataset selection. While the feedback provides valuable insights, it lacks explicit guidance on how the authors should address the issue, making it 3.", "grounding_specificity_rationale": "The comment addresses the adequacy of the datasets used for evaluation, specifically mentioning the number of datasets for each task. It raises a concern about the potential insufficiency of the datasets, particularly if some are too large for certain algorithms. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or figures, making it weakly grounded. The feedback is specific in detailing the concern about dataset size and the authors\" response, but without explicit grounding, it is challenging for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large for certain algorithms. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. This feedback is 4 as it provides some justification for the concern about dataset size and acknowledges the authors\" response, but it could be strengthened with more specific examples or references to support the claim about the insufficiency of the datasets. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large for certain algorithms. The reviewer acknowledges the authors\" detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. This feedback is 3 as it identifies a potential weakness in the evaluation process and provides some context through the authors\" response. However, it could be more helpful if it offered suggestions on how to address the issue or further details on the evaluation criteria. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a confusing aspect in the paper regarding the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting a revision of the text or providing a clearer explanation. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the multifidelity framework and sequential design for learning quantities, referencing a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach) for context. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment also highlights a confusing aspect in the abstract and introduction regarding the terms \"relatively inexpensive\" and \"expensive to evaluate.\" However, it does not specify what needs to be addressed in terms of clarity or how to resolve the confusion. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that the terms \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction are confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the terms \"relatively inexpensive\" and \"expensive to evaluate\" used in the abstract and introduction, respectively. It references a specific paper (Assessing Fire Safety using Complex Numerical Models with a Bayesian Multifidelity Approach) for context, which could be helpful for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing alternative phrasing or clarifying the terms. While it points out a potential area for improvement, the feedback is incomplete and does not provide actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the method addresses sparse reward problems and whether it supports this claim through the experiments. It also asks if the proposed method requires subtaskspecific rewards, which would be similar to providing dense rewards. Additionally, it inquires about the ability of other methods (Qmix) to solve sparsereward tasks when given the sum of lowlevel rewards as the global reward. While the comment raises valid questions, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback is vague and lacks actionable steps, making it barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. However, the comment does not specify which part of the paper these questions relate to, such as the experimental results or the method description. This lack of grounding makes it difficult for the authors to identify the exact sections needing attention. The comment is specific in its questions about the method\"s effectiveness and the need for further clarification, but without explicit references to the paper, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some basis for questioning but lacks sufficient detail to fully support the claims.", "helpfulness_rationale": "The review comment raises several questions about the method\"s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of subtaskspecific rewards and whether other methods like Qmix can solve sparsereward tasks with global rewards. While the comment identifies areas for improvement and raises valid concerns, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their draft. The feedback is 3 as it prompts the authors to consider additional aspects of their method and its application, but it could be more actionable with more detailed advice or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. While the comment does not explicitly instruct the authors to make a change, it does highlight a potential issue that needs to be addressed for a fair comparison. The authors can infer that they should clarify this aspect in their paper, but the action is not explicitly stated. The comment is 3 because it provides a clear direction for improvement but lacks explicit guidance on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its inquiry about the use of the AH36M dataset and its impact on fair comparisons, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. This question is logical and seeks clarification on a specific aspect of the paper, which is relevant to the evaluation of the methods and their comparison. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for this clarification. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a critical question about the clarity of whether the AH36M dataset is used for training and whether other methods like HMR and SPIN have access to this data during training. This is an important consideration for ensuring a fair comparison in the paper. By pointing out this issue, the comment provides the authors with a clear direction to improve the clarity and transparency of their methodology. However, the comment could be more helpful if it suggested how the authors might address this issue, such as by explicitly stating that the dataset is used for training or providing a detailed explanation of why it is relevant. Despite this, the comment is 4 as it highlights a significant area for improvement in the paper\"s presentation and methodology."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: the unclear motivation for using an adversarial network in the model and the unfair comparison of experimental results due to the proposed model\"s larger size. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns. The lack of actionable suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific issues: the motivation for using an adversarial network and the fairness of the experimental results comparison. It explicitly mentions the need for clarification regarding the use of the adversarial network and the unfairness of the comparison due to the proposed model\"s larger size. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of motivation and fairness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two concerns: the motivation for using an adversarial network and the fairness of the experimental results comparison. The first claim about the motivation is 3 as it questions the necessity of the adversarial network, but it lacks specific examples or references to support this claim. The second claim about the fairness of the experimental results comparison is 3, as it points out that the proposed model is larger than others, which could affect the comparison. However, the comment does not provide detailed reasoning or evidence to substantiate these claims, making them 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the unclear motivation for using an adversarial network and the unfairness of the experimental results comparison. It points out that the proposed model is larger than others, which could affect the comparison. However, the comment lacks actionable suggestions or detailed guidance on how the authors might address these issues. While it highlights important areas for improvement, the feedback is 3 as it provides some insight but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the reliability of the experimental results, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. While it points out a potential issue, it does not provide explicit guidance on how the authors should address this concern or what steps they should take to improve the reliability of their results. The comment lacks concrete suggestions or detailed instructions on how to resolve the issue, leaving the authors without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, particularly the concern about the reliability of the results due to the MSE being significantly smaller than the MAE. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, specifically mentioning Table 1 where the MSE is significantly smaller than the MAE. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, particularly in Table 1, where the MSE is significantly smaller than the MAE. This raises concerns about the validity of the results. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve the reliability of their results. While it points out a potential problem, it does not provide the authors with a clear path forward or specific steps to take to enhance the robustness of their findings. Therefore, the comment is 3, as it highlights an important area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their methodology or suggest alternative approaches. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this critique pertains to, such as the methodology section or specific results. This makes it difficult for the authors to identify the exact area needing improvement. Additionally, the comment lacks specificity regarding what aspects of the methodology are considered novel or how the proposed meta algorithm differs from existing methods. Without clear grounding and specific details, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the methodology lacks novelty and that the proposed meta algorithm is a direct extension of existing methods. While it identifies a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing methods. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it highlights a concern but does not provide actionable insights for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the limited number of methods used for performance comparison and the lack of consistency in the proposed method\"s performance. It suggests that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. However, the comment does not explicitly instruct the authors to take any specific actions, such as suggesting which methods to include for comparison or how to analyze the inferior results. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the performance comparison and the consistency of the proposed method\"s performance compared to other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than other methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s performance evaluation, noting that the comparison is limited to a few methods and that the proposed method is not consistently better than other methods. It suggests that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. This feedback is clear and actionable, as it directs the authors to address a critical weakness in their work by offering a detailed analysis of the results. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this analysis. Overall, the comment is 4 as it highlights a significant area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. While the comment identifies an area that needs further exploration, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should expand their discussion on the types of activities and their significance, but the comment lacks concrete suggestions or examples on how to do so. Therefore, the comment is 3, as it highlights a gap in the paper but does not offer specific instructions on how to address it.", "grounding_specificity_rationale": "The comment suggests that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for more discussion on the types of activities and their significance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors have not covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This feedback is 3 as it highlights an area that needs further exploration, but it lacks specific guidance or suggestions on how the authors might address this issue. The comment provides a clear direction for improvement but could be more helpful if it included examples or detailed advice on what types of activities should be discussed and how they relate to energy efficiency and occupant comfort. Therefore, the comment is rated as 3, as it points out a significant gap but does not fully guide the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the notation \"D\" should be used differently to avoid confusion between its representation as dimensionality of points and dilation factor. This feedback is clear and provides a direct action for the authors to take, which is to change the notation. The suggestion is concrete and actionable, as it specifies what needs to be done to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using different notation for \"D\" to avoid confusion between its representation as dimensionality of points and dilation factor. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to use different notation, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests using different notation for \"D\" to avoid confusion between its representation as dimensionality of points and dilation factor. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the clarity of the paper. Without such justification, the claim remains 1, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in the paper by pointing out that the notation \"D\" is used to represent both dimensionality of points and dilation factor. This feedback is clear and actionable, as it suggests using different notation to avoid ambiguity. By providing a specific suggestion for improvement, the comment helps the authors enhance the clarity and readability of their draft. However, it could be more helpful if it included examples of how to implement the suggested change or discussed the broader implications of this confusion. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for maximum benefit."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the clarity of the concept of state, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions\" in the context of the paper. It suggests that more elaboration is needed to clarify this. While the comment identifies an area for improvement, it does not provide explicit guidance on how to elaborate or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors can infer that more explanation is needed but may not know exactly how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 186line 187,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the concept of state, questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" The comment provides a clear direction for the authors to elaborate on this concept, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept of state, specifically regarding the equivalence of \"elements\" to \"states\" or \"actions.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the concept of state in the paper, particularly in relation to the elements and their equivalence to states or actions. It provides a clear and actionable suggestion for the authors to elaborate on this concept, which is crucial for understanding the methodology and results. By pointing out this area of ambiguity, the comment helps the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered specific examples or guidance on how to elaborate on the concept of state. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the clarity of these comparisons or what specific aspects need to be clarified. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper the comment addresses, making it weakly grounded. The comment is specific in pointing out the lack of clarity in the theoretical comparisons, but without grounding, it is difficult for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the theoretical comparisons to adaptive learning of GPRGNN. However, it lacks detail and does not provide any suggestions or guidance on how the authors might clarify or enhance these comparisons. Without actionable feedback or specific examples, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is 2, as it points out a potential weakness but does not offer constructive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what alternative measures they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion about object hallucination. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the measurement approach, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and challenging to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the sufficiency of measuring object hallucination through yes/no responses, suggesting that a positive response does not necessarily indicate comprehension of the object\"s presence in the image. This feedback highlights a potential limitation in the evaluation methodology, prompting the authors to consider alternative measures or metrics for assessing object hallucination. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative approaches might be more effective. While it identifies a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what needs to be improved, but the action is not directly stated, making it 3. The authors know what needs to be done but may need to infer the exact steps to take. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the practical significance of the verylongterm forecasting task and suggests improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in suggesting improvements to the discussion, such as conducting additional experiments and using the correct forecast horizon. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests that the discussion could be improved by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. However, the comment does not provide specific examples or references to support the claim about the practical significance of the task or the need for additional experiments. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the practical significance of the verylongterm forecasting task and suggests that the discussion could be improved by conducting additional experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. This feedback is 3 as it points out a specific area for improvement in the paper, namely the need for more comprehensive experimental validation. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what datasets should be used. Overall, the comment offers a direction for improvement but lacks depth and detail, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include experiments and explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. It also questions the impact of having only spatial or temporal/summary queries. This provides a clear and direct action for the authors to take, specifying what additional experiments and explanations are needed to address the key differences between the work and VideoChatGPT and other related works. The feedback is explicit and concrete, allowing the authors to understand exactly what needs to be added to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This provides clear guidance on what additional information is required to address the key differences between the work and VideoChatGPT and other related works. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper lacks experiments and explanations regarding the different queries used in spatiotemporal representation, specifically mentioning spatial, temporal, and summary queries. The reviewer questions the impact of having only spatial or temporal/summary queries. While the comment highlights a potential gap in the paper, it does not provide specific examples or references to support the claim that these components are crucial or missing. The reasoning is based on the reviewer\"s understanding of the field, but without detailed evidence or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing experiments and explanations regarding the different queries used in spatiotemporal representation, such as spatial, temporal, and summary queries. This feedback is clear and actionable, as it directs the authors to include additional experiments and explanations that would enhance the understanding of the key differences between the work and related studies like VideoChatGPT. By addressing this suggestion, the authors can provide a more comprehensive analysis of their approach and its impact on the results. However, the comment could be more helpful if it included specific examples or references to similar works that have effectively used these queries. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more detail on the innovation of the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify what aspects of the innovation should be detailed or how the authors should present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context on the innovation, but they are not given clear guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify which part of the paper this combination is discussed in, making it difficult for the authors to identify the exact section being referred to. The comment suggests that the innovation should be detailed, but it does not provide specific guidance on what aspects of the innovation need to be elaborated upon. This lack of grounding and specificity makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovation should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed FRM, noting that it is a simple combination of channel and spatial attention mechanisms. It suggests that the innovation should be detailed, implying that the authors should provide more context or explanation about the novelty of their approach. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the innovation should be elaborated upon or how to present this information. While it highlights an area for improvement, the feedback is 3 as it points out a potential weakness but does not offer actionable advice for addressing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider mentioning the social impact of increased automation or the risks associated with the dual use of their method, given that the authors state there are no negative social impacts. While the comment implies that the authors should address this aspect, it does not provide explicit instructions on how to do so or what specific points to include. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on social impact. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line number (379) where the authors state that they foresee no negative social impacts of their work. This provides clear guidance on where the authors should address this issue. The comment is also specific because it suggests that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method, which provides clear direction on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" claim that their work has no negative social impacts and suggests that increased automation and the dual use of their method could pose risks. However, the comment does not provide specific examples or references to support the claim that the work has the potential for negative social impact. The reviewer\"s own opinion is expressed but lacks detailed reasoning or evidence to substantiate the claim. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential oversight in the paper\"s discussion of societal impact, specifically questioning the authors\" assertion that their work has no negative social impacts. It suggests that the authors should consider mentioning the social impact of increased automation or the risks associated with the dual use of their method. This feedback is 3 as it points out an area where the authors might have overlooked potential implications of their work. However, it could be more helpful if it provided specific examples or guidance on how to address these concerns. Overall, the comment offers a direction for improvement but lacks depth and detail, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of connection between the improved variance control of prediction y^ and the smoothness of the loss landscape with zeroshot learning effectiveness. It suggests that the authors need to provide more details to clarify this connection. However, the comment does not explicitly instruct the authors on how to achieve this clarification or what specific details should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context or examples to strengthen the connection. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" However, it does not specify which part of the paper this connection is discussed in, making it weakly grounded. The comment is specific in detailing the issue of poor clarity and the need for more details to clarify the connection. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness,\" suggesting that the paper lacks clarity. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It highlights that the paper\"s explanation is unclear, suggesting that the authors need to provide more details to clarify this connection. However, the comment does not offer specific suggestions or examples on how to improve the clarity or what additional information should be included. While it points out a significant issue, the feedback lacks actionable guidance, making it 3. The authors are aware of the need for clarification but are left to infer the specific steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to perform these analyses. The suggestion is concrete in terms of what needs to be addressed, but the action is inferred rather than explicitly stated. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the results section or discussion, but this inference is not explicit. The comment is specific in detailing what additional analyses are needed, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide specific examples or references to support the claim that these approaches are indeed superior. The suggestion is based on a logical inference that the authors should investigate these aspects, but without detailed evidence or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions in NAS, and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the depth and novelty of their work. By suggesting these additional analyses, the comment offers a concrete path for improving the paper\"s contribution and understanding of the results. However, it could be more helpful if it included specific examples or references to support the claim that these approaches are indeed superior. Overall, the comment is 4, as it provides valuable guidance for enhancing the draft\"s depth and impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for a citation to be provided for the discussion of the kmax problem. This is a clear and direct request, giving the authors a specific action to take: identify and include the relevant citation. The comment is explicit and concrete, providing clear guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"kmax problem,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a citation for the discussion of the kmax problem, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for a citation, which is a factual statement rather than a claim or opinion. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking for a citation to be provided for the discussion of the kmax problem. This is a specific and direct request that helps the authors identify and address a gap in their paper. By providing this feedback, the reviewer is guiding the authors towards improving the completeness and accuracy of their references, which is valuable for enhancing the credibility and comprehensiveness of their work. However, the comment could be more helpful if it offered additional context or suggestions on how to find or include the relevant citation. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. It explicitly asks for clarification on these aspects, providing a clear and direct action for the authors to take. The comment specifies what needs to be addressed, namely the estimation process and the reliability of the model, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of information regarding the estimation of the function for the optimal sequence length and the reliability of the model. However, it does not provide any specific reasoning, examples, or references to support why this information is crucial or how its absence impacts the paper. The claim is based on a logical assumption that the authors should provide more details, but without additional context or evidence, it remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient justification or evidence to fully support it.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by questioning the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This feedback is clear and actionable, as it directs the authors to provide additional details or justification for their model\"s reliability. By addressing this issue, the authors can enhance the transparency and robustness of their work. However, the comment could be more helpful if it suggested specific ways to estimate the function or provided examples of how to assess model reliability. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to modify the statement \"thousands\" in the text to \"on the subword level.\" This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed and how to implement the correction. The feedback is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the phrase \"thousands\" is not accurate and recommending the addition of \"on the subword level.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests a correction to the text, specifically recommending the change from \"thousands\" to \"on the subword level.\" This is a factual statement that does not contain subjective opinions or claims, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the accuracy of a statement in the text. By recommending the change from \"thousands\" to \"on the subword level,\" the reviewer offers a clear and direct way for the authors to enhance the precision and clarity of their writing. This feedback is valuable as it helps the authors correct a potential error in their manuscript, ensuring that the information is presented accurately. However, the comment could be more helpful if it explained why this change is necessary or provided additional context. Overall, the comment is 4, as it guides the authors in making a specific improvement to their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. The first issue is explicit, as it directly instructs the authors to provide the missing hyperparameters. The second issue is more implicit, as it suggests that the authors clarify the y value at x=0 in the figures. While the comment does not provide specific guidance on how to clarify this, the authors can infer that they need to address this aspect in their description. Overall, the comment is 4, as it provides clear guidance on what needs to be addressed but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses two specific issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. It provides explicit references to \"Fig 3,\" allowing the authors to accurately identify the parts of the paper being addressed. The comment is specific in detailing what needs to be clarified or addressed, such as providing the missing hyperparameters and explaining the y value at x=0. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two issues: the absence of hyperparameters and the unclear y value at x=0 in the latent path figures. The first issue is a factual observation that requires clarification, while the second is a suggestion for further analysis. The comment does not contain subjective opinions or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. It points out the absence of hyperparameters, which is a critical aspect of any experimental setup, and suggests that the authors clarify the y value at x=0 in the latent path figures. These are actionable suggestions that can help the authors enhance the clarity and completeness of their work. However, the comment could be more helpful if it provided additional guidance or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It suggests that the exact contribution(s) need to be written more clearly in the Introduction. Additionally, it points out that the material supporting the main contributions seems to be in the appendix rather than the main sections, such as the deeprag algorithm or discussion on high concurrency. While the comment highlights specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the contributions in the Introduction and ensure that supporting material is appropriately integrated into the main sections. The action is implicit and somewhat vague, as it does not offer detailed guidance on implementation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It specifically mentions Figure 1 and suggests that the exact contribution(s) need to be written more clearly in the Introduction. Additionally, it points out that the material supporting the main contributions seems to be in the appendix rather than the main sections, such as the deeprag algorithm or discussion on high concurrency. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the introduction and main sections of the paper. The comment is specific in detailing what needs to be addressed, such as clarifying contributions and ensuring that supporting material is appropriately integrated. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It also suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the nature of the forward referencing and the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained in later sections. It suggests that the exact contribution(s) need to be written more clearly in the Introduction, which is a valuable piece of feedback for the authors to address. Additionally, the comment points out that the material supporting the main contributions seems to be in the appendix rather than the main sections, such as the deeprag algorithm or discussion on high concurrency. This observation is helpful as it directs the authors to ensure that their contributions are clearly presented and accessible to the reader. However, the comment could be more helpful if it provided specific suggestions on how to improve the clarity of the contributions or how to integrate the supporting material into the main sections. Overall, the comment is 4 as it highlights areas for improvement and provides some guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy. It specifically asks for an error bound in terms of epsilon, which is a clear and explicit request for additional information. The authors are given a direct action to provide this information, making the comment 5. The feedback is concrete and provides a specific direction for improvement, ensuring that the authors know exactly what needs to be addressed.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the rounding of core tensors is discussed, allowing the authors to accurately identify the section being addressed. It is also specific because it questions the theoretical effect of rounding on the approximation error and asks for an error bound in terms of epsilon. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy. It asks for an error bound in terms of epsilon, which is a logical inquiry seeking clarification on the approximation error. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for an error bound or to explain why it is important. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides a question but lacks sufficient support or evidence to fully substantiate the need for an error bound.", "helpfulness_rationale": "The review comment raises a specific question about the theoretical effect of rounding core tensors to smaller ranks with a given accuracy. It asks for an error bound in terms of epsilon, which is a relevant and detailed inquiry that could help clarify the approximation error in the full tensor. This feedback is clear and actionable, providing the authors with a specific area to address and improve upon. However, it could be more helpful if it suggested how the authors might derive or present this error bound. Overall, the comment is 4 as it directs the authors to a critical aspect of their work that needs further clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the presentation of test settings in the visual dialog domain. It highlights that while there are two test settings, only the discriminative setting is shown in Table 1, and it questions the applicability of the discriminative setting in realworld scenarios. The reviewer explicitly asks for the results on the generative setting, providing a clear and direct action for the authors to take. This feedback is explicit and concrete, as it specifies exactly what needs to be addressed and how to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"visual dialog,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the presentation of test settings, questioning the applicability of the discriminative setting and requesting results on the generative setting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the presentation of test settings in the visual dialog domain, specifically noting that only the discriminative setting is shown in Table 1, while the generative setting is not. The reviewer points out that the discriminative setting is not applicable in realworld scenarios, implying that the results on the generative setting are necessary for a comprehensive evaluation. However, the comment lacks specific examples or references to support the claim that the discriminative setting is not applicable in realworld scenarios, making it 3. The authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of test settings in the visual dialog domain. It points out that while there are two test settings, only the discriminative setting is shown in Table 1, and questions the applicability of the discriminative setting in realworld scenarios. The reviewer explicitly asks for the results on the generative setting, providing a clear and actionable feedback. This comment is helpful as it directs the authors to a specific area of improvement and offers a clear path for enhancing the completeness and relevance of their results. However, it could be more helpful if it provided additional context or suggestions on how to present the generative setting or why it is important. Overall, the comment is 4, as it effectively guides the authors towards addressing a significant gap in their paper."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the effectiveness of the proposed approach for other language families, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to investigate the effectiveness of their approach for other language families. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the effectiveness of the proposed approach for other language families, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section, table, or figure this comment pertains to, as there is no explicit reference or mention of specific elements. Additionally, the comment lacks specificity regarding what needs to be addressed or improved to address the concern about effectiveness. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the effectiveness of the proposed approach for other language families, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to similar work, the authors are left without guidance on how to address the issue or improve their approach. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, specifically questioning its effectiveness for other language families. This is a valid concern that could impact the broader applicability of the work. However, the comment lacks actionable feedback or suggestions on how the authors might address this issue or explore the effectiveness of their approach for other language families. Without specific guidance or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not provide actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to describe the form of p near line 135, indicating that it is assumed to be a Gaussian distribution but not explicitly stated. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the description of the form of p, and it assumes it is a Gaussian distribution but is not explicitly stated. This provides clear guidance on what the authors need to include or clarify in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, assuming it is a Gaussian distribution but not explicitly stated. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion by pointing out the need to describe the form of p near line 135. It assumes that p is a Gaussian distribution but notes that this is not explicitly stated. This feedback is specific and helps the authors understand where additional information is required to clarify their methodology. However, it could be more helpful if it provided a brief explanation of why this clarification is important or how it might impact the paper. Despite this, the comment is 4 as it directs the authors to a specific area needing improvement and offers a clear path forward. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the named works. However, it does not specify which specific works need more detailed descriptions or how the authors should go about providing this information. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed descriptions of the differences between the named works. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not specify which specific works are being referred to or what aspects of the differences need to be described. This lack of specificity makes it difficult for the authors to identify the exact parts of the paper that need revision. The comment is weakly grounded because it does not provide explicit references to sections or specific works, and it is not specific about what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between named works. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand which works are being referred to or what aspects need more detailed descriptions. Without detailed examples or references, the claim is not 5, as it lacks the necessary evidence to substantiate the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the related work section, suggesting that more detailed descriptions of the differences between named works are needed. This feedback is 3 as it points out a potential weakness in the paper\"s presentation of related work. However, it lacks depth and does not provide specific guidance on how the authors might enhance the related work section or what aspects of the differences should be described. To be more helpful, the comment could include examples of how the differences could be described or suggest specific works that might benefit from more detailed analysis. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by looking at PPP maps. While the comment implies that the authors should provide this explanation, it does not specify how to do so or what aspects of the explanation are needed. The action is implicit and somewhat vague, as the authors know they need to provide an explanation but may not know exactly how to structure it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of reliable PPP metrics and the lack of explicit explanation in the article. It suggests that the authors should provide an explicit explanation of what type of understanding one can gain by looking at PPP maps. While the comment does not specify a particular section of the paper, it is clear that it pertains to the discussion or conclusion sections where the authors might address the importance of PPP metrics. The comment is specific in its request for an explanation, but it lacks full grounding as it does not explicitly mention a section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the lack of explicit explanation regarding the importance of reliable PPP metrics for understanding PPP effects in different tasks. It suggests that the authors should provide a more detailed explanation of what type of understanding one can gain by looking at PPP maps. While the comment identifies a gap in the article, it does not provide specific examples or references to support the claim. The reasoning is based on the authors\" statement about the importance of PPP metrics, but without further elaboration, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the article by noting that while the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, this explanation is not explicitly provided in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by looking at PPP maps. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the concept, which could enhance the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it offered specific suggestions on how to structure this explanation or what aspects of understanding are crucial to highlight. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. This lack of comparison is noted as a potential issue regarding the credibility of the work. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific methods to include for comparison. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional comparisons to enhance the credibility of their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment points out a lack of comparison with stateoftheart methods for spanrelated tasks, specifically mentioning SpanBERT. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for comparison with other methods, which is a clear direction for improvement. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors lack credibility due to not comparing their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT. However, the comment does not provide specific examples or references to support the claim that SpanBERT or other methods are the only relevant ones. Without detailed justification or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with stateoftheart methods for spanrelated tasks, such as SpanBERT. This feedback is important as it highlights a potential weakness in the credibility and comprehensiveness of the work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending particular methods to include for comparison or how to structure these comparisons. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for enhancement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the training process for RBI, suggesting that rewardless actions with useful supervision, such as \"No, the answer is Timothy Dalton.\" in Task 3, are being ignored. It implies that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The reviewer also questions whether the authors should provide a stronger baseline for RBI, supervised by such feedback, to prove its usefulness. While the comment highlights a potential issue and suggests a direction for improvement, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to implement the suggested baseline. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the training process for RBI, noting that rewardless actions with useful supervision are being ignored. It suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The reviewer also questions whether the authors should provide a stronger baseline for RBI, supervised by such feedback, to prove its usefulness. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the training process and the comparison between FP + RBI and RBI alone. The authors can infer that it relates to the experimental setup or results, but the comment is specific in detailing the issue and suggesting a potential improvement. Therefore, this comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the training process for RBI, suggesting that rewardless actions with useful supervision are being ignored. The reviewer implies that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The suggestion to provide a stronger baseline for RBI, supervised by such feedback, is a logical response but remains somewhat vague without further elaboration. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a specific concern about the training process for RBI, noting that rewardless actions with useful supervision are being ignored. It suggests that this could be a significant factor contributing to the performance of FP + RBI over RBI alone. The reviewer also questions whether the authors should provide a stronger baseline for RBI, supervised by such feedback, to prove its usefulness. This feedback is clear and actionable, as it identifies a potential weakness in the current experimental setup and suggests a direction for improvement. By addressing this concern, the authors could enhance the robustness of their findings and provide a more comprehensive evaluation of their methods. Therefore, the comment is rated as 4, as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the multiscale statement, suggesting that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the multiscale statement or provide a more accurate explanation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the multiscale statement, specifically pointing out that the slow and fast RNN operate on the logical time scale rather than the physical time scale. This provides a clear and specific critique of the statement, allowing the authors to identify the part of the paper being discussed. The comment also specifies the issue with the multiscale statement, namely the reduction in gradient path by the slow RNN. This level of detail makes the comment 5, as it clearly identifies the part of the paper being addressed and what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the multiscale statement is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer provides a logical explanation by clarifying that the stacks are sequentialized in the graph, which supports the claim. However, the comment lacks specific references or examples to further substantiate the claim, making it 3. The authors would need to delve deeper into the explanation to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the multiscale statement, pointing out that the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. This feedback is 3 as it identifies a potential issue with the multiscale statement and provides a clear explanation of the problem. However, the comment could be more helpful if it suggested ways for the authors to address this issue or offered alternative explanations. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should clarify the distinction between the decision maker\"s interest in the true objective function and the noise, which is typically assumed to be noise. The comment provides a clear action for the authors to take, which is to make this distinction more explicit in the formulation. This guidance is concrete and provides a direct path for the authors to improve their draft by addressing the specific issue of clarity. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the formulation, which is the distinction between the decision maker\"s interest in the true objective function and the noise, which is assumed to be noise. The comment suggests that this distinction should be clarified upfront. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the typical use of expected performance under observation noise for evaluation is misleading because the decisionmaker is interested in the true objective function and the noise is assumed to be noise. The reviewer suggests that the formulation in the paper should clarify this distinction. While the comment provides a logical argument, it lacks specific examples or references to support the claim that the typical use is misleading. This makes the claim 3, as the authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formulation of the paper, noting that the decision maker\"s interest is in the true objective function, not the noise, which is typically assumed to be noise. The comment suggests that this distinction should be clarified upfront to avoid potential confusion. This feedback is clear and actionable, as it provides a specific area for improvement that can enhance the clarity and accuracy of the paper. By addressing this issue, the authors can better align their work with the intended focus of the decisionmaking process. Therefore, the comment is rated as 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises two separate issues. First, it suggests that running VGAE with a vamp prior could help determine whether the benefits of the model are due to a better generative model or better inference. This is an explicit suggestion with a clear action for the authors to take. Second, it mentions a minor point regarding Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would be beneficial for comparison. This is also an explicit suggestion. Both parts of the comment provide clear and concrete actions for the authors to take, making the feedback 5.", "grounding_specificity_rationale": "The comment addresses two separate issues. The first part suggests using VGAE with a vamp prior to better match the doubly stochastic construction, which is a specific suggestion for improving the model. This part is fully grounded as it explicitly mentions the model and the specific action to take. The second part is a minor point regarding Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would be beneficial for comparison. This part is also fully grounded, as it references a specific figure and provides a clear suggestion for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using VGAE with a vamp prior to better match the doubly stochastic construction, which could help determine whether the benefits are due to a better generative model or better inference. This is a logical suggestion based on the current model setup. However, the comment does not provide specific examples or references to support the claim that the benefits are solely due to inference or generative model improvements. The suggestion is 4, as it offers a clear direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides two actionable suggestions. First, it suggests using VGAE with a vamp prior to better match the doubly stochastic construction, which could help determine whether the benefits of the model are due to a better generative model or better inference. This is a clear and specific suggestion that offers a potential avenue for improvement. Second, it points out a minor issue with Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would be beneficial for comparison. This feedback is also clear and actionable, as it provides a specific way to enhance the clarity and comparability of the results. Overall, the comment is 4 as it offers valuable insights and suggestions for improving the draft, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the demonstration or results related to the model collapsing less than other methods. It also references a specific point in the text (line 159) where gradients become 0 and collapse, asking if this is a common occurrence and if it was observed in the experiments. While the comment implies that the authors should provide evidence or results to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional results or demonstrations to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 159,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the demonstration or results related to the model collapsing less than other methods, and it references a specific point in the text where gradients become 0 and collapse. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question seeking clarification about the demonstration or results related to the model collapsing less than other methods. It references a specific point in the text (line 159) where gradients become 0 and collapse, asking if this is a common occurrence and if it was observed in the experiments. However, the comment does not contain any claims or opinions that require verification. It is purely a request for clarification, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the demonstration or results related to the model collapsing less than other methods, referencing a specific point in the text where gradients become 0 and collapse. While it identifies an area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or provide additional evidence. The feedback is 3 as it prompts the authors to consider this aspect of their work, but it does not offer actionable steps or detailed insights. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and direct action for the authors to take, which is to include these experiments to enhance the paper\"s applicability and generalizability. The suggestion is concrete, as it specifies the types of models to consider, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or methodology. This makes it difficult for the authors to identify the exact section that needs attention. While the comment is specific in suggesting the need for additional experiments, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a logical suggestion for improving the paper\"s applicability and generalizability. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It provides a clear and actionable suggestion by recommending that the authors conduct trials with models like OPT, BLOOM, or other alternatives. This feedback is valuable as it guides the authors on how to enhance the applicability and generalizability of their method. However, the comment could be more helpful if it included specific guidance on how to design and execute these experiments or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not provide specific guidance or suggestions on how the authors might strengthen these connections or improve the clarity of their presentation. The comment lacks actionable details, leaving the authors uncertain about what steps to take to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not specify which sections or parts of the paper are being discussed, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in its critique of the connections but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to sections or specific issues that need clarification, making it difficult for the authors to address the feedback effectively. As a result, the claim is considered 2, as it provides some insight but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It provides a specific example of the author\"s initial expectations, which were not met, and notes that the process could be computationally demanding. However, the comment lacks actionable suggestions or guidance on how the authors might strengthen the connections or improve the clarity of their presentation. While it identifies a potential issue, it does not offer concrete steps or examples for the authors to follow, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include results for linear scalarization + Concorde for a better comparison, given that the obtained Pareto front is not highly nonconvex. This is an explicit action that the authors can take to improve their draft. The comment also provides a specific suggestion on which baseline to include, making the action concrete. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific comparison between learningbased and heuristicbased solvers. It also references the single objective TSP and the Pareto front, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it suggests including results for linear scalarization + Concorde for a better comparison, given the nature of the Pareto front. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers outperform heuristicbased solvers in the experimental results, but the SOTA heuristicsolver (e.g., Concorde) usually has the best performance for single objective TSP. The reviewer suggests including results for linear scalarization + Concorde for a better comparison. This claim is 3 as it provides a logical reasoning based on the experimental results and the nature of the Pareto front. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of baselines in the experimental results. It points out that while learningbased solvers perform better overall, the SOTA heuristicsolver (Concorde) is typically superior for single objective TSP. The comment suggests including results for linear scalarization + Concorde to provide a more comprehensive comparison, especially since the Pareto front is not highly nonconvex. This feedback is clear and actionable, as it guides the authors to make a specific improvement to their draft by including additional results. However, it could be more helpful if it provided further context or reasoning on why this comparison is important. Overall, the comment is 4, as it offers a clear direction for enhancing the paper\"s analysis and comparison."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using topological reasoning, generalized Voronoi graphs, semantic maps, and SLAM techniques. It provides specific examples of these methods, such as the generalized Voronoi graph and semantic maps, and references to the graphbased SLAM appendix section. This feedback is explicit and provides concrete guidance on what the authors need to include in their discussion to contextualize their proposed method. The authors are given a clear action to take, which is to discuss their method in the context of these existing methods, making the comment 5.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using topological reasoning, generalized Voronoi graphs, semantic maps, and SLAM techniques. It provides specific examples of these methods, such as the generalized Voronoi graph and semantic maps, and references to the graphbased SLAM appendix section. This level of detail allows the authors to accurately identify the parts of the paper that need to be addressed, providing full grounding. The comment is also specific, as it clearly specifies what needs to be discussed in relation to the proposed method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some of the general ideas in the proposed method are already present in other methods for exploration, such as reasoning topologically and longterm storage through pose graphs in SLAM. The reviewer provides specific examples of these methods, such as those using generalized Voronoi graphs or semantic maps, and references to the graphbased SLAM appendix section. This provides a clear and detailed justification for the claim, making it 5. The authors can easily understand and address the feedback by incorporating these references and discussions into their paper. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential overlap between the proposed method and existing methods for exploration, specifically those using topological reasoning, generalized Voronoi graphs, semantic maps, and SLAM techniques. It suggests that the paper should discuss the proposed method in relation to these existing methods, providing specific examples and references to support the discussion. This feedback is clear and actionable, as it guides the authors to include a more comprehensive comparison of their method with existing approaches, which can enhance the paper\"s novelty and contribution. By addressing this suggestion, the authors can better position their work within the broader context of exploration methods, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. While the comment implies that the authors should justify their choice of architectures, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation for their architectural choices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, it does not specify which part of the paper discusses these architectures or where the improvements are mentioned. The authors can infer that it relates to the methodology section, but the comment lacks explicit grounding. It is specific in questioning the choice of architectures and their impact on performance, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this combination might be beneficial or why it could lead to improvements. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using GRU for the Pyramid and LSTM for the sequential part, asking if this combination is a reason for the improvements observed. While it identifies a potential area for improvement or explanation, it lacks specific guidance or suggestions on how the authors might address this issue or justify their architectural choices. The comment provides a starting point for the authors to consider, but it does not offer detailed feedback or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on how \"active vertices\" is defined in line 135. This request provides a clear and direct action for the authors to take, which is to explain the definition of \"active vertices.\" The comment is explicit and concrete, as it specifies exactly what information is needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the definition of \"active vertices,\" providing a clear direction for the authors to address this issue. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the definition of \"active vertices\" in line 135. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, as it identifies a specific area of confusion regarding the definition of \"active vertices\" in line 135. By asking for clarification, the reviewer provides the authors with a clear direction to improve the clarity and understanding of their work. This feedback is valuable as it helps the authors ensure that their terminology is precise and unambiguous, which is crucial for effective communication. However, the comment could be more helpful if it suggested how the authors might define \"active vertices\" or provided an example to illustrate the concept. Overall, the comment is 4 as it guides the authors toward improving the clarity of their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential theoretical limitation in the paper, specifically that the theory does not seem to be applicable to the used model. It also highlights the vagueness of unspecified structural assumptions, which are only given in the appendix, making the limitation difficult to find. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts of graph neural networks in general. While the comment identifies a specific issue and suggests a potential area for improvement, it does not provide explicit guidance on how to address these concerns or what specific aspects of the theory or assumptions should be elaborated upon. The action is implicit and somewhat vague, as the authors can infer the need for elaboration but may not know exactly how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical limitations of the paper, specifically noting that the theory does not seem to be applicable to the used model. It also points out the vagueness of unspecified structural assumptions, which are only given in the appendix, making the limitation difficult to find. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the theoretical aspects and limitations of the work. The authors can infer that it relates to the methodology or results sections, but the comment does not provide explicit references to specific parts. The suggestion for elaboration on societal impacts is specific, but the lack of explicit section references makes the comment somewhat specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the applicability of the theory to the used model and the vagueness of unspecified structural assumptions, which are only given in the appendix. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion for elaboration on societal impacts is a logical extension of the critique but is not explicitly supported by evidence or references. Therefore, the comment is 3, as it provides some justification but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential theoretical limitation in the paper, noting that the theory does not seem to be applicable to the used model. It also points out the vagueness of unspecified structural assumptions, which are only given in the appendix, making the limitation difficult to find. The reviewer suggests that the authors underestimate the current use of graph neural networks in industry and recommends providing more elaboration on potential negative societal impacts of graph neural networks in general. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is 3 as it points out potential weaknesses but does not offer detailed advice on how to enhance the paper. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue regarding the projection head and classification head in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their draft. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the projection head and classification head in the paper, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or experimental setup, but they cannot confidently determine the exact section being addressed. The comment is specific in identifying the issue with the classification head, but it lacks grounding as it does not specify the exact part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that only the projection head (CNN layers) is affected but not the classification head (FCN layer). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue regarding the distinction between the projection head (CNN layers) and the classification head (FCN layer) in the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their work. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the generalization of the focusing distance beyond the 1m and 5m distances shown in Figure 8. It suggests that the authors should consider focusing distances that are not present in the training data to evaluate the model\"s generalization capabilities. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions or concrete steps on how to conduct this evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should explore generalization beyond the training data. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the generalization of the focusing distance beyond the 1m and 5m distances shown in the figure, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalization of the focusing distance beyond the 1m and 5m distances shown in Figure 8. It suggests that the authors should consider focusing distances not present in the training data to evaluate the model\"s generalization capabilities. While the comment is a request for further exploration, it does not contain a claim or an opinion that requires verification. It is a factual question seeking clarification, making it a normal statement. Therefore, the label \"No\" is appropriate.", "helpfulness_rationale": "The review comment raises a valid concern about the generalization of the focusing distance in Figure 8, which only shows distances of 1m and 5m. It suggests that the authors should consider focusing distances not present in the training data to evaluate the model\"s generalization capabilities. This feedback is clear and actionable, as it directs the authors to an important aspect of their work that needs further exploration. However, the comment could be more helpful if it provided specific suggestions on how to investigate this issue or what focusing distances to consider. Overall, the comment is 4 as it identifies a potential weakness and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. While the comment implies that the authors should reevaluate their definitions and consider a broader perspective, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. However, the comment does not specify which part of the paper this discussion should be addressed in, making it weakly grounded. The authors can infer that it relates to the discussion or methodology sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed regarding the definitions of \"style\" and \"movement dynamic,\" providing clear guidance on how to improve the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. However, the comment does not provide specific examples or detailed reasoning to support the claim that the authors\" definitions are unclear or incorrect. The reference to Gabbay & Hosehn (2018) is a step towards justification, but it lacks detailed explanation or specific examples to fully substantiate the claim. Therefore, the comment is 3, as it provides a general direction for improvement but lacks comprehensive support.", "helpfulness_rationale": "The review comment suggests that the authors should consider defining content and style more broadly in relation to their neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the authors\" understanding of \"style\" and \"movement dynamic\" in their model, which is not sequential and does not capture temporal dynamics. This feedback is 3 as it points out a potential area for improvement in the authors\" definitions and understanding of key concepts. However, it lacks specific guidance or suggestions on how the authors might redefine these terms or address the issues raised. The comment provides a direction for improvement but does not offer detailed steps or examples, which could make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides detailed feedback on the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. The comment explains that the proposed approach does not improve the phenomenon of information distortion, as evidenced by the variance difference in the figures. It also references existing work in the NLP domain to highlight the commonality of this issue. While the comment provides specific examples and references, it does not explicitly instruct the authors on how to address these issues or improve their analysis. The feedback is detailed and informative, but the lack of explicit guidance makes it 3. The authors can infer the need for a more detailed analysis and comparison, but the exact steps to take are not clearly outlined.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"Line 45,\" \"Fig1(b),\" and \"Fig5(b),\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the analysis of vit quantification, including the claim that the direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. Additionally, it references existing work in the NLP domain to highlight the commonality of the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point presents a claim that the direct quantization method leads to information distortion and that the proposed approach does not improve this phenomenon. It provides specific examples from figures (Fig1(b) and Fig5(b)) to support the claim. Additionally, it references existing work in the NLP domain to highlight the commonality of this issue, which adds credibility to the claim. However, the comment could be strengthened by providing more detailed reasoning or references to support the assertion that the proposed approach does not improve the phenomenon of information distortion. Despite this, the claim is 4 due to the provided examples and references to existing work.", "helpfulness_rationale": "The review comment provides detailed feedback on the analysis of vit quantification, specifically addressing two issues: (a) the direct quantization method leading to information distortion and (b) the quantization of MHSA introducing a large loss of precision. It points out that the proposed approach does not improve the phenomenon of information distortion, as evidenced by the variance difference in the figures. Additionally, it references existing work in the NLP domain to highlight the commonality of this issue. This feedback is valuable as it offers specific examples and references to help the authors understand and address the limitations of their analysis. However, the comment could be more helpful if it provided suggestions on how to improve the analysis or further explore these issues. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a main weakness in the work, which is the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It also points out that the proposed Xtransformation is similar to STN but applied locally, and that PointNet uses a variant of STN. The comment suggests that the technical novelty is limited and that there should be empirical or conceptual comparisons to STN. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific comparisons or analyses should be conducted. The action is implicit and somewhat vague, as the authors can infer the need for comparisons and novelty enhancements but lack detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the technical novelty of the work, specifically regarding the use of spatial transformer networks (STN) and the proposed Xtransformation. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture. However, the comment does not specify which part of the paper discusses STN or the proposed Xtransformation, making it weakly grounded. The comment is specific in detailing the issues with technical novelty and the lack of comparisons, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty with respect to spatial transformer networks (STN) and does not provide comparisons to existing works that use STN. It also notes that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it points out that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty of the work is limited. The comment provides specific references to existing works and highlights the similarity between the proposed Xtransformation and STN, which supports the claim. However, it could be strengthened by providing more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides a strong basis for the claim but lacks some specific details.", "helpfulness_rationale": "The review comment identifies a main weakness in the work, specifically regarding the lack of technical novelty in the use of spatial transformer networks (STN) and the absence of comparisons to existing works that use STN. It points out that the proposed Xtransformation is similar to STN but applied locally, and mentions existing works that apply STN in a local pixel neighborhood. Additionally, it notes that PointNet uses a variant of STN in their network architecture, suggesting that the technical novelty of the work is limited. The comment also highlights the importance of empirical or conceptual comparisons to STN. While the feedback is clear in identifying areas for improvement, it could be more helpful if it provided specific suggestions on how to enhance the technical novelty or what comparisons should be made. Overall, the comment is 4 as it provides valuable insights into the work\"s shortcomings and potential areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take. It suggests correcting a labeling error in the supplementary material (Row 821, \"Fig.7\" should be \"Fig.12\") and recommends attaching proof links to each theorem and corollary in the main paper for easier reader navigation. Additionally, it highlights concerns about motivation, methodology soundness, and experiment persuasion. While the comment does not specify how to address these concerns, it provides clear and actionable steps for the authors to take. The feedback is 4 because it outlines specific actions that the authors can take to improve their draft, but it could be more detailed in terms of how to address the concerns about motivation, methodology, and experiment persuasion. Therefore, the comment is rated as 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31\" and \"Fig.7,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue with the labeling error and provides a clear suggestion for improvement by recommending the attachment of proof links to each theorem and corollary in the main paper. Additionally, it highlights concerns about motivation, methodology soundness, and experiment persuasion. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a mix of factual statements and suggestions. The factual statements, such as the correction of a labeling error, are clear and verifiable. However, the suggestion to attach proof links to each theorem and corollary in the main paper is not fully supported by evidence or reasoning. While it is a logical suggestion, it lacks specific examples or references to justify why this would improve the paper. Therefore, the comment is 4, as it provides some support but could be strengthened with more detailed justification.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two distinct issues: a labeling error in the supplementary material and the need to attach proof links to theorems and corollaries in the main paper. The suggestion to correct the labeling error is clear and directly addresses a formatting issue, which is important for maintaining the integrity of the paper. The recommendation to attach proof links to theorems and corollaries is also constructive, as it enhances the reader\"s ability to follow the paper\"s logic and understand the theoretical foundations. Additionally, the comment raises concerns about motivation, methodology soundness, and experiment persuasion, which are important areas for the authors to address. While the feedback does not provide detailed guidance on how to improve these aspects, it highlights critical areas for the authors to consider. Overall, the comment is 4 as it offers actionable suggestions and identifies areas for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of a series of questions that seek clarification on specific aspects of the paper. The first question asks about the missing determiner in the definition, while the second question inquires about the selection of 50 classes and their explicit tagging as action verbs by Levin. The third question asks about the concept of \"action frames\" and how they are chosen. These questions provide explicit actions for the authors to take, such as clarifying the missing determiner and explaining the selection of action verbs and frames. However, the comment lacks concrete guidance on how to address these issues, such as suggesting specific changes or providing examples. While the actions are clear, the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3\" and \"306ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the definitions and selection of action verbs and frames, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the definition of \"determiner,\" the selection of 50 classes, and the tagging of action verbs. These questions are not claims but rather requests for clarification, making them normal statements. Therefore, they do not require verification and should be labeled as \"No.\"", "helpfulness_rationale": "The review comment consists of a series of questions seeking clarification on specific aspects of the paper, such as the definition of \"determiner,\" the selection of 50 classes, and the tagging of action verbs. While the questions provide valuable insights into areas that need clarification, they do not offer actionable feedback or suggestions on how to improve the draft. The authors are left with a list of questions but without guidance on how to address them or enhance the clarity and coherence of their work. Therefore, the comment is 3, as it identifies areas for improvement but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point is explicit and direct, instructing the authors to correct a spelling error in the text. The action is clear and concrete, as it specifies exactly what needs to be changed (\"Empiically\" should be \"Empirically\"). This provides the authors with a straightforward task to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the text, \"Empiically\" should be \"Empirically.\" This provides clear guidance on what needs to be corrected, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual correction regarding a spelling error in the text, \"Empiically\" should be \"Empirically.\" It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor typographical error in the text, specifically correcting \"Empiically\" to \"Empirically.\" While this is a small and straightforward issue, it is important to address to ensure the accuracy and professionalism of the manuscript. However, the comment does not provide any additional context or suggestions for improvement, such as how this error might impact the clarity or professionalism of the paper. Therefore, the comment is 3, as it highlights a specific error but lacks depth and actionable guidance for the authors. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and rawlevel features, while the former framework (Line 167174, Sec. 4) does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment highlights a specific area for improvement, it does not provide explicit guidance on how to incorporate representation learning or what specific aspects of feature selection need enhancement. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed instructions on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. Additionally, it suggests that the feature selection in Section 4.2 could be improved by considering representation learning. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed invariant learning module focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment identifies a potential issue with the focus of the proposed module, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of representation learning in the appendix provides some context but does not offer explicit guidance on how to address the issue. Therefore, the comment is 3, as it provides some support but requires more detailed justification or examples to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and rawlevel features, while the former framework does not seem limited to rawlevel selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to incorporate representation learning or what specific aspects of feature selection need enhancement. The feedback is 3 as it points out a potential gap in the paper but does not provide comprehensive suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to clarify or provide more information about the design of rewards, but it does not offer concrete steps or examples of what should be included. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific area where details are missing, mentioning the lack of understanding of how to design rewards. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the draft lacks detail, specifically mentioning the lack of understanding of how to design rewards. This feedback is 3 as it points out a gap in the paper that needs attention. However, it does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of reward design should be clarified. To be more helpful, the comment could include examples or references to similar works that might provide insight into designing rewards. Overall, the comment offers some direction but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the runtime of Prithvi WxC should be discussed as a potential limitation for MLbased emulators of climate model parametrizations, given its large parameter count. While the comment implies that the authors should address the runtime, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the runtime. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the runtime of Prithvi WxC as a potential limitation for MLbased emulators of climate model parametrizations, given its large parameter count. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the importance of runtime as a limitation, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be placed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the runtime of Prithvi WxC should be discussed as a potential limitation for MLbased emulators of climate model parametrizations, given its large parameter count. While the comment implies that runtime is a relevant aspect, it does not provide specific reasoning or evidence to support why this is a critical consideration. The claim is 3 as it highlights a potential issue but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of Prithvi WxC, specifically its runtime, which is relevant for MLbased emulators of climate model parametrizations. It suggests that the runtime should be discussed as a limitation, given the large parameter count. This feedback is clear and actionable, as it provides a specific area for the authors to address in their draft. However, the comment could be more helpful if it offered suggestions on how to discuss the runtime or provided examples of similar discussions in the literature. Overall, the comment is 4 as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific guidance or suggestions on how the authors might address this issue or clarify the contribution. The comment lacks explicit or implicit actions for the authors to take, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the framing are oversold or how the contribution could be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it difficult to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide specific examples or detailed feedback on how the authors might address this issue or clarify the contribution. Without actionable guidance or suggestions, the comment lacks depth and does not offer the authors a clear path to improve their draft. As a result, the comment is 2, as it identifies a potential problem but does not provide the authors with the necessary information to address it effectively."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of ensuring that the paraphrases generated for the training data are significantly different from the original sentences. It explains that this is crucial because the model relies on the quality of these paraphrases, and if the difference is not large enough, the final training data quality will be low, leading to a limited number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide specific guidance on how to address it, such as suggesting methods to ensure significant differences or how to measure the quality of the paraphrases. The action is implicit and somewhat vague, as the authors can infer the need to improve the paraphrasing process but lack concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"generating paraphrases for the training data,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the difference between paraphrases and original sentences, explaining how this affects the quality of the final training data and the subsequent discarding process. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the quality of the final training data depends on the difference between paraphrases and original sentences. This claim is 3 as it provides a logical reasoning that the quality of the training data is crucial for the model\"s performance. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue in the paper regarding the generation of paraphrases for the training data. It highlights the importance of ensuring that the paraphrases are significantly different from the original sentences, as this directly impacts the quality of the final training data and the model\"s performance. The comment provides a clear explanation of why this is important and how it affects the subsequent steps in the process. However, it lacks specific suggestions or guidance on how to address this issue, such as methods to ensure significant differences or how to measure the quality of the paraphrases. While it points out a significant area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a mix of explicit and implicit actions. It explicitly acknowledges that identifying rationales is a challenging problem, particularly for complex NLP tasks like machine translation. However, it also suggests that the paper is wellorganized and easy to follow, which is a positive observation. The comment implicitly suggests that Figure 2 is cluttered and recommends using another color or a bigger font to improve the visibility of the human identified rationales. While the action to improve Figure 2 is clear, the comment lacks specific guidance on how to implement these suggestions. The authors know they need to address the clutter in Figure 2, but the feedback is somewhat vague on the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2\" and \"the \"bold\" text,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with Figure 2 being cluttered and the difficulty in reading the \"bold\" text, suggesting a solution to improve visibility. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point acknowledges that identifying rationales is a challenging problem, particularly for complex NLP tasks like machine translation. This is a logical observation based on the nature of the task. The comment also provides a specific suggestion for improving Figure 2 by recommending a change in color or font size to enhance visibility. While the suggestion is clear, it lacks detailed reasoning or evidence to fully substantiate the claim about the difficulty of identifying rationales. Therefore, the comment is 4, as it provides a logical basis for the claim but could be strengthened with additional justification or examples.", "helpfulness_rationale": "The review comment provides a mix of positive and constructive feedback. It acknowledges that identifying rationales is a challenging problem, particularly for complex NLP tasks like machine translation, which is a relevant observation. However, the comment also highlights a specific issue with Figure 2, noting that it is cluttered and the \"bold\" text is hard to see. It suggests a potential solution by recommending the use of another color or a bigger font to improve visibility. While the comment identifies a problem, it could be more helpful if it offered more detailed guidance on how to address the clutter in Figure 2 or provided examples of how to improve visibility. Overall, the comment is 4 as it points out a specific area for improvement but lacks comprehensive suggestions for implementation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing could be improved, but it does not provide specific guidance on how to achieve this improvement. The authors are left without any explicit or implicit actions to take, such as suggestions for clearer explanations, rephrasing, or additional examples. Without concrete details or examples of what needs to be improved, the authors are unable to determine how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing could be improved, but it does not specify which parts of the paper are difficult to understand or where the theoretical analysis is unclear. This lack of specificity makes it challenging for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any guidance on how to enhance the writing or what specific issues should be addressed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing could be improved, but it does not provide any specific examples or reasoning to support this claim. The reviewer mentions that it took a lot of effort to understand the main idea and theoretical analysis, but without further explanation or evidence, the comment lacks verifiability. The authors are left without guidance on how to improve the writing or what specific aspects need clarification. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing could be improved, noting that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how to enhance the writing. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their work. The reviewer is willing to improve their score if the authors can address these concerns. While the comment implies an action, it does not provide explicit guidance on how to address the lack of novelty or theoretical contribution. The authors are left to infer that they need to provide more detailed explanations or evidence of novelty, but the comment lacks concrete steps or examples. Therefore, the comment is 3, as it identifies a specific area for improvement but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment addresses the theoretical novelty of the proposed method, noting that it primarily builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their work. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction or methodology sections, making it weakly grounded. The comment is specific in identifying the lack of theoretical novelty and suggesting a potential area for improvement, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks significant theoretical novelty, primarily because it builds upon existing methods such as ClopperPearson intervals and Gaussian elimination. The reviewer provides references to specific works by Clopper and Pearson, as well as Golub and Van Loan, which support the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed method adds value beyond these existing methods. While the references are a strong point, the lack of additional context or detailed analysis makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, noting that it primarily builds upon existing methods and lacks significant theoretical novelty. The reviewer acknowledges their willingness to improve the score if the authors can address this concern. However, the comment lacks specific suggestions or guidance on how the authors might enhance the theoretical contribution or differentiate their work from existing methods. While it highlights an important area for improvement, the feedback is 3 as it provides a direction for the authors to consider but does not offer detailed or actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the text input is concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what steps they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the text input is concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. Without specific grounding, the authors cannot confidently determine where to focus their attention. The comment is specific in its inquiry about the concatenation of text elements, but the lack of grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the concatenation of text elements in the text input. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the text input is concatenated by the four text elements of an object. While it identifies a potential area for clarification, it does not provide any context, reasoning, or suggestions on why this is important or how it might impact the paper. Without additional information or guidance, the authors are left without actionable feedback on how to address this question or improve their draft. Therefore, the comment is 2, as it lacks depth and specificity, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment explicitly identifies a specific sentence in the abstract as being cumbersome and suggests that it can be made clearer. However, it does not provide any guidance on how to achieve this clarity or what specific changes should be made. The authors are left with a clear understanding of what needs to be improved but are not given concrete steps on how to implement the suggested changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions for execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lines 1217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the sentence, which is its cumbersome nature and suggests that it can be made clearer. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the sentence in lines 1217 is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific reasoning, examples, or references to support why the sentence is cumbersome or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the abstract, noting that the sentence in lines 1217 is cumbersome and suggesting that it can be made clearer. While the comment highlights a potential problem, it does not provide any guidance on how to improve the clarity or what specific changes should be made. This lack of actionable feedback limits the usefulness of the comment for the authors, as it does not offer concrete steps or suggestions for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the fairness of the comparisons made between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zeroshot singleimage 3D reconstruction models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the comparison of the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, particularly in relation to the fairness of comparisons to zeroshot singleimage 3D reconstruction models. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. While the authors can infer that it relates to the comparison section, the lack of explicit grounding makes it difficult for them to pinpoint the exact part of the paper being addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the comparisons between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D are unfair, particularly when compared to zeroshot singleimage 3D reconstruction models. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment critiques the fairness of the comparisons made between the domainspecific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zeroshot singleimage 3D reconstruction models. While it identifies a potential issue with the methodology, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their comparisons. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. While the comment implies that the authors should expand their evaluation to include more scenarios, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation section, specifically mentioning the reliance on 4 OCR QA datasets and the need for more scenarios like the LLaVA benchmark. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the limited evaluation and suggests including more scenarios for ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, relying mostly on 4 OCR QA datasets, and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. The claim is 3 as it points out a specific limitation in the evaluation and suggests a potential improvement. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to provide more context or evidence to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation, specifically noting that it relies heavily on 4 OCR QA datasets and suggests that more scenarios like the LLaVA benchmark should be included, especially in ablation studies. This feedback is 3 as it points out a potential weakness in the current evaluation and provides a clear suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to incorporate these additional scenarios or what aspects of the evaluation should be expanded. Overall, the comment provides a direction for improvement but lacks depth, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the abstract visual reasoning tasks, noting that they are unintuitive and difficult to solve. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. However, the comment does not specify which part of the paper these tasks are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the tasks are problematic or how they could be simplified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. However, the comment lacks specific examples or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or references, the claim remains 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and suggests that simpler tasks might be more appropriate. The comment also asks for proof that more simpler visual reasoning tasks would not be more effective. While the comment identifies a potential issue with the complexity of the tasks, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for the authors to take, leaving them with limited direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details or examples of what specific visualizations or comparisons are missing, leaving the authors without a clear understanding of how to improve this aspect of their draft. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the need for more visualization, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific references or detailed explanations, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, noting the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any guidance or suggestions on how the authors might address this issue, such as recommending specific types of visualizations or comparisons that could be included. Without actionable advice or examples, the comment is vague and does not offer the authors a clear path to improvement. As a result, it is 2, as it highlights a potential weakness but lacks the depth and specificity needed to be beneficial."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the keypoint detection results should be included in the experiments section. This provides a clear and direct action for the authors to take, as it specifies exactly what needs to be added to the draft. The comment is explicit and concrete, giving the authors a clear path forward in improving their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the keypoint detection results should be included in the experiments section. However, it does not specify which part of the paper this section is currently located in, making it weakly grounded. The comment is specific in its suggestion to include the keypoint detection results in the experiments section, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, examples, or references to support why this inclusion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the keypoint detection results should be included in the experiments section. This is a clear and actionable suggestion that provides the authors with a specific area to address in their draft. By including these results, the authors can enhance the transparency and completeness of their experimental section, allowing readers to better understand and evaluate the findings. However, the comment could be more helpful if it provided additional context or guidance on how to present these results effectively. Overall, the feedback is 4 as it directs the authors to an important aspect of their draft that needs attention, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question about the methodology used in the grid search for learning rate, specifically whether it is conducted on the validation set. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the grid search for learning rate is conducted on the validation set. While it identifies a potential issue with the methodology, it does not provide any further context, analysis, or suggestions for improvement. The comment lacks depth and does not offer actionable feedback or guidance on how the authors might address this concern. As a result, it is 2, as it provides a question but does not offer any actionable insights or suggestions for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or whether it is necessary to make changes. As a result, the authors are left without a clear understanding of what steps to take in response to the comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the presence of a large number of discourse relations in the treebank and suggests that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. The comment provides a clear direction for the authors to consider, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the presence of a large number of discourse relations in the treebank, suggesting that this might be an artifact of colloquial language or a misclassification of \"discourse\" in the treebank. This feedback is 3 as it prompts the authors to consider whether their classification criteria are consistent with other languages in the Universal Dependencies (UD) project. However, the comment lacks detailed guidance or suggestions on how to address this issue, such as whether the authors should reevaluate their classification criteria or provide additional context. While it identifies an area for improvement, the feedback could be more actionable with more specific advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the generalizability of the results to different groups, specifically marginalized groups. It prompts the authors to consider the diversity of the sample, including racial and economic diversity, and its implications for generalizability. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to investigate these aspects. The action is implicit and somewhat vague, as the authors need to infer that they should consider these factors and potentially conduct further analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the generalizability of the results to different groups, particularly marginalized groups, and suggests considering racial and economic diversity in the sample. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the generalizability of the results to different groups, specifically marginalized groups, and suggests considering racial and economic diversity in the sample. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to similar studies that might address this concern, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the results to different groups, particularly marginalized groups. It prompts the authors to consider the diversity of the sample, including racial and economic diversity, and its implications for the applicability of the results. This feedback is valuable as it encourages the authors to broaden their perspective and address potential biases or limitations in their study. However, the comment could be more helpful if it provided specific suggestions or guidance on how to investigate these aspects or if it highlighted the potential impact of these considerations on the study\"s conclusions. Overall, the comment is 3 as it identifies an important area for consideration but lacks depth and actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the current state of output quality, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, suggesting that the paper\"s results are not up to par. The reviewer also mentions the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment does not provide specific guidance or suggestions on how the authors might improve the output quality or address these issues. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, suggesting that the paper\"s results are not up to par. The reviewer also mentions the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment does not specify which part of the paper discusses the output quality or the results, making it weakly grounded. The feedback is specific in identifying areas for improvement, such as output quality and novelty, but lacks detailed guidance on how to address these issues. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, referencing recent GAN works that have achieved impressive quality. The reviewer also notes the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment lacks specific examples or references to these recent GAN works, making it difficult for the authors to fully understand and address the critique. The claim is 3 as it provides a general direction for improvement but lacks detailed evidence or examples to support the specific areas needing enhancement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the output quality of the paper, noting that it is reasonable but still far from realistic. It references recent GAN works that have achieved impressive quality, setting a higher standard for the field. The reviewer also points out the limited novelty, low resolution output, and high hardware requirement, which contribute to the overall impression of the paper. However, the comment lacks specific suggestions or actionable steps for the authors to improve the output quality or address these issues. While it highlights important areas for improvement, the feedback could be more helpful if it provided concrete guidance or examples of how to enhance the results. Therefore, the comment is 3, as it identifies weaknesses but does not fully support the authors in addressing them."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that the authors should provide more evaluation in this direction, specifically on classifying unseen words. The reviewer suggests adding translations to Figure 6 to help nonChinese speakers understand the results. While the comment implies that more evaluation is needed, it does not explicitly instruct the authors to add translations to Figure 6. The action is somewhat implicit and vague, as the authors need to infer that they should enhance the evaluation and provide translations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting the addition of translations to help nonChinese speakers understand the results. This provides clear guidance on what the authors should do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the simple/traditional experiment for unseen characters is a nice idea but is presented as an afterthought. It implies that more evaluation is needed in this direction, specifically on classifying unseen words. The reviewer suggests adding translations to Figure 6 to aid nonChinese speakers. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more evaluation is necessary. The suggestion is 3, as it offers a clear direction for enhancement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential improvement in the paper by suggesting that the simple/traditional experiment for unseen characters, which is presented as an afterthought, could be expanded with more evaluation, specifically on classifying unseen words. The reviewer provides a specific suggestion to enhance the evaluation by adding translations to Figure 6, which would aid nonChinese speakers in understanding the results. This feedback is clear and actionable, offering the authors a concrete way to improve their draft. However, it could be more helpful if it included additional suggestions or examples of how to enhance the evaluation. Overall, the comment is 4, as it provides a clear direction for improvement, but could be further enhanced with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of discussion on computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with parameters that are not easily calculable, which is reflected in the experiments being performed on smallscale datasets. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to discuss computational aspects more thoroughly, possibly including methods to make the algorithm more practical for highdimensional data. However, the comment lacks concrete suggestions or examples of how to achieve this, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion on computational aspects, specifically mentioning the appendix and the experiments performed on smallscale datasets. However, it does not explicitly mention which sections of the paper discuss computational aspects, making it weakly grounded. The comment is specific in pointing out the need for more detailed discussion on computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not discuss computational aspects in detail, particularly regarding the practicality of their methods for highdimensional data. The reviewer provides specific examples, such as the requirement to solve several LPs in high dimensions with parameters that are not easily calculable, which supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these issues impact the practicality of the methods. Overall, the claim is 4 due to the specific examples and reasoning provided, but it could be further strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s discussion of computational aspects, particularly regarding the practicality of the proposed methods for highdimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with parameters that are not easily calculable, which is reflected in the experiments being performed on smallscale datasets. This feedback is valuable as it highlights an important area for improvement, suggesting that the authors need to address the computational feasibility of their methods. However, the comment could be more helpful if it provided specific suggestions or examples of how to make the methods more practical for highdimensional data. Overall, the comment is 4 as it directs the authors\" attention to a critical aspect that needs further exploration and improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a specific error in the equation on Line 502, suggesting that the \"+\" sign after \nu_j should be a \"\" sign. It also points out other errors in the definition of B and Line 504, specifying the necessary corrections. The comment provides clear and actionable feedback, guiding the authors on how to correct these errors. The instructions are explicit and concrete, allowing the authors to make direct changes to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 502,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the exact errors in the equation, such as the incorrect signs in the definition of B and Line 504. The comment provides clear guidance on what needs to be corrected, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of observations and suggestions regarding the mathematical notation in the paper. It identifies specific errors in the equations, such as the incorrect signs in the definition of B and Line 504. These observations are based on logical reasoning and are supported by the specific notation and symbols used in the equations. However, the comment does not provide references or detailed explanations for the corrections, which could enhance its verifiability. Therefore, the comment is 4, as it provides a clear basis for the claims but lacks full detail.", "helpfulness_rationale": "The review comment identifies specific errors in the mathematical notation of the paper, providing detailed feedback on the signs and symbols used in equations. It highlights the need for corrections in the definition of B and Line 504, ensuring that the authors understand and address these issues. The comment is clear and actionable, offering precise guidance on how to improve the draft. However, it could be more helpful if it provided additional context or suggestions for how these corrections might impact the overall understanding or presentation of the paper. Despite this, the feedback is 4 as it directs the authors to make necessary changes to improve the accuracy and clarity of their work."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their motivation. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the motivation are unclear or need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point challenges the claim that the crossencoder architecture \"ignores crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores. It provides a counterpoint by explaining that the architecture does not ignore crossentity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support the claim that the architecture is not as finegrained as implied. This makes the claim 3, as it provides a logical argument but requires more detailed evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the motivation of the paper, specifically regarding the crossencoder architecture. It clarifies that the architecture does not \"ignore crossentity comparison\" and \"attends to all candidates at once\" to obtain final matching scores, which is a significant point of clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their motivation or clarify their claims. While it identifies a potential area for improvement, it does not offer actionable feedback or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the work uses an antiquated GNN model and method, which impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the model or methods, nor are there suggestions for alternative approaches or references to more recent work. As a result, the authors are left without any actionable steps to address the issues raised. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment criticizes the use of an antiquated GNN model and method, as well as the antiquated baseline algorithms/methods. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in detailing what specific aspects of the model or methods are outdated or how they impact the performance. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work uses an antiquated GNN model and method, which impacts the performance of the framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to more recent and effective models, the authors are left without a clear understanding of the basis for this critique. As a result, the claim is 1, as it lacks the necessary justification to be actionable for the authors.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an antiquated GNN model and method, which is likely to impact the performance of the framework. It also points out that the baseline algorithms/methods are antiquated, which could be a concern for the authors. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations for improvement, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, as it highlights a potential problem but does not offer constructive feedback or actionable steps for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the experiment, specifically the reliance on pseudo feature importance due to the lack of true feature importance. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The reviewer provides a specific suggestion to strengthen the experiment by considering the difference in the number of perturbations. However, the comment does not explicitly instruct the authors to implement these suggestions or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors know what needs to be done but may not have a clear idea of how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"one experiment\" and \"Prop 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the reliance on pseudo feature importance and the difficulty in judging the experiment\"s trustworthiness due to the small difference between the tested method and the pseudo feature importance. The comment provides clear guidance on how to strengthen the experiment, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiment\"s reliance on pseudo feature importance due to the lack of true feature importance makes it difficult to judge the experiment\"s trustworthiness. The reviewer supports this claim by referencing \"Prop 3.2\" and suggesting that a large enough perturbation value is needed for the pseudo feature importance to be correct. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. While the suggestion to strengthen the experiment by considering the difference in the number of perturbations is a logical step, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiment, noting that the reliance on pseudo feature importance due to the lack of true feature importance makes it difficult to judge the experiment\"s trustworthiness. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The comment provides clear and actionable feedback, offering a specific direction for improvement by considering the difference in the number of perturbations. This guidance empowers the authors to enhance the robustness and credibility of their experimental results. However, the comment could be more helpful if it included additional suggestions or examples to further clarify the improvement. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out several issues with the paper, including the lack of comparison with other models, confusing sections, missing citations, and unreferenced notation. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific instructions or suggestions makes it difficult for the authors to know exactly what changes to make. The feedback is vague and does not offer concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues with the paper, including the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. It provides explicit references to specific lines and sections, such as \"Line 99, section 3.1\" and \"Line 165, section 3.4,\" which allows the authors to accurately identify the parts of the paper that need attention. The comment is specific in detailing what needs to be addressed, such as the need for additional comparisons and references. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several observations and requests for clarification. It does not contain subjective opinions, judgments, or suggestions that require verification. Instead, it points out factual issues such as the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. These are straightforward observations that do not require justification beyond the information provided. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including the lack of model comparisons, confusing sections, missing citations, and unreferenced notation. These are important points that the authors need to address to improve the clarity and rigor of their work. However, the comment does not provide detailed guidance on how to resolve these issues or suggest specific improvements. While it highlights areas for improvement, it lacks actionable advice, making it 3. The authors are given a starting point for addressing the issues but need additional guidance to fully implement the changes. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide explicit guidance on how to conduct such an analysis or what specific aspects should be addressed. The comment implies that the authors should consider expanding their analysis, but it lacks concrete details or actionable steps, making it vague and 3. The authors can infer that they need to enhance their analysis, but the lack of specific guidance makes it difficult to implement the suggested improvement. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not specify which part of the paper this analysis should be applied to, making it weakly grounded. The comment is specific in its suggestion that a more extensive analysis would enhance the paper, but without grounding, the authors cannot confidently determine which sections need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper significantly. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the need for a more extensive analysis, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would significantly improve the paper. However, it does not provide specific guidance or examples on what aspects of the analysis could be expanded or how this could be achieved. The comment acknowledges that the paper is short, which limits the scope of the analysis, but it does not offer actionable steps or suggestions for improvement. While it identifies a potential area for enhancement, the lack of detailed guidance makes it 3, as it provides a general direction for improvement but does not fully support the authors in implementing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the online learning formulation, including the absence of a proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. While the comment identifies specific areas that need clarification, it does not provide explicit actions or suggestions for how the authors should address these issues. The questions are clear and specific, but the lack of direct guidance on how to implement the suggested improvements makes the comment 3. The authors know what needs to be addressed but may need to infer the exact steps to take. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the online learning formulation is discussed. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it clearly outlines the issues with the current approach, such as the absence of a proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. It provides detailed questions that guide the authors on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the online learning formulation, specifically questioning the absence of a proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a proper comparison against online learning approaches and the challenges of including retraining cost in the evaluation. It raises specific questions that guide the authors in addressing these issues, such as why online learning cannot be used and how to compare retraining cost with incremental updates. This feedback is clear and actionable, providing the authors with a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or included examples of similar studies that have addressed these challenges. Overall, the comment is 4 as it highlights important areas for improvement and offers a starting point for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should include a deeper connection to metalearning and cite relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. While the comment implies that the authors should take these actions, it does not provide explicit instructions on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. However, the comment does not specify which part of the paper should be revised or how the authors should incorporate these suggestions. The authors can infer that the discussion on metalearning and the cited works are relevant, but the comment lacks specificity in terms of where these connections should be made. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the paper should include a deeper connection to metalearning and cites relevant works that do not directly target continual learning but are still relevant. It also recommends linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. The comment provides a logical reasoning by suggesting that these connections could enhance the paper\"s depth and relevance. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of the cited works and how they relate to metalearning and continual learning, which adds to the complexity of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper\"s literature review by suggesting that there is a deeper connection to metalearning, which has several approaches. It recommends citing relevant works that do not directly target continual learning but are still relevant, and it suggests linking the work on RL for architecture search and/or as optimizers for learning to the current work, as it seems to be an application to continual learning. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper\"s depth and relevance. However, the comment could be more helpful if it included examples of the cited works or further guidance on how to effectively integrate these connections into the paper. Overall, the comment is 4 as it offers valuable insights for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback. It suggests that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better reflect reallife situations. While the comment implies an action\u2014exploring different types of feedback\u2014it does not provide explicit instructions on how to implement this suggestion. The authors are left to infer that they should consider generating diverse feedback, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3, as it identifies a potential issue but lacks detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment addresses the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better reflect reallife situations. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for diversity in feedback, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is autogenerated, the authors might consider manually reviewing or generating different types of feedback to better reflect reallife situations. However, the comment does not provide specific examples or evidence to support the claim that the diversity is lacking. It lacks detailed reasoning or references to substantiate the assertion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the lack of lexical and syntactic diversity in the teacher feedback, particularly if it is autogenerated. It suggests that the authors might consider manually reviewing or generating different types of feedback to better reflect reallife situations. This feedback is 3 as it points out a specific area for improvement and provides a direction for enhancing the diversity of feedback. However, it could be more helpful if it included specific examples or guidance on how to generate diverse feedback. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should compare their performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This is a clear and direct action for the authors to take, as it provides specific references to compare with. The comment also specifies that these works involve training adapters on top of a welltrained multilingual pretrained model, which gives the authors a clear idea of what to look for in these comparisons. Therefore, the comment is 5, as it provides explicit and concrete guidance on how to improve the draft by including relevant comparisons.", "grounding_specificity_rationale": "The comment suggests comparing the performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, it does not specify which part of the paper this recommendation pertains to, such as a section or a particular experiment. This makes it difficult for the authors to identify the exact area where this comparison should be included. The comment is specific in its suggestion to compare with these works, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the performance of the current work with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". However, the comment does not provide any reasoning or evidence to support why these particular works are relevant or how they might influence the current study. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion and how it could enhance their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to compare their performance with two specific works: \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This recommendation is 5 as it directs the authors to relevant literature that could enhance the comprehensiveness and impact of their study. By including these comparisons, the authors can better position their work within the existing literature and potentially identify areas for improvement or innovation. The comment is specific and provides a clear path for the authors to follow, making it 5 for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests that the authors consider extending their approach to more general settings. While the comment implies that the authors should explore broader applicability, it does not provide explicit guidance on how to achieve this extension or what specific aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the extent of the extension required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the current setting, noting that it is very specific and requires certain conditions, such as knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. However, the comment does not explicitly mention which part of the paper discusses the current setting or the proposed approach, making it weakly grounded. The suggestion to extend the approach is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the current setting is very specific, requiring knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. The reviewer suggests extending the approach to more general settings. However, the comment lacks specific examples or references to support the claim about the current setting\"s limitations. While the suggestion to extend the approach is logical, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. This feedback is 3 as it points out a potential area for improvement and provides a clear direction for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or examples of how to extend the approach to broader settings. Overall, the comment provides a good starting point for the authors to explore, but it lacks depth and detail to be fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point is explicit in its request for clarification regarding the feature extractor used for the dimensionality of each region, which is specified as 512. This is a clear and direct action for the authors to take, as it prompts them to provide the specific feature extractor used in their work. The comment is concrete, as it specifies exactly what information is needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the feature extractor used for the dimensionality of each region, which is specified as 512. This provides clear guidance on what information is missing or needs clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement seeking clarification about the feature extractor used for a specific dimensionality. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The comment is clear and actionable, seeking clarification on the feature extractor used for the dimensionality of each region, which is specified as 512. This is a specific and direct request for additional information that can help the authors provide more context or details about their methodology. By addressing this question, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it provided suggestions on how to choose or justify the feature extractor used. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to explain how they chose the value p < 0.4 in Algorithm 1. This is a direct request for clarification, providing the authors with a clear and explicit action to take. The comment does not require any inference or interpretation, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on how the value p < 0.4 was chosen. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the choice of a specific value, p < 0.4, in Algorithm 1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a direct request for clarification regarding the choice of the value p < 0.4 in Algorithm 1. It does not provide any feedback or suggestions on how this choice might impact the results or the overall methodology. While it identifies a specific area that needs further explanation, it lacks depth and actionable guidance for the authors to improve their draft. Therefore, the comment is 3, as it points out a gap in the paper but does not offer comprehensive feedback or suggestions for improvement. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its suggestion to provide a clearer explanation, but without grounding, the authors may struggle to identify the exact section that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the motivation for applying CMD in federated learning. It suggests that the authors should provide a more explicit demonstration or explanation to clarify this aspect. While the comment highlights an area that could be improved, it lacks specific guidance or suggestions on how to enhance the clarity of the motivation. The feedback is 3 as it points out a potential weakness but does not offer detailed advice on how to address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies two specific areas for improvement: the lack of analysis of the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. It also suggests references for further reading. While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to conduct the analysis or compare methods. The authors are aware of what needs to be done but may require additional information to fully implement the suggestions. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"data augmentation method\" and \"paraphrasing methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as the lack of analysis and the need to compare the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment further provides references for the authors to consider, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods like EDA or LLMbased paraphrasing. The comment provides references to support the claim, such as 1 and 2, which are relevant to the topic of language models and their effectiveness. This provides a basis for the authors to understand the need for additional analysis and comparison. However, the comment could be strengthened by elaborating on why these comparisons are important or how they would enhance the paper. Overall, the comment is 4 due to the references provided, but it could be more robust with additional explanation.", "helpfulness_rationale": "The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis of the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, would clarify the unique advantages of the proposed method. The comment also provides references to relevant literature, which can guide the authors in expanding their analysis and understanding of the field. This feedback is clear and actionable, offering specific suggestions for improvement that can enhance the paper\"s depth and contribution. However, it could be more helpful if it included more detailed guidance on how to conduct the analysis or compare methods. Overall, the comment is 4, as it provides valuable insights and actionable steps for the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider this scenario, it does not provide explicit guidance or suggestions on how to address this question or what implications it might have for the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario in their analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context where this discussion is relevant. Without specific grounding, the authors cannot confidently determine where to address this question within their draft. Additionally, the comment lacks specificity as it does not provide any guidance on why this question is important or what implications it might have for the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider a specific scenario, it does not provide any guidance or suggestions on how this question might impact the paper or what implications it could have. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it identifies a potential area for exploration but does not offer actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time. This provides a clear and direct action for the authors to take, which is to include such quantitative analysis to substantiate the claimed computational benefits. The comment is explicit and concrete, guiding the authors on exactly what needs to be added to their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lack of quantitative analysis on computational gains,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the absence of specific measurements or comparisons to substantiate the claimed computational benefits. The comment is specific in detailing what needs to be addressed, namely the inclusion of quantitative analysis such as GPU hours, memory usage, or training time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time. This claim is supported by logical reasoning, as it points out the absence of specific metrics that would substantiate the claimed computational benefits. However, the comment could be strengthened by providing examples or references to similar studies that have included such analyses. Overall, the claim is 4 due to the logical reasoning provided, but it could be further strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s analysis by pointing out the lack of quantitative measurements to substantiate the claimed computational gains from replacing the MAE model with a CNNbased data augmentation strategy. It provides a clear and actionable suggestion by recommending the inclusion of specific metrics such as GPU hours, memory usage, or training time. This feedback is valuable as it guides the authors on how to strengthen their claims and provide a more robust evaluation of their proposed method\"s efficiency. However, the comment could be more helpful if it offered additional guidance on how to conduct these analyses or suggested specific tools or methodologies to use. Overall, the comment is 4, as it effectively directs the authors to improve their draft by addressing a critical gap in their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the \"filter manifold network\" (FMN), including the lack of discussion or analysis, the need for experimentation with other architectures, and the scalability of adaptive convolutions with the number of filter parameters. The reviewer also questions the scalability of FMN with larger input and output channels. While the comment identifies specific areas for improvement, it does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer the need for additional experimentation and analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and concerns about the FMN, including the lack of discussion, experimentation with other architectures, and the scalability of adaptive convolutions with the number of filter parameters. The comment also questions the scalability of FMN with larger input and output channels, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the lack of discussion and analysis on the \"filter manifold network\" (FMN), suggesting that the authors should experiment with other architectures for FMN and explore the scalability of adaptive convolutions with the number of filter parameters. The reviewer also questions the scalability of FMN with larger input and output channels. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that FMN is not being adequately discussed or analyzed. The suggestion to experiment with other architectures and explore scalability is logical but lacks detailed justification or evidence. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion and analysis on the \"filter manifold network\" (FMN), which is a crucial part of the technique. It raises several questions, such as whether the authors have experimented with other architectures for FMN and how the adaptive convolutions scale with the number of filter parameters. The comment also questions the scalability of FMN with larger input and output channels, which is common in many CNN architectures. While the comment highlights important areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it prompts the authors to consider additional aspects of their work, but it lacks depth and actionable advice, leaving the authors with a general sense of what needs to be improved."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain to the claimed performance boost. The reviewer suggests that comparisons to UNets are necessary to clarify the model\"s performance. While the comment implies that the authors should include comparisons to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that comparisons are necessary but are not given specific guidance on how to conduct these comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"complex UNet part after the fractional transform\" and questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the model\"s complexity and the need for comparisons to clarify the performance boost. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain to the claimed performance boost. The reviewer suggests that comparisons to UNets are necessary to clarify the model\"s performance. While the comment provides a logical reasoning for the need for comparisons, it lacks specific examples or references to support the claim fully. This makes the claim 3, as it provides a basis for the suggestion but requires further elaboration for full clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain to the claimed performance boost. The reviewer suggests that comparisons to UNets are necessary to clarify the model\"s performance. This feedback is 4 as it identifies a potential area for improvement and provides a clear direction for the authors to enhance their draft by including relevant comparisons. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is actionable and provides valuable insights for the authors to consider, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly requests the authors to rewrite a sentence that is unclear, specifically \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This is a clear and direct instruction, providing the authors with a specific action to take. The comment also specifies the page and line number, making it easier for the authors to locate and address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"P. 5, p. 3, l.\" which allows the authors to accurately identify the part of the paper being addressed, providing full grounding. It also specifies the issue by requesting a rewrite of a sentence that is unclear, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding a sentence that is unclear. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of a sentence in the paper, specifically \"While a smaller j to simulate more accumulate errors along with the inference steps.\" This feedback is clear and actionable, as it directly points out a confusing sentence that needs to be rewritten for better understanding. By specifying the page and line number, the authors are given a clear indication of where to make the necessary changes. This level of detail and specificity makes the comment 5, as it provides a direct path for the authors to improve the clarity of their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether they consider documents as entire sentences in the context of the DocRED dataset. It also inquires about how the authors handle concepts with multiple entity mentions referring to the same entity. These questions provide clear guidance on what information is missing from the manuscript and what needs to be addressed. The authors are given a direct action to include this information, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors consider documents as entire sentences and how they deal with concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what information is missing from the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on specific aspects of the paper, namely, whether documents are considered as entire sentences in the context of the DocRED dataset and how the authors handle concepts with multiple entity mentions referring to the same entity. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the handling of documents in the context of the DocRED dataset, particularly regarding whether they are considered as entire sentences and how concepts with multiple entity mentions referring to the same entity are addressed. This feedback is clear and actionable, as it prompts the authors to clarify these aspects in their manuscript. By addressing this question, the authors can provide more detailed information that could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included suggestions on how to handle these issues or examples of how other studies have addressed similar concerns. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the marginal contribution of the work, suggesting that the methods used are welldesigned and demonstrated. It also questions the need for adding another stream for lowresolution, implying that this might not be a significant contribution for a toptier venue like ICLR. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their contribution. The action is implicit and vague, as the authors are left to infer that they need to justify the significance of their work or consider alternative approaches. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses a concern about the marginal contribution of the work, suggesting that the methods used are welldesigned and demonstrated. It questions the need for adding another stream for lowresolution, implying that this might not be a significant contribution for a toptier venue like ICLR. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity in detailing what aspects of the contribution are marginal or how the addition of another stream might be significant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution is marginal because the methods used are welldesigned and demonstrated, and adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. However, the comment lacks specific reasoning or evidence to support these claims, such as detailed comparisons with existing work or examples of how the methods are welldesigned. Without additional context or justification, the authors may find it challenging to understand the basis of the critique, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment expresses a concern about the marginal contribution of the work, suggesting that the methods used are welldesigned and demonstrated, and adding another stream for lowresolution might not be a significant contribution for a toptier venue like ICLR. While the comment identifies a potential issue with the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the significance of their work. The feedback is 3 as it points out a potential weakness, but it does not provide actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It specifically asks how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the relationship between the testers and provide a detailed explanation of how the tester handles specific cases. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester, and it provides a specific example of how the tester might handle (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester, specifically asking if the tester immediately yields an (\u03b5, \u03b4)identity tester. It also questions how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim that the tester does not yield an (\u03b5, \u03b4)identity tester. The reasoning is based on a logical inquiry into the functionality of the tester, but without additional evidence or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the relationship between the tester for the spread parameter and the (\u03b5, \u03b4)identity tester. It highlights a potential issue regarding how the tester deals with (\u03c0, \u03d5) pairs where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. This feedback is clear and actionable, as it prompts the authors to clarify the relationship between the testers and provide a detailed explanation of how the tester handles specific cases. By addressing this question, the authors can improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to handle such cases. Overall, the comment is 4, as it identifies a potential weakness and offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the detailed distribution of the proposed dataset is unclear, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should clarify this distribution or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the detailed distribution of the proposed dataset, indicating that it is unclear. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the problem, but it lacks grounding as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the detailed distribution of the proposed dataset is unclear, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed dataset, noting that the detailed distribution is unclear. However, it does not provide any suggestions or guidance on how the authors might clarify this distribution or improve the dataset\"s description. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2, as it highlights a problem but does not offer actionable insights for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method\"s reliance on annotated labels for learning semantic tokens limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to implement this change or provide detailed guidance on how to transition to a selfsupervised approach. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the need for annotated labels in the proposed method, suggesting that a selfsupervised pretraining approach without annotations could be more appealing. However, it does not specify which part of the paper discusses the use of annotated labels or the proposed method. The authors can infer that it relates to the methodology or experimental setup, but the comment lacks explicit grounding. It is specific in suggesting a potential improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the proposed method\"s reliance on annotated labels limits its application to supervised training. It implies that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, which is its reliance on annotated labels for learning semantic tokens, thereby limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is clear and actionable, as it points out a potential area for improvement and provides a specific direction for the authors to consider. By suggesting a selfsupervised approach, the comment offers a concrete way to enhance the applicability and versatility of the method. However, it could be more helpful if it included specific examples or guidance on how to implement a selfsupervised approach. Overall, the comment is 4, as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should expand their experimental scope to include these tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion on scalability. The authors can infer that it relates to the experimental results or the discussion on the limitations of the current experiments, but this inference is not explicit. The comment is specific in its suggestion to include more challenging tasks, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for why the authors should expand their experiments to include more challenging tasks. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should expand their experimental scope to demonstrate the scalability of their method, LFF, by including more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is 3 as it provides a clear direction for the authors to enhance the robustness and applicability of their method. However, the comment could be more helpful if it included specific suggestions on how to design or approach these experiments or if it provided examples of existing methods that have successfully addressed similar challenges. Overall, the comment offers a valuable direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests that the abstract should include a more detailed statement about the expressivity of the model, referencing a specific citation. Additionally, it recommends including learning curves for all experiments, at least in an appendix. These suggestions are clear and provide specific guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"abstract\" part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion for improvement by recommending a more detailed statement about the expressivity of the model and the inclusion of learning curves for all experiments, at least in an appendix. This provides clear guidance on what needs to be addressed in the abstract. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific change to the abstract, recommending that it should include a more detailed statement about the expressivity of the model, referencing a specific citation. This is a factual suggestion rather than a claim or opinion, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the abstract, suggesting a more detailed statement about the expressivity of the model, referencing a specific citation. It also recommends including learning curves for all experiments, at least in an appendix, which is a constructive suggestion for improving the transparency and completeness of the paper. This feedback is clear and provides the authors with a clear direction for enhancing their draft, making it 4. However, it could be more helpful if it included specific examples or further guidance on how to incorporate these changes. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the motivation of the paper, specifically regarding the application of the proposed method. It suggests that the authors clarify the need for domain adaptation and provide examples of actual tasks involving domain adaptation. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context on the application of their method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the motivation of the paper, specifically regarding the application of the proposed method. It questions the relevance of the results, which involve mapping one RGB image to another with a different style, and suggests that the authors should provide a clearer explanation of when domain adaptation is needed and how it would be useful. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in its critique, as it clearly identifies the need for a more detailed explanation of the application and utility of the proposed method. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the motivation of the paper, questioning the relevance of the results and suggesting that the authors should provide a clearer explanation of when domain adaptation is needed and how it would be useful. The reviewer implies that the paper lacks a clear application or demonstration of the proposed method, which is a subjective claim. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a critical question about the motivation and relevance of the paper\"s proposed method. It points out that the paper\"s results involve mapping one RGB image to another with a different style, and it questions the need for domain adaptation and the utility of the proposed method. The reviewer suggests that the authors should demonstrate the methodology\"s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the paper by clarifying the motivation and demonstrating the practical application of their method. However, the comment could be more helpful if it offered additional suggestions or examples of how to achieve this demonstration. Overall, the comment is 4, as it effectively guides the authors in enhancing the clarity and relevance of their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point provides a list of references to other works in the field, including MISA, M2FNet, and MMDFN. However, it does not offer any explicit or implicit actions for the authors to take regarding these references. There is no guidance on how the authors should incorporate these references into their paper or what specific aspects of their work should be compared or discussed with these references. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment mentions specific references, such as MISA, M2FNet, and MMDFN, which are relevant to the paper. However, it does not explicitly mention which part of the paper these references are related to, making it weakly grounded. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline that considers crosssensory interaction, but it is out of fashion since it was proposed in 2019. This provides some specificity by highlighting a potential issue with the paper\"s baseline comparison. However, the comment lacks detailed guidance on how the authors might address this issue or improve their baseline comparison. Therefore, the comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction, but MULT was proposed in 2019 and is considered out of fashion. However, the comment does not provide specific evidence or examples to support the claim that MULT is outdated or why it is considered the only relevant baseline. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered 2, as it provides some basis for the assertion but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment provides a list of references to other works in the field, including MISA, M2FNet, and MMDFN. However, it does not offer any specific feedback or suggestions on how these references could be integrated into the paper or what aspects of the work should be compared or discussed with these references. The comment also critiques the paper by suggesting that MULT is considered the only deep learningbased baseline that considers crosssensory interaction, but it is out of fashion since it was proposed in 2019. While this critique highlights a potential issue with the paper\"s baseline comparison, it does not provide actionable guidance on how the authors might address this concern or improve their work. Therefore, the comment is 3, as it identifies a potential weakness but lacks detailed feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a major issue with the comparison against other models in the experiments, specifically noting that the value of the used ranks for all models is omitted, making it impossible to conduct a fair comparison. It explicitly instructs the authors to compare the tensor completion results for all models while ensuring that they have the same number of model parameters. The reviewer provides a specific suggestion to compute the number of model parameters by adding the number of entries of all core tensors for each model. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments\" and \"the value of the used ranks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison against other models, noting that the ranks are omitted, which makes it impossible to conduct a fair comparison. The comment further provides a concrete suggestion for improvement by instructing the authors to compare tensor completion results for all models with the same number of model parameters. This detailed guidance ensures that the authors know exactly what needs to be addressed in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear due to the omission of the value of the used ranks for all models. This makes it difficult to conduct a fair comparison. The reviewer suggests that the authors should compare the tensor completion results for all models while ensuring they have the same number of model parameters. This is a logical and reasonable suggestion, as it provides a clear and specific way to address the issue. However, the comment could be strengthened by providing examples or references to similar studies that have successfully compared models with different ranks. Overall, the claim is 4, as it offers a clear direction for improvement but lacks detailed examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the comparison against other models in the experiments. It points out that the omission of the value of the used ranks for all models makes it impossible to conduct a fair comparison. The reviewer provides a clear and actionable suggestion for improvement, instructing the authors to compare the tensor completion results for all models while ensuring they have the same number of model parameters. This feedback is detailed and provides a concrete path for the authors to enhance the clarity and rigor of their experimental comparisons. However, the comment could be more helpful if it included specific examples or references to similar studies that have successfully addressed this issue. Overall, the comment is 4, as it effectively guides the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide explicit guidance on how the authors should address this issue or what specific details are needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but the comment does not offer concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"observation\" and the \"theoretical part\" of the paper, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by questioning the lack of detail on how the proposed algorithm removes subdivision splines and whether it incurs extra computation cost. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific examples or references to support the claim that the algorithm lacks detail or incurs extra computation cost. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a concern about the theoretical part of the paper, specifically questioning the lack of detail on how the proposed algorithm removes subdivision splines. It also asks whether the algorithm incurs extra computation cost for space partition building. While the comment identifies a gap in the theoretical explanation, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional details are needed. The feedback is 3 as it highlights an area that requires further clarification, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that W1 and W2 are not defined in the paper, suggesting that they might denote the Encoder and the Decoder network. It also mentions that W and V are not defined in Eq. 3, which is similar to the issue with W1 and W2. However, the comment does not provide explicit instructions on how the authors should define these terms or where they should be defined. The actions are implicit and somewhat vague, as the authors need to infer that they should define these terms in the appropriate sections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides explicit references to page 3, line A4, and Eq. 3, allowing the authors to accurately identify the parts of the paper being addressed. This level of detail ensures full grounding. Additionally, the comment specifies what needs to be addressed, namely the need to define these terms, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that W1 and W2 are not defined in the paper, and it suggests that they might denote the Encoder and the Decoder network. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides clear and actionable feedback by suggesting that these terms might denote the Encoder and the Decoder network, which could help the authors clarify their notation. However, the comment could be more helpful if it offered suggestions on how to define these terms or where they should be defined in the paper. Overall, the comment is 4 as it directs the authors to address a critical issue in their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. It implies that a better comparison should be considered, but it does not provide explicit guidance on how to make this comparison more fair or what specific improvements are needed. The action is implicit and somewhat vague, as the authors can infer that they should improve the comparison, but they are left without concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the fairness of the comparison with some baselines, specifically mentioning that they lack prior knowledge of users or language embedding computation. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the fairness of the comparison, suggesting a better approach should be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate why these aspects are crucial for a fair comparison. As a result, the claim is not 5, as it requires additional information or justification to be understood and addressed by the authors. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and some baselines. It points out that these baselines lack prior knowledge of users or language embedding computation, suggesting that a better comparison should be considered. While the comment highlights an important aspect of the comparison, it lacks specific suggestions or guidance on how to address this issue or improve the fairness of the comparison. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and concerns about the paper. It asks why the outputside layers do not benefit from a certain aspect, questions the clarity of Figure 4, and seeks clarification on the Pixelshuffle operation. Additionally, it points out the lack of discussion on limitations and potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the benefits of the outputside layers, improve the clarity of Figure 4, explain the Pixelshuffle operation, and discuss the limitations and societal impacts of their work. The feedback is 3 as it provides a direction for improvement but lacks concrete steps or examples. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses several specific issues, including the lack of benefit for outputside layers, the clarity of Figure 4, the explanation of Pixelshuffle, and the absence of discussion on limitations and potential negative societal impacts. It provides detailed feedback on each of these points, making the comment fully grounded as it explicitly mentions the parts of the paper being addressed. The comment is also specific because it clearly outlines what needs to be addressed in each case. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the lack of benefit for outputside layers, the clarity of Figure 4, the explanation of Pixelshuffle, and the absence of discussion on limitations and potential negative societal impacts. While the comment identifies these issues, it does not provide specific examples, references, or detailed reasoning to support the claims. The lack of detailed evidence or justification makes it difficult for the authors to understand and address the concerns effectively. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises several specific concerns and questions about the paper, including the lack of benefit for outputside layers, the clarity of Figure 4, the explanation of Pixelshuffle, and the absence of discussion on limitations and potential negative societal impacts. These points are relevant and provide actionable feedback for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions or examples on how to address these issues. Overall, the feedback is 4 as it directs the authors to areas that need further clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their draft. The action is implicit and vague, as the authors are left to infer that they should explore the impact of this process on performance. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the process and its potential impact on performance, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance and asks for clarification. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to enhance their draft. The feedback is 3 as it prompts the authors to consider the impact of their current approach, but it does not provide detailed or actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should evaluate their proposed approach on new patients and old patients separately, given that the patients are firsttime visitors without historical reports. This is an explicit action that provides clear guidance on how the authors can improve their work. The suggestion is concrete, as it specifies the type of evaluation needed and the distinction between new and old patients. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the proposed approach on new patients and old patients separately, particularly when patients are firsttime visitors without historical reports. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to evaluate the approach on new and old patients, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests evaluating the proposed approach on new patients and old patients separately, particularly when patients are firsttime visitors without historical reports. However, the comment does not provide any reasoning, evidence, or references to support why this evaluation is necessary or how it would improve the approach. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests evaluating the proposed approach on new patients and old patients separately, particularly when patients are firsttime visitors without historical reports. This feedback is 3 as it identifies a potential limitation in the current evaluation and provides a clear direction for improvement. However, it lacks specific guidance on how to conduct this evaluation or what aspects of the approach should be considered when evaluating new versus old patients. To be more helpful, the comment could include suggestions on how to differentiate between new and old patients or what criteria should be used to assess the approach in these scenarios. Therefore, the comment is rated as 3, as it provides a direction for improvement but lacks depth."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that some aspects of the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address these concerns or what specific changes they should make to their draft. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of how to improve their work. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not specify which part of the paper discusses these techniques or where they are applied, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of these techniques are not novel or how they could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of some techniques used in the algorithm, specifically mentioning computation offloading and gradient augmentation. However, it lacks specificity and does not provide any further details or suggestions on how the authors might address this concern. Without actionable feedback or guidance, the comment does not offer the authors a clear path to improve their draft. As a result, it is rated as 2, as it provides some insight but does not fully support the authors in enhancing their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides an understanding of the integral in Equation (1) as a bag observation model or spatial aggregation process. It highlights a potential issue with the authors\" assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their formulation. The action is implicit and vague, as the authors are left to infer that they need to consider alternative aggregation methods. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Equation (1), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the formulation, suggesting that the observations might be aggregated by another procedure, such as simple summation or population weighted average. The comment provides a clear rationale for this suggestion, referencing the work of Law et al. and 4. This level of detail and clarity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the integral in Equation (1) corresponds to a bag observation model or spatial aggregation process, referencing specific works. It then suggests that the authors\" assumption about the aggregation method might be incorrect, as the data could be aggregated differently, such as by simple summation or population weighted average. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors\" assumption is incorrect. While it provides a general direction for improvement, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed understanding of the integral in Equation (1) as a bag observation model or spatial aggregation process, referencing specific works. It highlights a potential issue with the authors\" assumption about the aggregation method, suggesting that the data might be aggregated differently, such as by simple summation or population weighted average. This feedback is valuable as it offers a clear and actionable suggestion for the authors to consider alternative aggregation methods, which could significantly impact the accuracy and applicability of their results. However, the comment could be more helpful if it provided specific examples or guidance on how to implement these alternative methods. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis of this training dynamics would strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, but without explicit references to sections or figures, the authors may struggle to pinpoint where this analysis should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks indepth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis would strengthen the paper. However, the comment does not provide specific reasoning or evidence to support why this analysis is necessary or how it would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks depth, namely the lack of indepth analysis regarding why inverse scaling occurs over compute. It suggests that providing such analysis would significantly strengthen the paper. However, the comment does not offer specific guidance or examples on how to conduct this analysis or what aspects should be included. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it points out a critical area for enhancement but does not fully guide the authors in making the necessary improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider a more complex setting where the policy is not fixed, which would allow them to compare with a reinforcement learning algorithm baseline. While the comment implies that the authors should explore a more challenging scenario, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for a more complex setting, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring a more complex setting where the policy is not fixed, which would allow the authors to compare with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to consider a more complex setting, but without grounding, the authors may struggle to identify the exact section where this suggestion would be most relevant. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. However, the comment does not provide specific examples or references to support the claim that a more complex setting would be beneficial or how it would improve the comparison with reinforcement learning algorithms. The suggestion lacks detailed reasoning or evidence to fully substantiate the claim, making it 2. The authors would need to infer the potential benefits of such a change, which adds to the uncertainty. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the current setting with a fixed policy is a subset of reinforcement learning and proposes a more complex setting where the policy is not fixed. This suggestion could be valuable as it encourages the authors to explore a more challenging scenario that would allow them to compare their approach with a reinforcement learning algorithm baseline. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the policy should be varied to achieve a more complex setting. While it provides a direction for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it offers a potential enhancement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might expand the scope of their work or what specific areas they should explore to enhance applicability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not specify which part of the paper this critique pertains to, such as a particular section, figure, or table. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper needs revision. This lack of grounding and specificity makes it difficult for the authors to address the comment effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper\"s focus on explaining multitask models limits its applicability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s focus on explaining multitask models, suggesting that this focus may limit the applicability of the work. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential issue but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the literature review ignores several papers that are relevant, specifically mentioning VRMARINA for online problems from 1 and DASHAMVR from 2. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the literature review. The action is implicit and vague, as the authors are left to infer that they need to include these papers in the literature review. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the next section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the literature review, mentioning that it ignores several papers that are relevant and suggesting that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment also includes a question, which further clarifies the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review ignores several papers that are relevant, specifically mentioning VRMARINA for online problems from 1 and DASHAMVR from 2. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide specific examples or detailed reasoning to support why these papers should be included or why they are relevant. The mention of \"See Question\" implies that further explanation is needed, but it is not provided in the comment itself. Therefore, the claim is 3, as it provides a basis for the claim but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the literature review, noting that it ignores several papers that are relevant to the topic. It provides examples of papers, VRMARINA and DASHAMVR, which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. The comment also includes a question, suggesting that the authors should consider including these papers in their literature review. However, the comment lacks detailed guidance on how to integrate these papers or what specific aspects of the literature review should be revised. While it highlights an important area for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is 3, as it points out a significant issue but lacks depth and specificity in its guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two questions that seek additional insights and performance evaluations. The first question asks for additional insights into modest performance gains on the Clothing1M dataset, while the second question inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. These questions provide clear guidance for the authors to consider, as they are asking for specific information or analyses that could enhance the paper. However, the questions do not explicitly instruct the authors on how to address these points, such as by conducting additional experiments or providing detailed explanations. The actions are implicit but concrete, as the authors know what information is needed to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment consists of two questions, one about additional insights into modest performance gains on the Clothing1M dataset and the other about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix. While the questions are specific in their inquiries, they do not provide explicit references to specific sections of the paper where these topics might be discussed. The authors can infer that the questions relate to the results or discussion sections, but they cannot pinpoint exact parts. Therefore, the comment is weakly grounded as it does not specify the exact sections being addressed, but it is specific in its requests for additional insights and performance evaluations. This aligns with a score of 3.", "verifiability_rationale": "The review point consists of two questions seeking additional insights and performance evaluations. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment consists of two questions that seek additional insights and performance evaluations. The first question asks for additional insights into modest performance gains on the Clothing1M dataset, which could help the authors better understand and explain their results. The second question inquires about the algorithm\"s performance on other realworld datasets like WebVision, evaluated by DivideMix, which could provide a broader context for the algorithm\"s capabilities. While the questions are clear and provide areas for further exploration, they do not offer specific guidance or suggestions on how to address these points. The feedback is 3 as it prompts the authors to consider additional analyses or comparisons, but it lacks depth and actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a more detailed presentation of the compared models, specifically the KVAE, which is simpler due to its linear state space transition but requires computation of timedependent LGSSM parameters. The reviewer also asks for a comment on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more detailed information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information about the compared models. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the presentation of the compared models, specifically the KVAE, and provides a clear explanation of the differences between the models. The reviewer suggests that the authors provide a more detailed presentation of the compared models, including a discussion of the computation requirements of the three methods. This feedback is clear and actionable, providing the authors with a specific area to address in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reviewer is not familiar with the compared models DMM and DVBF in detail but understands their differences with KVAE. The reviewer suggests that a more detailed presentation of the compared models would be appreciated. The comment provides a logical reasoning for the suggestion, explaining that the KVAE is simpler due to its linear state space transition but requires computation of timedependent LGSSM parameters. However, the comment lacks specific examples or references to support the claim about the computation requirements of the three methods compared in Table 1. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper\"s presentation by suggesting that the authors provide a more detailed explanation of the compared models, specifically the KVAE. It highlights a key difference between the KVAE and the compared models, noting that the KVAE is simpler due to its linear state space transition but requires computation of timedependent LGSSM parameters. The reviewer also asks for a comment on the computation requirements of the three methods compared in Table 1. This feedback is clear and actionable, as it directs the authors to provide additional context and details that could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included specific suggestions or examples of how the authors might present this information. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment does not explicitly instruct the authors to include these takeaways or provide detailed guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include more practical implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and suggests that they lack immediate practical implications, which is understandable given the novelty of the work. It also mentions a specific observation regarding querying a cluster proportionally to the square root of its size as a main takeaway point. However, the comment does not specify which part of the paper discusses the theoretical results or where this observation is made, making it weakly grounded. The comment is specific in identifying the lack of practical implications and the main takeaway point, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that more takeaway points for practitioners would be beneficial, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment lacks specific examples or references to support the claim that this observation is novel or unique to the paper. While the comment provides a logical reasoning for the suggestion, it is 3 due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more takeaway points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main takeaway point. However, the comment lacks depth and does not provide specific guidance on how to present these takeaways or what additional points might be relevant. While it identifies a potential area for improvement, the feedback is 3 as it provides a starting point for the authors to consider, but it could be more comprehensive and actionable with additional details or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information they provide beyond T/I/O. While the comment highlights a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or explanation regarding the use of separators. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of introducing separators and asks for clarification on the additional information they provide beyond T/I/O. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information beyond T/I/O. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or what specific issues might arise. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, questioning the purpose and additional information provided by the introduction of \"separators\" in section 4. This feedback is clear and actionable, as it prompts the authors to clarify the role and significance of these elements in their work. By addressing this question, the authors can provide more context and depth to their paper, enhancing its clarity and comprehensibility. However, the comment could be more helpful if it suggested how the authors might elaborate on the purpose of the separators or provided examples of how they might be used. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that in Table 3, the authors should compare the real search cost, such as the number of GPU days, in addition to the number of queries. This is an explicit suggestion that provides a clear action for the authors to take, as it specifies what additional information should be included in the table. The comment is concrete, as it gives a specific direction on how to enhance the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular enhancement, namely comparing the real search cost (e.g., in terms of GPU days) in addition to the number of queries. This provides clear guidance on what needs to be added to improve the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that in Table 3, the authors should compare the real search cost, such as the number of GPU days, in addition to the number of queries. This is a logical suggestion that aligns with the goal of providing a comprehensive comparison. However, the comment does not provide specific examples or references to support why this comparison is necessary or how it would enhance the table. While the suggestion is reasonable, it lacks detailed justification or evidence, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that in Table 3, the authors should compare the real search cost, such as the number of GPU days, in addition to the number of queries. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the comparison presented in the table. By addressing this point, the authors can improve the comprehensiveness and utility of their results. However, the comment could be more helpful if it explained why this additional comparison is important or how it would impact the interpretation of the results. Overall, the comment is 4 as it directs the authors to a specific enhancement that could significantly improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks for clarification on whether the VQGAN is pretrained or only trained on the 88,635 images from the Computer Vision Figures dataset. This request provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"training details\" and specifically asks about the pretraining of the VQGAN and its training on the 88,635 images from the Computer Vision Figures dataset. This provides clear guidance on what part of the paper needs clarification. The comment is specific because it identifies the exact details that are missing, allowing the authors to address the issue directly. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on specific training details, specifically whether the VQGAN is pretrained or trained on a particular dataset. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or only trained on a specific dataset. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the transparency and reproducibility of their work. By addressing this question, the authors can improve the clarity and completeness of their methodology section. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or emphasized its importance. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods (DualIS and DualDIS) regarding their performance on crossmodel retrieval tasks, particularly in the MSVD dataset (Table 3). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the performance of their methods. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance of the proposed methods (DualIS and DualDIS) on crossmodel retrieval tasks, specifically mentioning the MSVD dataset (Table 3). This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it highlights a particular issue with the performance improvements in the MSVD dataset. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods (DualIS and DualDIS) are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). However, the comment lacks specific examples or detailed reasoning to support this claim. While it mentions a particular dataset and table, it does not provide detailed analysis or evidence to substantiate the claim that the methods are not generic. This makes the claim 3, as the authors would need to further investigate the claim to fully understand and address it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods (DualIS and DualDIS) by noting that they are not generic on some crossmodel retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). This feedback is 3 as it highlights a potential limitation of the methods, which could guide the authors in refining their approach or expanding their experimental scope. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the performance of their methods. Therefore, the comment is rated as 3, as it provides a starting point for improvement but does not fully support the authors in making significant enhancements to their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the experimental strengths of the approach and suggests an alternative method that could be used to demonstrate the effectiveness of the proposed algorithm. It implies that the authors should consider running a descent procedure for 40 different networks from the training phase, but it does not explicitly instruct them to do so. The comment provides a logical reasoning for the alternative approach, suggesting that running vanilla Adam on the final network with 40 random initial points could be sufficient to reach the global minimum. However, it lacks specific guidance on how to implement this alternative method or why it would be more effective. The action is implicit and somewhat vague, as the authors can infer the need for an alternative approach but may not know how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could be sufficient to reach the global minimum. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the experimental approach, suggesting a more efficient method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental strengths of the approach, questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could be sufficient to reach the global minimum. The comment provides a logical reasoning for the alternative approach, suggesting that it is not necessary for each initialization to reach the global minimum as long as at least one does. However, the comment lacks specific references or examples to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could be sufficient to reach the global minimum. This feedback provides a logical critique and an alternative approach that could be more efficient. However, the comment could be more helpful if it included specific reasoning or evidence to support the claim that the alternative method is more effective. Overall, the comment is 3 as it identifies a potential weakness in the experimental design and offers a suggestion for improvement, but it could be more comprehensive with additional details or examples."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to clarify what \"Omega\" is and to be more explicit about the link function and the theorem in 32 that provides the regret guarantee. These requests are direct and specific, providing clear guidance on what needs to be addressed. The authors know exactly what information to include and how to improve their draft in response to these questions. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L178,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as clarifying what \"Omega\" is, being more explicit about the link function, and specifying the theorem in 32 for the regret guarantee. This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions asking for clarification on specific aspects of the paper, such as the definition of \"Omega,\" the link function, and the theorem reference. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback by asking the authors to clarify the definition of \"Omega\" and to be more explicit about the link function and the theorem reference in 32. This feedback is clear and direct, guiding the authors to address potential confusion or gaps in their draft. By addressing these points, the authors can improve the clarity and comprehensiveness of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the models being learned directly from pixels without a Markovian state. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their models. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the models being learned directly from pixels without a Markovian state. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the absence of a Markovian state in the learning process, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the models being learned directly from pixels without a Markovian state. This is a critical observation that could impact the validity and effectiveness of the models. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their approach. Without additional context or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the usefulness of the sequence example in the paper but raises a specific concern about Example 2, questioning the common practice of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF. The reviewer suggests that the authors should provide references to support this approach. While the comment identifies a specific issue and requests references, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address the concern. The action is implicit and somewhat vague, as the authors need to infer that they should provide references to support the approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the mention of a \"common\" practice in the context of CRF, questioning the use of the Hamming distance over entire parts of the sequence as a scoring loss. The comment further requests references to support this approach, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of the Hamming distance as a scoring loss in Example 2, questioning its commonality and suggesting that the authors provide references to support this approach. While the comment identifies a potential issue, it lacks specific references or examples to substantiate the claim that this practice is uncommon. The suggestion to provide references is a step towards addressing the concern, but the comment remains 3 due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the usefulness of the sequence example in the paper but raises a specific concern about Example 2, questioning the common practice of using the Hamming distance over entire parts of the sequence as a scoring loss in the context of CRF. The reviewer suggests that the authors provide references to support this approach, which is a constructive and actionable feedback. By pointing out this potential issue and requesting references, the comment helps the authors improve the clarity and credibility of their work. However, the comment could be more helpful if it provided specific references or examples of works that report the Hamming loss defined nodewise. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests two actions: changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections while briefly mentioning the metrics in the captions of the tables. These suggestions are explicit and provide clear guidance on how the authors can improve their draft. The first action is concrete, as it specifies what needs to be changed, and the second action is also concrete, as it suggests how the metrics should be integrated into the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections, which implies that the authors should consider renaming the section and possibly revising the content. However, it does not specify which sections or parts of the paper are being addressed, making it weakly grounded. The comment is specific in suggesting changes to the terminology and structure of the paper, but without explicit references to sections, it is challenging for the authors to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and removing the corresponding sections, suggesting that the metrics are wellknown and standard practice. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that the metrics are indeed wellknown and standard. The authors would need to verify this themselves or seek additional information to fully understand the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting a change in terminology and the removal of sections, which could improve the clarity and organization of the paper. It also offers a specific suggestion to briefly mention the metrics in the captions of the tables, aligning with common practices. This feedback is clear and provides concrete steps for the authors to enhance their draft, making it 4. However, it could be more helpful if it included additional context or examples to fully support the suggestion. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any explicit guidance or suggestions on how to explore the dataset further or what aspects should be emphasized. The action is implicit and vague, as the authors are left to infer that they should expand their discussion or analysis of the dataset but without specific direction on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper where the dataset is mentioned. Without explicit references or detailed guidance, the authors may find it challenging to determine exactly where to focus their efforts. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could enhance the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific guidance or examples on how the authors might expand their discussion or analysis of the dataset. Without actionable advice or detailed suggestions, the comment lacks depth and does not offer the authors a clear path to improve their draft. As a result, the feedback is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It provides a specific example of the issue, mentioning the squished axes and the difficulty in characterizing the improvement as remarkable. This feedback is clear and direct, giving the authors a specific action to take in revising their draft. The comment is 5 as it provides concrete guidance on how to improve the language used in the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"218,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the use of the term \"remarkable\" and suggesting the use of more objective terms. The comment further clarifies the issue by mentioning the difficulty in characterizing the improvement as remarkable due to the squished axes. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the term \"remarkable\" should be replaced with more objective terms due to the difficulty in characterizing the accuracy improvement as such. The reviewer provides a specific example of the issue by mentioning the squished axes, which makes the claim 3. However, the comment lacks detailed reasoning or references to support the claim fully. While the example of the squished axes provides some context, it does not fully substantiate the claim, leaving it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors use more objective terms instead of \"remarkable\" when describing the accuracy improvement. It highlights a potential issue with the use of subjective language, which could mislead readers. By pointing out the difficulty in characterizing the improvement as remarkable due to the squished axes, the comment offers a clear direction for improvement. This feedback is valuable as it helps the authors refine their language to be more precise and objective, enhancing the clarity and credibility of their work. However, the comment could be more helpful if it provided examples of alternative, more objective terms or suggested ways to quantify the improvement. Overall, the comment is 4, as it effectively guides the authors in revising their language to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the synthesized results for UCF101, noting inconsistencies in motion, color, and object disappearance over time. It suggests that using videos with a longer duration, such as by running the LSTM over many time steps, could potentially address these issues. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what could be done to improve the results, but the action is not explicitly stated, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"short video sequences\" and references the UCF101 dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the synthesized results, noting inconsistencies in motion, color, and object disappearance over time. The suggestion to use videos with a longer duration by running the LSTM over many time steps is specific and provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the synthesized results for UCF101 exhibit inconsistencies in motion, color, and object disappearance over time. It suggests that using videos with a longer duration could potentially address these issues by running the LSTM over many time steps. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim of inconsistencies. The suggestion is 3 as it offers a potential solution but requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the synthesized results for the UCF101 dataset, noting inconsistencies in motion, color, and object disappearance over time. It suggests that using videos with a longer duration, such as by running the LSTM over many time steps, could potentially address these issues. This feedback is clear and actionable, providing the authors with a concrete direction for improvement. However, the comment could be more helpful if it included specific examples or detailed reasoning about how the suggested approach would resolve the inconsistencies. Overall, the comment is 4 as it offers a valuable suggestion for enhancing the results, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges that realizing efficiency gains on GPU is a common challenge in pruning work, but it does not provide any specific guidance or suggestions for how the authors might address this issue or improve their approach. The comment lacks actionable content, leaving the authors without a clear direction for enhancing their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges a common challenge in pruning work, specifically regarding the difficulty of realizing efficiency gains on GPU. However, it does not specify which part of the paper this issue is relevant to, nor does it provide any guidance on how the authors might address this challenge. Without explicit references to sections or specific parts of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity in terms of what needs to be addressed or improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges a common challenge in pruning work, specifically regarding the difficulty of realizing efficiency gains on GPU. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. While it identifies a relevant issue, it lacks actionable feedback or suggestions for how the authors might address this challenge or improve their approach. Without specific guidance or examples, the comment does not provide the authors with a clear path for enhancing their draft. Therefore, it is rated as 2, as it highlights a potential area of concern but does not offer actionable insights or suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not entirely fair due to the complexity of the problem addressed by 5. While the comment identifies a potential issue with the evaluation, it does not provide explicit guidance on how the authors should address this concern. The feedback lacks concrete suggestions or actions for improvement, such as recommending additional evaluation on realworld data or suggesting ways to adapt the comparison to a fairer basis. As a result, the authors are left without a clear understanding of what steps to take to enhance the credibility of their evaluation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation, specifically noting that the method is only evaluated on synthetic data and that the comparison with 5 is not completely fair due to the complexity of the problem addressed by 5. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the evaluation and the potential unfairness of the comparison, but it lacks grounding as it does not reference a specific section or table. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing due to the evaluation being conducted only on synthetic data and the comparison with 5 being unfair because 5 is designed for a more complex problem. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide evidence or references to substantiate the assertion that the evaluation is unfair or that 5 is more complex. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the numerical evaluation, noting that the method is only evaluated on synthetic data and that the comparison with 5 is not entirely fair due to the complexity of the problem addressed by 5. This feedback highlights an important aspect that the authors should consider when evaluating their method, which is crucial for ensuring the robustness and generalizability of their results. However, the comment could be more helpful if it provided specific suggestions on how to address this issue, such as recommending additional evaluation on realworld data or suggesting ways to adapt the comparison to a fairer basis. Overall, the comment is 3 as it points out a potential limitation but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment implies that conducting this experiment could strengthen the paper, but it does not explicitly instruct the authors to perform the experiment. The action is implicit and somewhat vague, as the authors need to infer that they should consider conducting the experiment to strengthen their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this is not explicitly mentioned. The comment is specific in questioning the impact of the number of bits in logits on robustness, but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but does not provide any supporting evidence or references to substantiate this claim. The comment acknowledges that the experiment is not absolutely necessary but implies that it could strengthen the paper. However, without specific reasoning or references, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the study of the number of bits in logits and their impact on robustness against a larger epsilon in the PGD attack. It suggests that having a 32bit logit might improve robustness, but acknowledges that this experiment is not absolutely necessary. The comment implies that conducting this experiment could strengthen the paper, as it aligns with the intuition that increased robustness is beneficial. However, the comment lacks specific guidance or suggestions on how to conduct the experiment or what results to expect. While it identifies an area for potential improvement, the feedback is 3 as it provides a direction for further exploration but does not offer detailed instructions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the method might affect insurance costs. The comment lacks both explicit and implicit actions, leaving the authors without any direction on how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about insurance costs, but without grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the impact of the method on insurance costs for men and women. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest or concern, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the method might affect insurance costs. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it provides a starting point for the authors but does not offer comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their categorization. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the discrepancy between arXiv and ACL Anthology publication dates, particularly mentioning the BERT paper as an example. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper categorizes papers based on their publication years, specifically mentioning the ACL Anthology, but notes that many papers are available on arXiv much earlier. The comment provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This provides some context and evidence for the claim, making it 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. It provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This feedback is 3 as it highlights a potential inconsistency in the paper\"s categorization, but it lacks depth and does not offer suggestions on how the authors might address this issue or improve their categorization. The comment could be more helpful if it provided additional context or guidance on how to handle such discrepancies in future work. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part questions why the authors did not use Importance sampling instead of the proposed relaxation of rejection sampling. This part is 3 as it prompts the authors to clarify their choice. The second part of the comment asks for clarification on the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide a specific value of u for which the two methods behave differently. This part is explicit and concrete, providing a clear action for the authors to take. However, the first part lacks specificity and does not provide a direct action, making the overall comment 3.", "grounding_specificity_rationale": "The comment addresses two specific issues: the use of an arbitrary parameter beta instead of the true upper bound of the ratio p/q, and the difference between QRS and RS in Algorithm 1. The first part of the comment is fully grounded as it explicitly mentions the use of beta and the true upper bound, allowing the authors to accurately identify the part of the paper being addressed. The second part is also fully grounded, as it refers to Algorithm 1 and the specific difference between QRS and RS. The comment is specific in detailing what needs to be addressed in each part, providing clear guidance for the authors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions why the authors did not use Importance sampling instead of the proposed relaxation of rejection sampling, which is using an arbitrary parameter beta. This part is 3 as it raises a logical question about the authors\" choice, but it lacks specific reasoning or examples to support the claim. The second part of the comment questions the difference between QRS and RS in Algorithm 1 and asks for clarification. This part is also 3, as it seeks clarification on a specific aspect of the algorithm, but it does not provide detailed reasoning or examples to support the need for clarification. Overall, the comment is 3 due to the lack of detailed justification or examples in both parts.", "helpfulness_rationale": "The review comment raises two points. First, it questions why the authors did not use Importance sampling instead of the proposed relaxation of rejection sampling, which uses an arbitrary parameter beta instead of the true upper bound of the ratio p/q. This part of the comment is 3 as it prompts the authors to clarify their choice and potentially improve their methodology. However, it lacks depth and does not provide specific suggestions for how to address this issue. The second part of the comment asks for clarification on the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide a specific value of u for which the two methods behave differently. This part is explicit and actionable, offering a clear direction for the authors to improve their draft. Overall, the comment is 3, as it identifies areas for clarification and improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, it does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve the performance. The comment lacks actionable details, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, it does not specify which part of the paper discusses these enhancements or where further refinement is needed. This lack of grounding makes it difficult for the authors to identify the exact sections that require attention. The comment is specific in suggesting a need for further refinement, but without clear grounding, it is not actionable. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that the enhancements are modest or to suggest where further refinement is needed. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the observed performance enhancements but suggests that they are modest, implying there is room for further refinement. While it identifies a potential area for improvement, the comment lacks specificity and actionable guidance. It does not provide any suggestions on how the authors might address this issue or what specific aspects need further refinement. As a result, the feedback is vague and does not offer the authors a clear path to improve their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to provide references for specific passages in Section 3.2, lines 230234 and 234235, which discuss the sequencetosequence machine translation model and previous works on summarization generation tasks. Additionally, it asks for clarification on \"MLP\" in Figure 2, as it is not described in the paper. These requests are clear and direct, providing the authors with explicit actions to take. The feedback is concrete, as it specifies exactly what needs to be addressed and how to implement the changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230234 and 234235\" and \"Figure 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as providing references for the passages about the sequencetosequence machine translation model and summarization generation tasks, and clarifying the term \"MLP\" in Figure 2. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: one requesting references for specific passages in the paper, and the other asking for clarification on \"MLP\" in Figure 2. The first part is 3 as it suggests providing references for specific sections, but it lacks detailed guidance on which references to include or why they are necessary. The second part is 1 because it does not provide any reasoning or context for why \"MLP\" is unclear or needs clarification. Overall, the comment is 4 due to the first part, but the lack of support for the second part makes it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the paper lacks references, such as the sequencetosequence machine translation model and previous works on summarization generation tasks. It also points out a missing explanation for \"MLP\" in Figure 2, which is a crucial element for understanding the figure. These suggestions are clear and actionable, providing the authors with specific steps to improve the clarity and completeness of their paper. However, the comment could be more helpful if it offered additional guidance on how to find or select appropriate references or suggested specific works to include. Overall, the feedback is 4, as it directs the authors to improve their draft by addressing these gaps."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to provide more convincing evidence or address the issues mentioned. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not specify which part of the paper these experiments are located in, making it difficult for the authors to identify the exact sections being referred to. While the authors can infer that it relates to the experimental results, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the concern about the experimental results and the potential issues with the proposed method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are not convincing or how the similarity to IRM is problematic. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment raises a concern about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above, implying that the results may not be robust. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the experimental results. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is 3, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference between detecting \"just\" the long one. While the comment raises a valid point about the purpose of detecting both entities, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the purpose of detecting both entities or provide a rationale for including both in the example. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks about the difference to \"just\" knowing the long one. This provides clear guidance on what aspect of the example needs further explanation or clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference to \"just\" knowing the long one. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of detecting both entities in Figure 2 and asks about the difference between detecting \"just\" the long one. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with a general question that does not offer a clear path for improvement. Therefore, it is rated as 2, as it provides some insight but does not fully support the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks empirical validation, specifically mentioning the absence of experiments to validate the bounds. It provides a clear and direct action for the authors to take, suggesting that they should include experiments to validate the bounds. This feedback is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment points out the absence of empirical validation, specifically mentioning the lack of experiments to validate the bounds. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not as clear as it could be. The comment is specific in its request for experiments to validate the bounds, but it lacks full grounding because it does not explicitly mention the sections or figures where this validation should be included. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation, specifically mentioning the absence of experiments to validate the bounds. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the absence of empirical validation, specifically mentioning the lack of experiments to validate the bounds. This feedback is clear and actionable, as it directs the authors to include experiments to substantiate their claims. However, the comment could be more helpful if it provided suggestions on how to design these experiments or what specific aspects of the bounds should be validated. Overall, the comment is 4 as it highlights a significant area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. It points out that the upper bound in this case would be 0, which is not true. However, the comment does not provide any explicit or implicit actions for the authors to take. It simply highlights a potential issue without suggesting how the authors should address it. As a result, the authors are left without guidance on how to improve their draft in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption of a separate node with 0 neighbors and explaining why the upper bound would be 0, which is not true. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. The reviewer points out that the upper bound in this case would be 0, which is not true. This raises a logical inconsistency that the authors need to address. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to investigate further to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about Theorem 1, pointing out a potential inconsistency in the assumption of a separate node with 0 neighbors. It highlights that the upper bound in this case would be 0, which is not true, and asks for an explanation. This feedback is clear and actionable, as it directs the authors to address a specific issue in their theoretical framework. However, it could be more helpful if it provided additional context or suggestions on how to resolve the inconsistency. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques a statement on page 5, suggesting that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers. It also notes that this point is not revisited in the Discussion section and suggests deleting the \"Discussion\" label if it is not relevant. While the comment identifies a potential issue with the discussion, it does not explicitly instruct the authors to make any changes or improvements. The suggestion to delete \"Discussion\" is clear, but the lack of specific guidance on how to address the issue makes the comment 3. The authors know what needs to be done but may need additional context to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential inconsistency in the discussion regarding the training time reduction and parameter reduction. The comment is specific in suggesting that the discussion on this topic should be revisited or deleted, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques a statement on page 5, suggesting that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers. The reviewer questions whether this point has been revisited in the Discussion section and suggests deleting \"Discussion\" if it is not relevant. However, the comment does not provide specific evidence or reasoning to support the claim that the training time reduction is less drastic than the parameter reduction or that the discussion is unnecessary. Without additional context or examples, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is rated as 2, as it provides some support but lacks detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques a specific statement on page 5, noting that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers. It suggests that this point has not been revisited in the Discussion section and recommends deleting the \"Discussion\" label if it is not relevant. This feedback is 3 as it identifies a potential inconsistency in the discussion and provides a clear suggestion for improvement. However, it could be more helpful if it offered additional context or guidance on why this issue is significant or how it could be addressed. Overall, the comment provides a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the problem addressed in the paper is specific to binding affinity prediction or applies to other downstream tasks. While it prompts the authors to consider the broader applicability of their work, it does not provide explicit guidance or suggestions on how to address this question. The action is implicit and somewhat vague, as the authors need to infer that they should explore the applicability of their problem to other tasks. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem addressed in the paper, specifically whether it is specific to binding affinity prediction or extends to other downstream tasks. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion. The authors may have to infer that it relates to the methodology or results sections where the problem is discussed. While the comment is specific in its inquiry, it lacks grounding as it does not explicitly mention a section or part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the applicability of the problem addressed in the paper, specifically whether it is specific to binding affinity prediction or extends to other downstream tasks. However, it does not provide any supporting evidence, reasoning, or references to justify this question. The comment lacks any specific examples or context to help the authors understand the scope of the problem or its potential applications. As a result, the claim is 1, as it does not provide sufficient information for the authors to address the question effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem addressed in the paper, specifically whether it is specific to binding affinity prediction or extends to other downstream tasks. This question prompts the authors to consider the broader implications of their work and encourages them to explore the potential applicability of their findings to different contexts. However, the comment does not provide specific guidance or suggestions on how to address this question or what aspects of the problem might be relevant to other tasks. While it identifies an area for further exploration, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a gap in the analysis of GPTgenerated rumors, suggesting that there is no explanation for why these rumors are as difficult to detect as natural rumors. It implies that the authors should provide further analysis or solutions to address this issue. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors can infer the need for additional analysis but lack concrete steps on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a gap in the analysis, questioning why GPTgenerated rumors are as difficult to detect as natural rumors, despite being written by humans. The comment suggests that further analysis or solutions should be proposed to address this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the difficulty of detecting rumors generated by GPT compared to natural rumors. It suggests that since artificial rumors are written by humans, they should be about the same difficulty as natural rumors, but the experimental results show otherwise. The comment implies that there is a gap in the analysis that needs to be addressed. However, it does not provide specific evidence or references to support this claim, making it 3. The authors would need to conduct further analysis or provide additional context to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the analysis of GPTgenerated rumors, specifically questioning why these rumors are as difficult to detect as natural rumors. It points out that artificial rumors are written by humans and should be about the same difficulty as natural rumors, but the experimental results suggest otherwise. This feedback is 3 as it highlights an area for further exploration and analysis. However, it could be more helpful if it provided specific suggestions or guidance on how to address this issue or what additional analysis could be conducted. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. While it identifies a potential issue with the technical contribution, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The comment lacks concrete details or actionable steps for the authors to take, such as recommending specific changes or improvements to the content. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This feedback is 3 as it points out a potential area for improvement in the paper\"s technical depth. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the technical contribution. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and implement the suggested improvements. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a specific issue with Figure 6, noting that the font size is a bit small. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting a specific font size to use or recommending ways to improve the readability of the figure. Without any guidance or instructions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the font size being too small. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual observation about the font size in Figure 6 being small. It does not express an opinion, judgment, or suggestion that requires verification. It is a descriptive statement that does not claim or imply any specific issue or problem. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6, noting that the font size is too small. While this feedback is clear and points out a potential problem with the figure\"s readability, it lacks depth and does not provide any suggestions or guidance on how to address the issue. The authors are left without actionable steps to improve the figure, such as recommending a specific font size or suggesting ways to enhance the figure\"s clarity. Therefore, the comment is 3, as it highlights a problem but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. It implies that using various probability mass functions would add depth to the experimental setting. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed instructions on how to achieve it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of the probability mass function in MixBoost, specifically mentioning that it is set to a quasiuniform distribution. It suggests that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. However, the comment does not specify which part of the paper discusses the probability mass function or the quasiuniform distribution, making it weakly grounded. The suggestion is specific, as it clearly outlines what could be improved in the experimental setting. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. The reviewer implies that using various probability mass functions would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that the quasiuniform distribution is not wellsuited or that using various probability mass functions would be beneficial. Without detailed reasoning or evidence, the claim remains 3, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the probability mass function, which is currently set to a quasiuniform distribution, could be more effectively utilized. The reviewer points out that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the experimental design. However, the comment could be more helpful if it included examples or references to support the claim that various probability mass functions would be beneficial. Overall, the comment is 4 as it directs the authors to a potential improvement in their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to discuss connections with a specific reference, a, which is relevant to their topic. It provides a clear action by suggesting that the authors should address the connections with a, which uses supervised learning in QBF solving. This guidance is concrete and provides a direct path for the authors to improve their draft by incorporating this reference and its connections. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed by suggesting a discussion of connections with a particular reference, a, which uses supervised learning in QBF solving. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references provided are relevant to the topic and suggests discussing connections with a specific reference, a, which uses supervised learning in QBF solving. However, the comment does not provide detailed reasoning or evidence to support why these connections are important or how they relate to the authors\" work. The lack of specific examples or detailed justification makes it difficult for the authors to understand the significance of the suggestion. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a missing reference that is relevant to the topic, specifically mentioning a as a potential connection. It suggests that the authors discuss the connections with this reference, which uses supervised learning in QBF solving, as QBF generalizes SMT. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by incorporating relevant connections and references. However, the comment could be more helpful if it included additional context or guidance on how to integrate these connections effectively. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison in terms of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to consider. Without any actionable advice or suggestions, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in asking about the comparison of computation cost or running time, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking for clarification about the comparison in terms of computation cost or running time. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison in terms of computation cost or running time, which is a relevant aspect to consider in evaluating the efficiency and practicality of the proposed method. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison should be included. While it identifies a potential area for improvement, it lacks actionable feedback or detailed advice, making it 3. The authors are left with a general idea of what to consider but without specific steps to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors clarify the goal of the paper in the introduction and provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses. It also recommends considering other ERMbased distributed algorithms like Hogwild. While the comment explicitly states these actions, it does not provide detailed guidance on how to achieve these changes or what specific aspects of the paper need to be revised. The authors are given a clear direction but may need to infer the exact steps to take to implement the suggestions fully. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"goal of the paper in the introduction\" and provides specific examples of the second paragraph where samplingbased Bayesian methods are mentioned. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests a focus on problems where the loss function does not decompose as the sum of sample losses and recommends considering other ERMbased distributed algorithms like Hogwild. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors did not provide a clear picture of the paper\"s goal in the introduction and suggests that the examples chosen did not convince the reviewer that there are problems requiring a lot of interprocess communication. The reviewer also mentions that the second paragraph, where samplingbased Bayesian methods are discussed, does not present relevant results that are already known. The reviewer suggests focusing on problems where the loss function does not decompose as the sum of sample losses and recommends considering other ERMbased distributed algorithms like Hogwild. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim fully. Therefore, the comment is 4, as it provides a reasonable basis for the suggestion but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper\"s goal in the introduction, suggesting that the examples chosen may not effectively convey the need for interprocess communication. It provides a specific suggestion to focus on problems where the loss function does not decompose as the sum of sample losses, which could be more relevant to the paper\"s objectives. Additionally, the comment recommends considering other ERMbased distributed algorithms like Hogwild, offering a direction for the authors to explore. While the comment provides actionable feedback, it could be more helpful if it included specific examples or detailed guidance on how to address these issues. Overall, the comment is 4 as it directs the authors to improve the clarity of their paper\"s goals and suggests a more focused direction for their research."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacypreserving nature of the approach compared to other federated learning methods. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed explanation of the privacypreserving aspects of their approach and address the potential privacy concerns in traffic signal control. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the privacypreserving nature of the approach compared to other federated learning methods and questions whether privacy preservation is a concern in traffic signal control. However, it does not specify which part of the paper this discussion pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its questions about privacy and the application of federated learning in traffic signal control, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the privacypreserving nature of the approach compared to other federated learning methods and questions whether privacy preservation is a concern in traffic signal control. However, it does not provide any specific evidence, examples, or references to support these claims. The comment lacks detailed reasoning or references to substantiate the assertion that one traffic signal knowing the color of the next one is a bad example of federated learning. Without additional context or justification, the claim remains 1, making it difficult for the authors to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises important questions about the privacypreserving nature of the approach compared to other federated learning methods. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example. This feedback is 3 as it prompts the authors to consider the privacy implications of their approach and the potential limitations of federated learning in traffic signal control. However, the comment lacks specific guidance or suggestions on how to address these concerns or improve the privacy aspects of the approach. To be more helpful, the comment could provide more detailed feedback or examples of how to enhance privacy in federated learning for traffic signal control. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly mentions that the hyperlinks for footnotes 3 and 4 do not seem to work. This provides a clear and direct action for the authors to take, which is to verify and correct the hyperlinks. The comment is explicit and concrete, giving the authors a straightforward task to address. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment is specific because it clearly identifies the issue with the hyperlinks not working, giving the authors a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a factual observation about the nonfunctioning of hyperlinks for footnotes 3 and 4. It does not express an opinion, judgment, or suggestion that requires verification. It is a straightforward statement of a technical issue, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the hyperlinks for footnotes 3 and 4, noting that they do not seem to work. This is a clear and actionable feedback that directly impacts the usability and accessibility of the paper. By pointing out this technical issue, the authors are given a straightforward task to address, which is to verify and correct the hyperlinks. This feedback is helpful as it provides a concrete step for improvement, ensuring that the paper is userfriendly and accessible. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, which is currently unclear. It specifically mentions the need for a better formalization of the architecture in section 2 and points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to revise the discussion or what specific changes are needed. The action is implicit and somewhat vague, as the authors can infer the need for clarification but lack detailed guidance on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, indicating that it is currently unclear. It specifies that a better formalization of the architecture in section 2 would be beneficial, and it points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. This provides some level of grounding as it mentions specific sections and elements of the paper, but it does not explicitly name them, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the architecture and the figure, which helps the authors understand the issues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, which is currently unclear. It provides a specific example by mentioning section 2 and the need for a better formalization of the architecture. The comment also points out that the figure is misleading, implying that the Label Embeddings are the output of the encoder rather than external parameters. While the comment provides some reasoning and examples, it lacks detailed justification or references to support the claim fully. The authors are left with a suggestion to improve clarity but without explicit guidance on how to achieve this. Therefore, the comment is 3, as it provides some support but requires more detailed explanation or references to be fully actionable.", "helpfulness_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, which is currently unclear. It provides a specific suggestion to improve clarity by offering a better formalization of the architecture in section 2. Additionally, it points out a potential issue with the figure, suggesting that it might be misleading, as it implies that Label Embeddings are the output of the encoder rather than external parameters. This feedback is clear and actionable, as it directs the authors to improve the clarity of their discussion and provides specific areas for revision. However, the comment could be more helpful if it offered additional guidance on how to achieve these improvements or suggested alternative approaches. Overall, the comment is 4, as it provides valuable insights and actionable steps for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of training the model with attentionbased encdec training instead of CTC loss. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this possibility. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not specify which part of the paper discusses the model\"s training or limitations, making it weakly grounded. The comment is specific in its suggestion to explore alternative training methods, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. However, it does not provide any supporting evidence, reasoning, or references to justify why this change might be beneficial or necessary. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s limitation to CTC loss and suggests the possibility of training it with attentionbased encdec training. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance on why this change might be beneficial or how it could be implemented. The authors are left with a general suggestion but without actionable feedback or detailed reasoning, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific steps they should consider to improve the image quality. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the impact of mitigation methods on the image generation capabilities of diffusion models, specifically mentioning that it can lead to lower image quality. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the effect of the mitigation methods on image quality, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment highlights a potential issue with the mitigation methods used in the paper, specifically noting that they affect the image generation capabilities of diffusion models, leading to lower image quality. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the image quality. Without actionable feedback or detailed recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential problem but does not offer meaningful assistance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or mitigate the risk of unfairness. The action is implicit and vague, as the authors are left to infer that they need to consider these issues and possibly adjust their methodology or analysis. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the fairness of comparisons, making it weakly grounded. The issue is clearly specified, as it addresses the potential risk of unfairness in the comparisons. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or references to support the claim of unfairness, making it difficult for the authors to fully understand and address the issue. The reasoning is logical, but the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. This feedback is important as it points out a critical aspect that the authors should consider when evaluating their results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of unfairness. While it identifies a potential problem, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what aspects of the paper could be revised in response. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation about the dominance of function words over content words in a Japanese sentence, which is a clear issue for the authors to consider. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or context to explain why this might be surprising or how it relates to the paper\"s content. Without any justification or references, the claim lacks verifiability, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as depicted in Figure 1. However, it does not provide any context, explanation, or suggestions for why this might be surprising or how it relates to the paper\"s content. Without additional information or guidance, the authors are left without a clear understanding of what aspects of the paper need improvement or clarification. The comment lacks actionable feedback, making it difficult for the authors to address the issue effectively. Therefore, it is rated as 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the FLOT cost matrix in Algorithm 1 is not defined. This provides a clear and direct action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the FLOT cost matrix is not defined. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. This is a factual statement that does not require any supporting evidence or justification. It is a straightforward observation that the authors should address, but it does not provide any reasoning or context to explain why this is a significant issue. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the FLOT cost matrix in Algorithm 1 is not defined. This is a clear and actionable feedback that highlights a gap in the paper\"s presentation, which is important for the authors to address. By pointing out this omission, the comment provides a direct suggestion for improvement, allowing the authors to enhance the clarity and completeness of their draft. However, the comment could be more helpful if it offered additional guidance on how to define the FLOT cost matrix or suggested potential consequences of this omission. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the clarity of the definition of the sparsity of the residual term and suggests that the authors provide evidence to support this assumption across various noisy cases. It also implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment does not explicitly instruct the authors to provide specific evidence or comparisons, the actions are clear and can be inferred from the comment. The authors know what needs to be addressed to improve their draft, but the comment lacks concrete details on how to execute these actions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the clarity of the definition of the sparsity of the residual term and suggests providing evidence to support this assumption across various noisy cases. It also implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where the sparsity assumption is discussed. The comment is specific in detailing what needs to be addressed, such as providing evidence and demonstrating advantages. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of the definition of the sparsity of the residual term and suggests providing evidence to support this assumption across various noisy cases. It also implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment does not contain an explicit claim, it poses a logical question and suggests a direction for improvement. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a specific concern about the clarity of the definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests that the authors provide evidence to support this assumption across various noisy cases. Additionally, the comment implies that the authors should demonstrate the advantages of their method compared to existing methods. While the comment identifies a potential area of improvement, it lacks detailed guidance or specific suggestions on how to address these issues. The authors are given a direction to improve their draft, but the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it points out a specific area for clarification but does not fully guide the authors in making improvements."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the term \"connectivity\" as misleading because it does not reflect the structural connections between the brain and body. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what alternative terminology might be more appropriate. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the term \"connectivity\" as misleading, suggesting that it does not accurately reflect the structural connections between the brain and body. However, it does not specify which part of the paper this critique pertains to, such as a specific section, figure, or table. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper needs revision. This lack of grounding and specificity makes it difficult for the authors to address the issue effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not reflect the structural connections between the brain and body. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the term \"connectivity\" as misleading because it does not accurately reflect the structural connections between the brain and body. This feedback is specific and identifies a potential issue with the terminology used in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the terminology. Without actionable advice or examples, the comment is 3 as it highlights a potential area for improvement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. It suggests referring to the \"Clarity, Quality, Novelty And Reproducibility\" section for more information, but it does not provide specific guidance on what details are missing or how to address them. The comment lacks explicit instructions or concrete steps for the authors to take to improve their draft, making it difficult for them to know exactly what actions to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper is not polished and lacks details in related work, experiments, and writing, but it does not specify which parts of the paper are affected or provide specific examples of what is missing. This makes it difficult for the authors to identify the exact areas that need attention. The mention of \"Clarity, Quality, Novelty And Reproducibility\" implies that the authors should refer to this section for more information, but it does not provide actionable guidance on how to address the issues. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks details in related work, experiments, and writing, but it does not provide specific examples or evidence to support these claims. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests that the authors should refer to this section for more information, but it does not offer actionable feedback or detailed guidance on how to improve the paper. Without specific examples or references, the claim remains 1, making it difficult for the authors to address the issues effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is not polished and lacks details in related work, experiments, and writing. It suggests referring to the \"Clarity, Quality, Novelty And Reproducibility\" section for more information, but it does not provide specific guidance or examples of what details are missing or how to improve them. While the comment highlights an important area for improvement, it lacks actionable feedback and detailed suggestions, making it 3. The authors are given a direction to look for more information, but they are left without specific steps to take to address the issues. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a detailed explanation of the steps involved in the process, identifying that the token reverse operation is straightforward and that Step 2 can be performed regardless of the weight matrix being orthogonal. It highlights that Step 3 is crucial for validating the use of orthogonal matrices, which is not addressed in the paper. However, the comment does not explicitly instruct the authors to include this validation or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should address this aspect in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific steps in the paper, identifying \"Step 2\" and \"Step 3,\" which allows the authors to accurately pinpoint the parts being discussed. It also mentions \"orthogonal matrix weight\" and \"local window MLP,\" providing clear references to the relevant sections. The comment is specific in detailing what needs to be addressed, such as the importance of Step 3 in validating the use of orthogonal matrices. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the token reverse operation is easy to get and that Step 2 can be done regardless of the weight matrix being orthogonal. It also suggests that Step 3 is crucial for validating the use of orthogonal matrices. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. While the reviewer provides a logical explanation for why Step 3 is important, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed analysis of the steps involved in the process, identifying that the token reverse operation is straightforward and that Step 2 can be performed regardless of the weight matrix being orthogonal. It highlights the importance of Step 3, which only orthogonal matrices can perform, and suggests that this aspect should be studied to validate the use of orthogonal matrices. This feedback is clear and actionable, offering the authors a specific area to explore and improve upon in their draft. However, the comment could be more helpful if it provided additional guidance or examples on how to conduct this study. Overall, the comment is 4, as it directs the authors to a critical area for improvement and provides a clear direction for further investigation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop in Figure 5, specifically asking why it starts to drop after a certain order of around 45. While the comment implies that the authors should consider overfitting as a potential cause, it does not explicitly instruct the authors to investigate this or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should explore overfitting as a possible explanation for the accuracy drop. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason behind the accuracy drop after a certain order, specifically asking if it is due to overfitting. This provides clear guidance on what aspect of the figure needs further explanation or analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the accuracy drop in Figure 5, specifically asking why it starts to drop after a certain order. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the accuracy drop observed in Figure 5, specifically asking why it starts to drop after a certain order of around 45. This question prompts the authors to consider potential causes, such as overfitting, which could help them better understand and potentially improve the results presented in the figure. However, the comment does not provide specific guidance or suggestions on how to address this issue or what steps to take to investigate overfitting. While it identifies an area for further exploration, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also inquires about the possibility of experimenting on language tasks. While the comment explicitly states these actions, it lacks concrete guidance on how to address these suggestions or what specific improvements would be beneficial. The authors are left with a general idea of what needs to be done but without detailed instructions on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of CIFAR100, ResNet 34 or 50, and ViTtiny or small. It also inquires about the possibility of experimenting on language tasks. However, the comment does not specify which part of the paper discusses the models and datasets, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed regarding the models and datasets, as well as the potential for language task experiments. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of more challenging datasets like CIFAR100 and models like ResNet 34 or 50, as well as ViTtiny or small. The reviewer also inquires about the possibility of experimenting on language tasks. While the comment provides a logical basis for the suggestions, it lacks specific references or detailed reasoning to fully substantiate the claims. The authors are left to infer the significance of these suggestions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the models and datasets used in the paper, suggesting that they are too toylike and recommending the inclusion of more challenging datasets like CIFAR100 and models like ResNet 34 or 50, as well as ViTtiny or small. The reviewer also inquires about the possibility of experimenting on language tasks. While the comment provides some guidance on what could be improved, it lacks specific suggestions or detailed reasoning on how to address these issues. The authors are left with a general idea of what needs to be done but without actionable steps or examples. Therefore, the comment is 3, as it points out areas for improvement but does not fully guide the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors did not consider the Vision Transformer, an important SOTA model in image classification, in their experiments. It also raises a question about whether the technique is still effective for larger datasets like ImageNet and whether the pruning strategy would differ in selfattention layers. While the comment identifies a potential gap in the experimental setup and raises a question about the applicability of the technique, it does not provide explicit guidance on how the authors should address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should consider including the Vision Transformer in their experiments and explore its effectiveness on larger datasets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the absence of the Vision Transformer in the experiments and questions its applicability to larger datasets like ImageNet. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in questioning the inclusion of the Vision Transformer and its potential effectiveness, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not consider the Vision Transformer, an important SOTA model in image classification, in their experiments. It also questions whether the technique is still effective for larger datasets like ImageNet and whether the pruning strategy would differ in selfattention layers. While the comment raises valid concerns about the completeness of the experimental setup, it lacks specific examples or references to support the claim about the effectiveness of the Vision Transformer on larger datasets. The question about the pruning strategy in selfattention layers is a logical inquiry but does not provide direct evidence or reasoning. Therefore, the comment is 3, as it identifies potential gaps in the experimental setup but lacks detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental setup by noting the absence of the Vision Transformer, an important SOTA model in image classification. It raises a valid concern about the applicability of the technique to larger datasets like ImageNet and questions whether the pruning strategy would differ in selfattention layers. This feedback is clear and actionable, as it prompts the authors to consider including the Vision Transformer in their experiments and exploring its effectiveness on larger datasets. However, the comment could be more helpful if it provided specific suggestions on how to incorporate the Vision Transformer or how to address the potential differences in the pruning strategy. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper discusses the advantages of the proposed method in terms of efficiency but does not provide any metrics to support this claim. This feedback implies that the authors should include metrics to demonstrate the efficiency of their method. However, the comment does not explicitly instruct the authors to include specific metrics or specify which metrics would be most appropriate. While the action is implied, it is vague in terms of how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of metrics to support the claim of efficiency over previous work. However, it does not specify which part of the paper discusses the efficiency or where the metrics should be included. This makes it weakly grounded, as the authors cannot confidently determine which section to focus on. The comment is specific in pointing out the absence of metrics to support the claim of efficiency, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not report any metrics to support the claim of efficiency over previous work. This is a factual statement that does not require verification, as it is based on the absence of specific information in the paper. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that it claims advantages over previous work in terms of efficiency but does not provide any metrics to support this claim. This feedback is clear and actionable, as it directs the authors to include metrics that would substantiate their claims of efficiency. However, the comment could be more helpful if it suggested specific metrics or methods for measuring efficiency. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly requests the authors to provide more details about the statespace, whether it is finite or continuous, and to specify the space in which theta lies. It also suggests that the authors should be precise in their descriptions. This feedback is clear and direct, giving the authors a specific action to take: providing additional details about the statespace and the space of theta. The request is concrete, as it outlines what information is needed to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more details about the statespace, whether it is finite or continuous, and the space in which theta lies. The comment also suggests that the authors should be precise in their descriptions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual statement asking for additional details, which is a normal statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors need to provide more details. It points out that the statespace is not clearly defined as finite or continuous, and it questions the space in which theta lies. While the comment highlights a gap in the paper\"s clarity, it does not offer specific suggestions or guidance on how to address these issues. The authors are left with a general understanding of what needs to be clarified but without detailed instructions on how to improve the draft. Therefore, the comment is 3, as it provides a starting point for the authors to consider but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the method or address the issue, nor are there suggestions for specific changes or additions. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper discusses the method or provides details on how the comparison is made. The authors can infer that it relates to the method section or experimental results, but this inference is not explicit. The comment is specific in identifying the issue of effectiveness but lacks grounding, as it does not pinpoint the exact section of the paper being discussed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the method does not work effectively on general reasoning tasks compared to mathematical reasoning. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the method\"s effectiveness on general reasoning tasks compared to mathematical reasoning. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the method. Without actionable feedback or specific recommendations, the comment does not offer the authors a clear path to enhance their draft. As a result, it is rated as 2, as it provides some insight but does not fully support the authors in improving their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the contradiction or the applicability of Theorem 1. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the proof relies on a special case where a contradiction arises as matrix norms approach infinity, and that this is acknowledged in Section 3. The comment is specific in detailing what needs to be addressed, providing clear guidance on the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. This claim is 3 as it provides a specific observation about the proof technique and references a section where the issue is acknowledged. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to delve deeper into the proof to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also acknowledges that this is mentioned in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This feedback is 3 as it points out a potential weakness in the proof and highlights an area that requires further clarification or explanation. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or improve the proof. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also states that allowing \"t\" to be arbitrary does not add value. This feedback is explicit and provides a clear action for the authors to take, which is to make the suggested change for clarity. The comment is concrete, as it specifies what needs to be done and why it is beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the histogram intersection kernel, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of T for clarity and explains that allowing \"t\" to be arbitrary does not add value. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also claims that allowing \"t\" to be arbitrary does not add value. However, the comment lacks specific reasoning or examples to support why this change would improve clarity or why allowing \"t\" to be arbitrary is unnecessary. Without detailed justification or references, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by recommending the replacement of \"t\" with the size of T. This feedback is actionable and directly addresses a potential source of confusion in the paper. By suggesting a change that could enhance the reader\"s understanding, the comment offers a clear and constructive way for the authors to improve their draft. However, it could be more helpful if it explained why this change is beneficial or provided additional context on the importance of clarity in this context. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder might not produce meaningful embeddings for such concepts, which could be a concern for the proposed method. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the adaptation capacity. The action is implicit and vague, as the authors are left to infer that they need to explore or address this concern, but without concrete steps or examples. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It mentions the use of DINO representations, which are known for containing rich geometric information, and questions whether the adaptation capacity still holds for such concepts. However, the comment does not specify which part of the paper discusses the adaptation capacity or the proposed visual memory, making it weakly grounded. The comment is specific in detailing the concern about the adaptation capacity for concepts with semantic correlations, but it lacks grounding, as it does not point to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder might not produce meaningful embeddings for such concepts, which could be a concern for the proposed method. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it lacks detailed evidence or analysis to substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It questions whether the image encoder can produce meaningful embeddings for such concepts, which could be a concern for the proposed method. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the adaptation capacity. The feedback is 3 as it points out a potential limitation, but it could be more actionable with additional insights or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides a series of explicit and concrete actions for the authors to take. It suggests corrections to grammatical errors, such as \"Line 029: \u201c\u2026 as it a lightweight \u2026\u201d > shouldn\u2019t this be \u201c\u2026 as in a lightweight \u2026\u201d,\" and offers specific suggestions for clarifying terminology, like \"Line 188: PLN > NLP.\" It also points out a repetition of words in Table 3 and provides detailed guidance on correcting the DOI number and table formatting. Each suggestion is clear and actionable, giving the authors a straightforward path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides a series of specific corrections and suggestions for improving the draft, including grammatical corrections, terminology clarification, and formatting issues. It explicitly mentions line numbers and table references, allowing the authors to accurately identify the parts of the paper needing attention. The comment is fully grounded as it provides clear references to specific lines and elements in the paper, and it is specific in detailing what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of corrections and suggestions for improving the draft, such as grammatical corrections, terminology clarification, and formatting issues. These are factual statements that do not require verification or evidence. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of actionable suggestions for improving the draft, including grammatical corrections, terminology clarification, and formatting issues. It specifically points out errors in punctuation, spelling, and formatting, such as \"Line 029: \u2018\u2026 as it a lightweight \u2026\u2019 > shouldn\u2019t this be \u2018\u2026 as in a lightweight \u2026\u2019,\" and \"Table 3, row 2, column 3: 72,0 > 72.0.\" These suggestions are clear and directly address the manuscript, offering the authors a straightforward way to enhance the clarity and professionalism of their work. However, the comment could be more helpful if it provided additional context or reasoning for why these corrections are necessary. Overall, the comment is 4 as it provides specific guidance for improvement, but it could be more comprehensive with additional context."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides several explicit suggestions for improvement. It points out that the notation is confusing, specifically mentioning the use of M and N without definition. The reviewer suggests spelling out F.L.T.R in Figure 4 and notes that the text in Figure 1 is too small to read. Additionally, the comment recommends crossreferencing notation and figures, such as ensuring that M and N are shown in the figure. These suggestions are clear and provide specific actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment addresses multiple issues, including notation confusion, the need to define M and N, and suggestions for improving the clarity of Figure 4 and the text in Figure 1. It provides specific examples, such as spelling out F.L.T.R in Figure 4 and recommending crossreferencing notation and figures. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of several suggestions for improving the clarity and consistency of notation and figures in the paper. It does not contain any subjective opinions, claims, or judgments that require verification. The comments are factual and descriptive, making them \"No.\"", "helpfulness_rationale": "The review comment identifies several specific issues with the paper, including notation confusion, the need to define variables like M and N, and suggestions for improving the clarity of figures and text. The reviewer provides actionable feedback by suggesting ways to clarify notation and figure references, such as spelling out F.L.T.R in Figure 4 and ensuring that notation and figures are crossreferenced. This detailed guidance empowers the authors to make significant improvements to their draft, making the comment 5. However, it could be even more beneficial if it included specific examples or further suggestions for addressing the notation issues. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. While the comment points out a potential issue, it does not provide explicit guidance on how to address this confusion. The authors are left to infer that they should clarify the notation or reword the description to avoid ambiguity, but the comment lacks concrete suggestions or examples of how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out potential confusion regarding the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2 might be confusing. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the confusion. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential source of confusion in Algorithm 1, specifically mentioning the use of $p$ to denote the phase mixing probability and the presence of a dummy variable in the inner loop of Phase 2. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify their notation or wording to improve the clarity of their algorithm description. However, the comment could be more helpful if it provided suggestions on how to resolve the confusion, such as proposing alternative notation or rephrasing. Overall, the comment is 4 as it directs the authors to an area that needs attention but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that a more detailed mathematical formulation, such as in the appendix, would be beneficial to complement the highlevel description. It also provides specific feedback on the figure, suggesting that it is confusing due to its abstraction and misalignment with the main contribution of the paper. The reviewer suggests adding more text labels to the figure and reworking it to depict the WiC task, which would help address the issues. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"highlevel description\" and the \"figure,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the highlevel description, suggesting a more detailed mathematical formulation in the appendix, and provides specific feedback on the figure, such as the need for more text labels and reworking it to depict the WiC task. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a more detailed mathematical formulation would be helpful to complement the highlevel description and that the figure is confusing due to its abstraction and misalignment with the main contribution of the paper. The reviewer provides specific suggestions for improvement, such as adding more text labels to the figure and reworking it to depict the WiC task. While the comment does not provide explicit references or detailed reasoning, the suggestions are clear and actionable, making the claim 3. However, the lack of specific examples or detailed justification for the suggestions limits the level of verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting that a more detailed mathematical formulation, such as in the appendix, would complement the highlevel description. It also identifies specific issues with the figure, noting that it is confusing due to its abstraction and misalignment with the main contribution of the paper. The reviewer offers concrete suggestions for improvement, such as adding more text labels and reworking the figure to better align with the WiC task. These suggestions are clear and provide the authors with a roadmap for enhancing their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide specific guidance on which tasks to include or how they would enhance the paper. The action is implicit, as the authors need to infer that they should expand the benchmarking tasks, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which tasks should be added or how they would enhance the paper. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and what specific improvements are needed. The comment is 1 because it does not reference a specific section, table, or figure, and it is not specific due to the absence of detailed guidance. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that including additional benchmarking tasks outside of AitW would have been helpful. However, it does not provide any specific examples or reasoning to support why these additional tasks would be beneficial or how they would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The comment suggests that including additional benchmarking tasks outside of AitW would have been helpful. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on which tasks to include or how they would enhance the paper. The feedback is vague and does not offer actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several specific questions and suggestions for improvement regarding the experiments section. It explicitly asks for the comparison result of YOSO with linformer on iterationwise convergence and whether there is any comparison to explain the difference in performance on downstream tasks like SST2. These requests provide clear and concrete actions for the authors to take, such as including specific comparisons in the figures or providing an analysis of the performance differences. The feedback is explicit and detailed, offering a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as the lack of comparison results for YOSO with linformer on iterationwise convergence and the need for an explanation of the difference in performance on downstream tasks like SST2. This provides clear guidance on what the authors need to include or explain in their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the experimental setup and results, specifically regarding the comparison of YOSO with linformer. It requests clarification on the comparison results of YOSO with linformer on iterationwise convergence and an explanation for the difference in performance on downstream tasks like SST2. While the comment identifies areas for improvement, it does not provide specific evidence or reasoning to support the need for these clarifications. The request for an explanation of the performance difference is a logical inference, but without detailed justification or references, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper could be improved, particularly in the experiments section. It points out that the pretraining experiment does not provide a comparison of YOSO with linformer, specifically asking for the steps and perplexity results in Figure 4. Additionally, it questions the performance difference between YOSO and linformer on downstream tasks like SST2 and suggests an explanation for this difference. These suggestions are clear and actionable, providing the authors with specific areas to address and improve in their draft. However, the comment could be more helpful if it offered additional guidance or examples on how to analyze and present these comparisons effectively. Overall, the feedback is 4, as it directs the authors to make significant improvements in their experimental analysis and interpretation of results."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part questions whether the policy gradient in Equation 6 solves the optimal problem and whether convergence leads to the optimal solution for Equation 5. This raises a concern about the clarity of the presentation and suggests that it might be beneficial to clarify this aspect. The second part points out a minor issue with the line number 78, where \"on\" is unnecessary, and provides a correction. The first part of the comment is explicit and concrete, as it directly questions the clarity of the policy gradient\"s optimality and suggests a specific action to clarify it. The second part is also explicit and concrete, providing a clear correction for a minor error. Therefore, the comment is 5, as it provides explicit and concrete actions for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 6\" and \"Line 78,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the optimality of the policy gradient in Equation 6 and suggests clarifying this point. Additionally, it points out a minor issue with the line number 78, providing a correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part questions the optimality of the policy gradient in Equation 6, suggesting that it might be better to clarify this aspect. This raises a logical concern about the accuracy of the solution, but it lacks specific evidence or references to support the claim. The second part points out a minor issue with the line number 78, where \"on\" is unnecessary, providing a correction. While the first part is 3 due to the logical reasoning, the second part is clear and verifiable. Therefore, the overall verifiability of the comment is 3.", "helpfulness_rationale": "The review comment raises a critical question about the optimality of the policy gradient in Equation 6, suggesting that it might be beneficial to clarify this aspect. This feedback is valuable as it prompts the authors to revisit and potentially clarify a key concept in their work, which could impact the understanding and interpretation of their results. Additionally, the comment points out minor formatting issues, such as unnecessary words in Line 78 and a correction in Line 132. These suggestions are actionable and can help the authors improve the clarity and precision of their draft. However, the comment could be more helpful if it provided specific guidance on how to clarify the optimality of the policy gradient or suggested alternative ways to address this concern. Overall, the comment is 4, as it identifies important areas for clarification and improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks about the difference between the two. While the comment highlights an area for consideration, it does not provide explicit guidance or suggestions on how the authors should address this question or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of assuming a general Gaussian distribution and compare it to the isotropic Gaussian. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the difference between the two distributions, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It seeks clarification on the difference between these two distributions. While the comment identifies a potential area for improvement or clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the algorithm could be affected by this assumption. The feedback is 3 as it prompts the authors to consider the implications of their assumptions, but it lacks depth and actionable advice, leaving the authors with a general direction to explore without detailed guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should discuss the limitations of freezing the partitioning in the first iteration, as it makes strong assumptions about the coverage of the initial data. This feedback provides a clear and direct action for the authors to take, which is to include a discussion on the limitations of this choice. The comment is explicit and concrete, giving the authors a specific task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. The comment suggests that the authors should discuss the limitations of this choice, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. The reviewer suggests that the authors should discuss the limitations of this choice. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that this choice is risky or assumptions are being made. The suggestion to discuss the limitations is a logical response but requires further elaboration to fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the claim but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of freezing the partitioning in the first iteration, noting that it makes strong assumptions about the coverage of the initial data. It suggests that the authors should discuss the limitations of this choice, which is a valuable piece of feedback. By pointing out this potential weakness, the comment encourages the authors to consider and address an important aspect of their methodology. However, the comment could be more helpful if it provided specific guidance on how to discuss these limitations or suggested alternative approaches. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this issue or improve the section. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the intent of Section 5.2, but it does not specify which part of the paper this section is located in. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in questioning the intent of the section, but without clear grounding, it is challenging for the authors to understand the context or what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking for clarification about the intent of Section 5.2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which is a valid inquiry that could help the authors clarify their objectives and structure their discussion. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the section. It lacks actionable feedback or specific advice, leaving the authors without a clear path forward. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer actionable guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It also mentions that the paper delves into technical details without providing a clear overview of the approach. While the comment identifies areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take to address these issues. The feedback is vague and lacks actionable guidance, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It mentions that the paper delves into technical details without providing a clear overview of the approach. However, the comment does not specify which part of the paper is unclear or lacks explanation, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in identifying the issue of clarity and the need for better explanation, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It highlights the complexity of the technical details without providing a clear overview of the overall approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or references leaves the claim 3, as it requires the authors to infer the nature of the issues and how to address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern about the clarity of the approach and the lack of explanation regarding how it addresses the issue of reporting bias. It highlights the complexity of the technical details without providing a clear overview of the overall approach. While the comment points out a critical area for improvement, it lacks specific suggestions or actionable steps for the authors to enhance clarity and address the issue of reporting bias. The feedback is 3 as it directs the authors\" attention to a specific area needing clarification, but it could be more helpful with detailed guidance or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the threat model by defining the assumed threat model more explicitly. It provides concrete guidance on what needs to be included, such as specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section, which further clarifies the action required. This level of detail and specificity makes the comment 5, as it provides clear and concrete steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as defining the assumed threat model more explicitly by specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. Additionally, it suggests including this information in a dedicated section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly. It provides a clear and specific suggestion for improvement, which is to include details such as the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is wellsupported by logical reasoning, as it highlights the importance of clarity in the threat model for enhancing the paper\"s comprehensibility. However, the comment could be strengthened by providing examples or references to similar works that effectively address the threat model, which would make it 5. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides a clear and actionable suggestion by asking the authors to define the assumed threat model more explicitly, including details such as the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or references to similar works that effectively address the threat model. Overall, the comment is 4, as it offers clear guidance for improvement but could be expanded with more detailed suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain how to set a reasonable classimbalanced task in the context of fewshot learning, providing a clear and direct action for the authors to take. It also requests concrete details, which further specifies the action needed. This level of specificity and directness makes the comment 5, as the authors know exactly what information to provide to address the issue.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sampling classimbalanced tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for a detailed explanation on how to set a reasonable classimbalanced task in the context of fewshot learning. The comment provides a clear direction for the authors to address this issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the setting of classimbalanced tasks in the context of fewshot learning, asking for a detailed explanation. However, it does not contain any claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, questioning the approach of \"sampling classimbalanced tasks\" in the context of fewshot learning. It highlights a potential weakness in the methodology by asking for a detailed explanation on how to set a reasonable classimbalanced task. This feedback is clear and actionable, as it prompts the authors to provide more context or justification for their approach. However, the comment could be more helpful if it offered suggestions on how to address the issue or provided examples of best practices. Overall, the comment is 4 as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of detail in the explanation of how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. It explicitly states that the authors should provide more details on how actual pruning was done. This feedback is clear and direct, giving the authors a specific action to take: to include more details on the pruning process. The comment is explicit and concrete, providing a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of detail on how the ground truth of sensitivity is achieved and the actual pruning process. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically mentioning lines 238239. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks clarity, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the authors mention estimating a layer\"s sensitivity by pruning, but without providing details on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more detailed information on the pruning process to enhance the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it suggested specific details or examples of what kind of information should be included. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific parts of the text that could be written more clearly, such as explaining what a proper rotation matrix is in line 97 and clarifying the meaning of \"solving the problem of the matrix being non positive semidefinite\" in lines 105106. While the comment does not explicitly instruct the authors to make these clarifications, it provides clear guidance on what needs to be addressed. The authors can infer that they should provide more detailed explanations in these sections to improve the clarity of the text. Therefore, the comment is 4, as it provides concrete guidance on what needs to be done but requires some inference from the authors.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text, such as \"line 97\" and \"lines 105106,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as explaining what a proper rotation matrix is and clarifying the meaning of \"solving the problem of the matrix being non positive semidefinite.\" This provides clear guidance on how to improve the clarity of the text. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions that seek clarification on specific parts of the text. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where the text could be written more clearly, providing examples such as explaining what a proper rotation matrix is and clarifying the meaning of \"solving the problem of the matrix being non positive semidefinite.\" This feedback is actionable and provides clear guidance on how the authors can improve the clarity and understanding of their text. However, the comment could be more helpful if it offered suggestions on how to rephrase or explain these concepts more effectively. Overall, the comment is 4 as it directs the authors to specific areas needing clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests a potential rephrasing of the term \"g activation function\" to \"a binary operator,\" aligning with the terminology used by Cohen and Shashua (2016). It provides a specific reference for the authors to consider, which is a clear and concrete action. The comment also offers a rationale for the suggested change, making it 5. The authors know exactly what needs to be done and how to implement the suggested change, ensuring a clear path for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential rephrasing of the term \"g activation function\" to \"a binary operator,\" aligning with the terminology used by Cohen and Shashua (2016). The comment provides a clear rationale for the suggested change, specifying what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential rephrasing of the term \"g activation function\" to \"a binary operator,\" aligning with the terminology used by Cohen and Shashua (2016). The comment provides a specific reference to support the suggestion, making it 4. However, it could be strengthened by including a direct comparison or explanation of why this rephrasing is more appropriate. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for rephrasing the term \"g activation function\" to \"a binary operator,\" aligning with the terminology used by Cohen and Shashua (2016). This feedback is actionable and offers a clear way for the authors to improve the clarity and consistency of their terminology. By following this suggestion, the authors can enhance the precision and accuracy of their paper\"s language, making it more readable and understandable. The comment is detailed and provides a concrete step for improvement, making it 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to shrink the captions of Figures 1 and 2 to create more space for the methods or related work. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1\" and \"Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the captions, suggesting that they have large overlaps with the content and recommending a solution to shrink them to create more space for the methods or related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Figures 1 and 2 have large overlaps with the content, which could be addressed by shrinking the captions to provide more space for the methods or related work. This is a subjective observation that requires the authors to make a judgment about the size and placement of the captions. However, the comment does not provide specific examples or reasoning to support the claim, making it difficult for the authors to understand the extent of the issue or how to address it. Therefore, the comment is considered 2, as it lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Figures 1 and 2, noting that they have large overlaps with the content. It provides a clear and actionable suggestion by recommending that the authors shrink the captions to create more space for the methods or related work. This feedback is valuable as it helps the authors improve the clarity and organization of their paper by addressing a potential visual clutter in the figures. However, the comment could be more helpful if it included specific suggestions on how to reduce the size of the captions or provided examples of how this could be achieved. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the exclusion of a specific dataset, Vidgen et al, 2021, from Table 2. It suggests that this dataset might be relevant for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide explicit guidance on how the authors should address this issue or why this dataset should be included. The action is implicit and somewhat vague, as the authors need to infer that they should consider including this dataset for evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the exclusion of a particular dataset, Vidgen et al, 2021, and suggests that it might be relevant for evaluation, especially in investigating the role of context in detecting hate. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the exclusion of a specific dataset, Vidgen et al, 2021, from Table 2. It suggests that this dataset might be relevant for evaluation, particularly in investigating the role of context in detecting hate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this dataset should be included. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific concern about the exclusion of a dataset, Vidgen et al, 2021, from Table 2. It questions why this dataset, which might be relevant for evaluating the role of context in detecting hate, is not included. This feedback is 3 as it identifies a potential gap in the paper\"s evaluation framework. However, it lacks depth and does not provide guidance on how the authors might address this issue or why it is important to include this dataset. To be more helpful, the comment could suggest specific ways to incorporate this dataset or explain why it is not included. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It highlights that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their approach. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed approach, suggesting that it is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights the need for careful selection of basis functions, meshes, and stiffness matrix assembly, and notes that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It suggests that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment lacks specific examples or references to support the claim that operator learning methods are not yet as accurate as specialized numerical solvers. The reasoning is based on general statements about the limitations of current operator learning methods, which may be challenging for the authors to fully understand and address without additional context or evidence. Therefore, the comment is considered 2, as it provides some reasoning but lacks detailed support or references.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed approach, suggesting that it is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It highlights that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. While the comment points out an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is 3 as it provides a direction for potential improvement but does not offer detailed actionable advice, leaving the authors with a general understanding of the challenge but no clear path forward."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point acknowledges the authors\" judgement that there is no immediate societal impact, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their work. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the concern about using fully realistic datasets and the difficulty in controlling multiple aspects of variation with precision. It also agrees with the authors\" judgement that there is no immediate societal impact. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or data section, but this inference is not explicit. The comment is specific in identifying the challenge of using realistic datasets and the societal impact, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the authors\" judgement that there is no immediate societal impact, but it does not provide any supporting evidence or reasoning for this claim. It lacks specific examples or references to substantiate the assertion about the societal impact. Without additional context or justification, the claim remains 1, as it does not help the authors understand or address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the authors\" judgement that there is no immediate societal impact, which could be a valid observation. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable advice or specific guidance, leaving the authors without a clear path forward. As a result, the comment is 1, as it does not offer any meaningful insights or suggestions for improvement. Therefore, it aligns with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the stated standard deviation of the noise (3) and the observed noise level in the plot, which appears to be lower than expected. It suggests that the authors should study the behavior of the model under higher noise levels. While the comment implies that the authors should investigate this further, it does not provide explicit instructions on how to conduct the study or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" and the \"observations in the plot compared to the true trajectories,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy between the stated standard deviation of the noise (3) and the observed noise level in the plot, suggesting that the noise value is not as high as it should be. The comment further specifies that the authors should study the behavior of the model under higher noise levels. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise stated in the simulation study (3) is not a very high noise value, as it appears lower than expected from the observations in the plot compared to the true trajectories. The reviewer suggests that the authors should study the behavior of the model under higher noise levels. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the noise level is lower than expected. This makes the claim 3, as the authors would need to conduct further analysis to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the stated standard deviation of the noise (3) and the observed noise level in the plot, suggesting that the noise value is not as high as it should be. It provides a clear suggestion for the authors to study the behavior of the model under higher noise levels. This feedback is actionable and provides a specific direction for the authors to improve their understanding of the model\"s performance under varying noise conditions. However, the comment could be more helpful if it included additional guidance on how to conduct this study or what specific aspects to focus on. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the bounds having o(1) terms and suggests that the improvement over previously known results is limited to arbitrarily long inputs. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to expand the applicability of their approach. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the bounds of the results, specifically mentioning \"o(1) terms\" and the improvement over previously known results for arbitrarily long inputs. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in questioning the implications of these bounds on the applicability of the approach, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the bounds having o(1) terms and suggests that the improvement over previously known results is limited to arbitrarily long inputs. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a concern about the bounds of the results, specifically noting the presence of o(1) terms and the improvement over previously known results for arbitrarily long inputs. It questions the applicability of this approach, implying that the bounds might limit the practical use of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand the applicability of their approach. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it 3. The authors are left with a general understanding of the concern but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what specific aspects of the performance they should investigate. Without any actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any details on what aspects of the performance should be considered or how the authors might address this question. Without clear grounding and specificity, the authors cannot effectively address the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question about the performance of DVP on video with different lengths. It does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification or information, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any context, analysis, or suggestions on how the authors might address this question or what specific aspects of the performance should be considered. Without actionable guidance or detailed feedback, the comment lacks depth and does not offer the authors meaningful insights or steps to improve their draft. Therefore, it is rated as 2, as it provides a starting point for curiosity but does not effectively guide the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the paper\"s focus on singletoken cloze queries or multitoken ones, noting that this is not clearly explained until the conclusion. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between singletoken and multitoken queries in the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"singletoken cloze queries\" and \"multitoken ones,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of clarity until the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about the paper\"s focus on singletoken cloze queries or multitoken ones, noting that this is not clearly explained until the conclusion. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim of confusion. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the distinction between singletoken cloze queries and multitoken ones. It notes that this clarification is not clearly presented until the conclusion, which could be confusing for readers. While the comment highlights an important issue, it does not provide specific suggestions or guidance on how the authors might clarify this distinction in their draft. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction on how to address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This is a clear and direct action that provides specific guidance on how to address the issue in Section 3.3. The comment also mentions \"Experiments,\" which implies that the authors should include this evaluation in their experiments. This level of detail and specificity makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed training objective, noting that the KLdivergence term has been ignored in equation (3). The comment further instructs the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests that the authors should evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This claim is 3 as it points out a specific oversight in the training objective but lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to calculate the actual KLdivergence provides a clear direction for the authors to address the issue, but the comment could be strengthened with additional justification or references to support the importance of this evaluation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed training objective, noting that the KLdivergence term has been ignored in equation (3). It provides a clear and actionable suggestion for the authors to evaluate the approximation error by calculating the actual KLdivergence and checking if it approaches zero. This feedback is valuable as it directs the authors to a specific area of improvement, offering a concrete step to enhance the accuracy and completeness of their work. However, the comment could be more helpful if it provided additional context or guidance on why this evaluation is important or how it could impact the results. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be further enhanced with additional context or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses an opinion that Section 2 shows limited connection with the methodology section and that the theoretical analysis is simplistic and closely related to 1. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the connection between Section 2 and the methodology section, nor is there any suggestion for enhancing the theoretical analysis. The comment lacks actionable details, leaving the authors without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the connection between Section 2 and the methodology section, suggesting that the theoretical analysis is simplistic and closely related to 1. However, it does not specify which part of Section 2 is being discussed or how it is disconnected from the methodology section. This lack of grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in its critique of the theoretical analysis being simplistic and related to 1, but it does not provide detailed guidance on how to improve the connection between Section 2 and the methodology section. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that Section 2 shows limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to 1. However, the comment does not provide specific examples or detailed reasoning to support these claims. The reference to 1 is not elaborated upon, leaving the authors without a clear understanding of how the theoretical analysis is simplistic or related to 1. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the connection between Section 2 and the methodology section, suggesting that the theoretical analysis is simplistic and closely related to 1. However, the comment lacks actionable guidance or suggestions on how the authors might improve the connection between these sections or enhance the theoretical analysis. Without specific recommendations or examples, the authors are left without a clear path to address the identified issue. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide detailed feedback or actionable steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be interesting to discuss in more detail which situations the losses are particularly helpful, such as mostly for specular areas. While the comment implies that the authors should consider expanding their discussion on this topic, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional discussion on the topic. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the situations where losses are particularly helpful, such as mostly for specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the effectiveness of losses in certain situations, particularly for specular areas. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it would be interesting to discuss which situations the losses are particularly helpful, such as mostly for specular areas. However, it does not provide any specific reasoning, examples, or references to support why this discussion would be valuable or how it could enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that it would be interesting to discuss which situations the losses are particularly helpful, such as mostly for specular areas. While the comment identifies a potential area for further exploration, it lacks specificity and does not provide detailed guidance on how to expand this discussion or what specific aspects should be addressed. The authors may find the suggestion intriguing, but it does not offer actionable feedback or detailed suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of clarity regarding the major contributions of the paper and suggests that analyzing previous work does not constitute a contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify their contributions or what specific aspects need to be revised. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the paper\"s contributions and suggests that analyzing previous work does not constitute a contribution. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in terms of what aspects of the contributions are unclear or how they should be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that analyzing previous work does not constitute a contribution, which is a subjective judgment. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity regarding its contributions. It points out that analyzing previous work does not constitute a contribution, which is a crucial observation that could help the authors clarify their paper\"s originality and impact. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their contributions. While it highlights an important area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it points out a critical area for attention but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address the reproducibility issue or what steps they should take to ensure their results are reproducible. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft in this regard. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the results section. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding the reproducibility issue, as it does not provide details on what aspects of the results are difficult to reproduce or how the code could be made more accessible. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code\"s availability is crucial. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. While it identifies a potential issue with the paper\"s reproducibility, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern. Without actionable advice or specific recommendations, the comment does not offer the authors a clear path to improve their draft. Therefore, it is rated as 2, as it highlights a potential weakness but does not provide meaningful feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. This is an explicit suggestion that provides a clear direction for the authors to consider. However, it does not specify how this extension should be implemented or what specific attributes should be included in the vector form. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area where this extension is needed. Additionally, the comment lacks specificity regarding what attributes should be included in the vector form or how this extension would be beneficial. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. However, it does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it could be implemented. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. This feedback is 3 as it provides a specific suggestion for improving the paper by suggesting a potential extension of the protected feature. However, the comment lacks detailed guidance on how to implement this extension or what specific attributes should be included in the vector form. To be more helpful, the comment could provide additional context or examples to support the suggestion, making it more actionable for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit and concrete actions for the authors to take. It suggests denoting the vector representations of words in the equation and following ones, and it asks for clarification on whether the vectors are L2normalized before the process and which metric (cosine or dotproduct) is used for computing \u201cnearest neighbor\u201d examples. These actions are clear and provide specific guidance on what information needs to be added or clarified in the paper. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as denoting the vector representations of words, checking if the vectors are L2normalized, and clarifying the metric used for computing \u201cnearest neighbor\u201d examples. This provides clear guidance on what information is missing or needs clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the notation used for vectors, whether they are L2normalized, and the metric used for computing \u201cnearest neighbor\u201d examples. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the clarity and completeness of the paper. It identifies a potential area of confusion regarding the notation used for vectors in the equation and suggests denoting them appropriately. Additionally, it raises questions about whether the vectors are L2normalized and which metric (cosine or dotproduct) is used for computing \u201cnearest neighbor\u201d examples. This feedback is clear and provides the authors with concrete steps to improve the clarity and accuracy of their presentation. By addressing these points, the authors can enhance the comprehensibility and rigor of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to check Figure 2, Line 433, and Line 468, pointing out that some equations end with a period while others end with a comma. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be addressed in terms of punctuation consistency. The comment provides concrete guidance on how to implement the suggested changes, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" \"Line 433,\" and \"Line 468,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with punctuation consistency, noting that some equations end with a period while others end with a comma. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for the authors to check specific parts of the paper for punctuation consistency, specifically mentioning Figure 2, Line 433, and Line 468. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with punctuation consistency in the paper, specifically mentioning Figure 2, Line 433, and Line 468. It provides a clear and actionable suggestion for the authors to ensure consistency in punctuation, which is an important aspect of maintaining clarity and professionalism in academic writing. However, the comment could be more helpful if it provided additional context or examples of how punctuation inconsistencies might affect the paper\"s readability or professionalism. Despite this, the feedback is 4 as it directs the authors to a specific area that needs attention, allowing them to make a straightforward correction. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might differentiate their work or enhance its technical contribution. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the similarity between $kNNECD$ and $kNNMT$, suggesting that the technical contribution of the paper is limited due to this similarity. However, it does not specify which part of the paper discusses these methods or how they are compared, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in terms of what aspects of the methods or contributions need to be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the technical contribution of the paper is limited because the method $kNNECD$ is very similar to another method, $kNNMT$. This feedback identifies a potential issue with the originality and novelty of the work, which is an important consideration for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might differentiate their work or enhance its technical contribution. While it highlights a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to clarify whether the figures in Figure 1 are generated by real experiments or artificially. It also suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is clear and provides a direct action for the authors to take, which is to either confirm the authenticity of the figures or conduct additional experiments. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authenticity of the figures and suggests that realworld experiments should be conducted to support the phenomenon observed in the figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the authenticity of the figures in Figure 1, asking whether they are generated by real experiments or artificially. It suggests that if they are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This is a logical and reasonable suggestion, as it questions the validity of the results presented in the figures. However, the comment lacks specific examples or references to support the claim that the figures are artificially generated, which could make it more challenging for the authors to address the issue. Therefore, the comment is 3, as it provides a logical basis for the suggestion but lacks detailed evidence or examples.", "helpfulness_rationale": "The review comment raises a critical question about the authenticity of the figures in Figure 1, specifically asking whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon observed in the figures. This feedback is 5 as it provides a clear direction for the authors to improve the credibility and verifiability of their results. By suggesting additional experiments, the comment offers a concrete way to strengthen the paper\"s findings and enhance its overall quality. Therefore, the comment is 5, as it not only identifies a potential issue but also provides a specific and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment does not specify which part of the manuscript this assumption is discussed in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the assumption are not practical or how it could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment lacks specific examples or references to support the claim that the assumption is not practical. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice on how to enhance the manuscript. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the evaluation results reported in Table 1, noting that the results are based on only three trials for each case. It suggests that this is statistically not significant and questions the reporting of deviations, particularly why the deviation is 0 in many cases. The reviewer also points out that statements about performance being at least two standard deviations better than the next best baseline are not justified. While the comment identifies specific issues with the evaluation and reporting, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit, as the authors need to infer that they should conduct more trials or provide a more robust statistical analysis, but it lacks concrete details on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the evaluation results, noting that the results are based on only three trials for each case, which is statistically not significant. The comment further explains why reporting deviations is problematic and questions the validity of statements about performance being better than the next best baseline. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically not significant. The reviewer suggests that this is why the deviations are reported as zero in many cases and questions the validity of statements about performance being at least two standard deviations better than the next best baseline. While the comment provides a logical reasoning for the claim, it lacks specific references or examples to fully substantiate the argument. The authors would need to conduct additional trials or provide a more robust statistical analysis to address this concern. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation results reported in Table 1, noting that the results are based on only three trials for each case, which is statistically not significant. It questions the reporting of deviations and why the deviation is 0 in many cases, suggesting that the reported statements about performance being at least two standard deviations better than the next best baseline are not justified. This feedback is clear and actionable, as it provides a specific area for improvement in the statistical analysis and reporting of results. However, the comment could be more helpful if it offered suggestions on how to address this issue, such as recommending additional trials or a more robust statistical analysis. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should include these missing papers in their comparison, but it does not specify how to integrate them or what specific aspects should be covered. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the feature comparison, mentioning that it is shallow and missing two relevant papers. However, it does not specify which part of the paper this comparison is in or provide detailed guidance on how to address the issue. The authors can infer that it relates to the discussion or results section, but the lack of explicit mention of specific sections or elements makes it weakly grounded. The comment is specific in identifying the missing papers, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and mentions two relevant papers that are missing. However, the comment does not provide specific examples or detailed reasoning to support why these papers are relevant or how their inclusion would improve the comparison. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison, noting that it is shallow and missing two relevant papers. This feedback is clear and actionable, as it directs the authors to include these missing papers to enhance the depth and comprehensiveness of their comparison. However, the comment could be more helpful if it provided additional guidance on how to integrate these papers or what specific aspects of the comparison should be expanded upon. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include detailed experimental results to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. It suggests that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, while the comment specifies the need for detailed experimental results, it does not provide specific guidance on what aspects of the results should be detailed or how they should be presented. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment lacks specific examples or detailed reasoning to support the claim that the scaling law does not apply to dense retrieval models or that the results on Wikipedia are not sufficient. The reference to Ni et al. provides some context, but the comment does not fully substantiate the claim or guide the authors on how to address the issue. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully justify the claim.", "helpfulness_rationale": "The review comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. While the comment identifies a potential weakness in the paper\"s findings, it lacks specific guidance on how to present or interpret these results. The feedback is 3 as it points out an area for improvement but does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies several specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, the lack of information in the \"Dataset\" columns, and the management of figures and tables. However, it does not provide explicit guidance on how to address these issues or suggest concrete steps for improvement. The authors are left to infer that they need to improve the presentation quality, but the comment lacks detailed instructions on how to do so. Therefore, the comment is 3, as it provides some direction but lacks concrete details.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figs 1&2, tables with a \"\" for the method, and the \"Dataset\" columns in the tables. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it details various issues with the presentation quality, such as the lack of information in the \"Dataset\" columns, the management of Fig 3 and Table 2, and the meaning of the \"*\" in Table 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation quality of the paper is a weakness, citing specific examples such as Figs 1&2, tables with a \"\" for the method, and the \"Dataset\" columns in the tables. However, the comment does not provide detailed reasoning or evidence to support why these aspects are problematic or how they impact the overall quality of the publication. The lack of specific examples or detailed explanations makes it difficult for the authors to understand and address the issues effectively. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several specific issues with the presentation quality of the paper, such as the quality of figures, the use of \"\" in tables, the lack of information in the \"Dataset\" columns, and the management of figures and tables. However, it does not provide detailed guidance or suggestions on how to address these issues or improve the presentation quality. While the comment highlights areas for improvement, it lacks actionable advice, making it 3. The authors are given some insight into what needs to be improved, but the feedback could be more comprehensive and constructive to fully benefit the authors. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include related experiments to demonstrate how the information axis tool can be applied. While the comment implies that such experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to design them. The action is implicit and somewhat vague, as the authors can infer the need for experiments but lack specific instructions on how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"conclusion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is related experiments demonstrating the application of the information axis tool. This provides clear guidance on what needs to be added to the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support the claim that such experiments are necessary. The comment lacks detailed reasoning or evidence to justify why these experiments are crucial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 2, as it provides some direction but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that the authors should include related experiments to demonstrate the utility of the information axis tool. This feedback is 3 as it points out a specific area where the paper could be strengthened, but it lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific results should be expected. The comment could be more helpful with additional context or suggestions on how to design these experiments, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. While the comment implies that the current setup might be limiting, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should consider extending the model to multiple vehicles, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it prompts the authors to consider a potential extension but does not provide specific steps or suggestions for implementation.", "grounding_specificity_rationale": "The comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about scalability, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it might impact the model\"s practicality. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the scalability of the approach, specifically asking if it is feasible to extend the model to multiple trucks and drones. This feedback is valuable as it challenges the authors to consider the practical implications of their work and suggests a direction for potential future research. However, the comment does not provide specific guidance or suggestions on how to address this scalability issue or what aspects of the current setup might be limiting. While it prompts the authors to think about broader applicability, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the novelty of their approach or what specific aspects of the pretraining strategy could be improved. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, it does not specify which part of the paper discusses the pretraining approach or how it is similar to or different from the strategies used in ELECTRA. This makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the lack of novelty, but it lacks grounding as it does not point to a specific part of the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining lacks novelty because it follows strategies used in the ELECTRA model. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it lacks sufficient justification to fully support the assertion.", "helpfulness_rationale": "The review comment identifies a potential lack of novelty in the proposed approach to pretraining, suggesting that it follows strategies used in the ELECTRA model. While it points out a potential issue, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their approach or differentiate it from existing work. Without actionable feedback or detailed insights, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, as it provides a starting point for consideration but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the motivation for using the Newton algorithm in section 4 is lacking, as it is essentially a 1dimensional line search on a convex function. The reviewer points out that even a basic bisecting line search would converge linearly, questioning the impact on runtime. The comment implies that additional experiments could help justify the need for the analysis or algorithm. While the action is implicit, the suggestion to conduct experiments provides a clear direction for improvement. However, the comment lacks specific guidance on how to design or execute these experiments, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the motivation for using the Newton algorithm, questioning its necessity and suggesting that experiments could help justify its use. The comment provides a clear direction for improvement by suggesting additional experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the motivation for using the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function, which could be improved with a bisecting line search. The reviewer questions the impact of quadratic convergence on the runtime of the algorithm. While the comment provides a logical argument, it lacks specific examples or references to support the claim about the impact on runtime. This makes the claim 3, as it provides a basis for questioning but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation for using the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function. The reviewer questions the necessity of the algorithm, noting that even a basic bisecting line search would converge linearly. The comment raises an important point about the impact of the algorithm\"s convergence rate on runtime, which could be a significant factor in the algorithm\"s practical utility. The suggestion to conduct experiments to justify the need for the analysis or algorithm provides a clear direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to design these experiments or what aspects to focus on. Overall, the feedback is 4 as it highlights a critical area for clarification and improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with Equation 8, suggesting that subtracting s from the dynamic information may lead to the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a way to mitigate the loss of dynamic information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Equation 8, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with Equation 8, specifically noting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in the equation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting s from the dynamic information in Equation 8 may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a logical explanation or references to substantiate the assertion that subtracting s would lead to the loss of dynamic information. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This feedback is 3 as it points out a specific area where the authors might need to reconsider their approach. However, the comment lacks depth and does not provide actionable suggestions or guidance on how to address this issue. The authors are left to infer that they need to find a way to mitigate the loss of dynamic information, but without further details, the feedback remains 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not provide any explicit or implicit actions for the authors to take. The questions are openended and do not offer guidance on how the authors should address these issues. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not specify which part of the paper these questions relate to, such as a specific section, figure, or table. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its questions about the impact of MC samples and network structure, but without grounding, it is not actionable. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point consists of two questions asking about the impact of the number of MC samples on performance and the influence of network structure on this aspect. These questions are factual inquiries seeking clarification and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. While these questions are relevant and could help the authors explore important factors affecting their results, they do not provide specific guidance or suggestions on how to address these issues or improve the draft. The feedback lacks actionable advice or detailed insights, leaving the authors with a general understanding of what to investigate but without clear steps to take. Therefore, the comment is 3, as it identifies areas for further exploration but does not fully support the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection of event types from Freebase. It explicitly asks for clarification on how the 21 event types are selected and what the coverage is on the 33 event types in the ACE data. This provides clear and direct actions for the authors to take, such as explaining the selection process and detailing the coverage. The comment is explicit and concrete, offering specific guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2 line 262,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the method to other domains and questions the selection of event types from Freebase. It asks for clarification on how the 21 event types are selected and what the coverage is on the 33 event types in the ACE data. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about generalizability. The request for clarification on the selection process and coverage provides some guidance but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a basis for the authors to address but requires additional detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the generalizability of the method to other domains, specifically questioning the selection of event types from Freebase and the coverage on the 33 event types in the ACE data. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the selection process and coverage, which is crucial for understanding the applicability of their method. By addressing these points, the authors can enhance the clarity and robustness of their work. However, the comment could be more helpful if it suggested specific ways to improve the generalizability or provided examples of how the method could be applied to other domains. Overall, the comment is 4 as it identifies a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what aspects need clarification or how to improve the motivation. The comment lacks concrete details or suggestions on how the authors might address these issues, leaving the authors uncertain about the specific steps to take. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need clarification. While the authors can infer that it relates to the experimental setup, the comment lacks full grounding. It is specific in identifying the areas of concern, such as corpora and datasets, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the exact issues and how to address them. Therefore, the claim is considered 2, as it lacks sufficient detail to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity and motivation of the experimental setup, particularly in relation to corpora and datasets. However, it lacks detail and does not provide specific suggestions or examples of what aspects are unclear or how they could be improved. This makes it difficult for the authors to address the feedback effectively. While it highlights an important area for improvement, the comment is incomplete and lacks actionable guidance, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the comparison of the model size (in terms of depth or number of parameters) to competing approaches. It also points out that the authors mention the number of hourglass modules but do not specify their size. This comment implies that the authors should provide more detailed information about the model size to facilitate a comprehensive comparison. While the action is implicit, it is clear and concrete, as the authors know exactly what information needs to be added to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the model size to competing approaches, specifically mentioning the number of hourglass modules. However, it does not specify which part of the paper this information is discussed in, making it weakly grounded. The comment is specific in asking for clarification on the size of the model, including the number of parameters or depth, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison of the model size to competing approaches, specifically asking about the size of the model in terms of depth or number of parameters. It also notes that the authors mention the number of hourglass modules but do not specify their size. This comment is a request for clarification and does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the comparison of the model size to competing approaches, specifically asking about the size of the model in terms of depth or number of parameters. It also notes that the authors mention the number of hourglass modules but do not specify their size. This feedback is 3 as it identifies a gap in the paper\"s presentation, prompting the authors to provide more detailed information about the model size. However, the comment could be more helpful if it suggested how this information could be presented or why it is important for the comparison. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a claim that the proposed PACE treats climate emulation as a diagnostictype prediction, which is misleading without clarifying that prior work (such as ClimateBench or ClimateSet) already does this. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific clarifications are needed. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the distinction between their work and existing approaches. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about PACE treating climate emulation as a diagnostictype prediction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of misleading claims and suggests that the authors clarify the distinction by referencing prior work like ClimateBench or ClimateSet. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the claim about PACE treating climate emulation as a diagnostictype prediction is misleading without providing clear evidence or references to prior work that already does this. The comment suggests that the authors should clarify this by referencing ClimateBench or ClimateSet, but it does not provide specific examples or detailed reasoning to support the claim. This makes the comment 3, as it highlights a potential issue but lacks sufficient evidence or explanation to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that PACE treats climate emulation as a diagnostictype prediction, noting that prior work (such as ClimateBench or ClimateSet) already does this. This feedback is 3 as it points out a gap in the authors\" claim and suggests that they clarify the distinction between their work and existing approaches. However, the comment could be more helpful if it provided specific suggestions on how the authors might address this issue or if it offered additional context on why this distinction is important. Overall, the comment provides a starting point for the authors to consider, but it lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not give better results compared to previous theoretical results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue or improve their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, stating that it does not give better results compared to previous theoretical results. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its critique of the metric perspective analysis, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not give better results compared to previous theoretical results. However, the comment lacks specific examples or detailed reasoning to support the claim that the metric perspective analysis is not better. The reference to Bartlett et al. (2017) provides some context, but it does not substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, suggesting that it does not give better results compared to previous theoretical results. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to strengthen the paper. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests moving some visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also provides a concrete suggestion to condense the existing figures on the network architecture to make room for additional visual results. This feedback is clear and provides specific guidance on how the authors can improve their draft by enhancing the visual representation of their work. The action is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also suggests condensing the existing figures on the network architecture to make room for additional visual results. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the main paper and the supplementary material. The suggestion to condense figures is specific, providing a clear direction for the authors to follow. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also suggests condensing existing figures on the network architecture to make room for additional visual results. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim that the current visual results are insufficient or that condensing figures would be beneficial. This makes the claim 3, as it provides a general direction for improvement but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to move visual results from the supplementary material to the main paper, specifically addressing the lack of visual results on crowd density estimation, which is a main experiment in the paper. It also offers a concrete suggestion to condense existing figures on the network architecture to make room for additional visual results. This feedback is 5 as it guides the authors on how to enhance the visual representation of their work, which can significantly improve the clarity and impact of the paper. The suggestion is specific and provides a clear path for improvement, making it a valuable contribution to the authors\" efforts to refine their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to incorporate the corpus residual value into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of corpus residual value to detect such differences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. The comment suggests that this issue could be detected using the corpus residual value, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the corpus residual value could be used for this purpose. Without additional justification or references, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a critical question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value, which is a constructive and insightful observation. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or incorporate the corpus residual value into their analysis. While it highlights an important area for consideration, the feedback could be more helpful with additional details or actionable steps. Therefore, the comment is 3, as it provides a valuable insight but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. While the comment implies that the authors should make this change, it does not explicitly instruct them to do so. However, the reasoning provided gives the authors a clear understanding of the benefits of using WebQuestions, making the action somewhat explicit. The authors know what change to consider but may need to infer the exact steps to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the choice of dataset used in the study, specifically mentioning \"WebQuestionsSP\" and suggesting the use of \"WebQuestions (Berant et al., 2013) benchmark set.\" This provides full grounding as it explicitly mentions the dataset being discussed, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests a change in dataset choice and provides a rationale for why this change would be beneficial, such as facilitating direct comparison with mainstream QA research. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP as the testbed for their work. It provides a rationale for this suggestion, explaining that using WebQuestions would be more intuitive and straightforward, and it could facilitate direct comparison with mainstream QA research. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim that WebQuestionsSP is not the most suitable choice. While the suggestion is logical and based on common practices in the field, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the choice of dataset used in the study. It suggests using the WebQuestions benchmark set instead of WebQuestionsSP, reasoning that this choice would be more intuitive and facilitate direct comparison with mainstream QA research. This feedback is valuable as it offers a specific and logical alternative that could enhance the relevance and impact of the study. However, the comment could be more helpful if it included additional details on why WebQuestions might be a better fit or how it could improve the study\"s outcomes. Overall, the comment is 4 as it directs the authors to a more suitable dataset choice, but it could be further enhanced with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment does not explicitly instruct the authors to remove or modify these claims, nor does it provide specific guidance on how to demonstrate the benefits. The action is implicit and somewhat vague, as the authors can infer the need for evidence but may not know exactly how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. While the comment is specific in its critique of the claims, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment lacks specific examples or references to support the claim that sparsity is not desirable or that it may not be beneficial. The reasoning is based on general observations about the potential limitations of sparsity and the importance of demonstrating practical benefits. While the comment provides some insight, it is not 5 due to the lack of detailed evidence or examples. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. This feedback is clear and actionable, as it directs the authors to substantiate their claims and provide concrete evidence. However, the comment could be more helpful if it offered specific suggestions on how to demonstrate these benefits or what kind of evidence would be most effective. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the novelty of the work is limited because the design is not entirely new, as attention for motion learning has been widely used in video understanding. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or improve the novelty of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the work is limited because the design is not entirely new, as attention for motion learning has been widely used in video understanding. However, it does not specify which part of the paper this critique pertains to, such as a specific section, table, or figure. The authors may have an idea of where this critique might apply, but the comment lacks explicit grounding. Additionally, the comment does not provide specific details on what aspects of the design are not novel or how the authors might address this limitation. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the work is limited because the design is not entirely new, as attention for motion learning has been widely used in video understanding. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the novelty of the work, stating that the design is not entirely new as attention for motion learning has been widely used in video understanding. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or improve the novelty of their work. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as 2, as it identifies a potential issue but does not offer constructive feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment points out a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for treating them as models. This feedback provides a clear and explicit action for the authors to take, which is to ensure consistency in the terminology throughout the paper. The suggestion is concrete, as it specifies the action needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the inconsistency in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets. It suggests that the authors should clarify this inconsistency or provide an explanation for treating them as models. However, the comment does not specify which sections of the paper this inconsistency occurs in, making it weakly grounded. The feedback is specific in identifying the issue with the inconsistent use of terms, but without explicit references to sections, the authors may struggle to pinpoint the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for treating them as models. This claim is 3 as it points out a logical inconsistency in the paper\"s terminology. However, it lacks specific examples or references to support the suggestion, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy in the use of BigFive and MBTI, which are initially mentioned as models to be extended but are later used as datasets. The reviewer suggests that it would be better to consistently refer to them as datasets unless there is a specific reason for treating them as models. This feedback is clear and actionable, as it provides a straightforward suggestion for improving the consistency and clarity of terminology throughout the paper. By addressing this issue, the authors can enhance the coherence and professionalism of their draft. Therefore, the comment is rated as 5, as it offers a clear and actionable way for the authors to improve their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include rejection rates in their experiments or to view misclassifications as rejections. This provides a clear and direct action for the authors to take, making the comment 5. The suggestion is concrete, as it specifies what needs to be included in the results section to address the issue of rejection rate. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of rejection rate in the experiments and suggests including it or viewing misclassifications as rejections. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that rejection rates should be included in the experiments or viewed as misclassifications. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of rejection rates in the experiments. It suggests that the authors should include rejection rates or view misclassifications as rejections, providing a clear and actionable feedback. This guidance helps the authors understand what needs to be addressed to improve the completeness and accuracy of their results. However, the comment could be more helpful if it offered additional suggestions on how to present or analyze the rejection rates. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to provide the final thresholds used for the results and suggests sharing the full set of hyperparameters for reproducibility. This request is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what information needs to be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"final thresholds\" and \"hyperparameters,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the sharing of thresholds and hyperparameters for reproducibility. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two requests for information: the final thresholds used for the results and the sharing of full hyperparameters for reproducibility. These are factual requests for additional information that do not require any justification or evidence. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, addressing a specific issue related to the reproducibility of the results. It explicitly asks for the final thresholds used for the results and suggests sharing the full set of hyperparameters, which is crucial for others to reproduce the study. This feedback provides a direct way for the authors to enhance the transparency and replicability of their work, making it 4. However, it could be more helpful if it included suggestions on how to present this information or why it is important for reproducibility. Overall, the comment is clear and actionable, but it could be further enhanced with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges the authors\" claim that the readability of RC datasets does not directly affect question difficulty, but it suggests that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. While the comment implies that the authors should consider these factors, it does not explicitly instruct them to do so or provide specific guidance on how to incorporate this information into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of different features on their analysis. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the impact of dataset readability on question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or results section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, namely the impact of features on the analysis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges a claim made by the authors about the impact of dataset readability on question difficulty, stating that it depends on the method or features used for answer detection. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges a claim made by the authors regarding the impact of dataset readability on question difficulty, stating that it depends on the method or features used for answer detection, such as POS or dependency parse features. This feedback is 3 as it challenges the authors\" initial claim and suggests that their analysis might be limited in scope. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or expand their analysis. To be more helpful, the comment could offer examples of how different features might affect the analysis or suggest additional methods for exploring this topic. Therefore, the comment is rated as 3, as it prompts the authors to consider a potential limitation but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While it implies that the authors should make an effort to reduce whitespace, it does not provide specific guidance on how to achieve this optimization. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests optimizing Figure 1 to use less whitespace, which is a specific and actionable suggestion. However, it does not explicitly mention which part of the paper this figure is located in, making it weakly grounded. The authors can infer that it pertains to Figure 1, but this inference is not as clear as it could be. The comment is specific in its suggestion to reduce whitespace, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any reasoning, examples, or specific guidance on how to achieve this optimization. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While this is a specific and actionable suggestion, it lacks context or explanation as to why reducing whitespace might be beneficial or how it could impact the clarity or effectiveness of the figure. Without additional guidance or examples, the authors may find it challenging to fully understand the rationale behind the suggestion or how to implement it effectively. Therefore, the comment is 3, as it provides a specific direction for improvement but lacks depth and context."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper should be improved, specifically mentioning the need to address the repetition of explaining basic memory networks and the forward model. It also points out that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not provide specific guidance on how to improve the writing quality or what aspects of the related work should be expanded. The authors are left with a general understanding of what needs to be addressed but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not specify which sections of the paper are affected by these issues, making it weakly grounded. The authors can infer that the writing quality and related work sections are being addressed, but the lack of specific guidance on how to improve these aspects makes the comment underspecific. Therefore, this comment is weakly grounded and underspecific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement in the paper: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and the forward model, suggesting that this repetition could be addressed. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. While the comment highlights specific areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without actionable steps to enhance their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. While the comment implies that the authors should explore these areas, it does not provide explicit guidance on how to identify or measure these improvements. The action is somewhat implicit and lacks concrete details on how to execute the suggested exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in suggesting areas for improvement, such as accuracy and modeling sequential relationships, but lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these specific properties might be more relevant or why they should be prioritized over FLOPs or inference time. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. This feedback is 3 as it provides a direction for the authors to explore alternative metrics for improvement. However, the comment lacks depth and does not offer specific guidance on how to measure or evaluate these properties. Additionally, it does not provide examples or detailed suggestions on how to assess the ease of modeling sequential relationships. While it offers a potential area for exploration, the feedback could be more comprehensive and actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the assumption that d_e are good replacements for entity embeddings, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this assumption should be tested or how it could be tested. The comment lacks specificity and does not offer any concrete steps for the authors to follow, making it 1.", "grounding_specificity_rationale": "The comment raises a question about the assumption that d_e are good replacements for entity embeddings, but it does not specify which part of the paper this assumption is made in. The authors may have an idea of where this assumption might be discussed, but the comment lacks explicit references to specific sections, figures, or tables. Additionally, the comment does not provide specific details on what needs to be addressed regarding this assumption. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the assumption that d_e are good replacements for entity embeddings, but it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or references to external works that might support the claim, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the claim remains 1. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a critical question about the assumption that d_e are good replacements for entity embeddings, which is an important aspect of the paper. However, it does not provide any guidance or suggestions on how the authors might test or address this assumption. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of their work might be affected by this inquiry. The comment lacks any explicit or implicit actions for the authors to take, leaving them without a clear direction for improvement. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or guidance on how the authors might address this question or what aspects of their work might be affected by it. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it identifies a potential area for exploration or clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of their work might be affected by it. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it provides a starting point for consideration but does not offer substantial guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It also points out that the authors do not employ onehot encoding for this dataset, which could negatively impact performance. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include more datasets with categorical features or employ onehot encoding, but the comment lacks concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Model Comparison\" and \"datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. The comment further specifies that the authors do not employ onehot encoding for this dataset, which could negatively impact performance for some models. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the chosen selection of datasets is inadequate for a variety of reasons, specifically noting that only one dataset has categorical features, which are generally more challenging for deep learning models. The comment also points out that the authors do not employ onehot encoding for this dataset, which could negatively affect performance for some models. While the claim is based on logical reasoning and common knowledge about the challenges posed by categorical features in deep learning, it lacks specific examples or references to support the assertion fully. The comment provides a clear rationale for the claim but could be strengthened with additional evidence or references to make it 5. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It points out that the authors do not employ onehot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it highlights a potential weakness in the experimental setup that could affect the validity of the conclusions drawn from the model comparison. By bringing this issue to the authors\" attention, the comment provides a valuable direction for improvement, encouraging them to consider a more diverse dataset selection or the use of onehot encoding. However, the comment could be more helpful if it suggested specific steps or examples of how to address this issue, such as recommending additional datasets with categorical features or providing guidance on implementing onehot encoding. Overall, the comment is 4, as it effectively identifies a critical area for improvement but could be further enhanced with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses dissatisfaction with the choice of two IoT datasets, suggesting that they are unpopular and not wellsuited for benchmarking. It implies that the authors should have considered better options, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. While the comment implies that the authors should reconsider their dataset choices, it does not provide explicit guidance on how to make these changes or which specific datasets to consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative datasets but are not given concrete suggestions on what those alternatives might be. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of datasets, noting that the two IoT datasets are unpopular and not wellsuited for benchmarking. The reviewer suggests that the authors should have considered better options, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This provides clear guidance on what the authors should consider in their dataset selection. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of two IoT datasets is \"unpopular\" and \"weird,\" suggesting that the datasets are not wellsuited for benchmarking. The reviewer provides reasoning by noting that the FlatCam Face dataset is relatively recent but not substantially followed, and the Headpose detection dataset was published in 2004 and is no longer widely used. This provides some logical reasoning and context for the claim, making it 3. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of datasets in Section 4, specifically the two IoT datasets mentioned. It points out that these datasets are not widely used and suggests that the authors should have considered better options for benchmarking, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. This feedback is clear and actionable, as it provides specific suggestions for improving the dataset selection and benchmarking results. However, the comment could be more helpful if it included additional context or examples to further substantiate the claim. Overall, the comment is 4 as it guides the authors towards a more robust dataset selection process, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the annotations in Figure 4 should be enlarged for better visibility. This is an explicit action that the authors can take to improve the figure. However, the comment does not provide specific guidance on how much enlargement is necessary or how to achieve it. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the enlargement of annotations for better visibility. This provides clear guidance on what the authors need to do to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 should be enlarged for better visibility. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the figure. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 4, suggesting that the annotations should be enlarged for better visibility. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, it lacks depth and does not offer additional guidance on how to achieve the enlargement or what specific changes might be necessary. While it points out a clear area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a common issue in the field of natural language processing, specifically regarding the existence of multiple entities in both sentences and documents, which is not limited to relation classification but also applies to documentlevel RE and joint entity and relation extraction. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or incorporate it into their work. Without specific suggestions or directions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 2627,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a common issue in the field of natural language processing, namely the existence of multiple entities in both sentences and documents, which is not limited to relation classification but also applies to documentlevel RE and joint entity and relation extraction. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that multiple entities typically exist in both sentences and documents, even for relation classification, which is not limited to documentlevel RE or joint entity and relation extraction. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a common issue in the field of natural language processing, specifically regarding the existence of multiple entities in both sentences and documents, which is not limited to relation classification but also applies to documentlevel RE and joint entity and relation extraction. This observation is relevant and could be useful for the authors to consider in their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate it into their research. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out a potential issue with Fig. 4, suggesting that one of the labels on the color bar should say \"worse.\" This is a clear and direct action for the authors to take, as it specifies exactly what needs to be corrected in the figure. The comment provides a concrete and actionable suggestion, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the color bar, suggesting that one of the labels should say \"worse.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about a potential labeling error in Fig. 4, suggesting that one of the labels should say \"worse.\" This is a straightforward claim that does not require any supporting evidence or reasoning, as it is based on a direct observation. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, pointing out a specific issue with Fig. 4, where it suggests that one of the labels on the color bar should say \"worse.\" This feedback is valuable as it provides a direct correction that the authors can implement to improve the clarity and accuracy of their figure. However, the comment could be more helpful if it explained why this correction is important or how it might impact the interpretation of the data. Despite this, the feedback is 4 as it offers a clear direction for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies a specific error in the text, suggesting that the phrase \u201ctraining/validation/test\u201d should be corrected to \u201ctraining/validation/test sets\u201d in Row 757 of the supplementary material on Page 29. This provides a clear and direct action for the authors to take, which is to correct the text in the specified location. The comment is explicit and concrete, as it specifies exactly what needs to be changed and where it should be made. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the correction of the phrase \"training/validation/test\" to \"training/validation/test sets.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual correction regarding a typographical error in the text, specifically the phrase \"training/validation/test\" being corrected to \"training/validation/test sets.\" This is a straightforward correction that does not require any justification or evidence. The comment is factual and does not contain any subjective opinions or claims, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the text, namely the incorrect use of \"training/validation/test\" instead of \"training/validation/test sets\" in Row 757 of the supplementary material on Page 29. This feedback is actionable and provides a clear correction that the authors can implement to improve the accuracy and clarity of their draft. By addressing this minor typographical error, the authors can enhance the overall quality and professionalism of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the inference process, provide the coefficient value, and ensure welltuned baselines and confident ablation studies. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. However, it does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks full grounding as it does not explicitly mention specific sections or elements of the paper. It is also not specific because it does not provide detailed guidance on how to address these issues. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises several concerns about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. However, the comment does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies these issues, it lacks specific guidance or suggestions on how to address them. For example, it questions the coefficient value but does not provide a rationale or suggest a method for determining it. Similarly, it highlights missing hyperparameter details and unclear writing but does not offer concrete steps or examples for improvement. The comment provides some insight into areas that need attention but does not offer actionable advice, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This is an explicit action that provides a clear direction for the authors to follow. However, the comment does not specify why this change is necessary or how it would improve the paper. While the action is clear, the lack of detailed reasoning or explanation makes it somewhat vague. Therefore, the comment is 4, as it provides a direct action but lacks full guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This provides clear guidance on how to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" However, it does not provide any reasoning or evidence to support why this model is no longer stateoftheart or why it should be replaced. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests replacing the mention of the model by Dozat and Manning (2016) with a more general phrase like \"very high performing model.\" This feedback is 3 as it provides a specific suggestion for improving the clarity and accuracy of the description. However, it lacks context or explanation as to why this particular model is no longer stateoftheart or why it should be replaced. Without additional justification or reasoning, the comment provides a limited benefit to the authors in terms of improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific weakness of the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed method or what specific changes should be made. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this comparison or where the authors should focus their efforts to improve the method. The authors can infer that it relates to the comparison section or results, but this inference is not explicit. The comment is specific in identifying the weakness of the proposed method, but it lacks grounding as it does not mention specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as the main weakness of the method. However, the comment does not provide any supporting evidence, such as specific data, examples, or references to other works that might corroborate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assertion, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a valuable observation that highlights an area where the authors need to improve their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance the performance of their method. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is 3, as it points out a significant weakness but does not offer comprehensive guidance for addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some subjective statements in the paper are inappropriate and recommends providing proofs and references to support the statements. It also points out that the image recovery performance is sensitive to the choice of neural architecture and highlights the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific proofs or references to include. The authors are left with a general understanding of what needs to be improved but without concrete steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses subjective statements in the paper, suggesting that they are inappropriate and should be supported with proofs and references. It also points out the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. However, the comment does not specify which parts of the paper contain these subjective statements or where the proofs and references should be included. This lack of specificity makes it difficult for the authors to pinpoint the exact sections that need revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that some subjective statements in the paper are inappropriate and suggests providing proofs and references to support them. It also highlights the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. The comment provides some reasoning by mentioning the sensitivity of performance and the challenge of multiscale architecture design, but it lacks specific examples or references to substantiate the claims fully. This makes the claim 3, as it provides some support but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that some subjective statements are inappropriate and should be supported with proofs and references. It highlights the sensitivity of image recovery performance to the choice of neural architecture and the challenge of multiscale architecture design, including the need to explain when to fuse multiscale features. The comment also points out that models with skip connections could be regarded as using multiscale information in an implicit way. However, the feedback lacks detailed guidance on how to address these issues or provide the necessary proofs and references. While it points out areas for improvement, it does not offer specific suggestions or examples, leaving the authors with a general understanding of what needs to be improved but without actionable steps. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method compares with prior art. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the comparison should be addressed or how the authors should approach this comparison. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method compares with prior art, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the discussion section or the conclusion, but this inference is not explicit. The comment is specific in asking for a comparison with prior art, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question asking for a comparison with prior art, which is a factual inquiry seeking clarification. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about how the proposed method compares with prior art. While it identifies a gap in the paper\"s discussion, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the comparison should be emphasized. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as 2, as it provides a starting point for the authors but does not offer detailed or comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that the authors should consider comparing biases towards different languages/nationalities. While the comment suggests an area for improvement, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for more detailed analysis and the specific comparisons to be made. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the presence of various languages/nationalities in the data and suggests an interesting observation to compare biases towards these different groups. This provides clear guidance on what aspect of the analysis could be expanded or improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that there might be interesting observations comparing biases towards different languages/nationalities. However, the comment does not provide specific examples or detailed reasoning to support the claim that these comparisons would be interesting or necessary. The suggestion lacks concrete evidence or examples to substantiate the need for more detailed analysis, making it 3. The authors would need to infer the potential significance of these comparisons, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It points out that biases towards different languages/nationalities might be different and suggests that comparing them could lead to interesting observations. This feedback is 3 as it identifies a potential area for improvement in the analysis and provides a specific suggestion for further exploration. However, it could be more helpful if it included more detailed guidance on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment offers a direction for enhancing the analysis but lacks depth, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. However, the comment does not provide specific guidance on which properties to explore or how they might be incorporated into the approach. The action is implicit and somewhat vague, as the authors need to infer the specific properties to consider and how to integrate them into their design. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. The authors can infer that it relates to the methodology or approach section, but this inference is not explicit. The comment is specific in suggesting the exploration of additional properties, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. However, the comment does not provide any specific reasoning, examples, or references to support why these additional properties are necessary or how they might enhance the approach. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests exploring additional properties of features beyond the norm, implying that the authors should consider other properties that could be used in their approach design. This feedback is 3 as it points out a potential area for improvement in the methodology or approach section of the paper. However, it lacks specificity and does not provide guidance on which properties to explore or how they might be incorporated into the design. The authors are left with a general suggestion but without detailed instructions on how to implement it, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this topic numerically. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of learning F^dagger or the experimental results, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, namely the conservation properties of learning F^dagger. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that learning F^dagger should conserve these properties. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physicsrelated continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. This feedback is valuable as it prompts the authors to consider an important aspect of their work that may impact its applicability and accuracy. However, the comment could be more helpful if it included specific guidance on how to investigate this issue or suggested methods for conserving properties during training. Overall, the comment is 4 as it identifies a critical area for exploration and provides a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not provide any explicit or implicit actions for the authors to take, nor does it offer guidance on how to address this expectation. The comment lacks specificity and does not provide any concrete steps or suggestions for improvement, leaving the authors without a clear understanding of what actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not specify which part of the paper this feedback pertains to, such as a particular section, table, or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity as it does not provide examples or detailed suggestions on how to address the expectation of seeing a variety of tasks where PE is important. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that it is expected to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or references, the authors may find it challenging to understand the basis of this expectation or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. While this feedback provides a general direction for the authors to consider, it lacks specificity and actionable guidance. It does not offer any suggestions on how the authors might address this expectation or where they might find examples of such tasks. As a result, the comment is 3, as it offers a potential area for exploration but does not provide detailed or comprehensive guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include a discussion about a set of fewshot demonstrations that could be drawn from, possibly with the help of domain experts. It also questions the inclusion of zeroshot generation results, suggesting that they might be included to satisfy general curiosity about the LLM\"s capabilities. However, the comment does not explicitly instruct the authors to include this discussion or remove the zeroshot results. The action is implicit and somewhat vague, as the authors need to infer that they should address these points. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a discussion about a set of fewshot demonstrations that could be drawn from, possibly with the help of domain experts. It also questions the inclusion of zeroshot generation results, suggesting that they might be included to satisfy general curiosity about the LLM\"s capabilities. However, the comment does not specify which part of the paper these suggestions relate to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding the issues with the zeroshot results or how they might be addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the inclusion of zeroshot generation results, suggesting that they might be included to satisfy general curiosity about the LLM\"s capabilities. However, it does not provide specific reasoning or evidence to support why these results are strange or unnecessary. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the inclusion of zeroshot generation results, suggesting that they might be included to satisfy general curiosity about the LLM\"s capabilities. It also recommends including a discussion about a set of fewshot demonstrations that could be drawn from, possibly with the help of domain experts. While the comment identifies a potential issue with the experimental setup, it lacks specific guidance on how to address these concerns or improve the paper. The feedback is 3 as it points out a potential area for improvement, but it could be more actionable with detailed suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a minor issue regarding Figure 3, specifically mentioning that \"OAA\" is never referenced in the body text. It suggests that there might be additional content in the appendix that is missing or that the caption is outdated. While the comment identifies a potential issue, it does not provide explicit instructions on how to address it. The authors can infer that they need to ensure the caption is uptodate and that all relevant content is included, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that \"OAA\" is never referenced in the body text and suggesting that there might be additional content in the appendix that is missing or that the caption is out of date. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a minor issue regarding Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be additional content in the appendix that is missing or that the caption is out of date. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor issue with Figure 3, specifically noting that \"OAA\" is never referenced in the body text. It suggests that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment points out a potential inconsistency, it does not provide specific guidance on how to address this issue or what additional content might be missing. The feedback is 3 as it highlights a specific area that needs attention, but it lacks depth and actionable suggestions, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after using the GS module to propagate context information over different spatial locations. It references a specific source, 2, which suggests that the authors should compute the effective receptive field. However, the comment does not provide explicit instructions or guidance on how to compute the effective receptive field or what specific improvements should be expected. The action is implicit and somewhat vague, as the authors need to infer that they should compute the effective receptive field and compare it before and after applying the GS module. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the effectiveness of the GS module in propagating context information over different spatial locations. It suggests that the authors should compute the effective receptive field, referencing a specific source 2 for guidance. However, the comment does not explicitly mention which part of the paper discusses the GS module or the effective receptive field, making it weakly grounded. The authors can infer that it relates to the methods or results sections, but this inference is not precise. The comment is specific in its request for computation and comparison of the effective receptive field, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effectiveness of the GS module in propagating context information over different spatial locations. It suggests that the authors should compute the effective receptive field, referencing a specific source 2 for guidance. However, the comment does not provide any additional context, reasoning, or evidence to support why this computation is necessary or how it would improve the paper. The reference to 2 is not sufficient to fully substantiate the claim, as it lacks detailed explanation or examples. Therefore, the comment is considered 2, as it provides some support but lacks the depth needed for a 5 claim.", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in propagating context information over different spatial locations. It suggests that the authors should compute the effective receptive field, referencing a specific source 2 for guidance. This feedback is 3 as it prompts the authors to consider a specific aspect of their work that could be improved or further explored. However, the comment lacks depth and does not provide detailed guidance on how to compute the effective receptive field or what specific improvements might be expected. To be more helpful, the comment could include more detailed suggestions or examples on how to compute the effective receptive field and what improvements might be expected. Therefore, the comment is rated as 3, as it identifies an area for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning stages, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This comment provides a clear and explicit action for the authors to take, which is to clarify the objective for the LSTM part and add a head for value function computation in the finetuning stage. The suggestion is concrete, as it specifies what needs to be done and how to implement it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the objective for the LSTM part, specifically mentioning that it would be the same for pretraining and finetuning stages. It suggests that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This provides a clear and specific direction for the authors to consider, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part remains the same for both pretraining and finetuning stages, and that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors would need to infer the reasoning behind the suggestion, which makes it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion regarding the objective for the LSTM part, specifically noting that it remains the same for both pretraining and finetuning stages. It further suggests that in the finetuning stage, the authors should add another head to the network to compute value functions for the states. This feedback is specific and provides a concrete direction for the authors to improve their draft by clarifying the objective and adding a new component to their model. However, the comment could be more helpful if it included additional context or examples to further explain the rationale behind the suggestion. Overall, the comment is 4 as it offers a clear and actionable improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge older works in their related works section, which is a clear and explicit action. However, it does not specify which older works should be acknowledged or how they relate to the current work. While the action is explicit, the lack of specific guidance on which works to include makes it somewhat vague. Therefore, the comment is 4, as it provides a clear direction but lacks detailed implementation guidance.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related works,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the related works section, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should acknowledge older works in their related works section. However, it does not provide any specific examples or reasoning to support why these older works should be included. The comment lacks detailed justification or references to specific works, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered 2, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge older works in their related works section, which is a valuable piece of feedback. It provides a clear direction for improvement by pointing out a potential oversight in the literature review. However, the comment lacks specificity regarding which older works should be acknowledged or how they relate to the current work. While it highlights an important aspect for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, as it identifies a gap but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that the authors\" argument about the predictor being accurate on the good subregion should lead to better performance with increased sampling probability for topperforming predicted architectures. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their results or analysis. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly revise their results or analysis to align with the suggested argument. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, specifically the underperformance of linear/exponentialdecay sampling compared to uniform sampling, and questions the authors\" argument about the predictor being accurate on the good subregion. The comment suggests that increasing the sampling probability for topperforming predicted architectures should lead to better performance, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It questions the authors\" argument about the predictor being accurate on the good subregion and suggests that increasing the sampling probability for topperforming predicted architectures should lead to better performance. However, the comment lacks specific examples or detailed reasoning to support the claim that the predictor is accurate or that increasing the sampling probability would indeed lead to better performance. Without additional evidence or analysis, the claim remains 3, as it provides a logical basis for questioning but lacks comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the results in Table 2, specifically regarding the performance of linear/exponentialdecay sampling compared to uniform sampling. It questions the authors\" argument about the predictor being accurate on the good subregion and suggests that increasing the sampling probability for topperforming predicted architectures should lead to better performance. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, it does not provide actionable steps or detailed feedback, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is 3, as it highlights a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several issues contributing to the high time complexity of the proposed method. It points out the use of an itemoriented autoencoder, which may involve many users associated with a typical item, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps for reducing the time complexity. The authors are left to infer that they need to optimize the model or explore alternative approaches, but the lack of detailed instructions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the issue of high time complexity in the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issues related to time complexity, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high due to the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. However, the comment lacks specific examples or detailed reasoning to support these claims. While the reviewer identifies potential sources of high time complexity, the lack of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some support but requires additional information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies several factors contributing to the high time complexity of the proposed method, including the use of an itemoriented autoencoder, the expense of elementwise functions, and the large number of hidden units compared to typical matrix factorizationbased methods. This feedback is 3 as it points out specific areas where the authors might need to focus on to improve the efficiency of their approach. However, the comment lacks detailed suggestions or guidance on how to address these issues, such as proposing alternative methods or optimization strategies. While it highlights potential areas for improvement, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders.\" This is an explicit suggestion that provides a clear and concrete action for the authors to take, which is to modify the figures to include this additional information. The comment does not require the authors to infer the action or make assumptions about how to implement it, making it 5.", "grounding_specificity_rationale": "The comment suggests that the figures in the paper would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders.\" While it does not explicitly mention which figures are being referred to, the authors can infer that it pertains to figures related to the solution encoders and decoders. This makes the comment weakly grounded, as the authors cannot confidently determine which specific figures are being addressed. However, the comment is specific in suggesting a way to improve the clarity of the figures by specifying the types of autoencoders used. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders.\" This is a subjective suggestion for improvement, as it is based on the reviewer\"s opinion that specifying the types of autoencoders would enhance clarity. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change would be beneficial. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the figures in the paper. It suggests that specifying \"pretrained solution encoders & solution decoders\" instead of just \"autoencoders\" would enhance the understanding of the figures. This feedback is clear and actionable, as it directs the authors to make a specific change that could significantly improve the clarity and comprehensibility of their figures. However, the comment could be more helpful if it explained why this change would be beneficial or provided examples of how it could be implemented. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful, which is an explicit action for the authors to take. However, it does not specify what aspects of \"multiaspect\" need to be explained or how this explanation should be integrated into the text. The comment also mentions a specific issue with Figure 1, suggesting that the subscripts s and t should be 1 and 2, respectively. While this part is explicit, the overall comment lacks detailed guidance on how to address the \"multiaspect\" explanation, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 14, 47\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, a brief explanation of \"multiaspect\" and a correction regarding the subscripts in Figure 1. This provides clear guidance on what the authors need to address, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that a brief explanation of \"multiaspect\" would be helpful, and it also mentions a specific issue with Figure 1 regarding the subscripts. However, the comment does not provide any reasoning or evidence to support why an explanation of \"multiaspect\" is necessary or how it could improve the paper. Similarly, the comment does not explain why the subscripts in Figure 1 should be 1 and 2, nor does it provide references or examples to justify these claims. Without additional context or justification, the claims are difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment is 3 as it identifies two specific areas for improvement: a brief explanation of \"multiaspect\" and a correction regarding the subscripts in Figure 1. However, the comment lacks depth and does not provide detailed guidance on how to address these issues. While it points out the need for clarification, it does not offer suggestions on what aspects of \"multiaspect\" should be explained or how the correction should be made. This limits the usefulness of the feedback for the authors, as it provides some insight but does not fully support their efforts to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. While the comment implies that a more detailed analysis is needed, it does not explicitly instruct the authors to provide this information. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the extraction process, but the comment does not specify how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the parts of sentences and documents are extracted and whether the rules of extraction affect the experiment. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the extraction of parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. This feedback is 3 as it prompts the authors to clarify a potentially important aspect of their methodology. However, it lacks depth and does not provide specific guidance on how to address the issue or what additional information might be necessary. The authors are left with a general suggestion to provide more detail, but without actionable steps or examples, the comment does not fully support the authors in improving their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to provide information about the computation required to implement the experiments, including the duration of the experiments and the hardware used. This request is clear and direct, giving the authors a specific action to take in terms of providing additional details about the computational aspects of their work. The comment is explicit and concrete, as it directly instructs the authors on what information to include, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the computation required to implement the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests information about the duration of the experiments and the hardware used, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information about the computational requirements of the experiments, specifically asking for details on the duration and hardware used. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is clear and actionable, asking the authors to provide additional information about the computational requirements of their experiments. This includes details on the duration of the experiments and the hardware used. By addressing this request, the authors can provide more context and transparency about their experimental setup, which is valuable for readers and reviewers. However, the comment could be more helpful if it suggested specific ways to present this information or discussed the importance of this information for the readers. Overall, the comment is 4 as it directs the authors to a specific area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the authors\" approach to applying the meta sampler, specifically whether it is only used in a decoupled manner, updating the linear classifier while keeping the features fixed. The comment implies that the authors should provide more discussion on this aspect and specify when the meta sampler is applied (i.e., at which epoch). While the action is implicit, it is clear and concrete, as it specifies what additional information the authors need to include. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the authors\" approach to applying the meta sampler, specifically whether it is only used in a decoupled manner, updating the linear classifier while keeping the features fixed. It also asks when the meta sampler is applied, implying a specific part of the paper where this information should be discussed. However, the comment does not explicitly mention which section of the paper this relates to, making it weakly grounded. The question is specific in its inquiry about the decoupled application and the timing of the meta sampler\"s use. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the authors\" approach to applying the meta sampler, specifically whether it is only used in a decoupled manner, updating the linear classifier while keeping the features fixed. The reviewer asks for more discussion on this and when the meta sampler is applied. However, the comment does not provide any evidence, reasoning, or references to support the claim that the meta sampler is only used in a decoupled manner. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the authors\" approach to applying the meta sampler, particularly whether it is only used in a decoupled manner, updating the linear classifier while keeping the features fixed. It also asks when the meta sampler is applied, implying a need for more discussion on this aspect. While the comment identifies a potential area for clarification, it lacks detailed guidance or suggestions on how the authors might address this issue or what additional information should be included. The feedback is 3 as it prompts the authors to clarify their methodology, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the content in lines 107114 is speculative or overly opinionated and suggests that it should be stated as a remark, an aside in the Discussion section, or removed. This provides a clear and direct action for the authors to take, specifying the exact changes needed to address the issue. The feedback is explicit and concrete, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the content, suggesting that it should be stated as a remark, an aside in the Discussion section, or removed. This provides clear guidance on how to address the concern, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the content in lines 107114 is speculative or overly opinionated and suggests it should be stated as a remark, an aside in the Discussion section, or removed. However, the comment does not provide specific examples or reasoning to support why this content is speculative or opinionated, nor does it offer a detailed explanation of why it should be removed or rephrased. This lack of detailed justification makes the claim 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the content in lines 107114, noting that it seems speculative or overly opinionated. It provides actionable advice by suggesting that this content should be stated as a remark, an aside in the Discussion section, or removed. This feedback is clear and provides a direct way for the authors to improve their draft by addressing the speculative nature of the content. However, the comment could be more helpful if it offered additional guidance on how to rephrase or restructure the content to make it more appropriate for the Discussion section. Overall, the comment is 4 as it directs the authors to a specific area for improvement and offers a clear solution, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. While the comment implies that the authors should include these baselines for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines to validate their results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or experiment. The authors might infer that it pertains to the discussion or results sections, but this is not explicitly mentioned. The comment is specific in its suggestion to include additional baselines for comparison, but it lacks grounding as it does not specify the exact part of the paper where this suggestion should be addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, the comment does not provide any specific reasoning or evidence to support why these baselines are relevant or how they would improve the verification process. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should consider baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. This feedback is 3 as it provides a specific suggestion for additional experiments that could enhance the validation of the results. However, the comment lacks depth and does not offer detailed guidance on how to implement these baselines or what specific aspects of the results should be compared. To be more helpful, the comment could include more detailed reasoning or examples of how these baselines would contribute to the analysis. Therefore, the comment is rated as 3, as it provides a direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly states that the paper lacks an analysis of the value of the neighborhood size h and its influence on the model\"s performance. It also points out that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is clear and direct, giving the authors a specific action to take: conduct an analysis of the neighborhood size h and its impact on performance, and provide insights into the robustness of the method with respect to different neighborhood sizes. Additionally, the comment suggests that the authors should explore the performance variations with a constant set of parameters. This level of detail and specificity makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and the \"influence over the model\"s performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as providing insights into the value of h and the robustness of the method with respect to different neighborhood sizes. Additionally, it highlights the issue of using different hyperparameter sets per dataset, suggesting that the authors should provide insights into how performance varies with a constant set of parameters. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an analysis of the value of the neighborhood size h and its influence on the model\"s performance. It also points out that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the value of h or the robustness of the method. The suggestion to provide insights into performance variations with a constant set of parameters is a logical extension of the critique but remains somewhat vague without further elaboration. Therefore, the comment is 3, as it provides a basis for the claim but requires additional detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies two critical areas for improvement in the paper: the lack of analysis of the neighborhood size h and its influence on the model\"s performance, and the use of different hyperparameter sets per dataset. It highlights the importance of providing readers with intuitive knowledge of the value of h and the robustness of the method with respect to different neighborhood sizes. Additionally, it suggests that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is clear and actionable, offering specific areas for the authors to address to enhance the comprehensiveness and robustness of their work. By addressing these points, the authors can significantly improve the clarity and impact of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of missing data on the model and its ability to leverage additional modalities. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it difficult for the authors to identify the exact area needing attention. While the comment is specific in its inquiry about the impact of missing data, it lacks grounding, as it does not reference a specific part of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this issue. Without additional context or examples, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It prompts the authors to consider whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. This question is relevant and could lead to valuable insights into the robustness and generalizability of the model. However, the comment does not provide specific guidance or suggestions on how the authors might explore or address this issue, such as through additional experiments or analyses. While it identifies a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is explicit and concrete, as it clearly identifies what information should be included and how it should be presented. The authors are given a direct action to take, which is to include these statistics in their analysis. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely, to show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This provides a clear direction for the authors to enhance their analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This is a logical suggestion based on the observation that the SST dataset has phraselevel annotations. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of this suggestion based on the context of the paper, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. By including these statistics, the authors can better demonstrate the effectiveness of their approach and provide a more comprehensive understanding of their results. However, the comment could be more helpful if it included specific examples or references to support the suggestion. Overall, the comment is 4 as it offers a clear and actionable improvement to the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. While the comment implies that these methods are natural to consider and could provide valuable experimental comparisons, it does not explicitly instruct the authors to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should explore these methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental setup or methodology, but this inference is not explicit. The comment is specific in suggesting alternative methods that could be explored, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. This is a suggestion for further exploration rather than a claim. It does not contain any subjective opinions, judgments, or requests for changes that would require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameterefficient methods like LoRA. This feedback is 3 as it provides a direction for the authors to explore additional techniques that could enhance their work. However, the comment lacks specific guidance on how to implement these suggestions or what benefits they might offer, which limits its usefulness. The authors are given a direction for improvement but need more detailed information to fully act on the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to expand the related work section and compare their approach to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, specifying what needs to be added or improved in the related work section. The comment is explicit and concrete, giving the authors a clear path forward. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is located in, making it weakly grounded. The comment is specific in its suggestion to compare with strong baselines, but without explicit references to the related work section, the authors may struggle to pinpoint the exact area needing expansion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not provide any specific examples or references to support the claim that such comparisons are necessary or beneficial. Without detailed reasoning or evidence, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion to expand the related work section by comparing the approach to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for the authors to enhance their paper by including relevant comparisons. However, the comment could be more helpful if it provided examples of strong baselines or detailed guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the experiments in the paper should be expanded to include multiple seed experiments, which would provide a more robust evaluation of the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The suggestion is concrete, as it specifies what additional experiments should be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Single Seed Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experiments, which are limited to a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The suggestion to conduct multiple seed experiments provides a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. While the claim is logical and makes sense, it lacks specific examples or references to support the assertion that multiple seed experiments would indeed provide a more robust evaluation. This makes the claim 3, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the experimental design, noting that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that conducting multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it points out a critical area for improvement and offers a specific suggestion for enhancing the experimental methodology. By addressing this feedback, the authors can strengthen the validity and reliability of their results, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern about the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or suggestions for alternative approaches that could make the method more accessible. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a concern about the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the accessibility issue but lacks grounding, as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method requires an entire multiGPU setup for optimizations, making it less accessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts the accessibility of the method. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential accessibility issue with the proposed method, noting that it requires an entire multiGPU setup for optimizations. This observation is relevant and could be helpful for the authors to consider when discussing the practical implications of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the method more accessible. Without actionable advice or further elaboration, the feedback is limited in its usefulness. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that there is a missing citation for the public skipgram data set in line 425. This provides a clear and direct action for the authors to take, which is to include the necessary citation. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing citation for the public skipgram data set. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a factual statement that identifies a missing citation for a public skipgram data set in line 425. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, namely the missing citation for the public skipgram data set in line 425. This is a clear and actionable feedback that helps the authors correct an oversight in their paper. By pointing out this omission, the comment provides a direct path for the authors to improve the accuracy and completeness of their references. However, the comment could be more helpful if it offered additional guidance on how to find or cite the appropriate data set. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. While the comment provides explicit suggestions for improvement, it does not offer detailed guidance on how to implement these suggestions or what specific aspects to focus on when comparing the systems. The authors are given a clear direction but may need to infer the exact steps to take, making the comment 4.", "grounding_specificity_rationale": "The comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion to compare with another system and use Ref2 as a baseline, but without grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. While the suggestion to compare with another system is logical, the comment lacks specific details or evidence to support why this comparison is necessary or how it would enhance the paper. The mention of Ref2 provides some context, but it does not fully substantiate the claim. Therefore, the comment is considered 2, as it provides some support but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests comparing the current system, which captures semantics through RNNbased models, with another system that also captures semantics. It also recommends using Ref2 as a strong baseline for performance comparison. This feedback is clear and actionable, providing the authors with specific steps to enhance their work by including additional comparisons and baselines. However, the comment could be more helpful if it offered more detailed guidance on how to conduct these comparisons or what specific aspects to focus on when evaluating the performance. Overall, the comment is 4 as it directs the authors towards meaningful improvements but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. It suggests that one of the assumptions may not be satisfied or that there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions might be at fault. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what assumptions might not be satisfied or what learning difficulties are present. Without clear grounding or detailed guidance, the authors cannot effectively address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. It suggests that one of the assumptions may not be satisfied or that there are learning difficulties, but it does not provide any specific details or guidance on how to address these issues. The comment lacks actionable advice or suggestions for improvement, leaving the authors without a clear path to enhance their draft. As a result, the feedback is not helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly requests the authors to explain how the SE framework can help improve their work, similar to the previous comment. It suggests that the authors should provide a detailed explanation of why and how their framework is beneficial, rather than just showing what has been achieved. This feedback is clear and direct, providing a concrete action for the authors to take. The comment also includes a reference to a related work, which could guide the authors in their explanation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SE framework\" and references a specific work by Luo et al. (2020), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly requests a detailed explanation of how the SE framework can help improve the work, providing a clear direction for the authors to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" explanation of how the SE framework can help improve their work, suggesting that it lacks depth and requires a more detailed justification. The comment references a specific work by Luo et al. (2020) as a potential source of inspiration or comparison, which could provide a basis for the authors to expand their explanation. However, the comment does not fully explain why the reference is relevant or how it could be used to enhance the authors\" argument. While the reference is a step in the right direction, the lack of detailed reasoning or specific examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement in the paper, namely the lack of explanation of how the SE framework can help improve the work. It provides a clear and actionable suggestion for the authors to include a detailed explanation of the benefits and improvements that the SE framework offers. By referencing a related work, the comment also offers a potential direction for the authors to explore and expand upon. However, the comment could be more helpful if it provided specific examples or guidance on how to structure this explanation. Overall, the feedback is clear and actionable, but it could be further enhanced with more detailed suggestions. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes they should make to their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the user decoder\"s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the rationale behind the user decoder\"s information usage, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify this question or suggest why this might be problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the user decoder\"s information usage, specifically why it only uses information from time step t instead of all time steps. This question highlights a potential gap in the paper\"s methodology or explanation, prompting the authors to clarify or justify their approach. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that a section on synonym identification is missing under the similarity measurement section, specifying that it should describe how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, as they are instructed to include a section on synonym identification that explains the approach to the multiplechoice task. The comment is explicit and concrete, offering a specific direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"a section on synonym identification\" and specifies that it is missing under the \"similarity measurement\" section. This provides full grounding, as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of a section on synonym identification under similarity measurement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under the similarity measurement section, specifically regarding the multiplechoice task. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how its absence affects the paper. Without additional context or explanation, the claim remains 1, as the authors may not understand the significance of the missing section. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the absence of a section on synonym identification under the similarity measurement section. It specifies that this section should describe how the multiplechoice task is approached, providing a clear and actionable suggestion for improvement. By highlighting this omission, the comment helps the authors understand where their draft needs to be strengthened, making it 4. However, it could be more helpful if it offered additional guidance or examples on how to structure this section. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the comment implies that such an overview would be beneficial, it does not explicitly instruct the authors to include it or provide specific guidance on how to structure this overview. The action is implicit and somewhat vague, as the authors can infer the need for an overview but may not know how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, making it difficult for the authors to identify the exact sections that need revision. While the comment implies that the overview should be part of the introduction or methodology sections, this is not explicitly stated. The comment is specific in its suggestion but lacks grounding, as it does not provide a clear reference to the parts of the paper that need this overview. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While this feedback highlights an area that could improve the paper\"s comprehensibility, it lacks specificity and actionable guidance. It does not specify what aspects of the workflow or model should be included in the overview or how it would enhance the paper. This makes it 3, as it identifies a potential improvement but does not provide detailed instructions for implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The reviewer suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address it. The action is implicit and somewhat vague, as the authors need to infer that they should discuss this issue in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and its potential impact, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It argues that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment provides a logical reasoning for the concern, it lacks specific references or examples to fully substantiate the claim. This makes the claim 3, as it provides a basis for the concern but requires further elaboration for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the debiasing process in the paper, specifically noting the need to know the statistical dimension d_lambda of the design matrix A. It points out that accurately computing this dimension would require the same runtime as solving the ridge regression problem, which could introduce bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or discuss it in their paper. The feedback is 3 as it points out a potential weakness but does not provide detailed actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to redefine Figure 3, stating that the expected quantities are scalars but are currently shown as a vector. This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the figure. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is that the expected quantities are scalars but are currently shown as a vector. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 should be redefined because the expected quantities are scalars but are currently shown as a vector. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion regarding the redefinition of Figure 3. It identifies a particular issue with the figure, noting that the expected quantities are scalars but are currently shown as a vector. This feedback is clear and direct, offering a concrete step for the authors to take to improve the clarity and accuracy of their figure. By addressing this issue, the authors can enhance the quality and comprehensibility of their draft. Therefore, the comment is 5, as it provides a clear and actionable direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific guidance on what aspects of the experimental setup need improvement or how to address these questions. The comment lacks explicit instructions or concrete details on how to enhance the experimental setup, leaving the authors uncertain about what actions to take. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not specify which part of the paper these ablation experiments are discussed in, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestion that the experiments deserve better setup, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific details or examples of what these questions are or how the experiments could be improved. This lack of specificity and actionable guidance makes it difficult for the authors to address the feedback effectively. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer concrete steps or suggestions for enhancement. Therefore, it aligns with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide empirical evidence to test this hypothesis, which is a clear and explicit action. Additionally, the comment implies that the lack of explanation for the improvements is a concern, as it does not seem to explain the improvements in the word similarity data sets. While the action is explicit, the comment does not provide detailed guidance on how to conduct the empirical evidence or what specific aspects to focus on. Therefore, the comment is 4, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses a specific claim about the usefulness of the proposed models for learning representations for lowfrequency words. It highlights the lack of empirical evidence to support this claim and suggests that the authors should provide such evidence. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing what is missing (empirical evidence) and what could be improved (explaining the improvements in word similarity data sets). Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the authors have made a reasonable argument about the usefulness of the proposed models for learning representations for lowfrequency words, but they lack empirical evidence to support this claim. The reviewer suggests that the authors should provide empirical evidence to test the hypothesis. However, the comment does not provide specific examples or references to support the claim or suggest how the authors might conduct the empirical evidence. This makes the claim 3, as it highlights a gap in the paper but lacks detailed guidance or evidence to fully substantiate the need for empirical evidence.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for lowfrequency words. It suggests that the authors should provide empirical evidence to test this hypothesis, which is a clear and actionable suggestion. Additionally, the comment points out that the lack of explanation for the improvements is a concern, as it does not seem to explain the improvements in the word similarity data sets. This feedback is 4 as it provides clear guidance on what the authors need to address to improve their draft, but it could be more detailed by offering specific suggestions on how to conduct the empirical evidence or what aspects to focus on. Overall, the comment is valuable in guiding the authors towards enhancing the empirical support for their claims, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the resolution of the 3D voxel and its impact on the computational and memory cost of the network. It suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. The comment also mentions a specific scenario where the resolution is reduced to 1x1x1, which is essentially using a single global feature. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this comparison to strengthen their argument. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the resolution of the 3D voxel and its impact on the computational and memory cost of the network. The comment suggests a comparison with different resolutions of voxel features to study the importance of the global feature. The mention of a specific scenario where the resolution is reduced to 1x1x1 provides a clear example of the proposed comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the resolution of the 3D voxel and its impact on the computational and memory cost of the network. It suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. The comment provides a logical reasoning by pointing out that reducing the resolution to 1x1x1 would essentially use a single global feature, which could be a more convincing approach. However, the comment lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to conduct the suggested comparison to fully address the concern, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the resolution of the 3D voxel and its impact on the computational and memory cost of the network. It suggests that the authors should study the importance of the global feature by comparing it with different resolutions of voxel features. The comment provides a specific scenario where the resolution is reduced to 1x1x1, which is essentially using a single global feature. This feedback is clear and actionable, as it guides the authors to conduct a more comprehensive analysis of the global feature\"s importance. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific results to expect. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the error analysis on the movie dataset is missing, and it suggests that other researchers need to know what cases the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis on the movie dataset. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely, the need for an error analysis to understand the cases where the model fails. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual statement rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks detail, namely the absence of an error analysis on the movie dataset. It highlights the importance of this analysis for other researchers who might build upon the work, as it would provide insights into the cases where the model fails. This feedback is clear and actionable, as it directs the authors to include an error analysis to enhance the comprehensiveness and utility of their work. However, the comment could be more helpful if it suggested specific methods or approaches for conducting the error analysis. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that it would be interesting to see trends in the development set with respect to these hyperparameters. While the comment implies that the authors should investigate and present these trends, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore and present these trends. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in discerning trends in the table, particularly regarding the behavior of PM+CL compared to PM or CL alone. The comment suggests that it would be interesting to see trends in the development set with respect to these hyperparameters. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that it would be interesting to see trends in the development set with respect to these hyperparameters. While the comment identifies a potential issue with the table, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to explore trends in the development set provides a direction for improvement but does not offer a comprehensive explanation or evidence to support the need for this exploration. Therefore, the comment is 3, as it provides a suggestion but lacks detailed justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends, particularly regarding the behavior of PM+CL compared to PM or CL alone. It suggests that it would be interesting to see trends in the development set with respect to these hyperparameters. This feedback is 3 as it points out a potential weakness in the presentation of results and offers a suggestion for improvement. However, it could be more helpful if it provided specific guidance on how to present these trends or what aspects of the trends are particularly important to highlight. Overall, the comment provides a direction for improvement but lacks depth, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the difficulty in understanding Figure 5 due to the clutter of lines. It suggests that the authors could report additional metrics like flops or model size to make the figure more concrete and easier to interpret. This feedback is clear and provides a specific action for the authors to take, making it 5. The authors know exactly what needs to be done to improve the clarity of their figure and the report, ensuring a direct path to enhancing the draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the difficulty in understanding the figure due to the clutter of lines and suggests reporting additional metrics like flops or model size to make the figure more concrete. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is difficult to understand due to the clutter of lines and suggests reporting additional metrics like flops or model size to make it more concrete. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to report additional metrics is a logical step to improve clarity, but without further elaboration, the comment remains 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to understand due to the clutter of lines. It provides a clear suggestion for improvement by recommending that the authors report additional metrics such as flops or model size to enhance the clarity and comprehensiveness of the figure. This feedback is actionable and provides a concrete direction for the authors to improve their draft, making it 4. However, it could be more helpful if it included specific examples of how these additional metrics could be incorporated or how they might enhance the figure. Overall, the comment is clear and actionable, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that some details of the proposed method are missing, but it does not provide specific guidance on what these details are or how they should be addressed. The comment mentions \"questions section below,\" which implies that the authors should refer to that section for more information, but it does not explicitly instruct them to do so. Without concrete details or explicit actions, the authors are left without a clear understanding of what needs to be added or clarified. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment mentions \"some details of the proposed method are missing,\" but it does not specify which part of the paper these details are missing from or what specific details are lacking. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in suggesting that \"some details are missing,\" but without explicit references or examples, it remains weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that some details of the proposed method are missing, but it does not provide any specific examples or reasoning to support this claim. Without detailed information or references, the authors may find it challenging to understand what specific details are missing and how to address them. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that some details are missing. However, it does not provide any further context, examples, or suggestions on what these details might be or how they could be addressed. This lack of detail and guidance makes it difficult for the authors to understand the scope of the problem or how to improve their draft. As a result, the comment is 2, as it does not offer actionable feedback or insights that could guide the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should evaluate the EIGNN with respect to oversmoothing under standard settings on realworld datasets, particularly in comparison with variants that address oversmoothing, like the setting used in GCNII. While the comment implies that the authors should conduct this evaluation, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for this evaluation, but it lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests evaluating the EIGNN with respect to oversmoothing under standard settings on realworld datasets, comparing it with variants that address oversmoothing, such as the setting used in GCNII. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to evaluate the model under standard settings and compare it with existing methods, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the EIGNN with respect to oversmoothing under standard settings on realworld datasets, comparing it with variants that address oversmoothing, such as the setting used in GCNII. While the comment provides a logical suggestion for further evaluation, it lacks specific examples or references to support the claim that this evaluation is necessary or would be beneficial. The suggestion is 3 as it points out a potential area for improvement, but it requires more detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an interesting direction for evaluating the EIGNN by comparing it with variants that address oversmoothing, such as the setting used in GCNII. This feedback provides a clear and actionable suggestion for further research, encouraging the authors to explore a specific aspect of their model\"s performance. By comparing the EIGNN with existing methods, the authors can gain insights into its strengths and weaknesses, potentially leading to improvements in their work. However, the comment could be more helpful if it included specific details on how to conduct this evaluation or what aspects to focus on. Overall, the comment is 4 as it offers a clear direction for enhancing the paper\"s scope and impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of a separate part or subsection dedicated to introducing the inference strategy, specifically how to use multiple prompts in the test stage. This provides a clear and direct action for the authors to take, which is to include such a section or subsection in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a separate part or subsection dedicated to introducing the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the approach method lacks a separate part or subsection dedicated to introducing the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of a separate part or subsection dedicated to introducing the inference strategy, particularly how to use multiple prompts in the test stage. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of such a section. However, the comment could be more helpful if it offered additional guidance on how to structure this section or what specific aspects of the inference strategy should be included. Despite this, the comment is 4 as it directs the authors to a specific area needing attention and improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises two concerns: first, it questions whether the conclusion drawn from the Streetview experiment is valid, suggesting that MaxGapTop2UCB might be better than other methods. Second, it points out that the realworld applications of the new problem setting are not clear, particularly regarding the applicability to sorting/ranking and the computational complexity of the proposed algorithms. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes. The feedback is 3 as it identifies potential areas of concern but lacks detailed instructions on how to resolve them. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the discussion of experiment results and the clarity of realworld applications. It raises a question about the conclusion drawn from the Streetview experiment regarding the superiority of MaxGapTop2UCB, suggesting that this conclusion may not be justified. Additionally, it questions the applicability of the new problem setting to sorting/ranking and the computational complexity of the proposed algorithms. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the discussion of results and the applicability of the problem setting. The comment is specific in detailing the issues, but it lacks explicit grounding, making it weakly grounded. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises two concerns. First, it questions the conclusion drawn from the Streetview experiment, suggesting that MaxGapTop2UCB might be better than other methods. This claim is 3 as it provides a logical basis for questioning the conclusion, but it lacks specific examples or detailed reasoning to fully substantiate the claim. Second, the comment questions the applicability of the new problem setting to sorting/ranking and the computational complexity of the proposed algorithms. This part of the comment is 3 as it points out a potential issue with the complexity of the algorithm, but it does not provide specific examples or references to support the claim. Overall, the comment is 4, as it provides some reasoning and examples but lacks full justification.", "helpfulness_rationale": "The review comment identifies two areas for improvement in the paper. First, it questions the conclusion drawn from the Streetview experiment, suggesting that the results may not support the claim that MaxGapTop2UCB is better than other methods. This feedback prompts the authors to reconsider their conclusions and provide a more robust justification for their findings. Second, the comment raises concerns about the applicability of the new problem setting to realworld scenarios, particularly regarding the computational complexity of the proposed algorithms. It highlights the need for a more detailed discussion on the practical implications of the work. While the comment provides valuable insights, it could be more helpful if it offered suggestions on how to address these issues or provided specific examples. Overall, the comment is 4 as it identifies areas for improvement and encourages the authors to enhance the clarity and depth of their discussion."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods. It suggests that more explanations could be provided. While the comment implies that the authors should offer additional explanations, it does not explicitly instruct them to do so or provide specific guidance on what aspects to explain. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like fCLSWGAN and fVAEGAND2. It suggests that more explanations could be given. However, the comment does not specify which part of the paper this issue is related to, such as the results section or the ablation experiments. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the explanations are needed or how they should be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like fCLSWGAN and fVAEGAND2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the results are indeed lower than expected. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like fCLSWGAN and fVAEGAND2. It suggests that more explanations could be given, implying that the authors should provide additional context or analysis to address this issue. While the comment identifies a potential weakness in the results, it lacks specific guidance or suggestions on how to improve the explanations or address the low results. The feedback is 3 as it points out an area for improvement but does not offer detailed advice or actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of an ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this lack. The action is implicit, as the authors need to infer that they should include an ablation analysis to better understand the performance gains. However, the comment lacks concrete details on how to conduct the analysis or what specific components should be analyzed. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment highlights the absence of an ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper should include this analysis or provide guidance on how to conduct it. The authors can infer that the main paper is being referred to, but the lack of specific guidance makes it challenging to pinpoint the exact section needing attention. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the lack of an ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the paper, namely the absence of an ablation analysis, which makes it difficult to determine the source of the small performance gain. This feedback is clear and actionable, as it highlights a critical area that the authors need to address to improve the clarity and robustness of their results. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation analysis or which components should be analyzed. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a concern with the experimental design, specifically noting that the hypothesis is not wellverified by the current experimental setup. It suggests that comparing the model trained on the original dataset with that trained on a mixture of the original and adversarial examples would better highlight the impact of the augmented adversarial examples. The comment implies that the authors should modify their experimental setup to include this comparison, which is a clear and concrete action. However, it does not explicitly instruct the authors to make this change, leaving some room for interpretation. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks explicit instructions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental design, suggesting that the authors should compare the model trained on the original dataset with that trained on a mixture of the original and adversarial examples to better highlight the impact of the augmented adversarial examples. This provides clear guidance on how to improve the experimental setup. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not wellverified by the designed experiment, particularly noting that the models in conventional methods are trained on the original training set plus adversarial examples, while the base model is trained only on adversarial examples. The reviewer suggests that comparing the model trained on the original dataset with that trained on a mixture of the original and adversarial examples would better highlight the impact of the augmented adversarial examples. This claim is 3 as it provides a logical reasoning for the need to make the experiment more convincing, but it lacks specific examples or references to support the claim fully. The authors would need to further explore and substantiate this suggestion to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental design, specifically noting that the hypothesis is not wellverified by the current experimental setup. It points out a discrepancy in the training of models, suggesting that comparing the model trained on the original dataset with that trained on a mixture of the original and adversarial examples would better highlight the impact of the augmented adversarial examples. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the verifiability of the hypothesis. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or if it pointed out other areas where the experimental design could be improved. Overall, the comment is 4, as it offers a clear direction for enhancing the paper\"s experimental rigor."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on what aspects of the experiments are lacking or how they could be improved. Without explicit guidance or concrete steps for the authors to take, the comment does not offer actionable feedback. The lack of specificity and direction makes it difficult for the authors to understand what needs to be addressed or how to improve their experiments. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in or provide any details on what aspects are lacking. This makes it difficult for the authors to identify the exact sections that need attention. Without specific guidance or examples, the comment lacks both grounding and specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern with the CNN experiments, stating that they are not fully convincing. However, it does not provide any specific details or examples of what aspects of the experiments are lacking or how they could be improved. Without actionable feedback or suggestions, the authors are left without a clear path to address the issue. The comment lacks depth and specificity, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the results for model (3) in Table 1, which are not reported in the paper, should be mentioned if they were computed by the authors themselves. This provides a clear and direct action for the authors to take, which is to include a note about the computation of these results. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"model (3) (Chung et al. 2016) for CsEn,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the results for model (3) are not reported in the paper and should be mentioned if they were computed by the authors themselves. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) in Table 1 are not reported in the paper and should be mentioned if they were computed by the authors themselves. The comment provides a specific example of a missing result, which is \"CsEn,\" and suggests that the authors should include a note about the computation of these results. This claim is 3 as it identifies a specific issue with the paper\"s reporting and provides a clear suggestion for improvement. However, it lacks detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that the results for model (3) (Chung et al. 2016) for CsEn are not reported and suggesting that the authors should mention if they computed these results themselves. This feedback is clear and actionable, as it directs the authors to clarify their methodology or include additional information in their paper. By addressing this issue, the authors can enhance the transparency and completeness of their work. However, the comment could be more helpful if it provided additional guidance on how to present this information or suggested ways to improve the clarity of the results. Overall, the comment is 4, as it provides a specific and actionable suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. While the action is explicit, it does not provide detailed guidance on how to conduct the comparison or what specific aspects to focus on. The authors are given a clear direction to follow but are left to determine the exact steps and details of the comparison. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result section. The authors may infer that it relates to the results or discussion section, but this inference is not explicit. The comment is specific in suggesting a comparison with HateXplain models, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. However, it does not provide any reasoning, evidence, or examples to support why such a comparison would be beneficial or how it could enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the results with existing stateoftheart (SoTA) approaches, specifically mentioning HateXplain models. This feedback is 3 as it provides a specific direction for the authors to enhance their work by comparing their results with established models in the field. However, the comment lacks depth and does not offer detailed guidance on how to conduct the comparison or what specific aspects to focus on. To be more helpful, the comment could include suggestions on how to structure the comparison or what metrics to use for evaluation. Overall, the feedback is 3 as it points out a potential area for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment implies that the authors should consider using the adaptive method, it does not provide explicit guidance on how to implement this change or why it would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should explore the adaptive method and justify its use. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. However, it does not specify which part of the paper discusses the use of freezing or the MLS selection process, making it weakly grounded. The comment is specific in its critique of the methodological choice, suggesting a potential improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. However, the comment lacks specific reasoning or evidence to support why freezing is not effective or why the adaptive method should be preferred. The claim is based on a subjective comparison between the two methods without detailed justification, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might justify or implement the use of the adaptive method. The feedback is 3 as it prompts the authors to consider alternative methods, but it does not provide detailed advice or examples to support this suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) that involves adding negation or changing entities in text to test the model\"s robustness. While the comment implies that such an analysis would be beneficial, it does not explicitly instruct the authors to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should perform a robustness analysis similar to existing work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\"s robustness. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting a method for testing robustness, but without explicit grounding, the authors may struggle to identify the exact section where this analysis should be integrated. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\"s robustness. While the comment provides a reference to existing work, it lacks specific details or examples of how the analysis should be conducted or what aspects of robustness should be tested. This makes the claim 3, as the authors would need to infer the exact steps to take based on the reference provided. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about whether the issue of robustness is addressed in the proposed knowledgeCLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\"s robustness. This feedback is 3 as it identifies a potential area for improvement and provides a specific reference for the authors to follow. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the analysis or what specific aspects of robustness should be tested. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should provide more explanation on how novel values in the test set are handled. This is a clear and direct action for the authors to take, as it specifies what additional information is needed to improve the clarity of the paper. The comment is concrete, as it directly instructs the authors to provide more explanation, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing more explanation on how novel values in the test set are handled. This provides clear guidance on what the authors need to do to improve the clarity of their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more explanation on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more explanation on how novel values in the test set are handled. This is a clear and actionable suggestion that can help the authors clarify their methodology and improve the clarity of their draft. However, the comment could be more helpful if it provided specific examples or guidance on how to handle novel values in the test set. Overall, the feedback is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the comment provides a potential solution, it lacks explicit instructions on how the authors should implement this solution or address the confusing writing. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to resolve the issues. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses two issues (1) and (2) and suggests a potential solution by using a generic external knowledge base, as shown in Figure 3. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in suggesting a solution to the issues, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as shown in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the suggestion is logical and supported by the reference to Figure 3, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the confusing writing. This makes the claim 3, as it provides a potential solution but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two issues (1) and (2) that can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. This provides a clear and actionable suggestion for improvement, offering a potential solution to the issues. However, the comment also notes that the writing is confusing, which is a separate issue that needs to be addressed. While the suggestion is helpful, the comment could be more comprehensive by providing specific examples or guidance on how to clarify the confusing writing. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more detailed to fully support the authors in enhancing their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also suggests trying other influential losses, such as replacing the min with a mean or NDCG. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should explore alternative loss functions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also suggests trying other influential losses, such as replacing the min with a mean or NDCG. However, the comment does not specify which part of the paper this relates to, making it weakly grounded. The authors can infer that it pertains to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, such as the choice of similarity threshold and the exploration of alternative loss functions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification and suggestions for improvement. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions and suggestions for improvement regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also suggests exploring other influential losses, such as replacing the min with a mean or NDCG. While the comment identifies areas for further exploration and improvement, it lacks specific guidance or detailed suggestions on how to implement these changes. The authors are left with a general understanding of what needs to be addressed but without actionable steps to take. Therefore, the comment is 3, as it provides some insight but does not fully guide the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a missing aspect in the paper, specifically the lack of indepth analysis on experimental results. It questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to conduct a more detailed analysis of the experimental results, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific area for improvement but does not offer detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment highlights a missing aspect in the paper, specifically the lack of indepth analysis on experimental results. It questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this is not explicitly mentioned. The comment is specific in detailing what is missing, namely an indepth analysis of the experimental results, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a missing indepth analysis on experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an indepth analysis of experimental results. It specifically questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is valuable as it highlights an area where the authors can provide more detailed explanations or analyses to enhance the comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what specific aspects should be explored. Overall, the comment is 3 as it directs the authors to a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several actions for the authors to consider, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for nonsynthetic tasks. However, the comment does not provide specific guidance on how to implement these suggestions or what constitutes an appropriate number of convolutional layers. While the actions are explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests several actions for the authors to consider, such as training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for nonsynthetic tasks. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing the actions and improvements needed, but without grounding, it is challenging for the authors to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests several actions for the authors to consider, such as training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. It also questions the effectiveness of the proposed method, referencing the common failure of robustness and domaininvariance interventions. However, the comment lacks specific examples or references to support the claim that the proposed method would not work, making it difficult for the authors to fully understand and address the critique. The suggestion to use modern backbone baselines is a logical recommendation, but without further justification, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for nonsynthetic tasks. These suggestions are clear and provide specific guidance on how the authors can enhance their work. However, the comment also expresses skepticism about the effectiveness of the proposed method, which is a personal opinion and not directly actionable. Overall, the comment is 4 as it offers valuable insights and actionable steps for improvement, but it could be more comprehensive if it included a more detailed analysis of the skepticism. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to achieve this. The action is somewhat vague, as it does not specify the exact steps or methods to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of hyperparameters and suggests that the baseline should be fully tuned with the same resources as the proposed method for a fair comparison. However, it does not specify which part of the paper discusses the hyperparameters or the baseline, making it weakly grounded. The comment is specific in its suggestion to ensure a fair comparison, but without explicit references to sections or parts of the paper, it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. However, the comment does not provide specific examples or detailed reasoning to support why this is important or how it would impact the fairness of the comparison. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the extensive use of hyperparameters and the need for a fair comparison. It suggests that the authors should ensure the baseline is fully tuned with the same resources as the proposed method, which is a valuable piece of feedback. However, the comment lacks specific guidance on how to achieve this or what resources should be considered. While it points out an important area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a discrepancy in the definition of perplexity, stating that it is not what perplexity is and that Eq1 does not resemble perplexity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to correct the definition or what changes should be made to Eq1. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and points out that Eq1 does not resemble perplexity. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of factual statements about the definition of perplexity and the equation presented in the paper. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in the definition of perplexity, pointing out that the definition provided in the text does not align with the standard understanding of perplexity. It also notes that Eq1 does not resemble perplexity, suggesting that it might be a different measure. This feedback is clear and actionable, as it highlights specific areas where the authors need to clarify or correct their definitions. However, the comment could be more helpful if it provided additional context or suggested how the authors might address these issues. Overall, the comment is 4 as it guides the authors in improving their understanding and presentation of key concepts. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add more baselines of graph contrastive learning and test them on common datasets. This is a clear and direct action that provides specific guidance on what needs to be done to improve the draft. The comment is 5 because it gives the authors a clear path forward in addressing the issue of insufficient baseline comparison in the graph classification task.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and specifies the issue with the lack of sufficient baselines, such as MVGRL4 and gptgnn5. This provides clear guidance on which part of the paper needs attention. The comment is also specific because it suggests adding more baselines of graph contrastive learning and testing them on common datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the baseline comparison in the graph classification task is insufficient, specifically mentioning the absence of MVGRL4 and gptgnn5. The reviewer suggests adding more baselines of graph contrastive learning and testing them on common datasets. While the comment identifies a potential issue with the baseline comparison, it lacks specific examples or references to support the claim that these particular baselines are essential or that their inclusion would significantly improve the study. The suggestion to add more baselines is a logical one, but without detailed justification or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the baseline comparison in the graph classification task, noting that the current baseline is insufficient. It suggests adding more baselines of graph contrastive learning and testing them on common datasets. This feedback is clear and actionable, providing the authors with a specific direction for improving their study by expanding the baseline comparison. However, the comment could be more helpful if it offered additional guidance on which specific baselines to consider or how to effectively test them. Despite this, the feedback is 4 as it directs the authors to a clear area for enhancement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern regarding the evaluation of the proposed strategies, specifically noting that the authors should consider evaluating their defense against an adversarial attack that minimally alters the edge map while still misleading the model predictions. While the comment implies that the authors should conduct this evaluation, it does not provide explicit instructions on how to implement this evaluation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for a new evaluation but lack detailed guidance on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern regarding the evaluation of the proposed strategies, particularly the need to evaluate the defense against an adversarial attack that minimally alters the edge map. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the evaluation against an adversarial attack that minimally alters the edge map, providing clear guidance on the issue to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically noting that the authors should consider evaluating their defense against an adversarial attack that minimally alters the edge map. The comment provides a logical reasoning by suggesting that an adversary could potentially optimize the perturbation to maintain minimal structural alterations while still misleading the model predictions. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the relevance of this concern and determine how to address it, which limits the level of verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the evaluation of the proposed strategies, specifically highlighting the need to evaluate the defense against an adversarial attack that minimally alters the edge map while still misleading the model predictions. This feedback is 5 as it provides a clear direction for the authors to improve their evaluation methodology. By suggesting a more refined adversarial attack scenario, the comment offers a specific and constructive way to enhance the robustness of the proposed defense mechanisms. This feedback is valuable as it guides the authors in addressing a potential weakness in their evaluation, potentially leading to a more comprehensive and robust study. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a theoretical weakness in the analysis, specifically regarding the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. While it identifies an area that needs improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed analysis or references to support the theoretical claims. However, the comment lacks concrete steps or suggestions on how to strengthen the analysis, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theoretical work on sampling and particlebased optimization methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the analysis, such as the lack of information on the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis is weak in light of theoretical work on sampling and particlebased optimization methods. It specifically mentions the lack of information on the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. While the comment identifies a gap in the analysis, it does not provide specific references or detailed reasoning to support the claim. The lack of explicit examples or detailed justification makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a significant theoretical weakness in the paper by pointing out that the analysis lacks information on the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization in time and space. This feedback is valuable as it highlights an area that needs further development or clarification. However, the comment could be more helpful if it provided specific suggestions or references on how to address these issues. Overall, the comment is 3 as it directs the authors\" attention to a critical area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the quality of the generated images or what specific aspects need to be addressed. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not specify which part of the paper discusses the generated images or the results, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue of limited realism, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, despite achieving good continuous control. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. This feedback is 3 as it points out a specific area for improvement, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness but does not offer concrete steps or examples for the authors to consider, leaving them with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It instructs them to describe how G is built using the human skeleton, to specify the size and elements of G, and to include the dimensions of G, X, and W. These actions are clear and concrete, guiding the authors on exactly what information needs to be added or clarified to improve their draft. The comment is 5 because it provides specific and detailed guidance on how to enhance the clarity and comprehensiveness of the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as describing how G is built using the human skeleton, detailing the size and elements of G, and adding the dimensions of G, X, and W to better understand the role of DGCN. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more details about how G is built using the human skeleton and specify the size and elements of G. It also recommends adding the dimensions of G, X, and W to better understand the role of DGCN. While the comment provides a clear suggestion for improvement, it does not include specific examples or references to support the claim that this information is necessary or missing. The lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of this information themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a gap in the description of how G is built using the human skeleton in Section 3.3. It suggests that the authors should provide more details about the size and elements of G, as well as the dimensions of G, X, and W, to enhance the clarity and understanding of the paper. This feedback is clear and actionable, offering the authors a straightforward way to improve the comprehensibility of their work. However, it could be more helpful if it included suggestions on how to present this information or examples of how other studies have addressed similar issues. Overall, the comment is 4 as it guides the authors toward improving the clarity and completeness of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. However, the comment does not explicitly instruct the authors to make this correction or provide guidance on how to incorporate this information into their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address the discrepancy in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 559560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement about Cycle Consistency loss and provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point challenges a statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This explanation is logical and provides a clear correction to the original claim, making the comment 4. However, it could be strengthened by providing specific references or examples to support the correction. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a discrepancy in the paper\"s description of Cycle Consistency loss, pointing out that the statement is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This feedback is clear and actionable, as it guides the authors to correct a potential misunderstanding in their paper. However, the comment could be more helpful if it included specific suggestions on how to incorporate this correction into the draft or provided additional context to enhance the authors\" understanding. Overall, the comment is 4, as it offers valuable insights for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the term \"hyperspectral\" is confusing and suggests that it is used incorrectly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the confusion or what alternative terminology might be more appropriate. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the term \"hyperspectral,\" which is used in the context of hyperspectral imaging. However, it does not specify which part of the paper this term is used in, making it difficult for the authors to identify the exact section that needs revision. While the comment provides a clear explanation of what is confusing about the term, it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the term \"hyperspectral\" is confusing, suggesting that it is used incorrectly. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential confusion in terminology, specifically regarding the term \"hyperspectral.\" It points out that the term is misleading and suggests that it is used incorrectly, as hyperspectral imaging is defined as obtaining the spectrum for each pixel in an image. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their terminology. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, specifically mentioning the example of combining Linformer and window attention in Big Bird using contrition. While the comment implies that the authors should include such explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for more detailed explanations, but it lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment refers to specific points mentioned in the paper, \"1), 2), and 3) mentioned above,\" which suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. However, it does not explicitly mention which sections or parts of the paper these points are located in, making it weakly grounded. The comment is specific in its suggestion to provide more detailed explanations, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, specifically mentioning the example of combining Linformer and window attention in Big Bird using contrition. While the comment implies that the current explanations are insufficient, it does not provide specific examples or references to support the claim that the current explanations are inadequate. The suggestion is clear and logical, but without detailed justification or examples, it is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. It references specific examples, such as the combination of Linformer and window attention in Big Bird using contrition, which could be used to illustrate the point. This feedback is clear and actionable, as it guides the authors on what additional information is needed to enhance the clarity and depth of their explanations. However, the comment could be more helpful if it provided specific suggestions or examples of how to improve the explanations. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some details of the models are missing, specifically mentioning the lack of explanation for the grammar over kernels. It suggests that there are probabilities associated with the grammar that define a hypothesis space of kernels and asks how inference is performed. While the comment identifies areas that need clarification, it does not explicitly instruct the authors to add specific details or provide guidance on how to address these issues. The action is implicit and somewhat vague, as the authors can infer that more details are needed but may not know exactly what to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detail regarding the models, specifically mentioning the grammar over kernels and the probabilities associated with it. It also questions how inference is performed. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in detailing what is missing and suggesting areas for clarification, such as the grammar over kernels and inference methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of detail regarding the models, specifically the grammar over kernels and the probabilities associated with it. It questions how inference is performed, which is a logical and reasonable inquiry. However, the comment does not provide specific examples or references to support the claim that these details are missing or that they are not explained in detail. This makes the claim 3, as the authors would need to infer the extent of the issue based on their understanding of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks detail, specifically the grammar over kernels and the probabilities associated with it. It questions how inference is performed, which is a valid concern for understanding the practical application of the approach. However, the comment does not provide specific suggestions or guidance on how to address these issues, such as recommending additional explanations or references. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of explicit verification of the effectiveness of the visual information, the unclear implementation details of the w/o perception module, and the questionable significance of the improvements based on the sample size. While the comment identifies these issues, it does not provide specific guidance or suggestions on how the authors should address them. The lack of actionable steps or concrete advice makes it difficult for the authors to know exactly what changes to make to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the paper, including the lack of explicit verification of the effectiveness of the visual information, the unclear implementation details of the w/o perception module, and the questionable significance of the improvements based on the sample size. It also mentions Table 10, which is a specific part of the paper. However, the comment does not explicitly mention which part of the paper is being discussed, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, such as the need for explicit verification and detailed implementation details. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the paper, including the lack of explicit verification of the effectiveness of the visual information, unclear implementation details, and questionable significance of the improvements based on the sample size. The reviewer provides logical reasoning by pointing out that the ablation study does not explicitly verify the effectiveness of the visual information and that the improvements are impossible to be significant given the sample size of 1000 users. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to provide additional evidence or clarification to fully address these concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several critical issues with the paper, including the lack of explicit verification of the effectiveness of the visual information, unclear implementation details, and questionable significance of the improvements based on the sample size. It provides specific examples, such as the ablation study and Table 10, which helps the authors understand where the issues lie. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as proposing specific experiments or analyses to clarify the effectiveness of the visual information. Overall, the comment is 3 as it highlights areas for improvement but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the paper\"s claim that Transfer Lasso showed the best accuracy in feature screening, as it does not cite or compare previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This comment explicitly instructs the authors to cite and compare these previous works, providing a clear and concrete action for them to take. The feedback is specific and actionable, as it outlines exactly what needs to be added to the paper to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of citation and comparison of previous works on Lasso screening, such as Ren et al. \"Safe feature screening for generalized LASSO.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s assertion about Transfer Lasso showing the best accuracy in feature screening is not supported by a citation or comparison to previous works on Lasso screening, specifically mentioning Ren et al.\"s work. However, the comment does not provide specific examples or detailed reasoning to substantiate the claim, such as explaining why the cited work is relevant or how it compares to Transfer Lasso. Without additional context or references, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim that Transfer Lasso showed the best accuracy in feature screening, noting that it does not cite or compare previous works on Lasso screening, such as Ren et al.\"s work. This feedback is clear and actionable, as it directs the authors to include relevant citations and comparisons to strengthen their argument. By providing a specific reference, the comment offers a concrete step for the authors to take to improve the paper\"s credibility and comprehensiveness. However, the comment could be more helpful if it suggested how the authors might integrate these references or what specific aspects of the previous work should be highlighted. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting they provide the missing hyperparameters or clarify their implementation in the paper. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the model, noting that it has many components with unspecified hyperparameters. However, it does not specify which parts of the paper discuss these components or provide details on the hyperparameters. The authors can infer that the issue relates to the model description or implementation, but they cannot confidently pinpoint the exact sections. The comment is specific in identifying the need for more detailed information on hyperparameters, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model, noting that it has many components with unspecified hyperparameters. This is a critical point as it could affect the reproducibility and replicability of the model. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as providing the missing hyperparameters or clarifying their implementation in the paper. Without actionable feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential weakness but does not offer constructive advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity in the notation used for results, specifically questioning what \"%p\" stands for in the context of the paper\"s claims about the improvement on CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it highlights a specific area for improvement but does not offer detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"notation for results\" and specifically questions the meaning of \"%p\" in the context of the paper\"s claims about the improvement on CIFAR10. This provides clear guidance on where the authors need to clarify their notation, making it easy for the authors to identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notation, namely the unclear meaning of \"%p.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of notation used in the paper, specifically regarding the meaning of \"%p\" in the context of the claim about the improvement on CIFAR10. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify what \"%p\" stands for or why it is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of notation in the paper, specifically questioning the meaning of \"%p\" in the context of the claim about the improvement on CIFAR10. This feedback is clear and actionable, as it points out a potential source of confusion for readers. By addressing this issue, the authors can improve the clarity and accessibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the notation or offered alternative ways to express the results. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative metrics they should use. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their choice of metrics. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, namely the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the human evaluation section. The comment is also specific because it clearly specifies the issue with the use of TSS and suggests that this choice weakens the convincingness of the human evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of an automatic metric, TSS, instead of a human metric weakens the convincingness of the human evaluation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is problematic or how it affects the evaluation\"s credibility. Without additional context or explanation, the claim remains 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the human evaluation process, specifically questioning the use of an automatic metric, TSS, instead of a human metric for evaluating style control. This feedback highlights a gap in the evaluation methodology that could impact the credibility of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their evaluation process. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. While the comment implies that the authors should expand their experiments to cover a broader range of domains, it does not provide explicit guidance on how to achieve this or which specific domains to include. The action is somewhat implicit and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are succinct and effectively prove the authors\" point, but it would be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. However, the comment does not specify which part of the paper these experiments are in or how they relate to the broader discussion. The authors can infer that it pertains to the experimental section, but the lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in suggesting a direction for improvement, but the lack of grounding makes it challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiments are succinct and effectively prove the authors\" point, but it would be strengthened by including experiments across more diverse domains. However, the comment does not provide any specific examples or reasoning to support the claim that the experiments are not diverse enough. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment acknowledges that the experiments effectively prove the authors\" point but suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TDMPC 2. This feedback is 3 as it identifies a potential area for improvement in the paper\"s experimental validation. However, the comment lacks specific guidance on how to expand the experiments or which additional domains to explore. To be more helpful, the comment could provide more detailed suggestions or examples of how to diversify the experiments. Therefore, the comment is rated as 3, as it offers a direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of the interpretability tax they should evaluate. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the lack of evaluation of the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or subsection. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue of not evaluating the interpretability tax, but it lacks grounding as it does not specify the exact part of the paper where this evaluation should be included. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks evaluation, namely the magnitude of the interpretability tax associated with the method. This is a valuable observation as it highlights a potential weakness in the paper\"s analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what aspects of the interpretability tax should be evaluated. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. However, it suggests that the main contribution of the paper lies in demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel techniques. While the comment identifies a potential area of contribution, it does not provide explicit guidance or suggestions on how the authors might enhance their paper to better highlight their novel contributions. The action is implicit and somewhat vague, as the authors are left to infer that they should emphasize the simplicity and effectiveness of their approach rather than novelty. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the design of the LUQ and the approaches in Section 5, providing a clear reference to specific parts of the paper. This allows the authors to accurately identify the sections being discussed, making the comment fully grounded. The comment also specifies the issue by noting that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper lies in demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel techniques. This provides clear guidance on what the authors need to address in their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper is demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel techniques. While the comment provides some logical reasoning by noting the standard nature of the approaches, it lacks specific references or examples to support the claim that the LUQ is straightforward or that the approaches are explored in previous literature. This makes the claim 3, as the authors would need to further investigate the references or examples to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges that the design of the LUQ is straightforward and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper lies in demonstrating the effectiveness of a simple combination of existing techniques rather than proposing novel techniques. This feedback provides a clear perspective on the paper\"s contribution and highlights an area where the authors might emphasize the practicality and simplicity of their approach. However, the comment could be more helpful if it offered specific suggestions on how to emphasize the simplicity and effectiveness of the approach or how to differentiate it from previous work. Overall, the comment is 3 as it identifies a potential area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While the comment explicitly states the need for training losses, it does not provide specific guidance on how to obtain or analyze these losses. The action is implicit, as the authors need to infer that they should include training losses in their analysis, but it is concrete because the direction is clear. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for training losses, but without grounding, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it might impact the results. Without such context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While it identifies a potential issue, it lacks specificity and does not provide guidance on how to address the concern or what aspects of the training process might be unstable. The request for training losses is a logical step to take, but without further elaboration, the comment remains 3. The authors are given a direction to investigate, but the feedback could be more comprehensive and actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It suggests that the proposed framework, FFAEVAL, and similar systems like Chatbot Arena may not be suitable for evaluating a single dialogue system, such as giving a fluency score. However, the comment does not provide explicit guidance on how the authors should address these concerns or what alternative approaches they might consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the relevance of their method to their motivations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations, specifically mentioning the use of automatic scores and human evaluation scores. It also questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as giving a fluency score. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the abstract section or the methodology, but this is not explicitly stated. The comment is specific in detailing the concerns about the relevance of the proposed method to the authors\" motivations and the limitations of the evaluation systems. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as giving a fluency score. The comment provides a logical reasoning by suggesting that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to provide more detailed evidence or examples to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the relevance of the proposed method to the authors\" motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as giving a fluency score. The comment provides a logical reasoning by suggesting that these arenabased evaluation systems may not solve the problems of current scorebased evaluation systems. However, the feedback lacks specific suggestions or guidance on how the authors might address these concerns or improve their methodology. While it identifies a potential issue, it does not offer actionable steps or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of sample size on training speed and potentially adjust their comparisons accordingly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the training of RegMixup, specifically mentioning that it sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with sample size and its impact on training speed and comparison fairness. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. The comment provides a logical reasoning for the claim, explaining that the increased sample size could affect the training speed. However, it lacks specific examples or references to support the assertion about unfair comparison, making the claim 3. The authors would need to further investigate the impact of sample size on training speed and comparison fairness to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to slower running speed and an unfair comparison with other methods. This feedback is 3 as it points out a specific area where the authors might need to address the impact of sample size on training efficiency and fairness of comparison. However, the comment lacks detailed guidance on how the authors should address this issue or suggestions for potential solutions. While it highlights an important consideration, the feedback could be more actionable with additional insights or recommendations. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the statistical significance of the improvements in the proposed model compared to the RL without feedback model. It suggests that the authors should verify the statistical significance of these improvements. While the comment implies that the authors should conduct a statistical analysis to confirm the significance, it does not provide explicit instructions on how to perform this verification or which statistical tests to use. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"row3 vs. row4 in table 6,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the improvements of the proposed model over the RL without feedback model, particularly noting that the improvements are not statistically significant. The comment provides a clear direction for the authors to verify the statistical significance of the improvements, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvements of the proposed model over the RL without feedback model are not statistically significant, based on a comparison in row 3 vs. row 4 of Table 6. The reviewer suggests that the authors verify the statistical significance of these improvements. However, the comment lacks specific details or examples to support the claim, such as the statistical tests used or the criteria for determining significance. Without this information, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient evidence or guidance to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the statistical significance of the improvements in the proposed model compared to the RL without feedback model. It highlights that the improvements are not statistically significant, particularly for BLEU1, and suggests that the authors should verify this. This feedback is clear and actionable, as it provides a specific area for the authors to investigate and potentially address in their paper. By suggesting a verification of statistical significance, the comment offers a concrete step for the authors to take to strengthen their claims and improve the robustness of their results. However, the comment could be more helpful if it provided guidance on how to conduct the verification or which statistical tests to use. Overall, the comment is 4, as it directs the authors to a critical area for improvement and provides a clear direction for addressing the issue."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This question provides a clear and direct action for the authors to take, which is to explore the assumptions and potential outcomes of partial coverage. The comment is explicit and concrete, guiding the authors on how to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly references a previous remark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action needed, which is to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration and what would happen if they partially cover them. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification or further exploration of a specific aspect of the paper, rather than a claim or suggestion that requires verification. It does not contain any subjective opinions, judgments, or requests for changes that would necessitate verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a continuation of a previous remark, asking the authors to consider what assumptions are needed to relax the requirement of visiting all ballaction pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This feedback provides a clear and actionable direction for the authors to explore, offering insights into potential improvements or alternative approaches. By prompting the authors to consider specific assumptions and their implications, the comment is 4, as it guides the authors toward a more detailed analysis of their work. However, it could be more helpful if it included specific suggestions or examples of how to relax the requirement or what assumptions might be necessary. Therefore, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to explore this possibility. As a result, the authors are left without a clear understanding of what actions to take in response to this comment. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper would benefit from this consideration or how it could be addressed. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTabase, instead of BERT. While it identifies a potential area for further exploration, it does not provide any specific guidance or suggestions on how the authors might investigate this question or what improvements might be expected. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path forward. Therefore, the comment is rated as 2, as it provides a starting point for consideration but does not offer substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks, such as XNLI and XTREME, to demonstrate the generalizability of the proposed technique across tasks with varying reasoning requirements. While the comment implies that additional datasets should be included, it does not provide specific guidance on which datasets to use or how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. The authors may infer that it relates to the experimental results or the conclusion, but this inference is not explicit. The comment is specific in its suggestion to include more datasets, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique. However, the comment does not provide any specific reasoning or evidence to support why these datasets are particularly relevant or why including them would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This feedback is 3 as it provides a specific direction for enhancing the paper by expanding the experimental evaluation. However, it lacks detailed guidance on which datasets to include or how to incorporate them into the analysis, which could limit its effectiveness. The comment highlights an important aspect for the authors to consider, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It explicitly recommends comparing the current methods to RefNeRF, which contains appearance decomposition, and mentions MipNerf as another potential baseline for larger outdoor scenes. This feedback provides clear and concrete actions for the authors to take, specifying which baselines to consider and why. The authors know exactly what needs to be done to improve their draft, making this comment 5.", "grounding_specificity_rationale": "The comment suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It recommends comparing the current methods to RefNeRF, which contains appearance decomposition, and mentions MipNerf as another potential baseline for larger outdoor scenes. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the evaluation and comparison of methods. The authors can infer that it relates to the experimental section, but the comment does not specify the exact part of the paper being addressed. However, the suggestion to compare with specific methods provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods can be improved, particularly for evaluating the appearance decomposition part. It recommends comparing the current methods to RefNeRF, which contains appearance decomposition, and mentions MipNerf as another potential baseline for larger outdoor scenes. This feedback is 3 as it provides specific examples of baselines that could be used for comparison, which helps the authors understand the rationale behind the suggestion. However, the comment could be strengthened by providing more detailed reasoning or evidence on why these specific baselines are recommended. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides actionable feedback by suggesting improvements to the choice of baseline methods, particularly for evaluating the appearance decomposition part. It recommends comparing the current methods to RefNeRF, which contains appearance decomposition, and mentions MipNerf as another potential baseline for larger outdoor scenes. This feedback is clear and specific, offering the authors a concrete direction for enhancing the evaluation and comparison of their work. By addressing this suggestion, the authors can significantly improve the robustness and relevance of their experimental results. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide more implementation details of the proposed methods, which are currently lacking. It specifies that these details should be included in Section 4.1. This direct and concrete guidance gives the authors a clear understanding of what needs to be done to address the concern, making the comment 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of implementation details of the proposed methods, which is a clear and specific issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the lack of implementation details in the paper is a significant issue, particularly in Section 4.1. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this lack of details is problematic or how it affects the paper\"s comprehensibility or reproducibility. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is crucial for understanding and replicating the work. It provides a clear and actionable suggestion by specifying that these details should be included in Section 4.1. This feedback is valuable as it guides the authors on how to enhance the clarity and reproducibility of their work. However, the comment could be more helpful if it offered additional guidance or examples of what specific implementation details should be included. Overall, the comment is 4, as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a significant issue with the paper, noting that there is no empirical evaluation and no comparison with other methods. It emphasizes the lack of practical value and suggests that the paper is not suitable for publication at NeurIPS without addressing these concerns. While the comment identifies a critical gap in the paper, it does not provide specific guidance on how to address these issues or what kind of empirical evaluation or comparison would be necessary. The authors are left with a general understanding of what needs to be improved but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is 3, as it points out a significant problem but lacks detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses the lack of empirical evaluation and comparison with other methods, noting that the paper does not provide a practical value for its contributions. It also critiques the theoretical contributions, stating that the paper is not suitable for publication at NeurIPS without addressing these issues. However, the comment does not specify which part of the paper lacks empirical evaluation or comparison, making it weakly grounded. The feedback is specific in identifying the need for empirical evaluation and comparison, but without explicit references to sections or figures, the authors may struggle to pinpoint where these elements are missing. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. The reviewer suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. The claim is 3 as it points out a significant gap in the paper\"s evaluation and comparison, but it lacks specific examples or references to other works for comparison. The authors would need to infer the extent of the critique and the potential improvements, making the claim 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that there is no empirical evaluation or comparison with other methods, which makes it difficult to assess the practical value of the contribution. It suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. While the comment highlights a significant gap in the paper, it does not provide specific guidance on how to address this issue or what kind of empirical evaluation or comparison would be necessary. The feedback is 3 as it points out a critical weakness, but it lacks actionable suggestions or detailed advice on how to improve the paper, leaving the authors with a general understanding of what needs to be addressed but without concrete steps to take."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential source of confusion in the manuscript regarding the use of \"P\" as both a probability and a cumulative distribution function. It explicitly states that this inconsistency leads to confusion, but it does not provide specific guidance on how the authors should address this issue. The comment does not offer suggestions for redefining \"P\" or revising the equations to clarify their usage. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations (Eqs. (3) and (4)) and a line in the text (L44) in the Appendix, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the confusion caused by the inconsistent use of \"P\" as both a probability and a cumulative distribution function. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"P mostly represents a probability but sometimes for a cumulative distribution function,\" which leads to confusion. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion. Without detailed examples or references, the claim remains vague and lacks sufficient evidence to be 5. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript regarding the inconsistent use of \"P\" as both a probability and a cumulative distribution function, leading to confusion. This feedback is clear and actionable, as it points out a potential source of confusion that the authors should address. By highlighting this inconsistency, the comment provides a concrete direction for the authors to improve the clarity and consistency of their manuscript. However, the comment could be more helpful if it suggested specific ways to resolve the confusion, such as recommending the use of different symbols or providing clearer explanations. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including additional baselines, such as those mentioned in the related work section, would enhance the paper. It also acknowledges that the authors\" response addressed the weaknesses and clarifies the choice of baseline. However, the comment does not provide explicit instructions on how to include these additional baselines or what specific aspects of the paper need further clarification. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding these baselines and addressing any remaining unclear parts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the weaknesses. It also mentions that the authors explained why the chosen baseline makes sense. However, the comment does not specify which part of the paper this suggestion pertains to, such as the related work section or the experimental setup. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of additional baselines and asking for clarification on testing, but it lacks grounding. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\" response addressed the weaknesses. However, it does not provide specific reasoning or evidence to support the claim that including these baselines would enhance the paper. The comment lacks detailed justification or examples of how these additional baselines would improve the study, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to fully support the assertion.", "helpfulness_rationale": "The review comment suggests including additional baselines in the paper, such as those mentioned in the related work section, which could enhance the study\"s comprehensiveness. It acknowledges that the authors\" response addressed the weaknesses and clarifies the choice of baseline. However, the comment lacks specificity regarding which additional baselines should be included or how they would improve the paper. While it provides a direction for improvement, the feedback could be more helpful if it offered more detailed guidance or examples. Therefore, the comment is 3, as it identifies an area for enhancement but lacks depth and actionable suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the uniform weighting of modalities, suggesting that dynamically weighting them is important. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their approach. The comment implies that the authors should consider dynamic weighting, but it lacks concrete suggestions or examples of how to implement this change. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the uniform weighting of modalities and suggests that dynamically weighting them is important, as evidenced by works in multimodal fusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the uniform weighting of modalities is problematic and suggests that dynamically weighting them is important, referencing works in multimodal fusion. However, the comment lacks specific examples or references to these works, making it difficult for the authors to fully understand and address the issue. The claim is 3 as it points out a potential issue but requires more detailed support to be fully actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the uniform weighting of modalities in the paper, suggesting that dynamically weighting them is more important. It references works in multimodal fusion to support this claim, which provides a logical basis for the critique. However, the comment lacks specific guidance on how the authors might dynamically weight the modalities or what changes they should make to their approach. While it highlights an important area for improvement, the feedback could be more actionable with detailed suggestions or examples. Therefore, the comment is 3, as it points out a significant issue but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but L_class in the figure. This comment explicitly instructs the authors to ensure consistency in notation, which is a clear and direct action. However, it does not provide specific guidance on how to achieve this consistency, such as suggesting which notation to use or where to make the change. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy in notation between the text and the figure, where the task loss is referred to as L_task in the text but L_class in figure 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but L_class in the figure. This is a factual observation that does not require any justification or evidence to be understood. It is a straightforward correction of a typographical error or inconsistency in notation, which is a common issue in technical writing. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a discrepancy in notation between the text and figure 1, where the task loss is referred to as L_task in the text but L_class in the figure. This is a clear and specific observation that highlights a potential source of confusion for readers. By pointing out this inconsistency, the comment provides the authors with a straightforward action to take: ensure consistency in notation throughout the paper. However, the comment does not offer additional guidance or suggestions on how to achieve this consistency, such as recommending a specific notation or explaining why consistency is important. While it provides a clear direction for improvement, the lack of detailed advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this limitation or what specific aspects they should consider. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity as it does not provide details on what specific limitations are being referred to or how they relate to the graph case. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about the limitations of the method, specifically in the context of the graph case where the network was shallow. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not provide any additional context, analysis, or suggestions on how the authors might address this limitation or improve their work. The comment lacks actionable feedback or guidance, leaving the authors without a clear direction for enhancing their draft. As a result, the comment is not helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the work would be more convincing if it were also evaluated in machine translation, as this would provide a more comprehensive assessment of the proposed method. However, the comment does not provide specific guidance on how to implement this evaluation or what aspects of machine translation should be considered. The action is implicit and somewhat vague, as the authors can infer the need for additional evaluation but lack detailed instructions on how to execute it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the proposed method, specifically mentioning the use of answer generation and summarization as conditional generation tasks. It suggests that the work would be more convincing if it were also evaluated in machine translation, which exhibits lower uncertainties per word. However, the comment does not specify which part of the paper discusses the evaluation or the proposed method, making it weakly grounded. The suggestion to evaluate in machine translation is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work\"s evaluation is limited because it only uses answer generation and summarization, which are more akin to opendomain generation rather than closedomain tasks like machine translation. The reviewer suggests that evaluating the method in machine translation would be more convincing due to the lower uncertainties per word in this domain. While the comment provides a logical argument, it lacks specific examples or references to support the claim that machine translation is a more appropriate evaluation domain. This makes the claim 3, as the authors would need to explore the suggestion themselves to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization, which are more akin to opendomain generation rather than closedomain tasks like machine translation. The reviewer suggests that evaluating the method in machine translation would be more convincing due to the lower uncertainties per word in this domain. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation of the method. However, the comment could be more helpful if it offered additional guidance on how to conduct the machine translation evaluation or what aspects of machine translation would be most relevant. Overall, the comment is 4 as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the dropping rate and the number of masks generated for the dropout technique. While it does not explicitly instruct the authors to provide this information, the question is clear and specific, allowing the authors to understand what additional details are needed. The action is implicit but concrete, as the authors know exactly what information is required to address the comment. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout\" and references the response letter, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what information is needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification on the dropping rate and the number of masks generated for the dropout technique. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the dropout technique, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it prompts the authors to provide additional details that could enhance the clarity and completeness of their explanation. By addressing this question, the authors can improve the transparency and understanding of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or what specific aspects of the dropout technique might be affected by the lack of this information. Overall, the comment is 4, as it directs the authors to a specific area that needs clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the effectiveness of the proposed twostage optimization approach needs further justifications. It provides a clear action by suggesting that the authors should compare their approach with other singlestage attacks and provide proper benchmarks. This feedback is explicit and concrete, guiding the authors on what specific comparisons and benchmarks are needed to strengthen their claims. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the effectiveness of the proposed twostage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for further justifications and comparisons with other singlestage attacks. The comment provides a clear direction for improvement, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justifications, as only showing the performance drop on fusion models is not sufficient. The reviewer suggests comparing the approach with other singlestage attacks and providing proper benchmarks and comparisons with other SOTA algorithms. This claim is 4 as it provides a logical reasoning for the need for additional comparisons and benchmarks. However, it lacks specific examples or references to support the comparison with other singlestage attacks, which could strengthen the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical area for improvement in the paper, specifically the need for further justifications of the effectiveness of the proposed twostage optimization approach. It points out that merely showing the performance drop on fusion models is not sufficient and suggests comparing the approach with other singlestage attacks and providing proper benchmarks. This feedback is clear and actionable, guiding the authors on how to strengthen their claims and improve the paper\"s rigor. However, the comment could be more helpful if it provided specific examples or references of other singlestage attacks for comparison. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper does not provide information on the type of GPUs used and the inference time during testing. This feedback is clear and direct, instructing the authors to include this information in their draft. The action is explicit and concrete, as it specifies exactly what needs to be added to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the lack of information regarding the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying the missing details, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper does not provide information on the type of GPUs used and the inference time during testing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of information on the type of GPUs used and the inference time during testing. This feedback is clear and actionable, as it directly points out a gap in the paper that needs to be addressed. By highlighting these missing details, the authors can improve the completeness and transparency of their work. However, the comment could be more helpful if it provided suggestions on how to include this information or examples of how other papers have addressed similar issues. Overall, the comment is 4 as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point consists of two parts. The first part suggests that the authors should investigate the performance of RSD4PG with even smaller lambda values, which is an explicit action. However, it lacks specific guidance on how to conduct this investigation or what to look for in the results. The second part points out missing elements in the text, such as the symbols \"\u03c4\" and \"\u03b7\" in the equation on page 3, line 2, and the notation \"s\" in the equation on page 4, line 4. While these are specific issues, they do not provide detailed instructions on how to correct them. Therefore, the comment is 4, as it provides explicit actions but lacks concrete guidance on execution.", "grounding_specificity_rationale": "The comment addresses two separate issues. The first part is weakly grounded as it mentions \"table 1\" but does not specify which part of the table is being referred to. The second part is fully grounded as it explicitly mentions \"page 3, line 2\" and \"page 4, line 4,\" allowing the authors to accurately identify the sections needing attention. However, the comment lacks specificity in the first part, as it does not explain what is meant by \"overall performance of RSD4PG monotonically increases w.r.t. \u03bb values\" or why the authors should investigate smaller lambda values. In the second part, the comment is specific about the missing symbols and notation. Therefore, the comment is 3 overall, aligning with a score of 3.", "verifiability_rationale": "The review point consists of two parts. The first part suggests investigating the performance of RSD4PG with even smaller lambda values, which is a request for further exploration rather than a claim. The second part points out missing symbols and notation in the text, which is a factual observation. Therefore, the comment is 4, as it provides specific observations but lacks detailed reasoning or references to support the suggestion for further investigation. The overall score aligns with a 3.", "helpfulness_rationale": "The review comment addresses two separate issues. The first part suggests investigating the performance of RSD4PG with even smaller lambda values, which is a valuable suggestion for further exploration. However, it lacks specific guidance on how to conduct this investigation or what to look for in the results, making it 3. The second part points out missing symbols and notation in the text, which is a clear and actionable suggestion for improvement. Overall, the comment provides some helpful feedback but could be more comprehensive with detailed guidance on the investigation and correction of the missing elements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a confusing sentence in the paper and suggests that it is not immediately clear what is meant. The reviewer provides context by mentioning that they understood it after rereading it and subsequent sentences, but this does not offer explicit guidance on how the authors should address the confusion. The comment implies that the authors should clarify the sentence, but it lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific sentence, \"9395,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the sentence is confusing and suggesting that it is not immediately clear what is meant. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the sentence is confusing, but it does not provide specific examples or detailed reasoning to support this claim. The reviewer mentions that they understood it after rereading it and subsequent sentences, but this does not substantiate the claim. Without additional context or evidence, the comment lacks verifiability, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a confusing sentence in the paper, specifically mentioning line numbers 9395. It notes that the sentence is not immediately clear and suggests that it was understood after rereading it and subsequent sentences. While the comment highlights a potential issue, it lacks specific guidance or suggestions on how the authors might clarify the sentence or address the confusion. This limits the usefulness of the feedback, as the authors are left without actionable steps to improve the draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide detailed guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit actions for the authors to take, such as adding citations for claims about diffusion models outperforming GANs, providing citations for previous work, and seeking evidence for the reliability and efficiency of diffusion models. Each action is clearly stated, and the authors know exactly what needs to be done to improve their draft. The comment also suggests using different samplers for more efficient sampling, which is another concrete action. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific references to lines 7879, 129130, 156158, and 217218, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed in each case, such as the need for citations, evidence, or additional references. This level of detail ensures that the authors can effectively respond to the feedback. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of claims that require citations or evidence to support them. For example, the comment suggests that diffusion models have outperformed GANs on image generation benchmarks, but it lacks a specific citation or reference to substantiate this claim. Similarly, the comment requests citations for previous work and evidence for the reliability and efficiency of diffusion models. The lack of detailed support or references makes it difficult for the authors to address these points effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies several areas where the authors need to provide additional context, evidence, or citations to support their claims. It specifically points out the need for citations in lines 7879 regarding the performance of diffusion models compared to GANs, in lines 129130 regarding previous work, in lines 156158 regarding the efficiency of diffusion models, and in lines 217218 regarding sampling efficiency. Each point is clear and actionable, providing the authors with specific guidance on how to improve their draft. However, the comment could be more helpful if it offered suggestions on where to find appropriate citations or evidence. Overall, the feedback is 4 as it directs the authors to address critical gaps in their paper, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy between Fig 1 and Fig 2, specifically noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This observation highlights a potential inconsistency in the figures. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes are necessary. The action is implicit and somewhat vague, as the authors need to infer that they should ensure consistency between the figures. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the inconsistency between the figures, noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Fig 1 is inconsistent with Fig 2, specifically noting that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This is a factual observation that does not require verification, as it is a direct comparison between two figures. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency between two figures, Fig 1 and Fig 2, regarding the representation of encoderdecoder structures for auxiliary tasks. It points out that Fig 2 shows one encoderdecoder per auxiliary task, while Fig 1 shows a single shared encoderdecoder for multiple tasks. This feedback is clear and actionable, as it highlights a discrepancy that needs to be addressed to ensure consistency in the figures. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or if it pointed out the potential impact of this inconsistency on the interpretation of the results. Despite this, the comment is 4 as it directs the authors to a specific area that requires attention for improving the clarity and accuracy of their figures. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about whether each node can attend to its own lowerlevel representation, based on the description of equation 2. It suggests that only neighboring nodes are attended to, which implies that the authors should clarify this aspect. While the comment does not explicitly instruct the authors to make this clarification, it is clear that addressing this issue would help improve the clarity of the paper. The action is implicit but concrete, as the authors know exactly what needs to be clarified. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether each node can attend to its own lowerlevel representation, based on the description of equation 2. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the functionality of nodes in the context of equation 2, specifically whether each node can attend to its own lowerlevel representation. The comment is based on the description of equation 2, which suggests that only neighboring nodes are attended to. However, it does not provide specific evidence or references to support this claim, making it 3. The authors would need to clarify or provide additional information to fully address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the functionality of nodes in the context of equation 2, questioning whether each node can attend to its own lowerlevel representation. This is a relevant and constructive inquiry that prompts the authors to clarify a potential misunderstanding or oversight in their work. By addressing this question, the authors can enhance the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue. Overall, the feedback is 4 as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify how the inequality after line 433 follows from Lemma 7. It provides a specific request for the authors to explain the connection between the lemma and the inequality, which is a direct and concrete action. This feedback gives the authors a clear direction on what needs to be addressed to improve the clarity of their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of how the inequality follows from Lemma 7. This provides clear guidance on what the authors need to do to improve the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the derivation of an inequality from Lemma 7, suggesting that it may follow from a combination of previous inequalities. The comment requests clarification on how Lemma 7 is applied in this context. While the comment identifies a potential issue with the logical flow, it lacks specific examples or references to support the claim. The authors are left to infer the exact nature of the problem, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the derivation of an inequality from Lemma 7. It points out that the inequality seems to follow from a combination of previous inequalities but does not explicitly explain how Lemma 7 is involved. This feedback is clear and actionable, as it directs the authors to clarify the connection between Lemma 7 and the inequality, which is crucial for improving the clarity and understanding of the paper. However, the comment could be more helpful if it provided additional guidance or examples on how to address this issue. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the lack of clarity regarding the main contribution of the paper and the proposed method\"s ability to cope with dynamic largescale multitasking. It also questions the applicability of the method and the process of automation. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, specifically mentioning the proposed method\"s novel properties and the main idea of how it copes with dynamic largescale multitasking. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the main contribution and the proposed method\"s applicability and automation process. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the proposed method\"s ability and applicability are overstated or not wellsupported. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references to other works or detailed explanations of what aspects are unclear or overstated. As a result, the claim is difficult for the authors to verify and address, making it barely verifiable.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s main contribution, noting that the proposed method\"s novel properties are either overstated or not wellsupported. It also points out that the main idea of how the proposed method copes with dynamic largescale multitasking is unclear, and the process of automation is not wellexplained. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas of concern but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to compare their method to token pruning and token combination baselines, in addition to the existing BERTbaseline. This provides a clear and direct action for the authors to take, specifying what additional comparisons are needed to strengthen the experiment section. The feedback is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiment comparison,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: comparing the method to token pruning and token combination baselines, in addition to the existing BERTbaseline. This provides clear guidance on how to enhance the experiment section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. The reviewer suggests that the authors should also compare their method to token pruning and token combination baselines. This claim is 3 as it provides a logical reasoning for the need to expand the comparison, but it lacks specific examples or references to support the suggestion. The authors would need to conduct additional research or experimentation to substantiate the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental section of the paper, noting that the comparison is weak because it only compares the proposed method to the BERTbaseline. It provides a clear and actionable suggestion by recommending that the authors should also compare their method to token pruning and token combination baselines. This feedback is valuable as it guides the authors on how to strengthen their experimental evaluation, making the comment 4. However, it could be more helpful if it included specific guidance on how to conduct these additional comparisons or what aspects to focus on when comparing the methods. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, which are not currently included in the comparison. This feedback is explicit and provides a clear action for the authors to take, as it specifies which type of methods should be added to the comparison. The suggestion is concrete, as it outlines the exact methods that need to be included, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of a comparison to coordinateaware methods like TFN or SchNet. This provides clear guidance on how to improve the experimental section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods, such as TFN or SchNet, which are not currently included. This claim is based on the observation that the current comparison only includes methods that are unaware of point coordinates, which may not provide a comprehensive evaluation. The reviewer does not provide specific examples or references to support the need for these comparisons, making the claim 3. The authors would need to infer the relevance of these methods and their potential impact on the evaluation, which adds a layer of uncertainty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental section of the paper, specifically noting that the comparison only includes methods that are unaware of point coordinates in their convolution. It suggests that a more comprehensive comparison would include coordinateaware methods like TFN or SchNet. This feedback is clear and actionable, as it provides a specific suggestion for expanding the experimental evaluation to include a broader range of methods. By addressing this feedback, the authors can enhance the robustness and relevance of their experimental results. Therefore, the comment is rated as 5, as it offers a clear direction for improving the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors did not address the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on what specific weaknesses should be addressed or how to address them. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of discussion on the weaknesses of the proposed model. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the absence of a discussion on weaknesses, but it lacks grounding as it does not provide a clear reference to the part of the paper where this discussion should be included. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by pointing out that they did not discuss the possible weaknesses of the proposed model. This feedback is clear and actionable, as it directs the authors to consider and address potential limitations or drawbacks of their model. However, the comment could be more helpful if it provided examples of what these weaknesses might be or suggested ways to address them. Overall, the comment is 4 as it highlights an important aspect for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extractthengenerate approaches. While the comment highlights a potential issue with the paper\"s lack of context and comparison, it does not provide explicit guidance on how the authors should address this. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a related work section and compare their system with other extractthengenerate methodologies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It also points out the absence of a related work section and suggests that the paper lacks a comparison with other extractthengenerate approaches. However, the comment does not specify which part of the paper should include a related work section or how the comparison should be made. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific enough to provide clear guidance on what needs to be improved. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extractthengenerate approaches. However, the comment does not provide specific examples or references to support the claim that the methodology is not novel or that the paper lacks a related work section. This makes the claim 3, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extractthengenerate methodologies. It questions the lack of a related work section and suggests that the paper does not compare its system with other extractthengenerate approaches. This feedback is 3 as it points out a potential weakness in the paper\"s presentation and encourages the authors to include a related work section and compare their system with existing methodologies. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of related work to include. Overall, the comment offers some guidance but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. While the comment implies that more work on GLN should be included, it does not explicitly instruct the authors to do so or provide specific guidance on how to incorporate this information. The action is implicit and somewhat vague, as the authors can infer the need for additional content but lack detailed instructions on execution. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction of related work is insufficient and recommends providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, it does not specify which part of the paper the introduction of related work is located in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in suggesting that more information on GLN should be included, but the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests providing more information on GLN to reflect the advantages or differences of the proposed method compared to BGLN. However, the comment lacks specific examples or references to support the claim that the introduction is insufficient or how GLN should be discussed. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper\"s introduction, noting that the discussion of related work is insufficient. It suggests that more information on GLN should be provided to reflect the advantages or differences of the proposed method compared to BGLN. This feedback is clear and actionable, as it directs the authors to enhance their discussion by including additional details on GLN. However, the comment could be more helpful if it provided specific examples or references of how GLN should be discussed or what aspects of the proposed method are unique. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy in the use of dropout rates in the paper. It explicitly points out the inconsistency in using only one dropout rate for Moon\"s approach compared to the use of inputoutput and recurrent dropout parameters in Variational dropout. However, the comment does not provide specific guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit, as the authors need to infer that they should clarify or justify the use of different dropout rates, but it lacks concrete details on how to implement this action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the use of dropout rates in the paper, specifically mentioning \"hyperparameters\" and \"Moon\"s approach.\" It also compares this with the use of inputoutput and recurrent dropout parameters in Variational dropout. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the discussion of dropout rates. The comment is specific because it highlights the inconsistency in the use of dropout rates and suggests a comparison with Variational dropout. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of a single dropout rate for Moon\"s approach compared to the use of inputoutput and recurrent dropout parameters in Variational dropout. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this difference is problematic or how it affects the paper\"s results or methodology. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the use of dropout rates in the paper, comparing Moon\"s approach with Variational dropout. It highlights the discrepancy in the number of dropout rates used, suggesting that only one dropout rate is used for Moon\"s approach, while Variational dropout employs inputoutput and recurrent dropout parameters. This feedback is clear and actionable, as it points out a potential area for clarification or justification in the paper. However, the comment could be more helpful if it provided suggestions on how to address this issue or why it might be important to consider different dropout rates. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It suggests that the absence of these experiments makes it difficult to assess whether the method has scalability issues or if it was due to a lack of time. The reviewer proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This suggestion provides a clear and concrete action for the authors to take, as it specifies the type of experiments that would be beneficial and offers a potential solution. The feedback is explicit and provides detailed guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. It suggests that the absence of these experiments makes it difficult to assess whether the method has scalability issues or if it was due to a lack of time. The reviewer proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This provides a clear and specific suggestion for the authors to conduct additional experiments. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as specific sections or experiments. While the authors can infer that it relates to the experimental section, the comment lacks full grounding. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. The reviewer suggests that this absence makes it difficult to judge whether the method has scalability issues or if it was due to a lack of time. The comment proposes that convincing experiments could be conducted on simple videogame domains, which have a lowcardinality discrete state and actionspace, and are publicly available. This provides a clear suggestion for additional experiments that could be conducted to address the scalability concern. However, the comment lacks specific examples or references to support the claim about the scalability of the method, making it 3. The authors would need to conduct further research or experimentation to fully address the concern, which is why the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s experimental setup by noting the absence of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls and other nontrivial tiles. This is a relevant observation as it questions the scalability of the method and whether the lack of experiments is due to a lack of time or inherent limitations. The reviewer suggests that conducting experiments on simple videogame domains, which have a lowcardinality discrete state and actionspace, would provide convincing evidence of the method\"s scalability. This feedback is clear and actionable, offering a specific direction for the authors to improve their draft by expanding their experimental setup. However, the comment could be more helpful if it provided additional guidance on how to design and execute these experiments. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear path for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting specific metrics or methods to quantify the extent of occupation bias. Without concrete instructions or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement for the extent of occupation bias relative to real distributions in society. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks quantitative measurement for the extent of occupation bias relative to real distributions in society. This is a valuable observation that highlights a potential weakness in the paper\"s methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the potential impact of the method on their findings. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its inquiry about the potential impact of the method on findings, but without clear grounding, it is weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that such a method might affect the findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). While the comment identifies a potential area for exploration, it lacks specific guidance or suggestions on how the authors might address this concern or what implications it might have for their results. The feedback is 3 as it prompts the authors to consider the impact of their choice of optimization method, but it does not provide actionable steps or detailed insights to enhance the draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the inclusion of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what changes might be necessary. The comment lacks specificity and does not offer concrete steps for improvement, leaving the authors without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the inclusion of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in questioning the effectiveness of the method but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the method is simple but unclear why it is effective. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed reasoning or specific examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of information from 2hop neighbors, noting that it is not included in the method. It also questions the effectiveness of the method, suggesting that it is simple but unclear why it is effective. However, the comment lacks actionable feedback or suggestions on how the authors might address this issue or improve the clarity of their method. While it points out a potential weakness, it does not provide the authors with a clear path forward for enhancing their draft. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the current approach of using ProtPainter for binder design is empirical and lacks optimization and validation. It implies that the authors should consider further optimization and validation of the conformation estimation process. However, the comment does not provide explicit guidance on how to achieve this optimization or validation, nor does it specify which aspects of the process need improvement. The action is implicit and somewhat vague, as the authors can infer the need for optimization and validation but lack concrete steps on how to implement these changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of binder design, specifically mentioning ProtPainter, which provides an empirical conformation estimation. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in suggesting that further optimization and validation are required, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that ProtPainter provides an empirical conformation estimation for binder design and implies that further optimization and validation are needed. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current approach is empirical or lacks optimization. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some support but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the binder design process, where the use of ProtPainter is mentioned. It suggests that the current approach is empirical and lacks optimization and validation, implying that further work is needed to enhance the methodology. However, the comment does not provide specific guidance or suggestions on how to optimize or validate the process, nor does it offer examples or references to similar approaches. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to clarify how the model in Figure 7 was trained, specifically regarding the training on full field flicker stimulus changing contrast with a fixed cycle. It also raises a question about how the duration of the cycle changes and its impact on the time scale of adaptation, referencing a specific study (Smirnakis et al. Nature 1997). This feedback provides clear and direct actions for the authors to take, such as explaining the training process and addressing the potential impact of cycle duration changes on adaptation. The comment is explicit and concrete, offering specific guidance on what needs to be clarified or addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the model was trained and questioning the impact of cycle duration changes on adaptation, referencing a specific study. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a series of questions seeking clarification and an observation about the model\"s training and adaptation. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and seek clarification, making the comment a normal statement. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for clarification regarding the training of the model depicted in Figure 7. It raises a question about the training process, specifically asking whether it was conducted on a full field flicker stimulus changing contrast with a fixed cycle. Additionally, it inquires about the impact of changes in cycle duration on the time scale of adaptation, referencing a specific study (Smirnakis et al. Nature 1997) for context. This feedback provides clear and actionable guidance for the authors to address, helping them improve the clarity and completeness of their draft. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the comparison in Table 2, suggesting that comparisons should be made between using the same amount of data. It provides specific examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. While the comment identifies a potential issue, it does not explicitly instruct the authors to make these comparisons or provide guidance on how to address the problem. The action is implicit and somewhat vague, as the authors need to infer that they should make these comparisons to ensure a fair comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison in the table, noting that comparisons should be made between using the same amount of data. The comment provides examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This level of detail helps the authors understand what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the comparison in Table 2, suggesting that comparisons should be made between using the same amount of data. It provides specific examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This feedback is 3 as it identifies a potential issue with the data comparison in the table, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to investigate further to understand the implications of these comparisons and how they might affect the results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the comparison in Table 2, suggesting that comparisons should be made between using the same amount of data. It provides examples of comparisons that are not being made, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. This feedback is clear and actionable, as it directs the authors to ensure that their comparisons are consistent and fair. By addressing this issue, the authors can improve the validity and reliability of their results. However, the comment could be more helpful if it suggested specific ways to make these comparisons or provided examples of how to adjust the data to ensure consistency. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "4", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises two issues: the counterintuitive placement of the addition at the end of the paper and the lack of reference to Laplacian eigenmaps in the text. The first comment suggests that the authors should clarify the iterative process, particularly for larger iterations T, which is a concrete suggestion for improvement. However, the second comment about the lack of reference to Laplacian eigenmaps is not explicitly actionable, as it does not provide guidance on how to address this issue. The authors may infer that they need to include a reference to Laplacian eigenmaps, but the comment lacks specific instructions on where or how to incorporate this reference. Therefore, the comment is 4, as it provides a clear action for the first issue but lacks specificity for the second issue.", "grounding_specificity_rationale": "The comment addresses two separate issues: the placement of the addition at the end of the paper and the lack of reference to Laplacian eigenmaps. The first part of the comment is fully grounded as it explicitly mentions \"Line 224,\" allowing the authors to accurately identify the section being addressed. However, the second part of the comment is 1, as it does not specify which part of the paper lacks a reference to Laplacian eigenmaps. The authors may infer that it is related to the discussion or methodology, but this inference is not explicit. Therefore, the comment is fully grounded and somewhat specific, aligning with category 4.", "verifiability_rationale": "The review point raises two issues: the counterintuitive placement of an addition at the end of the paper and the lack of reference to Laplacian eigenmaps. The first claim about the counterintuitive placement is 3 as it suggests that the iterative process should be explained more clearly, particularly for larger iterations T. However, the comment lacks specific examples or references to support this claim, making it 3. The second claim about the lack of reference to Laplacian eigenmaps is not supported by any evidence or reasoning, making it 1. Therefore, the overall verifiability of the comment is 2.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper. First, it points out that the addition of a particular section is counterintuitive and suggests that the authors clarify the iterative process, particularly for larger iterations T. This feedback is actionable and provides a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to clarify the iterative process or provided examples of how to address this issue. Additionally, the comment notes the lack of reference to Laplacian eigenmaps, which is a significant omission. While this is an important point, it lacks specific guidance on how to incorporate this reference or why it is relevant. Overall, the comment is 4 as it identifies key areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 2.1 is unnecessary because it discusses Batch Normalization and Conditional Batch Normalization (CBN), which are general techniques. The reviewer also recommends that the description of the proposed methodology should be independent of the choice of model and suggests that the time spent on describing the ResNet architecture could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment implies that the authors should reconsider the inclusion of Section 2.1 and how they present their methodology, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should restructure their presentation to better motivate the CBN approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the inclusion of Section 2.1, suggesting that the description of the proposed methodology seems independent of the choice of model and that the time spent on ResNet could be better used to provide greater motivation and intuition for the proposed CBN approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2.1 is unnecessary because Batch Normalization and Conditional Batch Normalization are general techniques, and the description of the proposed methodology seems independent of the choice of model. The reviewer suggests that the time spent on ResNet could be better used to provide greater motivation and intuition for the proposed CBN approach. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion that the description of the proposed methodology is independent of the choice of model. This makes the claim 3, as it provides a basis for the critique but could be strengthened with more detailed evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential redundancy in Section 2.1, suggesting that the inclusion of Batch Normalization and Conditional Batch Normalization is general and does not seem to be directly related to the proposed methodology. The reviewer recommends that the description of the proposed methodology should be independent of the choice of model and suggests that the time spent on describing ResNet could be better used to provide greater motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. This feedback is clear and actionable, as it provides specific suggestions for improving the paper\"s structure and content. However, it could be more helpful if it offered additional guidance on how to enhance the motivation and intuition for the CBN approach. Overall, the comment is 4 as it directs the authors to improve the clarity and focus of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix in equation (1) and how it relates to the expectation of sparsity. While the comment highlights a potential inconsistency, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify or revise their assumptions regarding sparsity and conditioning. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the assumption of multiplying by a dense projection matrix and its implications for sparsity, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the assumption of multiplying by a dense projection matrix and its implications for sparsity. While it does not contain an explicit claim, it poses a logical question that requires the authors to clarify their assumptions. The comment does not provide any supporting evidence or references to substantiate the claim, making it difficult for the authors to address the issue without additional context. Therefore, the comment is considered 2, as it lacks sufficient justification or evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a question about the assumption of multiplying by a dense projection matrix and its implications for sparsity. It points out a potential inconsistency in the expectation of sparsity given the multiplication by a dense matrix. While the comment identifies a specific area of confusion, it does not provide detailed guidance or suggestions on how the authors might address this issue or clarify their assumptions. The feedback is 3 as it prompts the authors to consider and potentially revise their assumptions, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It also provides a reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should revisit and possibly revise their statement about initialization, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should make a more careful statement and consider the reference provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"initialization\" and references a specific work by Kunstner, Hennig, and Balles (2019), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement about initialization should be more carefully stated, referencing a specific work by Kunstner, Hennig, and Balles (2019) as a source of evidence. This provides a clear and specific reference to support the claim, making it 5. The authors can easily understand the basis of the claim and the need for a more careful statement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It provides a specific reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. This feedback is valuable as it directs the authors to a source of information that can help them better understand and address the issue. However, the comment could be more helpful if it provided additional context or guidance on how to incorporate this reference into the paper or improve the statement about initialization. Overall, the comment is 4 as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point consists of two parts. The first part, \"L200: \"for every arm a\" implies there is a single optimistic parameter, but of course it depends on a,\" suggests that the authors should clarify the relationship between the optimistic parameter and the arms. This is an explicit action, but it lacks concrete guidance on how to address this issue, such as providing examples or specific changes to make. The second part, \"L303: Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" offers a suggestion for improving the condition, but it does not provide detailed instructions on how to implement this change. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L200\" and \"L303,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as clarifying the relationship between the optimistic parameter and the arms, and suggesting a change to the condition. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts. The first part suggests a clarification regarding the relationship between the optimistic parameter and the arms, which is a logical observation that requires no further justification. The second part offers a suggestion for improving the condition, which is a specific and reasonable suggestion. However, it does not provide detailed reasoning or evidence to support why this change would be beneficial, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. The first part suggests clarifying the relationship between the optimistic parameter and the arms, which is a logical observation that could enhance the clarity of the text. The second part offers a suggestion for improving the condition, which is a constructive and actionable suggestion that could enhance the draft. However, the comment could be more helpful if it provided more context or examples to support the suggestions. Overall, the feedback is 4 as it identifies areas for improvement and offers clear guidance, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experimental section is weak and requires more experiments. However, it does not provide specific guidance on what additional experiments are needed or how they should be conducted. The action is implicit, as the authors can infer that more experiments are necessary, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it identifies a need for improvement but does not offer explicit guidance on how to achieve it.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and requires more experiments. However, it does not specify which part of the experimental section is weak or what specific experiments are needed. This lack of detail makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 because it does not reference specific sections, tables, or figures, and it is not specific about what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental section is weak and requires more experiments. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental section of the paper, noting that it is weak and suggesting the need for more experiments. However, the comment lacks detail on what specific aspects of the experimental section are weak or how additional experiments could address these weaknesses. Without further guidance or examples, the authors may find it challenging to understand the nature of the problem and how to improve their experimental design. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and specificity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point consists of a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and concrete, providing the authors with clear instructions on how to improve the draft. The reviewer identifies specific lines where corrections are needed, such as \"line 2,\" \"line 56,\" \"line 158,\" and \"line 265,\" and suggests the necessary changes. This level of detail and specificity ensures that the authors know exactly what needs to be done to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific corrections for grammatical errors and punctuation in the manuscript, such as \"Despite of being compact\u00e2\u0080\u009d > \u00e2\u0080\u009cDespite being compact\u00e2\u0080\u009d,\" \"We refer multiway arrays\u00e2\u0080\u009d > \u00e2\u0080\u009cWe refer to multiway arrays\u00e2\u0080\u009d,\" \"HPFN to a even deeper ConAC\u00e2\u0080\u009d > \u00e2\u0080\u009cHPFN to an even deeper ConAC\u00e2\u0080\u009d,\" and \"Effect of the modelling mixed temporalmodality features.\" > I\"m not sure what this means, it\"s not grammatically correct.\" These corrections are clearly identified and specify what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point consists of corrections for grammatical errors and punctuation, which are factual statements without any claims or opinions. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides a series of corrections for grammatical errors and punctuation in the manuscript. Each correction is explicit and actionable, helping the authors to improve the clarity and professionalism of their draft. The comment identifies specific lines where corrections are needed, such as \"line 2,\" \"line 56,\" \"line 158,\" and \"line 265,\" and suggests the necessary changes. This level of detail and specificity is beneficial for the authors, as it allows them to make direct improvements to their manuscript. However, the comment could be more helpful if it provided additional context or suggestions for how to address the grammatical issues or improve the overall clarity of the text. Despite this, the feedback is 4 as it provides clear guidance for enhancing the manuscript\"s quality."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the comparison and understand how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs to be addressed. The comment is specific in its suggestion to compare sequential and combinational designs, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, the comment does not provide any evidence, reasoning, or examples to support this claim. Without specific data, analysis, or references to similar studies, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a comparison between sequential design and combinational design, implying that the proposed method may perform better in pure combinational logic without registers. This is a valuable suggestion as it provides a direction for further exploration and evaluation of the method\"s performance. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. While it offers a potential area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is 3, as it identifies an interesting direction for the authors to consider but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. While it prompts the authors to provide this information, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to include the performance of the baseline in their draft. However, the comment lacks concrete guidance on how to present this information or what specific details should be included. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the performance of the baseline, LDA+LSTM, in terms of the topic switch percent metric. This provides clear guidance on what additional information the authors should include in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification or additional information, as it seeks to understand the performance of a specific baseline in terms of a particular metric. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the performance of a baseline, LDA+LSTM, in terms of the topic switch percent metric. This feedback is 3 as it prompts the authors to provide additional information that could enhance the comprehensiveness of their experimental results. However, the comment lacks depth and does not offer suggestions on how to present this information or what specific aspects of the performance should be highlighted. To be more helpful, the comment could include guidance on how to analyze and present the results or suggest additional metrics that could be relevant. Therefore, the comment is rated as 3, as it provides a clear direction for improvement but lacks comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This action is clear and concrete, as it specifies the exact change needed to improve the draft. The authors know exactly what action to take to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5 to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of GPT4\"s cost, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting a change to include GPT3.5 experiments, which would enhance the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including experiments with GPT3.5 to provide a more comprehensive evaluation of the proposed approach. The reviewer acknowledges the cost of GPT4 and proposes a more affordable alternative. However, the comment lacks specific reasoning or evidence to support why GPT3.5 would be a better choice or how it would enhance the evaluation. The suggestion is based on a general understanding of the cost of GPT4, but without detailed justification or examples, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it identifies a specific way to enhance the evaluation of the work. By suggesting a more accessible alternative, the comment offers a practical step for the authors to take to improve the robustness and comprehensiveness of their experimental setup. However, the comment could be more helpful if it provided additional context or reasoning on why GPT3.5 would be a better choice or how it would impact the evaluation. Despite this, the suggestion is clear and actionable, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4. It specifies the exact example, \"WMT17WIKT,\" and highlights that the best result in terms of BLEU is actually in the baselines. This provides clear and concrete guidance on what needs to be done to improve the presentation of the results. The authors know exactly how to address the feedback by adding bold numbers to the relevant baseline results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: including bold numbers for the baselines of previous work, particularly for the example \"WMT17WIKT.\" This provides clear guidance on how to improve the presentation of results in the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the best result in terms of BLEU for WMT17WIKT is actually in the baselines, suggesting that the current presentation of results in Table 4 is incorrect. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion by pointing out a potential issue with the presentation of results in Table 4. It highlights that the best result in terms of BLEU for WMT17WIKT is actually in the baselines, suggesting that the current presentation of results is incorrect. This feedback is clear and actionable, as it directs the authors to include bold numbers for the baselines of previous work, providing a concrete way to improve the clarity and accuracy of the results presentation. However, the comment could be more helpful if it explained why this is important or how it affects the overall interpretation of the results. Despite this, the feedback is 4 as it offers a specific and actionable improvement to the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of support for the claim about the synergies between DQD and PPO, specifically noting that the main paper does not mention TD3GA, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the central claim that using onpolicy RL better fits the DQD framework. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include a discussion of TD3GA and its relevance to the comparison. The action is implicit and somewhat vague, as it does not offer concrete steps on how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about the synergies between DQD and PPO, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of mention of TD3GA and the importance of comparing it to TD3GA to support the central claim about using onpolicy RL better fitting the DQD framework. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backedup, particularly because the main paper does not mention TD3GA, which is crucial for understanding these synergies. The comment also suggests that the comparison to TD3GA should be central to the central claim that using onpolicy RL better fits the DQD framework. While the comment identifies a specific gap in the paper, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the importance of TD3GA and the relevance of the comparison, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s claim about the synergies between DQD and PPO, noting that the main paper does not mention TD3GA, which is crucial for understanding these synergies. It also suggests that the comparison to TD3GA should be central to the central claim that using onpolicy RL better fits the DQD framework. This feedback is clear and actionable, as it directs the authors to include a discussion of TD3GA and its relevance to the comparison. However, the comment could be more helpful if it provided additional guidance on how to integrate TD3GA into the analysis or suggested specific aspects of the comparison that should be emphasized. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the paper\"s empirical findings, including the lack of polishing of figures and empirical results, which impede clarity and confidence in the results. It specifies specific areas for improvement, such as missing axis labels, randomly masked out portions of curves, and single seed experiments. Additionally, it notes that the core findings in section one are conducted on two smallscale datasets and a single architecture type. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address these issues, such as suggesting specific changes or improvements to the figures or experiments. The action is implicit and somewhat vague, as the authors know what needs to be done but may not have a clear idea of how to implement the changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of polishing in figures and empirical results, which affects the clarity and confidence in the findings. It specifies issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. However, it does not explicitly mention which sections or figures are affected, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as improving the clarity of figures and empirical results. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks confidence in its empirical findings due to issues with the figures and empirical results. The reviewer provides specific examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. These examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several specific issues with the paper\"s empirical findings, including the lack of polishing in figures and empirical results, which impede clarity and confidence in the results. It provides detailed examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. This feedback is actionable and provides clear guidance for the authors to improve the clarity and robustness of their empirical results. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending specific improvements to the figures or experiments. Overall, the comment is 4 as it directs the authors to specific areas needing attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the novelty of their work or address the limitations mentioned. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. However, it does not specify which part of the paper this observation is based on, nor does it provide specific details about what aspects of the findings are considered limited or expected. This lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision or improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges the interesting findings but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. The reviewer provides a logical reasoning based on the common knowledge that taskspecific finetuning generally increases confidence for a specific task while potentially reducing generalizability. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the interesting findings of the work but suggests that the novelty is limited due to the expected observation of tighter confidence intervals (CIs) with finetuning. While it identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might enhance the novelty or address this limitation. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, the comment is rated as 2, consistent with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This action is explicit and provides a clear direction for the authors to enhance their analysis. The comment also mentions that even if the phenomenon significantly weakens in this setting, the numbers are worth seeing, which adds a minor suggestion. However, the comment does not specify how to report these numbers or what additional analysis should be conducted, which could be addressed with more detailed guidance. Overall, the comment is 4 due to its explicit nature and the clear direction it provides, but it lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the paper would be strengthened by reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes, at least on nontail classes. This provides a clear and specific suggestion for additional analysis, making the comment fully grounded. The authors can accurately identify the part of the paper being addressed, which is the label noise experiment, and the comment specifies what needs to be addressed in terms of reporting numbers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that reporting numbers from the label noise experiment on ImageNet with 1000 classes would strengthen the paper. However, the comment does not provide specific reasoning or evidence to support why this would be beneficial or how it would enhance the paper. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the rationale behind the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that reporting the numbers observed when the label noise experiment is performed on ImageNet with 1000 classes would strengthen the paper. This is a clear and actionable suggestion that provides a specific direction for the authors to enhance their analysis. By including these numbers, the authors could further stresstest their conjecture and provide additional insights into the phenomenon. The comment also acknowledges that even if the phenomenon significantly weakens in this setting, the numbers are worth seeing, which adds a minor suggestion. Overall, the comment is 4 as it offers a clear and constructive suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what additional feedback might be beneficial. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the metric choice but lacks grounding, as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. This question prompts the authors to consider the validity of their chosen metric and encourages them to provide additional feedback or justification for their choice. However, the comment does not offer specific guidance or suggestions on how to address this question or improve the paper. While it identifies an area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific scenarios they should consider. Without actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about the applicability of adversarial prediction accuracy, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the applicability of adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of adversarial prediction accuracy compared to classical prediction accuracy in real scenarios. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the paper could be improved to better explain the relevance of adversarial prediction accuracy. The comment lacks depth and actionable feedback, leaving the authors with a general direction but no concrete steps to take. Therefore, it is rated as 2, consistent with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several issues with the evaluation in the paper, including the lack of transparency in the experiment setup, the absence of information about the number of different sets of incontent examples used, and the reliance on a single dataset. It suggests that the authors should provide more details about the experiment setup and explore the effects of varying the number of InContext Examples. However, while the comment highlights specific areas that need improvement, it does not provide explicit instructions on how to address these issues or what specific changes to make. The authors are left with a general understanding of what needs to be improved but without concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the lack of transparency in the experiment setup, the absence of information about the number of different sets of incontent examples used, and the reliance on a single dataset. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of information about the number of different sets of incontent examples used and the reliance on a single dataset, which limits the generalizability of the results. These points are wellsupported by logical reasoning and specific examples, making the claim 4. However, the comment could be strengthened by providing additional references or detailed explanations to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies several critical issues with the evaluation section of the paper, including the lack of transparency in the experiment setup and the reliance on a single dataset. It points out specific areas that need improvement, such as the absence of information about the number of different sets of incontent examples used and the need to explore the effects of varying the number of InContext Examples. This feedback is valuable as it highlights potential weaknesses in the paper\"s methodology and suggests ways to enhance the comprehensiveness and generalizability of the evaluation. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues, such as recommending additional datasets or methods for analysis. Overall, the comment is 4 as it directs the authors\" attention to important areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out the absence of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2 in Section 4.3. It suggests that including these comparisons would provide a broader context and highlight the unique advantages or potential shortcomings of the proposed method. This feedback is clear and direct, giving the authors a specific action to take: conduct and report comparative experiments with these nonlinear blocks. The comment provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback provides clear guidance on what needs to be added to the paper to enhance its comprehensiveness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, which could provide a broader context for the proposed method. However, the comment does not provide specific examples or references to support the claim, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without detailed reasoning or evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by highlighting the lack of comparative experiments with nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s comprehensiveness and context. By including these comparisons, the authors could better showcase the unique advantages or potential shortcomings of their proposed method. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific results to expect. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, it does not provide explicit guidance on how to incorporate this related work or what specific aspects of the related work should be addressed. The action is implicit, as the authors can infer that they need to include more references to related work, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides a general direction but lacks specific guidance.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, it does not specify which part of the paper this feedback pertains to, such as the introduction or discussion section, making it weakly grounded. The comment is specific in suggesting that the authors should include more references to related work, but it lacks detailed guidance on how to incorporate these references or what specific aspects of the related work should be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. However, the comment does not provide any reasoning, evidence, or justification for why these references are relevant or how they would enhance the paper. Without specific examples or explanations, the authors may find it challenging to understand the basis of the suggestion and how to incorporate it into their work. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples 1, 2, and 3. While this feedback highlights the need for more comprehensive referencing, it lacks specific guidance on how to incorporate these references or what aspects of the related work should be addressed. The comment provides a general direction but does not offer actionable steps or detailed suggestions, making it 3. The authors can use this feedback to identify areas where additional references would be beneficial, but the comment could be more comprehensive to fully support their improvement efforts."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not provide specific guidance on how to incorporate these aspects or what algorithmic details should be included. The action is implicit and somewhat vague, as the authors can infer that they need to expand their focus on algorithmic aspects, but they lack concrete instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the algorithmic focus should be addressed or how the novelty of the paper could be enhanced. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper should have focused more on the algorithmic aspects of the solution, suggesting that the novelty of the paper seems limited after the concept of Blackwell winner is proposed. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully support the assertion.", "helpfulness_rationale": "The review comment suggests that the paper should have focused more on the algorithmic aspects of the solution, particularly after the concept of Blackwell winner is proposed. This feedback highlights a potential area for improvement in the paper, indicating that the authors might have overlooked an important aspect of their work. However, the comment lacks specific guidance or suggestions on how to enhance the algorithmic focus or what aspects should be addressed. While it identifies a potential weakness, it does not provide actionable advice or detailed feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that specifying what \"valid\" and \"orig\" differ in would be helpful in Fig. 5. While it implies that the authors should provide this clarification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to clarify what \"valid\" and \"orig\" differ in. This provides clear guidance on what the authors should focus on improving in their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that specifying what \"valid\" and \"orig\" differ in would be helpful in Fig. 5. However, it does not provide any reasoning, examples, or references to support why this clarification is necessary or how it would improve the understanding of the figure. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area in Fig. 5 that could be improved by providing more clarity. It suggests that specifying what \"valid\" and \"orig\" differ in would enhance the understanding of the figure. This feedback is clear and actionable, as it directs the authors to a specific aspect of their draft that needs clarification. However, the comment could be more helpful if it provided additional context or examples of how this clarification could be achieved. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. While the comment implies that the authors should consider this suggestion, it does not provide explicit instructions or concrete steps on how to implement this change. The action is implicit and somewhat vague, as the authors need to infer that they should explore the comparison to the computer vision method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to a specific method from the computer vision setting, which would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or table. This makes it difficult for the authors to identify the exact area where the suggestion should be applied. Additionally, the comment lacks specificity in detailing what aspects of the comparison would be more useful or how the adaptation to language tasks could be achieved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the suggested comparison would be more useful. The authors are left to infer the potential benefits of this comparison, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including a comparison to a specific method from the computer vision setting would be more useful than comparing to lossbased sampling. It acknowledges that these methods may not always be applicable but suggests that some of them could be adapted for language tasks. This feedback provides a clear direction for the authors to consider a more relevant comparison, which could enhance the paper\"s utility and relevance. However, the comment could be more helpful if it offered specific examples of the methods from the computer vision setting or detailed guidance on how to adapt them for language tasks. Overall, the comment is 4 as it directs the authors towards a potentially more effective comparison, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate this connection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection to properties of universal kernels and references a specific chapter for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This provides a clear and specific reference to external literature that could support the claim, making the comment 4. However, the comment could be strengthened by including a brief explanation of why this connection is relevant or how it could impact the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This feedback is 3 as it prompts the authors to consider a potential connection that could enhance the understanding or applicability of their work. However, the comment lacks depth and does not provide specific guidance on how to explore this connection or why it might be relevant. To be more helpful, the comment could include a suggestion for how to investigate this connection or what aspects of the paper could be improved by exploring this topic. Therefore, the comment is rated as 3, aligning with a score of 3."}
