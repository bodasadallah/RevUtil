{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the difficulty of training a min-max optimization, especially for PDEs with advective terms. It also notes that the methodology is better than the baselines but lacks clarity in the presentation. The reviewer suggests that the paper would benefit from a revision. While the comment identifies a potential issue and suggests a revision, it does not provide specific guidance on what aspects of the methodology or presentation need to be revised or how to address the lack of clarity. The action is implicit and somewhat vague, as the authors know they need to revise the paper but are not given clear instructions on what to focus on. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the difficulty of training a min-max optimization, particularly for PDEs with advective terms, and suggests that the paper would benefit from a revision. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the challenge of training and suggesting a revision, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the min-max optimization is difficult to train, especially for PDEs with advective terms, and suggests that the paper would benefit from a revision. However, the comment lacks specific examples or detailed reasoning to support this claim. While it acknowledges that the methodology performs better than baselines, it does not provide a clear explanation of why the presentation lacks clarity or how it could be improved. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential challenge in training a min-max optimization, particularly for PDEs with advective terms, and suggests that the paper would benefit from a revision. While it acknowledges that the methodology performs better than baselines, it lacks specific details or suggestions on how to address the lack of clarity in the presentation or the revision needed. The comment provides a general direction for improvement but does not offer actionable guidance or specific examples, making it somewhat helpful. The authors are given a starting point for revision, but the feedback could be more detailed to be fully beneficial. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the practical use of the modified TD learning algorithm defined in Definition 5.1 compared to the original proposal (Algorithm 1). While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should justify or explain the practical implications of using the modified algorithm over the original one. However, the comment lacks concrete details on how to implement this action, making it vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the practical use of the modified TD learning algorithm compared to the original proposal (Algorithm 1). The comment clearly specifies what needs to be addressed, namely, the justification for using the modified algorithm in practice. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the practical use of a modified TD learning algorithm compared to the original proposal. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the practical relevance of the modified TD learning algorithm defined in Definition 5.1 compared to the original proposal (Algorithm 1). This question prompts the authors to justify why the modified algorithm should be preferred in practice. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue or what aspects of the original algorithm might be preferable. The feedback is somewhat helpful as it highlights a gap in the paper\\'s practical applicability but could be more comprehensive with additional details or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a concern about the lack of empirical validation for the diversity coefficient as a data quality metric. It explicitly states that the paper does not provide empirical evidence to support this claim, which is a significant concern. However, the comment does not offer specific guidance on how the authors should address this issue or what empirical validation would entail. While the action is clear in terms of needing empirical validation, the comment lacks concrete details on how to implement this, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'diversity coefficient' and its potential as a data quality metric, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern about the lack of empirical validation for this claim, which is a significant issue given the paper's emphasis on Task2Vec and model diversity. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper's suggestion of the diversity coefficient as a data quality metric lacks empirical validation, which is a significant concern. The reviewer provides a logical reasoning by highlighting the paper's emphasis on Task2Vec and model diversity, suggesting that empirical validation is crucial to support the claim. However, the comment lacks specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to provide empirical evidence or further explanation to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant concern regarding the lack of empirical validation for the diversity coefficient as a data quality metric, which is a key claim in the paper. It highlights the importance of empirical evidence to support the claim, especially given the paper's emphasis on Task2Vec and model diversity. However, the comment could be more helpful if it provided specific suggestions on how to conduct the empirical validation or what aspects should be considered. Overall, the feedback is mostly helpful as it directs the authors' attention to a critical area needing improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using canary clients is more inefficient than using canary examples and implies that more resource allocation might be needed. However, it does not explicitly instruct the authors to make this change or provide guidance on how to allocate additional resources. The action is implicit and somewhat vague, as the authors can infer that they should consider using canary examples instead, but the specific steps or rationale for this change are not detailed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that using canary clients is more inefficient than using canary examples and implies that more resource allocation might be needed. However, it does not specify which part of the paper discusses the use of canary clients or provides context for this comparison. The authors can infer that it relates to the experimental setup or methodology, but the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in suggesting that more resource allocation might be needed, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using canary clients is more inefficient than using canary examples and implies that more resource allocation might be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that using canary clients is more inefficient than using canary examples and implies that more resource allocation might be needed. While it identifies a potential inefficiency, the comment lacks specific details or suggestions on how to address this issue or improve the resource allocation. Without actionable guidance or examples, the authors may find it challenging to understand the implications of this feedback or how to implement changes. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not provide sufficient detail or direction for the authors to effectively address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point questions the relevance of Carefl to the paper and suggests that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. The reviewer implies that the authors should clarify why Carefl is relevant to their work, but does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of Carefl's relevance. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Carefl' and references Equation (6) in the method description, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of Carefl and suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. The reviewer provides a specific reference to Equation (4) in the cited work, which supports the claim that Carefl could be a standard definition. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by explicitly explaining why the authors should clarify the relevance of Carefl, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a question about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. This feedback is somewhat helpful as it prompts the authors to clarify the significance of Carefl in their methodology. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or improve their explanation. While it identifies a potential area for clarification, it does not offer actionable steps or detailed suggestions for improvement, leaving the authors with limited guidance on how to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. The reviewer implies that the authors should clarify why Carefl is relevant to their work, but does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of Carefl's relevance. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Carefl' and references Equation (6) in the method description, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the relevance of Carefl and suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. The reviewer provides a specific reference to Equation (4) in the cited work, which supports the claim that Carefl could be a standard definition. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by explicitly explaining why the authors should clarify the relevance of Carefl, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a question about the relevance of Carefl to the paper, suggesting that it might be a standard definition of a nonlinear SEM, similar to Equation (4) in a referenced work. This feedback prompts the authors to clarify the significance of Carefl in their methodology, which is a valuable point for improving the clarity and understanding of their work. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or improve their explanation. While it identifies a potential"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It suggests that if the assumption about the GAA model\\'s performance is not valid, it could lead to larger annotation times, questioning the speedup claim of the proposed approach. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to mitigate the compute-intensive nature of the approach or consider alternative methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the compute-intensive nature of the approach, which involves pretraining the GAA model on the same dataset as the QA model. It also highlights the potential issue with the assumption that the GAA model is performant enough to provide meaningful prompts to annotators, which could lead to larger annotation times. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the potential problem and its implications, but without explicit references to sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach is compute-intensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also suggests that if the assumption about the GAA model\\'s performance is not valid, it could lead to larger annotation times, questioning the speedup claim of the proposed approach. The comment provides a logical reasoning for the claim, explaining the potential issue with the assumption and its implications. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the compute-intensive nature of the proposed approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It highlights the assumption that the GAA model is performant enough to provide meaningful prompts to annotators, which could lead to larger annotation times. This feedback is somewhat helpful as it points out a critical aspect of the approach that could impact its practicality and efficiency. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative approaches to consider. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the compute-intensive nature of the approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It suggests that if the assumption about the GAA model\\'s performance is not valid, it could lead to larger annotation times, questioning the speedup claim of the proposed approach. While the comment highlights a potential problem, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to mitigate the compute-intensive nature of the approach or consider alternative methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the compute-intensive nature of the approach, which involves pretraining the GAA model on the same dataset as the QA model. It also highlights the potential issue with the assumption that the GAA model is performant enough to provide meaningful prompts to annotators, which could lead to larger annotation times. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the potential problem and its implications, but without explicit references to sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the approach is compute-intensive due to the need for pretraining the GAA model on the same dataset as the QA model. It also suggests that if the assumption about the GAA model's performance is not valid, it could lead to larger annotation times, questioning the speedup claim of the proposed approach. The comment provides a logical reasoning for the claim, explaining the potential issue with the assumption and its implications. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might mitigate this limitation or improve the generality of their method. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the dependence of the proposed method on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in identifying the issue of dependence on the server dataset and its impact on generality, but it lacks detailed guidance on how to address this limitation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and reduces its generality. This feedback is valuable as it points out a critical area for improvement that the authors should address. However, the comment lacks specific suggestions or guidance on how to mitigate this limitation or enhance the generality of the method. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might mitigate this limitation or improve the generality of their method. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the dependence of the proposed method on the server dataset, which limits its potential use cases and reduces its generality. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in identifying the issue of dependence on the server dataset and its impact on generality, but it lacks detailed guidance on how to address this limitation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and reduces its generality. This feedback is valuable as it points out an important area for improvement that the authors should address. However, the comment lacks specific suggestions or guidance on how to mitigate this limitation or enhance the generality of the method. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and reduces its generality. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might mitigate this limitation or improve the generality of their method. As a result, the comment lacks actionable content, leaving the authors without a clear path"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider adding additional downstream search methods, such as BO and LS, to their analysis. While the comment implies that these additions would be beneficial, it does not provide explicit instructions on how to implement this suggestion or why these specific methods should be included. The action is implicit and somewhat vague, as the authors need to infer that they should expand their search methods and understand the rationale behind the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding more downstream search methods, specifically mentioning EA, BO, and LS. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these methods are discussed. Without explicit references, the authors may find it challenging to identify the exact area needing attention. The comment is specific in its suggestion to include additional search methods, but the lack of grounding makes it difficult for the authors to pinpoint where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider adding more downstream search methods, such as BO and LS, to their analysis. However, the comment does not provide any reasoning or evidence to support why these specific methods should be included or how they would enhance the analysis. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors should consider adding more downstream search methods, such as BO and LS, to their analysis. While the comment identifies a potential area for improvement by recommending the inclusion of additional methods, it lacks specific guidance or reasoning on why these methods would be beneficial or how they could enhance the analysis. The feedback is somewhat helpful as it points out a potential limitation but does not provide detailed suggestions or examples to support the claim. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a gap in the paper's analysis, specifically the lack of a direct comparison between FLOPs and FPS for pDETR and other sparse models. It explicitly suggests that the paper should include such a comparison, which is a clear and direct action for the authors to take. The comment provides specific guidance on what needs to be added to improve the draft, making it highly actionable. The authors know exactly what action to take to address the feedback, ensuring a clear path for improvement.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 7' and 'pDETR', allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of a direct comparison between FLOPs and FPS for pDETR and other sparse models. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper does not sufficiently highlight the importance of FLOPs and FPS in sparse network research, despite listing FLOPs for pDETR in Table 7. The comment suggests that a direct comparison with other sparse models is missing. However, the comment lacks specific examples or references to other sparse models for comparison, making it somewhat verifiable. The authors would need to infer which models are relevant for comparison, which adds an element of uncertainty. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper could be improved by highlighting the importance of FLOPs and FPS in sparse network research. It points out that while FLOPs for pDETR are listed in Table 7, a direct comparison with other sparse models is missing. This feedback is clear and actionable, as it directs the authors to include a comparison that would enhance the paper's analysis and relevance. However, the comment could be more helpful if it provided suggestions on how to conduct or present this comparison. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the difficulty in understanding the metrics described in Appendix A.1 and the resulting tables. It provides a specific example of how reversing the prediction of Dolly-V2-7B in Table 5 could lead to an incorrect accuracy measurement. This feedback is explicit in suggesting that the authors clarify the metrics and their interpretation in the results. The comment also provides a concrete example of how to address the issue, making it highly actionable. The authors know exactly what needs to be done to improve the clarity of their results, namely, to clarify the metrics and their interpretation in the tables. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the issue with the metrics, explaining that they are hard to understand and providing a specific example of how reversing the prediction of Dolly-V2-7B could lead to an incorrect accuracy measurement. This level of detail helps the authors understand what needs to be addressed in terms of clarifying the metrics and their interpretation in the results. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metrics described in Appendix A.1 are hard to understand, making it unclear what the numbers mean in the result tables. It provides a specific example of how reversing the prediction of Dolly-V2-7B in Table 5 could lead to an incorrect accuracy measurement, which is a clear and logical explanation. This provides a strong basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including references to specific sections or examples of other metrics that are easier to understand, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the metrics described in Appendix A.1, noting that they are difficult to understand, which makes it unclear what the numbers in the result tables mean. It provides a concrete example of how reversing the prediction of Dolly-V2-7B in Table 5 could lead to an incorrect accuracy measurement, highlighting a potential source of confusion. This feedback is clear and actionable, as it directs the authors to clarify the metrics and their interpretation in the results. By addressing this issue, the authors can improve the clarity and accuracy of their presentation, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the Gaussian assumption and its applicability in practice. It asks whether this is a typical situation and whether it is always possible to compute the effective variance for non-gaussian outputs. Additionally, it inquires about a finite-N expansion that could characterize the departure from Gaussianity in the non-ideal case. While the comment raises important questions, it does not provide explicit guidance or suggestions on how the authors should address these concerns. The authors are left to infer that they need to explore these questions further, but the lack of concrete actions or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the Gaussian assumption and its applicability in practice, specifically in the context of the limit r << N. It asks whether this is a typical situation and whether it is always possible to compute the effective variance for non-gaussian outputs. Additionally, it inquires about a finite-N expansion that could characterize the departure from Gaussianity in the non-ideal case. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the analysis and assumptions made in the study. The authors can infer that it relates to the methodology or results sections, but the lack of explicit references makes it weakly grounded. The comment is specific in detailing the questions and issues related to the Gaussian assumption, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the Gaussian assumption and its applicability in practice, particularly in the context of the limit r << N. It asks whether this is a typical situation and whether it is always possible to compute the effective variance for non-gaussian outputs. Additionally, it inquires about a finite-N expansion that could characterize the departure from Gaussianity in the non-ideal case. While the comment does not contain a claim that requires verification, it poses a series of questions that prompt the authors to consider the practical implications of their assumptions and methods. As it is a series of questions seeking clarification, it does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the Gaussian assumption and its applicability in practice. It asks whether this is a typical situation and whether it is always possible to compute the effective variance for non-gaussian outputs. Additionally, it inquires about a finite-N expansion that could characterize the departure from Gaussianity in the non-ideal case. These questions are relevant and could help the authors refine their analysis and assumptions. However, the comment does not provide specific guidance or suggestions on how to address these questions or improve the draft. While it prompts the authors to consider important aspects of their work, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly addressed. It also mentions that other categories are tackled via Wikipedia and a popularity metric. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to clarify or enhance their approach to the math and science categories. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the approach to the math and science categories, suggesting an open vocabulary problem that is not clearly tackled. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue with the approach but lacks grounding, as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly tackled. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach to the math and science categories, noting that it suggests an open vocabulary problem that is not clearly addressed. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it highlights a potential weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include a more thorough discussion of stochastic routing due to its similarity to the work being compared against. While the comment implies that a more detailed discussion is warranted, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a more thorough discussion of stochastic routing, implying that the comparison with this work is significant. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include a more detailed discussion, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a more thorough discussion of stochastic routing due to its similarity to the work being compared against. However, the comment does not provide specific reasoning or examples to support why this discussion is necessary or how it would enhance the paper. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include a more thorough discussion of stochastic routing, noting that the comparison with this work is significant. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to enhance the discussion or what aspects should be addressed. The feedback is somewhat helpful as it points out a potential gap in the paper\\'s analysis, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given that the CE loss cannot be minimized due to the exponential nature of the problem. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider this aspect of convergence but are not given concrete steps on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that convergence in direction should be considered as convergence, given the nature of the CE loss. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity as it does not provide details on how this suggestion should be implemented or what specific aspects of the paper it relates to. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that convergence in direction should be considered as convergence, given that the CE loss cannot be minimized due to its exponential nature. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion, making it difficult to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that convergence in direction should be considered as convergence, given the nature of the CE loss, which cannot be minimized due to its exponential nature. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how the authors might address this issue or what specific changes could be made to their draft. Without actionable advice or examples, the feedback is limited in its usefulness, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the lack of exploration of alternative models to demonstrate the robustness of the proposed framework. It explicitly states that the authors did not try any changes or alternatives in the paper to prove the robustness of the framework. This provides a clear and direct action for the authors to take, which is to conduct experiments with alternative models to demonstrate the robustness of their framework. The comment is explicit and concrete, offering a specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the lack of exploration of alternative models to demonstrate the robustness of the proposed framework. However, it does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing what is missing, which is the exploration of alternative models to prove robustness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have stated that components can be replaced by other models for flexibility but have not demonstrated this in the paper. This is a factual statement that does not contain an opinion, judgment, or suggestion. It is a descriptive observation about the paper\\'s content, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their paper by exploring alternative models to demonstrate the robustness of their proposed framework. It highlights a potential weakness in the current approach and suggests a direction for further investigation. However, the comment lacks specific guidance on which alternative models to consider or how to conduct these experiments, which limits its usefulness. While it points out an important area for improvement, the lack of detailed suggestions makes it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 30 disentangled factors in the Atari game experiments. It implies that the authors should provide an explanation or justification for this choice, as it might be difficult to specify for an arbitrary domain. However, the comment does not explicitly instruct the authors to provide this explanation or suggest how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their choice of disentangled factors. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of 30 disentangled factors and points out the difficulty in specifying this number for an arbitrary domain. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of 30 disentangled factors in the Atari game experiments, noting that it might be difficult to specify for an arbitrary domain. This is a logical claim that raises a valid concern about the methodology. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide more detailed reasoning or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the choice of 30 disentangled factors in the Atari game experiments, noting that it might be difficult to specify for an arbitrary domain. This feedback is somewhat helpful as it prompts the authors to clarify their methodology and justification for choosing 30 factors. However, the comment could be more helpful if it provided suggestions on how to address the difficulty in specifying the number of factors or offered alternative approaches. Overall, the comment provides a starting point for the authors to consider, but it lacks depth and actionable guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the use of colloquial expressions in the paper, specifically mentioning the phrase \"By the way\" in the training stage. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to remove or replace the colloquial expressions, nor is there any advice on how to maintain professionalism in the writing. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific instance of colloquial expressions used in the paper, specifically the phrase \"By the way\" in the training stage. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly identifies the issue with the use of colloquial expressions, which are considered unprofessional. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that colloquial expressions are unprofessional, specifically mentioning the phrase \"By the way\" in the training stage. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this particular expression is considered unprofessional or how it affects the overall professionalism of the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the use of colloquial expressions, such as the phrase 'By the way,' in the paper. It highlights that such expressions are unprofessional and suggests that the authors should consider revising their language to maintain a more formal tone. However, the comment does not provide specific guidance on how to address this issue or offer alternative suggestions for phrasing. While it points out a potential problem, it lacks depth and actionable advice, making it somewhat helpful. The authors are given a direction to improve, but the feedback could be more comprehensive to fully support their efforts. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly points out that the abbreviation 'LLH' is not defined, and it questions why 'ECE' is considered a pivotal metric without explanation. This feedback is clear and direct, instructing the authors to define 'LLH' and provide an explanation for 'ECE.' The action is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment explicitly mentions the abbreviation 'LLH' and questions its definition, as well as the lack of explanation for 'ECE.' This provides full grounding, as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: defining 'LLH' and providing an explanation for 'ECE.' Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the abbreviation 'LLH' is not defined, and it questions why 'ECE' is considered a pivotal metric without explanation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper by pointing out that the abbreviation 'LLH' is not defined, despite the definition of 'OOD' and 'ECE.' This is a critical oversight that could impact the clarity and understanding of the paper. By highlighting this gap, the comment provides clear and actionable feedback, instructing the authors to define 'LLH' and explain 'ECE.' This guidance is valuable as it helps the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to define 'LLH' or provided examples of how to explain 'ECE.' Overall, the comment is mostly helpful, as it effectively directs the authors to address a significant issue in their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units. It suggests that the authors should justify the stability of their method and provide information on how it behaves when more layers are added. While the comment implies that the authors need to address the stability of their method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide stability analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the stability of the proposed method when stacking multiple layers of WLS units. It raises a question about the probability of failure in stochastic/random projection and its impact on the proposed method\\'s ability to form deeper GNN. However, the comment does not explicitly mention which part of the paper this concern relates to, such as a specific section or figure. The authors can infer that it pertains to the methodology or results sections, but this inference is not as clear as it could be. The comment is specific in detailing the issue of stability and the need for justification, but it lacks full grounding due to the lack of explicit reference to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units. The reviewer questions the probability of failure in stochastic/random projection and its impact on the proposed method\\'s ability to form deeper GNN. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the probability of failure increases with each layer. Without additional evidence or explanation, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the stability of the proposed method when stacking multiple layers of WLS units. It points out that the probability of failure in stochastic/random projection increases with each layer, potentially hindering the formation of deeper GNN. The comment suggests that the authors should justify the stability of their method and provide information on how it behaves with more layers. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their methodology that could impact the effectiveness of their proposed method. However, the comment could be more helpful if it provided specific suggestions or examples of how to justify the stability of the method or how to mitigate the potential issues. Overall, the comment is mostly helpful as it identifies a significant area for improvement and offers a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific area of the paper that lacks clarity, mentioning the computation of the Bottleneck Distance in Definition 4.1. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to improve the clarity or what specific changes should be made. As a result, the authors are left without a clear understanding of what steps to take to enhance the clarity of the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific section of the paper, \"Definition 4.1,\" which lacks clarity regarding the computation of the Bottleneck Distance. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity in the computation of the Bottleneck Distance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some sections of the paper lack clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide any supporting evidence, examples, or detailed reasoning to explain why this computation is unclear or how it could be improved. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that lacks clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. This feedback is somewhat helpful as it points out a specific issue that needs attention, but it lacks depth and does not provide detailed guidance on how to improve the clarity of the computation. The authors are left with a general understanding of what needs to be addressed but without specific suggestions or examples to enhance the clarity of the section. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for improvement but requires further elaboration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out a weakness in the visualization of the paper, specifically mentioning Fig 5, and suggests that it could be more convincing by providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4. While the comment identifies a specific area for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Fig 5' and 'Figure 4', allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the weaker visualization compared to Balikas COLING16's work and suggests improvements, such as providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper's visualization is weaker compared to Balikas COLING16's work, which raises doubts about the segmenting and assigning results of the document. The reviewer suggests that providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4 could make the visualization more convincing. However, the comment lacks specific examples or detailed reasoning to support the claim that the visualization is weaker or how the suggested improvements would address this issue. Without additional context or evidence, the claim remains somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the visualization in the paper, comparing it to Balikas COLING16's work. It points out that the visualization is weaker and suggests ways to improve it by providing a longer exemplar and ensuring consistent color assignment with topics listed in Figure 4. This feedback is clear and actionable, offering the authors a concrete direction for enhancing the clarity and effectiveness of their visualization. However, the comment could be more helpful if it provided specific examples or detailed suggestions on how to achieve these improvements. Overall, the comment is mostly helpful as it guides the authors in addressing a significant issue in their draft, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of P5-small as the backbone model and expresses confusion about the necessity of using a parameter-efficient training method. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should consider using a different model or training method, or if there is a specific reason for using P5-small and the parameter-efficient method. Without actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the use of P5-small as the backbone model and expresses confusion about the necessity of using a parameter-efficient training method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity in terms of what needs to be addressed regarding the use of P5-small and the parameter-efficient training method. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the use of P5-small as the backbone model and expresses confusion about the necessity of using a parameter-efficient training method. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is questionable or unnecessary. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the use of P5-small as the backbone model and expresses confusion about the necessity of using a parameter-efficient training method. While it identifies a potential issue with the model choice, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or detailed reasoning, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it provides some insight but lacks depth and actionable advice.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors\\' goal of proposing a way to create a challenging set is not scalable, suggesting that the description is specific and lacks scalability. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the scalability of their approach. The comment lacks actionable details, leaving the authors uncertain about what specific changes or additions are needed to address the scalability concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a general concern about the scalability of the proposed approach, specifically mentioning the authors\\' goal of creating a challenging set. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the scalability issue but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' goal of proposing a way to create a challenging set is not scalable, suggesting that the description is specific and lacks scalability. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the proposed approach, specifically noting that the authors\\' goal of creating a challenging set is not scalable. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve the scalability of their approach. Without additional guidance or examples, the authors may find it challenging to understand and implement the necessary changes. Therefore, the comment is barely helpful, as it highlights a concern but does not offer actionable insights for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to strengthen their approach. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. Without explicit references or detailed information, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of this reliance are problematic or how it could be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. While it identifies a potential issue, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or detailed insights, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the approach is derivative, combining two existing approaches, and finds it acceptable as long as it works. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve or enhance their work, nor are there suggestions for further development or clarification. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the derivative nature of the approach, mentioning that it combines two existing approaches. However, it does not specify which parts of the paper this observation pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the approach are considered derivative or how it could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the approach is derivative, combining two existing approaches, but finds it acceptable as long as it works. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the approach is acceptable or how it might be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the approach is derivative, combining two existing approaches, and finds it acceptable as long as it works. However, it does not provide any constructive feedback or suggestions for improvement. The comment lacks actionable advice or specific guidance on how the authors might enhance their work or address potential weaknesses. Without actionable insights, the comment does not effectively support the authors in improving their draft. Therefore, it is rated as not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, and finds it acceptable as long as it works. However, it does not provide any explicit or implicit actions for the authors to take, such as suggestions for improvement or further development. The comment lacks actionable content, leaving the authors without a clear direction for enhancing their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, combining two existing approaches, but finds it acceptable as long as it works. However, it does not specify which part of the paper this observation pertains to, such as the methodology or results sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact parts of the paper being addressed. Additionally, the comment lacks specificity regarding what aspects of the approach are considered derivative or how it could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the approach is derivative, combining two existing approaches, but finds it acceptable as long as it works. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the approach is acceptable or how it might be improved. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the approach is derivative, combining two existing approaches, but finds it acceptable as long as it works. However, it does not provide any constructive feedback or suggestions for improvement, such as how the authors might enhance their work or address potential weaknesses. Without actionable advice or specific guidance, the comment does not effectively support the authors in improving their draft. Therefore, it is rated as not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment acknowledges that the approach is derivative, combining two existing approaches, but finds it acceptable as long as it works. However, it does not provide any explicit or implicit actions for the authors to take, such as suggestions for improvement or further development. Without actionable guidance, the authors are left without a clear direction for enhancing their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the approach is derivative, combining two existing approaches, but finds it acceptable as long as it works"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of comparisons against baseline approaches in the evaluation section, suggesting that a simple photographic style transfer method might achieve similar or better results. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include baseline comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the evaluation\" and \"the results shown in the paper and the supplementary material,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that a simple photographic style transfer method might achieve similar or better results, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no comparisons against any other potential baseline approaches in the evaluation, and suggests that a simple photographic style transfer method might achieve similar or better results. However, the comment lacks specific examples or references to support the claim that a photographic style transfer method would be more effective. While the suggestion is logical, it requires further elaboration or evidence to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a basis for the claim but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of comparisons against other baseline approaches in the evaluation section. It suggests that a simple photographic style transfer method might achieve similar or better results, implying that the authors should include such comparisons to strengthen their evaluation. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by including additional comparisons. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or which specific baseline methods to consider. Overall, the comment is mostly helpful as it guides the authors towards a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, making it difficult to understand the proposed method. It explicitly points out that the authors did not explain the meaning of C_i, Q_i, R_i, and A_i in Figure 2, and questions the difference between S_i and calligraphic S_j. The comment also suggests that the authors should clarify how to compute each node in Figure 2. While the comment provides clear guidance on what needs to be addressed, it does not specify how to resolve these issues, such as suggesting specific changes or examples. The action is explicit but somewhat vague, as the authors know what needs to be done but not how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with mapping symbols in the figure to those in the equations, questioning the lack of explanation for C_i, Q_i, R_i, and A_i, and the difference between S_i and calligraphic S_j. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the difficulty in mapping symbols in Figure 2 to those in the equations makes it challenging to understand the proposed method. The reviewer provides specific examples, such as the lack of explanation for C_i, Q_i, R_i, and A_i, and the difference between S_i and calligraphic S_j. This provides a clear and detailed explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing specific references or examples from the paper to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mapping of symbols in Figure 2 to those in the equations, making it difficult to understand the proposed method. It highlights the lack of explanation for symbols like C_i, Q_i, R_i, and A_i, and questions the difference between S_i and calligraphic S_j. The comment provides clear guidance on what needs to be addressed, such as explaining the meaning of these symbols and how to compute each node in Figure 2. This feedback is actionable and helps the authors improve the clarity and understanding of their method. However, the comment could be more helpful if it suggested specific ways to clarify these points or provided examples of how to address them. Overall, the comment is mostly helpful, as it effectively directs the authors to improve the clarity of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should also study the number of backtracking steps and the acceptance rate, as well as the amount of tuning required to achieve good results. While the comment implies that these aspects should be investigated, it does not provide explicit instructions on how to conduct these studies or what specific aspects should be examined. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should study additional hyperparameters, specifically the number of backtracking steps and the acceptance rate, in addition to the number of revisions with local searches. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to study additional hyperparameters, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should study additional hyperparameters, specifically the number of backtracking steps and the acceptance rate, in addition to the number of revisions with local searches. However, the comment does not provide any reasoning, examples, or references to support why these additional parameters are important or how they might affect the results. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should consider studying additional hyperparameters, specifically the number of backtracking steps and the acceptance rate, in addition to the number of revisions with local searches. This feedback is somewhat helpful as it identifies a potential area for further exploration that could enhance the depth of the analysis. However, the comment lacks specificity regarding how these additional parameters might impact the results or what specific aspects of the study could be improved by examining them. Without detailed guidance or examples, the authors may find it challenging to fully address the suggestion. Therefore, the comment is rated as somewhat helpful, as it provides a direction for potential improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the objective functions used in GSdyn and FABOLAS, specifically asking for clarification on the accuracy metric used in Section 5.1. While the comment does not explicitly instruct the authors to provide this information, it does imply that the authors should clarify which accuracy metric is being used. The action is implicit but concrete, as the authors know exactly what information is needed to address the comment. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the objective function for GSdyn and FABOLAS, and it asks for clarification on whether the accuracy is measured on the validation or test dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the objective function used in GSdyn and FABOLAS, specifically asking for clarification on the accuracy metric used in Section 5.1. The comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking clarification, which is a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the objective function used in GSdyn and FABOLAS, specifically asking for clarification on the accuracy metric used in Section 5.1. It points out a potential ambiguity regarding whether the accuracy is measured on the validation or test dataset. This feedback is valuable as it prompts the authors to clarify a significant aspect of their methodology, which could impact the interpretation and reproducibility of their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how to clarify the objective function. Overall, the comment is mostly helpful as it identifies a crucial area for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a reorganization of the paper\\'s structure, specifically recommending that the \"section 3.1\" be moved to the \"related work\" section and that the \"section 3.2\" be renamed as \"section 3\" with the proposal. This implies a clear action for the authors to take, which is to reorganize the sections as suggested. The comment provides explicit guidance on how to implement the change, making it highly actionable. The authors know exactly what needs to be done to improve the draft based on the reviewer\\'s feedback.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests a reorganization of the paper\\'s structure, specifically recommending that the \"section 3.1\" be moved to the \"related work\" section and that the \"section 3.2\" be renamed as \"section 3\" with the proposal. This provides a clear and specific suggestion for reorganizing the sections, allowing the authors to accurately identify the parts of the paper being addressed. The comment is fully grounded as it explicitly mentions sections, and it is specific in detailing what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a reorganization of the paper\\'s structure, recommending that certain sections be moved or renamed. However, the comment does not provide any reasoning, examples, or references to support why this reorganization is necessary or beneficial. Without additional justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for reorganizing the paper\\'s structure, recommending that the \"section 3.1\" be moved to the \"related work\" section and that the \"section 3.2\" be renamed as \"section 3\" with the proposal. This feedback is clear and actionable, offering a concrete way for the authors to improve the organization and flow of their paper. By following this suggestion, the authors can enhance the clarity and coherence of their draft, making it more effective for readers. However, the comment could be more helpful if it included additional context or reasoning to support the reorganization, such as explaining how this change would benefit the overall narrative or understanding of the paper. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for examples on how to efficiently obtain priors, indicating a clear action for the authors to take. It also points out a perceived lack of practical methods for obtaining the required prior {$U_{k_n}$}, suggesting that the authors need to address this issue. While the comment does not provide specific examples or detailed guidance on how to obtain the priors, it is clear that the authors need to address this aspect. The action is explicit but somewhat vague, as the authors know what needs to be done but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"numerical experiment section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a practical way to obtain the required prior {$U_{k_n}$}. The comment provides a clear direction for the authors to address this issue by giving examples of how to obtain priors efficiently. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the efficiency of obtaining priors and requests examples, suggesting that the authors may not have a practical method for obtaining the required prior {$U_{k_n}$}. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific concern about the efficiency of obtaining priors and requests examples to illustrate this process. It highlights a potential gap in the paper's methodology by noting that the authors may not have a practical way to obtain the required prior {$U_{k_n}$}. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their methodology. However, the comment could be more helpful if it provided suggestions or examples of how to obtain priors efficiently. Overall, the comment is mostly helpful as it identifies a significant area for improvement and offers a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. While the action is explicit, it does not provide detailed guidance on how to conduct this evaluation or which specific aspects of the VOT dataset should be considered. The suggestion is concrete in terms of what needs to be done, but the lack of detailed instructions makes it somewhat vague. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation section or the results section where the current benchmarks are discussed. The comment is specific in suggesting additional metrics for evaluation, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. The reviewer provides a rationale by noting that the current evaluation benchmarks (OTB-50, OTB-100, OTB-2015, and LASOT) evaluate methods using AUC and precision metrics, and suggests that additional metrics are needed for a more comprehensive comparison. While the suggestion is logical and provides a clear rationale, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the suggestion but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors perform additional evaluation on the VOT dataset to compare methods in terms of different metrics like Accuracy, Robustness, and EAO. This is a constructive suggestion as it identifies a potential gap in the current evaluation, which could provide a more comprehensive comparison of the proposed framework. The comment is specific and actionable, offering a clear direction for the authors to enhance the evaluation of their work. However, it could be more helpful if it provided examples of how these metrics could be applied or if it suggested specific aspects of the VOT dataset that would be particularly relevant. Overall, the comment is mostly helpful, as it guides the authors towards a meaningful improvement in their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It explicitly states that the paper claims the performance of the proposed method is comparable to supervised semantic segmentation, but it does not report the performance of any state-of-the-art methods. This feedback provides a clear action for the authors to take, which is to include comparisons with relevant state-of-the-art methods. The comment is explicit and concrete, guiding the authors on what specific action to take to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It explicitly mentions the absence of performance reports for such methods, which allows the authors to identify the relevant part of the paper where this issue is discussed. The comment is specific in detailing what needs to be addressed, namely the inclusion of comparisons with state-of-the-art methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not compare the proposed method to any state-of-the-art unsupervised semantic segmentation techniques, despite stating that the performance is comparable to supervised semantic segmentation. The reviewer provides a specific observation that the paper lacks a comparison to state-of-the-art methods, which is a logical and reasonable claim. However, the comment could be strengthened by providing examples of relevant state-of-the-art methods or references to support the claim. Overall, the comment is mostly verifiable as it provides a clear direction for improvement but lacks detailed examples or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper, specifically the lack of comparison to state-of-the-art unsupervised semantic segmentation techniques. It points out that while the paper claims the performance of the proposed method is comparable to supervised semantic segmentation, it does not report the performance of any state-of-the-art methods, either supervised or unsupervised. This feedback is clear and actionable, as it directs the authors to include comparisons with relevant state-of-the-art methods to strengthen their claims. However, the comment could be more helpful if it provided specific suggestions on which state-of-the-art methods to include or how to structure the comparison. Overall, the comment is mostly helpful as it highlights a significant gap in the paper's evaluation and offers a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It questions whether the cyclical learning rate scheduling perturbs the weight around the initial converged weight and whether it guarantees that the weight changes along the curve described in the first part. However, the comment does not provide explicit guidance or suggestions on how the authors might improve the explanation or clarify the relationship between the curve-finding part and the FGE work. The action is implicit and vague, leaving the authors uncertain about how to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific part of the paper, which is the first curve-finding part, and questions the explanation regarding its relation to the FGE work. It highlights a concern about the cyclical learning rate scheduling and its impact on the weight changes. However, the comment does not specify which section or figure this part is located in, making it weakly grounded. The comment is specific in detailing the issue with the explanation, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It questions whether the cyclical learning rate scheduling perturbs the weight around the initial converged weight and whether it guarantees that the weight changes along the curve described in the first part. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the explanation is unclear or incomplete. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It questions whether the cyclical learning rate scheduling perturbs the weight around the initial converged weight and whether it guarantees that the weight changes along the curve described in the first part. This feedback is somewhat helpful as it identifies a specific area of confusion or lack of clarity in the paper. However, it lacks detailed guidance or suggestions on how the authors might improve the explanation or clarify the relationship between the curve-finding part and the FGE work. To be more helpful, the comment could provide specific examples or suggestions for clarification. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but does not fully guide the authors in addressing it.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It questions whether the cyclical learning rate scheduling perturbs the weight around the initial converged weight and whether it guarantees that the weight changes along the curve described in the first part. However, the comment does not provide explicit guidance or suggestions on how the authors might improve the explanation or clarify the relationship between the curve-finding part and the FGE work. The action is implicit and lacks concrete details, making it barely actionable. The authors are left uncertain about how to address the issue, leaving the comment unhelpful in terms of actionable feedback.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific part of the paper, which is the first curve-finding part, and questions the clarity of the explanation regarding its relation to the FGE work. It highlights a concern about the cyclical learning rate scheduling and its impact on the weight changes. However, the comment does not specify which section or figure this part is located in, making it weakly grounded. The comment is specific in detailing the issue with the explanation, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the first curve-finding part and its relation to the FGE work. It questions whether the cyclical learning rate scheduling perturbs the weight around the initial converged weight and whether it guarantees that the weight changes along the curve described in the first part. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the explanation is unclear or incomplete. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifi"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that presenting a case study with synthetic datasets would enhance the paper by demonstrating the effectiveness of a distillation strategy. It also questions the performance of LFADS-Hard and LFADS-Soft, suggesting that the authors should provide more reasoning or hypotheses based on the results. While the comment implies that the authors should conduct additional analysis or provide more context, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a case study and provide more reasoning. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests presenting a case study with synthetic datasets to demonstrate the effectiveness of a distillation strategy, particularly in relation to the results in Table 3. It questions the performance of LFADS-Hard and LFADS-Soft and asks if the authors have checked the reason behind it. However, the comment does not specify which part of the paper this suggestion pertains to, such as a particular section or table. While the authors can infer that it relates to the results in Table 3, the lack of explicit mention makes it weakly grounded. The comment is specific in detailing what the authors should consider, such as presenting a case study and providing more reasoning or hypotheses. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that presenting a case study with synthetic datasets would be beneficial for demonstrating the effectiveness of a distillation strategy. It questions the performance of LFADS-Hard and LFADS-Soft, suggesting that the authors should provide more reasoning or hypotheses based on the results. However, the comment does not provide specific examples or detailed reasoning to support the claim that a case study would be beneficial or why the performance of these methods is unclear. The suggestion is somewhat vague and lacks detailed justification, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is categorized as \"2: Borderline Verifiable.\"', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that presenting a case study with synthetic datasets would be beneficial for demonstrating the effectiveness of a distillation strategy. It specifically questions the performance of LFADS-Hard and LFADS-Soft, suggesting that the authors should provide more reasoning or hypotheses based on the results. This feedback is clear and actionable, as it guides the authors to conduct additional analysis or provide more context to support their findings. However, the comment could be more helpful if it included specific examples or detailed reasoning about why a case study would be beneficial. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should create cloze-style or question answering evaluation sets to focus on factual knowledge generation, as the current evaluation of LM loss is not clean enough because only a few tokens in a sentence are related to facts. While the comment implies that the authors should make these changes, it does not provide explicit instructions on how to create these evaluation sets or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of LM loss, specifically mentioning that it is not clean enough because only a few tokens in a sentence are related to facts. It suggests creating cloze-style or question answering evaluation sets to focus on factual knowledge generation. However, the comment does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improving the evaluation process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of LM loss is not clean enough because only a few tokens in a sentence are related to facts. The reviewer suggests creating cloze-style or question answering evaluation sets to focus on factual knowledge generation. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the current evaluation is insufficient. This makes the claim somewhat verifiable, as the authors would need to infer the exact issues and improvements needed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the evaluation of LM loss, specifically noting that only a few tokens in a sentence are related to factual knowledge. It suggests creating cloze-style or question answering evaluation sets to focus on factual knowledge generation, which is a constructive and actionable suggestion. However, the comment could be more helpful if it provided specific examples or guidance on how to implement these evaluation sets. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters. It suggests that while the authors claim the RTD score is sensitive to clusters, they should also explain the theoretical or topological reasons behind this sensitivity. Additionally, the comment questions why the proposed RTD score specifically works for network representation and not for any vectors with the same size. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues. The action is implicit and somewhat vague, as the authors need to infer that they should provide theoretical or topological explanations and clarify the scope of the RTD score. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RTD score,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters and why it is specifically applicable to network representation. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical or topological aspects of the RTD score\\'s sensitivity to clusters. It suggests that while the authors claim sensitivity, they should also explain the theoretical or topological reasons behind it. Additionally, it questions why the proposed RTD score specifically works for network representation and not for any vectors with the same size. The comment is mostly verifiable as it provides a logical basis for the questions raised, but it lacks specific references or detailed examples to fully substantiate the claim. The authors would need to provide additional context or evidence to fully address the reviewer\\'s concerns. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a critical question about the theoretical and topological aspects of the RTD score's sensitivity to clusters. It points out that while the authors claim sensitivity, they should also explain the theoretical or topological reasons behind it. Additionally, the comment questions why the proposed RTD score specifically works for network representation and not for any vectors with the same size. This feedback is valuable as it prompts the authors to provide a more comprehensive explanation of their method's theoretical foundations and its applicability. However, the comment could be more helpful if it offered suggestions on how to address these questions or provided specific examples to illustrate the points. Overall, the comment is mostly helpful as it identifies areas for improvement and encourages deeper exploration of the method's theoretical underpinnings.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the claim that ROCK has similar complexity to the original model, suggesting that it is unlikely due to the addition of multiple layers. It explicitly requests inference timings to support the claim. Additionally, it identifies a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. The reviewer suggests conducting comparisons between the full model (DNS) and models where one task is dropped out (DS, NS, DN) to address this issue. These suggestions provide clear and concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L88-89,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the claim that ROCK has similar complexity to the original model, noting the addition of multiple layers and suggesting the need for inference timings to support the claim. Additionally, it identifies a weakness in the experiments regarding the ablation studies on the contribution of each auxiliary task. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the complexity of the ROCK model compared to the original model, suggesting that the claim is unlikely due to the addition of multiple layers. However, the comment lacks specific evidence or detailed reasoning to support this claim, such as detailed comparisons of the computational complexity or inference times. The suggestion to provide inference timings to support the claim adds some verifiability but remains somewhat vague. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed justification to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the claim that the ROCK model has similar complexity to the original model, noting the addition of multiple layers. It suggests providing inference timings to support this claim, which is a concrete and actionable suggestion for the authors to address. Additionally, the comment points out a weakness in the experiments, specifically the lack of ablation studies showing the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. It provides a clear direction for improvement by suggesting comparisons between the full model and models with dropped tasks. This feedback is mostly helpful as it offers specific and actionable guidance for enhancing the experimental section of the paper, enabling the authors to strengthen their claims and provide a more comprehensive analysis.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) and suggests adding the equation to the paper for clarity. While the comment explicitly requests the addition of an equation, it does not provide specific guidance on how to implement this suggestion or what aspects of the equation should be included. The action is clear, but the comment lacks detailed instructions on how to execute it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 197-198,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) and the suggestion to add the equation for clarity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) and suggests adding the equation to the paper for clarity. However, it does not provide any supporting evidence, reasoning, or examples to justify why this calculation is unclear or how it affects the paper\\'s clarity. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the calculation of the joint probability P(y_1, y_2, ..| y_{<i}, X) and suggests adding the equation to the paper for clarity. This feedback is clear and actionable, as it identifies a specific area where the paper could be improved by providing additional details or equations. By addressing this suggestion, the authors can enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided a specific example of how the equation should be included or if it discussed the potential impact of this addition on the paper. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also questions how the model might behave on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. While the comment identifies areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to expand their discussion on dataset diversity and quality, but the comment lacks concrete suggestions or examples on how to do so. Therefore, the comment is somewhat actionable, as it points out areas for improvement but does not provide detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on the diversity and quality of the dataset, specifically regarding rare conditions and imaging variations. It also questions how the model might behave on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the dataset description or experimental setup sections, but this is not explicitly mentioned. The comment is specific in detailing what is missing, such as a discussion on dataset quality and real-world applicability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also questions how the model might behave on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or examples makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's discussion, specifically the lack of exploration into the diversity and quality of the dataset, including rare conditions and imaging variations. It also questions how the model might perform on noisy or imbalanced real-world medical datasets, where labels may be incomplete, inaccurate, or skewed. This feedback is valuable as it points out areas that need further investigation and discussion, which could enhance the robustness and applicability of the model. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues, such as recommending additional analyses or experiments. Overall, the comment is mostly helpful as it highlights important areas for improvement but lacks detailed guidance on implementation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a concern about the reproducibility of the results due to the lack of promised code for training and testing. It explicitly states that the provided training details about data and hyperparameters do not guarantee reproducibility. However, the comment does not provide specific guidance on how the authors might address this issue, such as suggesting the inclusion of code or detailed instructions for replication. The action is implicit and somewhat vague, as the authors need to infer that they should take steps to ensure reproducibility, but the comment does not offer concrete steps on how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the reproducibility of the results, specifically mentioning the lack of promised code for training and testing. However, it does not specify which part of the paper discusses the model components or the training stages, making it weakly grounded. The comment is specific in pointing out the issue of reproducibility, but without explicit references to sections or details, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the model's training requires multiple stages and that the lack of promised code for training and testing makes the results non-reproducible. However, the comment does not provide specific examples or references to support the claim that the results are not reproducible due to the lack of code. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a critical issue regarding the reproducibility of the results, specifically noting that the lack of promised code for training and testing makes the results non-reproducible. This is a significant concern for the authors and the scientific community, as reproducibility is a cornerstone of scientific research. However, the comment lacks actionable guidance on how the authors might address this issue, such as suggesting the inclusion of code or detailed instructions for replication. While it highlights a significant problem, the feedback could be more helpful if it provided concrete steps or examples of how to ensure reproducibility. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that critical setup information is missing, specifically mentioning the total number of agents available in Flow\\'s default configuration. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, giving the authors a straightforward task to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the missing information regarding the total number of agents available in Flow\\'s default configuration. However, it does not specify which part of the paper this information should be included in, such as a specific section or table. While the authors can infer that it relates to the methodology or experimental setup, the lack of explicit mention of a section or table makes it weakly grounded. The comment is specific in identifying the missing information, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that critical setup information is missing, specifically mentioning the total number of agents available in Flow\\'s default configuration. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is critical or how its absence affects the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary details to help the authors understand the significance of this information or how to address the issue.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks critical information, namely the total number of agents available in Flow\\'s default configuration. This is an important piece of information that could significantly impact the understanding and reproducibility of the experimental setup. By pointing out this omission, the comment provides a clear and actionable suggestion for the authors to include this information in their draft. However, the comment could be more helpful if it offered additional guidance on why this information is crucial or how it might affect the results or interpretation of the study. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional context or suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the claim that the paper presents the first deep generative model for unsupervised scene-graph discovery, noting that there are numerous works that infer structures in an unsupervised manner. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their claim. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claim that the paper presents the first deep generative model for unsupervised scene-graph discovery, noting that there are numerous works that infer structures in an unsupervised manner. However, it does not specify which part of the paper this claim is made in, nor does it provide specific details on what aspects of the claim are problematic. The authors might infer that it relates to the introduction or methodology sections, but this is not explicitly stated. The comment lacks specificity in identifying the exact part of the paper being addressed and what needs to be revised. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point challenges the claim that the paper presents the first deep generative model for unsupervised scene-graph discovery by pointing out that there are numerous works that infer structures in an unsupervised manner. This critique is based on common knowledge and the authors\\' familiarity with the field, as it does not require external references or detailed reasoning. The comment is logical and provides a clear basis for questioning the novelty of the claim, making it somewhat verifiable. However, it could be strengthened by providing specific examples of these works or further elaboration on why they are relevant. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the claim that the paper presents the first deep generative model for unsupervised scene-graph discovery, noting that there are numerous works that infer structures in an unsupervised manner. This feedback is somewhat helpful as it identifies a potential issue with the novelty claim, prompting the authors to reconsider their characterization of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this critique or improve their claim. Without additional context or actionable advice, the feedback is limited in its usefulness. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the ablation study, noting that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to address this issue or suggest how to conduct the necessary analysis. The action is implicit and somewhat vague, as the authors can infer that they need to include this analysis, but the comment lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study, which is that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. This provides clear guidance on what needs to be addressed in the study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue and how to address it. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the ablation study, noting that it does not provide the effect of different numbers of projectors on distillation when the feature dimensions are different. This feedback is clear and actionable, as it directs the authors to a specific area where their analysis is lacking. By addressing this gap, the authors can enhance the comprehensiveness and depth of their study. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific results to expect. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should conduct additional experiments on diverse datasets to demonstrate the generalization capabilities of the model beyond the three categories mentioned (chair, airplane, car). It specifically recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. This feedback is explicit and provides concrete guidance on what additional experiments should be conducted to enhance the paper's claims. The authors are given a clear direction on how to improve their draft, making the comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment suggests conducting additional experiments on diverse datasets to demonstrate the generalization capabilities of the model, specifically beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental section or results, as it discusses the need for additional experiments. The authors can infer that this comment relates to the experimental results or methodology sections. However, the comment is specific in detailing what additional experiments are needed to demonstrate the model's generalization capabilities. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the authors should conduct additional experiments on diverse datasets to demonstrate the generalization capabilities of their model beyond the three categories mentioned (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to showcase the core idea of the proposed method. While the comment provides a logical rationale for these suggestions, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the relevance and importance of these suggestions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for enhancing the paper's experimental validation. It recommends conducting additional experiments on diverse datasets to demonstrate the model's generalization capabilities beyond the three categories (chair, airplane, car) mentioned in the paper. The comment also suggests evaluating more complex shapes with various topologies, which would help illustrate the core idea of the proposed method. This feedback is specific and provides a concrete direction for the authors to improve their draft, making it highly helpful. By addressing this suggestion, the authors can strengthen their paper's claims and provide a more comprehensive evaluation of their model's performance. Therefore, the comment is rated as highly helpful.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements and notes that low compute restrictions during test time are typically essential for inference on new examples. However, the comment does not explicitly instruct the authors to conduct this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but lack detailed instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to compare against methods with longer training times and highlights the importance of understanding the implications of low computational requirements. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements and notes that low compute restrictions during test time are typically essential for inference on new examples. However, the comment lacks specific examples or references to support the claim that such a comparison is necessary. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that a comparison against methods requiring more training time is necessary, particularly in light of the neural networks proposed by Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements and notes that low compute restrictions during test time are typically essential for inference on new examples. However, the comment lacks specific guidance on how to conduct this comparison or what aspects to focus on. While it identifies a relevant area for improvement, the feedback could be more actionable by providing detailed suggestions or examples. Therefore, the comment is somewhat helpful, as it points out an important area for consideration but does not fully guide the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the comparison between DetNAS and ResNet is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks. It provides a specific action for the authors to take, recommending that they provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2 with 3.8G FLOPs. This feedback is clear and concrete, giving the authors a direct path to improve their draft by suggesting specific comparisons to make. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between DetNAS and ResNet, noting that the comparison is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks. The suggestion to provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2 with 3.8G FLOPs, is detailed and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks in ResNet. The reviewer suggests that the authors provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a specific action for the authors to take. However, it lacks detailed examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between DetNAS and ResNet, noting that the comparison is unfair due to the efficiency difference between ShuffleNetv2 and Residual blocks in ResNet. It provides a specific suggestion for improvement by recommending that the authors provide more comparisons between DetNAS and other networks constructed with efficient blocks, such as ShuffleNetv2 with 3.8G FLOPs. This feedback is clear and actionable, offering the authors a concrete way to enhance the fairness and comprehensiveness of their comparisons. By following this suggestion, the authors can improve the robustness and validity of their results. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the input and output spaces/representations are restricted to specific representations, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. It suggests that this limitation is not as general as the two papers mentioned in point (3), which can work with any finite-dimensional representation. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should consider expanding the generality of their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the input and output spaces/representations, suggesting that they are restricted to specific representations. However, it does not specify which part of the paper discusses these spaces or representations, making it weakly grounded. The comment is specific in pointing out the limitation of the generality of the approach compared to other papers mentioned. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the input and output spaces/representations are restricted to specific representations, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer compares this limitation to other papers that can work with any finite-dimensional representation. However, the comment does not provide specific examples or references to these other papers, making it difficult for the authors to understand the basis of the claim. Without detailed examples or references, the claim remains somewhat verifiable, as it lacks the necessary evidence to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the generality of the input and output spaces/representations, noting that they are restricted to specific representations such as the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer compares this limitation to other papers that can work with any finite-dimensional representation, suggesting that the current approach is not as general. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand the generality of their approach. While it highlights an area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. While it identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. The comment lacks concrete steps or examples of how to make the system more user-friendly or practical. As a result, the authors are left without a clear understanding of what changes or improvements are needed to address the complexity. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the complexity and potential restrictions of the system, providing a clear understanding of what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the complexity of practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that these complexities might restrict the practical usability of the system. The reasoning is based on general observations about real-world image editing tasks, which provides some context but not enough detail to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks comprehensive evidence or examples to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. This highlights a potential limitation of the system that could restrict its usability for typical users seeking simpler image adjustments. While the comment points out a relevant issue, it lacks specific suggestions or guidance on how the authors might address this complexity or simplify the process. The feedback is somewhat helpful as it raises an important consideration, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. While it identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process. The comment lacks concrete steps or examples of how to make the system more user-friendly or practical. As a result, the authors are left without a clear understanding of what changes or improvements are needed to address the complexity. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the complexity and potential restrictions of the system, providing a clear understanding of what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the complexity of practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that these complexities might restrict the practical usability of the system. The reasoning is based on general observations about real-world image editing tasks, which provides some context but not enough detail to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks comprehensive evidence or examples to fully support the assertion.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. This highlights a potential limitation of the system that could restrict its usability for typical users seeking simpler image adjustments. While the comment points out an important consideration, it lacks specific suggestions or guidance on how the authors might address this complexity or simplify the process. The feedback is somewhat helpful as it raises an important issue, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3.\", 'helpfulness_label"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the paper's contributions and lack of comparison with traditional classification or manifold learning literature. However, it does not provide explicit guidance or suggestions on how the authors might address these issues. The comment implies that the authors should consider expanding their contributions or comparing their technique with existing literature, but it lacks concrete steps or examples on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment critiques the paper's contributions and lack of comparison with traditional classification or manifold learning literature. However, it does not specify which part of the paper these issues are addressed in, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its critique of the contributions and lack of comparison, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper's contributions are not significant and lacks comparison with traditional classification or manifold learning literature. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification to fully support the assertion.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the paper's contributions, stating that they are not significant and lacks comparison with traditional classification or manifold learning literature. However, it does not provide specific suggestions or examples on how the authors might enhance their contributions or compare their technique with existing literature. This lack of actionable feedback limits the usefulness of the comment for the authors, as it does not offer concrete guidance on how to improve the draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide actionable steps for the authors to address it.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides references to existing works, such as [1] and [2], which discuss the impact of dataset size on accuracy and computation time. However, the comment does not explicitly instruct the authors to include this discussion or provide specific guidance on how to incorporate it into their paper. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the impact of the few-shot dataset for the sparsity ratio. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides references to existing works, [1] and [2], which discuss the impact of dataset size on accuracy and computation time. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the discussion or results sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, namely the impact of the few-shot dataset on sparsity ratio. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides references to existing works, [1] and [2], which discuss the impact of dataset size on accuracy and computation time. This provides some support for the claim, as it references relevant literature. However, the comment could be strengthened by elaborating on how these references specifically relate to the impact of few-shot datasets on sparsity ratio. Additionally, the comment could be more detailed by explaining why this discussion is important or how it could enhance the paper. Therefore, the claim is somewhat verifiable, as it provides a basis for the suggestion but lacks full detail and context.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that a discussion on the impact of the few-shot dataset for the sparsity ratio is necessary. It provides references to existing works, [1] and [2], which discuss the impact of dataset size on accuracy and computation time. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, namely the need for a discussion on the impact of the few-shot dataset on sparsity ratio. However, the comment could be more helpful if it provided specific guidance on how to incorporate this discussion or what aspects of the impact should be emphasized. Overall, the comment offers a direction for improvement but lacks depth and actionable details, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of explanation for keeping representations in the same hidden space and the absence of experimental verification to support this claim. While the comment identifies these gaps, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to provide a rationale and conduct experiments to support their claim, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed guidance on how to implement those improvements.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of explanation for keeping representations in the same hidden space and the absence of experimental verification to support this claim. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for both an explanation and experimental verification, but without grounding, the authors may struggle to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide an explanation for keeping representations in the same hidden space and that this has not been experimentally verified. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of explanation for keeping representations in the same hidden space and the absence of experimental verification to support this claim. This feedback is valuable as it highlights an area where the authors need to provide more detailed justification and evidence to strengthen their argument. However, the comment could be more helpful if it offered suggestions on how to address these gaps, such as proposing specific experiments or analyses that could be conducted to support the claim. Overall, the comment is somewhat helpful as it points out a critical weakness but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of sufficient novelty in the methodologies used, specifically mentioning the extension of Longitudinal Representation Learning as an extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer a significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors might address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should explore new methodologies or extensions to enhance the novelty of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of novelty in the methodologies used, specifically mentioning the extension of Longitudinal Representation Learning as an extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the methodology section. The comment is also specific because it clearly specifies the issue of lack of novelty and suggests that the approach does not offer a significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient novelty in its methodologies, specifically mentioning the extension of Longitudinal Representation Learning as an extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). The reviewer supports this claim by referencing existing works and suggesting that the approach does not offer a significant advancement beyond existing methods. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. The lack of specific details or references to the exact aspects of the methodologies that lack novelty makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks comprehensive evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of sufficient novelty in the methodologies used, specifically mentioning the extension of Longitudinal Representation Learning as an extension of Karwande et al. (2022) using Faster R-CNN (Ren et al., 2015). It suggests that this approach does not offer a significant advancement beyond existing methods, potentially limiting its contribution to the NLP community. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is somewhat helpful as it points out a critical weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate these approaches or why they should be considered. The comment lacks specificity and does not offer any concrete steps for improvement, leaving the authors without a clear understanding of what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the oversight of various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. However, it does not specify which part of the paper this oversight is in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the issue of keeping \\u0394t fixed and suggesting alternative approaches, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. However, the comment does not provide specific examples or references to these approaches, making it difficult for the authors to understand the basis of the claim. Without detailed examples or references, the authors may struggle to grasp the scope of the oversight and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant oversight in the paper by pointing out that it overlooks various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. This feedback is valuable as it highlights a potential gap in the literature that the authors may have overlooked. However, the comment does not provide specific suggestions or guidance on how the authors might incorporate these approaches or why they are relevant. While it alerts the authors to an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the paper overlooks various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate these approaches or why they should be considered. The comment lacks specificity and does not offer concrete steps for improvement, leaving the authors without a clear understanding of what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the oversight of various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. However, it does not specify which part of the paper this oversight is in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the issue of keeping \\u0394t fixed and suggesting alternative approaches, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper overlooks various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. However, it does not provide specific examples or references to these approaches, making it difficult for the authors to understand the basis of the claim. Without detailed examples or references, the authors may struggle to grasp the scope of the oversight and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some context but lacks sufficient evidence or justification.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant oversight in the paper by pointing out that it overlooks various SSM-based approaches that address the issue of keeping \\u0394t fixed, such as S5. This feedback is valuable as it highlights an important area for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might incorporate these approaches or why they are relevant. While it alerts the authors to an important oversight, the lack of actionable advice limits its"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues with the presentation and clarity of the paper. It explicitly points out that \"3 is presented as the underlying data generating mechanism which it isn\\'t,\" suggesting that the authors should clarify this point. It also recommends using \"causal graphs\" instead of \"label inference process\" when referring to the underlying system, and it highlights the difficulty in understanding definition 4 due to a lack of clarity on what graph should be considered for determining independencies. Additionally, it mentions the proof of Theorem, but does not provide specific guidance on how to improve it. While the comment identifies several areas for improvement, it lacks concrete suggestions on how to address these issues, making the feedback somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses three specific issues: the presentation of \"3\" as the underlying data generating mechanism, the use of \"causal graphs\" instead of \"label inference process,\" and the difficulty in understanding definition 4 due to a lack of clarity on what graph should be considered for determining independencies. It also mentions the proof of Theorem, but this is not explicitly grounded in the comment. While the authors can infer that these issues pertain to specific parts of the paper, such as the sections discussing the data generating mechanism, causal graphs, and definition 4, the comment does not explicitly mention these sections. Therefore, the comment is weakly grounded as it does not provide full grounding, but it is specific in detailing the issues. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several claims about the presentation and clarity of the paper. It claims that \"3 is presented as the underlying data generating mechanism which it isn\\'t,\" suggesting a misrepresentation. It also argues that it would be more standard to discuss causal graphs in the context of the underlying system, as shown in Fig. 2, rather than for the label inference process. Additionally, it points out that definition 4 is difficult to read due to a lack of clarity on what graph should be considered for determining independencies. While the reviewer provides some reasoning for these claims, such as the suggestion to use causal graphs and the difficulty in understanding definition 4, the comment lacks specific examples or references to fully substantiate the claims. Therefore, the comment is somewhat verifiable, as it provides some support but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several specific issues with the paper, including the misrepresentation of '3' as the underlying data generating mechanism, the suggestion to use causal graphs instead of the label inference process, and the difficulty in understanding definition 4 due to a lack of clarity on what graph should be considered for determining independencies. These points are clear and actionable, providing the authors with specific areas to address and improve upon. However, the comment could be more helpful if it offered suggestions on how to clarify these issues or provided examples of how to implement the suggested changes. Overall, the feedback is mostly helpful as it guides the authors in enhancing the clarity and accuracy of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. However, the comment does not provide explicit guidance on how to address this issue or what specific examples should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide more examples to justify the dual-free approach. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the circumstances and the suggestion to include more examples, but without explicit grounding, the authors may struggle to identify the exact context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it impacts the dual-free approach. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the circumstances under which evaluating the gradient of a conjugate function is expensive or infeasible. It suggests including more examples in machine learning to motivate the dual-free approach. While the comment identifies a potential area for improvement, it lacks specific guidance or examples on how to address this issue or what examples would be most effective. The feedback is somewhat helpful as it prompts the authors to consider additional context or examples, but it could be more actionable with more detailed suggestions or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of explanation regarding the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It explicitly requests the authors to provide an explanation for why the selection is made from the range [0, Pcj(0)]. This feedback is clear and direct, giving the authors a specific action to take: to include an explanation in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 3 of the Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of explanation regarding the selection of a probability for the appearance of an unobservable data point. The comment provides a clear request for an explanation, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the lack of explanation for the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It does not contain a subjective claim or opinion but rather seeks clarification on a specific aspect of the methodology. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors lack explanation, namely the selection of a probability for the appearance of an unobservable data point in the data approximation technique. It provides a clear and actionable suggestion for the authors to include an explanation for this choice. This feedback is valuable as it guides the authors to improve the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered additional context or suggestions on how to address the lack of explanation. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions, as these terms are referenced throughout the paper. While the comment implies that the authors should clarify these concepts, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide more detailed explanations, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (line 128 and line 168), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for a precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. This provides clear guidance on what the authors should focus on improving. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. This is a logical suggestion based on the observation that these terms are referenced throughout the paper. However, the comment does not provide specific examples or references to support the need for clarification, which makes it somewhat verifiable. The authors would need to infer the importance of this suggestion based on the reviewer\\'s observation, but the lack of detailed justification limits the level of verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing a more precise definition or informal description of the notion of the spectrum of distributions and their characteristic functions. This is a valuable suggestion as it highlights a potential gap in the clarity of the paper, which could be addressed to enhance the reader\\'s understanding. However, the comment does not offer specific guidance on how to define these concepts or what aspects of the definitions would be most beneficial. While it points out a relevant area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that the AIG-generation task is not convincing and recommends providing more background for readers unfamiliar with logic synthesis. Additionally, it suggests benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). These actions are clear and provide specific guidance on how the authors can improve their draft. The feedback is concrete and actionable, allowing the authors to directly address the issues and enhance the clarity and persuasiveness of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the AIG-generation task, suggesting that it is not convincing and recommending more background for readers unfamiliar with logic synthesis. It also suggests benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the AIG-generation task and the need for additional background information. The authors can infer that it relates to the methodology or results sections where the task is discussed. The comment is specific in detailing what needs to be addressed, such as providing more background and benchmarking the method. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the AIG-generation task is not convincing and suggests providing more background for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). The comment provides a logical reasoning for the need for additional background and benchmarking, as it suggests that these actions would enhance the credibility and comprehensiveness of the paper. However, the comment could be strengthened by providing specific examples or references to support the claim about the task being challenging or the need for additional background. Overall, the comment is mostly verifiable, as it offers a reasonable basis for the claims but lacks detailed examples or references to fully substantiate the reasoning.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the AIG-generation task, noting that it is not convincing and suggesting that more background should be provided for readers unfamiliar with logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to enhance the credibility of the work. This feedback is clear and actionable, providing the authors with specific steps to improve the clarity and persuasiveness of their draft. By addressing these points, the authors can enhance the comprehensiveness and impact of their paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some statements in the paper lack detail and analysis. However, it does not provide specific examples or guidance on which statements need more detail or analysis. Without explicit instructions or concrete suggestions, the authors are left without a clear understanding of what needs to be addressed or how to improve their draft. This lack of specificity and direction makes the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a general issue with the paper, stating that some statements lack detail and analysis. However, it does not specify which statements or sections are affected, making it difficult for the authors to pinpoint the exact parts of the paper that need attention. Without specific examples or references to sections, the comment is not grounded, and the authors cannot determine what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some statements in the paper lack detail and analysis, but it does not provide specific examples or reasoning to support this claim. Without detailed evidence or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a general issue with the paper, noting that some statements lack detail and analysis. However, it does not provide specific examples or guidance on which statements need more detail or analysis, nor does it suggest how the authors might address this issue. Without actionable feedback or detailed examples, the comment lacks the depth and specificity needed to be helpful. As a result, it is rated as barely helpful, as it provides a general direction but does not offer the authors a clear path to improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be more informative by comparing diffusion models with other generative models, such as VAE. It specifically mentions the unique features of diffusion models, like diffusion timesteps, and suggests that an analysis of how these differences affect feature learning would be valuable. While the comment implies that the authors should conduct such a comparison, it does not provide explicit instructions on how to perform this analysis or which specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the details of the comparison and analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing diffusion models with other generative models, such as VAE, and highlights the unique features of diffusion models, like diffusion timesteps. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in suggesting that an analysis of how these differences affect feature learning would be valuable, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be more informative by comparing diffusion models with other generative models, such as VAE. It highlights the unique features of diffusion models, like diffusion timesteps, and suggests that an analysis of how these differences affect feature learning would be valuable. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that such a comparison would be informative. This makes the claim somewhat verifiable, as the authors would need to infer the potential benefits of such a comparison themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the paper could be more informative by comparing diffusion models with other generative models, such as VAE. It highlights the unique features of diffusion models, like diffusion timesteps, and suggests that an analysis of how these differences affect feature learning would be valuable. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the depth and relevance of their work. By comparing diffusion models with other generative models, the authors could potentially gain insights into the strengths and limitations of their approach, which could lead to improvements in the paper. Therefore, the comment is rated as highly helpful, as it offers a clear and constructive suggestion for enhancing the draft.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues regarding the paper. The first comment questions the complementarity of the self-supervised tasks ICT and DaPI, noting that the effectiveness of DaPI, which doubles GPU memory usage, is not significant. The second comment points out that ICoL is proposed to mitigate memory issues and allow more negative instances, but there are no corresponding experiments to demonstrate the influence of the number of negatives. While the comments identify specific areas for improvement, they do not provide explicit guidance on how to address these issues. The authors are left to infer that they need to conduct additional experiments or provide more detailed analysis to support their claims. The feedback is somewhat actionable as it highlights areas for improvement but lacks concrete steps or suggestions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The review point addresses two specific issues: the complementarity of tasks ICT and DaPI in Table 4, and the lack of experiments demonstrating the influence of the number of negatives on performance with ICoL. The first comment is fully grounded as it explicitly mentions \"table 4,\" allowing the authors to accurately identify the part of the paper being addressed. The second comment is also fully grounded, as it references \"ICoL\" and \"negatives,\" providing clear guidance on what needs to be addressed. The comment is specific in detailing the issues with the effectiveness of DaPI and the need for experiments on the influence of the number of negatives. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two claims. The first claim questions the complementarity of the self-supervised tasks ICT and DaPI, noting that the effectiveness of DaPI, which doubles GPU memory usage, is not significant. The second claim questions the lack of experiments demonstrating the influence of the number of negatives on performance with ICoL, referencing the importance of negative instance quality over quantity as shown in TAS-B. While the claims are logical and based on common knowledge in the field, they lack specific references or detailed reasoning to fully substantiate the claims. The authors would need to conduct additional research or provide more detailed analysis to fully address these claims. Therefore, the claims are somewhat verifiable, as they provide a basis for the critique but require further elaboration.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper. First, it questions the complementarity of the self-supervised tasks ICT and DaPI, noting that the effectiveness of DaPI, which doubles GPU memory usage, is not significant. This observation suggests that the authors should provide a more detailed analysis or justification for the inclusion of DaPI. Second, the comment points out that ICoL is proposed to mitigate memory issues and allow more negative instances for better performance, but there are no corresponding experiments to demonstrate the influence of the number of negatives. This feedback is somewhat helpful as it highlights areas where the paper could be improved by providing additional experimental evidence. However, it could be more helpful if it offered suggestions on how to conduct these experiments or what specific results should be expected. Overall, the comment provides valuable insights but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 3 is unclear regarding the difference between the three plots on the same row and suggests that a caption should be added to clarify this. This feedback is clear and direct, providing a specific action for the authors to take to improve the clarity of their figure. The suggestion is concrete, as it specifies what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the lack of clarity in the difference between the three plots on the same row. The suggestion to add a caption to emphasize this difference provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is unclear regarding the difference between the three plots on the same row. The reviewer suggests that a caption should be added to clarify this. However, the comment does not provide specific examples or detailed reasoning to support why the current caption is insufficient or how the addition of a caption would improve clarity. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the exact nature of the issue and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is unclear what the difference is between the three plots on the same row. It suggests that adding a caption could help clarify this. This feedback is clear and actionable, as it provides a specific area for improvement and a clear direction for the authors to enhance the clarity of their figure. However, the comment could be more helpful if it offered additional suggestions or examples of how the caption could be structured to effectively communicate the differences. Overall, the comment is mostly helpful as it guides the authors in improving the clarity of their figure, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a deeper analysis of the computational complexity of GPSE, particularly when compared to complex hand-crafted PSEs and other encoding strategies. While the comment implies that the authors should conduct a more detailed examination of computational complexity, it does not provide specific guidance on how to approach this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a deeper analysis of the computational complexity of GPSE, particularly when compared to complex hand-crafted PSEs and other encoding strategies. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its suggestion to address the computational complexity, but without explicit references to sections or figures, the authors may struggle to pinpoint where this analysis should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a deeper analysis of the computational complexity of GPSE, particularly when compared to complex hand-crafted PSEs and other encoding strategies. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the authors should provide a deeper analysis of the computational complexity of GPSE, particularly when compared to complex hand-crafted PSEs and other encoding strategies. This feedback is valuable as it highlights a significant aspect of the paper that could be further explored to enhance its comprehensiveness and relevance. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this analysis or what aspects of computational complexity should be emphasized. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement but lacks detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a discrepancy in the reporting of results on the VQA dataset, suggesting that the results should be reported on the test-standard split instead of the test-dev split. It provides a clear and specific action for the authors to take, which is to correct the reporting of results on the VQA dataset. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1\" and \"VQA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reporting of results on the test-dev split, suggesting that the results should be reported on the test-standard split to avoid overfitting. The comment provides a clear and actionable suggestion for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results on the VQA dataset should be reported on the test-standard split instead of the test-dev split to avoid overfitting. The comment provides a logical reasoning by referencing the guidelines from the VQA dataset authors, which supports the claim. However, the comment could be strengthened by providing specific examples or references to illustrate the potential overfitting issue. Therefore, the claim is mostly verifiable, as it is well-supported but lacks detailed examples or references to fully substantiate the argument.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the reporting of results on the VQA dataset, noting that the results should be reported on the test-standard split rather than the test-dev split. It provides a clear rationale by referencing the guidelines from the VQA dataset authors, which helps the authors understand the importance of this distinction. The comment is actionable, as it directs the authors to make a specific change to improve the accuracy and reliability of their results. However, it could be more helpful if it included additional guidance on why this change is critical or how it might impact the overall interpretation of the results. Despite this, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how to choose the parameters $\\beta$, $\\alpha$, and $\\eta$ to guarantee a certain decision-making loss level while optimizing the Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide explicit guidance or concrete steps on how to address this issue, such as suggesting specific methods or parameters to consider. The action is implicit and somewhat vague, as the authors can infer that they need to manage the trade-off, but they are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of parameters ($\\beta$, $\\alpha$, and $\\eta$) and their impact on decision-making loss and Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the theoretical result. However, the comment does not specify which part of the paper this discussion pertains to, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the issue with controlling the term $T_i \\beta$, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss and Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the theoretical result. However, the comment does not provide any specific reasoning, examples, or references to support the claim that managing this trade-off is necessary or how it would improve the result. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of managing the trade-off themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss and Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment lacks specific guidance or actionable advice on how to manage this trade-off or which parameters to focus on. While it identifies an area for improvement, it does not provide detailed suggestions or examples that would help the authors address this issue effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for enhancement but lacks depth and specificity in its feedback.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss and Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the impact of the theoretical result. However, the comment does not provide explicit guidance or concrete steps on how to address this issue, such as suggesting specific methods or parameters to consider. The action is implicit and somewhat vague, as the authors can infer that they need to manage the trade-off, but they are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss and Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the theoretical result. However, the comment does not specify which part of the paper this discussion pertains to, making it weakly grounded. The authors might infer that it relates to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing the issue with controlling the term $T_i \\\\beta$, but it lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the choice of parameters ($\\\\beta$, $\\\\alpha$, and $\\\\eta$) and their impact on decision-making loss and Brier scores. It suggests that managing the trade-off between prediction accuracy and decision-loss would improve the theoretical result. However, the comment does not provide any specific reasoning, examples, or references to support the claim that managing this trade-off is necessary or how it would improve the result. The lack of detailed justification or evidence makes"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. It questions whether the methods are ready to be extended to non-fully connected architectures, implying that the authors should consider this limitation. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or explore the applicability of their methods to different architectures. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate the applicability of their methods to non-fully connected architectures. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the methods presented in the paper to more structured layers like convolutions, specifically mentioning the strength of being able to apply LBEN to convnets without much modification. However, it does not specify which part of the paper discusses this limitation, making it weakly grounded. The comment is specific in questioning the applicability of the methods to non-fully connected architectures, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. The comment questions whether the methods are ready to be extended to non-fully connected architectures, suggesting that the performance of the methods considerably trails that of MON. However, the comment lacks specific examples or references to support the claim about the limited applicability or the extent of the performance trail. This makes the claim somewhat verifiable, as the authors would need to further investigate the issue to fully understand and address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the limited applicability of the methods presented in the paper to more structured layers like convolutions, despite the strength of being able to apply LBEN to convnets without much modification. It questions whether the methods are ready to be extended to non-fully connected architectures, implying that the authors should consider this limitation. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or explore the applicability of their methods to different architectures. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to clarify how to evaluate the refactoring process and points out that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. While the comment implies that the authors should explore these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider the suggested metrics. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the refactoring process, suggesting that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark. However, it does not specify which part of the paper this evaluation is related to, making it weakly grounded. The comment is specific in suggesting alternative metrics, but without grounding, the authors may struggle to identify the exact section where this evaluation is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the current evaluation of the refactoring process is insufficient, specifically mentioning the use of a pass rate for unit tests as inadequate. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of the refactoring process, specifically noting that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that the authors could consider for their next benchmark, offering a clear direction for improvement. However, the comment could be more helpful if it explained why these metrics are more suitable or how they could be implemented. Overall, the feedback is mostly helpful as it highlights a specific area for enhancement and provides actionable suggestions, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the main contribution of the paper by stating that the Wiener deconvolution has already been proposed. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or what steps they could take to enhance the sufficiency of their main contribution. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main contribution of the paper by questioning the novelty of the Wiener deconvolution, which has already been proposed. However, it does not specify which part of the paper discusses the Wiener deconvolution or how it is being used, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in detailing what aspects of the main contribution are insufficient or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is not sufficient because the Wiener deconvolution has already been proposed. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the main contribution of the paper by questioning the novelty of the Wiener deconvolution, which has already been proposed. However, it does not provide any specific suggestions or guidance on how the authors might address this critique or enhance the sufficiency of their main contribution. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment critiques the main contribution of the paper by questioning the novelty of the Wiener deconvolution, which has already been proposed. However, it does not provide any explicit or implicit actions for the authors to take to address this critique or enhance the sufficiency of their main contribution. Without actionable guidance or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main contribution of the paper by questioning the novelty of the Wiener deconvolution, which has already been proposed. However, it does not specify which part of the paper discusses the Wiener deconvolution or how it is being used, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in detailing what aspects of the main contribution are insufficient or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is not sufficient because the Wiener deconvolution has already been proposed. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the main contribution of the paper by questioning the novelty of the Wiener deconvolution, which has already been proposed. However, it does not provide any specific suggestions or guidance on how the authors might address this critique or enhance the sufficiency of their main contribution. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment critiques the main contribution of the paper by questioning the novelty of the Wiener deconvolution, which has already been proposed. However, it does not provide any explicit or implicit actions for the authors to take to address this critique or enhance the sufficiency of their main contribution. Without actionable guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the main contribution of the paper by questioning the novelty of the Wiener deconvolution, which has already been proposed. However, it does not specify which part of the paper discusses the Wi"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues with the connection to spin glasses, specifically questioning how the regularization helps escaping local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. While the comment highlights specific areas that need clarification, it does not provide explicit guidance on how the authors should address these issues. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details what needs to be addressed, including the connection to spin glasses, the role of regularization, the effect on Parisi\\'s order parameter, and the role of temperature. This provides clear guidance on what aspects of the paper require further explanation or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the connection to spin glasses, specifically questioning the role of regularization in escaping local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. While the authors may infer that the connection is weak, the lack of explicit evidence or detailed explanation makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several critical areas where the paper could be improved, specifically regarding the connection to spin glasses. It highlights three main points that need clarification: the role of regularization in escaping local minima, the effect on Parisi\\'s order parameter, and the role of temperature in the proposed scheme. By pointing out these specific areas of weakness, the comment provides actionable feedback that can help the authors enhance their draft. However, the comment could be more helpful if it offered suggestions or examples on how to address these issues. Overall, the feedback is mostly helpful as it directs the authors to areas that need further development, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the authors\\' exploration of a self-training scheme but suggests that the contribution is relatively limited. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might enhance their contribution or what aspects of the self-training scheme could be further developed. The comment lacks explicit or concrete actions for the authors to take, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the self-training scheme, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this scheme is discussed in, making it weakly grounded. The comment is specific in its critique, noting that the contribution is relatively limited, but it does not provide detailed guidance on how the authors might enhance their contribution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the self-training scheme is a direct application and that the contribution is relatively limited. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the exploration of a self-training scheme but suggests that the contribution is relatively limited. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might enhance their contribution or what aspects of the self-training scheme could be further developed. The comment provides a general observation but does not offer actionable feedback or detailed insights that could help the authors improve their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in enhancing their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results shown in the paper are low-resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. This feedback is explicit and provides a clear action for the authors to take, which is to include higher-resolution images or zoomed-in regions to better demonstrate the quality of the results. The suggestion is concrete, as it specifies what should be included to improve the presentation of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results shown in the paper are low-resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the results section or figures that present the focal stack or all-in-focus images. This makes the comment weakly grounded, as the authors can make an educated guess but cannot pinpoint the exact part of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the need for higher-resolution images or zoomed-in regions to inspect the quality of the results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results shown in the paper are low-resolution and recommends providing zoomed-in regions of the rendered focal stack or all-in-focus images to inspect the quality. This is a subjective claim as it expresses an opinion about the quality of the results. However, it lacks specific examples or detailed reasoning to support why the results are low-resolution or how the suggested zoomed-in regions would improve the quality. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the results presented in the paper, noting that they are low-resolution. It provides a clear and actionable suggestion by recommending the inclusion of zoomed-in regions of the rendered focal stack or all-in-focus images to better inspect the quality of the results. This feedback is valuable as it guides the authors on how to improve the presentation and clarity of their results, making it highly helpful. However, the comment could be more helpful if it included specific examples or guidance on how to effectively present these zoomed-in regions. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for maximum benefit.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights two concerns regarding the comparative inference method: the significant increase in inference cost due to multiple forward passes, and the need for validation data for post-hoc calibration, which may not be readily available for open-ended generation tasks. While the comment identifies these issues, it does not provide explicit guidance on how the authors might address them. The authors are left to infer that they should consider alternative methods or strategies to mitigate these concerns, but the lack of concrete suggestions makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the comparative inference method, specifically mentioning the increase in inference cost due to multiple forward passes and the need for validation data for post-hoc calibration. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about computational cost and the availability of validation data, which helps the authors understand what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the comparative inference method increases the inference cost significantly due to multiple forward passes, which may be a concern for real-world applications. It also mentions that post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks, limiting the method's applicability. The claim is somewhat verifiable as it provides a logical reasoning for the inference cost increase and the need for validation data. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two significant concerns regarding the comparative inference method. It points out that the method increases the inference cost due to multiple forward passes, which could be a concern in real-world applications with limited computational resources. Additionally, it notes that post-hoc calibration requires validation data, which may not be readily available for open-ended generation tasks, limiting the method's applicability. While the comment highlights important issues, it does not provide specific suggestions or guidance on how the authors might address these concerns or improve the method. The feedback is somewhat helpful as it points out potential limitations but lacks actionable advice, leaving the authors to infer potential solutions on their own.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if exploding gradients are a problem, the authors should perform gradient clipping with a high value for the gradient norm to avoid NaNs appearing. It also questions the use of simply reinitializing the model as a solution, implying that gradient clipping is a more robust approach. The comment explicitly states the action to take (gradient clipping) and provides a clear rationale for why it is a better solution. This level of detail and specificity makes the action concrete and actionable, allowing the authors to directly address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of reinitializing the model as a solution to the problem of NaNs appearing due to exploding gradients. The reviewer suggests an alternative approach, gradient clipping, and provides a rationale for why it might be a better solution. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that if exploding gradients are a problem, the authors should perform gradient clipping with a high value for the gradient norm to avoid NaNs appearing. It questions the use of simply reinitializing the model as a solution, implying that gradient clipping is a more robust approach. While the comment provides a logical argument for using gradient clipping, it lacks specific examples or references to support the claim that gradient clipping is a better solution. This makes the claim somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the use of NaNs due to exploding gradients. It suggests a solution by recommending the use of gradient clipping with a high value for the gradient norm to avoid NaNs. This feedback is clear and actionable, providing the authors with a specific and effective way to address the problem. However, the comment could be more helpful if it included additional context or examples to further explain the issue and the benefits of gradient clipping. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests a more detailed explanation of the term \"common pattern.\" This is a clear and direct action for the authors to take, as it specifies what additional information is needed to clarify the concept. The comment provides a specific area for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"common pattern,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, a more detailed explanation of the term \"common pattern.\" This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the term \"common pattern,\" which is a factual question seeking additional explanation. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the meaning of the term \"common pattern.\" It requests a more detailed explanation, which is a clear and actionable suggestion for the authors to provide additional context or clarification. This feedback is valuable as it helps the authors to enhance the clarity and understanding of their work. However, the comment could be more helpful if it provided examples or further guidance on how to define or explain the term \"common pattern.\" Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, such as Twitter and Facebook. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to test the model\\'s generalizability. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not specify which part of the paper discusses the pre-trained model or the downstream datasets, making it weakly grounded. The comment is specific in questioning the generalizability of the model to datasets from other sources, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the generalizability of the pre-trained model to datasets from sources other than Reddit, specifically mentioning Twitter and Facebook. This is a valid point that the authors should consider, as it could impact the applicability of their findings. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what steps they could take to test the model's generalizability. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are left with a general understanding of the concern but without clear direction on how to improve their work. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the quality of the generated dataset, specifically mentioning the issue of LLM hallucinating. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting methods for quality checking or improving the dataset. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the quality of the generated dataset, specifically mentioning the issue of LLM hallucinating. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its concern about the quality of the dataset but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the quality of the generated dataset, specifically mentioning the issue of LLM hallucinating. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the dataset is of poor quality due to hallucinations. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the quality of the generated dataset, specifically mentioning the issue of LLM hallucinating. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the quality of their dataset. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it identifies a potential problem but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the meaningfulness of the comparison across the four models, specifically noting that only the wav2vec model is fine-tuned while the others are trained from scratch. The reviewer suggests that this might make the comparison less meaningful, as it is easy to predict that the fine-tuned model would perform best. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the comparison. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of model training on the comparison. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the comparison of four models, noting that only the wav2vec model is fine-tuned while the others are trained from scratch. This provides some grounding as it mentions a specific model and training method, allowing the authors to identify the part of the paper being discussed. However, the comment lacks specificity in terms of what aspects of the comparison might be less meaningful or how the authors could address this issue. It does not provide detailed guidance on how to improve the comparison or what specific aspects to consider. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the meaningfulness of the comparison across four models, noting that only the wav2vec model is fine-tuned while the others are trained from scratch. The reviewer suggests that this might make the comparison less meaningful, as it is easy to predict that the fine-tuned model would perform best. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of supporting evidence or references leaves the claim somewhat verifiable, as it requires the authors to infer the implications of the comparison. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the meaningfulness of the comparison across four models, noting that only the wav2vec model is fine-tuned while the others are trained from scratch. The reviewer suggests that this might make the comparison less meaningful, as it is easy to predict that the fine-tuned model would perform best. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve the comparison. The feedback is somewhat helpful as it points out a potential weakness in the study, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and could benefit from more examples, such as Figure 2. While the comment implies that additional examples would be helpful, it does not explicitly instruct the authors to include more examples or specify which parts of the paper need more detailed explanations. The action is implicit and somewhat vague, as the authors can infer the need for more examples but may not know exactly how to implement this suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions \"Figure 2,\" which provides a clear reference to a specific part of the paper, making it fully grounded. It also specifies that the paper is dense and suggests the inclusion of more examples to clarify the content. This feedback is specific as it identifies a particular area for improvement and provides a clear suggestion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is dense, even compared to other pure-math ML papers, and suggests that more examples, such as Figure 2, would help. However, the comment lacks specific reasoning or evidence to support why the paper is dense or how additional examples would address this issue. The mention of Figure 2 provides some context, but it does not explain how this figure relates to the density of the paper or why it would be beneficial. Therefore, the claim is somewhat verifiable, as it provides a general observation but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges that the paper is well-written but notes that it feels dense, even compared to other pure-math ML papers. It suggests that more examples, such as Figure 2, would help clarify and simplify the content. While the comment identifies a potential issue with the paper's density, it lacks specific guidance on how to address this concern or what additional examples might be beneficial. The suggestion to include more examples is a positive step, but the feedback could be more helpful if it provided more detailed advice or examples of what could be included. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the structure of the paper, noting that Section 4.2 starts with high-level intuition, while Section 4.1 does not. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to improve the structure of their paper. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a discrepancy in the structure of the paper, noting that Section 4.2 starts with high-level intuition, while Section 4.1 does not. However, it does not specify which part of Section 4.1 lacks high-level intuition, making it difficult for the authors to pinpoint the exact issue. The comment is specific in identifying the difference between the two sections, but it lacks full grounding as the authors cannot confidently determine the exact sections being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point compares the structure of two sections, noting that Section 4.2 starts with high-level intuition while Section 4.1 does not. However, the comment does not provide any reasoning, examples, or references to support why this structure is problematic or how it affects the paper\\'s clarity or effectiveness. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a discrepancy in the structure of the paper, noting that Section 4.2 starts with high-level intuition, while Section 4.1 does not. This observation could be helpful in guiding the authors to improve the organization and flow of their paper. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending the inclusion of high-level intuition in Section 4.1 or providing examples of how to achieve this. Without actionable advice, the comment provides some insight but does not fully support the authors in enhancing their draft. Therefore, it is rated as somewhat helpful, consistent with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide better representation by including the obtained permutation matrices in Figure 3(e)(j)(o) and introducing more discussions. While the comment implies that additional explanations or discussions are needed, it does not specify what aspects of the permutation matrices should be discussed or how these discussions should enhance the representation. The action is somewhat explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3(e)(j)(o)\", allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed by suggesting that more discussions should be introduced regarding the obtained permutation matrices. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more discussions should be introduced regarding the obtained permutation matrices in Figure 3(e)(j)(o). However, it does not provide any specific reasoning, examples, or references to support why these discussions are necessary or how they would enhance the representation. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more discussions should be introduced regarding the obtained permutation matrices in Figure 3(e)(j)(o). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by adding additional context or explanations. However, the comment could be more helpful if it offered suggestions on what aspects of the permutation matrices should be discussed or how these discussions could improve the representation. Despite this, the feedback is mostly helpful as it guides the authors toward a specific area for enhancement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for information about the crowd workers, including who they were, how they were recruited, and how they were trained. This request provides a clear and direct action for the authors to take, as it specifies what information is needed to improve the transparency and reproducibility of the study. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"crowd workers,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is needed, namely, details about who the crowd workers were, how they were recruited, and how they were trained. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information about the crowd workers, including their recruitment and training. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a request for additional information about the crowd workers, specifically asking for details on who they were, how they were recruited, and how they were trained. This feedback is valuable as it highlights a gap in the transparency and reproducibility of the study, which is crucial for ensuring the credibility of the results. By addressing this question, the authors can provide more context and potentially enhance the robustness of their findings. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or what specific details should be included. Overall, the comment is somewhat helpful as it identifies a gap in the paper but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It implies that the authors should consider the importance of human evaluations in validating their conclusions. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their evaluation methods. The action is implicit and somewhat vague, as the authors are left to infer that they need to emphasize the importance of human evaluations. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of weakly correlated human evaluations, specifically mentioning the correlation between automatic metrics and human evaluations. It highlights the potential limitations of automatic metrics in capturing the quality of simplifications and suggests that human evaluations are more important. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not explicit. The comment is specific in detailing the concern about the weak correlation and the importance of human evaluations, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the weak correlation between automatic metrics and human evaluations suggests that the automatic metrics may not fully capture the quality of the simplifications. This claim is somewhat verifiable as it provides a logical reasoning based on the observation of weak correlation. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It highlights the importance of human evaluations in validating the conclusions drawn from the study. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their evaluation methods. While it points out a critical area for improvement, the feedback could be more actionable and comprehensive to be considered highly helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to be more specific about the \"Chain of Reasoning\" section, particularly regarding line 276. This provides a clear and direct action for the authors to take, which is to enhance the clarity and specificity of this section. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Chain of Reasoning\" section and specifies the line number (276) where the authors need to be more specific. This provides clear guidance on where the authors should focus their attention for improvement, making it easy for the authors to identify the part of the paper being addressed. The comment is specific because it clearly identifies what needs to be addressed, namely the need for more specificity in the \"Chain of Reasoning\" section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for more specificity in the \"Chain of Reasoning\" section, particularly regarding line 276. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it directs the authors to be more specific about the \"Chain of Reasoning\" section, particularly regarding line 276. This feedback provides a clear and direct instruction for improvement, which is valuable for the authors to enhance the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to improve the specificity or provided examples of what constitutes a more detailed explanation. Despite this, the feedback is mostly helpful as it guides the authors toward a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a sample quality metric on the CARLA data, referencing the common metric of minADE or minMSD, which is computed by fixing a budget of samples. While the comment implies that the authors should add this metric, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to include a sample quality metric, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ability to perform \"hypothetical inference\" / planning,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the inclusion of a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that there should be a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. However, it does not provide specific reasoning or evidence to support why these metrics are necessary or how they would improve the analysis. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement by suggesting the inclusion of a sample quality metric on the CARLA data. It references common metrics like minADE or minMSD, which are computed by fixing a budget of samples. This feedback is somewhat helpful as it provides a specific suggestion for enhancing the analysis, but it could be more helpful if it included additional context or guidance on how to implement this metric or why it is important. The authors would benefit from this feedback by gaining insight into how to improve their data analysis and potentially enhance the performance of their model. However, the comment lacks depth and does not fully address the authors' needs for improving the draft, making it somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the authors should include a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. While the comment implies that the authors should add this metric, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to include a sample quality metric, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ability to perform \"hypothetical inference\" / planning,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the inclusion of a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that there should be a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. However, it does not provide specific reasoning or evidence to support why these metrics are necessary or how they would improve the analysis. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable, as it lacks sufficient evidence or explanation to support the claim.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors should include a sample quality metric on the CARLA data, referencing common metrics like minADE or minMSD. This is a specific and actionable suggestion that could enhance the analysis by providing a metric to evaluate the quality of the samples used in the study. However, the comment does not provide detailed guidance on how to implement this metric or why it is important, which limits its helpfulness. The authors would benefit from this feedback by gaining insight into how to improve their data analysis and potentially enhance the performance of their model. However, the lack of depth in the suggestion reduces its overall helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the authors should include a sample quality"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the assumption of having every constraint and its corresponding discriminator. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether this assumption is incorrect, how it could be addressed, or what steps should be taken to clarify this point. The comment lacks any actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of having every constraint and its corresponding discriminator. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. Additionally, the comment lacks specificity as it does not provide any context or details about the constraints or discriminators being discussed. Without clear grounding and specificity, the authors cannot effectively address the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the assumption of having every constraint and its corresponding discriminator. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the assumption of having every constraint and its corresponding discriminator. While it identifies a potential area for clarification, it does not provide any context, explanation, or suggestions on how the authors might address this issue or why it is important. Without additional guidance or context, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is barely helpful, as it lacks actionable insights or detailed suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss or even include the Wasserstein GAN (WGAN) as a baseline method, as it is the first instance of using Optimal Transport (OT) in GANs. While the comment implies that the authors should consider adding WGAN to their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include WGAN as a baseline. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests discussing or adding the Wasserstein GAN (WGAN) as a baseline method, referencing the first instance of using Optimal Transport (OT) in GANs. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or discussion. The authors can infer that it relates to the methodology or related work section, but this inference is not explicit. The comment is specific in its suggestion to discuss or include WGAN, but it lacks grounding as it does not pinpoint a specific section. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of Optimal Transport (OT) in GANs, specifically leveraging the Wasserstein Distance, was first introduced in the Wasserstein GAN paper (Arjovsky et al., ICML 2017). This claim is somewhat verifiable as it references a specific paper as the first instance of the method. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to verify the claim by examining the referenced paper or other relevant literature. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a valuable suggestion by pointing out the historical context of using Optimal Transport (OT) in GANs, specifically referencing the Wasserstein GAN paper (WGAN). This reference is important for the authors to acknowledge and potentially discuss in their work. The comment also suggests that including WGAN as a baseline method could be beneficial, as it is the first instance of using OT in GANs. This feedback is clear and actionable, offering a specific direction for the authors to enhance their draft by incorporating a relevant baseline method. However, the comment could be more helpful if it provided additional context or guidance on how to integrate WGAN into the discussion. Overall, the comment is mostly helpful as it directs the authors to an important historical reference and suggests a potential improvement to their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights the absence of related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It provides specific references (1 and 2) to relevant works that should be discussed. Additionally, the comment notes that the paper's preliminary results and issues with clarity and organization make it more suitable for presentation at a workshop. While the comment identifies areas for improvement, it does not explicitly instruct the authors to include these references or discuss the related work. The suggestion to discuss the related work is implicit and somewhat vague, as it does not provide detailed guidance on how to integrate this information into the paper. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific instructions on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment highlights the absence of related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It provides specific references (1 and 2) to relevant works that should be discussed. Additionally, it notes that the paper's preliminary results and issues with clarity and organization make it more suitable for presentation at a workshop. However, the comment does not specify which part of the paper is lacking this related work or how it should be integrated. While it mentions specific references, it does not provide detailed guidance on how to incorporate them into the paper. Therefore, the comment is weakly grounded as it does not identify a specific part of the paper, but it is specific in suggesting what needs to be addressed. This aligns with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper lacks discussion of related work on MCMC in discrete spaces and suggests that several methods have applied Langevin MCMC to sample discrete sequences. It provides specific references to support this claim, which are cited in the paper. Additionally, the comment notes that the paper's preliminary results and issues with clarity and organization make it more suitable for presentation at a workshop. The references provided offer a clear and detailed basis for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by noting the absence of related work on MCMC in discrete spaces. It provides specific references (1 and 2) to relevant works that should be discussed, which is a valuable suggestion for the authors to consider. Additionally, the comment acknowledges the paper's preliminary results and issues with clarity and organization, suggesting that it may be more suitable for presentation at a workshop. This feedback is clear and actionable, offering the authors a clear direction for improvement. However, it could be more helpful if it provided specific guidance on how to integrate the suggested references or address the issues with clarity and organization. Overall, the comment is mostly helpful, as it provides actionable feedback but could be more comprehensive.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions why DS-FedDRO and FedDRO use different methods to estimate $g$. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific actions the authors should consider, such as exploring the reasons behind the methodological differences or suggesting alternative approaches. Without actionable guidance, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions why DS-FedDRO and FedDRO use different methods to estimate $g$. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodological discussion. The authors may have an idea of where this question relates to, but the comment lacks explicit grounding. Additionally, the comment does not provide specific details on what aspects of the methods are different or why this is problematic. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions why DS-FedDRO and FedDRO use different methods to estimate $g$. However, it does not provide any reasoning, evidence, or references to support why this is a concern or why it should be addressed. The comment lacks any specific claims or examples that would help the authors understand the significance of this difference or how it might impact their work. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence for the authors to address the issue effectively.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about why DS-FedDRO and FedDRO use different methods to estimate $g$. While it identifies a potential area for exploration, it does not provide any further context, analysis, or suggestions on how the authors might address this issue or why it is significant. The comment lacks depth and actionable guidance, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it provides a starting point for the authors but does not fully support their efforts to enhance the draft.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a discussion about the difference between (6) in the paper and (6) in the work by Nicekl Kiela. However, it does not provide any explicit guidance or instructions on how to conduct this discussion or what specific aspects should be addressed. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly what needs to be done. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests a discussion about the difference between (6) in the paper and (6) in the work by Nicekl Kiela. However, it does not specify which part of the paper (6) appears, making it difficult for the authors to identify the exact section being addressed. The comment is specific in suggesting a discussion about the difference, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a discussion about the difference between (6) in the paper and (6) in the work by Nicekl Kiela. However, it does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a discussion about the difference between (6) in the paper and (6) in the work by Nicekl Kiela. However, it does not provide any context, explanation, or reasoning for why this discussion is necessary or how it would contribute to the paper. Without specific guidance or examples, the authors are left without actionable feedback on how to address this suggestion. The comment lacks depth and does not offer meaningful insights or suggestions for improvement, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the lack of variance analysis in the experiments and notes that the experiments were not conducted multiple times. However, it does not provide explicit guidance on how the authors should address this issue, such as suggesting specific methods for variance analysis or recommending the number of times the experiments should be repeated. The action is implicit and somewhat vague, as the authors can infer that they need to conduct multiple experiments and analyze variance, but the comment lacks concrete details on how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a concern about the lack of variance analysis in the experiments and notes that the experiments were not conducted multiple times. However, it does not specify which part of the paper discusses the experiments or the variance analysis, making it weakly grounded. The comment is specific in identifying the issue of variance analysis and the need for multiple experiments, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments were not conducted multiple times and lacks variance analysis for the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experiments, noting that they were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is clear and actionable, as it highlights a critical area for improvement in the experimental design and analysis. By pointing out the need for variance analysis and multiple runs, the comment provides the authors with a clear direction for enhancing the robustness and reliability of their results. However, the comment could be more helpful if it suggested specific methods or techniques for conducting variance analysis or multiple runs. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the experiments conducted in the paper and real-world datasets, specifically mentioning factors like differing dataset qualities and temporal drifts in data distributions. While the comment acknowledges the authors\\' recognition of these gaps, it does not provide explicit guidance or suggestions on how to address them. The authors are left to infer that they need to consider these factors in their experiments or discuss them in the paper, but the comment lacks concrete steps or examples. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a gap in the paper regarding the comparison between AL experiments and real-world datasets. It highlights specific factors, such as differing dataset qualities and temporal drifts in data distributions, that are not accounted for in the experiments. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the experimental section or discussion, but this inference is not explicit. The comment is specific in detailing the gaps between the experiments and real-world datasets, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not account for factors like differing dataset qualities and temporal drifts in data distributions, which are characteristic of real-world data. This claim is somewhat verifiable as it highlights specific issues that are relevant to the field of active learning. However, the comment lacks detailed examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's experimental design by highlighting the lack of consideration for factors like differing dataset qualities and temporal drifts in data distributions, which are characteristic of real-world data. This feedback is valuable as it points out an important limitation that the authors need to address to ensure the relevance and applicability of their findings. However, the comment could be more helpful if it provided suggestions on how to incorporate these factors into the experiments or discussed potential implications for the results. Overall, the comment is somewhat helpful as it directs the authors' attention to a critical area for improvement but lacks depth in actionable guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the communication cost provided in the paper, suggesting that it does not seem particularly low or noteworthy compared to other federated Q-learning algorithms. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their communication cost analysis. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the communication cost provided in the paper, specifically mentioning the complexity of O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper this critique pertains to, such as a particular section or table where the communication cost is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its critique of the communication cost, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy compared to other federated Q-learning algorithms, which have demonstrated that O(H) communication rounds are sufficient. However, the comment does not provide specific examples or references to these other algorithms or their communication costs. This lack of detailed evidence or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the communication cost provided in the paper, suggesting that it does not seem particularly low or noteworthy compared to other federated Q-learning algorithms. It references specific algorithms that have demonstrated more efficient communication costs. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their communication cost analysis. Without specific recommendations or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not provide actionable feedback for improvement.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment critiques the communication cost provided in the paper, suggesting that it does not seem particularly low or noteworthy compared to other federated Q-learning algorithms. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their communication cost analysis. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the communication cost provided in the paper, specifically mentioning the complexity of O(SAH^2) or O(MSAH^2). However, it does not specify which part of the paper this critique pertains to, such as a particular section or table where the communication cost is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its critique of the communication cost, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the communication cost provided in the paper (O(SAH^2) or O(MSAH^2)) is not particularly low or noteworthy, given that other federated Q-learning algorithms have demonstrated that O(H) communication rounds are sufficient. However, the comment lacks specific examples or references to these other algorithms or their communication costs, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or comparisons, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the communication cost provided in the paper, suggesting that it does not seem particularly low or noteworthy compared to other federated Q-learning algorithms. It references specific algorithms that have demonstrated more efficient communication costs, implying that the current communication cost is not as effective. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their communication cost analysis. Without specific recommendations or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not provide actionable feedback for improvement.\", 'helpfulness_label': '2'}{'action"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the main idea of using an ensemble of neural networks is common in machine learning literature and lacks specific adaptation to the homomorphic encryption domain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific adaptations could be made to the paper. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the main idea of using an ensemble of neural networks and its commonality in machine learning literature, noting that the paper does not provide specific adaptations to the homomorphic encryption domain. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in pointing out the lack of adaptation to the homomorphic encryption domain, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main idea of using an ensemble of neural networks is \"trivial and very common in machine learning literature,\" suggesting that the paper lacks specific adaptations to the homomorphic encryption domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a common issue in the literature, noting that the main idea of using an ensemble of neural networks is not unique and lacks specific adaptation to the homomorphic encryption domain. This feedback highlights a potential weakness in the paper's contribution and suggests that the authors may need to provide more detailed explanations or novel approaches to differentiate their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the paper's contribution. While it points out a critical area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding why and how the new model works better than the previous state-of-the-art, MH. While it identifies a specific area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details or actionable steps, such as recommending specific analyses or experiments to clarify the model\\'s performance. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of not understanding why and how the new model works better than the previous state-of-the-art, MH. This provides clear guidance on what the authors need to address in their discussion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the paper regarding why and how the new model works better than the previous state-of-the-art, MH. However, it does not provide any specific evidence, examples, or references to support this claim. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the paper\\'s discussion on the new model\\'s improvements over the previous state-of-the-art, MH. It highlights the need for a more detailed explanation of why and how the new model works better. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional analyses or comparisons. While it points out a critical area for improvement, the feedback is somewhat helpful as it provides a direction for the authors to enhance their draft but does not fully guide them in implementing the changes. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reasonableness of the formula used in the Adjective Projection part. It suggests that the authors should calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, and calculate the difference between the two similarities instead of using the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. This feedback provides a clear and explicit action for the authors to take, as it suggests a specific change to the formula. The comment also offers concrete guidance on how to implement this change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the formula, suggesting that the authors should calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, and calculate the difference between the two similarities instead of using the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. This provides clear guidance on how to improve the formula, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reasonableness of a formula used in the Adjective Projection part. It suggests an alternative method for estimating whether an object is large or small, which involves calculating the similarity between \"large\" and the object, then \"small\" and the object, and calculating the difference between the two similarities instead of using the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. While the comment provides a logical reasoning for the alternative approach, it lacks specific references or examples to fully substantiate the claim. The suggestion is mostly verifiable as it offers a clear rationale for the proposed change, but it could be strengthened with additional evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the formula used in the Adjective Projection part of the paper. It suggests a more reasonable approach by proposing to calculate the similarity between \"large\" and the object, then \"small\" and the object, respectively, and calculate the difference between the two similarities instead of using the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. This feedback is clear and actionable, providing the authors with a specific and logical suggestion for improvement. By following this advice, the authors can enhance the clarity and effectiveness of their method. However, the comment could be more helpful if it included a detailed explanation of why the suggested approach is more reasonable or if it provided additional context on how this change might impact the results. Overall, the comment is mostly helpful, as it offers a clear direction for improvement, but it could be further enhanced with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \\u03c7_k = sigmoid(\\u03c7_k) in line 121, suggesting that the authors clarify this. It also provides a positive comment about the method\\'s ability to capture long-range context information for computer vision tasks. However, the comment does not explicitly instruct the authors to address the issues mentioned above or provide specific guidance on how to elaborate on them. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation and elaborate on the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 121,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \\u03c7_k = sigmoid(\\u03c7_k) and suggests that the authors elaborate on the issues mentioned above. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the notation \\u03c7_k = sigmoid(\\u03c7_k) in line 121, suggesting that \\u03c7_k appears on both sides, which is unclear. The reviewer also finds the proposed method interesting for its ability to capture long-range context information in computer vision tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim about the method\\'s interest or the need for clarification. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment, making it difficult to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the notation \\u03c7_k = sigmoid(\\u03c7_k) in line 121, suggesting that \\u03c7_k appears on both sides, which is unclear. This provides a clear and actionable suggestion for the authors to clarify the notation. Additionally, the comment expresses interest in the method\\'s ability to capture long-range context information for computer vision tasks, which is a positive observation. However, the comment could be more helpful if it elaborated on the issues mentioned above or provided specific suggestions for elaboration. Overall, the comment is mostly helpful as it identifies a specific area for clarification and offers a positive comment, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2]. While the comment implies that the authors should include these references in their discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these references in their comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2]. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or discussion. The authors can infer that it relates to the section where the advantage of any-resolution generation is discussed, but this inference is not explicit. The comment is specific in suggesting a comparison to recent works, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2]. This claim is somewhat verifiable as it provides references to specific works that the authors could compare their approach to. However, the comment lacks detailed reasoning or analysis on why these comparisons are necessary or how they would enhance the paper. The authors would need to conduct additional research or analysis to fully understand the implications of these comparisons, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should discuss and compare their work to more recent works on any-resolution image generation, specifically mentioning [1] and [2]. This feedback is somewhat helpful as it provides a clear direction for the authors to enhance their paper by including relevant comparisons. However, the comment could be more helpful if it explained why these comparisons are important or how they would benefit the paper. Additionally, the comment does not offer specific guidance on how to integrate these references or what aspects of the comparison should be emphasized. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the overfitting issue in the CT experiment due to the small test set size and suggests that Section 6 does not sufficiently describe the limitations of the work. It also requests the authors to discuss limitations, such as theoretical assumptions and implementation considerations. Additionally, it questions the relative improvement of ODER over RED alternatives and asks for a comparison of training times. While the comment identifies specific areas for improvement and provides some guidance, it does not explicitly instruct the authors to make these changes or provide detailed suggestions on how to address them. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of overfitting in the CT experiment due to the small test set size and suggests that Section 6 does not sufficiently describe the limitations of the work. Additionally, it raises questions about the limitations of the approach, such as theoretical assumptions and implementation considerations, and asks for a discussion of the relative improvement of ODER over RED alternatives. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the overfitting issue in the CT experiment due to the small test set size and suggests that Section 6 does not sufficiently describe the limitations of the work. It also questions the relative improvement of ODER over RED alternatives and asks for a comparison of training times. While the comment identifies potential issues and areas for improvement, it lacks specific examples or references to support the claim of overfitting or the limitations of the work. The suggestion to discuss theoretical assumptions and implementation considerations is a logical extension of the critique but remains somewhat vague without detailed examples or references. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks comprehensive evidence or examples to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with overfitting in the CT experiment due to the small test set size and suggests that Section 6 does not sufficiently describe the limitations of the work. It requests the authors to discuss limitations, such as theoretical assumptions and implementation considerations, which is a valuable suggestion for improving the transparency and robustness of the work. Additionally, the comment questions the relative improvement of ODER over RED alternatives and asks for a comparison of training times, which is another area that could enhance the paper's analysis. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions or examples for addressing these issues. Overall, the comment is mostly helpful as it guides the authors towards improving the clarity and depth of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific error in the text, noting that the bound on the 2-Wasserstein is incorrectly stated as $O(\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This comment provides a clear and explicit action for the authors to correct the error by revising the text to accurately reflect the bound. The feedback is concrete, as it specifies the exact line where the error occurs and what needs to be changed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the line numbers (216 and 217) where the error is said to occur, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, which is the incorrect representation of the bound on the 2-Wasserstein as $O(\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific error in the text regarding the bound on the 2-Wasserstein, stating that it is incorrectly represented as $O(\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This is a factual observation that does not require any supporting evidence or reasoning. It is a straightforward correction of a mathematical error, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific error in the text regarding the bound on the 2-Wasserstein, noting that it is incorrectly stated as $O(\\epsilon^2)$ instead of the correct bound on the 2-Wasserstein squared. This feedback is clear and actionable, as it provides a direct correction that the authors can apply to improve the accuracy of their draft. By addressing this error, the authors can enhance the clarity and correctness of their work. However, the comment could be more helpful if it explained the significance of this correction or provided additional context on why it is important. Overall, the comment is mostly helpful as it guides the authors towards a specific improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, such as IEConv and CDConv. It also mentions ProNet, which provides hierarchical representations for proteins. The comment does not provide explicit guidance on how the authors should address this question or what specific aspects of the proposed method need to be clarified or improved. The action is implicit and vague, as the authors are left to infer that they need to provide a detailed comparison and explanation of their method in relation to these existing methods. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, such as IEConv and CDConv. It also mentions ProNet, which provides hierarchical representations for proteins. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the comparison section or the methodology, but this is not explicit. The comment is specific in asking for clarification on the differences between the proposed method and existing methods, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, such as IEConv and CDConv. It references specific works, including [1] Intrinsic-Extrinsic Convolution and Pooling for Learning on 3D Protein Structures, [2] Learning from Protein Structure with Geometric Vector Perceptrons, [3] Equivariant Graph Neural Networks for 3D Macromolecular Structure, [4] Protein Representation Learning by Geometric Structure Pretraining, [5] Learning Hierarchical Protein Representations via Complete 3D Graph Networks, and [6] Continuous-Discrete Convolution for Geometry-Sequence Modeling in Proteins. By providing references to these works, the comment offers a basis for comparison and allows the authors to understand the context and potential differences between their method and existing approaches. However, the comment does not provide detailed reasoning or analysis to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is mostly verifiable, as it provides a strong foundation for the claim but lacks full detail.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a question about the differences between the proposed multi-scale hierarchical predictor and other methods, such as IEConv and CDConv. It also mentions ProNet, which provides hierarchical representations for proteins. The comment is somewhat helpful as it prompts the authors to clarify the unique aspects of their method compared to existing approaches. However, it lacks specific guidance on how to address this question or what aspects of the proposed method need to be emphasized. The authors are left to infer that they need to provide a detailed comparison and explanation of their method in relation to these existing methods. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but does not fully guide the authors in making the necessary enhancements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper does not read well and needs more careful proofreading. However, it does not provide specific guidance on what aspects of the writing are unclear or need improvement, nor does it suggest how the authors might address these issues. Without actionable details or suggestions, the authors are left without a clear understanding of what changes are necessary to improve the readability of the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the paper does not read well and needs more careful proofreading. However, it does not specify which sections or parts of the paper are problematic, making it difficult for the authors to identify the exact areas that need attention. Without specific guidance or examples, the authors cannot effectively address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper does not read well and needs more careful proofreading. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed feedback or references, the authors are left without a clear understanding of what aspects of the writing are unclear or need improvement. This lack of detail makes the claim unverifiable, as it does not provide the necessary information for the authors to address the issue effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a general issue with the readability of the paper, stating that more careful proofreading is needed. However, it lacks specificity and does not provide any guidance on what aspects of the writing are unclear or need improvement. Without actionable feedback or detailed suggestions, the authors are left without a clear understanding of how to address the issue. This makes the comment barely helpful, as it provides a general direction but does not offer the depth or specificity needed for effective improvement. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several actions for the authors to consider. First, it recommends analyzing the distribution of addressing coefficients (Betas) with and without a bias towards sequential addressing, which is crucial for understanding the synthetic task. It also points out the lack of mention of the trade-off parameter (Theta) and questions its selection. Additionally, it suggests comparing the performance of a baseline that uses attention from the previous question instead of soft attention. These suggestions are explicit and provide clear guidance on what the authors should address to improve their draft. The feedback is concrete, as it outlines specific areas for analysis and comparison, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests several specific areas for improvement, including analyzing the distribution of addressing coefficients (Betas) with and without a bias towards sequential addressing, mentioning the value of the trade-off parameter (Theta), and comparing the performance of a baseline that uses attention from the previous question instead of soft attention. However, it does not specify which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests several areas for improvement, including analyzing the distribution of addressing coefficients (Betas) with and without a bias towards sequential addressing, mentioning the value of the trade-off parameter (Theta), and comparing the performance of a baseline that uses attention from the previous question instead of soft attention. While the comment provides a logical basis for these suggestions, it lacks specific examples or references to support the claim that these aspects are crucial for the synthetic task. The reasoning is somewhat verifiable, as it highlights potential areas for improvement, but it could be strengthened with more detailed justification or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, including the need for analysis of the distribution of addressing coefficients (Betas) with and without a bias towards sequential addressing, which is crucial for understanding the synthetic task. It also points out the lack of mention of the trade-off parameter (Theta) and questions its selection. Additionally, the comment suggests comparing the performance of a baseline that uses attention from the previous question instead of soft attention. These suggestions are clear and actionable, providing the authors with specific areas to focus on for enhancing their draft. The feedback is detailed and constructive, offering valuable insights that can significantly improve the paper. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for such a proposition. It also expresses personal opinion about the value of the mathematical content and its relevance to the paper\\'s main points. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the necessity of Proposition 1, questioning its relevance to the paper. It suggests that the application of standard concentration inequalities is expected in a regression problem and questions the value of the mathematical content. However, the comment does not specify which part of the paper this proposition is found in, making it weakly grounded. The feedback is specific in its critique of the mathematical content and its relevance to the paper\\'s main points, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for such a proposition. The reviewer also expresses personal opinion about the value of the mathematical content and its relevance to the paper. However, the comment lacks specific examples or references to support the claim that the mathematical content is unnecessary or decorative. While the reviewer provides a logical argument based on the nature of the problem, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for such a proposition. It also expresses personal opinion about the value of the mathematical content and its relevance to the paper's main points. While the comment identifies a potential issue with the paper's presentation, it lacks specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it prompts the authors to reconsider the inclusion of certain mathematical content, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for such a proposition. It also expresses personal opinion about the value of the mathematical content and its relevance to the paper's main points. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to the critique. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for such a proposition. It also expresses personal opinion about the value of the mathematical content and its relevance to the paper\\'s main points. However, the comment does not specify which part of the paper this proposition is found in, making it weakly grounded. The feedback is specific in its critique of the mathematical content and its relevance to the paper, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for such a proposition. The reviewer also expresses personal opinion about the value of the mathematical content and its relevance to the paper's main points. However, the comment lacks specific examples or references to support the claim that the mathematical content is unnecessary or decorative. While the reviewer provides a logical argument based on the nature of the problem, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the necessity of Proposition 1, suggesting that it is a standard regression problem and questioning the need for such a proposition. It also expresses personal opinion about the value of the mathematical content and its relevance to the paper's main points. While the comment identifies a potential issue with the paper's presentation, it lacks specific suggestions"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the evaluation of defense techniques, specifically mentioning the need to evaluate defense methods that rely on input perturbation in backdooring classification. It provides specific references to relevant works by Doan et al. (ICCV 2021) and (NeurIPS 2021), suggesting that the authors should include these evaluations to enhance the comprehensiveness of their understanding of the attacks. This feedback is explicit and provides concrete guidance on what the authors should include in their evaluation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a limitation in the evaluation of defense techniques, specifically mentioning the need to evaluate defense methods that rely on input perturbation in backdooring classification. It provides specific references to relevant works by Doan et al. (ICCV 2021) and (NeurIPS 2021), suggesting that the authors should include these evaluations to enhance the comprehensiveness of their understanding of the attacks. This feedback is fully grounded as it explicitly mentions the sections or references that need to be addressed, providing clear guidance on what the authors should include. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of defense techniques is limited, particularly in the context of backdooring classification. It suggests that evaluating defense methods relying on input perturbation is essential for a comprehensive understanding of the attacks. The comment provides specific references to relevant works by Doan et al. (ICCV 2021) and (NeurIPS 2021), which supports the claim by offering examples of existing research in the field. This provides a clear and logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the suggested evaluations would enhance the paper\\'s comprehensiveness. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the evaluation of defense techniques, specifically mentioning the need to evaluate defense methods that rely on input perturbation in backdooring classification. It provides specific references to relevant works by Doan et al. (ICCV 2021) and (NeurIPS 2021), suggesting that the authors should include these evaluations to enhance the comprehensiveness of their understanding of the attacks. This feedback is clear and actionable, offering the authors a concrete direction for improving their evaluation and analysis. By addressing this limitation, the authors can provide a more robust and comprehensive understanding of the attacks, which is beneficial for the overall quality of the paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. Additionally, it recommends that the context and evidence-based methods be more thoroughly presented. While the comment provides specific areas for improvement, it does not explicitly instruct the authors on how to achieve these changes or what specific datasets or methods should be included. The actions are implicit and somewhat vague, as the authors need to infer the details of the improvements needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the related work section, specifically mentioning the need for a more focused section that includes descriptions of similar datasets for non-English or underrepresented languages. It also notes that the context and evidence-based methods are presented shallowly. However, the comment does not specify which part of the paper the related work section is located in, making it weakly grounded. The feedback is specific in identifying areas for improvement, such as the need for a more focused related work section and a deeper discussion of context and evidence-based methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. It also notes that the context and evidence-based methods are presented shallowly. While the comment provides a clear suggestion for improvement, it lacks specific examples or references to support the claim that the related work section is too broad or shallow. This makes the claim somewhat verifiable, as the authors would need to infer the extent of the issues based on their own understanding of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas for improvement in the paper: the related work section and the presentation of context and evidence-based methods. It suggests that the related work section should be more focused and include descriptions of similar datasets for non-English or underrepresented languages. Additionally, it recommends that the context and evidence-based methods be more thoroughly presented. While the comment provides clear areas for improvement, it lacks detailed guidance on how to achieve these enhancements or specific examples of what should be included. This makes the feedback somewhat helpful, as it offers direction but could be more comprehensive with additional details or suggestions. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution operations. It highlights a discrepancy in the experimental results presented in Table 2, where it shows that BN before ReLU can hurt performance. The reviewer questions the authors\\' claim that BN can be folded into convolution operations, particularly regarding the folding of BN after ReLU into the next Conv op. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their argument. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed explanation or justification for their claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution operations, particularly regarding the folding of BN after ReLU into the next Conv op. The comment highlights a discrepancy in the experimental results presented in Table 2, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the authors\\' argument regarding the folding of Batch Normalization (BN) into convolution operations. It highlights a discrepancy in the experimental results presented in Table 2, where it shows that BN before ReLU can hurt performance. The reviewer questions the authors\\' claim that BN can be folded into convolution operations, particularly regarding the folding of BN after ReLU into the next Conv op. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim or challenge the authors\\' argument. This makes the claim somewhat verifiable, as the authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the authors' argument regarding the folding of Batch Normalization (BN) into convolution operations. It highlights a discrepancy in the experimental results presented in Table 2, where it shows that BN before ReLU can hurt performance. The reviewer questions the authors' claim that BN can be folded into convolution operations, particularly regarding the folding of BN after ReLU into the next Conv op. This feedback is somewhat helpful as it identifies a potential weakness in the authors' argument and prompts them to clarify or justify their claim. However, the comment could be more helpful if it provided specific suggestions or examples on how the authors might address this issue or strengthen their argument. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of large-scale experiments in the paper, noting that the models used in the experiments are quite small. It suggests that including experiments with varying network sizes would be beneficial, as it could demonstrate whether the results from the small-scale experiments extend to larger scale experiments. While the comment implies that the authors should conduct these experiments, it does not provide explicit instructions on how to implement them or what specific results to expect. The action is implicit but concrete, as the authors know what kind of experiments to perform to address the issue. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experiments section\" and specifies the issue with the small scale of the experiments, particularly the number of hidden neurons and the convolutional layer channels used in the MNIST and SVHN experiments. This provides clear guidance on where the authors should focus their attention to address the issue. The comment is also specific because it clearly outlines the need for experiments that vary the size of the network and demonstrate the scalability of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are lacking in scale, specifically mentioning the small number of hidden neurons and the single convolutional layer with 40 channels. The reviewer suggests that including experiments with varying network sizes would be beneficial to demonstrate the scalability of the results. While the comment provides a logical argument for the need for larger-scale experiments, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the need for larger-scale experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the lack of large-scale experiments. It points out that the models used in the experiments are quite small, suggesting that including experiments with varying network sizes would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by conducting larger-scale experiments. However, the comment could be more helpful if it offered suggestions on how to design these larger-scale experiments or what results to expect. Overall, the comment is mostly helpful as it guides the authors towards a meaningful enhancement of their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the behavior of the problem when W is the identity matrix and how it compares with prior work. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific aspects of the problem or results should be addressed or how to compare them with prior work. Without actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the behavior of the problem when W is the identity matrix and how it compares with prior work. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the problem or results should be addressed or compared with prior work. Without clear grounding or detailed guidance, the authors cannot effectively respond to the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the behavior of the problem when W is the identity matrix and how it compares with prior work. However, it does not provide any supporting evidence, reasoning, or references to justify the claim or suggest why this is a significant issue. The comment lacks depth and does not offer any specific examples or references to help the authors understand the context or importance of the question. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the question effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the behavior of the problem when W is the identity matrix and how it compares with prior work. While it identifies a potential area for exploration, it does not provide any specific guidance or suggestions on how the authors might address this question or what aspects of the problem should be considered. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not offer sufficient guidance for the authors to effectively enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work primarily focuses on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might expand their work to address the broader application scope or what specific changes could be made to achieve this. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the work, specifically that it focuses on CO problems on graphs rather than general MILP or QUBO problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in pointing out the limitation but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work focuses mainly on CO problems on graphs, limiting its application scope to general MILP or QUBO problems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the work, specifically noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. This feedback highlights an area where the authors could expand their work to increase its applicability. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or what additional aspects they could explore. While it points out a potential area for improvement, it does not provide actionable advice or detailed recommendations, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that learning both low- and high-frequency information in balance is not novel and mentions several related works that have been published. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of their work need improvement. Without actionable steps or suggestions, the authors are left without a clear understanding of how to respond to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of learning both low- and high-frequency information in balance, referencing several related works. However, it does not specify which part of the paper this critique pertains to, such as the introduction or discussion section, making it weakly grounded. The comment is specific in identifying the lack of analysis or comparison to these related works, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that learning both low- and high-frequency information in balance is not novel and references several related works. However, the comment does not provide specific examples or detailed reasoning to support why these works are relevant or how they differ from the current study. The references are not fully integrated into the critique, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential lack of novelty in the paper\\'s approach to learning both low- and high-frequency information in balance, referencing several related works. However, it does not provide specific feedback on how the authors might address this issue or improve their work. The comment lacks actionable guidance or suggestions for the authors to enhance their draft, making it barely helpful. While it highlights a potential area for improvement, it does not offer the authors a clear path forward, leaving them without a comprehensive understanding of how to address the critique. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the compression bandwidth of PC+IDF should be compared with IDF in Section 5. However, it does not provide any explicit instructions or guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should perform a comparison and determine the details themselves. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests a comparison between the compression bandwidth of PC+IDF and IDF, specifically in Section 5. However, it does not specify which part of Section 5 is being addressed, making it weakly grounded. The comment is specific in its suggestion to compare the compression bandwidth of PC+IDF with IDF, but without explicit references to Section 5, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a comparison between the compression bandwidth of PC+IDF and IDF, specifically in Section 5. However, it does not provide any reasoning, evidence, or references to support why this comparison is necessary or how it would enhance the paper. Without such justification, the claim is not verifiable, as it lacks the necessary context or explanation for the authors to understand the significance of the suggested comparison. Therefore, the comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific comparison between the compression bandwidth of PC+IDF and IDF, specifically in Section 5. While this is a clear and actionable suggestion, it lacks context or explanation as to why this comparison is important or how it could enhance the paper. The comment does not provide any additional guidance or suggestions for how the authors might conduct this comparison or what specific aspects to focus on. As a result, the feedback is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in implementing it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names such as Desc-ind/seq, Eg-ind, and Demo-ind/seq. While the comment explicitly states what the authors should do, it does not provide detailed guidance on why these names are misleading or how the proposed names would be more appropriate. The action is clear, but the lack of specific reasoning or examples makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model names T5-ind and T5-seq, suggesting that they are misleading and proposing alternative names. However, it does not specify which part of the paper these model names are mentioned in, making it difficult for the authors to pinpoint the exact location. The comment is specific in its suggestion for alternative names, but the lack of grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model names T5-ind and T5-seq are misleading and proposes alternative names. However, the comment does not provide any reasoning or evidence to support why these names are misleading or why the proposed names are more appropriate. Without specific justification or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model names T5-ind and T5-seq, suggesting that they are misleading. It proposes alternative names such as Desc-ind/seq, Eg-ind, and Demo-ind/seq. This feedback is clear and actionable, as it provides specific suggestions for improving the clarity of the model names. However, the comment could be more helpful if it explained why the current names are misleading or how the proposed names would enhance understanding. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of acronym \"AR\" for \"artificial intelligence\" and mentions its repeated use in line 055. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the acronym should be changed, why it was chosen, or how it should be addressed. The comment lacks actionable information, leaving the authors uncertain about what steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of acronym \"AR\" for \"artificial intelligence\" and its repeated use in line 055. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. The authors may infer that it relates to the introduction or methodology, but this inference is not explicit. The comment is specific in questioning the choice of acronym and its repetition, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the choice of acronym \"AR\" for \"artificial intelligence\" and its repeated use in line 055. However, it does not provide any reasoning, evidence, or context to support why this choice is problematic or why it should be changed. The comment lacks any supporting information or justification, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of acronym \"AR\" for \"artificial intelligence\" and its repeated use in line 055. While it identifies a potential issue with the consistency of terminology, it does not provide any further context, reasoning, or suggestions for improvement. The comment lacks actionable feedback or guidance on how the authors might address this issue or why it is problematic. As a result, the comment is not helpful, as it does not offer the authors any insights or steps to improve their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the motivation for the gating design in the paper and notes that the gating mechanism is not a new concept in multi-task learning (MTL). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these concerns or improve the clarity of their motivation. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the motivation behind the gating design for multi-task learning (MTL) and questions the novelty of the gating mechanism. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure. The authors might infer that it relates to the introduction or methodology, but this inference is not explicit. The comment is specific in its critique of the gating mechanism being a \"not a new story\" in MTL, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for the gating design in multi-task learning (MTL) is not clear and that the gating mechanism is not a new concept. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity in the motivation for the gating design in multi-task learning (MTL). It points out that the gating mechanism is not a new concept in MTL, suggesting that the paper may not offer a novel contribution. However, the comment does not provide any actionable feedback or suggestions on how the authors might address this issue or improve the clarity of their motivation. Without specific guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it highlights a potential weakness but lacks actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might modify their approach or what specific steps they could take to mitigate these assumptions. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the practical scenarios in which learning to defer is preferable and details how it is expected to behave. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the issue of strong assumptions required for training, such as the availability of ground truth and DM\\'s decisions for each DM of interest. This provides some clarity on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. However, the comment does not provide specific examples or references to support the claim that these assumptions are problematic or how they might affect the model\\'s performance. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the practicality of learning to defer, noting that it is heavily impaired by strong assumptions required for training, such as the availability of ground truth and decisions from each decision maker (DM) of interest. This feedback is somewhat helpful as it highlights an important consideration for the authors to address in their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might mitigate these assumptions or address the issue. Without actionable advice or detailed insights, the comment provides only a partial benefit to the authors. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental part is less convincing due to the use of weak baselines like LR and SVM compared to deep learning approaches. However, it does not provide specific guidance on how to improve the experimental setup or what alternative baselines should be used. The action is implicit and vague, as the authors are left to infer that they need to strengthen their experimental results by using more robust baselines. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the experimental part of the paper, specifically mentioning the use of LR and SVM as weak baselines compared to deep learning approaches. However, it does not specify which part of the paper this critique pertains to, such as a particular section or table where these baselines are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs improvement. The comment is specific in its critique of the baselines, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental part is less convincing due to the use of weak baselines like LR and SVM compared to deep learning approaches. However, the comment does not provide specific examples or detailed reasoning to support why these baselines are considered weak or how they impact the overall validity of the experimental results. Without additional context or evidence, the claim lacks sufficient justification, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental part of the paper, specifically noting that the use of LR and SVM as baselines is weak compared to deep learning approaches. This feedback is somewhat helpful as it points out a potential area for improvement in the experimental setup. However, the comment lacks specificity and does not provide detailed guidance on how to strengthen the experimental part or what specific deep learning approaches could be used as more robust baselines. Without actionable suggestions or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper\\'s motivation, specifically the lack of discussion on the communication cost of the GLASU algorithm. It explicitly states that neither the theorem nor the experiment address this aspect, which undermines the contribution of the paper. However, the comment does not provide specific guidance on how the authors should address this issue or what aspects of the communication cost they should discuss. While the action is clear in terms of identifying the need for a discussion on communication cost, it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation of the GLASU algorithm, specifically the claim that it is communication-efficient. However, it does not specify which part of the paper discusses this motivation, making it weakly grounded. The comment is specific in pointing out the lack of discussion on the communication cost, which is a critical aspect of the algorithm\\'s contribution. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the GLASU algorithm is to save communication, but neither the theorem nor the experiment discuss the communication cost. This claim is somewhat verifiable as it identifies a gap in the paper\\'s discussion, but it lacks specific examples or references to support the claim fully. The authors would need to provide more detailed reasoning or evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's motivation, specifically the lack of discussion on the communication cost of the GLASU algorithm. This is a critical aspect of the algorithm's contribution, as it claims to be communication-efficient. By pointing out this omission, the comment provides clear and actionable feedback, encouraging the authors to address this gap in their paper. However, the comment could be more helpful if it offered suggestions on how to discuss the communication cost or provided examples of how to incorporate this aspect into the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated. While this implies that the authors should clarify and highlight the contributions in their draft, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should make their contributions more explicit but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this should be addressed in. This makes it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity as it does not provide details on what aspects of the contributions should be clarified or how they should be stated. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the contributions of the paper should be explicitly stated, but it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without specific guidance or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the contributions of the paper should be explicitly stated. While this is a valid observation, it lacks specificity and does not provide any guidance on how the authors might clarify or enhance their contributions. Without actionable advice or examples, the comment does not offer the authors a clear path to improve their draft. Therefore, it is rated as barely helpful, as it identifies a potential issue but does not provide sufficient direction for the authors to address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the motivation of the work is unclear and the explanation is not convincing. It specifically mentions that the statement \"different densities directly will cause semantic conflicts\" should be justified experimentally or theoretically. This feedback provides a clear and explicit action for the authors to take, which is to provide experimental or theoretical justification for the claim. The comment is concrete in its suggestion, giving the authors a specific direction to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the clarity of the motivation and explanation in the paper, specifically mentioning the statement \"different densities directly will cause semantic conflicts.\" However, it does not specify which part of the paper this statement is found in, making it weakly grounded. The comment is specific in suggesting that the claim should be justified experimentally or theoretically, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the work is unclear and the explanation is not convincing. It suggests that the statement \"different densities directly will cause semantic conflicts\" should be justified experimentally or theoretically. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the motivation is unclear or the explanation is not convincing. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue with the clarity of the motivation and explanation in the paper. It points out that the authors mention a potential issue with \"different densities directly causing semantic conflicts,\" but this is not adequately justified. The comment suggests that this claim should be supported with either experimental or theoretical evidence. This feedback is clear and actionable, as it directs the authors to provide additional justification for their claims, which is essential for improving the paper\\'s clarity and credibility. However, the comment could be more helpful if it offered specific suggestions on how to present this justification or examples of how other works have addressed similar issues. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it questions whether the three transformer modules are trained iteratively or in an end-to-end manner, suggesting that the authors clarify this aspect. Second, it critiques the repetition of visualizations in Figure 5, questioning the necessity of repeating the visualization if it does not provide new insights. While the comment implies that the authors should clarify the training method and consider the redundancy of visualizations, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5\" and references \"figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether the three transformer modules are trained iteratively or in an end-to-end manner and suggesting that the repetition of visualizations in Figure 5 is unnecessary unless it provides new insights. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two concerns. First, it questions the training method of the transformer modules, asking whether they are trained iteratively or in an end-to-end manner. This is a logical inquiry that requires clarification. Second, it critiques the repetition of visualizations in Figure 5, suggesting that it is unnecessary unless it provides new insights. While the comment raises valid points, it lacks specific examples or references to support the claim about the redundancy of visualizations. The reasoning is logical but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional support to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises two important points. First, it questions the training method of the transformer modules, asking whether they are trained iteratively or in an end-to-end manner. This is a critical aspect that affects the overall approach and should be clarified. Second, it critiques the repetition of visualizations in Figure 5, suggesting that it is unnecessary unless it provides new insights. This feedback is valuable as it prompts the authors to consider the redundancy of their visualizations and to ensure that each one adds value to the paper. While the comment identifies areas for improvement, it could be more helpful if it provided specific suggestions on how to address these issues or examples of how to present the information more effectively. Overall, the comment is mostly helpful as it directs the authors to important areas for clarification and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit feedback on the need for greater precision and clarity in the writing, as well as specific suggestions for improvement, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" Additionally, it suggests that the paper would benefit from explicitly outlining the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. These suggestions are concrete and provide clear guidance on how the authors can improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"questions and comments\" and provides specific examples, such as \"parameters of BFNs\" versus \"parameters of BFN-produced distributions.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment also specifies what needs to be improved, namely the precision and clarity of the writing, as well as the need for explicit differentiation of the unique contributions of ParamReL from those of infoDiffusion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the writing would benefit from greater precision and clarity, and it provides specific examples of where this could be improved, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" Additionally, it highlights the similarity between the proposed method and infoDiffusion, suggesting that the authors should explicitly outline the unique contributions of ParamReL. While the comment provides some guidance, it lacks detailed examples or references to support the claim about the similarity to infoDiffusion. This makes the claim somewhat verifiable, as the authors would need to further investigate the comparison with infoDiffusion to fully understand the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the writing, suggesting that greater precision and clarity are needed. It highlights a particular area of improvement, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFN-produced distributions.\" Additionally, the comment points out that the proposed method is closely related to infoDiffusion and suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations that are not due to BFNs. This feedback is clear and provides the authors with a clear direction for improvement, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the paper\\'s focus on a situation where the gradient of the sum is not the sum of the individual gradients, which is not communicated in the text. It suggests that this setting is shared in all ERM approaches and could be discussed in less space. The comment also notes that this situation is rare and could require some space. While the comment highlights a specific area for improvement, it does not provide explicit guidance on how to address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors need to infer that they should clarify this point in the text. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 60-74 and the beginning of Section 2, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the authors\\' focus on a situation where the gradient of the sum is not the sum of the individual gradients is not communicated in the text. The comment further suggests that this setting is shared in all ERM approaches and could be discussed in less space, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' focus on a situation where the gradient of the sum is not the sum of the individual gradients is not communicated in the text, despite being a common setting in all ERM approaches. The reviewer suggests that this issue could be discussed in less space, as it is a rare occurrence. However, the comment lacks specific examples or references to support the claim that this situation is indeed rare or that it requires more space. Without detailed evidence or examples, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s focus on a situation where the gradient of the sum is not the sum of the individual gradients, which is not communicated in the text. It suggests that this setting is shared in all ERM approaches and could be discussed in less space, noting that this situation is rare and could require some space. This feedback is somewhat helpful as it points out a gap in the paper\\'s communication and suggests a potential area for improvement. However, it could be more helpful if it provided specific suggestions on how to address this issue or examples of how to communicate this concept more effectively. Overall, the comment offers some guidance but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the proposed question-rewrite strategy, specifically questioning whether it covers a sufficiently large number of questions. It provides detailed reasoning, explaining that out of 100 passages or approximately 3.7K questions, 23% become invalid, with 44% of those attributed to unresolved coreference. The reviewer also mentions that the proposed method rewrites 12% of the questions for all models, which is hardly significant. While the comment highlights specific issues and provides some reasoning, it does not offer explicit guidance or suggestions on how the authors might address these concerns or improve their strategy. The feedback is somewhat actionable as it provides a clear direction for the authors to consider, but it lacks concrete steps or detailed advice on how to resolve the issues. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed question-rewrite strategy,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns with the method, including the number of invalid questions and the attribution of these issues to unresolved coreference. The reviewer provides a clear explanation of the problem and the proposed method, making it easy for the authors to understand and address the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim about the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a large number of questions. The reviewer provides evidence by citing the percentage of invalid questions and the attribution of these issues to unresolved coreference. Additionally, the comment mentions the number of questions rewritten for all models, which is hardly significant. This provides a logical and detailed explanation of the concern, making the claim mostly verifiable. However, the comment could be strengthened by providing more specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant concern with the proposed question-rewrite strategy, specifically questioning its effectiveness in covering a large number of questions. It provides detailed reasoning, explaining that out of 100 passages or approximately 3.7K questions, 23% become invalid, with 44% of those attributed to unresolved coreference. The reviewer also notes that the proposed method rewrites only 12% of the questions for all models, which is hardly significant. This feedback is clear and actionable, as it highlights a critical issue that the authors need to address. However, the comment could be more helpful if it suggested potential solutions or improvements to the question-rewrite strategy. Overall, the comment is mostly helpful as it provides valuable insights and guidance for the authors to consider in revising their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in OT. It implicitly suggests that the authors should consider using earth mover\\'s distance instead of L2 distance. However, the comment does not provide specific guidance on how to implement this change or why it would be beneficial. The action is inferred, and while it is somewhat explicit, it lacks concrete details on how to execute the suggested change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4)\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of L2 distance in OT and asks for clarification on the benefit of using L2 distance. The comment provides a clear direction for the authors to consider alternative distance measures, such as earth mover\\'s distance, which enhances its specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in OT. The comment provides a logical reasoning by pointing out the prevalence of earth mover\\'s distance in OT, which implies that it might be a better choice for the context. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to conduct further research or consult relevant literature to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the use of L2 distance in equation (4) and suggests that earth mover\\'s distance is more common in OT. It implicitly suggests that the authors should consider using earth mover\\'s distance instead of L2 distance. While the comment identifies a potential area for improvement, it lacks specific guidance or explanation on why earth mover\\'s distance might be more appropriate or beneficial. The feedback is somewhat helpful as it prompts the authors to reconsider their choice of distance measure, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the description of the related work is scattered throughout the paper and suggests that the authors should provide a broader discussion on how their algorithm compares to other offline RL algorithms. While the comment implies that the authors should include a more comprehensive comparison, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to expand their discussion, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the related work being scattered throughout the paper, specifically mentioning papers [14] and [15] as relevant. However, it does not specify which sections or parts of the paper are affected by this issue, making it weakly grounded. The comment is specific in suggesting that a broader discussion on how the algorithm compares to other offline RL algorithms is needed, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the description of the related work is scattered throughout the paper, suggesting that the authors should provide a broader discussion on how their algorithm compares to other offline RL algorithms. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or improvements needed. The lack of detailed justification or evidence makes the claim borderline verifiable, as it requires the authors to infer the nature of the problem and how to address it. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper's organization, noting that the description of the related work is scattered throughout the document. It suggests that the authors should provide a broader discussion on how their algorithm compares to other offline RL algorithms, which is a valuable suggestion for improving the paper's clarity and comprehensiveness. However, the comment lacks specific guidance on how to structure this broader discussion or which aspects of the comparison should be emphasized. While it points out a potential area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about how the final solution changes if all increments are available at the same time. While it prompts the authors to consider a specific scenario, it does not provide explicit guidance on how to address this question or what aspects of the paper should be revised in response to this inquiry. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of this scenario on their results. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the impact of having all increments available at the same time on the final solution. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors might infer that it relates to the experimental results or methodology, but this inference is not explicit. The comment is specific in its question about the impact of a particular scenario, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the impact of having all increments available at the same time on the final solution. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the impact of having all increments available at the same time on the final solution. While it prompts the authors to consider a specific scenario, it does not provide any guidance or suggestions on how to address this question or what aspects of the paper might be affected by this change. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for exploration but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the convoluted nature of using multiple different feature spaces, such as the 25 feature space of Mitchell et al. and the full/pruned glove model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the approach or what alternative methods could be considered. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the technique of using multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et al. and the full/pruned glove model. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify what aspects of this technique are convoluted or potentially circular. The comment lacks specificity in detailing the exact issues or areas that need clarification or improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the technique of using multiple different feature spaces is convoluted and potentially circular. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et al. and the full/pruned glove model. It suggests that this approach may be convoluted and potentially circular, implying that the authors should consider simplifying their methodology. However, the comment lacks specific guidance or suggestions on how to address this concern or improve the approach. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are left with a general understanding of the issue but without clear steps to take for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment expresses concern about the convoluted nature of using multiple different feature spaces, such as the 25 feature space of Mitchell et al. and the full/pruned glove model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the approach or what alternative methods could be considered. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the technique of using multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et al. and the full/pruned glove model. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify what aspects of this technique are convoluted or potentially circular. The comment lacks specificity in detailing the exact issues or areas that need clarification or improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the technique of using multiple different feature spaces, such as the 25 feature space of Mitchell et al. and the full/pruned glove model, is convoluted and potentially circular. However, the comment lacks specific evidence, reasoning, or examples to support this claim. Without additional context or detailed explanation, the authors may find it challenging to understand the basis of the concern. As a result, the claim is unverifiable, aligning with a score of 1.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et al. and the full/pruned glove model. It suggests that this approach may be convoluted and potentially circular, implying that the authors should consider simplifying their methodology. However, the comment lacks specific guidance or suggestions on how to address this concern or improve the approach. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are left with a general understanding of the issue but without clear steps to take for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment expresses concern about the convoluted nature of using"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and to include their FLOPs and parameter sizes in Table 7. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback is clear and provides specific actions for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, namely, to include additional comparisons and results in the table. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of comparisons with other works using the MobileNetV3 search space and the exclusion of OFA with progressive shrink results. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 7 should include comparisons with other works using the MobileNetV3 search space, such as AtomNAS, and provides a specific reason for this suggestion: the inclusion of FLOPs and parameter sizes. This feedback is based on a logical reasoning that the addition of these comparisons would enhance the comprehensiveness of the results presented in the table. However, the comment does not provide specific references or examples of other works that have used the MobileNetV3 search space, which could further strengthen the justification. Therefore, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed references or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, in Table 7. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback is specific and provides a concrete direction for the authors to enhance the comprehensiveness and relevance of their results. By addressing this suggestion, the authors can better contextualize their findings and make their work more informative and comparable to existing literature. Therefore, the comment is rated as highly helpful, as it offers clear guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a brief discussion on why fixing hallucinations is important, in addition to referencing existing work. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide a rationale for fixing hallucinations, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a discussion on why fixing hallucinations is important, in addition to referencing existing work. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to address the issue of hallucinations, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it might be useful to include a discussion on why fixing hallucinations is important, in addition to referencing existing work. However, the comment does not provide any specific reasoning or evidence to support why this discussion is necessary or how it would benefit the paper. Without further elaboration or examples, the claim lacks sufficient justification, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on why fixing hallucinations is important, in addition to referencing existing work. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on how to address the issue or what aspects of the discussion should be emphasized. The comment identifies a potential area for improvement but does not offer actionable steps or examples, making it somewhat helpful. The authors are given a direction to consider but are left to determine the specifics of the discussion themselves. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the text, where terms like Type-1 error, Type-2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This suggests that the authors should clarify the order of presentation or ensure that the null hypothesis is introduced before these terms. While the comment implies that the authors need to address this issue, it does not provide explicit instructions on how to do so, such as suggesting a specific reordering or rephrasing. The action is implicit and somewhat vague, as the authors know what needs to be done but not how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 50-54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the order of presentation of terms like Type-1 error, Type-2 error, and false positive rate before the null hypothesis is clearly stated. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the terms \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue in the text where terms like \"Type-1 error,\" \"Type-2 error,\" and \"false positive rate\" are mentioned before the null hypothesis is clearly stated. This feedback is clear and actionable, as it points out a logical inconsistency that needs to be addressed. By highlighting this issue, the authors can ensure that their presentation is clear and coherent, which is crucial for reader understanding. However, the comment could be more helpful if it provided suggestions on how to restructure the text to address this issue, such as suggesting the order in which these terms should be introduced. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It explicitly asks the authors to address how they solve this issue. This question provides a clear and direct action for the authors to take, prompting them to discuss or provide a solution to the uncertainty in their draft. The comment is explicit and concrete, offering a specific direction for improvement. Therefore, it is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to estimating a continuous importance weight function, which is inherently uncertain due to the probabilistic process and regularization. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem of inherent uncertainty and the need to address it, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It questions how the authors address this issue, which is a logical and reasonable concern. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this uncertainty affects the model\\'s reliability. Without additional context or evidence, the claim is somewhat verifiable, as it prompts the authors to consider the implications of uncertainty but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It prompts the authors to address how they handle this issue, which is a critical aspect of their work. However, the comment does not provide specific suggestions or guidance on how to mitigate this uncertainty or improve the model's reliability. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors are given a direction to consider but are left to their own devices in terms of implementation. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It explicitly asks the authors to address how they solve this issue, providing a clear and direct action for them to take. The question prompts the authors to discuss or provide a solution to the uncertainty in their draft, offering a specific direction for improvement. This feedback is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to estimating a continuous importance weight function, which is inherently uncertain due to the probabilistic process and regularization. It raises a question about how the authors address this issue, providing a clear and direct action for the authors to take. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but without explicit references, it remains challenging to pinpoint the exact location. Despite this, the comment is specific in detailing the problem of inherent uncertainty and the need for a solution, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It questions how the authors address this issue, which is a logical and reasonable concern. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this uncertainty affects the model\\'s reliability. Without additional context or evidence, the claim is somewhat verifiable, as it prompts the authors to consider the implications of uncertainty but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the inherent uncertainty in estimating a continuous importance weight function due to the probabilistic process and regularization. It prompts the authors to address this issue, which is a critical aspect of their work. However, the comment does not provide specific suggestions or guidance on how to mitigate this uncertainty or improve the model\\'s reliability. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors are given a direction to consider but are left to their own devices in terms of implementation. Therefore, the comment aligns with a score of"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the performance of the SFAM scorers, which correlate well with human judgments on semantics-relevant styles but not on linguistics-relevant styles. It suggests that this might make the LISA more content-focused rather than style-focused. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the performance of the scorers on linguistics-relevant styles. The action is implicit and vague, as the authors are left to infer that they need to investigate and potentially modify their scorers to address this discrepancy. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the performance of the SFAM scorers, which correlate well with human judgments on semantics-relevant styles but not on linguistics-relevant styles. It suggests that this might make the LISA more content-focused rather than style-focused. However, the comment does not explicitly mention which part of the paper discusses these scorers or the LISA embedding, making it weakly grounded. The comment is specific in detailing the issue with the scorers\\' performance and the potential implications for the LISA\\'s focus. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human judgments on linguistics-relevant styles, such as simplification and linguistic acceptability. This is supported by the observation that the scorers correlate well with semantics-relevant styles, such as sentiment and emotion. The reviewer provides a logical reasoning based on the observed correlation patterns, which helps the authors understand the issue. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the performance of the SFAM scorers, which are fundamental components of the LISA embedding. It highlights that while the scorers correlate well with human judgments on semantics-relevant styles (e.g., sentiment and emotion), they do not correlate well with linguistics-relevant styles (e.g., simplification and linguistic acceptability). This discrepancy suggests that the LISA may be more content-focused rather than style-focused. The comment provides a clear and actionable insight into a potential limitation of the current approach, encouraging the authors to investigate and potentially address this issue. However, it could be more helpful if it offered suggestions on how to improve the scorers' performance on linguistics-relevant styles. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their experiments on additional real-world datasets, specifically mentioning DexYCB. While the comment implies that the authors should consider including more recent hand-object pose estimation pipelines to predict the initial hand-object poses, it does not provide explicit instructions on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should expand their dataset evaluation to include DexYCB and consider more recent pipelines. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the experiments on additional real-world datasets, specifically mentioning DexYCB. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to evaluate on a particular dataset and pipeline, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the experiments on additional real-world datasets, specifically mentioning DexYCB. However, it does not provide any reasoning, evidence, or references to support why this particular dataset is more suitable or why it would be beneficial to include it. The comment lacks specific justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should evaluate their experiments on additional real-world datasets, specifically mentioning DexYCB. This feedback is somewhat helpful as it provides a specific direction for expanding the dataset evaluation, which could enhance the robustness and generalizability of the results. However, the comment lacks depth and does not offer detailed guidance on how to incorporate these datasets or what specific aspects of the evaluation should be focused on. To be more helpful, the comment could include examples of how evaluating on DexYCB might benefit the study or suggest specific metrics to consider. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of explicit explanation regarding the design of sequential models and how the attention model is updated, which is crucial for understanding the rationale of the proposed work. While the comment identifies a specific area that needs clarification, it does not provide explicit instructions on how the authors should address this issue. The authors are left to infer that they need to include more detailed explanations, but the comment lacks concrete guidance on what specific aspects should be elaborated upon. Therefore, the comment is somewhat actionable, as it points out a need for clarification but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a lack of explicit explanation regarding the design of sequential models and how the attention model is updated, which is critical for understanding the rationale of the proposed work. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact sections that need clarification. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in identifying the need for more detailed explanations, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks explicit explanation regarding the design of sequential models and how the attention model is updated, which is critical for understanding the rationale of the proposed work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or improvements needed. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by pointing out the lack of explicit explanation regarding the design of sequential models and how the attention model is updated. This feedback is important because it highlights a key area that needs clarification to enhance the paper\\'s comprehensibility and understanding of the proposed work. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue, such as recommending additional sections or detailed explanations. Overall, the comment is somewhat helpful as it directs the authors to a specific area needing improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that making the entire code accessible would be helpful if the paper is accepted. While the action is explicit, it lacks concrete details on how the authors should make the code accessible or what specific aspects of the code should be included. The comment does not provide guidance on how to implement this suggestion, such as whether it should be made available on a public repository or in a supplementary material section. As a result, the action is implicit and somewhat vague, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that making the entire code accessible would be helpful if the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, such as the methods section or the supplementary materials. Without explicit references to specific sections or elements, the authors may find it challenging to determine where to implement this suggestion. Additionally, the comment lacks specificity regarding what aspects of the code should be made accessible or how this would enhance the paper. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that making the entire code accessible would be helpful if the paper is accepted. However, it does not provide any reasoning, evidence, or examples to support why this would be beneficial or how it would enhance the paper. Without such justification, the claim remains unverifiable, as the authors may not understand the rationale behind the suggestion. Therefore, the comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that making the entire code accessible would be beneficial if the paper is accepted. While this is a reasonable suggestion, it lacks specificity and does not provide any context or reasoning as to why the code should be made accessible. Without additional details or examples, the authors may find it challenging to understand the potential benefits or how to implement this suggestion effectively. Therefore, the comment is barely helpful, as it provides a general idea but lacks actionable guidance for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a concrete action by recommending the inclusion of pseudo-code or flow diagrams to enhance the reader's understanding of the model's operation. This feedback is clear and provides specific guidance on how the authors can improve their draft, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'hybrid architecture' and specifies the areas where the explanations could be clearer, such as 'spike-driven token selection' and 'intra- and inter-stage feature fusion.' This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests including pseudo-code or flow diagrams to enhance understanding. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that the explanations of specific processes, such as spike-driven token selection and intra- and inter-stage feature fusion, could be clearer. It provides a logical reasoning by suggesting the inclusion of pseudo-code or flow diagrams to enhance understanding. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact processes that need clarification and how the suggested additions would improve understanding. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the clarity of explanations for certain processes, such as spike-driven token selection and intra- and inter-stage feature fusion. It provides a clear and actionable suggestion by recommending the inclusion of pseudo-code or flow diagrams to enhance the reader's understanding of the model's operation. This feedback is valuable as it guides the authors on how to improve the clarity and accessibility of their work, making it mostly helpful. However, it could be more helpful if it provided examples of how these additions might be structured or if it suggested specific sections where these elements should be included. Nonetheless, the comment offers a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the proposed method is an incremental improvement over existing AutoAugment, but the performance improvements are not significant when compared to recent methods. It specifically mentions that the resnet-50 model is only 0.3 better than a reference method and notes the large standard deviation, which raises doubts about the method's generalizability. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes. The authors are left to infer that they need to improve the performance of their method or provide more detailed analysis to address the concerns about generalizability. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks concrete steps for the authors to take.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method, specifically mentioning its incremental improvement over AutoAugment and the performance improvements compared to recent methods. It provides a specific example, mentioning \"resnet-50 is only 0.3 better than [18],\" which allows the authors to identify the relevant part of the paper. However, the comment does not specify which part of the paper discusses the performance or the method itself, making it weakly grounded. The comment is specific in detailing the performance issues and doubts about generalizability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is an incremental improvement over existing AutoAugment, but the performance improvements are not significant when compared to recent methods. It provides a specific example, mentioning that resnet-50 is only 0.3 better than a reference method. However, the comment lacks detailed reasoning or references to support the claim about the significance of the performance improvements. The mention of the large standard deviation also raises doubts about generalizability, but without further explanation or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some evidence but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a key issue with the proposed method, noting that it is an incremental improvement over existing AutoAugment but lacks significant performance improvements compared to recent methods. It provides a specific example, mentioning that the resnet-50 model is only 0.3 better than a reference method, and highlights the large standard deviation, which raises doubts about the method's generalizability. This feedback is clear and actionable, as it directs the authors to address the performance gap and provide a more robust analysis of the method's generalizability. However, the comment could be more helpful if it suggested specific steps or strategies for improving the method's performance or generalizability. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a weakness in the comparison section, noting that it lacks references to existing prior arts and that a simple search reveals significant performance gaps between the proposed method and the latest methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should include references to prior arts and conduct a more thorough comparison with recent methods. However, the lack of concrete steps or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the comparison\" and \"the 5 experiment datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of references to existing prior arts and highlights the significant performance gaps between the proposed method and the latest methods. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is weak without references to existing prior arts and that a simple search reveals significant performance gaps between the proposed method and the latest methods. However, the comment does not provide specific examples or references to the prior arts that should be included, nor does it offer detailed reasoning or evidence to support the claim about the performance gaps. This lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to conduct their own research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the lack of references to existing prior arts in the comparison section. It also highlights a potential issue with the comparison by suggesting that a simple search reveals significant performance gaps between the proposed method and the latest methods. This feedback is clear and actionable, as it directs the authors to include references to prior arts and conduct a more thorough comparison. However, the comment could be more helpful if it provided specific examples of prior arts or suggested how to address the performance gaps. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a quantification of the diversity of the data gathered, which is currently lacking. It implies that this is a straightforward task, as it only requires a simple statistic like a types vs. token count. However, the comment does not explicitly instruct the authors to perform this quantification or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this quantification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of quantification for the diversity of the data gathered, specifically mentioning the absence of a types vs. token statistic. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a quantification and suggesting a particular statistic to use, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should provide a quantification of the diversity of the data gathered, specifically mentioning the absence of a types vs. token statistic. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this quantification is necessary or how it would improve the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary details to help the authors understand the significance of this suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of quantification for the diversity of the data gathered. It suggests that providing a simple statistic, such as a types vs. token count, would be useful. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that could be improved. However, the comment could be more helpful if it provided additional guidance on how to incorporate this quantification or why it is important. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a claim made in the paper about creating a more diverse set of positive instance pairs. However, it does not provide explicit guidance on how the authors should substantiate this claim or suggest specific measures of diversity. The comment implies that the authors should include a measure of diversity and compare their results with earlier works, but it does not offer concrete steps or examples on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific actions required to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made in the paper regarding the creation of a more diverse set of positive instance pairs. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the lack of a measure of diversity and the absence of a comparison with earlier works regarding diversity. This provides clear guidance on what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of creating a more diverse set of positive instance pairs is not sufficiently backed. This is because there is no suggested measure of diversity and no comparison with earlier works regarding diversity. The comment provides a logical reasoning by pointing out the lack of evidence and comparison, which makes the claim somewhat verifiable. However, it could be strengthened by providing specific examples or references to earlier works for comparison, which would make the claim more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific claim made in the paper regarding the creation of a more diverse set of positive instance pairs. However, it points out that this claim is not sufficiently backed by providing a measure of diversity or a comparison with earlier works. This feedback is somewhat helpful as it highlights a gap in the paper's methodology and suggests areas for improvement. However, it could be more helpful if it offered specific suggestions on how to measure diversity or which earlier works to compare with. Overall, the comment provides a clear direction for the authors to enhance their work, but it lacks depth and could be more comprehensive. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors\\' approach compares to other inputs, such as structured information, and mentions that the AUCROC seems high in other models in literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this comparison or what specific aspects they should consider when comparing their approach to others. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how the authors\\' approach compares to other inputs, such as structured information, and mentions that the AUCROC seems high in other models in literature. However, it does not specify which part of the paper this question pertains to, such as a specific section or result, making it weakly grounded. The comment is specific in its inquiry about the comparison to structured information and the high AUCROC, but without explicit grounding, the authors may struggle to identify the exact context of the question. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the comparison of the authors\\' approach to other inputs, such as structured information, and mentions that the AUCROC seems high in other models in literature. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that the AUCROC is high or how it compares to other models. Without this additional context or evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the comparison of the authors' approach to other inputs, such as structured information, and mentions that the AUCROC seems high in other models in literature. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable guidance on how the authors might address this comparison or what specific aspects they should consider. Without detailed suggestions or examples, the authors may find it challenging to effectively incorporate this feedback into their draft. Therefore, the comment is somewhat helpful, as it points out an area for consideration but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should state the objective function in experiments, including Monte Carlo estimates of the expectations. It also questions the use of a reverse inequality sign in Eq. 7 and the definition of the gap. Additionally, the comment suggests that some parts of Section 3, particularly Section 3.2, are too technical and recommends leaving more space in Section 4 to explain the training procedure. While the comment provides specific suggestions for improvements, it does not explicitly instruct the authors to make these changes or how to implement them. The actions are implicit and somewhat vague, as the authors need to infer the exact modifications to apply. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 7,\" \"the gap definition below,\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the objective function and the technical nature of Section 3, particularly Section 3.2. The comment provides clear guidance on what needs to be addressed, such as stating the objective function and clarifying the technical aspects. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several claims and suggestions. It questions the use of a reverse inequality sign in Eq. 7 and the definition of the gap, suggesting that the expected loss is represented by \"v.\" However, the comment lacks specific reasoning or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Additionally, the suggestion to leave more space in Section 4 to explain the training procedure is a subjective opinion that does not provide detailed justification or examples. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides several actionable suggestions for improvement. It suggests stating the objective function in experiments, including Monte Carlo estimates of the expectations, and questions the use of a reverse inequality sign in Eq. 7. Additionally, it points out that some parts of Section 3 are too technical and recommends leaving more space in Section 4 to explain the training procedure. These suggestions are clear and provide specific guidance on how the authors can enhance the clarity and comprehensiveness of their draft. However, the comment could be more helpful if it offered additional context or examples to support the suggestions. Overall, the feedback is mostly helpful, as it empowers the authors to make significant improvements to their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for an explanation regarding the decrease in the Disc. reward for SPACE and f-PCPO in the Grid (Fig. 3, top right plot). This request is clear and direct, providing a specific action for the authors to take. It does not require the authors to infer the action or deduce how to address the issue. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 3, top right plot,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation regarding the decrease in the Disc. reward for SPACE and f-PCPO in the Grid. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification or explanation, asking why the Disc. reward for certain methods is decreasing in a specific plot. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, asking for an explanation regarding the decrease in the Disc. reward for certain methods in a specific plot. This feedback provides a direct request for clarification, which is valuable for the authors as it prompts them to address a potential weakness or area of confusion in their paper. However, the comment could be more helpful if it offered suggestions on how to explain the decrease or what factors might be contributing to it. Overall, the comment is mostly helpful as it guides the authors towards a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific area where the paper lacks detail, namely the missing implementation details regarding the resolutions at which images successfully achieve adversarial effects. While the comment identifies a gap in the paper, it does not provide explicit instructions on how the authors should address this issue. The authors are left to infer that they need to include this information in their draft, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific area where the paper lacks detail, namely the missing implementation details regarding the resolutions at which images successfully achieve adversarial effects. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the methodology or results sections, the comment lacks full grounding. It is specific in identifying the missing information, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"Key implementation details are missing,\" specifically mentioning the lack of information on the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks detail, namely the missing implementation details regarding the resolutions at which images successfully achieve adversarial effects. This feedback is somewhat helpful as it points out a gap in the paper's methodology that could impact the comprehensiveness and reproducibility of the results. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or what specific details should be included. To be more helpful, the comment could offer guidance on how to incorporate this information or suggest relevant references for the authors to consider. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current approach of using DDIM Inversion for data preprocessing is effective in reducing training time but does not significantly simplify the overall complexity. It recommends exploring improvements to the motion guidance strategy to enhance training efficiency. While the comment implies that the authors should consider alternative approaches or strategies, it does not provide specific guidance on what those improvements might be or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific improvements to make. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section on data preprocessing, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, which is that it does not significantly simplify the overall complexity despite being effective in reducing training time. The comment suggests exploring improvements to the motion guidance strategy to enhance training efficiency, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current approach of using DDIM Inversion for data preprocessing is effective in reducing training time but does not significantly simplify the overall complexity. It recommends exploring improvements to the motion guidance strategy to enhance training efficiency. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the current approach does not simplify complexity. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the current approach of using DDIM Inversion for data preprocessing, noting that while it reduces training time, it does not significantly simplify the overall complexity. It suggests exploring improvements to the motion guidance strategy to enhance training efficiency. This feedback is clear and actionable, as it provides a specific area for improvement and offers a direction for the authors to consider. However, the comment could be more helpful if it included specific suggestions or examples of how to improve the motion guidance strategy. Overall, the comment is mostly helpful as it guides the authors towards a potential enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might make it difficult to see individual words as a whole phrase, which could exacerbate the heavy tail problem. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to investigate the statistics of relation phrases and consider the implications of heavy tail in relations. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might make it difficult to see individual words as a whole phrase, which could exacerbate the heavy tail problem. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the problem of heavy tail in relations and its implications, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might make it difficult to see individual words as a whole phrase, which could exacerbate the heavy tail problem. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the heavy tail problem in relation phrases. The authors are left to infer the relevance and severity of this issue, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important questions about the statistics of relation phrases and the potential issue of heavy tail in relations. It suggests that chunking into relation phrases might make it difficult to see individual words as a whole phrase, which could exacerbate the heavy tail problem. This feedback is valuable as it prompts the authors to consider the implications of their approach and encourages them to investigate the statistics of relation phrases and the heavy tail problem. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues or improve the analysis. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a direction for further exploration.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the robustness of the approach in dynamic regions, specifically mentioning the Bonn dataset where moving objects can occupy a significant portion of the image. It suggests two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. While the comment implies that the authors should consider these solutions, it does not explicitly instruct them to implement them. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Bonn dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the need for more robust approaches in dynamic regions, particularly in the context of the Bonn dataset. The comment suggests potential solutions, such as masking out dynamic regions or re-running relative pose estimation, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point makes a claim about the robustness of the approach in dynamic regions, specifically mentioning the Bonn dataset. It suggests that the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements\" is generally true but acknowledges the need for more robust approaches in edge cases, such as the Bonn dataset where moving objects can occupy a significant portion of the image. The comment provides a logical reasoning for the need for robustness in dynamic regions and suggests potential solutions, such as masking out dynamic regions or re-running relative pose estimation. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the robustness of the approach in dynamic regions, specifically mentioning the Bonn dataset where moving objects can occupy a significant portion of the image. It suggests that the current approach may not be robust enough to handle such cases and provides two potential solutions: masking out dynamic regions using segmentation masks or re-running relative pose estimation after identifying dynamic regions. This feedback is clear and actionable, offering the authors a direction for improving the robustness of their approach. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to implement these solutions. Overall, the comment is mostly helpful as it provides valuable insights and suggestions for enhancing the robustness of the approach.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only compare the models proposed by the authors and lack a comparison with other methods. While it identifies a specific area for improvement, it does not provide explicit guidance on how the authors should address this issue. The comment suggests that the authors should include comparisons with other methods, but it does not specify which methods to include or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the experiments, noting that they only compare the models proposed by the authors and lack comparisons with other methods. However, it does not specify which part of the paper this issue is addressed in, making it weakly grounded. The comment is specific in identifying the need for additional comparisons, but without grounding, the authors may struggle to pinpoint where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments only compare the models proposed by the authors and lack comparisons with other methods. This is a factual statement that does not require verification, as it is a direct observation of the content of the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the experiments only compare the models proposed by the authors and lack comparisons with other methods. This feedback is clear and actionable, as it directs the authors to expand their analysis by including comparisons with other methods. However, the comment could be more helpful if it provided suggestions on which specific methods to include for comparison or how to structure these comparisons. Overall, the comment is mostly helpful as it highlights a critical area for enhancement and provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a minor inconsistency in Table 3 and 4, where the models labeled as \"math specialists\" have an asterisk, but the MAVIS models do not. The reviewer suggests that the MAVIS models should also be considered \"math specialists\" and recommends adding an asterisk to them. This feedback is explicit and provides a clear action for the authors to take, which is to ensure consistency in labeling the MAVIS models as \"math specialists.\" The suggestion is concrete, as it specifies what needs to be done to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular inconsistency in the labeling of models as \"math specialists\" and suggests that the MAVIS models should also be labeled as such. This provides clear guidance on what needs to be addressed in the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the labeling of models in Tables 3 and 4, suggesting that the models labeled as \"math specialists\" should also have an asterisk, as the MAVIS models are considered \"math specialists\" as well. This is a straightforward observation that does not require any additional justification or evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor inconsistency in the labeling of models in Tables 3 and 4. It points out that while models labeled as \"math specialists\" have an asterisk, the MAVIS models do not, despite being considered \"math specialists\" as well. The reviewer suggests that the MAVIS models should also be labeled with an asterisk to maintain consistency. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the clarity and consistency of their presentation. However, the comment could be more helpful if it explained why this consistency is important or how it might impact the interpretation of the results. Despite this, the feedback is mostly helpful as it guides the authors in making a straightforward correction to enhance the quality of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical novelty of the work is limited, as KNN-based methods are widely studied in LM and MT. It suggests that the work provides few insights into the use of a non-parametric method for text classification. However, the comment does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects they should focus on to provide more insights. As a result, the authors are left without a clear understanding of what changes or additions are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the technical novelty of the work, specifically mentioning the use of KNN-based methods in LM and MT. However, it does not specify which part of the paper discusses these methods or how they are applied, making it weakly grounded. The comment is specific in pointing out the limited novelty and the lack of insights into the use of a non-parametric method for text classification. However, without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical novelty of the work is limited due to the widespread study of KNN-based methods in LM and MT. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a limitation in the technical novelty of the work, specifically noting that KNN-based methods are widely studied in LM and MT. It suggests that the work provides few insights into the use of a non-parametric method for text classification. However, the comment lacks actionable feedback or suggestions on how the authors might enhance the novelty of their work or provide more insights. Without specific guidance or examples, the authors are left without a clear understanding of how to address the identified limitation. Therefore, the comment is barely helpful, as it points out a potential issue but does not offer actionable advice for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper emphasizes the enhancement of the Information Maximization (IM) for most existing Reinforcement Learning (RL) algorithms, but it lacks a comparison with the latest work, particularly non-pixel-based approaches. The comment suggests that the description of the mainstream RL algorithms in the related work section is outdated, specifically mentioning SAC from 2018. While the comment identifies a gap in the paper\\'s coverage, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to update the related work section to include more recent and relevant literature. However, the lack of specific instructions or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s emphasis on the enhancement of the Information Maximization (IM) for most existing RL algorithms, but it lacks a comparison with the latest work, especially non-pixel-based approaches. It specifically mentions the outdated description of the mainstream RL algorithms in the related work section, citing SAC from 2018 as an example. However, the comment does not specify which part of the paper this issue is related to, such as the introduction or the related work section. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific about the need for a comparison with recent work, it lacks full grounding as it does not explicitly mention the sections or parts of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s emphasis on the enhancement of the Information Maximization (IM) for most existing RL algorithms is an overstatement, lacking a comparison with the latest work, especially non-pixel-based approaches. The comment provides a specific example by mentioning SAC from 2018, which suggests that the paper could be more comprehensive in its coverage of recent literature. However, the comment lacks detailed reasoning or references to support the claim that the paper\\'s description of mainstream RL algorithms is outdated or incomplete. While the mention of SAC provides some context, the lack of additional evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's emphasis on the enhancement of the Information Maximization (IM) for most existing RL algorithms. It points out that the description of the mainstream RL algorithms in the related work section is outdated, specifically mentioning SAC from 2018. The comment suggests that the paper lacks a comparison with the latest work, especially non-pixel-based approaches, which could be relevant to the data efficiency aspect. While the comment highlights a gap in the paper's coverage, it does not provide specific suggestions or guidance on how the authors might address this issue or what recent work should be included. The feedback is somewhat helpful as it points out a potential area for improvement but lacks detailed actionable advice, leaving the authors with a general direction to explore.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests expanding the background discussion in Section 2 by incorporating further background knowledge on adversarial examples and threat models. It specifically recommends referencing relevant surveys to clarify the threat model and position of the work within the state-of-the-art (SoA). This feedback provides a clear and explicit action for the authors to take, as it outlines specific areas to expand upon and suggests a method for doing so. The comment also offers concrete guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2\" and \"related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be expanded, namely the background discussion on adversarial examples and threat models, and suggests referencing relevant surveys to clarify the threat model and position within the state-of-the-art. This provides a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests expanding the background discussion in Section 2 by incorporating further background knowledge on adversarial examples and threat models. It recommends referencing relevant surveys to clarify the threat model and position of the work within the state-of-the-art (SoA). While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these additions would be beneficial. The authors would need to infer the potential benefits of this expansion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for expanding the background discussion in Section 2 by incorporating further background knowledge on adversarial examples and threat models. It specifically recommends referencing relevant surveys to clarify the threat model and position of the work within the state-of-the-art (SoA). This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and depth of their paper, making it highly helpful. By following this advice, the authors can improve the comprehensibility of their work for both experts and non-experts, which is a significant contribution to the draft. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the relevance of the proposed multiple-span answer setting in real-world applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might clarify or explain the importance of this setting, nor are there suggestions for additional information or examples that could help clarify the point. Without any actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relevance of the proposed multiple-span answer setting in real-world applications. However, it does not specify which part of the paper discusses this setting, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in questioning the importance of the setting, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the relevance of the proposed multiple-span answer setting in real-world applications, but it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relevance of the proposed multiple-span answer setting in real-world applications. While it identifies a potential area of confusion, it does not provide any specific suggestions or guidance on how the authors might address this concern or clarify the importance of their approach. Without actionable feedback or detailed insights, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an action by questioning why the train set examples are not mixed with hypernyms and non-hypernyms in the test sets. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should consider mixing the train set examples with hypernyms and non-hypernyms in the test sets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Testsets\" and \"574ff,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the train set examples should be mixed with hypernyms and non-hypernyms in the test sets. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an action regarding the mixing of train set examples with hypernyms and non-hypernyms in the test sets. However, it does not provide any reasoning or evidence to support why this change would be beneficial or how it might impact the results. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an action by questioning why the train set examples are not mixed with hypernyms and non-hypernyms in the test sets. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper. However, it lacks specificity and does not provide detailed guidance on how to implement this suggestion or what benefits it might bring. The authors are left with a general idea of what could be improved but without actionable steps to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to provide the results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results for AdpCLR_pre in Table 1. This is a clear and direct action, specifying exactly what needs to be done to improve the draft. The authors are given a specific task to perform, which is to include the requested results in their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing the results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results for AdpCLR_pre. This provides clear guidance on what additional information is required to improve the draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for the results of the AdpCLR_full approach for the ResNet-50 architecture. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it explicitly requests the authors to provide additional results for the AdpCLR_full approach for the ResNet-50 architecture, similar to the results already included in the table. This feedback is specific and provides a direct way for the authors to enhance the completeness and comprehensiveness of their results section. By addressing this request, the authors can improve the transparency and comparability of their findings, which is beneficial for both the authors and the readers. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should clarify this similarity, explore it further, or provide additional context. Without any actionable steps or suggestions, the comment lacks direction for the authors, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the similarity between N trajectories and the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the similarity between these concepts, but without grounding, the authors may struggle to identify the exact context in which this question is relevant. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the similarity between N trajectories and the concept of replay in the Dyna model. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the similarity between N trajectories and the concept of replay in the Dyna model. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or why it is important to clarify. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but does not offer sufficient guidance for the authors to effectively address the feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some experiment results are suspicious, specifically mentioning Tables 16 and 17, which share the same result despite changing the 2-hop EG into 3-hop EG. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address the issue or what steps to take to resolve it. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Tables 16 and 17, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out a particular issue with the experiment results, specifically mentioning that Tables 16 and 17 share the same result despite changing the 2-hop EG into 3-hop EG. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some experiment results are suspicious, specifically mentioning Tables 16 and 17, which share the same result despite changing the 2-hop EG into 3-hop EG. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suspicion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment results, noting that Tables 16 and 17 share the same result despite changing the 2-hop EG into 3-hop EG. This observation is clear and provides a concrete example of a potential inconsistency in the data. However, the comment lacks actionable guidance on how the authors might address this issue or improve the reliability of their results. While it highlights a problem, it does not offer suggestions for resolution or further analysis, leaving the authors without a clear path forward. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results show some advantages of the proposed algorithms but are not very significant. It also mentions that the results are still competitive with state-of-the-art algorithms. While the comment highlights a potential issue with the significance of the results, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the significance of their findings. The action is implicit and vague, as the authors are left to infer that they need to enhance the significance of their results, but without concrete steps on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental results, specifically mentioning that they show some advantages of the proposed algorithms but are not very significant. It also notes that the results are still competitive with state-of-the-art algorithms. However, the comment does not specify which part of the paper these results are discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the experimental results section, the lack of explicit grounding makes it weakly grounded. The comment is specific in identifying the issue with the significance of the results and the competitive nature with state-of-the-art algorithms. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results show some advantages of the proposed algorithms but are not very significant, and that they are still competitive with state-of-the-art algorithms. However, the comment does not provide any specific evidence, examples, or reasoning to support these claims. Without detailed justification or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the significance of the experimental results, noting that while the proposed algorithms show some advantages, they are not very significant. It also points out that the results are still competitive with state-of-the-art algorithms. However, the comment lacks specific guidance or suggestions on how the authors might enhance the significance of their results or improve their competitive edge. While it highlights an area for improvement, the feedback is somewhat helpful as it provides a direction for the authors to consider but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to LLM\\'s overconfidence. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what steps to consider to mitigate the issue. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of the per-sentence assessment protocol, which is a specific aspect of the paper. It provides a critique about the protocol\\'s potential for LLM\\'s overconfidence, suggesting that it may prefer its predictions even if they are incorrect. This feedback is specific in identifying the issue with the protocol and its potential limitations. However, the comment does not explicitly mention which part of the paper discusses this protocol, making it weakly grounded. Despite this, the comment is specific in detailing the issue, so the comment is weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the per-sentence assessment protocol may be prone to LLM\\'s overconfidence, suggesting that it prefers its predictions even if they are incorrect. However, the comment lacks specific examples or evidence to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or references, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the per-sentence assessment protocol, suggesting that it may be prone to LLM\\'s overconfidence. It points out that the protocol might prefer its predictions even if they are incorrect, which is a valid concern. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the protocol. While it highlights an important area for consideration, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, it is somewhat helpful, as it offers a starting point for the authors to explore but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the non-semantic diversity modeling, specifically asking why it reflects only non-semantic diversity and not semantic diversity. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should explore and explain the distinction between non-semantic and semantic diversity in their modeling. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W6.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the basis for modeling smooth non-semantic diversity, asking why it reflects only non-semantic diversity and not semantic diversity. This provides clear guidance on what aspect of the paper needs further clarification or explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the non-semantic diversity modeling, specifically asking why it reflects only non-semantic diversity and not semantic diversity. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand and address the issue. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to improve their work. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the non-semantic diversity modeling, specifically asking why it reflects only non-semantic diversity and not semantic diversity. This feedback is somewhat helpful as it identifies a potential area for clarification or improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance their modeling approach. The comment could be more helpful with additional context or detailed feedback, such as suggesting ways to differentiate between non-semantic and semantic diversity. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the experimental results, specifically asking whether the promising results are due to the superiority of the method or an accidental result from a specific kernel function and feature map. While the comment highlights an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this question. The authors are left to infer that they need to provide more detailed analysis or explanation to clarify the results. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks concrete guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the experimental results, specifically asking whether the promising results are due to the superiority of the method or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the experimental results, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the experimental results, specifically asking whether the promising results are due to the superiority of the method or an accidental result from a specific kernel function and feature map. This question is logical and seeks clarification on the factors influencing the results, but it does not contain any claims or opinions that require verification. It is a request for further explanation or analysis, which is a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the experimental results, specifically asking whether the promising results are due to the superiority of the method or an accidental result from a specific kernel function and feature map. This question highlights an important aspect that the authors should consider when interpreting their results, which could impact the validity and generalizability of their findings. However, the comment does not provide any guidance or suggestions on how the authors might address this concern or conduct further analysis to clarify the results. While it identifies a potential issue, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not provide any explicit or implicit action for the authors to take. The comment simply points out a missing detail without suggesting how the authors should address it or where they should include this information. As a result, the authors are left without guidance on how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment raises a specific concern about the lack of description of the estimation of $\\\\mu_t^a$ in the algorithm. However, it does not specify which part of the paper this issue is related to, such as a particular section or subsection. The authors might infer that it pertains to the algorithm section, but this inference is not explicit. The comment is specific in detailing the missing information, but without full grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that there is no description of the estimation of $\\\\mu_t^a$ in the algorithm, which is a factual statement. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that there is no description of the estimation of $\\\\mu_t^a$ in the algorithm. This is a clear and actionable feedback that highlights a gap in the paper's documentation. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or where to include the necessary information. While it points out a critical omission, it lacks depth and specificity, making it somewhat helpful. The authors are aware of the need for clarification but are left without detailed instructions on how to improve their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a complexity issue with the proposed method, noting the use of modified Gromov-Hausdorff distances and hypergraph structures, which may increase time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but suggests that a discussion of the computational costs associated with training would be beneficial. While the comment implies that the authors should include a discussion on training costs, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that a discussion on training costs is necessary. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the complexity of the proposed method, mentioning the use of modified Gromov-Hausdorff distances and hypergraph structures, which likely increase the time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but suggests that a discussion of the computational costs associated with training would be beneficial. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the method section or the appendices, but the lack of explicit reference to specific sections or figures makes it difficult to pinpoint. The comment is specific in suggesting a discussion on training costs, but the lack of grounding makes it challenging for the authors to fully address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method is complex due to the use of modified Gromov-Hausdorff distances and hypergraph structures, which likely increase the time complexity. The reviewer acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but suggests that a discussion of the computational costs associated with training would be beneficial. While the comment provides some context and acknowledges the theoretical analysis, it lacks specific examples or detailed reasoning to fully substantiate the claim about the increased complexity. The suggestion for a discussion on training costs is a logical extension but remains somewhat vague without further elaboration. Therefore, the comment is somewhat verifiable, as it provides some support but could be strengthened with more detailed evidence or examples.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a complexity issue with the proposed method, noting the use of modified Gromov-Hausdorff distances and hypergraph structures, which may increase the time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but suggests that a discussion of the computational costs associated with training would be beneficial. This feedback is clear and actionable, as it points out a potential area for improvement in the paper's analysis and suggests a specific direction for the authors to address. By addressing this concern, the authors could enhance the comprehensiveness of their work and provide a more complete understanding of the computational aspects. Therefore, the comment is mostly helpful, as it provides valuable guidance for improving the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the proposed method not being groundbreaking and lacking distinction from existing contrastive decoding techniques. It suggests that the paper does not provide a clear understanding of the unique contributions and advantages of the new approach. However, the comment does not offer specific guidance or suggestions on how the authors might address this issue or improve the clarity of their contributions. The action is implicit and vague, as the authors are left to infer that they need to clarify the unique aspects of their method, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s lack of distinction from existing contrastive decoding techniques, suggesting that the paper does not provide a clear understanding of the unique contributions and advantages of the new approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarity on the unique contributions, but without grounding, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may not represent a groundbreaking innovation within the field of LLMs, despite effectively building upon existing strategies. The comment suggests that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. However, the comment lacks specific examples or references to existing contrastive decoding techniques, making it difficult for the authors to fully understand and address the critique. The claim is somewhat verifiable, as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's proposed method, noting that it may not represent a groundbreaking innovation within the field of LLMs. It highlights that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. This feedback is somewhat helpful as it points out a critical area for improvement, but it lacks specific suggestions or guidance on how the authors might address this issue. The comment provides a direction for the authors to consider, but it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any explicit or implicit actions for the authors to take to improve the figure. There is no guidance on how to make the representation more intuitive, such as suggesting alternative formats, reorganizing the data, or providing additional explanations. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed to enhance the figure\\'s clarity. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the tabular representation of node agent interactions is not intuitive. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4\\'s tabular representation of node agent interactions is not intuitive. However, it does not provide any supporting evidence, reasoning, or examples to justify why the representation is not intuitive. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that the tabular representation of node agent interactions is not intuitive. While it points out a problem, it lacks actionable suggestions or guidance on how the authors might improve the figure to make it more intuitive. Without additional context or specific recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but does not provide detailed feedback or actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it suggests considering other frameworks besides PU as baselines if the benefit is prioritizing learning on examples with less irreducible uncertainty. Second, it asks how the use of the PU loss impacts calibration and the importance of uncertainty estimation for downstream use cases of AI text detectors. While the comment implies that the authors should consider alternative baselines and explore the impact of the PU loss on calibration, it does not explicitly instruct them to do so. The questions provide valuable insights but lack concrete guidance on how to address them. Therefore, the comment is somewhat actionable, as it identifies areas for further exploration but does not provide explicit instructions on how to implement these suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions regarding the use of the PU loss and its impact on calibration, as well as the importance of uncertainty estimation for downstream use cases. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is weakly grounded because it does not provide explicit references to specific parts of the paper, and it is not specific about what needs to be addressed in terms of alternative baselines or the impact of the PU loss on calibration. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises two questions regarding the use of the PU loss and its impact on calibration, as well as the importance of uncertainty estimation for downstream use cases. The comment suggests considering other frameworks besides PU as baselines if the benefit is prioritizing learning on examples with less irreducible uncertainty. However, it does not provide specific examples or references to support these suggestions, making it difficult for the authors to fully understand and address the points raised. The questions are logical and could be answered with additional information or evidence, but the lack of detailed support makes the claim borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two important questions regarding the use of the PU loss and its impact on calibration, as well as the importance of uncertainty estimation for downstream use cases of AI text detectors. The first question suggests considering alternative frameworks besides PU as baselines if the benefit is prioritizing learning on examples with less irreducible uncertainty. This is a valuable insight that could lead the authors to explore different approaches. The second question highlights the importance of uncertainty estimation, which is crucial for downstream applications. While the comment identifies these areas for improvement, it does not provide specific guidance or suggestions on how to address them. The authors are left with a general understanding of what needs to be improved but without detailed steps on how to implement these suggestions. Therefore, the comment is somewhat helpful, as it provides valuable insights but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefitting another task, and fine-tuning is a sequential way of doing it. The reviewer provides a clear explanation of the distinction between TL and FT, but does not offer explicit guidance or suggestions for how the authors should revise their characterization. The comment lacks actionable details, leaving the authors uncertain about how to address the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefitting another task, and fine-tuning is a sequential way of doing it. The comment provides a clear explanation of the distinction between TL and FT, but it does not specify which part of the paper this critique is based on. The authors can infer that it relates to the introduction, where the characterization is described, but the comment lacks explicit grounding. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point challenges the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, providing a clear explanation of the distinction between the two concepts. The reviewer explains that TL is a broader term for the phenomenon of learnings from one task benefitting another task, and fine-tuning is a sequential way of doing it. This explanation is logical and provides a clear rationale for the critique, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the distinction between TL and FT. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment critiques the characterization of Transfer Learning (TL) and Fine-tuning (FT) as sequential MTL, suggesting that TL is a broader term for the phenomenon of learnings from one task benefitting another task, and fine-tuning is a sequential way of doing it. The reviewer provides a clear and logical explanation of the distinction between TL and FT, which could help the authors clarify their terminology and improve the accuracy of their description. However, the comment does not offer specific suggestions or guidance on how the authors might revise their characterization or improve their understanding of these concepts. While it provides valuable insight, the feedback lacks actionable details, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a Limitation section, which is important. However, it does not provide any guidance on how to address this issue or what specific limitations should be included. The authors are left with a clear action to take but without detailed instructions on how to implement it. This makes the comment somewhat actionable, as it identifies a necessary improvement but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a missing element in the paper, specifically the absence of a \"Limitation\" section. However, it does not specify which part of the paper this section should be included in or what specific limitations should be addressed. The authors can infer that it pertains to the conclusion or discussion section, but this inference is not explicit. The comment is specific in identifying the need for a \"Limitation\" section, but it lacks grounding as it does not specify where this section should be placed or what it should contain. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a \"Limitation\" section, which is important. However, the comment does not provide any reasoning, examples, or references to support why this is a significant omission. Without additional context or evidence, the authors may find it challenging to understand the significance of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical omission in the paper, specifically the absence of a \"Limitation\" section. This is an important aspect to address, as it allows the authors to acknowledge and discuss the potential weaknesses or constraints of their work. However, the comment lacks specificity and does not provide guidance on what specific limitations should be included or how to structure this section. While it highlights a necessary improvement, the lack of detailed feedback limits its usefulness for the authors. Therefore, the comment is somewhat helpful, as it points out a significant gap but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a list of specific areas where the authors need to improve their draft. It suggests that Section 2.1 requires more detailed explanations of the theory behind diffusion models, and it mentions that Section 2.2 discusses CLIP guidance using global and local directional losses. Additionally, it notes that the works of Choi et al. (2021) and Meng et al. (2021) are not explained in detail. Finally, it points out that the captions of figures are often not explanatory. While the comment identifies several areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and improve the clarity of their figures, but without concrete guidance on what specific changes to make, the action remains vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific feedback on several sections of the paper, including Section 2.1, Section 2.2, and Section 3.2. It suggests that Section 2.1 requires more detailed explanations of the theory behind diffusion models, and it mentions that Section 2.2 discusses CLIP guidance using global and local directional losses. Additionally, it notes that the works of Choi et al. (2021) and Meng et al. (2021) are not explained in detail. The comment also points out that the captions of figures are often not explanatory. This level of detail allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. However, it lacks specificity in terms of what exactly needs to be improved in each section, such as specific examples or detailed explanations. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point consists of several observations and suggestions for improvement, but it does not contain any claims that require verification. It provides specific feedback on sections of the paper, such as the need for more detailed explanations in Section 2.1 and the lack of explanation for works by Choi et al. (2021) and Meng et al. (2021). It also notes issues with figure captions. However, the comment does not make any subjective claims or judgments that would require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on several aspects of the paper. It identifies areas where the authors need to provide more detailed explanations, such as the theory behind diffusion models in Section 2.1 and the use of CLIP guidance in Section 2.2. Additionally, it points out that the works of Choi et al. (2021) and Meng et al. (2021) are not explained in detail, suggesting that the authors should provide more context or discussion. Furthermore, the comment highlights issues with figure captions, indicating that they are not explanatory. This feedback is clear and provides the authors with specific areas to focus on for improvement, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to enhance the explanations or provide examples of what constitutes detailed explanations. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This is an explicit suggestion that the authors can follow to improve their title. The action is clear and concrete, as it specifies what needs to be done to enhance the title. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. However, it does not specify which part of the paper discusses the title or the application of the new model, making it weakly grounded. The comment is specific in suggesting a change to the title, but without grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. However, the comment does not provide any reasoning or evidence to support why this term is crucial for the title. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient evidence or explanation to support the recommendation.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the title of the paper should include the term \"tensor completion\" because it is the only application of the new model presented in the paper. This feedback is specific and actionable, as it provides a clear and direct suggestion for improving the title. By including the term \"tensor completion,\" the title would better reflect the focus of the paper and its main application. This feedback is valuable as it helps the authors enhance the clarity and accuracy of their title, which is an important aspect of academic writing. Therefore, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should compare their proposed method to other prior methods or a simple baseline, such as character frequencies, to make the paper more persuasive. While the action is explicit, it does not provide detailed guidance on how to implement these comparisons or what specific aspects to focus on. The authors are given a clear direction but may need to infer the exact steps to take, making the comment mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the proposed method and the lack of comparison to other prior methods or a simple baseline. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed: the need for empirical evaluation by comparing the proposed method to other methods or a simple baseline. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the authors should compare their proposed method to other prior methods or a simple baseline to make the paper more persuasive. The reviewer suggests implementing a simple baseline, such as character frequencies, for comparison. This claim is somewhat verifiable as it provides a logical suggestion for improvement but lacks specific examples or references to other studies that have used similar comparisons. The authors would need to explore and justify the relevance of these comparisons themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's evaluation by pointing out that the authors have not compared their proposed method to other prior methods. This is a crucial aspect of empirical evaluation that can enhance the paper's credibility and impact. The reviewer suggests implementing a simple baseline, such as character frequencies, for comparison, which provides a clear and actionable suggestion for improvement. This feedback is mostly helpful as it guides the authors on how to strengthen their paper by including a more comprehensive evaluation. However, it could be more helpful if it offered additional guidance on how to interpret or present the results of these comparisons. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential limitation of the proposed method in reducing computational load in real applications. It identifies specific challenges, such as the difficulty in applying a uniform activation pattern across tokens due to their unique activation patterns. The comment suggests that the method may not generalize well to other tokens, potentially requiring all tokens to activate all channels to achieve their unique patterns. However, it does not provide explicit guidance on how the authors might address these issues or improve the method's practicality. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to enhance the method's applicability and generalizability. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses a specific issue related to the practicality of reducing computational load in the proposed method. It highlights a potential challenge in applying a uniform activation pattern across tokens due to their unique activation patterns. The comment is fully grounded as it explicitly mentions the issue of computational load and provides specific reasoning about the challenges involved. However, it does not specify which part of the paper discusses this issue, making it somewhat specific. Therefore, the comment is fully grounded and somewhat specific, aligning with category 4.\", 'grounding_specificity_label': '4', 'verifiability_rationale': \"The review point claims that the proposed method may face challenges in reducing computational load in real applications due to the difficulty in applying a uniform activation pattern across tokens. The comment provides a logical reasoning by explaining that different tokens activate different channels, which makes it challenging to generalize activation patterns. However, the claim lacks specific examples or references to support the assertion that these patterns may not generalize well or that all tokens would need to activate all channels. This makes the claim somewhat verifiable, as it provides a logical basis but requires further evidence or examples to fully substantiate the concern.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the proposed method in reducing computational load in real applications. It highlights a specific challenge related to the difficulty in applying a uniform activation pattern across tokens, which may not generalize well to other tokens. The comment provides a logical reasoning for this limitation, explaining that in extreme cases, all tokens would need to activate all channels to achieve their unique activation patterns, negating the intended efficiency gains. However, the comment does not offer suggestions or guidance on how the authors might address this issue or improve the method's practicality. While it points out a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential limitation in the proposed method regarding its practicality in reducing computational load. It highlights a challenge in applying a uniform activation pattern across tokens due to their unique activation patterns, which may not generalize well to other tokens. The comment suggests that in extreme cases, all tokens would need to activate all channels to achieve their unique patterns, negating the intended efficiency gains. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the method's practicality. The action is implicit and somewhat vague, as the authors need to infer that they should explore ways to enhance the method's applicability and generalizability. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses a specific issue related to the practicality of reducing computational load in the proposed method. It highlights a potential challenge in applying a uniform activation pattern across tokens due to their unique activation patterns, which may not generalize well to other tokens. The comment is fully grounded as it explicitly mentions the issue of computational load and provides specific reasoning about the challenges involved. However, it does not specify which part of the paper discusses this issue, making it somewhat specific. Therefore, the comment is fully grounded and somewhat specific, aligning with category 4.\", 'grounding_specificity_label': '4', 'verifiability_rationale': \"The review point claims that the proposed method may face challenges in reducing computational load in real applications due to the difficulty in applying a uniform activation pattern across tokens. The comment provides a logical reasoning by explaining that different tokens activate different channels, which makes it challenging to generalize activation patterns. However, the claim lacks specific examples or references to support the assertion that these patterns may not generalize well or that all tokens would need to activate all channels to achieve their unique patterns. This makes the claim somewhat verifiable, as it provides a logical basis but requires further evidence or examples to fully substantiate the concern.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the proposed method regarding its practicality in reducing computational load. It highlights a specific challenge in applying a uniform activation pattern across tokens due to their unique"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of clarity in the core motivation of the paper, specifically mentioning the abstract\\'s statements about demarcating task boundaries and the proposed benchmark, metrics, and gating technique. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to clarify the motivation. The comment suggests that the stacked statements are not effective in capturing the main problem, but it does not offer concrete steps or examples of how the authors might rephrase or restructure their content to improve clarity. As a result, the authors are left with a vague understanding of what needs to be done to enhance the clarity of the paper\\'s motivation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the clarity of the core motivation in the paper, specifically mentioning the abstract\\'s statements about demarcating task boundaries and the proposed benchmark, metrics, and gating technique. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in identifying the issue of stacked statements that do not effectively capture the main problem, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the core motivation of the paper is not clear enough, citing the abstract\\'s statements about demarcating task boundaries and the proposed benchmark, metrics, and gating technique. However, the comment lacks specific examples or detailed reasoning to support the claim that these statements are not effective in capturing the main problem. Without further elaboration or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a key issue with the paper's core motivation, noting that the abstract does not effectively convey the main problem to be solved. It highlights the stacked statements about demarcating task boundaries and the proposed benchmark, metrics, and gating technique, suggesting that these elements do not clearly capture the main problem. This feedback is somewhat helpful as it points out a specific area of confusion or lack of clarity in the paper. However, it could be more helpful if it provided suggestions on how the authors might restructure or clarify their abstract to better communicate the core motivation. Overall, the comment offers a starting point for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the sequence inference classifier used for filtering data and questions the nature of the data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment identifies a specific area of concern and provides a clear action\u2014requesting examples of filtered data\u2014it does not offer explicit guidance on how to address the issue or what specific aspects of the classifier need improvement. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the sequence inference classifier used for filtering data, specifically questioning the nature of the data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where the classifier is discussed. The comment is specific in detailing what needs to be addressed, namely, providing examples of the filtered data. Therefore, the comment is weakly grounded but specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the sequence inference classifier used for filtering data, questioning the nature of the data that passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data to better understand the process. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The request for examples provides a direction for the authors to address the concern, but the comment itself is somewhat verifiable due to the lack of detailed evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the sequence inference classifier used for filtering data, specifically questioning the nature of the data that passes this filter. It notes that the task of filtering data using the task description seems different from the original MNLI distribution and suggests that examples of the filtered data would be helpful. This feedback is somewhat helpful as it identifies a potential area of confusion or discrepancy in the methodology, prompting the authors to clarify their approach. However, the comment could be more helpful if it provided specific suggestions on how to address the issue or what aspects of the classifier need further explanation. Overall, the comment offers a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the application experiments, including potential biases due to the reliance on a single model and a small dataset. It suggests that the authors need to conduct comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, it recommends an in-depth editorial review to improve the structure, argumentation, and language clarity of the paper. The comment provides specific examples, such as the chaotic equation numbering and the lack of indentation in Algorithm 1, which give the authors concrete guidance on how to address these issues. However, while the actions are explicit, the comment does not provide detailed instructions on how to conduct the comprehensive experiments or improve the editorial aspects. The authors know what needs to be done but may require additional guidance on the execution. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the application experiments, specifically mentioning the reliance on a single model (DALL-E) and a small dataset (30 famous paintings and 30 generated paintings). It highlights the potential biases and suggests that comprehensive experiments are needed to validate the effectiveness of the proposed methods. The comment also recommends an in-depth editorial review to improve the structure, argumentation, and language clarity of the paper. While the comment does not explicitly mention specific sections, the authors can infer that it pertains to the experimental results and the introduction of the paper. The feedback is specific in identifying the need for comprehensive experiments and editorial review, but it lacks explicit references to specific sections. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the application experiments may have biases due to the reliance on a single model and a small dataset. The reviewer supports this claim by noting that the experiment results are difficult to be convincing without comprehensive experiments. The comment also highlights specific issues, such as the chaotic equation numbering and the lack of indentation in Algorithm 1, which could affect the clarity and readability of the paper. While the comment provides some reasoning and examples, it lacks detailed justification or references to substantiate the claim fully. Therefore, the comment is somewhat verifiable, as it provides some support but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant concern regarding the application experiments, noting that the reliance on a single model (DALL-E) and a small dataset (30 famous paintings and 30 generated paintings) may introduce biases. It suggests that the authors need to conduct comprehensive experiments to validate the effectiveness of their proposed methods. Additionally, the comment recommends an in-depth editorial review to improve the structure, argumentation, and language clarity of the paper. It provides specific examples, such as the chaotic equation numbering and the lack of indentation in Algorithm 1, which give the authors concrete guidance on how to enhance the draft. While the feedback is mostly helpful, it could be more comprehensive by offering suggestions on how to conduct the comprehensive experiments or provide more detailed guidance on the editorial review. Overall, the comment is mostly helpful, as it provides clear and actionable feedback that can significantly improve the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider practical applications of catastrophic forgetting and provide comments on real tasks with available data. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include practical applications in their discussion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the practical applications of catastrophic forgetting, specifically questioning the relevance of the experiments conducted on datasets made up from standard benchmarks. It suggests that the authors should comment on real tasks with available data for which their model might be applicable. However, the comment does not specify which part of the paper this critique pertains to, such as the experimental section or the discussion. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the practical applications should be addressed or how the authors should comment on them. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the practical relevance of the experiments conducted in the paper, specifically questioning the use of datasets made up from standard benchmarks. The reviewer suggests that there might be real tasks with available data for which the model could be applied. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the practical relevance of the experiments conducted in the paper, specifically questioning the use of datasets made up from standard benchmarks. It suggests that the authors should comment on real tasks with available data for which their model might be applicable. This feedback is somewhat helpful as it prompts the authors to consider the broader implications of their work and encourages them to address the practicality of their approach. However, the comment could be more helpful if it provided specific examples or guidance on how to identify and discuss relevant real-world tasks. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the process of selecting m\\' in the CAL-MIR method, specifically asking if it involves an exhaustive search over all loss minimizer subsets. While the comment implies that this process might be prohibitive, it does not provide explicit guidance or suggestions for how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the selection process and potentially suggest a more efficient approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the selection of m\\' in the CAL-MIR method, specifically asking if it involves an exhaustive search over all loss minimizer subsets. This question implies that the authors should clarify this aspect of their methodology. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The question is specific in its inquiry about the selection process, but without explicit grounding, the authors may struggle to pinpoint the exact section needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the selection of m\\' in the CAL-MIR method, specifically asking if it involves an exhaustive search over all loss minimizer subsets. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection of m\\' in the CAL-MIR method, specifically asking if it involves an exhaustive search over all loss minimizer subsets. This question highlights a potential inefficiency or complexity in the selection process, which could be important for the authors to address. However, the comment does not provide any suggestions or guidance on how the authors might improve this aspect of their methodology. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider other backdoor detection methods that are input data-free, such as those based on weight matrix statistics or matrix factorization, in their analysis of algorithm performance. While the comment implies that these methods should be included, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should consider other backdoor detection methods, such as those based on weight matrix statistics or matrix factorization, in their analysis of algorithm performance. This provides clear guidance on what needs to be addressed in the \"Robustness\" section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider other backdoor detection methods that are input data-free, such as those based on weight matrix statistics or matrix factorization. This claim is somewhat verifiable as it provides a logical reasoning for including these methods in the analysis of algorithm performance. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential gap in the 'Robustness' section of the paper by suggesting that other backdoor detection methods, such as those based on weight matrix statistics or matrix factorization, should be considered. This feedback is valuable as it encourages the authors to broaden their analysis and potentially improve the robustness of their algorithm. However, the comment could be more helpful if it provided specific examples or references to these methods, which would enable the authors to better understand and implement the suggestion. Overall, the comment is mostly helpful as it highlights an area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the \"relation works section\" is incomplete and that the authors need to provide a description of which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback is clear and direct, providing the authors with a specific action to take: to include this information in the relation works section. The comment is explicit and concrete, offering a clear path for the authors to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"relation works section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking for a description of which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This provides clear guidance on what additional information is required. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"relation works section\" is incomplete and that the authors need to describe which view of the knowledge graph is part of the assumption. However, the comment does not provide specific examples or references to support why this information is crucial or how it affects the completeness of the section. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of incompleteness in the paper, namely the \"relation works section,\" and provides a clear and actionable suggestion for improvement. It specifies that the authors need to describe which view of the knowledge graph is part of the assumption, such as instance-view, ontology-view, or two-view KG. This feedback is valuable as it directs the authors to a specific aspect of their work that requires clarification, thereby helping them improve the clarity and completeness of their draft. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in addressing this issue. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the focus of the paper, suggesting that the contribution is more about regression than black box optimization. It implies that the authors should clarify this point and provide evidence of their method\\'s accuracy on the regression task compared to strong baselines. While the comment explicitly states that the authors should address this issue, it does not provide specific guidance on how to conduct the comparison or which baselines to use. The action is clear but somewhat vague, as it lacks detailed instructions on how to implement the suggested comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the problem setup and the relevance of the optimality gap metric, suggesting that the contribution is more about regression than black box optimization. It implies that the authors should clarify their focus and provide evidence of their method\\'s accuracy on the regression task compared to strong baselines. However, the comment does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The feedback is specific in suggesting a comparison with strong baselines to clarify the contribution, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the focus of the paper, suggesting that the contribution is more about regression than black box optimization. The reviewer questions whether the optimality gap is a relevant metric for the proposed method, given that the contribution is about regression. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a logical basis for questioning the focus of the paper but lacks sufficient detail to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the focus of the paper, suggesting that the contribution is more about regression than black box optimization. It questions whether the optimality gap is a relevant metric for the proposed method, given that the contribution is about regression. The reviewer suggests that the authors should clarify this point and provide evidence of their method's accuracy on the regression task compared to strong baselines. This feedback is clear and actionable, as it directs the authors to address a potential misalignment in their focus and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or which baselines to consider. Overall, the comment is mostly helpful as it identifies a critical area for clarification and improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical support for the technical design, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It also notes that the update derivation for these parameters is hardly convincing. While the comment identifies an area that requires improvement, it does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they need to strengthen the theoretical foundation and provide a more convincing derivation, but the lack of concrete steps or examples makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical support for the technical design, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It references a specific update derivation (Eq.7-10) and provides a citation (Sorg et al. 2010) for further context. This level of detail allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it details what needs to be addressed, namely the theoretical support and the convincing derivation of the update for intrinsic reward parameters. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical design lacks theoretical support, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It references a previous work (Sorg et al. 2010) for context, but the comment lacks detailed reasoning or specific examples to fully substantiate the claim. While the reference provides some context, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the theoretical foundation of the technical design, specifically noting the lack of theoretical support for the update of intrinsic reward parameters. It highlights a need for justification and provides a reference to a previous work (Sorg et al. 2010) for context. However, the comment could be more helpful if it offered specific suggestions or guidance on how to strengthen the theoretical foundation or provide a more convincing derivation. While it points out a critical area for improvement, the lack of detailed actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a lack of theoretical support for the technical design, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It references a previous work (Sorg et al. 2010) for context, but the comment does not provide explicit guidance on how to address this issue or what specific changes should be made. The authors are left to infer that they need to strengthen the theoretical foundation and provide a more convincing derivation, but the lack of concrete steps or examples makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical support for the technical design, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It references a specific update derivation (Eq.7-10) and provides a citation (Sorg et al. 2010) for further context. This level of detail allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it details what needs to be addressed, namely the theoretical support and the convincing derivation of the update for intrinsic reward parameters. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the technical design lacks theoretical support, specifically mentioning the need for justification regarding the update of intrinsic reward parameters. It references a previous work (Sorg et al. 2010) for context, but the comment lacks detailed reasoning or specific examples to fully substantiate the claim. While the reference provides some context, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the theoretical foundation of the technical design, specifically noting the lack of theoretical support for the update of intrinsic reward parameters. It references a previous work (Sorg et al. 2010) for context, which provides some direction for the authors to consider. However, the comment lacks specific guidance or actionable suggestions on how to strengthen the theoretical"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on the choice of a \"small enough\" beta parameter. The reviewer implies that this choice does not align with the adaptivity claim, as it is not consistent with adaptive methods like AdaGrad. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their claim. The action is implicit and vague, as the authors are left to infer that they need to reconsider their claim and possibly provide a more robust justification. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on the choice of a \"small enough\" beta parameter. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in pointing out the issue with the adaptivity claim and referencing AdaGrad as an example, but it lacks detailed guidance on how the authors might address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' claim of an adaptive variance reduction property, suggesting that it is based on the choice of a \"small enough\" beta parameter, which is not consistent with adaptive methods like AdaGrad. The comment provides a logical reasoning by comparing the claim to adaptive methods, which is a common-sense argument. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more detailed evidence or examples to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the authors' claim of an adaptive variance reduction property, suggesting that it is based on the choice of a 'small enough' beta parameter, which does not align with the adaptivity claim. The reviewer provides a logical critique by comparing this to adaptive methods like AdaGrad. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their claim. While it identifies a potential weakness, it does not offer actionable steps or detailed feedback that could help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the unclear value of different augmentation techniques and suggests further investigation into why DINOv2 is the best-performing model most of the time. It implies that the authors should explore the reasons behind this and consider ways to improve the best-performing model. However, the comment does not provide specific guidance on how to conduct this investigation or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the unclear value of different augmentation techniques and suggests further investigation into why DINOv2 is the best-performing model most of the time. However, it does not specify which part of the paper discusses these techniques or where the investigation should be conducted. The authors can infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in suggesting an area for further investigation but lacks grounding, as it does not pinpoint the exact section or table where this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the value of different augmentation techniques is unclear and that DINOv2 is the best-performing model most of the time. However, it does not provide any specific evidence, reasoning, or examples to support these claims. The comment lacks detailed justification or references to external works that could substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area of improvement by questioning the value of different augmentation techniques and noting that DINOv2 seems to be the best-performing model most of the time. It suggests further investigation into why this is the case and how to improve the best-performing model. This feedback is somewhat helpful as it points out a specific area for exploration and improvement, but it lacks depth and does not provide detailed guidance on how to conduct the investigation or what aspects to focus on. The authors are given a direction to consider, but the comment could be more comprehensive and actionable with additional details or suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it is similar to \"Follow the Leader,\" which is a well-established term in the literature. The reviewer implies that a change in the acronym might be necessary to avoid confusion. However, the comment does not explicitly instruct the authors to make this change or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider changing the acronym but are not given specific instructions on how to implement this suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it is similar to \"Follow the Leader,\" which is a well-established term in the literature. However, it does not specify which part of the paper this acronym is used in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the acronym, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the acronym for \"follow the top perturbed leader\" is unfortunate because it is similar to \"Follow the Leader,\" which is a well-established term in the literature. The reviewer provides a logical reasoning by pointing out the potential confusion caused by the similarity between the two acronyms. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the potential confusion and the need for a change in the acronym, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the acronym used for \"follow the top perturbed leader,\" noting that it is unfortunate because it is similar to \"Follow the Leader,\" which is a well-established term in the literature. The reviewer suggests that a change in the acronym might be necessary to avoid confusion. While the comment highlights a specific area for improvement, it lacks depth and does not provide detailed guidance on how to address this issue or what alternative acronyms might be more appropriate. The feedback is somewhat helpful as it points out a potential problem, but it could be more beneficial with additional suggestions or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the selection of attacks in Table 1 is arbitrary and suggests that the attacks are not state-of-the-art. It further recommends including a reference to a survey paper (https://arxiv.org/pdf/2310.17534.pdf) for an extensive analysis. Additionally, the comment suggests mentioning the number of iterations the attacks are run for and other relevant hyperparameters. These suggestions are clear and provide specific guidance on how the authors can improve their draft by expanding the information in Table 1. The feedback is explicit and concrete, allowing the authors to directly address the issues and enhance the comprehensiveness of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the selection of attacks, suggesting that the current choices are arbitrary and not state-of-the-art. The comment further recommends including a reference to a survey paper for an extensive analysis and suggests mentioning the number of iterations and other hyperparameters. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of attacks in Table 1 is arbitrary and suggests that the attacks are not state-of-the-art, as there are dozens of better attacks available, such as MIDIFGSM. The reviewer provides a reference to a survey paper (https://arxiv.org/pdf/2310.17534.pdf) for an extensive analysis, which supports the claim. However, the comment could be strengthened by providing specific examples of the better attacks or by elaborating on why the current selection is considered arbitrary. Despite this, the feedback is mostly verifiable as it offers a logical basis for the claim and provides a reference for further exploration. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the selection of attacks in Table 1, noting that the choices are arbitrary and not state-of-the-art. It provides a clear suggestion to include a reference to a survey paper (https://arxiv.org/pdf/2310.17534.pdf) for an extensive analysis of attacks. Additionally, the comment recommends mentioning the number of iterations and other hyperparameters for the attacks, which is a valuable piece of advice for improving the transparency and reproducibility of the results. This feedback is clear and actionable, offering the authors a straightforward way to enhance the quality and comprehensiveness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the method, stating that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or explore the performance of their method with different pre-training methods. Without actionable suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to the limitations and conclusion sections of the paper, indicating that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, it does not specify which parts of the paper discuss these limitations or provide specific examples of where the method is applied. The authors can infer that it relates to the limitations and conclusion sections, but the lack of explicit references makes it difficult to pinpoint the exact parts of the paper being addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the method is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors are left without a clear understanding of the basis for this assertion, making it difficult for them to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the method, specifically noting that it is primarily effective for encoders pre-trained with contrastive learning and may not perform well with other self-supervised learning pre-training methods like Masked Image Modeling (MIM). This feedback is somewhat helpful as it highlights an area where the method's applicability might be restricted. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or explore the performance of their method with different pre-training methods. Without actionable advice or further elaboration, the feedback is limited in its usefulness for improving the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the qualitative analysis section, specifically regarding the determination of input sentences, the fine-tuning process, and the attribution values in Figure 1. It explicitly asks for clarification on how the input sentences were chosen and whether they were part of the fine-tuning process. Additionally, it questions the normalization of vector norms and the effectiveness of the attribution map for input examples that failed classification. While the comment provides specific areas for improvement, it does not offer explicit guidance on how to address these issues or what changes to make. The authors are left to infer the necessary actions, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 4.5.5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the qualitative analysis, such as the determination of input sentences, the fine-tuning process, and the attribution values in Figure 1. The reviewer questions the normalization of vector norms and the effectiveness of the attribution map for input examples that failed classification. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises several questions and concerns about the qualitative analysis section, specifically regarding the determination of input sentences, the fine-tuning process, and the attribution values in Figure 1. The reviewer asks for clarification on how the input sentences were chosen and whether they were part of the fine-tuning process. Additionally, it questions the normalization of vector norms and the effectiveness of the attribution map for input examples that failed classification. While the comment does not contain subjective opinions or claims, it seeks clarification on specific aspects of the paper, which is a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions and concerns about the qualitative analysis section of the paper. It specifically asks for clarification on how the input sentences for qualitative analysis were determined, whether they were part of the fine-tuning process, and whether the attribution values in Figure 1 are normalized. Additionally, it questions the effectiveness of the attribution map for input examples that failed classification. This feedback is clear and actionable, providing the authors with specific areas to address and improve upon. By addressing these points, the authors can enhance the clarity and robustness of their qualitative analysis. Therefore, the comment is rated as highly helpful, as it offers detailed guidance that can significantly contribute to the improvement of the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a clear and explicit suggestion for the authors to include examples of practical applications where specific types of tensors need to be equivariant. It also instructs the authors to clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is concrete and provides a direct action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to include specific examples and clarify their relevance. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the discussion or conclusion sections, but this inference is not explicit. The comment is specific in its suggestion to include examples and clarify the advantages, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any specific examples or references to support the claim that these examples are necessary or how they would validate the advantages. Without detailed reasoning or evidence, the authors may find it challenging to understand the significance of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to include examples of practical applications where specific types of tensors need to be equivariant. It also instructs the authors to clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is specific and offers a concrete way for the authors to enhance their draft by providing real-world context and demonstrating the utility of their work. However, the comment could be more helpful if it included specific examples or references to guide the authors in their selection of applications. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path forward, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with the tables, particularly Table 2, where it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. It also notes that Section 3.2.3 does not fully align with the table. While the comment highlights the need for clarification and alignment, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the methods and ensure alignment between the table and the section, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the unclear representation of methods like ERM, cRT, and LWS, and the lack of alignment between Section 3.2.3 and the table. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific issues with the tables, such as the unclear representation of methods like ERM, cRT, and LWS, and the lack of alignment between Section 3.2.3 and the table. These claims are based on the observation of the current state of the paper, which is a form of logical reasoning. However, the comment lacks specific examples or references to support the claim of misalignment, making it somewhat verifiable. The authors would need to infer the exact nature of the misalignment, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific issues with the tables, particularly Table 2, where it is unclear what methods like ERM, cRT, and LWS represent, as they are not referenced properly. Additionally, it notes that Section 3.2.3 does not fully align with the table. This feedback is clear and actionable, as it points out specific areas where the paper needs clarification and improvement. By addressing these issues, the authors can enhance the clarity and coherence of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the methods or improve the alignment between the table and the section. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two specific questions for the authors to address. The first question asks for more details on the suitability of the model for sarcastic and non-sarcastic utterances. The second question seeks clarification on why eye-movement data would be useful for sarcastic/non-sarcastic sentiment classification beyond textual features. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors are left to infer the specific details or analyses needed to provide the requested information. Therefore, the comment is somewhat actionable, as it identifies clear areas for improvement but lacks detailed instructions on how to implement the changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear and detailed feedback on two specific points: the suitability of the model for sarcastic and non-sarcastic utterances, and the usefulness of eye-movement data for sarcastic/non-sarcastic sentiment classification beyond textual features. The authors are given clear guidance on what additional information or explanations are needed to address these points. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions that seek clarification on the suitability of the model for sarcastic and non-sarcastic utterances and the usefulness of eye-movement data for sarcastic/non-sarcastic sentiment classification. These questions are logical and seek additional information or explanations, but they do not contain claims or opinions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two specific questions for the authors to address, which are relevant to the content and analysis of the paper. The first question asks for more details on the suitability of the model for sarcastic and non-sarcastic utterances, which is a valid concern that could impact the paper\\'s applicability. The second question seeks clarification on the usefulness of eye-movement data for sarcastic/non-sarcastic sentiment classification, which is an important consideration for the field. While the comment identifies areas for improvement, it does not offer detailed guidance or suggestions on how to address these issues. The authors are left to infer the specific details or analyses needed to provide the requested information. Therefore, the comment is somewhat helpful, as it provides clear areas for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results are few, noting that the paper only conducts experiments on two small-scale/resolution datasets. It also mentions that the tables are unprofessional, specifically identifying that \"DDIM is a sampler method, not a model.\" However, the comment does not provide explicit guidance on how the authors should address these issues. While it highlights areas for improvement, it lacks concrete suggestions or actions for the authors to take, such as recommending additional experiments or suggesting ways to improve the presentation of the tables. As a result, the authors are left without clear instructions on how to enhance their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental results and the presentation of tables, specifically mentioning \"table1 and table2\" as being unprofessional and incorrectly identifying \"DDIM\" as a sampler method instead of a model. This provides some level of grounding as it references specific parts of the paper, making it weakly grounded. However, the comment lacks specificity in terms of what exactly is wrong with the experimental results or the tables, such as suggesting how to improve them or what additional experiments should be conducted. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experimental results are few and that the tables are unprofessional, specifically mentioning that \"DDIM is a sampler method, not a model.\" However, the comment lacks detailed reasoning or evidence to support these claims. It does not provide specific examples or comparisons to illustrate the issues with the experimental results or the tables. Without additional context or justification, the authors may find it challenging to understand and address the concerns effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper: the limited number of experimental results and the unprofessional presentation of the tables. It points out that the experiments are conducted only on two small-scale/resolution datasets and that the tables are incorrect, with 'DDIM' being labeled as a sampler method instead of a model. This feedback is somewhat helpful as it highlights areas where the paper could be improved, such as expanding the experimental scope or correcting the labeling in the tables. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues, such as recommending additional datasets or methods for comparison. Therefore, the comment is rated as somewhat helpful, as it provides some insight but does not fully support the authors in improving their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more clarification about why the proposed method is important. It points out that the method is essentially adjusting the variance level of DPSGD, which should influence the utility, but it questions what might be lost in terms of privacy. The comment implies that the authors should address this issue by explaining the trade-offs between utility and privacy. While the action is explicit, it lacks concrete guidance on how to present this information or what specific aspects to focus on. The authors know they need to clarify the importance of the method, but the comment does not provide detailed instructions on how to do so. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors provide more clarification about the importance of the proposed method, specifically questioning whether it is just adjusting the variance level of DPSGD and what impact this might have on privacy. However, it does not specify which part of the paper this clarification should be addressed in, making it weakly grounded. The comment is specific in its request for clarification on the importance and potential impact of the method, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed method is essentially adjusting the variance level of DPSGD, which should influence the utility but questions what might be lost in terms of privacy. The reviewer implies that the authors should present this trade-off more clearly. However, the comment lacks specific examples or references to support the claim about the method\\'s impact on privacy. While the suggestion is logical, it requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper's explanation regarding the importance of the proposed method. It questions whether the method is merely adjusting the variance level of DPSGD, and if so, it should also discuss the potential impact on privacy. This feedback is somewhat helpful as it points out a specific area where the authors need to clarify their claims and provide more detailed explanations. However, the comment lacks depth and does not offer specific suggestions on how to address this issue, such as what aspects of privacy might be affected or how to present this information effectively. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. The comment provides a clear and explicit action for the authors to take, which is to conduct a larger-scale experiment and include a longer-horizon example. This guidance is concrete, as it specifies the type of experiment and the type of example needed. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or result. This makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment provides a clear suggestion for improvement, it lacks grounding, as the authors cannot confidently determine the specific section being addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the empirical results are illustrative rather than demonstrative and recommends conducting a bigger-scale experiment, particularly with a longer-horizon example. However, the comment does not provide any specific reasoning or evidence to support why a bigger-scale experiment or longer-horizon example would be beneficial. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the empirical results, suggesting that they are illustrative rather than demonstrative. It provides a specific suggestion for improvement by recommending a bigger-scale experiment, particularly with a longer-horizon example. This feedback is clear and actionable, as it guides the authors on how to enhance the empirical validation of their work. However, the comment could be more helpful if it included additional details or examples of what a longer-horizon example might entail or how it could be structured. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Equation (13) does not have a closed-form solution in general and suggests that the authors provide details on how it is solved in the experiments and discuss the computational complexity. This feedback is clear and direct, giving the authors a specific action to take: to include details about the solution and computational complexity. The comment provides concrete guidance on what information is needed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation (13), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the equation, namely that it does not have a closed-form solution in general, and suggests that the authors provide details on how it is solved in the experiments and discuss the computational complexity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equation (13) does not have a closed-form solution in general, which is a factual statement. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equation (13), noting that it does not have a closed-form solution in general. It provides a clear suggestion for improvement by asking the authors to provide details on how the equation is solved in the experiments and discuss the computational complexity. This feedback is actionable and helps the authors understand where their draft could be improved, making it mostly helpful. However, it could be more helpful if it included specific examples or guidance on how to address the computational complexity aspect. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of discussion on the choice of \"proximity\" and the nature of the task. It suggests that the authors should analyze which tasks have reasonable proximity metrics and demonstrate failure on those that do not. While the comment implies that the authors should address this issue, it does not provide explicit instructions on how to conduct this analysis or what specific tasks to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion on the choice of \"proximity\" and the nature of the task, specifically mentioning the proposed tasks. It provides a specific example of a complicated maze where the Euclidean metric can be misleading, suggesting that the paper would be better if it analyzed which tasks have reasonable proximity metrics and demonstrated failure on those that do not. This feedback is fully grounded as it explicitly mentions the \"proximity\" and \"fingertip Cartesian positions\" and provides a specific example of a task where the relationship between proximity and solution space is not straightforward. The comment is also specific in its suggestion to analyze and demonstrate failure on tasks with unreasonable proximity metrics. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion on the choice of \"proximity\" and the nature of the task, particularly in relation to the proposed tasks. It provides a specific example of a complicated maze where the Euclidean metric can be misleading, suggesting that the paper would be better if it analyzed which tasks have reasonable proximity metrics and demonstrated failure on those that do not. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the tasks with reasonable proximity metrics. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the choice of \"proximity\" and the nature of the task. It highlights a critical issue by noting that the relationship between proximity in fingertip Cartesian positions and proximity in the solution space does not hold for certain tasks, such as complicated mazes or robotic tasks with various obstacles and collisions. The comment suggests that the paper would be improved by analyzing which tasks have reasonable proximity metrics and demonstrating failure on those that do not. This feedback is clear and actionable, providing the authors with a specific direction for improvement. However, it could be more helpful if it offered additional guidance on how to analyze and demonstrate these points. Overall, the comment is mostly helpful, as it effectively directs the authors to address a significant oversight in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experiments lack many implementation details necessary for readers to fully understand or reproduce the results. It also provides a reference to \"Questions\" for more details, which implies that the authors should address these questions to provide the necessary implementation details. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which is to include the missing implementation details as requested in the questions. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a lack of implementation details in the experiments, which is a specific issue that the authors need to address. However, it does not specify which part of the paper these details are missing from, making it weakly grounded. The comment is specific in detailing what is missing, such as implementation details necessary for readers to understand or reproduce the results. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack many implementation details necessary for readers to fully understand or reproduce the results. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand exactly what details are missing or how to address them. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the specific details that need to be included. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the experiments, specifically noting that they lack many implementation details necessary for readers to fully understand or reproduce the results. This feedback is clear and actionable, as it directs the authors to provide the missing implementation details. However, the comment could be more helpful if it specified which details are missing or suggested how to address them. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of the comparison between SSUL and the paper, noting that the use of different detectors for object proposal generation may introduce bias. It suggests two potential improvements: either SSUL adopts Mask2Former for detecting unseen classes or it generates object proposals in an unsupervised manner without additional data or a heavy model. While the comment implies these actions, it does not explicitly instruct the authors to make these changes. The suggestion is concrete in terms of the proposed solutions, but the action is inferred, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a potential issue with the comparison between SSUL and the paper, specifically regarding the use of different detectors for object proposal generation. It points out that the use of a pretrained Mask2Former for this purpose may introduce an unfair comparison due to differences in data and model size. The comment suggests two potential improvements: either SSUL adopts Mask2Former for detecting unseen classes or it generates object proposals in an unsupervised manner without additional data or a heavy model. However, the comment does not specify which part of the paper discusses the use of these detectors or the comparison between them, making it weakly grounded. The suggestion is specific, as it provides clear guidance on how to address the issue, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between SSUL and the paper, noting the use of different detectors for object proposal generation. It points out that the use of a pretrained Mask2Former may introduce an unfair comparison due to differences in data and model size. The reviewer suggests two potential improvements: either SSUL adopts Mask2Former for detecting unseen classes or it generates object proposals in an unsupervised manner without additional data or a heavy model. While the comment provides a logical reasoning for the concern, it lacks specific references or examples to fully substantiate the claim. The suggestion is mostly verifiable as it offers a clear direction for improvement but could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the comparison between SSUL and the paper, specifically regarding the use of different detectors for object proposal generation. It points out that the use of a pretrained Mask2Former may introduce an unfair comparison due to differences in data and model size. The comment suggests two potential improvements: either SSUL adopts Mask2Former for detecting unseen classes or it generates object proposals in an unsupervised manner without additional data or a heavy model. This feedback is clear and actionable, providing the authors with specific suggestions for enhancing the fairness of their comparison and improving the methodology. However, the comment could be more helpful if it included specific examples or references to support the suggested improvements. Overall, the comment is mostly helpful as it guides the authors towards addressing a potential weakness in their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights potential issues with the validation of the proposed approach, specifically regarding the metrics used for evaluation. It points out that the style accuracy is based on a style classifier, which may be accurate but does not necessarily validate the performance of the algorithm. Additionally, it questions the verifiability of the transfer results when using a styled motion input. While the comment identifies areas for concern, it does not provide explicit guidance or suggestions on how the authors might address these issues or improve the validation process. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the validation of the proposed approach, specifically mentioning the metrics used for evaluation. It points out potential issues with the style accuracy metric, which is based on a style classifier, and questions the verifiability of the transfer results when using a styled motion input. However, the comment does not specify which part of the paper discusses these metrics or the experiments, making it weakly grounded. The feedback is specific in identifying the issues with the validation process, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the validation of the proposed approach, specifically regarding the metrics used, such as style accuracy. It questions the reliance on a style classifier for accuracy and the verifiability of the transfer results when using a styled motion input. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claims. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some justification but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the validation of the proposed approach, specifically regarding the metrics used, such as style accuracy. It points out that the style accuracy is based on a style classifier, which may be accurate but does not necessarily validate the performance of the algorithm. Additionally, it questions the verifiability of the transfer results when using a styled motion input. While the comment highlights important considerations for the evaluation of the proposed approach, it lacks specific suggestions or guidance on how the authors might address these issues or improve the validation process. The feedback is somewhat helpful as it points out areas for improvement but could be more actionable with detailed recommendations or examples.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of how individual preferences are generated and interpreted in the paper. It explicitly points out that the authors need to clarify whether \"preference\" is understood as rules or policies learned from experiences, or if it refers to a more nuanced concept. While the comment identifies a specific area that requires clarification, it does not provide explicit guidance on how to address this issue or suggest specific changes. The action is implicit and somewhat vague, as the authors know they need to clarify the concept of \"preference,\" but the comment does not offer detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"paper\" and the specific issue of how individual preferences are generated and interpreted. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for clarification regarding the generation and interpretation of individual preferences, particularly in relation to risk aversion among agents. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of how individual preferences are generated and interpreted in the paper. It questions whether the authors have adequately addressed the concept of \"preference\" and whether it is understood as rules or policies learned from experiences. The comment suggests that this needs to be clarified. While the comment identifies a potential area of confusion, it does not provide specific examples or references to support the claim. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the exact nature of the issue based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding the interpretation of 'preference' in the paper. It points out that the authors need to clarify how individual preferences are generated and interpreted, particularly in relation to risk aversion among agents. This feedback is clear and actionable, as it directs the authors to address a potential weakness in their argumentation. By providing a specific area for clarification, the comment offers valuable guidance for improving the clarity and coherence of the paper. However, it could be more helpful if it suggested ways to address the issue or provided examples of how to clarify the concept of 'preference.' Overall, the comment is mostly helpful, as it effectively guides the authors towards enhancing the clarity of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises several questions about Figure 4, specifically regarding the meaning of '1-200 frames,' how the values are computed, and why the precision and recall change with trajectory length. It also asks about the concept of 'action repeat.' While the comment identifies specific areas of confusion, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their draft. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the figure, such as the lack of clarity in the meaning of \"1-200 frames,\" the computation of values, and the change in precision and recall with trajectory length. Additionally, it questions the concept of \"action repeat.\" This level of detail provides clear guidance on what needs to be addressed in the figure, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises questions about the clarity of Figure 4, specifically regarding the meaning of '1-200 frames' and how the values are computed. It also questions why the precision and recall change with the trajectory length and asks about the concept of 'action repeat.' While the comment identifies areas of confusion, it does not provide specific examples or references to support these claims. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies specific issues with Figure 4, providing clear and actionable feedback. It questions the clarity of the figure, specifically regarding the meaning of '1-200 frames' and how the values are computed. Additionally, it asks why the precision and recall change with the trajectory length and seeks clarification on the concept of 'action repeat.' This feedback is valuable as it directs the authors to areas where their draft needs clarification, allowing them to improve the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the figure. Overall, the comment is mostly helpful, as it provides clear guidance for improvement but could be more comprehensive with additional suggestions.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the arbitrariness of certain design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that the authors should provide justification for these decisions, especially in light of the cost-effectiveness motivation. The reviewer also proposes a specific comparison, comparing LLaMAA with finetuning on a number of samples equivalent in cost to the additional samples from the LLM. While the comment implies that the authors should provide justification for their design choices, it does not explicitly instruct them to do so. The suggestion to compare LLaMAA with finetuning adds a concrete action, but the overall feedback is somewhat vague and lacks detailed guidance on how to address the arbitrariness of the design decisions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific design decisions, such as the number of initial ground truth examples and the number of labeled examples, which are mentioned as arbitrary. It suggests that the authors should provide justification for these decisions, especially in light of the cost-effectiveness motivation. The comment also proposes a specific comparison, comparing LLaMAA with finetuning on a number of samples equivalent in cost to the additional samples from the LLM. However, it does not explicitly mention which part of the paper these design decisions are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the design decisions and the proposed comparison, providing clear guidance for the authors. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the arbitrariness of certain design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, especially in light of the cost-effectiveness motivation. The reviewer proposes a specific comparison, comparing LLaMAA with finetuning on a number of samples equivalent in cost to the additional samples from the LLM, to provide a more satisfying explanation. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that these decisions are arbitrary. The suggestion for a comparison provides some direction, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the arbitrariness of certain design decisions, such as the number of initial ground truth examples and the number of labeled examples. It suggests that these decisions should be justified, especially in light of the cost-effectiveness motivation. The reviewer also proposes a specific comparison, comparing LLaMAA with finetuning on a number of samples equivalent in cost to the additional samples from the LLM, to provide a more satisfying explanation. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by justifying their design choices and comparing different approaches. However, the comment could be more helpful if it provided additional guidance on how to justify these decisions or what specific aspects of the design should be addressed. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also points out that the encoder and decoder are based on the Transformer, which can already handle global dependencies. The reviewer expresses confusion about the complexity of the approach. While the comment highlights an area of potential confusion, it does not provide explicit guidance or suggestions on how the authors might address this issue or clarify their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the motivation and approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation behind using a graph structured model to capture global dependencies in sentences, which is different from existing sequence models that focus on local dependencies. It also notes that the encoder and decoder are based on the Transformer, which can handle global dependencies. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The comment is specific in questioning the complexity of the approach and suggesting that the authors clarify their motivation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also points out that the encoder and decoder are based on the Transformer, which can already handle global dependencies. The comment expresses confusion about the complexity of the approach. However, it does not provide specific examples, references, or detailed reasoning to support the claim that the approach is complex or that the authors should clarify their motivation. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the basis of the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also points out that the encoder and decoder are based on the Transformer, which can already handle global dependencies. This feedback highlights a potential area of confusion for the reader and suggests that the authors clarify their motivation and approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide a clearer explanation. While it identifies a potential area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also points out that the encoder and decoder are based on the Transformer, which can already handle global dependencies. The comment expresses confusion about the complexity of the approach. While the comment identifies an area of potential confusion, it does not provide explicit guidance or suggestions on how the authors might address this issue or clarify their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the motivation and approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also points out that the encoder and decoder are based on the Transformer, which can already handle global dependencies. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The comment is specific in questioning the complexity of the approach and suggesting that the authors clarify their motivation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the motivation behind using a graph structured model to capture global dependencies in sentences, noting that existing sequence models typically focus on local dependencies. It also points out that the encoder and decoder are based on the Transformer, which can already handle global dependencies. The comment expresses confusion about the complexity of the approach. However, it does not provide specific examples, references, or detailed reasoning to support the claim that the approach is complex or that the authors should clarify their motivation. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the basis of the reviewer\\'s concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', '"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing videos demonstrating different policies controlling cars on different tracks would enhance the understanding of how various methods work. Additionally, it highlights the lack of implementation details in the main paper, which makes reproducing the results challenging. The comment explicitly suggests that the authors should provide videos and clarify the policy gradient approach used. This feedback is clear and provides concrete actions for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing videos to demonstrate different policies controlling cars on different tracks, which could enhance the understanding of the methods. It also mentions the lack of implementation details in the main paper, which makes reproducing the results difficult. However, the comment does not specify which part of the paper lacks these details or how they should be addressed. While it provides a clear suggestion for improvement, it lacks full grounding as it does not explicitly mention specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing videos demonstrating different policies controlling cars on different tracks would enhance the understanding of the methods. It also notes that some implementation details are lacking, making it difficult to reproduce the results. The claim is somewhat verifiable as it provides a suggestion for improvement and highlights a specific area where the paper could be strengthened. However, it lacks detailed examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two actionable suggestions for improvement. First, it suggests that providing videos demonstrating different policies controlling cars on different tracks would enhance the understanding of the methods. This is a clear and specific recommendation that could significantly improve the paper\\'s comprehensibility. Second, it highlights the lack of implementation details in the main paper, which makes reproducing the results difficult. This feedback is also actionable, as it directs the authors to clarify the policy gradient approach used. While the comment could be more detailed in explaining the importance of these suggestions, it still offers valuable guidance for enhancing the paper. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the approximation in Equation 11 and suggests that it does not account for the effect of the order of layers with the same parameters in the network. It also points out a lack of clarity in Figure 1 regarding the representation of different parameters in each layer. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to conduct more experiments and theoretical analyses to explore the effect of the order of layers with the same parameters. However, the lack of concrete guidance on how to conduct these experiments or analyses makes the action implicit and vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation 11 and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by questioning the approximation in Equation 11 and suggesting that it does not account for the effect of the order of layers with the same parameters in the network. Additionally, it points out a lack of clarity in Figure 1 regarding the representation of different parameters in each layer. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the approximation in Equation 11 and suggests that it does not account for the effect of the order of layers with the same parameters in the network. It also points out a lack of clarity in Figure 1 regarding the representation of different parameters in each layer. While the comment identifies a potential issue with the approximation, it does not provide specific examples or references to support the claim that the approximation is incomplete. The suggestion to conduct more experiments and theoretical analyses is a logical response to the identified issue but lacks detailed guidance on how to address it. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the approximation in Equation 11, specifically questioning why it can be approximated in the way proposed by the authors. It points out a potential limitation in the approximation, which only considers the impact of parameters in each layer and does not account for the effect of the order of layers with the same parameters in the network. Additionally, it highlights a lack of clarity in Figure 1 regarding the representation of different parameters in each layer. The comment suggests that the authors should conduct more experiments and theoretical analyses to explore this aspect. While the comment identifies a specific area for improvement, it lacks detailed guidance on how to conduct these experiments or analyses, making it somewhat helpful. The authors are given a direction to improve their work but are left to infer the specific steps needed to address the issue. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the offline-to-online learning adaption is incremental and that implementing online fine-tuning on existing benchmarks is feasible. However, it does not provide specific guidance or suggestions on how the authors should address this issue or improve their approach. The comment lacks explicit or implicit actions for the authors to take, making it unactionable. The authors are left without a clear understanding of what steps to take to enhance their draft based on this feedback.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the incremental nature of addressing offline-to-online learning adaption and mentions that most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its observation about the incremental nature of the approach and the feasibility of online fine-tuning, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the offline-to-online learning adaption is incremental and that implementing online fine-tuning on existing benchmarks is feasible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the claim, making it difficult to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the incremental nature of the offline-to-online learning adaption and suggests that most previous offline RL benchmarks are based on simulation environments and rule-based reward functions. It points out the feasibility of implementing online fine-tuning on existing benchmarks. However, the comment lacks specific guidance or actionable suggestions on how the authors might address this issue or improve their approach. While it highlights a relevant aspect, it does not provide detailed feedback or constructive advice that could help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction in the results presented in Table 6, specifically mentioning that AT fine-tunes the detection model with emotion classification data but achieves a worse F1 score than BERTsynth. It also points out that GAS achieves the lowest F1 score despite fine-tuning with emotion classification datasets. The reviewer suggests that these results do not support the claim that emotion-awareness is useful for synthetic text detection. However, the comment does not provide specific guidance or suggestions on how the authors should address this issue or improve their results. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their claims regarding emotion-awareness. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the contradiction in the results, providing examples of AT and GAS, and explaining why these results suggest that emotion-awareness might not be useful for synthetic text detection. The comment clearly specifies what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 6 provides contradicting evidence regarding the utility of emotion-awareness for synthetic text detection. It cites specific examples, such as AT and GAS, to illustrate the discrepancy in results. However, the comment lacks detailed reasoning or analysis to fully substantiate the claim. While the examples are clear, the absence of detailed justification or references to support the claim makes it somewhat verifiable. The authors would need to provide more context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a contradiction in the results presented in Table 6, specifically regarding the utility of emotion-awareness for synthetic text detection. It points out that AT, which fine-tunes the detection model with emotion classification data, achieves a worse F1 score than BERTsynth, and that GAS, despite fine-tuning with emotion classification datasets, achieves the lowest F1 score. This observation suggests that the results do not support the claim that emotion-awareness is useful for synthetic text detection. The comment provides clear and actionable feedback by highlighting specific examples and suggesting that the authors should address this contradiction in their results. However, it could be more helpful if it offered suggestions on how to resolve the contradiction or further explore the implications of these findings. Overall, the comment is mostly helpful as it directs the authors' attention to a critical issue in their results and provides a starting point for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments to address the research question and demonstrate the method\\'s generalizability. It specifically recommends testing with various models, including Vision Transformers (ViT), and mentions two references for further reading. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions, to provide a more comprehensive evaluation. While the comment provides clear guidance on what additional experiments to conduct and references to support the suggestions, it does not explicitly instruct the authors to perform these experiments or how to implement them. The action is concrete but not explicitly stated, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments to address the research question and demonstrate the method\\'s generalizability. It specifically recommends testing with various models, such as Vision Transformers (ViT), and references two papers for further reading. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions, to provide a more comprehensive evaluation. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental section or methodology. The authors can infer that it relates to the experimental setup or results, but the comment does not provide explicit references to specific parts of the paper. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments to address the research question and demonstrate the method\\'s generalizability. It recommends testing with various models, such as Vision Transformers (ViT), and references two papers for further reading. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions, to provide a more comprehensive evaluation. The comment provides specific references and examples, which enhance its verifiability. However, it could be strengthened by providing more detailed reasoning on why these experiments are necessary or how they would improve the paper. Overall, the comment is mostly verifiable due to its clear suggestions and references, but it lacks some depth in the reasoning behind the recommendations.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides valuable feedback by suggesting additional experiments to address the research question and demonstrate the method's generalizability. It specifically recommends testing with various models, such as Vision Transformers (ViT), and references two relevant papers for further reading. Additionally, it suggests including results under more complex input noise models, such as those involving multiplicative distortions, to provide a more comprehensive evaluation. These suggestions are clear and actionable, offering the authors a path to enhance the depth and robustness of their experimental validation. However, the comment could be more helpful if it provided specific guidance on how to implement these experiments or what results to expect. Overall, the feedback is mostly helpful, as it effectively directs the authors towards improving their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the D.2 appendix mentions two human annotators, but based on the author responses, the number should be four. This provides a clear and direct action for the authors to take, which is to correct the discrepancy in the number of annotators mentioned in the appendix. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the D.2 appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy in the number of human annotators mentioned in the appendix compared to what is stated in the author responses. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the D.2 appendix mentions two human annotators, but based on the author responses, the number should be four. This is a factual statement that does not require verification, as it is based on a direct comparison between the appendix and the author responses. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the number of human annotators mentioned in the D.2 appendix compared to what is stated in the author responses. This feedback is clear and actionable, as it provides a specific area for the authors to correct in their draft. By highlighting this inconsistency, the comment helps the authors ensure accuracy and consistency in their reporting. However, the comment could be more helpful if it suggested how the authors might address this discrepancy or provided additional context on why this is important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would have helped the authors better understand the value of the proposed approach. However, it does not provide specific guidance on how to improve the motivation or what aspects of the encoder and decoder structure need further explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed motivation for these components. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a better motivation for the encoder and decoder structure would have helped to better understand the value of the proposed approach. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its suggestion to provide better motivation for the encoder and decoder structure, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a better motivation for the encoder and decoder structure would have helped to better understand the value of the proposed approach. However, it does not provide any specific examples, references, or detailed reasoning to support why this is the case. The comment lacks concrete evidence or justification, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a better motivation for the encoder and decoder structure would have helped the authors better understand the value of the proposed approach. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to enhance the motivation or what aspects of the encoder and decoder structure need further explanation. The feedback is somewhat helpful as it points out a potential weakness, but it does not offer actionable advice or suggestions for improvement, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limited novelty of the explored loss functions and the absence of black-box evaluation. It also suggests that the paper should consider extending the analysis to targeted attacks. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should explore new loss functions, conduct black-box evaluations, and consider targeted attacks, but the comment lacks concrete steps or examples on how to implement these suggestions. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the explored loss functions, the absence of black-box evaluation, and the limited scope of the paper to untargeted attacks. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the limitations and suggesting improvements, such as exploring new loss functions and considering targeted attacks. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the novelty of the explored loss functions and the limitations of the paper, such as the absence of black-box evaluation and the focus on untargeted attacks. The reviewer provides some reasoning by noting that the loss functions are not new and that the attacks are conducted in a white-box setting. However, the comment lacks specific examples or references to support the claim about the loss functions being \"simple 'plug and play'.\" Additionally, the suggestion to consider targeted attacks is not fully supported by evidence or examples. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed justification and specific references to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several key areas for improvement in the paper. It points out the limited novelty of the explored loss functions, suggesting that the use of JS divergence, masked CE loss, and masked spherical loss is not groundbreaking. The reviewer also highlights the absence of black-box evaluation, which is a significant limitation, and recommends extending the analysis to targeted attacks to showcase the strength of the proposed attack method. These suggestions are clear and actionable, providing the authors with specific directions for enhancing the novelty and scope of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to implement these suggestions. Overall, the feedback is mostly helpful, as it effectively directs the authors towards improving their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also requests results for CIFAR100. While the comment implies that the authors should conduct a direct comparison and provide results for CIFAR100, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these comparisons and additions to their results. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the results for CIFAR10 and CIFAR100, indicating that the results for CIFAR10 are not impressive and suggesting that a direct comparison with other approaches is necessary. It also requests results for CIFAR100. However, the comment does not specify which part of the paper discusses these results, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not precise. The comment is specific in detailing what needs to be addressed, namely the need for a direct comparison and results for CIFAR100. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, the comment does not provide specific examples or references to support the claim that the results are not impressive or to justify the need for a direct comparison. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive compared to other approaches. It suggests that a direct comparison with other methods is necessary and requests results for CIFAR100. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on what additional results should be included. However, the comment could be more helpful if it offered suggestions on how to present the results or what aspects of the comparison are crucial. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a known characteristic of hyperbolic space being well-suited for hierarchical datasets but notes that the experiments do not clearly demonstrate this. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should conduct experiments to demonstrate the suitability of hyperbolic space for hierarchical datasets. However, the comment lacks concrete details on how to execute this action, making it vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the suitability of hyperbolic space for hierarchical datasets, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in pointing out that the experiments do not clearly demonstrate the suitability of hyperbolic space for hierarchical datasets, but it lacks grounding because it does not specify the exact section or experiment. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that hyperbolic space is well-suited for hierarchical datasets but notes that the experiments do not clearly demonstrate this. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experiments, noting that while it is known that hyperbolic space is well-suited for hierarchical datasets, the experiments do not clearly demonstrate this. This feedback is somewhat helpful as it points out a gap in the experimental validation, which could be addressed by conducting additional experiments or analyses to better illustrate the suitability of hyperbolic space for hierarchical datasets. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what aspects should be emphasized, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. While the comment identifies a gap in the paper's clarity, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the strengths of MixBoost in their draft. However, the comment lacks concrete details on how to improve the clarity, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the strengths of MixBoost, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point consists of a question seeking clarification about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as 'No', as it does not fit any of the categories for claims or verifiability.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment raises a question about the main strengths of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. While the comment identifies a gap in the paper's clarity, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their strengths. The feedback lacks actionable advice or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it highlights a potential area for improvement but does not offer actionable feedback.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the surprising nature of the statement \"Unlike previous works which use the test set for hyperparameter tuning\" and suggests that the wording is unclear. It also points out that the \"smaller training set\" could be avoided by training the network with optimal parameters on the complete train+val set. While the comment identifies specific issues and suggests potential improvements, it does not provide explicit instructions on how to address these concerns. The authors are left to infer that they should clarify the wording and consider using the complete train+val set for hyperparameter tuning. However, the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l. 243\" and \"l. 245,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the wording and suggests improvements, such as clarifying the statement about hyperparameter tuning and avoiding the \"smaller training set\" by using optimal parameters on the complete train+val set. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the surprising nature of a statement regarding hyperparameter tuning and suggests that the wording is unclear. It also points out that the \"smaller training set\" could be avoided by training the network with optimal parameters on the complete train+val set. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to use the complete train+val set for hyperparameter tuning is a logical improvement, but the comment could be strengthened by providing more context or evidence to support the claim. Therefore, the comment is somewhat verifiable, as it provides some reasoning but requires additional details to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a surprising statement in the paper regarding the use of the test set for hyperparameter tuning, suggesting that it is unexpected compared to previous works. It also points out a potential issue with the 'smaller training set' and offers a suggestion to avoid it by training the network with optimal parameters on the complete train+val set. This feedback is somewhat helpful as it highlights a potential area of confusion and provides a suggestion for improvement. However, the comment could be more helpful if it included specific examples or further explanation of why the suggestion is beneficial. Overall, the comment provides a good starting point for the authors to consider, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper needs improvement, particularly in the introduction, which is described as obscure and high-level. It lacks detailed elaboration on the actual implementation. The reviewer provides a specific suggestion for improvement by suggesting that the authors hint at how they tokenize the parameters and use DDPM to predict actual parameters. This feedback is explicit and provides a clear direction for the authors to enhance their draft by offering concrete steps to improve the clarity and detail of their writing. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper needs improvement, particularly in the introduction, which is described as obscure and high-level. It lacks detailed elaboration on the actual implementation. The reviewer provides a specific suggestion for improvement by suggesting that the authors hint at how they tokenize the parameters and use DDPM to predict actual parameters. This feedback is fully grounded as it explicitly mentions the introduction and provides a clear suggestion for improvement. However, it does not specify which part of the introduction is obscure or lacks detail, which could be addressed with more specific guidance. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the introduction is obscure and lacks detail, and it provides a specific suggestion for improvement by suggesting that the authors hint at how they tokenize the parameters and use DDPM to predict actual parameters. This feedback is somewhat verifiable as it provides a clear suggestion for improvement but lacks specific examples or references to support the claim that the introduction is obscure. The suggestion for improvement is concrete, but the initial claim of obscurity is not fully substantiated with evidence or reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the writing of the paper, noting that the introduction is obscure and lacks detailed elaboration on the actual implementation. It provides a clear and actionable suggestion for improvement by recommending that the authors hint at how they tokenize the parameters and use DDPM to predict actual parameters. This feedback is valuable as it offers a concrete way for the authors to enhance the clarity and detail of their writing, making it highly helpful. However, the comment could be more helpful if it provided additional context or examples of how this improvement could be achieved. Overall, the comment is mostly helpful, as it guides the authors towards a specific area for improvement and offers a clear direction for enhancing their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point simply states that the presentation is not good without providing any specific feedback or suggestions on what aspects of the presentation are problematic or how they could be improved. This lack of detail and specificity leaves the authors without a clear understanding of what needs to be addressed or how to improve their presentation. As a result, the comment is unactionable, as it does not provide any guidance or direction for the authors to follow.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment \"The presentation is not good. Just name a few.\" is not grounded at all, as it does not specify which part of the presentation is problematic or what specific issues need to be addressed. Without any reference to specific sections, figures, or tables, the authors cannot determine which aspects of the presentation are being criticized. Additionally, the comment lacks specificity, as it does not provide any details or examples of what is wrong with the presentation. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a subjective statement expressing dissatisfaction with the presentation but lacks any supporting evidence, reasoning, or specific examples. It does not provide any logical reasoning, common knowledge, or references to substantiate the claim that the presentation is not good. Without any justification or evidence, the comment does not help the authors understand or address the issue, making it unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses dissatisfaction with the presentation but lacks specificity and actionable feedback. It does not provide any details or examples of what aspects of the presentation are not good or how they could be improved. Without this level of detail, the authors are left without a clear understanding of what needs to be addressed or how to enhance their presentation. As a result, the comment is not helpful, as it does not offer any guidance or suggestions for improvement. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific oversight in the \"Related work\" section, mentioning that the authors fail to acknowledge the work by Rieck et al. [2] regarding the correlation of topological complexity with generalization ability. While the comment explicitly identifies a gap in the literature review, it does not provide any guidance on how the authors should address this oversight. The action is implicit, as the authors need to infer that they should include this work in their review, but it lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the oversight, which is the omission of the work by Rieck et al. [2] regarding the correlation of topological complexity with generalization ability. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors miss the work by Rieck et al. [2] in their \"Related work\" section, which discusses the correlation of topological complexity with generalization ability. However, the comment does not provide any specific details or examples of how this work is relevant or how it should be integrated into the paper. Without additional context or references, the claim is difficult for the authors to verify and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific oversight in the \"Related work\" section, pointing out that the authors fail to mention the work by Rieck et al. [2], which discusses the correlation of topological complexity with generalization ability. This feedback is clear and actionable, as it directs the authors to include this relevant work in their literature review. However, the comment could be more helpful if it provided additional context or guidance on how to integrate this work into the paper. Overall, the comment is mostly helpful as it highlights a gap in the literature review and provides a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the usefulness of the exploration parameter gamma, given that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. Additionally, it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment identifies several areas for improvement, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The actions are implicit and somewhat vague, as the authors need to infer the specific modifications to make. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Alg 1\" and \"Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the exploration parameter gamma, questioning its usefulness given the provided upper-bounds and suggesting a remark on high-probability upper-bounds and the role of gamma. Additionally, it raises a question about the extension of the analysis to high-probability bounds on the regret. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the usefulness of the exploration parameter gamma, given that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. Additionally, it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. While the comment identifies potential issues and suggests areas for improvement, it lacks specific examples or references to support the claim about the usefulness of gamma. The reasoning is logical and based on common knowledge in the field, but the lack of detailed evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the exploration parameter gamma, noting that only upper-bounds on the pseudo-regret are provided. It suggests that the choice gamma=0 might be optimal and proposes a remark on high-probability upper-bounds and the role of gamma. Additionally, it questions whether the analysis, which is heavily based on expectations, can be extended to high-probability bounds on the regret. This feedback is clear and actionable, providing the authors with specific areas to consider for improvement. It encourages them to explore the implications of their analysis and suggests potential enhancements to their work. However, the comment could be more helpful if it offered more detailed guidance or examples on how to address these issues. Overall, the comment is mostly helpful, as it directs the authors' attention to important aspects of their work that need further exploration and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to either add a restatement of the definition of LCA relaxation from Wang et al. in the body of the paper or include a description in the appendix. This provides a clear and direct action for the authors to take, making the comment highly actionable. The feedback is specific and concrete, guiding the authors on exactly what needs to be done to address the issue of undefined terms in their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of definition for the LCA relaxation, and suggests a solution by recommending the addition of a restatement from Wang et al. or a description in the appendix. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the LCA relaxation was referenced but never defined in the paper. This is a factual statement that does not require verification, as it is based on the observation of a missing definition. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, noting that the LCA relaxation was referenced but never defined. It provides a clear and actionable suggestion for the authors to either add a restatement of the definition from Wang et al. in the body of the paper or include a description in the appendix. This feedback is valuable as it guides the authors on how to improve the clarity and completeness of their draft, making it mostly helpful. However, it could be more helpful if it included specific examples or further guidance on how to present the definition effectively. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more information on how validation and test splits influence model training could strengthen reproducibility. While it implies that additional details are needed, it does not explicitly instruct the authors to provide this information or specify how to incorporate it into their draft. The action is implicit and somewhat vague, as the authors can infer the need for more details but lack concrete guidance on how to implement this suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to provide more details on the validation and test splits, but without explicit references to sections or figures, the authors may struggle to pinpoint where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The comment lacks detailed reasoning or evidence to substantiate the claim, leaving it unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, suggesting that more information on how validation and test splits influence model training could strengthen reproducibility. This feedback is actionable and provides a clear direction for the authors to enhance their draft by including additional details on this aspect. However, the comment could be more helpful if it offered specific suggestions or examples of how to incorporate this information. Overall, the comment is mostly helpful as it guides the authors towards a meaningful enhancement of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scope of the regularization techniques addressed in the paper, specifically questioning why the authors limit their focus to dropout and not other techniques like L2 regularization, data augmentation, or adding noise. It also inquires about the potential impact of using ZeroLiers in conjunction with these techniques. While the comment highlights areas for exploration and suggests that the authors should consider broader regularization techniques, it does not provide explicit guidance or concrete steps on how to address these points. The action is implicit and somewhat vague, as the authors need to infer that they should expand their analysis to include other regularization techniques and consider their interactions with ZeroLiers. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scope of the regularization techniques addressed in the paper, specifically questioning why the authors limit their focus to dropout and not other techniques like L2 regularization, data augmentation, or adding noise. It also inquires about the potential impact of using ZeroLiers in conjunction with these techniques. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table where these techniques are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the scope of regularization techniques and their interactions, but without explicit grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scope of regularization techniques addressed in the paper, specifically questioning why the authors limit their focus to dropout and not other techniques like L2 regularization, data augmentation, or adding noise. It also inquires about the potential impact of using ZeroLiers in conjunction with these techniques. While the comment highlights a logical gap in the paper\\'s scope, it does not provide specific examples or references to support the claim that these techniques are commonly used in practice. The reasoning is based on general knowledge of common practices in regularization, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent question about the scope of the regularization techniques addressed in the paper, specifically questioning why the authors limit their focus to dropout and not other techniques like L2 regularization, data augmentation, or adding noise. It also inquires about the potential impact of using ZeroLiers in conjunction with these techniques. This feedback is valuable as it prompts the authors to consider a broader range of regularization methods and their interactions, which could enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific suggestions or examples of how to incorporate these techniques or how they might affect the results. Overall, the comment is mostly helpful as it directs the authors to expand their analysis and consider additional aspects, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the assumption of overlap is reasonable in a tabular setting but questions its generalization to the function approximation setting. It implies that the authors should discuss this generalization in the context of consistency, as mentioned in the section. While the comment implies an action to discuss the generalization, it does not explicitly instruct the authors to do so. The action is somewhat implicit and vague, as the authors need to infer that they should address this issue in their draft. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the assumption of overlap, specifically questioning its generalization to the function approximation setting. It suggests that the authors discuss this generalization in the context of consistency, as mentioned in the section. However, the comment does not specify which section or part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the generalization, but without explicit grounding, the authors may find it challenging to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the generalization of an assumption (overlap) from a tabular setting to a function approximation setting. It suggests that the authors discuss this generalization in the context of consistency, as mentioned in the section. However, the comment does not provide specific reasoning or examples to support why this generalization might be problematic or how it could be addressed. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the generalization of an assumption (overlap) from a tabular setting to a function approximation setting. It suggests that the authors discuss this generalization in the context of consistency, as mentioned in the section. This feedback is somewhat helpful as it points out a potential area for improvement in the paper's generalizability. However, it lacks specific guidance or suggestions on how to address this issue, such as what aspects of the generalization should be discussed or how it could be supported. The comment could be more helpful with additional details or examples, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that Table 1 should be one column wide, and figures 3, 5, and 6 would benefit from a two-column width. Additionally, it recommends that the paper be made easier to understand by straightening up the content. These actions are clear and concrete, giving the authors specific steps to follow for improvement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the width of these elements, suggesting that they should be one column wide for Table 1 and two-column width for the figures. The comment further provides a specific suggestion for improvement by recommending that the paper be made easier to understand. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Table 1 should be one column wide and figures 3, 5, and 6 would benefit from a two-column width. It also notes that the paper was not easy to understand during the first read and recommends that the content be straightened up. While the comment provides specific suggestions for improvement, it lacks detailed reasoning or examples to fully substantiate the claim about the figures\\' width or the paper\\'s readability. The suggestion to make the paper easier to understand is a general observation without specific guidance on how to achieve this. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific and actionable feedback on the formatting of the paper, suggesting that Table 1 should be one column wide and figures 3, 5, and 6 would benefit from a two-column width. This guidance is clear and directly addresses the layout of the paper, which can significantly improve its readability. Additionally, the comment notes that the paper was not easy to understand during the first read and recommends that the content be straightened up. This feedback is valuable as it offers concrete steps for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it provided additional suggestions or examples on how to straighten up the content. Overall, the comment is mostly helpful, as it provides clear guidance on formatting improvements and highlights an area for content clarification.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the effectiveness of the DPO objective and suggests that the additional performance benefit may come from training with perturbed images rather than the DPO objective itself. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their method. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"repeat Text-DPO baseline\" and the specific action of \"with the generated images used for DPO as images for additional image-question-answer triplets.\" This provides clear guidance on which part of the paper is being addressed, allowing the authors to accurately identify the section. The comment is also specific because it details the suggested action of creating new triplet pairs with perturbed images and questions the effectiveness of the DPO objective. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of the DPO objective and suggests that the additional performance benefit may come from training with perturbed images rather than the DPO objective itself. The reviewer provides a logical reasoning by questioning the specific contribution of the DPO objective and suggesting an alternative explanation for the observed performance improvement. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further investigate and provide evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the effectiveness of the DPO objective and suggests that the additional performance benefit may come from training with perturbed images rather than the DPO objective itself. This feedback is valuable as it challenges the authors to reconsider their experimental setup and potentially revise their approach. However, the comment could be more helpful if it provided specific suggestions on how to address this concern or alternative methods to evaluate the impact of perturbed images. Overall, the comment is mostly helpful as it prompts the authors to consider a significant aspect of their work that may require further investigation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential assumption in the paper that there is no difference in expertise between Alice and Bob, which may not hold in real-world tasks. It suggests that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this assumption or incorporate non-linear interactions into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should consider these factors in their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific assumption in the paper, namely that there is no difference in expertise between Alice and Bob. It points out that this assumption may not hold in real-world tasks and suggests that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment does not specify which part of the paper this assumption is made in, making it weakly grounded. The suggestion is specific, as it highlights a potential issue with the assumption and provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that there is no difference in expertise between Alice and Bob, suggesting that this assumption may not hold in real-world tasks. The reviewer provides a logical reasoning by pointing out that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of this concern to their work, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's assumptions regarding the expertise of the human and AI agents, specifically that there is no difference in their abilities. It highlights that this assumption may not hold in real-world tasks, where there could be non-linear interactions between success-rate and speed-up due to varying levels of expertise. This feedback is somewhat helpful as it points out a potential area for improvement in the paper's assumptions and suggests that the authors should consider more realistic scenarios. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to incorporate non-linear interactions into the analysis. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential limitation in the paper\\'s assumptions regarding the expertise of the human and AI agents, suggesting that this assumption may not hold in real-world tasks. It highlights the possibility of non-linear interactions between success-rate and speed-up due to varying levels of expertise. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate non-linear interactions into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should consider these factors in their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific assumption in the paper, namely that there is no difference in expertise between Alice and Bob. It points out that this assumption may not hold in real-world tasks and suggests that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise between the human and AI agents. However, the comment does not specify which part of the paper this assumption is made in, making it weakly grounded. The suggestion is specific, as it highlights a potential issue with the assumption and provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that there is no difference in expertise between Alice and Bob, suggesting that this assumption may not hold in real-world tasks. The reviewer provides a logical reasoning by pointing out that there could be non-linear interactions between success-rate and speed-up due to different levels of expertise. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of this concern to their work, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's assumptions regarding the expertise of the human and AI agents, specifically that there is"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the generalizability of the mitigation strategies, specifically mentioning the possibility of data leakage. It suggests that the strategies might be dataset-specific and not applicable more generally. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve the generalizability of their framework. The action is implicit and vague, as the authors are left to infer that they need to explore alternative strategies or methods to enhance generalizability. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the mitigation strategies being dataset-specific and not generally applicable. It highlights the potential for data leakage and suggests that the framework may not be generalizable to other LLMs or datasets. However, the comment does not specify which part of the paper discusses the mitigation strategies or the data leakage issue, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing the concern about generalizability and the potential for data leakage, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the mitigation strategies are dataset-specific and may not be applicable more generally. This claim is somewhat verifiable as it provides a logical reasoning that the strategies might be specific to the dataset used, which could limit their generalizability. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the study's mitigation strategies, noting that they might be specific to the dataset used and not applicable more generally. This observation is relevant as it highlights a potential gap in the generalizability of the framework. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the generalizability of their approach. While it points out an important consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a list of questions that the reviewer finds unclear in the paper. While the questions provide a clear indication of what needs to be addressed, they do not specify how to resolve these issues or what changes should be made. The authors are left with a general understanding of what needs clarification but lack concrete guidance on how to improve the clarity of their draft. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on how to implement those changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions a list of questions that the paper is not sufficiently clear in, but it does not specify which parts of the paper are unclear or what specific issues need to be addressed. This lack of detail makes it difficult for the authors to identify the exact sections that require clarification. Without specific guidance, the authors cannot effectively address the feedback. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a list of questions regarding the clarity of the paper, suggesting that the weaknesses could be fixed. However, it does not provide any specific examples, reasoning, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a lack of clarity in the paper, suggesting that the weaknesses could be addressed before the final submission. However, it does not provide specific examples or detailed feedback on what aspects are unclear or how they could be improved. This lack of specificity and actionable guidance limits the usefulness of the comment for the authors, as it does not offer concrete steps or suggestions for enhancing the clarity of their draft. Therefore, the comment is rated as barely helpful, as it provides a general direction but does not fully support the authors in improving their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants are performing. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the task conditions and the task participants are performing. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking about the relationship between natural and synthetic audio signals and task conditions, as well as the task participants are performing. This provides clear guidance on what information is missing or needs clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions asking for clarification about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants performing. These questions are factual inquiries seeking additional information and context, which do not express opinions, judgments, or suggestions. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the relationship between natural and synthetic audio signals and task conditions referenced in Figure 2, as well as the task participants performing the task. By asking these questions, the reviewer prompts the authors to clarify and provide more detailed information about these aspects, which are crucial for understanding the context and methodology of the study. This feedback is valuable as it encourages the authors to enhance the clarity and comprehensiveness of their draft, making it mostly helpful. However, it could be more helpful if it included specific suggestions or examples of how to address these questions. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors did not address certain problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address these issues or what specific steps they should take to improve their work. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights specific areas where the paper could be improved, such as addressing problems like memory to register and personalize to user characteristics, reasoning over common sense, and facts in open domain dialogue. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in terms of the issues it raises, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not address specific problems in open domain dialogue, such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved, namely addressing problems in open domain dialogue such as memory to register and personalize to user characteristics, reasoning over common sense, and facts. However, it does not provide any suggestions or guidance on how the authors might address these issues or what specific steps they could take to improve their work. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not offer the level of detail needed for meaningful improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to clarify the distribution of papers. However, the comment does not explicitly instruct the authors to include this information or explain why it is important. The action is implicit and somewhat vague, as the authors can infer the need for this information but may not know how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to clarify the distribution of papers. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing the issue with the inclusion of Arxiv papers and the potential bias this might introduce, but it lacks explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to clarify the distribution of papers. The reviewer also expresses reservations about including Arxiv papers in the study, citing the perception that most Arxiv papers are not peer-reviewed and are of lower quality. However, the comment lacks specific examples or references to support the claim about the quality of Arxiv papers, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the statistical distribution of papers from different venues, specifically ACL, EMNLP, and Arxiv. It suggests that the authors should provide this information to clarify the distribution of papers. The reviewer also expresses reservations about including Arxiv papers in the study, citing the perception that most Arxiv papers are not peer-reviewed and are of lower quality. This feedback is somewhat helpful as it identifies a potential issue with the study's methodology and suggests a specific area for improvement. However, it lacks detailed guidance on how the authors might address this concern or provide a more robust analysis of the distribution of papers. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more comprehensive in its feedback.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on the proposed problem and framework, rather than spending a significant amount of space on applications. While the comment implies that the authors should shift their focus, it does not provide specific guidance on how to achieve this or what aspects of the framework should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact changes to make. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should focus more on the proposed problem and framework, rather than spending a significant amount of space on applications. However, it does not specify which part of the paper this advice pertains to, such as a particular section or section title. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment lacks specificity regarding what aspects of the framework or problem should be emphasized. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on the proposed problem and framework rather than the applications. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending a significant amount of space on applications. While this feedback highlights a potential imbalance in the paper's content, it lacks specificity and actionable guidance. It does not provide any suggestions on how to reallocate the focus or what aspects of the framework should be emphasized. As a result, the comment is vague and does not offer the authors a clear path to improve their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact. While it acknowledges the authors\\' efforts, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their work or what specific aspects need further attention. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the marginally above acceptance threshold of the work and acknowledges the authors\\' efforts in addressing limitations and potential negative societal impact. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on how the authors have addressed these issues. Without explicit references to sections or specific aspects of the paper, the authors cannot confidently determine which parts need further attention or improvement. Additionally, the comment lacks specificity regarding the criteria used to determine the marginally above threshold status or the details of the limitations and societal impact addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work is \"marginally above the acceptance threshold\" and that the authors have adequately addressed the limitations and potential negative societal impact. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of this assessment, making it difficult for them to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the work is 'marginally above the acceptance threshold' and that the authors have adequately addressed the limitations and potential negative societal impact of their work. While it provides some recognition of the authors' efforts, it lacks specific feedback or suggestions for improvement. The comment does not offer actionable advice or guidance on how the authors might enhance their work or address any remaining concerns. As a result, the comment is somewhat helpful, as it provides some insight into the paper's standing but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the simplicity of the dataset, suggesting that it could be solved by an agent translating natural language into specific triples. It also notes that the natural language is generated by patterns, making natural language understanding easy. The comment implies that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the research impact of their work. The action is implicit and vague, as the authors are left to infer that they need to consider the potential limitations of their dataset and explore ways to enhance the research impact. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the simplicity of the dataset and suggests that it could be solved by an agent translating natural language into specific triples. It also mentions that the natural language is generated by patterns, making natural language understanding easy. However, the comment does not specify which part of the paper this critique pertains to, such as the methodology or results sections. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in detailing the potential limitations of the dataset and the implications for future research, but without explicit references to the paper, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the simplicity of the dataset, suggesting that it could be solved by an agent translating natural language into specific triples. It also notes that the natural language is generated by patterns, making natural language understanding easy. The comment implies that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods such as PAL or LLMs with code interpreters as tools. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the critique. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim about the dataset\\'s simplicity or the potential impact on future research. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the simplicity of the dataset, suggesting that it could be solved by an agent translating natural language into specific triples. It also notes that the natural language is generated by patterns, making natural language understanding easy. The comment implies that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods such as PAL or LLMs with code interpreters as tools. While the comment identifies a potential limitation of the dataset, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the research impact of their work. The feedback is somewhat helpful as it highlights a potential weakness, but it lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests revising a statement about maximum likelihood estimation and questions the fairness of discussing the limitations of the proposed measure. It also points out that the proposed measure does not provide a stronger theoretical connection to generalization or outperform other measures experimentally. While the comment implies that the authors should revise the statement and address the limitations, it does not provide explicit guidance on how to revise the statement or what specific aspects need to be improved. The action is implicit and somewhat vague, as the authors can infer the need for revision but lack detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"masures 242,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement about maximum likelihood estimation and questions the fairness of discussing the limitations of the proposed measure. The comment further points out that the proposed measure does not provide a stronger theoretical connection to generalization or outperform other measures experimentally. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of discussing the limitations of the proposed measure, particularly in relation to its theoretical connection to generalization and experimental performance compared to other measures. The reviewer provides a detailed explanation of their concern, referencing the presentation and suggesting that the proposed measure does not offer a stronger theoretical connection or outperform other measures. This provides a logical and detailed justification for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper's discussion of the proposed measure, noting that it does not provide a stronger theoretical connection to generalization than competing measures and does not demonstrate experimental outperformance. The reviewer suggests revising a statement about maximum likelihood estimation and questions the fairness of discussing the limitations of the proposed measure. This feedback is clear and actionable, as it provides the authors with specific areas to address and improve in their draft. By highlighting these weaknesses, the comment offers valuable guidance for enhancing the paper's theoretical foundation and empirical validation. However, it could be more helpful if it provided additional suggestions or examples on how to strengthen the discussion. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to critical areas for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of results for fine-tuned open-source LLMs, which is considered important for a domain-specific benchmark. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting specific LLMs to include or how to incorporate their results into the paper. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights the lack of results for fine-tuned open-source LLMs, which is considered important for a domain-specific benchmark. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the missing results, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lack of results for fine-tuned open-source LLMs is \"important\" for a domain-specific benchmark. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate why this is the case. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper could be improved by highlighting the absence of results for fine-tuned open-source LLMs, which is considered important for a domain-specific benchmark. This feedback is clear and actionable, as it points out a potential weakness in the paper's evaluation methodology. However, the comment could be more helpful if it provided suggestions on how to incorporate these results or which specific LLMs should be considered. Overall, the comment is mostly helpful as it directs the authors' attention to an important aspect that needs further exploration, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the training of the regression model, including the input and output, the parameter space for the ridge regression model, and the impact of the number of parameters on model performance. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors are left to infer that they need to provide more detailed information about the model training process and its parameters. However, the lack of specific instructions on how to improve the draft makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the training of the regression model, specifically asking about the input, output, and parameter space for the ridge regression model. It also inquires about the impact of the number of parameters on model performance. However, it does not specify which part of the paper these questions relate to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its questions, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification about the training of a regression model, including the input, output, and parameter space for the ridge regression model. It also inquires about the impact of the number of parameters on model performance. However, the comment does not contain any claims or opinions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions about the training of the regression model, including the input and output, the parameter space for the ridge regression model, and the impact of the number of parameters on model performance. While these questions are relevant and could help the authors clarify their methodology, the comment lacks specific guidance or suggestions on how to address these issues. It provides a starting point for the authors to consider, but it does not offer actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is somewhat helpful, as it identifies areas for clarification but does not fully support the authors in enhancing their work.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly identifies a potential error in the equations, specifically suggesting that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, as it is an operator between a scalar and a tensor, not just between two scalars. This feedback is clear and direct, providing a specific action for the authors to take in correcting the equations. The comment is highly actionable as it gives the authors a clear and concrete path to follow in revising their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq 6 and related equations,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the equations, suggesting that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, as it is an operator between a scalar and a tensor, not just between two scalars. This provides clear guidance on what needs to be revised in the equations. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the operator after w_i should be the multiplication of the underlying vector space and not \\cross_g, as it is an operator between a scalar and a tensor, not just between two scalars. This claim is supported by logical reasoning, as it provides a clear explanation of why the operator should be interpreted differently. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is mostly verifiable, as it offers a reasonable basis for the claim but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable feedback by identifying a potential error in the equations, specifically regarding the operator after w_i. It suggests that the operator should be the multiplication of the underlying vector space and not \\cross_g, as it is an operator between a scalar and a tensor, not just between two scalars. This feedback is clear and actionable, as it guides the authors to correct a specific mathematical error in their draft. However, the comment could be more helpful if it included additional context or examples to further explain the significance of this correction. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add more ablation experiments to demonstrate the effectiveness of the proposed model. It provides specific examples of what should be included, such as ablation experiments on different updating methods and the role of reweighting after selection. This level of detail and specificity gives the authors a clear understanding of what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, providing clear guidance on how to improve the draft. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically mentioning the role of different updating methods and reweighting after selection. However, the comment does not provide any specific examples or references to support why these ablation experiments are necessary or how they would enhance the paper. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the significance of the suggestion, leaving the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the manuscript by recommending the addition of more ablation experiments. It specifies what types of ablation experiments should be conducted, such as those that would demonstrate the effectiveness of different updating methods and the role of reweighting after selection. This feedback is specific and provides a concrete direction for the authors to enhance their work, making it mostly helpful. However, it could be more helpful if it included examples of how these experiments could be structured or what specific outcomes should be expected. Overall, the comment is mostly helpful as it guides the authors in improving their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental results can be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. While the comment provides a clear direction for improvement, it does not specify which specific datasets or tasks should be considered or how the adaptive mechanisms should be integrated into the study. The authors are given a general idea of what to do but lack detailed guidance on execution, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experimental results can be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. However, the comment does not specify which part of the paper these suggestions relate to, such as the experimental section or specific results. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in its suggestions for improvement, it lacks grounding as it does not clearly indicate where in the paper these suggestions should be applied. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental results can be improved by expanding the datasets used in the experiments to include more complex datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from existing works as baseline approaches for comparison. The comment provides a logical reasoning for the suggestion, as it highlights the current limitations of the datasets used in the experiments and suggests a direction for improvement. However, it lacks specific examples or references to the adaptive mechanisms mentioned, which would strengthen the verifiability of the claim. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but could be more robust with additional supporting evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experimental results by suggesting that the datasets used in the experiments have a limited number of dimensions. It proposes expanding the experiments to include more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. Additionally, the comment recommends considering adaptive mechanisms from existing works, such as those by Phan et al. (2017, 2019, 2020), as baseline approaches for comparison. This feedback is clear and actionable, providing the authors with specific directions for enhancing the depth and relevance of their experimental results. However, the comment could be more helpful if it included specific suggestions on how to integrate these adaptive mechanisms or which datasets to consider. Overall, the comment is mostly helpful, as it offers valuable insights and guidance for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the experiment results, specifically questioning the effectiveness of PRESENCE and the relationship between temperature $\\\\tau$ and downstream performance. It suggests that the results in Figure 5 and Table 4 do not provide sufficient evidence to justify the two-stage pre-training. The reviewer expresses curiosity about the importance of reweighting using a positive or negative $\\\\tau$. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their results. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to these critiques. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific parts of the paper, such as the experiment results and Figure 5, which allows the authors to identify the relevant sections. It also mentions Table 4, providing full grounding. The comment is specific in questioning the effectiveness of PRESENCE, the relationship between temperature $\\\\tau$ and downstream performance, and the importance of reweighting using a positive or negative $\\\\tau$. It also highlights the lack of advantage shown in the cross-lingual zero-shot transfer results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the experiment results and the relationship between temperature $\\\\tau$ and downstream performance, specifically questioning the justification for two-stage pre-training. It suggests that using a positive or negative $\\\\tau$ can yield improvement over no reweighting, which raises questions about the importance of reweighting. However, the comment lacks specific examples, detailed reasoning, or references to support these claims, making it difficult for the authors to fully understand and address the critique. The feedback is somewhat verifiable, as it provides a general direction for improvement but lacks the depth and specificity needed for a fully verifiable comment. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific concerns about the experiment results, particularly regarding the effectiveness of PRESENCE and the relationship between temperature $\\\\tau$ and downstream performance. It questions the justification for two-stage pre-training and suggests that using a positive or negative $\\\\tau$ can yield improvement over no reweighting. Additionally, it points out that the results from Table 4 do not show the advantage of using PRESENCE. While the comment highlights areas for improvement, it lacks detailed suggestions or guidance on how the authors might address these issues or enhance their results. The feedback is somewhat helpful as it provides a direction for the authors to consider but does not offer comprehensive or actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the results presented in Table 2, where the results for k=1 are better than the baselines. It suggests that this might indicate a performance gain for a reason different from applying Eq.10. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this observation or what steps they should consider to investigate further. As a result, the authors are left without a clear understanding of what actions to take in response to this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the results for k=1, suggesting that the performance gain might be due to a reason other than applying Eq.10. This provides clear guidance on what the authors need to consider or investigate further. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results for k=1 in Table 2 are better than the baselines, suggesting that the performance gain might be due to a reason other than applying Eq.10. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a discrepancy in the results presented in Table 2, where the results for k=1 are better than the baselines. It suggests that this might indicate a performance gain for a reason other than applying Eq.10. However, the comment lacks specific guidance or suggestions on how the authors should investigate or address this observation. While it points out an interesting discrepancy, it does not provide actionable feedback or detailed insights that could help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for further exploration but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of solid grounding for the proposed method, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to justify their choice of mixed-integer programming and explain its advantages, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out a specific area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of solid grounding for the proposed method, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This makes it difficult for the authors to pinpoint the exact area needing improvement, resulting in weak grounding. The comment is specific in identifying the issue with the choice of mixed-integer programming and its lack of justification, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks solid grounding, specifically mentioning the choice of mixed-integer programming and its unclear advantages over alternative approaches. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that the choice of mixed-integer programming is not fully justified and its advantages over alternative approaches are unclear. This feedback is valuable as it points out a critical area for improvement, suggesting that the authors need to provide a more robust justification for their method. However, the comment lacks specific guidance on how to address this issue, such as suggesting alternative approaches or providing detailed explanations. While it highlights a significant weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate issues. The first issue is about notation in Equation 1, which is confusing due to the use of \"c\" instead of \"o.\" This is an explicit action that the authors can take to correct the notation. The second issue is about a missing reference, \"Pedersen et al 2007,\" which is mentioned in the comment but not explicitly stated as an action. However, the first part of the comment provides a clear and concrete action for the authors to take, while the second part is implicit and lacks specific guidance. Therefore, the comment is mostly actionable, as it provides a clear action for the first issue but lacks specificity for the second issue.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the confusing notation in Equation 1 and the missing reference \"Pedersen et al 2007\" in the reference section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate issues: notation confusion in Equation 1 and the missing reference \"Pedersen et al 2007\" in the reference section. The first issue is a factual observation about notation, which does not require verification. The second issue is a claim that a reference is missing, which is supported by the mention of \"Pedersen et al 2007\" in the comment. However, the comment does not provide specific details or context about why this reference is missing, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the draft: notation confusion in Equation 1 and the missing reference \"Pedersen et al 2007\" in the reference section. These are clear and actionable points that provide the authors with specific areas to address, making the feedback mostly helpful. However, the comment could be more helpful if it offered suggestions on how to resolve the notation confusion or provided context for the missing reference. Overall, the comment is mostly helpful as it directs the authors to important corrections that can improve the clarity and completeness of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the second contribution of the paper, which is the proposal to combine SSMs with Attention, is not new and has been proposed before in MEGA and Block-state Transformer. It also notes that the architecture in Figure 5 is similar to the proposed architecture in MEGA. The comment suggests that the authors should discuss the similarities and differences between S++ and this work, including an ablation study. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to conduct the discussion or ablation study. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second contribution of the paper, which is the proposal to combine SSMs with Attention, and references specific works (MEGA and Block-state Transformer) that have proposed similar ideas. It also provides a specific example of the architecture in Figure 5, which is similar to the proposed architecture in MEGA. The comment is specific in suggesting that the authors should discuss the similarities and differences between S++ and this work, including an ablation study. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposal to combine SSMs with Attention is not new and has been proposed before in MEGA and Block-state Transformer. The comment provides references to these works, which supports the claim. Additionally, it notes that the architecture in Figure 5 is similar to the proposed architecture in MEGA, further substantiating the claim. The suggestion to discuss the similarities and differences between S++ and this work, including an ablation study, provides a clear direction for the authors to improve their draft. However, the comment could be strengthened by providing more detailed comparisons or examples of the similarities and differences. Overall, the claim is mostly verifiable due to the references and the suggestion for further analysis, but it could be more robust with additional supporting evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper\\'s second contribution, which is the proposal to combine SSMs with Attention. It points out that this idea has been proposed before in MEGA and Block-state Transformer, suggesting that the authors should discuss the similarities and differences between their work and these previous contributions. The comment also recommends an ablation study to thoroughly analyze the proposed architecture. While the comment highlights a potential weakness in the novelty of the paper, it provides clear and actionable feedback on how the authors can address this issue. By suggesting a detailed discussion and an ablation study, the comment empowers the authors to significantly improve their draft. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the reason for reporting results on knowledge transfer only on a few select environments. While it implies that the authors should provide a rationale for this choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the reason for reporting results on knowledge transfer only on a few select environments, specifically referring to section 4.3. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the rationale behind the selection of environments for reporting results on knowledge transfer. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the reason for reporting results on knowledge transfer only on a few select environments, specifically referring to section 4.3. However, the comment does not provide any supporting evidence, reasoning, or context to justify why this is a concern or what impact it might have on the paper. Without additional information or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind reporting results on knowledge transfer only on a few select environments, specifically referring to section 4.3. While it identifies a potential issue with the selection of environments, it does not provide any further guidance or suggestions on how the authors might address this concern or improve their reporting. The comment lacks depth and actionable feedback, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is rated as barely helpful, as it provides a starting point for the authors but does not fully support their efforts to enhance the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue with the lack of ablation experiments in the manuscript, suggesting that the performance improvement could be attributed to pre-trained weights rather than the proposed method. It implies that the authors should conduct detailed ablation comparisons to clarify the contribution of their method. While the comment explicitly states the need for ablation experiments, it does not provide specific guidance on which aspects to focus on or how to structure these experiments. The action is clear but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of specific ablation experiments, which could lead to confusion about the performance improvement attributed to pre-trained weights rather than the proposed method. However, it does not specify which part of the manuscript lacks these experiments, making it weakly grounded. The comment is specific in identifying the issue of ablation experiments and their potential impact on the evaluation, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance improvement could be attributed to pre-trained weights rather than the proposed method, suggesting that the absence of detailed ablation comparisons may lead to confusion. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the manuscript, specifically the lack of specific ablation experiments. It points out that the performance improvement could be attributed to pre-trained weights rather than the proposed method, suggesting that detailed ablation comparisons are necessary to clarify the contribution of the proposed method. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to strengthen their work. However, the comment could be more helpful if it offered suggestions on how to conduct these ablation experiments or which aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a major concern regarding the lemmatizer\\'s limitation, specifically that it strips suffixes from words that are already lemmas but end with a suffix substring. While the comment identifies a potential issue, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this limitation or suggestions for improvement. The authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the lemmatizer, which is stripping suffixes from words that are already lemmas but end with a suffix substring. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the lemmatizer\\'s limitation is a major concern for real-world texts with evolving vocabularies. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or examples, the authors may find it challenging to understand the significance of this limitation or how it affects their work. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a significant concern, especially for real-world texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or specific recommendations, the comment lacks depth and fails to offer meaningful assistance to the authors. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the use of pre-trained DGCNN for semantic segmentation in Table 2, suggesting that the comparison of segmentation metrics is not meaningful because the segmentation of the methods + DGCNN is worse than the proposed method. While the comment identifies a potential issue with the comparison, it does not provide explicit guidance on how the authors should address this concern. The feedback lacks concrete suggestions or actions for improvement, such as recommending alternative methods or metrics for comparison. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison of segmentation metrics, noting that the comparison is not meaningful due to the use of pre-trained DGCNN. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the comparison of segmentation metrics in Table 2 is not meaningful because the use of pre-trained DGCNN results in a worse segmentation performance for the methods compared to the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the comparison of segmentation metrics in Table 2, noting that the use of pre-trained DGCNN for semantic segmentation may not provide meaningful results. It suggests that the comparison is not meaningful because the segmentation performance of the methods + DGCNN is worse than the proposed method. While the comment highlights a specific area for improvement, it lacks detailed guidance on how the authors might address this issue or what alternative approaches could be considered. The feedback is somewhat helpful as it points out a potential weakness in the comparison, but it could be more actionable with additional suggestions or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it is challenging to obtain rules in real-world applications and that statistical rules learned from data might be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they could take to improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that it is difficult to obtain rules in real-world applications and that statistical rules learned from data might be feasible. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the rules are challenging or how statistical rules might be feasible. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it is difficult to obtain rules in real-world applications and that statistical rules learned from data might be feasible. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that it is challenging to obtain rules in real-world applications and that statistical rules learned from data might be feasible. While it identifies a potential issue, it lacks specificity and actionable guidance. The authors are left without clear direction on how to address this challenge or what aspects of their work might be improved. The feedback is vague and does not provide detailed suggestions for improvement, making it barely helpful. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to include a comparison with dynamic sparse training-based and other sparsity-based methods. However, it does not provide explicit instructions on how to conduct this comparison or which specific methods should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add this comparison but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a comparison with dynamic sparse training-based and other sparsity-based methods. However, it does not specify which part of the paper this comparison should be included in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to include a comparison, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper lacks a comparison with dynamic sparse training-based and other sparsity-based methods. However, it does not provide any specific examples, references, or reasoning to support why these comparisons are necessary or how they would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper lacks a comparison with dynamic sparse training-based and other sparsity-based methods. While this is a valid observation, the comment does not provide specific guidance on which methods should be included in the comparison or how they would enhance the paper. The feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reasoning presented in the paper regarding the intractability of $p_\\\\theta(y|x)$. It questions the assumption that the intractability of $p_\\\\theta(z|x)$ necessarily leads to the intractability of $p_\\\\theta(y|x)$. The reviewer provides a counterexample to illustrate that both the posterior and likelihood can be tractable while $p_\\\\theta(y|x)$ remains intractable. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their understanding of the topic. As a result, the authors are left without a clear direction for improvement, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly references a specific part of the paper, \"From the paper,\" which allows the authors to accurately identify the section being addressed. It is also specific because it clearly details the issue with the reasoning presented regarding the intractability of $p_\\\\theta(y|x)$. The reviewer points out a potential misunderstanding in the paper\\'s explanation and provides a counterexample to illustrate the point. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reasoning presented in the paper regarding the intractability of $p_\\\\theta(y|x)$. It questions the assumption that the intractability of $p_\\\\theta(z|x)$ necessarily leads to the intractability of $p_\\\\theta(y|x)$. The reviewer provides a counterexample to illustrate that both the posterior and likelihood can be tractable while $p_\\\\theta(y|x)$ may still be intractable. This critique is based on logical reasoning and a specific example, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a critical point about the reasoning presented in the paper regarding the intractability of $p_\\\\theta(y|x)$. It questions the assumption that the intractability of $p_\\\\theta(z|x)$ necessarily leads to the intractability of $p_\\\\theta(y|x)$, providing a counterexample to illustrate that both the posterior and likelihood can be tractable while $p_\\\\theta(y|x)$ remains intractable. This feedback is valuable as it challenges the authors' understanding and encourages them to reevaluate their assumptions. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve their analysis. Overall, the comment is mostly helpful as it prompts the authors to consider a more nuanced perspective on the topic, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the irreproducibility of the study due to the inaccessible datasets. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might make the datasets accessible or what steps they could take to ensure reproducibility. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the irreproducibility of the study due to inaccessible datasets. However, it does not specify which part of the paper discusses the datasets or how they are made inaccessible. The authors may have an idea of where the datasets are mentioned, but the comment lacks specificity in identifying the exact sections or elements that need attention. This makes the comment weakly grounded and not specific, as it does not provide clear guidance on what needs to be addressed. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the study is irreproducible due to inaccessible datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a critical issue with the study, namely the irreproducibility due to inaccessible datasets. This is an important point that the authors should address to ensure the validity and impact of their work. However, the comment lacks specific guidance or suggestions on how the authors might make the datasets accessible or how to improve reproducibility. While it identifies a significant problem, it does not provide actionable steps or detailed feedback, making it somewhat helpful. The authors are aware of the issue but may need additional support to effectively address it. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks if there is a missing equation before \"where p is the firing rate\" in section 3.4.1. This is a clear and direct request for the authors to identify and correct any missing equations in that section. The action is explicit, and the authors know exactly what needs to be done to address the comment. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the potential presence of a missing equation before \"where p is the firing rate.\" This provides clear guidance on what needs to be addressed in the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the presence of an equation before \"where p is the firing rate\" in section 3.4.1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual statement seeking clarification, which is why it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, specifically asking the authors to identify and correct any missing equations in section 3.4.1. This provides a direct and specific direction for the authors to improve their draft by ensuring completeness and accuracy in their presentation. However, the comment could be more helpful if it provided additional context or guidance on what specific equations might be missing or how to address the issue. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing attention, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the evaluation of sentiment word detection and correction is lacking, and it suggests that the key ideas of SWRM are the detection and correction of possible sentiment word errors. The reviewer implies that it is necessary to conduct experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. While the action is clear, the comment does not provide specific guidance on how to design or execute these experiments. The authors know they need to address the evaluation gap but may need additional information to fully implement the suggested changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sentiment word detection and correction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of these aspects, which is crucial for validating the key ideas of SWRM. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of sentiment word detection and correction is lacking, given that the key ideas of SWRM involve these aspects. The reviewer suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the necessity of these experiments. This makes the claim somewhat verifiable, as the authors can infer the need for additional experiments but may require more detailed guidance to fully understand the rationale.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the evaluation of the paper's key ideas, specifically the detection and correction of sentiment words. It highlights that the paper's core contributions are related to these aspects and suggests that conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates is necessary. This feedback is clear and actionable, providing the authors with a specific area to focus on for improvement. However, the comment could be more helpful if it offered suggestions on how to design or execute these experiments. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for enhancement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for the results of KMLM-XLM-R_{large}(ours) in all the result tables, indicating that the authors did not report all the performance of KMLM-large without logical reasoning. This is a clear and direct request for the authors to provide the missing results, making the comment highly actionable. The authors know exactly what action to take to address the feedback, which is to include the requested results in their draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"all the result tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the absence of results for KMLM-XLM-R_{large}(ours) in the result tables. This provides clear guidance on what the authors need to include to address the feedback. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the completeness of the results reported in the result tables, specifically asking for the results of KMLM-XLM-R_{large}(ours). However, it does not provide any reasoning, evidence, or examples to support why these results are missing or why they are important. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the request. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the completeness of the results reported in the result tables, specifically questioning the absence of results for KMLM-XLM-R_{large}(ours). This feedback is clear and actionable, as it directs the authors to include the missing results, which could enhance the comprehensiveness and transparency of their findings. However, the comment could be more helpful if it provided additional context or suggestions on how to present these results effectively. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a concern about the reliability of the results, specifically noting that many in-context learning baselines underperform the backbone. It suggests that the variance in results or the design of the baselines might be the cause. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific explanations are needed to support the reliability of their claims. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed explanations or analyses. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses a specific issue with the results, noting that many in-context learning baselines underperform the backbone. It suggests that this might be due to large variance in results or uncareful design of the baselines. However, the comment does not specify which sections or figures these results are from, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this is not explicitly mentioned. The comment is specific in detailing the issue with the results and suggesting the need for more explanations, but without full grounding, it aligns with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the results of many in-context learning baselines, such as static few-shot and chain-of-thought, underperform the backbone, suggesting that this might be due to large variance in results or uncareful design of the baselines. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the results, noting that many in-context learning baselines underperform the backbone. It suggests that this might be due to large variance in results or uncareful design of the baselines. The comment implies that more explanations are needed to support the reliability of the claims. However, it does not provide specific suggestions or guidance on how the authors might address this issue or what additional explanations are necessary. While it highlights an important area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies an ambiguity in the paper regarding the key innovation of GFNSeqEditor. It suggests that the paper should clarify what novel techniques or insights are responsible for the claimed improvements. While the comment explicitly states the need for clarification, it does not provide specific guidance on how to articulate these novel aspects or where in the paper this clarification should be made. The action is implicit but concrete, as the authors know what needs to be addressed but may need to infer the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GFNSeqEditor,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim of key innovation, namely the lack of clarity regarding the novel techniques or insights that drive the claimed improvements. The comment provides a clear direction for the authors to enhance their understanding of the method\\'s unique value. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding the key innovation of GFNSeqEditor, specifically regarding how it produces novel sequences with improved properties. The comment suggests that the paper should better articulate the novel techniques or insights that drive these contributions. While the comment identifies a gap in the paper\\'s clarity, it does not provide specific examples or references to support the claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's clarity regarding the key innovation of GFNSeqEditor. It points out that the claim of producing novel sequences with improved properties lacks clarity, suggesting that the paper should better articulate the novel techniques or insights responsible for these improvements. This feedback is highly helpful as it provides a clear direction for the authors to enhance the clarity and impact of their work. By addressing this issue, the authors can improve the reader's understanding of the method's unique value and potential contributions. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting a simple experiment. While the action is explicit, it lacks concrete details on how to design or execute the experiment to effectively demonstrate the claim. The authors are given a clear direction but are left to infer the specifics of the experiment, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the \"faithfulness\" of the proposed approach, suggesting that the authors\\' claim about their method being less at risk to biases than other methods needs to be demonstrated with a simple experiment. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its suggestion to demonstrate the claim with an experiment, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors\\' claim about their method being less at risk to biases than other methods needs to be demonstrated with a simple experiment. However, the comment does not provide any specific reasoning, examples, or references to support why this claim is necessary or how an experiment could effectively demonstrate it. Without additional context or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement regarding the \"faithfulness\" of the proposed approach. It suggests that the authors\\' claim about their method being less at risk to biases than other methods needs to be demonstrated with a simple experiment. This feedback is clear and actionable, providing a concrete step for the authors to take to strengthen their argument. However, the comment could be more helpful if it offered additional guidance on how to design or interpret the experiment. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method, stating that it is not suitable for real-world applications due to its reliance on discrete state-action spaces. It suggests that the motivation for the proposed method is not well-suited to real-world applications, which are typically continuous. However, the comment does not provide specific guidance on how the authors might address this issue or improve the motivation. The action is implicit and vague, as the authors are left to infer that they need to find a way to make the method more applicable to real-world scenarios, but without concrete suggestions on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques a specific sentence in the manuscript, \"Most real-world applications are continuous in nature and are quite difficult to discretize or solve with discrete state-action spaces.\" It highlights that the proposed method, which operates with state-action spaces, may not be well-suited for real-world applications. However, the comment does not specify which part of the manuscript this sentence is found in, making it weakly grounded. The comment is specific in identifying the issue with the proposed method's applicability to real-world scenarios, but without clear grounding, it is challenging for the authors to pinpoint the exact sentence or section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method for its applicability to real-world scenarios, stating that most real-world applications are continuous and difficult to discretize or solve with discrete state-action spaces. The comment suggests that the method's motivation is not well-suited to real-world applications. However, the comment lacks specific examples or references to support the claim that the method is not applicable to real-world scenarios. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the proposed method, noting that it is not well-suited for real-world applications due to its reliance on discrete state-action spaces, which are not applicable to continuous real-world scenarios. The comment suggests that the motivation for the proposed method is not aligned with its potential applications. However, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the motivation. While it identifies a significant limitation, the feedback lacks actionable advice, making it somewhat helpful. The authors are aware of the problem but are left without clear steps to address it, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the proposed method, noting that it is not well-suited for real-world applications due to its reliance on discrete state-action spaces, which are not applicable to continuous real-world scenarios. The comment suggests that the motivation for the proposed method is not aligned with its potential applications. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the motivation. The action is implicit and vague, as the authors are left to infer that they need to find a way to make the method more applicable to real-world scenarios, but without concrete suggestions on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the proposed method, noting that it is not well-suited for real-world applications due to its reliance on discrete state-action spaces, which are not applicable to continuous real-world scenarios. It suggests that the motivation for the proposed method is not aligned with its potential applications. However, the comment does not specify which part of the manuscript this critique is based on, making it weakly grounded. The authors can infer that it relates to the motivation or applicability section, but without explicit references, it remains challenging to pinpoint the exact location. The comment is specific in identifying the issue with the method's applicability, but the lack of grounding makes it difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method for its applicability to real-world scenarios, noting that most real-world applications are continuous and difficult to discretize or solve with discrete state-action spaces. The comment suggests that the method's motivation is not well-suited to real-world applications. However, the critique lacks specific examples or references to support the claim that the method is not applicable to real-world scenarios. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies several issues with the paper's experimental results and presentation. It points out that the results are not very competitive with state-of-the-art (SOTA) methods and suggests that the presentation of the main results in Table 1 is unclear due to differences in backbones compared to prior methods. The comment also recommends moving the baseline to the ablation study and only showing the proposed method. While the comment provides explicit actions for the authors to take, such as moving the baseline and clarifying the presentation, it does not offer detailed guidance on how to implement these changes. The authors know what needs to be done but may require additional information to fully execute the suggestions. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment addresses the experimental results and the presentation of the main results in Table 1. It points out that the results are not very competitive with state-of-the-art methods and suggests that the presentation is unclear due to differences in backbones compared to prior methods. The comment also recommends moving the baseline to the ablation study and only showing the proposed method. While the comment does not explicitly mention specific sections, it is clear that it pertains to the experimental results and the presentation of Table 1. The authors can infer that it relates to these parts of the paper, but the comment lacks explicit references to specific sections or figures. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the experimental results are not very competitive with state-of-the-art (SOTA) methods and suggests that the presentation of the main results in Table 1 is unclear due to differences in backbones compared to prior methods. The comment also recommends moving the baseline to the ablation study and only showing the proposed method. However, the comment lacks specific examples or references to support the claim about the competitiveness of the results or the clarity of the presentation. Without detailed evidence or comparisons, the authors may find it challenging to understand and address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two main issues with the paper: the experimental results being not very competitive with state-of-the-art (SOTA) methods and the presentation of the main results in Table 1 being unclear due to differences in backbones compared to prior methods. It also suggests moving the baseline to the ablation study and only showing the proposed method. While the comment highlights specific areas for improvement, it lacks detailed guidance on how to address these issues or suggestions for alternative approaches. The authors are given a clear direction to improve their results and presentation, but the feedback could be more comprehensive and actionable to fully benefit the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking the authors to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback provides a clear and explicit action for the authors to take, which is to clarify the copyright scenario in their draft. The comment also offers a specific area for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking the authors to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is fully grounded as it explicitly mentions the copyright scenario, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed regarding the copyright scenario. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking the authors to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking the authors to specify whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the end-users who utilize the model. This feedback is clear and actionable, providing a specific area for the authors to address in their draft. By clarifying the copyright scenario, the authors can enhance the transparency and understanding of their work, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it offered suggestions on how to achieve this clarification or examples of how other works have addressed similar issues. Overall, the comment is mostly helpful, as it directs the authors to an important area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical justification or intuitive explanation for the behavior of low-rank and high-rank adapters. It suggests that the authors should provide a theoretical basis or an intuitive explanation for these phenomena, which is an explicit action. However, the comment does not specify how to achieve this or what kind of theoretical framework or explanation is needed. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the theoretical justification and intuitive explanation of the behavior of low-rank and high-rank adapters. It highlights the lack of theoretical basis or explanation for why these adapters acquire domain-agnostic information or domain-specific knowledge, respectively. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the theoretical or methodological sections, but this inference is not explicit. The comment is specific in detailing the issue with the lack of theoretical justification, but without full grounding, it is challenging for the authors to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no theoretical justification or intuitive explanation for why low-rank and high-rank adapters acquire domain-agnostic and domain-specific information, respectively. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the theoretical justification and intuitive explanation of the behavior of low-rank and high-rank adapters. It points out that there is no theoretical basis or explanation for why these adapters acquire domain-agnostic information or domain-specific knowledge, respectively, beyond experimental observation. This feedback is clear and actionable, as it highlights a critical area where the authors need to provide a more robust theoretical framework or explanation. However, the comment could be more helpful if it suggested specific theoretical approaches or references that could be explored to address this issue. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the validity of the statement regarding local models and their relationship to decision boundaries. It asks why this is true and why we can\\'t measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they should consider. As a result, the authors are left without a clear understanding of what changes or clarifications are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the validity of the statement regarding local models and their relationship to decision boundaries, and it asks for clarification on why this is true and why we can\\'t measure differences in probabilities. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the validity of a statement regarding local models and their relationship to decision boundaries. It asks why this is true and why we can\\'t measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the validity of a statement regarding local models and their relationship to decision boundaries. It asks why the statement is true and why we can't measure differences in probabilities, such as 'if feature 1 were higher, the model would be less confident in class y.' This question prompts the authors to clarify or justify their claims, which is valuable for improving the clarity and accuracy of the paper. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the explanation. While it identifies a potential area for clarification, it lacks depth and actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments only report results on ImageNet and suggests including results on classic datasets like CIFAR-10 and CIFAR-100. While the comment explicitly states what needs to be done, it does not provide specific guidance on how to incorporate these datasets or what aspects of the results should be emphasized. The action is clear, but the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ImageNet\" and \"CIFAR-10 and CIFAR-100,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of results on classic datasets like CIFAR-10 and CIFAR-100. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments only report results on ImageNet and suggests including results on classic datasets like CIFAR-10 and CIFAR-100. However, the comment does not provide any reasoning or evidence to support why including these datasets is necessary or beneficial. It lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental evaluation, noting that the experiments only report results on ImageNet and do not include results on classic datasets like CIFAR-10 and CIFAR-100. This feedback is clear and actionable, as it highlights an area where the authors can expand their analysis to provide a more comprehensive evaluation of their work. By suggesting the inclusion of additional datasets, the comment offers a concrete way for the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific guidance on how to incorporate these datasets or what aspects of the results should be emphasized. Overall, the comment is mostly helpful, as it directs the authors to a significant improvement area but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a confusion in Figure 1 regarding the softmax layer, which is not clearly shown in the figure but is mentioned in the text description as being part of the encoder. The reviewer compares this to the original DinoSR paper, where the figure is clear. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting the inclusion of the softmax layer in the figure or clarifying the text description. The action is implicit and vague, as the authors are left to infer that they need to make the figure more clear, but without specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the softmax layer is not clearly shown in the figure, despite being mentioned in the text description as part of the encoder. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the DinoSR part in Figure 1 is confusing because the softmax layer is not clearly shown, despite being mentioned in the text description as part of the encoder. The reviewer compares this to the original DinoSR paper, where the figure is clear. However, the comment lacks specific examples or detailed reasoning to support the claim that the softmax layer is not clearly shown in the figure. While the reviewer provides a reference to the original DinoSR paper, the lack of detailed justification or specific examples makes the claim somewhat verifiable. The authors would need to infer the exact issue from the comparison to the original paper, which adds to the ambiguity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1 in the paper, noting that the softmax layer is not clearly shown despite being mentioned in the text description as part of the encoder. The reviewer compares this to the original DinoSR paper, where the figure is clear, providing a reference for improvement. This feedback is clear and actionable, as it directs the authors to clarify the figure to match the textual description. However, the comment could be more helpful if it suggested specific ways to improve the figure, such as adding labels or arrows to indicate the softmax layer. Overall, the comment is mostly helpful as it highlights a specific area for improvement and provides a reference for better presentation, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include more related work on causal inference, referencing specific examples such as [1], [2], and [3]. While the comment implies that the authors should review and discuss these works, it does not provide explicit instructions on how to incorporate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and discuss them in their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should review related work on causal inference and mentions specific references ([1], [2], [3]). However, it does not specify which part of the paper this feedback pertains to, such as the introduction or discussion section, making it weakly grounded. The comment is specific in suggesting that more related work should be discussed, but without explicit references to the paper, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should review related work on causal inference and mentions specific references ([1], [2], [3]). However, it does not provide any reasoning or evidence to support why these references are relevant or how they would enhance the paper. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should review related work on causal inference and mentions specific references ([1], [2], [3]). While this feedback highlights an area for improvement, it lacks specificity and does not provide detailed guidance on how the authors should incorporate this related work into their paper. The comment does not offer suggestions on which aspects of the related work are particularly relevant or how they could enhance the paper. As a result, the comment is somewhat helpful, as it identifies a potential area for improvement but does not provide actionable advice for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly states that sections 3.1 and 3.2 could have been avoided if the authors used the LLM2Vec encoder, which is already cited in the paper. It also points out that the reasoning for not adopting this approach is unclear and suggests that the decision should be validated with ablation studies. This provides a clear and concrete action for the authors to take, which is to conduct ablation studies to justify their decision. The feedback is explicit and provides detailed guidance on how to address the issue, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'sections 3.1 and 3.2,' allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the potential for avoiding these sections if the authors had used the LLM2Vec encoder, which is already cited in the paper. The comment further specifies that the reasoning for not adopting this approach is unclear and suggests that the decision should be validated with ablation studies. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that sections 3.1 and 3.2 could have been avoided if the authors had used the LLM2Vec encoder, which is already cited in the paper. However, the comment does not provide specific reasoning or examples to support why these sections are unnecessary or how the LLM2Vec encoder would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential redundancy in the paper by suggesting that sections 3.1 and 3.2 could have been avoided if the authors had used the LLM2Vec encoder, which is already cited in the paper. It points out that the reasoning for not adopting this approach is unclear and recommends validating the decision with ablation studies. This feedback is clear and actionable, as it provides a specific suggestion for improvement and highlights an area where the authors can enhance their paper's clarity and justification. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the ablation studies. Overall, the comment is mostly helpful as it directs the authors to a potential improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lacks real-world problems. While the comment identifies a potential limitation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they need to include real-world problems in their experiments, but the comment lacks concrete details or examples on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, specifically noting that only synthetic objective functions are used and no real-world problems are included. This provides some grounding as it mentions a specific aspect of the paper, but it does not specify which sections or experiments are being discussed. The comment is specific in pointing out the absence of real-world problems, but the lack of explicit mention of sections or experiments makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack real-world problems. This claim is somewhat verifiable as it identifies a potential limitation in the experimental setup. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The authors would need to infer that real-world problems are important for validation, but without detailed guidance, the claim remains somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the experimental setup, specifically noting that only synthetic objective functions are used for comparison with existing baselines, without including real-world problems. This feedback is somewhat helpful as it points out a gap in the evaluation that could impact the validity and generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, such as recommending the inclusion of real-world problems or suggesting alternative methods for comparison. While it highlights an important area for improvement, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a detailed analysis of benchmark sentence differences between explanation and listener-focused parts to clarify the findings that distinguishing roles using explanation-focused cues is challenging. While the comment implies that such an analysis could be beneficial, it does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer the need for this analysis and how to carry it out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the challenge of distinguishing roles using explanation-focused cues, suggesting that LLMs may rely more on language style than informational depth. It implies that a detailed analysis of benchmark sentence differences between explanation and listener-focused parts could clarify these findings. However, the comment does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely, the analysis of sentence differences. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that distinguishing roles using explanation-focused cues is challenging, suggesting that LLMs may rely more on language style than informational depth. While the comment provides a logical reasoning for this claim, it lacks specific examples or references to support the assertion that LLMs indeed rely more on language style. This makes the claim somewhat verifiable, as the authors would need to further explore the literature or conduct additional analysis to fully understand and address the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential challenge in distinguishing roles using explanation-focused cues, suggesting that LLMs may rely more on language style than informational depth. It provides a specific suggestion for addressing this issue by conducting a detailed analysis of benchmark sentence differences between explanation and listener-focused parts. This feedback is clear and actionable, offering the authors a concrete direction for improving their work. However, it could be more helpful if it included specific examples or references to support the analysis. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the heavy use of acronyms in the paper, which affects readability, and specifically mentions the acronym \"DU\" without a clear definition. While the comment identifies a potential issue with the use of acronyms, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they should clarify the meaning of \"DU\" or reduce the use of acronyms, but the comment lacks concrete steps or suggestions on how to implement these changes. Therefore, the comment is somewhat actionable, as it highlights a specific issue but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the issue of heavy use of acronyms in the paper, specifically mentioning the acronym \"DU\" without a clear definition. This provides some grounding as it allows the authors to identify the part of the paper being addressed, but it does not specify which sections or paragraphs are affected by this issue. The comment is specific in pointing out the need for clarification of the \"DU\" acronym, but it lacks full grounding because it does not explicitly mention the sections where this issue occurs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper makes heavy use of acronyms, which affects readability, and specifically mentions the acronym \"DU\" without a clear definition. This is a factual observation rather than a claim, as it does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting the heavy use of acronyms, which can affect readability. It highlights a particular acronym, \"DU,\" that is mentioned without a clear definition, which is a clear area for improvement. However, the comment lacks actionable guidance on how to address this issue, such as suggesting ways to clarify the meaning of \"DU\" or reduce the use of acronyms. While it points out a potential problem, it does not provide detailed feedback or suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the estimation of variance in the distribution p(q|s) and whether it is estimated using the sample variance of quality values in the training data. It also inquires about the assumption of a sentence-independent variance and whether a complete covariance matrix is approximated or a diagonal covariance matrix is assumed. While the comment identifies specific areas of concern, it does not provide explicit guidance on how the authors should address these issues. The questions are clear and direct, but the lack of specific suggestions or concrete steps makes the action implicit and somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the estimation of variance in the distribution p(q|s) and asks about the method used to determine it, as well as whether a complete covariance matrix is approximated or a diagonal covariance matrix is assumed. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the estimation of variance in the distribution p(q|s) and the assumptions made about its independence across sentences. It asks whether the variance is estimated using the sample variance of quality values in the training data and whether a complete covariance matrix is approximated or a diagonal covariance matrix is assumed. While the comment does not provide explicit evidence or references to support these questions, it is logical and reasonable to expect that the authors would clarify these aspects. The questions are clear and based on common statistical practices, making the claim somewhat verifiable. However, the lack of specific references or examples makes it difficult to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises specific questions about the estimation of variance in the distribution p(q|s) and the assumptions made about its independence across sentences. It asks whether the variance is estimated using the sample variance of quality values in the training data and whether a complete covariance matrix is approximated or a diagonal covariance matrix is assumed. This feedback is clear and actionable, as it prompts the authors to clarify their methodology and assumptions, which are crucial for understanding the model's performance and limitations. By addressing these questions, the authors can improve the clarity and robustness of their paper. However, the comment could be more helpful if it provided suggestions on how to estimate the variance or discussed the implications of the assumptions made. Overall, the comment is mostly helpful as it identifies areas for clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the initial accuracy of the MIL-based baseline model in Fig. 7, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should investigate or how they might address this issue. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the initial accuracy of the MIL-based baseline model in Fig. 7, particularly for the NSCLC dataset. This provides clear guidance on what aspect of the figure needs further explanation or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the initial accuracy of the MIL-based baseline model in Fig. 7, particularly for the NSCLC dataset. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the initial accuracy of the MIL-based baseline model in Fig. 7, particularly for the NSCLC dataset. While it identifies a potential issue, it does not provide any context, analysis, or suggestions for how the authors might address this concern or improve their results. Without additional guidance or actionable feedback, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. While the comment implies that the authors should expand their dataset analysis, it does not provide specific guidance on which datasets to consider or how to incorporate them into the study. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result. The authors can infer that it relates to the discussion or results sections, but this inference is not explicit. The comment is specific in its suggestion to consider other datasets for generalization, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. However, the comment does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. This feedback is somewhat helpful as it identifies a potential area for improvement by recommending the inclusion of additional datasets. However, the comment lacks specificity and does not provide guidance on which datasets to consider or how to incorporate them into the study. To be more helpful, the comment could specify which datasets are relevant or provide examples of how additional datasets could enhance the generalizability of the proposed method. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and actionable details.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the Bayes-optimality of the systems and suggests that more work needs to be done at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more context and experiments to test the Bayes-optimality hypothesis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the Bayes-optimality of the systems and suggests that more work needs to be done at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. While the comment does not explicitly mention a specific part of the paper, it implies that the authors should address this issue in the introduction or methodology sections. The authors can infer that the comment pertains to the initial sections of the paper, but they cannot pinpoint the exact part being addressed. The comment is specific in detailing what needs to be addressed, namely, establishing alternative hypotheses and designing experiments to discriminate between them. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the Bayes-optimality of the systems and suggests that more work needs to be done to establish alternative hypotheses and design experiments to discriminate between them. The comment implies that the current analysis is confirmatory and lacks a comprehensive exploration of alternative hypotheses. However, it does not provide specific examples or references to support the claim that the systems are not Bayes-optimal or that more work is needed. The reasoning is based on the reviewer\\'s perception of the paper\\'s focus and the lack of alternative hypotheses, but it lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the Bayes-optimality of the systems discussed in the paper, particularly in relation to the relatively straightforward problems investigated. It suggests that more work is needed at the start of the paper to establish alternative hypotheses and design experiments to discriminate between them. This feedback is valuable as it points out a potential gap in the paper's analysis and encourages the authors to provide a more comprehensive exploration of alternative hypotheses. However, the comment could be more helpful if it provided specific suggestions on how to establish these alternative hypotheses or design the experiments. Overall, the comment is mostly helpful as it identifies a significant area for improvement and offers a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add confidence intervals to the reported values in Table 1, which provides results for the performance of different fairness improvement techniques. This action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. The authors know exactly how to address the feedback by including confidence intervals, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values being very close, making it difficult to draw conclusions. The comment suggests a concrete solution by recommending the addition of confidence intervals to provide a more robust analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the reported values in Table 1 are very close, making it difficult to draw conclusions. The reviewer suggests adding confidence intervals to provide a more robust analysis. While the comment identifies a potential issue with the reported values, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to add confidence intervals is a logical response to the issue, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that the reported values are very close, making it difficult to draw conclusions. It provides a clear and actionable suggestion by recommending the addition of confidence intervals to provide a more robust analysis. This feedback is valuable as it guides the authors on how to improve the presentation and interpretation of their results, enhancing the clarity and reliability of their findings. However, the comment could be more helpful if it explained why confidence intervals are important or how they would affect the conclusions drawn from the data. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some choices in the paper are not justified or clear, but it does not provide specific examples or guidance on which choices need clarification or justification. The comment ends with \"See questions for the authors,\" implying that the authors should address these issues through additional questions. However, without explicit instructions or detailed examples, the authors are left without a clear understanding of what specific choices need clarification or justification. The action is implicit and somewhat vague, as it requires the authors to infer which choices need attention and how to address them. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights that some choices are not justified or clear, but it does not specify which choices are being referred to or provide any context. This makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment lacks grounding as it does not mention specific sections, figures, or tables, and it is not specific about what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some choices are not justified or clear, but it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights that some choices in the paper are not justified or clear, but it does not provide specific examples or guidance on which choices need clarification or justification. The comment ends with a request for the authors to address these issues through additional questions, which implies that the authors should provide more detailed explanations or justifications for their choices. However, without specific examples or detailed feedback, the authors may find it challenging to address the concerns effectively. The comment is somewhat helpful as it identifies a potential area for improvement but lacks depth and specificity, leaving the authors with a general direction to follow rather than concrete steps to take.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about hyperparameter tuning, specifically noting that the paper has two hyperparameters that make pruning laborious. It also points out that the hyperparameters affect both FLOPs and accuracy, making the tuning process challenging. The reviewer suggests that the paper should provide detailed discussions on how the grid search is conducted for reproducibility. While the comment identifies a specific issue and suggests a potential solution, it does not explicitly instruct the authors to include detailed discussions on hyperparameter tuning. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information on the grid search process. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameter tuning, specifically mentioning the presence of two hyperparameters that make pruning laborious. It also points out that the hyperparameters affect both FLOPs and accuracy, making the tuning process challenging. The reviewer suggests that the paper should provide detailed discussions on how the grid search is conducted for reproducibility. While the comment does not explicitly mention a specific section, it is clear that it pertains to the hyperparameter tuning aspect of the paper. The authors can infer that it relates to the experimental section or the discussion on regularization. However, the comment lacks specificity in terms of what aspects of the hyperparameter tuning process need to be addressed or how the grid search should be discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about hyperparameter tuning, specifically noting that the paper has two hyperparameters that make pruning laborious. It also points out that the hyperparameters affect both FLOPs and accuracy, making the tuning process challenging. The reviewer suggests that the paper should provide detailed discussions on how the grid search is conducted for reproducibility. While the comment identifies a potential issue with the hyperparameter tuning process, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for detailed discussions on grid search is a logical response to the concern, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific concern regarding hyperparameter tuning, noting that the paper has two hyperparameters that make pruning laborious. It highlights a potential issue with the tuning process, where multiple solutions can hit the same FLOPs, making it challenging to navigate. The reviewer suggests that the paper should provide detailed discussions on how the grid search is conducted for reproducibility. This feedback is clear and actionable, as it points out a specific area for improvement and provides a clear direction for the authors to enhance their draft. However, the comment could be more helpful if it offered suggestions on how to present the grid search process or provided examples of how to address the issue. Overall, the comment is mostly helpful, as it effectively guides the authors in improving their draft by addressing a critical aspect of the paper's methodology.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, making it unclear how the known attacks differ from the unknown attacks. While the comment identifies a specific issue with the presentation of data, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to include the accuracies in Figure 1 to clarify the distinction between known and unknown attacks. However, the comment lacks concrete details on how to present this information, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of accuracies of the target model using different defenses against the FGSM attack, which makes it unclear how the known attacks differ from the unknown attacks. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, making it unclear how the known attacks differ from the unknown attacks. This claim is somewhat verifiable as it identifies a specific issue with the presentation of data in Figure 1, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how it affects the clarity of the presentation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the presentation of data in Figure 1, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown. This lack of information makes it unclear how the known attacks differ from the unknown attacks. By pointing out this omission, the comment provides clear and actionable feedback, encouraging the authors to include the missing data to enhance the clarity and completeness of their presentation. This feedback is valuable as it helps the authors improve the transparency and comprehensiveness of their results, making the comment mostly helpful. However, it could be more helpful if it suggested specific ways to present the data or provided examples of how to address this issue. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. This provides a clear and direct action for the authors to take, which is to consider implementing a log-scale for better readability. The suggestion is concrete and specific, giving the authors a clear path forward in improving their figures. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. However, it does not specify which figures are problematic or provide specific examples of what makes them hard to read. This lack of detail makes it difficult for the authors to identify the exact figures that need attention. While the authors can infer that the comment pertains to figures, the comment is not fully grounded and lacks specificity. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that some figures are difficult to read and recommends using a log-scale for the y-axis. However, it does not provide any specific examples or reasoning to support why this change would improve readability. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures in the paper, noting that they are difficult to read. It provides a clear and actionable suggestion by recommending the use of a log-scale for the y-axis to improve readability. This feedback is valuable as it guides the authors on how to enhance the clarity and effectiveness of their figures, which is crucial for effective communication of their results. However, the comment could be more helpful if it included examples of figures that are particularly challenging to read or detailed guidance on how to implement the log-scale. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the validation of the proposed method, specifically noting that the claim about the usefulness of augmentation information for \"flowers and birds\" is not supported by experimental results. It suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. While the comment explicitly states the need for validation and provides specific examples of datasets, it does not offer detailed guidance on how to conduct the validation or what specific metrics to use. The action is clear but somewhat vague, as the authors know what needs to be done but may not have a complete understanding of how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific examples of datasets, such as the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset, which are relevant to the discussion. This provides clear guidance on where the authors should focus their attention. However, the comment does not specify what aspect of the validation is lacking or what specific improvements are needed. It suggests using these datasets to validate the claims, but without further detail, the authors may still need to infer the exact nature of the improvement. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the proposed method was motivated by the usefulness of augmentation information for \"flowers and birds,\" as claimed in the introduction, but this claim is not validated in the experiments. The reviewer suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. While the comment identifies a gap in the validation process, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use these datasets provides a direction for improvement but does not offer a comprehensive justification for why these datasets are particularly relevant. Therefore, the comment is somewhat verifiable, as it points out a potential issue but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical gap in the validation of the proposed method, specifically noting that the claim about the usefulness of augmentation information for 'flowers and birds' is not supported by experimental results. It suggests using fine-grained datasets like the Oxford 102 flowers dataset and the Caltech-UCSD Birds-200 dataset to validate these claims. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their work by conducting additional experiments. However, the comment could be more helpful if it offered suggestions on how to analyze the results or what specific metrics to use for validation. Overall, the comment is mostly helpful as it guides the authors towards a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of theoretical analyses and empirical evaluations regarding the convergence of GEMS to the Nash equilibrium. It explicitly states that there are no theoretical analyses and that empirical evaluations are unclear regarding convergence. However, it does not provide specific guidance on how the authors should address this issue or what kind of analyses or evaluations would be necessary. The action is implicit, as the authors need to infer that they should conduct theoretical analyses and empirical evaluations to address the lack of evidence for convergence. While the action is implied, the comment provides concrete details on what needs to be done, making it mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paper\\'s statement about opponents evolving toward the Nash equilibrium, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of theoretical analyses and empirical evaluations regarding the convergence of GEMS to the Nash equilibrium. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no theoretical analyses and empirical evaluations regarding the convergence of GEMS to the Nash equilibrium. However, it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence or detailed explanation makes it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of theoretical analyses and empirical evaluations regarding the convergence of GEMS to the Nash equilibrium. This feedback is clear and actionable, as it highlights a critical area where the authors need to provide more evidence or analysis to support their claims. However, the comment could be more helpful if it offered suggestions on how to conduct these analyses or what specific aspects should be addressed. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It identifies three specific issues with Equation (1): the unclear purpose, the incorrect definition of the optimization variable, and the unusual constraints notation. Each issue is clearly specified, giving the authors a clear understanding of what needs to be addressed. The comment provides detailed guidance on how to correct these issues, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation (1), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details three issues with the equation: the unclear purpose, the incorrect definition of the optimization variable, and the unusual constraints notation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific issues with Equation (1), such as its unclear purpose and the incorrect definition of the optimization variable. It also notes the unusual constraints notation. While the comment provides clear reasoning for each issue, it lacks specific references or examples to fully substantiate the claims. The authors would need to infer the exact nature of the issues from the comment, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides detailed and actionable feedback on Equation (1), which is crucial for understanding the paper. It identifies three specific issues: the unclear purpose of the equation, the incorrect definition of the optimization variable, and the unusual constraints notation. By pointing out these issues, the comment helps the authors clarify their presentation and improve the clarity of their work. However, the comment could be more helpful if it suggested how to resolve these issues or provided examples of how to address them. Overall, the feedback is mostly helpful as it guides the authors in enhancing the clarity and precision of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the strange observation that including the collected LIV-EN parallel data for fine-tuning makes the NMT system perform worse. It explicitly requests more discussions or explanations on this phenomenon. However, the comment does not provide specific guidance on what kind of discussions or explanations are needed, nor does it suggest how the authors might address this issue. The action is implicit and somewhat vague, as the authors know they need to provide more information but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the strange observation that including the collected LIV-EN parallel data for fine-tuning makes the NMT system perform worse and requests more discussions or explanations on this phenomenon. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about a specific observation in the paper, namely that including the collected LIV-EN parallel data for fine-tuning makes the NMT system perform worse. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim or explain why this observation is strange. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about a specific observation in the paper, where including the collected LIV-EN parallel data for fine-tuning makes the NMT system perform worse. It requests more discussions or explanations on this phenomenon. While the comment identifies a potential issue, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this observation or improve their analysis. The feedback is somewhat helpful as it prompts the authors to consider additional explanations, but it could be more comprehensive and actionable to be fully beneficial. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to substantiate these conjectures, what specific reasoning or references are needed, or how to address the lack of clarity. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim about the paper, namely that it contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in identifying the issue of unsubstantiated conjectures and the need for reasoning or references, but it lacks grounding because it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it contains unsubstantiated conjectures about \"fine-tuning as exposure of existing capabilities in LMs.\" However, the comment lacks depth and does not provide any guidance or suggestions on how the authors might substantiate these conjectures or address the lack of reasoning or references. Without actionable feedback or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. While the comment implies that this could be beneficial, it does not explicitly instruct the authors to include NaturalSpeech 3 as a baseline. The action is somewhat implicit, as the authors can infer that it would be beneficial to do so, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in suggesting a baseline for comparison, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. However, it does not provide any reasoning or evidence to support why this is beneficial or how it would improve the paper. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the recommendation.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when using FACodec. This is a constructive suggestion that could enhance the paper by providing a more comprehensive comparison. However, the comment lacks specificity and does not explain why NaturalSpeech 3 is a suitable baseline or how it would improve the paper. While the suggestion is relevant, it does not offer detailed guidance or examples, making it somewhat helpful. The authors would benefit from more detailed feedback on how to implement this suggestion effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the experiments, specifically regarding the use of first 4 weeks data for inference by the proposed method. It suggests that other methods should also use this data for training, implying that the current experimental setting may not be fair. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their experimental setup. The action is implicit and somewhat vague, as the authors need to infer that they should adjust their experimental design to ensure fairness. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the fairness of the experiments, particularly regarding the use of first 4 weeks data for inference by the proposed method. It suggests that other methods should also use this data for training, implying that the current experimental setting may not be fair. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing the fairness concern and suggesting a potential adjustment to the experimental setup. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the experiments, specifically regarding the use of first 4 weeks data for inference by the proposed method. The reviewer suggests that other methods should also use this data for training, implying that the current experimental setting may not be fair. However, the comment lacks specific examples or references to support the claim of unfairness, making it difficult for the authors to understand and address the issue. The reasoning is based on a logical assumption but lacks detailed justification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the fairness of the experiments, specifically regarding the use of first 4 weeks data for inference by the proposed method. It suggests that other methods should also use this data for training, implying that the current experimental setting may not be fair. This feedback is somewhat helpful as it identifies a potential issue with the experimental design that could affect the validity of the results. However, the comment lacks specific guidance on how the authors might address this concern or improve the fairness of their experiments. To be more helpful, the comment could provide suggestions on how to ensure fairness, such as proposing alternative experimental setups or data splits. Therefore, the comment is rated as somewhat helpful, as it points out a potential weakness but does not fully guide the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). This is a clear and direct action that the authors can take to improve their draft. The comment provides specific details on what needs to be included in the results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or table where these results should be included. The authors can infer that it relates to the results section, but the lack of explicit grounding makes it difficult to pinpoint the exact location. The comment is specific in detailing what needs to be addressed, namely the inclusion of speedup results for different model sizes and sparsity categories. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This feedback is specific and offers a concrete way for the authors to enhance the completeness and utility of their results section. By addressing this suggestion, the authors can provide a more comprehensive analysis of their model's performance, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it included examples of how to present these results or discussed the potential impact of including them. Overall, the comment is mostly helpful, as it guides the authors towards a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of sequential bias on the VisDial results. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider to investigate the impact of sequential bias. Without specific instructions or suggestions, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of sequential bias on the VisDial results, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the results section or the discussion of VisDial, but this inference is not explicit. The comment is specific in asking about the impact of sequential bias, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification about the impact of sequential bias on the VisDial results. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of sequential bias on the VisDial results. While it identifies a potential area for improvement or clarification, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the results might be affected by sequential bias. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the experimental results and the stated goal of LTAP, specifically regarding the performance improvement for head classes compared to tail classes. It implies that the authors should address this contradiction by either revising their experimental results or reevaluating their claim about parameter protection for tail classes. However, the comment does not explicitly instruct the authors to take these actions or provide specific guidance on how to resolve the discrepancy. The action is implicit and somewhat vague, as the authors need to infer the need for revision and the steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experimental results on the ImageNet-LT dataset and compares them with ATO and RReg. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a discrepancy between the performance improvement for head classes and the stated goal of strengthening parameter protection for tail classes in LTAP. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on the ImageNet-LT dataset contradict the stated goal of LTAP, which is to strengthen parameter protection for tail classes. The reviewer provides a logical reasoning by comparing the performance improvement for head classes versus tail classes, suggesting that the results do not align with the stated goal. However, the comment lacks specific examples or detailed analysis to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the experimental results and the stated goal of the paper, specifically regarding the performance improvement for head classes compared to tail classes in the LTAP method. It highlights that the results contradict the goal of strengthening parameter protection for tail classes, which is a significant observation. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their experimental design to better align with their stated goals. While it points out a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It suggests that this reliance may introduce biases or inconsistencies in the quality assessment of generated documentations due to the potential for inaccurate scores from LLMs. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the reliability of their evaluation. The action is implicit and vague, as the authors are left to infer that they need to consider alternative evaluation methods or mitigate the potential biases introduced by LLMs. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the reward computation, specifically mentioning the reliance on LLM-based evaluation by prompting. This provides some grounding as it allows the authors to identify the relevant part of the paper, but it does not specify which section or part of the evaluation process is being discussed. The comment is specific in detailing the concern about the reliability of the search process and the potential introduction of biases or inconsistencies in the quality assessment. However, without explicit references to sections or figures, the comment is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reward computation relies on LLM-based evaluation by prompting, which may introduce biases or inconsistencies in the quality assessment of generated documentations. The claim is somewhat verifiable as it provides a logical reasoning for the potential issue, but it lacks specific examples or references to support the claim fully. The authors would need to further investigate or provide evidence to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the reliability of the reward computation, which relies on LLM-based evaluation by prompting. It highlights the concern that this reliance may introduce biases or inconsistencies in the quality assessment of generated documentations due to the potential for inaccurate scores from LLMs. This feedback is somewhat helpful as it points out a critical area for improvement, but it lacks specific suggestions or guidance on how the authors might address this issue or enhance the reliability of their evaluation. The comment provides a starting point for the authors to consider alternative evaluation methods or mitigate potential biases, but it could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more empirical examples to demonstrate the effectiveness of the described process and compare it to state-of-the-art (SOTA) performance from referenced papers. It also mentions that Equation 12 might contribute to this, but it is unclear. While the comment implies that the authors should clarify the effectiveness of their process, it does not provide specific guidance on how to improve the clarity of Equation 12 or what additional empirical examples to include. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq 12,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the effectiveness of the described process should be demonstrated through empirical examples and comparisons to state-of-the-art (SOTA) performance from referenced papers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of the described process is surprising and suggests that empirical examples and comparisons to state-of-the-art (SOTA) performance should be provided. However, the comment does not provide specific examples or references to support the claim that the process is surprising or ineffective. The mention of Equation 12 implies that it might contribute to this, but the comment lacks detailed reasoning or evidence to substantiate the claim. As a result, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the necessary details to fully support the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by suggesting that the authors should provide more empirical examples to demonstrate the effectiveness of the described process and compare it to state-of-the-art (SOTA) performance from referenced papers. It also mentions that Equation 12 might contribute to this, but it is unclear. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that needs clarification and improvement. However, the comment could be more helpful if it provided additional guidance on how to enhance the clarity of Equation 12 or suggested specific examples to include. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty of the problem and provides an explanation based on Assumption 1. It suggests that the adversary cannot pick arbitrary S but only those where a constant alpha-fraction of the observations are hidden/removed. The reviewer then explains that after removal, it reduces to alpha * m pairs (a, y), which still suffices for accurate recovery provided that m = O(k log n). While the comment provides an insightful explanation, it does not offer explicit guidance or suggestions for how the authors might address this concern or improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider this explanation in their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern about the difficulty of the problem, which is related to Assumption 1. It provides a detailed explanation of why the problem might be difficult based on the assumption that the adversary cannot pick arbitrary S but only those where a constant alpha-fraction of the observations are hidden/removed. The reviewer explains that after removal, it reduces to alpha * m pairs (a, y), which still suffices for accurate recovery provided that m = O(k log n). This level of detail allows the authors to understand the specific issue being raised and how it relates to their work. However, the comment does not explicitly mention which part of the paper this concern is related to, such as a specific section or figure. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point presents a claim about the difficulty of the problem based on Assumption 1. It provides a detailed explanation of why the problem might be difficult, using logical reasoning to support the claim. The reviewer explains that the assumption limits the adversary's ability to pick arbitrary S, which reduces the number of pairs (a, y) after removal. This explanation is clear and provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises a concern about the difficulty of the problem, specifically addressing Assumption 1. It provides a detailed explanation of why the problem might be difficult, based on the assumption that the adversary cannot pick arbitrary S but only those where a constant alpha-fraction of the observations are hidden/removed. The reviewer explains that after removal, it reduces to alpha * m pairs (a, y), which still suffices for accurate recovery provided that m = O(k log n). This feedback is somewhat helpful as it identifies a potential weakness in the paper and offers a detailed explanation of the issue. However, it could be more helpful if it suggested ways for the authors to address this concern or improve their draft. Overall, the comment provides valuable insights but lacks actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a contradiction between Figure 1 and the last two columns of Table 1, specifically regarding the relationship between NNGS and the number of selected k-nearest neighbors. It suggests that the increase in NNGS with k contradicts the comparison in the table. However, the comment does not provide explicit guidance on how the authors should address this contradiction or what changes need to be made to resolve it. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate and correct the discrepancy. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the contradiction between the relationship illustrated in Figure 1 and the comparison in the last two columns of Table 1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that Figure 1 illustrates a relationship between NNGS and the number of selected k-nearest neighbors, which contradicts the comparison in the last two columns of Table 1. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed explanations or references to the data or methods used in Figure 1 and Table 1, making it difficult for the authors to understand and address the issue. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific contradiction between Figure 1 and the last two columns of Table 1, regarding the relationship between NNGS and the number of selected k-nearest neighbors. It highlights that the increase in NNGS with k contradicts the comparison in the table. This feedback is clear and actionable, as it points out a potential error or inconsistency that the authors need to address. By identifying this discrepancy, the comment provides valuable guidance for the authors to correct or clarify their results. However, the comment could be more helpful if it suggested how the authors might resolve this contradiction or offered additional insights into the implications of this finding. Overall, the comment is mostly helpful, as it directs the authors' attention to a critical area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact of a large number of tasks on the set of shared parameters. It also suggests that the experiments only provide results for a limited number of tasks (up to 20) and asks the authors to address this question. While the comment explicitly requests the authors to address the impact of a large number of tasks, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit but concrete, as the authors know what needs to be addressed but may need to infer the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact of a large number of tasks on the set of shared parameters. It also points out that the experiments only provide results for a limited number of tasks (up to 20). The authors are prompted to address this question regarding the effect of the number of tasks on the proposed approach. However, the comment does not specify which part of the paper this concern relates to, such as the methodology or experimental setup. While the authors can infer that it pertains to the experimental section, the lack of explicit grounding makes it difficult to pinpoint the exact area of concern. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and suggests that the experiments only provide results for a limited number of tasks (up to 20). The comment requests the authors to address this question, indicating a need for further analysis or discussion. While the comment identifies a potential issue, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional information or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the extensibility of the proposed method to a large number of tasks, similar to the challenges faced in multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and highlights that the experiments only provide results for a limited number of tasks (up to 20). The comment is specific in its inquiry, prompting the authors to address the potential impact of a large number of tasks on their approach. However, it does not provide detailed guidance or suggestions on how to conduct this analysis or what aspects to focus on. While it identifies a relevant area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the eyetracking data selection/filtering is perplexing, suggesting that everything is analyzed with some exclusions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what specific aspects need clarification. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"eyetracking data selection/filtering,\" which is a specific aspect of the paper related to data analysis. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is perplexing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the eyetracking data selection/filtering, noting that everything is analyzed with some exclusions. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the eyetracking data selection/filtering process, noting that everything is analyzed with some exclusions. However, it does not provide any suggestions or guidance on how the authors might clarify or address this issue. Without actionable feedback or detailed insights, the comment lacks the depth and specificity needed to be helpful. The authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the credibility of the results in the Appendix for InitNO, suggesting that the paper InitNO reported improved text-image alignment on StableDiffusion-v1-4, but Table 6 shows that InitNO\\'s alignment is lower than that of StableDiffusion-v1-4. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the credibility of their results. The feedback is vague and lacks actionable steps, leaving the authors uncertain about what specific actions to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the credibility of the results in the Appendix for InitNO, specifically mentioning the comparison with Table 6. However, it does not explicitly mention which part of the paper this comparison is in, making it weakly grounded. The comment is specific in detailing the issue with the credibility of the results, as it points out a discrepancy between the reported results in InitNO and the results shown in Table 6. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the credibility of the results in the Appendix for InitNO is questionable, based on a comparison with Table 6. However, the comment does not provide specific evidence or reasoning to support this claim, such as detailed analysis or references to the original paper InitNO. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the credibility of the results in the Appendix for InitNO, specifically noting a discrepancy between the reported results in InitNO and the results shown in Table 6. However, the comment lacks specific details or suggestions on how the authors might address this issue or improve the credibility of their results. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could benefit from additional editing, particularly in terms of language usage and type, rather than a technical perspective. It also mentions that the equations are unwieldy due to the use of sub/superscripts and suggests considering dropping some of them for convenience. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The suggestion to drop sub/superscripts is concrete, but the overall feedback lacks detailed guidance on how to improve the writing or equations. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks specific instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing is uneven and could benefit from additional editing, particularly in terms of language usage and type. It also mentions that the equations are unwieldy due to the use of sub/superscripts and suggests considering dropping some of them for convenience. However, the comment does not specify which parts of the paper are affected by these issues, making it weakly grounded. The authors can infer that the writing and equations are being discussed, but without explicit references, it is difficult to pinpoint the exact sections. The comment is specific in suggesting ways to improve the writing and equations, but the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing is uneven and could benefit from additional editing, particularly in terms of language usage and type. It also notes that the equations are unwieldy due to the use of sub/superscripts and suggests considering dropping some of them for convenience. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the writing is uneven or the equations are unwieldy. This makes the claim somewhat verifiable, as the authors can infer the issues but may need to explore them further to fully understand the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two areas for improvement: the uneven writing and the unwieldy equations due to the use of sub/superscripts. It suggests that the authors consider dropping some of the sub/superscripts for convenience, which is a concrete and actionable suggestion. However, the comment lacks specific guidance on how to improve the writing or equations, such as providing examples of where the writing could be edited or suggesting alternative ways to simplify the equations. While the feedback is somewhat helpful, it could be more comprehensive and actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that the authors should explain the high cost of image acquisition and the manual collection process used. This is an explicit action that provides a clear direction for the authors to address the issue of dataset size and cost. The second part of the comment raises minor questions about the clarity of the text, specifically regarding the content of \"regulatory requirements\" and the definition of \"politically sensitive.\" While these questions are relevant, they do not provide specific guidance on how to improve the draft. Therefore, the comment is mostly actionable, as it includes an explicit action and provides some guidance on minor issues.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the dataset size and the cost of image acquisition, as well as the line numbers for the questions about \"regulatory requirements\" and \"politically sensitive.\" This allows the authors to accurately identify the sections being addressed. The comment is also specific because it provides clear guidance on what needs to be addressed, such as explaining the cost of image acquisition and the manual collection process, as well as clarifying the content of \"regulatory requirements.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions the cost of image acquisition and the manual collection process, suggesting that the dataset size is small relative to the development cost. This is a factual observation rather than a claim, as it does not express an opinion or require justification. The second part of the comment raises minor questions about the clarity of the text, specifically regarding the content of \"regulatory requirements\" and the definition of \"politically sensitive.\" These questions are factual and do not require verification. Therefore, the overall comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it highlights a concern about the small size of the dataset relative to the development cost, suggesting that the authors should explain the cost of image acquisition and the manual collection process used. This feedback is actionable and provides a clear direction for the authors to address the issue of dataset size and cost. However, the comment also raises minor questions about the clarity of the text, specifically regarding the content of \"regulatory requirements\" and the definition of \"politically sensitive.\" While these questions are relevant, they do not offer actionable guidance on how to improve the draft. Overall, the comment is mostly helpful as it identifies a significant issue and provides some guidance, but it could be more comprehensive with additional feedback. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses curiosity about the generation of the third column in Figure 7, noting that the visualizations do not appear to be normalized. While the comment raises a question, it does not provide explicit guidance or suggestions for the authors to address this issue. The action is implicit, as the authors can infer that they need to clarify or explain the normalization process for the third column, but the comment lacks concrete details on how to do so. Therefore, this comment is somewhat actionable, as it prompts the authors to address a specific aspect of their visualization but does not provide detailed instructions on how to do so.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the third column, questioning whether the visualizations are normalized. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses curiosity about the generation of the third column in Figure 7, noting that the visualizations do not seem to be normalized. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses curiosity about the generation of the third column in Figure 7, noting that the visualizations do not appear to be normalized. While it identifies a potential issue with the visual presentation, it lacks specific guidance or suggestions for the authors to address this concern. The comment does not provide actionable feedback or detailed explanations on how to improve the normalization or clarify the data presentation. As a result, the comment is somewhat helpful, as it highlights a potential area for improvement but does not offer comprehensive guidance for the authors to enhance their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the heuristic nature of the assignment entropy maximization objective and the lack of evaluation of its benefits in the ablation experiment. It also mentions the absence of discussion on potential negative societal impacts. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to conduct a more thorough evaluation of the assignment entropy maximization and discuss potential societal impacts. However, the lack of specific instructions or examples makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the heuristic nature of the assignment entropy maximization objective and the lack of evaluation of its benefits in the ablation experiment. It also mentions the absence of discussion on potential negative societal impacts. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology and the ablation experiment. The comment is specific in detailing what needs to be addressed, such as evaluating the benefits of assignment entropy maximization and discussing potential societal impacts. However, the lack of explicit section references makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assignment entropy maximization objective is heuristic and lacks evaluation in the ablation experiment. It also mentions the absence of discussion on potential negative societal impacts. While the comment identifies specific areas for improvement, it does not provide detailed reasoning or evidence to support these claims. The lack of specific examples or references makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two key areas for improvement in the paper. First, it points out that the assignment entropy maximization objective is regarded as heuristic, suggesting that the authors should provide a more thorough evaluation of its benefits in the ablation experiment. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. Second, the comment highlights the absence of discussion on potential negative societal impacts, which is an important consideration for the authors to address. While the comment identifies these issues, it does not offer specific suggestions or guidance on how to address them, which limits its helpfulness. Overall, the comment is somewhat helpful as it points out areas for improvement but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that there is only one baseline model in the experimental section. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting additional baseline models to include or explaining why multiple baselines are necessary. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that there is only one baseline model in the experimental section. However, it does not specify which part of the paper this issue is related to, such as a particular section or table where the baseline models are discussed. This makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed, such as suggesting additional baseline models or explaining why multiple baselines are necessary. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is only one baseline model in the experimental section, which is a factual statement. However, it does not provide any reasoning, examples, or references to support why this is a concern or how it affects the paper\\'s validity or comprehensiveness. Without additional context or evidence, the claim remains unverifiable, as it lacks the necessary support to help the authors understand the significance of this observation. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that there is only one baseline model in the experimental section. This feedback is clear and actionable, as it highlights a potential limitation in the experimental setup that could affect the comprehensiveness and robustness of the results. By pointing out this issue, the reviewer provides the authors with a clear direction for improvement, namely the need to include additional baseline models. However, the comment could be more helpful if it suggested specific types of baseline models that might be beneficial to include or explained why multiple baselines are important. Despite this, the feedback is mostly helpful as it directs the authors' attention to a critical area for enhancement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of certain baselines and literature comparisons in the results section, specifically mentioning traditional quantization-aware training (QAT) methods like LSQ and LSQ+, as well as LLM-based QAT work and recent post-training quantization (PTQ) baselines like SpinQuant. It suggests that including these comparisons would be beneficial, particularly in understanding the trade-offs between using extra memory and relying on fine-tuning low-rank adapters. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to include these comparisons or which specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for additional comparisons but may not know exactly how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results\" and \"some baselines and literature comparisons,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is missing, such as traditional QAT methods like LSQ and LSQ+, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. The comment also provides a rationale for including these comparisons, suggesting that understanding the benefits of using extra memory versus fine-tuning low-rank adapters is important. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that certain baselines and literature comparisons are missing from the results section, such as traditional QAT methods like LSQ and LSQ+, other LLM-based QAT work, and recent PTQ baselines like SpinQuant. The reviewer suggests that including these comparisons would be beneficial, particularly in understanding the trade-offs between using extra memory and relying on fine-tuning low-rank adapters. While the comment identifies specific areas for improvement, it does not provide detailed reasoning or evidence to support why these comparisons are crucial. The mention of \"traditional QAT\" being more memory expensive provides some context, but the claim lacks comprehensive justification or examples. Therefore, the comment is somewhat verifiable, as it highlights areas for improvement but lacks detailed support or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas where the paper could be improved by providing additional comparisons and baselines. It suggests including traditional quantization-aware training (QAT) methods like LSQ and LSQ+, as well as other LLM-based QAT work and recent post-training quantization (PTQ) baselines like SpinQuant. The comment highlights the importance of understanding the benefits of using extra memory compared to relying solely on fine-tuning low-rank adapters. This feedback is clear and actionable, as it provides specific suggestions for enhancing the paper's results section. However, it could be more helpful if it included examples or detailed reasoning on why these comparisons are crucial. Overall, the comment is mostly helpful as it guides the authors in improving their draft by suggesting relevant additions and comparisons.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for more detailed instructions on defining attributes and the difference between them. This is a clear and direct request for the authors to provide additional information, making the action explicit and concrete. The authors know exactly what needs to be done to improve their draft, which is to provide more detailed instructions on these aspects. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about defining attributes and the difference between them, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its request for more detailed instructions, but without grounding, the authors may struggle to identify the exact sections that need clarification. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for more detailed instructions on defining attributes and the difference between them, without any claim or suggestion that requires verification. It is a factual request for clarification, not an opinion or judgment. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the definition of attributes and the difference between them. It suggests that more detailed instructions should be provided, which is a clear and actionable feedback. However, the comment does not offer specific suggestions or examples of how to improve the definition or provide detailed instructions, which could enhance its helpfulness. While it points out a critical area for clarification, the lack of detailed guidance limits its impact. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the theory in the paper, suggesting that it may not be helpful in predicting the robustness of models to adversarial perturbations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the theory to better predict robustness. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the theory in the paper, specifically questioning whether it can help predict the robustness of models to adversarial perturbations. However, it does not specify which part of the paper this theory is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the theory\\'s utility but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the theory in the paper, suggesting that it may not be helpful in predicting the robustness of models to adversarial perturbations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the theory presented in the paper, specifically questioning whether it can help predict the robustness of models to adversarial perturbations. This feedback is somewhat helpful as it identifies a potential weakness in the theoretical framework, which could guide the authors in revising or expanding their theory to address this issue. However, the comment lacks depth and does not provide specific suggestions or guidance on how to improve the theory or address the concern. Therefore, it is rated as somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and where the \"agnostic\" part comes into play. While the comment identifies a potential area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the term \"scenario\" and its implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and where the \"agnostic\" part comes in. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the meaning of \"scenario,\" but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and where the \"agnostic\" part comes in. However, it does not provide any supporting evidence, reasoning, or references to clarify the ambiguity. The lack of justification or examples makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"scenario\" in the paper, specifically whether it refers to class or instances, and where the \"agnostic\" part comes in. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this issue. The comment lacks depth and actionable feedback, leaving the authors with a vague understanding of what needs to be addressed. Therefore, it is rated as barely helpful, as it provides some insight but does not offer meaningful assistance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the naming of the method \"Maestro\" and points out that it is never introduced. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the name should be changed, explained, or justified. The comment lacks actionable details, leaving the authors uncertain about how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the naming of the method \"Maestro\" and points out that it is never introduced. However, it does not specify which part of the paper this naming issue is related to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what is wrong with the naming or why it seems strange. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the naming of a method, \"Maestro,\" and points out that it is never introduced. However, the comment does not provide any reasoning, examples, or references to support why this naming choice is confusing or inappropriate. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the naming of a method, \"Maestro,\" and points out that it is never introduced in the paper. This is a valid observation that could help the authors clarify their methodology or provide context for the naming choice. However, the comment lacks depth and does not offer suggestions or guidance on how the authors might address this issue or improve the clarity of their work. While it identifies a potential area for improvement, it does not provide actionable feedback or specific recommendations, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly instructs the authors to clarify the definition of 'best' candidate on page 5. It provides a specific action by asking the authors to define what 'best' means within the context of the paper, such as whether it refers to candidates that are most relevant for prediction, those with the highest confidence scores, or other criteria. This feedback is clear and concrete, giving the authors a direct path to improve their draft by providing a more precise definition. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'page 5' and 'candidate,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the definition of 'best' candidate and whether it refers to candidates that are most relevant for prediction, those with the highest confidence scores, or other criteria. This provides clear guidance on what the authors need to clarify in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that the term 'best' candidate is not clearly defined in the paper, and it asks for clarification on what criteria are used to determine the 'best' candidate. This is a request for clarification rather than a claim, as it does not express an opinion or judgment about the paper's content. Therefore, it is classified as 'No', as it does not contain a claim that requires verification.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies a specific area of ambiguity in the paper, namely the definition of 'best' candidate on page 5. It provides a clear and actionable suggestion by asking the authors to clarify what criteria are used to determine the 'best' candidate, such as relevance for prediction or confidence scores. This feedback is valuable as it guides the authors to improve the clarity and precision of their terminology, which is essential for effective communication and understanding. However, the comment could be more helpful if it offered examples of how to define 'best' or suggested alternative criteria. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some claims in the paper are over-asserted, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. This feedback implies that the authors should revisit and clarify their claims to ensure accuracy and consistency. However, the comment does not provide explicit guidance on how to address this issue or suggest specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their claims but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the over-claiming of certain points in the paper, particularly noting that the proposed method does not consider feed-forward layers but is described as if it does. This feedback is fully grounded as it explicitly mentions the specific aspect of the paper being addressed, allowing the authors to accurately identify the part needing revision. The comment is also specific because it clearly specifies the issue with the over-claiming and provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some points are over-claimed, specifically mentioning that the proposed method does not consider feed-forward layers but is described as if it does. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the over-claiming. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some points are over-claimed, particularly regarding the consideration of feed-forward layers in the proposed method. This feedback is somewhat helpful as it points out a potential area of confusion or misrepresentation in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their claims. To be more helpful, the comment could include examples of where the over-claiming occurs or offer suggestions on how to rephrase the text to accurately reflect the method\\'s capabilities. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific aspects of the experiments that are not clearly motivated, namely the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific changes to improve the clarity of the experiments. The action is implicit, as the authors need to infer that they should clarify the motivation behind these methods, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific aspects of the experiments that are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. This provides some grounding as it allows the authors to understand which parts of the paper are being addressed. However, the comment does not specify what aspects of these methods are unclear or how they could be improved, making it somewhat specific. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these methods are unclear or how they could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the experiments, noting that the \"no variations\" and \"Up to 18 games\" finetuning methods are not clearly motivated. This feedback is somewhat helpful as it points out a gap in the paper that needs attention. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might clarify these methods or improve their motivation. Without additional details or actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that it is necessary to evaluate the method performance under missing modality cases, such as testing sets with different missing ratios. It provides references to specific works, [A] and [B], which suggest how to approach this evaluation. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The authors know exactly which aspect to address and how to implement the suggested evaluation, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the tables, which only show results for \"Miss-V\" and \"Miss-A\" and suggests that it is necessary to evaluate the method performance under missing modality cases, such as testing sets with different missing ratios. The comment provides references to specific works, [A] and [B], which offer guidance on how to approach this evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that only \"Miss-V\" and \"Miss-A\" results are shown in tables 1/2, and it is necessary to evaluate the method performance under missing modality cases. The comment provides references to specific works, [A] and [B], which suggest how to approach this evaluation. This level of detail and reference to external works supports the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of results in tables 1/2, noting that only \"Miss-V\" and \"Miss-A\" results are shown. It highlights the importance of evaluating the method performance under missing modality cases, such as testing sets with different missing ratios. By providing references to specific works, [A] and [B], the comment offers actionable guidance on how to address this limitation. This feedback is clear and constructive, as it directs the authors to a specific area for improvement and provides a path for enhancing the comprehensiveness of their evaluation. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an ablation study on the effect of using image features should be included, given that the conditions are not changed during browsing the web shop. While the comment implies that an ablation study is necessary, it does not explicitly instruct the authors to conduct this study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is necessary and understand the specific aspects to investigate. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an ablation study on the effect of using image features, given that the conditions are not changed during browsing the web shop. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in suggesting an ablation study on image features, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study on the effect of using image features should be included, given that the conditions are not changed during browsing the web shop. However, the comment does not provide any specific reasoning or evidence to support why this ablation study is necessary or how it would improve the paper. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an ablation study on the effect of using image features should be included, given that the conditions are not changed during browsing the web shop. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct the ablation study or what specific aspects should be investigated. This limits the usefulness of the feedback, as the authors may not know how to implement the suggested change effectively. Therefore, the comment is somewhat helpful, as it points out a potential enhancement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. While the comment implies that the authors should consider testing their approach in more challenging scenarios, it does not provide explicit instructions or guidance on how to conduct these experiments or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include more challenging settings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental results or methodology, but without explicit references, it is challenging to pinpoint the exact area being addressed. The comment is specific in its inquiry about the performance in challenging settings, but it lacks grounding as it does not specify the exact part of the paper being questioned. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance of the approach in challenging settings, specifically mentioning the use of Transformer Big and deep Transformers. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might affect the results. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the limited scope of the experiments, which were conducted only on three language pairs with a base setting. It questions whether the approach can perform well in more challenging settings, such as those involving Transformer Big and deep Transformers. This feedback is somewhat helpful as it prompts the authors to consider the robustness and generalizability of their approach. However, the comment lacks specific suggestions or guidance on how to address this concern, such as recommending additional experiments or methodologies to evaluate performance in challenging settings. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide detailed actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' understanding of identifiability, stating that it is a property of a model assuming infinite data can be observed. It implies that the authors\\' claim about a model being unidentifiable due to insufficient data is incorrect. However, the comment does not provide explicit guidance on how the authors should correct their understanding or address this issue in their draft. The action is implicit and vague, as the authors are left to infer that they need to revise their understanding of identifiability but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the authors\\' understanding of identifiability, specifically pointing out that it is a property of a model assuming infinite data can be observed. However, it does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in its correction of the authors\\' understanding, providing a clear explanation of what is incorrect. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' understanding of identifiability, stating that it is a property of a model assuming infinite data can be observed. This claim is supported by logical reasoning, as it provides a clear explanation of what identifiability entails and why the authors\\' claim about insufficient data is incorrect. However, the comment could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a strong basis for the claim but lacks full detail in its justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant misunderstanding of the concept of identifiability in the paper. It provides a clear and concise explanation of what identifiability is and why the authors\\' claim about a model being unidentifiable due to insufficient data is incorrect. This feedback is valuable as it offers a correction to a fundamental concept in the paper, which could significantly impact the understanding and interpretation of the results. However, the comment could be more helpful if it suggested how the authors might address this misunderstanding in their draft, such as by revising their discussion or providing additional context. Overall, the comment is mostly helpful as it highlights a critical error and provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the results show no particular benefit with respect to the simple baseline the authors compare with. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results section, specifically mentioning the comparison with a simple baseline. This provides some grounding as the authors can infer that it relates to the results section, but it does not specify which part of the results section is being discussed. The comment is specific in pointing out that the results show no particular benefit with respect to the baseline, but it lacks detailed guidance on how to address this issue or what improvements might be necessary. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results show no particular benefit with respect to the simple baseline the authors compare with. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the results, stating that they show no particular benefit compared to a simple baseline. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a problem but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues related to efficiency: the time cost of the pre-training process and the slower inference speed due to the use of a diffusion-based vocoder. It explicitly suggests that the authors should describe the time cost of the pre-training process and acknowledge the slower inference speed compared to DSP and WarpNet. However, the comment does not provide specific guidance on how to address these issues or offer suggestions for improvement, such as how to optimize the pre-training process or mitigate the slower inference speed. While the action is clear, the lack of detailed guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific aspects of efficiency: the time cost of the pre-training process and the slower inference speed due to the use of a diffusion-based vocoder. It explicitly mentions the training process and inference process, providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it details the issues with efficiency, such as the time cost of pre-training and the slower inference speed compared to other methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method requires a significant amount of time for pre-training and that the inference process is slower due to the use of a diffusion-based vocoder. The claim is somewhat verifiable as it provides a logical reasoning for the inefficiency, mentioning the time cost of pre-training and the slower inference speed compared to other methods. However, the comment lacks specific details or references to support the exact time cost or the exact difference in inference speed, which would make the claim more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas of inefficiency in the paper: the time cost of the pre-training process and the slower inference speed due to the use of a diffusion-based vocoder. It provides a clear and actionable suggestion for the authors to describe the time cost of the pre-training process, which is an important aspect of efficiency. Additionally, the comment highlights the slower inference speed compared to other methods, such as DSP and WarpNet, which is a relevant observation. However, the comment could be more helpful if it offered suggestions on how to optimize the pre-training process or mitigate the slower inference speed. Overall, the feedback is mostly helpful as it provides clear directions for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but it does not explore this generalization. This implies that the authors should consider exploring this generalization to strengthen the framework\\'s applicability. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to explore this generalization. The action is implicit and somewhat vague, as the authors need to infer that they should explore the generalization themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document. It points out that while this generalization is mentioned, it is not explored, which makes the generalization of the framework questionable. This provides a clear indication of what needs to be addressed, making the comment fully grounded. However, it lacks specificity in terms of suggesting how the authors should explore this generalization or what specific aspects should be considered. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper mentions the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, but it does not explore this generalization. This makes the generalization of the framework questionable. The comment provides a logical reasoning by pointing out the lack of exploration of this generalization, which is a valid concern. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact aspects that need to be explored, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by noting that while the authors mention the possibility of generalizing the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, they do not explore this generalization. This observation is important as it questions the applicability and robustness of the framework. The comment provides a clear and actionable suggestion for the authors to explore this generalization, which could significantly enhance the framework's versatility and utility. However, the comment could be more helpful if it offered specific guidance on how to explore this generalization or what aspects to consider. Overall, the feedback is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\\'s performance. It also references a specific paper, \"Yiming Zhang, Lingfei Wu, Qi Shen, Yitong Pang, Zhi-hua Wei, Fangli Xu, Bo Long, and Jian Pei. 2022. Multiple choice questions based multi-interest policy learning for conversational recommendation. In Proceedings of the ACM Web Conference 2022, pages 2153\u20132162,\" which could serve as a model for how to present this information. This feedback is explicit and provides a concrete suggestion on how to enhance the paper, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"For a comprehensive understanding of the proposed approach\\'s performance,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting the inclusion of information on the success rate at each conversation turn. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\\'s performance. It references a specific paper, \"Multiple choice questions based multi-interest policy learning for conversational recommendation,\" which could serve as a model for presenting this information. This provides a clear rationale for the claim, as it offers a concrete example of how the information could be included and its potential benefits. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced paper. Therefore, the comment is mostly verifiable, as it provides a strong basis for the claim but lacks some specific details.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that including information on the success rate at each conversation turn would provide a more comprehensive understanding of the proposed approach\\'s performance. It highlights the importance of this data in offering insights into the framework\\'s comparative performance throughout the recommendation process. By referencing a specific paper as a model for presenting this information, the comment provides actionable feedback that can help the authors enhance their draft. This feedback is clear and actionable, offering a concrete suggestion for improvement, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is dense and difficult to read, particularly due to the inclusion of numbered lists within paragraphs. It recommends that these lists be presented as actual lists instead of being integrated into the text. While the comment implies that the authors should make this change, it does not provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors know they need to address the issue but may not be entirely sure how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is dense and difficult to read, particularly due to the inclusion of numbered lists within paragraphs. It recommends presenting these lists as actual lists instead of being integrated into the text. However, the comment does not specify which parts of the paper are particularly dense or where the numbered lists are located, making it weakly grounded. The suggestion is specific in terms of the issue identified and the proposed solution, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is dense and difficult to read, particularly due to the inclusion of numbered lists within paragraphs. It recommends presenting these lists as actual lists instead of being integrated into the text. While the comment identifies a potential issue with the readability of the paper, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion is logical and reasonable, but without additional context or evidence, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper's readability, noting that it is dense and difficult to follow, particularly due to the inclusion of numbered lists within paragraphs. It provides a clear suggestion for improvement by recommending that these lists be presented as actual lists instead of being integrated into the text. This feedback is actionable and provides a concrete way for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional guidance on how to present the lists or examples of how this might be done. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the simplicity of the classifier and suggests that other \"fake image detectors\" might also rely on spectral cues. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what steps they should consider to explore this further. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the simplicity of the classifier and suggests that other \"fake image detectors\" might also rely on spectral cues. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the discussion of the classifier or the experimental results, but this inference is not explicit. The comment is specific in its question about the underlying mechanisms of other detectors, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the simplicity of the classifier and suggests that other \"fake image detectors\" might also rely on spectral cues. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the claim or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises an interesting question about the simplicity of the classifier and suggests that other \"fake image detectors\" might also rely on spectral cues. This observation prompts the authors to consider the broader implications of their findings and encourages them to explore potential commonalities among different detectors. However, the comment does not provide specific guidance or suggestions on how the authors might investigate this further or what aspects of their work could be expanded to address this question. While it stimulates curiosity and encourages deeper exploration, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the visualization results are \"terrible\" compared to the ground truth and suggests that the authors should provide analysis of both satisfied and unsatisfied cases. This feedback is clear and direct, giving the authors a specific action to take: analyze the results and provide a breakdown. The comment also references a specific type of learning, \"class-incremental learning for semantic segmentation,\" which provides context for the analysis. This level of detail and specificity makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"visualization results\" and references a specific comparison with the ground truth. This allows the authors to accurately identify the part of the paper being addressed, which is the visualization results. The comment is also specific because it suggests a particular analysis to be conducted, namely, comparing satisfied and unsatisfied cases. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visualization results are \"terrible\" compared to the ground truth, suggesting that the authors should provide analysis of satisfied and unsatisfied cases. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visualization results, stating that they are \"terrible\" compared to the ground truth. It suggests that the authors should provide analysis of both satisfied and unsatisfied cases, which could help in understanding the performance of the model. However, the comment lacks detailed guidance on how to conduct this analysis or what specific aspects should be examined. While it points out a potential area for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is somewhat helpful, as it highlights a critical area for enhancement but does not fully guide the authors in making the necessary improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the paper\\'s reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The action is implicit and vague, as the authors are left to infer that they need to consider the limitations of previous works and possibly discuss them in their paper. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment discusses the paper\\'s reliance on previous work and the potential impact of limitations in those works on the validity and effectiveness of TIW. It also mentions that the implementation process is similar to previous work on GAN. However, the comment does not specify which part of the paper this discussion pertains to, such as a specific section or subsection. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in detailing the potential issues but lacks grounding, making it weakly grounded. Therefore, the comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper\\'s reliance on previous work could potentially affect the validity and effectiveness of TIW, and that the implementation process is similar to previous work on GAN. However, the comment does not provide specific examples or references to the previous works or how they might impact the current study. This lack of detailed evidence or reasoning makes it difficult for the authors to understand and address the concerns effectively. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment highlights a potential limitation in the paper's reliance on previous work, suggesting that any limitations or issues in those works could affect the validity and effectiveness of TIW. It also notes that the implementation process is similar to previous work on GAN. While the comment identifies a relevant issue, it lacks specific guidance or suggestions on how the authors might address this limitation or improve their work. The feedback is somewhat helpful as it points out a potential area for concern, but it does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of information during the partitioning step, specifically whether information unavailable to the policy is being used. It also questions why certain information, like patient characteristics, is not incorporated into the policy training. While the comment highlights an area of potential concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or justify the use of information during the partitioning step. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the idea of selecting a policy for each sub-group, which is a specific aspect of the paper. It raises a question about the use of information during the partitioning step, particularly whether information unavailable to the policy is being used. This provides some level of grounding as it refers to a specific part of the paper, but it does not specify which section or part of the paper this issue is discussed in. The comment is specific in questioning the use of information during partitioning, but it lacks full grounding because it does not explicitly mention the relevant section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of information during the partitioning step, specifically whether information unavailable to the policy is being used. It also questions why certain information, like patient characteristics, is not incorporated into the policy training. While the comment highlights a potential issue, it does not provide specific examples or references to support the claim. The reasoning is based on logical questioning, but without detailed evidence or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the use of information during the partitioning step, specifically whether information unavailable to the policy is being used or not. It also questions why certain information, like patient characteristics, is not incorporated into the policy training. This feedback is somewhat helpful as it identifies a potential area of confusion or oversight in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify their approach. The comment could be more helpful with additional context or detailed feedback, such as suggesting ways to incorporate the missing information or explaining the rationale behind the current approach. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the use of information during the partitioning step, specifically whether information unavailable to the policy is being used or not. It also questions why certain information, like patient characteristics, is not incorporated into the policy training. While the comment identifies a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify or justify the use of information during the partitioning step. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the idea of selecting a policy for each sub-group, which is a specific aspect of the paper. It raises a question about the use of information during the partitioning step, specifically whether information unavailable to the policy is being used. This provides some level of grounding as it refers to a specific part of the paper, but it does not specify which section or part of the paper this issue is discussed in. The comment is specific in questioning the use of information during partitioning, but it lacks full grounding because it does not explicitly mention the relevant section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of information during the partitioning step, specifically whether information unavailable to the policy is being used. It also questions why certain information, like patient characteristics, is not incorporated into the policy training. While the comment highlights a potential area of concern, it does not provide specific examples or references to support the claim. The reasoning is based on logical questioning, but without detailed evidence or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the use of information during the partitioning step, specifically whether information unavailable to the policy is being used or not. It also questions why certain information, like patient characteristics, is not incorporated into the policy training. This feedback is somewhat helpful as it"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, specifically asking why the former is worse. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what steps they might need to take to improve the quality of NeRF\\'s rendering. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rendering quality of NeRF compared to NeuS and Geo NeuS, providing a clear direction for the authors to investigate and potentially address. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the rendering quality of NeRF compared to NeuS and Geo NeuS. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, specifically asking why the former is worse. While it identifies a potential area for improvement, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the rendering quality could be improved. Without actionable feedback or detailed insights, the comment is somewhat helpful as it prompts the authors to consider a specific comparison but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about a bold assumption made in Section 3.7, questioning how it can be concluded from the proposed evaluation approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions a bold assumption made in that section, specifically about the suitability of unsupervised large-scale pretraining for NLP applications. The reviewer highlights the lack of understanding regarding how this conclusion can be drawn from the proposed evaluation approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about a bold assumption made in the manuscript regarding the suitability of unsupervised large-scale pretraining for NLP applications. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment lacks specific references, logical reasoning, or detailed explanations to help the authors understand the basis of the concern or how to address it. Without additional context or justification, the claim remains unverifiable, making it difficult for the authors to effectively respond to the feedback. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a bold assumption in the manuscript regarding the suitability of unsupervised large-scale pretraining for NLP applications, specifically in Section 3.7. It questions the validity of this assumption, noting the lack of understanding regarding how it can be concluded from the proposed evaluation approach. This feedback is somewhat helpful as it highlights a potential weakness in the manuscript's argument and prompts the authors to clarify or justify their stance. However, the comment could be more helpful if it provided specific suggestions or examples on how to address the issue or improve the evaluation approach. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues regarding the related work section. First, it points out that the paper fails to discuss recent related work, including [A], both qualitatively and quantitatively. It also mentions that [A] achieves higher performance on SUN and that DCN [18] is not discussed and misses in Table 3, despite being better than other prior work on CUB. Additionally, it notes that [B] is relevant but not discussed in the context of performance. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include discussions of [A] and DCN [18] in their related work section and possibly discuss [B] in a different context. The action is implicit and somewhat vague, as it does not offer detailed guidance on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2.1\" and \"2.2,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it details the issues with the related work section, including the omission of recent work [A] and [B], and the lack of discussion of DCN [18] in Table 3. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper misses discussions of recent related work, including [A] and DCN [18], which are better than other prior work. The reviewer provides specific references to [A] and [18], allowing the authors to understand the basis of the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how these works are better or why their inclusion would be beneficial. Despite this, the claim is mostly verifiable due to the provision of specific references and the clear identification of the issue.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper could be improved by discussing recent related work, including [A] and DCN [18], both qualitatively and quantitatively. It highlights that these works achieve higher performance on different datasets, which could be relevant to the paper\\'s claims. Additionally, the comment notes that [B] is relevant but not discussed in the context of performance, suggesting that it could be included in a different context. While the comment provides clear areas for improvement, it could be more helpful if it offered suggestions on how to integrate these discussions into the paper or what specific aspects should be highlighted. Overall, the feedback is mostly helpful as it directs the authors to important areas for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the operator should be a Hadamard product between the DAG and Attention, instead of an addition, as depicted in Figure 2. This provides a clear and direct action for the authors to take, which is to correct the operator in the figure. The comment is explicit and concrete, as it specifies exactly what needs to be changed and how to implement the correction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the operator, suggesting that it should be a Hadamard product between the DAG and Attention, instead of an addition. This provides clear guidance on what needs to be revised in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a correction to the operator in Figure 2, recommending that it should be a Hadamard product between the DAG and Attention, instead of an addition. This is a specific suggestion that provides a clear and actionable change to the figure. However, the comment does not provide any reasoning or evidence to support why this change is necessary or beneficial. Without additional context or justification, the claim is somewhat verifiable, as it offers a suggestion but lacks detailed explanation or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the operator used in Figure 2. It recommends that the operator should be a Hadamard product between the DAG and Attention, instead of an addition, which is a clear and direct improvement to the figure. This feedback is valuable as it offers a specific correction that can enhance the clarity and accuracy of the visual representation in the paper. However, the comment could be more helpful if it explained why this change is important or how it affects the overall understanding of the results. Despite this, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path forward. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point provides specific feedback on the authors' response to concerns, particularly regarding the achievement of optimal rates for SOBA under additional smoothness assumptions. It also highlights the need for addressing limitations, such as the non-standard finite sum assumption, which could be anticipated in the abstract. Additionally, it mentions the discrepancy between theoretical and practical updates of SABA, which is briefly mentioned but not fully addressed. While the comment provides detailed feedback on specific aspects of the paper, it does not explicitly instruct the authors on how to address these issues. The feedback is concrete in terms of what needs to be improved, but the lack of explicit guidance makes it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'No.7. 2022. Post authors\u2019 response,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues related to weaknesses 2 and 3, providing clear guidance on what needs to be addressed. The comment is specific in detailing the improvements made in the response, such as achieving optimal rates for SOBA under additional smoothness assumptions, and the limitations that remain, such as the non-standard finite sum assumption and the discrepancy between theoretical and practical updates of SABA. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point consists of a series of observations and suggestions regarding the authors' response to concerns and the limitations of their work. It provides specific examples, such as the achievement of optimal rates for SOBA under additional smoothness assumptions and the need for addressing the non-standard finite sum assumption in the abstract. However, the comment lacks detailed reasoning or references to support the claim that the authors' response is thorough or that the limitations are only partially addressed. While the feedback is specific, it could be strengthened with more detailed justification or examples to fully substantiate the claims. Therefore, the comment is somewhat verifiable, aligning with a score of 3.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific and actionable feedback on the authors' response to concerns and the limitations of their work. It highlights the achievement of optimal rates for SOBA under additional smoothness assumptions, which is a positive aspect of the revision. However, it also points out that the non-standard finite sum assumption is only partially addressed and could be anticipated in the abstract. Additionally, it notes the discrepancy between theoretical and practical updates of SABA, which is briefly mentioned but not fully addressed. The comment is mostly helpful as it identifies specific areas for improvement and provides clear guidance on what the authors need to address to enhance their draft. However, it could be more helpful if it offered suggestions on how to address these issues, such as providing additional examples or references. Overall, the feedback is comprehensive and actionable, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that UnKE\\'s cause-driven optimization preserves pre-trained knowledge during the editing process. It points out that the experiments show UnKE\\'s ability to retain original knowledge is worse than the baseline (MMLU in Table 2 and Src-Acc and Tgt-Acc in Table 3). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or improve their claims. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the claim about UnKE\\'s ability to preserve pre-trained knowledge is contradicted by the experimental results, which show that UnKE\\'s performance is worse than the baseline. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim that the paper\\'s claim about UnKE\\'s ability to preserve pre-trained knowledge is contradicted by the experimental results. The reviewer provides specific references to Tables 2 and 3, which show that UnKE\\'s performance is worse than the baseline. This provides a clear and detailed justification for the claim, making it fully verifiable. The references to specific tables and results offer concrete evidence to support the critique, allowing the authors to effectively address the issue. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a significant discrepancy between the paper's claim and the experimental results. It points out that the claim that UnKE's cause-driven optimization preserves pre-trained knowledge is contradicted by the experimental results, which show that UnKE's performance is worse than the baseline. The comment provides specific references to Tables 2 and 3, allowing the authors to pinpoint the exact areas where the claim is not supported. This feedback is clear and actionable, as it directs the authors to address the discrepancy and potentially revise their claims or experimental setup. However, the comment could be more helpful if it offered suggestions on how to resolve the contradiction or improve the experimental design. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand. However, it does not provide any explicit or implicit actions for the authors to take to improve this explanation. There is no guidance on how to clarify the intention or what specific details should be included. As a result, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the explanation for the intention of BWTP/GLBW, noting that many details are in the appendix, making it difficult to understand. However, it does not specify which part of the paper this explanation is found in, nor does it provide specific details about what is unclear or missing. This lack of grounding makes it difficult for the authors to identify the exact section that needs improvement. The comment is specific in pointing out the issue with the explanation but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the explanation for the intention of BWTP/GLBW is weak and that many details are in the appendix, making it difficult to understand. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and does not provide specific suggestions or guidance on how to address the issue. The authors are left with a general understanding of the problem but without actionable steps to enhance their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly instructs the authors to include a proof that was omitted due to space constraints, either in the revision or as supplementary material. The action is clear and concrete, as it specifies what needs to be done to address the issue. The comment provides a direct and actionable suggestion for improvement, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the omission of a proof due to space constraints. The comment suggests including the proof in the revision, either as supplementary material or possibly within the main paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests including a proof that was omitted due to space constraints. It does not contain any subjective claims, opinions, or suggestions that require verification. Instead, it presents a factual statement about the need to include a proof, which is a logical conclusion based on the space constraints mentioned in the paper. Therefore, the comment is classified as 'No', as it does not contain a claim that requires verification.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that a proof was omitted due to space constraints in Section 3. It provides a clear and actionable suggestion for the authors to include the proof either in the revision or as supplementary material. This feedback is valuable as it helps the authors understand where their draft could be improved and offers a concrete step to address the issue. However, the comment could be more helpful if it provided additional context or guidance on why the proof is important or how it could be integrated into the main paper. Despite this, the feedback is mostly helpful as it directs the authors toward a specific area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing specific experimental results or references would be more effective than simply stating that \"Since the NPPs lack any direct dependence on magnitudes\" is the reason why NPPs perform worse than ETAS. While the comment implies that the authors should include more detailed information, it does not explicitly instruct them to do so or provide specific guidance on what kind of results or references to include. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed experimental results or references. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing specific experimental results or references instead of relying on a general statement about the performance of NPPs compared to ETAS. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or result, making it weakly grounded. The comment is specific in its suggestion to provide more detailed information, but without grounding, the authors may struggle to identify the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing specific experimental results or references would be more effective than relying on a general statement about the performance of NPPs compared to ETAS. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this approach would be more effective. The lack of supporting evidence or justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that providing specific experimental results or references would be more effective than relying on a general statement about the performance of NPPs compared to ETAS. While the comment identifies a potential improvement in the paper, it lacks specificity and does not provide detailed guidance on what kind of results or references would be most beneficial. Without actionable suggestions or examples, the authors may find it challenging to implement the feedback effectively. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the lack of clarity in the implementation details, specifically mentioning Equations 3 and 4, which outline the connectivity patterns between layers. It points out that there is no guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet, as shown in Tables 1, 4, and 5. The reviewer also notes that these details are not included in the Appendix. This feedback implies that the authors should provide more detailed guidance on how to apply the connectivity patterns to complex architectures and ensure that these details are included in the main text or Appendix. While the action is implicit, it is clear and concrete, as the authors know exactly what needs to be done to improve the clarity of the implementation details. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific equations (Equations 3 and 4) and tables (Tables 1, 4, and 5) that are relevant to the discussion. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of guidance on how to apply the connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. Additionally, it notes that these details are not included in the Appendix, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the implementation details are unclear, specifically mentioning Equations 3 and 4, which outline the connectivity patterns between layers. However, the comment does not provide specific examples or detailed reasoning to support why these details are unclear or how they might be improved. The mention of complex architectures like UNet, ResNet, and MobileNet, as shown in Tables 1, 4, and 5, provides some context but does not offer a comprehensive explanation of the issue. Without further elaboration or examples, the claim is somewhat verifiable, as it suggests a potential problem but lacks detailed justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the implementation details in the paper. It points out that Equations 3 and 4, which outline the connectivity patterns between layers, are not accompanied by specific guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet, as shown in Tables 1, 4, and 5. This lack of guidance makes it difficult for readers to understand and replicate the methodology. Additionally, the comment notes that these details are not included in the Appendix, which further complicates the issue. The feedback is clear and actionable, as it highlights a specific area where the authors need to provide more detailed guidance to improve the clarity and reproducibility of their work. However, it could be more helpful if it suggested ways to address these issues or provided examples of how to improve the implementation details. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance the clarity and completeness of their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the calculation of HTER labels relies on automatic scripts and questions whether this approach can be scaled to other annotations like MQM or DA. It implies that the authors should experiment with other languages and annotations to verify the scalability of their method. While the comment implies an action, it does not explicitly instruct the authors to conduct these experiments or provide specific guidance on how to do so. The action is somewhat vague, as it lacks detailed instructions on how to implement the suggested experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the calculation of HTER labels, which relies on automatic scripts. It questions whether this approach can be scaled to other annotations like MQM or DA, suggesting that the authors should experiment with other languages and annotations to verify the scalability. However, the comment does not specify which part of the paper discusses the calculation of HTER labels or how it is currently implemented. This makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in terms of the issue it raises, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the scalability of the HTER label calculation, which relies on automatic scripts, to other annotations like MQM or DA. It suggests that the authors should experiment with other languages and annotations to verify the scalability. However, the comment lacks specific examples or references to support the claim that the current approach is not scalable. While it raises a valid concern, the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the scalability of the HTER label calculation, which relies on automatic scripts. It suggests that the authors should experiment with other languages and annotations to verify the scalability of their method. This feedback is somewhat helpful as it points out a potential area for improvement and provides a direction for further investigation. However, the comment lacks specific guidance on how to conduct these experiments or what languages and annotations to focus on, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks about the dependence of overall performance on $m$ in $G_m$, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this question or what specific aspects of the performance they should consider. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the dependence of overall performance on $m$ in $G_m$, but it does not specify which part of the paper this question pertains to. The authors might infer that it relates to a specific section or discussion on performance metrics, but this inference is not explicit. The comment is specific in its inquiry about the dependence of performance on $m$, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the dependence of overall performance on $m$ in $G_m$. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the dependence of overall performance on the parameter $m$ in the context of $G_m$. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the performance they should consider. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential theory-practice gap in the paper, specifically mentioning that theoretical works on deep learning often do not reflect practice, such as the difficulty in fitting sparse neural nets. It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment implies that the authors should address this gap, it does not provide explicit instructions on how to do so, such as suggesting specific aspects to discuss or how to present the information. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the theory-practice gap. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a potential theory-practice gap in the paper, specifically mentioning that theoretical works on deep learning often do not reflect practice, such as the difficulty in fitting sparse neural nets. It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to comment on the theory-practice gap is specific, as it provides a clear direction for the authors to address the gap. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that theoretical works on deep learning often do not reflect practice, specifically mentioning the difficulty in fitting sparse neural nets, as discussed in a referenced paper. The comment suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the claim is based on a reference to a specific paper, the comment lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the significance of the theory-practice gap and how it relates to their work. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to explore but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential theory-practice gap in the paper, specifically mentioning that theoretical works on deep learning often do not reflect practice, such as the difficulty in fitting sparse neural nets. It suggests that the authors should comment on this gap to help readers understand the key elements that allow Causal-Stonet to learn sparse neural nets. While the comment highlights an important issue, it lacks specific guidance on how the authors should address this gap or what aspects of the theory-practice gap they should discuss. The feedback is somewhat helpful as it points out a potential area for improvement but could be more detailed and actionable to be fully beneficial for the authors.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests several actions for the authors to consider, such as making some tables smaller, relocating them to the Appendix, and possibly reducing the size of certain figures. These suggestions are concrete and provide clear guidance on how the authors can address the issue of dense packing in the manuscript. The comment also indicates that these changes could be made in the camera-ready version if the paper is accepted, giving the authors a specific timeframe and context for implementing these changes. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figures and tables\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the manuscript appears densely packed due to the close positioning of figures and tables to the text, and provides concrete suggestions for addressing this issue, such as making some tables smaller or relocating them to the Appendix. The comment also suggests reducing the size of certain figures. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the manuscript appears densely packed due to the close positioning of figures and tables to the text, which can make the paper seem cluttered and condensed. The reviewer provides a suggestion to make some tables smaller or relocate them to the Appendix, and possibly reduce the size of certain figures. This feedback is based on the observation of the manuscript\\'s layout and suggests a solution to improve readability. However, the comment lacks specific examples or references to support the claim of dense packing, which could make it more challenging for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a logical suggestion but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript\\'s layout, noting that figures and tables are positioned too closely to the text, which can make the paper appear cluttered and condensed. It provides actionable suggestions for addressing this issue, such as making some tables smaller or relocating them to the Appendix, and possibly reducing the size of certain figures. These suggestions are clear and provide the authors with a concrete plan for improving the manuscript\\'s readability and organization. The comment also indicates that these changes could be made in the camera-ready version if the paper is accepted, giving the authors a timeframe and context for implementing these changes. Overall, the feedback is mostly helpful as it offers detailed guidance on how to enhance the manuscript, making it a valuable contribution to the authors\\' efforts to improve their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point consists of two parts. First, it suggests that the ReCPE method proposed in the article is too strategic and lacks a strong theoretical guarantee. This implies that the authors should strengthen the article by providing a more robust theoretical foundation for their method. However, the comment does not provide specific guidance on how to achieve this, such as suggesting additional theoretical frameworks or references to support the method. The second part of the comment is a minor correction regarding the spelling of 'real word' in Note 2 on page 7. While this is a factual correction, it does not offer any actionable advice for improvement. Therefore, the comment is mostly actionable for the first part but not for the second part, resulting in a score of 3.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the ReCPE method and the theoretical guarantee, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the method is too strategic and lacks a strong theoretical guarantee, providing clear guidance on what needs to be addressed. Additionally, the minor comment about the spelling of 'real word' is specific and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point consists of two parts. The first part claims that the ReCPE method is too strategic and lacks a strong theoretical guarantee. This claim is somewhat verifiable as it suggests that the method is lacking in theoretical support, but it does not provide specific examples or references to substantiate this claim. The second part is a minor correction regarding the spelling of 'real word' in Note 2 on page 7, which is factual and does not require verification. Therefore, the overall verifiability of the comment is 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides two pieces of feedback. First, it suggests that the ReCPE method proposed in the article is too strategic and lacks a strong theoretical guarantee. This feedback is somewhat helpful as it identifies a potential weakness in the paper's theoretical foundation, which could be addressed by providing a more robust theoretical framework. However, the comment does not offer specific suggestions or guidance on how to strengthen the theoretical basis, leaving the authors with a general direction but no actionable steps. The second part of the comment is a minor correction regarding the spelling of 'real word' in Note 2 on page 7, which is a factual correction but does not contribute to the overall improvement of the draft. Therefore, the comment is somewhat helpful, as it provides a mix of actionable and non-actionable feedback. However, it could be more helpful with additional guidance on strengthening the theoretical foundation, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the method beyond NLU tasks to generation tasks. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should explore this application or how to address it if they choose to do so. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the method beyond NLU tasks to generation tasks. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about the applicability of the method, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking whether the method can be applied to generation tasks beyond NLU tasks. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which is why it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the method beyond NLU tasks to generation tasks. While it identifies a potential area for exploration, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the method could be adapted for generation tasks. The comment lacks actionable feedback or detailed suggestions, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it highlights an area of interest but does not offer meaningful guidance for the authors to enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that $N_d$ is not defined in the text and suggests that it would be beneficial to clarify that there could be a different number of observations per task. This feedback is clear and direct, providing a specific action for the authors to take: to define $N_d$ and explain the variability in observations per task. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of definition for $N_d$ and the need to clarify that there could be a different number of observations per task. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that $N_d$ is not defined in the text and suggests that it would be beneficial to clarify that there could be a different number of observations per task. This is a factual observation rather than a claim or suggestion, as it does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that $N_d$ is not defined and suggesting that it would be beneficial to clarify that there could be a different number of observations per task. This feedback is clear and actionable, as it points out a potential confusion or lack of clarity in the paper. By addressing this issue, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define $N_d$ or explain the variability in observations per task. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a formatting issue where the appendix is not properly formatted as part of the main paper. It specifies that the PDF provided for the main paper is a 14-page document, implying that the appendix is not included in the main text. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to correct this issue or what steps to follow to ensure the appendix is properly integrated into the main paper. As a result, the authors are left without a clear understanding of what actions are needed to address the problem. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a formatting issue regarding the appendix, specifying that it is not cut from the main paper and providing a reference to a PDF document. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the appendix. The comment is also specific because it clearly identifies the issue with the formatting and provides a reference to the PDF document. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the appendix is not cut from the main paper, referencing a PDF document that is 14 pages long. However, the comment does not provide any additional context, reasoning, or evidence to support why this is a concern or how it affects the paper. Without further explanation or justification, the claim remains unverifiable, as the authors may not understand the significance of the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a formatting issue with the appendix, noting that it is not properly integrated into the main paper. It provides specific information by mentioning that the PDF provided for the main paper is a 14-page document, implying that the appendix is not included. However, the comment does not offer any suggestions or guidance on how to resolve this issue, such as whether the appendix should be included in the main text or how to format it properly. Without actionable advice or detailed feedback, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the main improvement in the proposed model coming from the ternary potential. It suggests that without the ternary potential, the proposed model does not outperform existing models for 2 modalities setup (except HieCoAtt). The reviewer explicitly requests the authors to provide more insight into this observation. This feedback is explicit and concrete, as it clearly identifies what the authors need to address and provides a specific action to take. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed model, noting that the main improvement comes from the ternary potential and that without it, the model does not outperform existing models for 2 modalities setup (except HieCoAtt). The comment provides a clear direction for the authors to address this concern by offering more insight into the results in table 1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main improvement in the proposed model comes from the ternary potential, and without it, the model does not outperform existing models for 2 modalities setup (except HieCoAtt). The reviewer suggests that the authors provide more insight into this observation. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the basis of the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the main improvement in the proposed model, which seems to come from the ternary potential. It highlights that without the ternary potential, the proposed model does not outperform existing models for 2 modalities setup (except HieCoAtt). The comment is clear and actionable, as it explicitly requests the authors to provide more insight into this observation. This feedback is valuable as it guides the authors to address a potential weakness in their model and encourages them to provide additional context or analysis. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how the ternary potential contributes to the model's performance. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include additional information in the tables to facilitate easier assessment of the comparisons. Specifically, it recommends noting which methods use data augmentations, what architecture they employ, and whether they perform episodic or joint training. This feedback is explicit and provides concrete guidance on what additional details should be included to enhance the clarity and comprehensiveness of the tables. The authors are given a clear action to take, which is to add this information, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the tables\" and \"the various comparisons,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what additional information should be included to facilitate easier assessment of the comparisons, such as noting which methods use data augmentations, what architecture they use, and whether they perform episodic or joint training. This provides clear guidance on what needs to be addressed in the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include additional information in the tables to facilitate easier assessment of the comparisons. It specifically recommends noting which methods use data augmentations, what architecture they use, and whether they perform episodic or joint training. This feedback is based on a logical reasoning that the inclusion of such information would enhance the clarity and comprehensiveness of the tables. While the comment does not provide specific examples or references to support the claim, the reasoning is clear and straightforward, making it mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the clarity and comprehensiveness of the tables in the paper. It identifies specific details, such as noting which methods use data augmentations, what architecture they employ, and whether they perform episodic or joint training, that would enhance the readers' ability to assess the comparisons. This feedback is detailed and constructive, offering the authors a straightforward way to improve their draft. By addressing this suggestion, the authors can enhance the transparency and utility of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests that it would be interesting to see how LSH performs on actual state of the art models. Additionally, it questions the relevance of the PTB benchmark, which is a small dataset, and suggests that the hyperpruning method may not perform as well on more recent benchmarks and architectures. While the comment identifies potential issues and suggests further exploration, it does not provide explicit guidance on how the authors should address these concerns or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments or comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests that it would be interesting to see how LSH performs on actual state of the art models and questions the relevance of the PTB benchmark, which is a small dataset. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, results, or discussion sections. This makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its critique, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the claim that hyperpruning methods would beat the state of the art, noting that the architectures used (LSTM and LSH networks) are not state of the art for language modeling. It suggests that it would be interesting to see how LSH performs on actual state of the art models and questions the relevance of the PTB benchmark, which is a small dataset. The comment provides some reasoning by pointing out the lack of state of the art status for the architectures and the potential limitations of the PTB benchmark. However, it lacks specific examples or references to support the claim that LSH would perform better on more recent benchmarks or architectures. This makes the claim somewhat verifiable, as it provides a basis for questioning the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several concerns about the paper's claims and methodology. It questions the relevance of the architectures used (LSTM and LSH networks) for language modeling, suggesting that it would be interesting to see how LSH performs on actual state-of-the-art models. Additionally, it points out the small size of the PTB benchmark and questions whether the hyperpruning method would still perform well on more recent benchmarks and architectures. While the comment identifies potential weaknesses and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance their work. The feedback is somewhat helpful as it prompts the authors to consider broader implications and suggests further experiments, but it could be more actionable with more detailed advice. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more experimental details, including the neural networks and hyperparameters used, should be included in the appendix. This provides a clear and direct action for the authors to take, as it specifies what additional information needs to be added to improve the transparency and reproducibility of the experiments. The suggestion is concrete, as it outlines the exact elements that should be included, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more experimental details, such as the neural networks and hyperparameters used, should be included in the appendix. However, it does not specify which part of the paper these details are currently missing, making it weakly grounded. The comment is specific in its suggestion to include more details, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental details, such as the neural networks and hyperparameters used, should be included in the appendix. However, the comment does not provide any reasoning, examples, or references to support why these details are necessary or how their inclusion would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more experimental details, specifically the neural networks and hyperparameters used, should be included in the appendix. This feedback is clear and actionable, as it provides a specific area for the authors to enhance the transparency and reproducibility of their experimental setup. By including these details, the authors can make their work more accessible to other researchers and facilitate future replication and extension of their findings. However, the comment could be more helpful if it provided examples of how these details could be structured or if it highlighted the potential benefits of including them. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that section 5.1 does not provide useful information regarding why the new model is superior. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the section or what specific information should be included to make it more useful. Without actionable advice or suggestions, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of useful information regarding why the new model is superior. This provides clear guidance on what needs to be addressed in the section, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that section 5.1 does not provide useful information regarding why the new model is superior. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with section 5.1, noting that it does not provide useful information regarding why the new model is superior. This feedback is clear and actionable, as it directs the authors to focus on improving the section to better explain the advantages of the new model. However, the comment could be more helpful if it provided suggestions on how to enhance the section, such as by including specific comparisons or detailed explanations. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. It implies that a comparison between the single-IMP and multi-IMP is necessary to better understand their transferability. However, the comment does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that a comparison is necessary but are not given specific steps on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. It implies that a comparison between the single-IMP and multi-IMP is necessary. However, the comment does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to conduct the comparison. The authors can infer that it relates to the discussion or results sections, but the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact part of the paper needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. It implies that a comparison between the single-IMP and multi-IMP is necessary to better understand their transferability. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the single-IMP might also have transferability, but it is not as strong as the multi-IMP. It implies that a comparison between the single-IMP and multi-IMP is necessary to better understand their transferability. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects should be considered. While it identifies an area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. The authors are given a direction to explore, but the comment could be more comprehensive by offering detailed guidance or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider checking human-factors literature on creating systems that effectively interact with people, implying that there may be ethical concerns related to the proposed methods. However, the comment does not explicitly instruct the authors to identify and address these ethical concerns or provide specific references to relevant literature. The action is implicit and somewhat vague, as the authors are left to infer that they should explore human-factors literature but are not given concrete guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.03. 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the lack of ethical concerns with the proposed methods and provides a detailed explanation of the limitations and practical challenges related to interacting with humans. The comment suggests that the authors should consider human-factors literature, which is a clear and specific direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are no specific ethical concerns with the proposed methods and suggests that the authors should consider human-factors literature. However, the comment does not provide any specific examples or references to support the claim about ethical concerns, nor does it explain why the proposed methods might be ethically concerning. The suggestion to check human-factors literature is a logical one, but without specific examples or references, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a lack of specific ethical concerns with the proposed methods and suggests that the authors should consider human-factors literature to address potential ethical issues related to interacting with humans. While the comment points out a relevant area for improvement, it does not provide specific examples or references to guide the authors in addressing these concerns. The feedback is somewhat helpful as it highlights an important aspect for consideration but lacks depth and actionable guidance, leaving the authors with a general direction to explore without detailed instructions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two points. First, it questions whether the proposed model selection approach scales beyond MNIST-like datasets, suggesting that the experiments should be conducted on more diverse datasets. Second, it recommends comparing the proposed approach with other neural network pruning methods. While the comment implies that the authors should expand their experiments to include more datasets and compare their approach with existing methods, it does not provide explicit instructions on how to implement these suggestions. The actions are implicit and somewhat vague, as the authors need to infer the need for additional experiments and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two points: first, it questions whether the proposed model selection approach scales beyond MNIST-like datasets, and second, it suggests comparing the proposed approach with other neural network pruning methods. However, it does not specify which part of the paper these concerns relate to, such as the experimental section or the methodology section. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestions, as it points out the need for broader experimentation and comparison, but it lacks grounding, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the proposed model selection approach beyond MNIST-like datasets. It also suggests comparing the approach with other neural network pruning methods. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the approach may not scale or that it should be compared with other methods. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the concern and determine how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises two important points. First, it questions the scalability of the proposed model selection approach beyond MNIST-like datasets, suggesting that the authors should conduct experiments on more diverse datasets. This feedback is valuable as it encourages the authors to expand the scope of their experiments and potentially validate the generalizability of their approach. Second, the comment recommends comparing the proposed approach with other neural network pruning methods, which could provide a more comprehensive evaluation of the effectiveness of the model selection approach. While the comment identifies areas for improvement, it does not offer specific guidance on how to conduct these experiments or comparisons, which could be more helpful. Overall, the comment is mostly helpful as it provides clear directions for enhancing the paper's scope and evaluation, but it could be more comprehensive with additional details or suggestions.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several mathematical formulation issues and inconsistencies in the paper, providing specific examples and suggestions for correction. It highlights errors in notation, such as the incorrect use of \"max\" instead of \"max\" in Line 345, and inconsistencies in index notation. Additionally, it points out the presence of an unexplained variable \"x'\" in the hypervolume formula on Line 225 and questions the use of a uniform distribution in Line 819. Each of these comments provides explicit actions for the authors to take, such as correcting the notation and addressing the inconsistencies. The feedback is concrete and actionable, guiding the authors on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, such as \"Line 345,\" \"Line 347,\" \"Line 344,\" \"Line 374,\" \"Line 225,\" and \"Line 819,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with mathematical formulation, such as inconsistencies in notation and the presence of unexplained variables. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies specific mathematical formulation issues and inconsistencies in the paper, providing examples such as the incorrect use of \"max\" instead of \"max\" in Line 345, and inconsistencies in index notation. The reviewer also questions the presence of an unexplained variable \"x'\" in the hypervolume formula on Line 225 and the use of a uniform distribution in Line 819. Each of these claims is supported by specific references to lines in the paper, making the feedback verifiable. The reviewer provides clear reasoning and examples, allowing the authors to understand and address the issues effectively. Therefore, the comment is fully verifiable, aligning with a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies several specific mathematical formulation issues and inconsistencies in the paper, providing detailed examples and suggestions for correction. It highlights errors in notation, such as the incorrect use of \"max\" instead of \"max\" in Line 345, and inconsistencies in index notation, such as the use of \"i\" for both objectives and time steps. Additionally, it points out the presence of an unexplained variable \"x'\" in the hypervolume formula on Line 225 and questions the use of a uniform distribution in Line 819. By providing explicit examples and actionable feedback, the comment helps the authors identify and correct these issues, enhancing the clarity and accuracy of their mathematical formulations. This level of detail and specificity makes the comment highly helpful, as it empowers the authors to significantly improve their draft. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include experiments that demonstrate the effect of using different numbers of particles. While the comment implies that such experiments could help clarify the importance of this choice, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should include such experiments to clarify the importance of the choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be beneficial to include experiments demonstrating the effect of using different numbers of particles. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors may have to infer that it relates to the experimental section or methodology, but this inference is not explicit. The comment is specific in its suggestion to include experiments, but it lacks grounding as it does not specify the exact part of the paper where this information should be added. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include experiments demonstrating the effect of using different numbers of particles. However, it does not provide any specific reasoning or evidence to support why this is important or how it could impact the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the significance of the suggestion. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include experiments demonstrating the effect of using different numbers of particles. This feedback highlights a potential area for improvement in the paper, as it questions the importance of this choice and implies that additional experiments could provide clarity. However, the comment does not provide specific guidance on how to conduct these experiments or what results to expect, which limits its usefulness. While it identifies a relevant aspect for further exploration, the lack of detailed suggestions makes it somewhat helpful, as it prompts the authors to consider additional experiments but does not fully guide them in implementing these changes. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly states that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. This provides a clear and direct action for the authors to take, which is to include a comparison of their methods using the covariance metric. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in identifying the need for a comparison using the covariance metric, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area where this comparison should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it difficult to understand the significance of this claim or how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks depth, namely the comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric. This feedback is clear and actionable, as it directs the authors to include a comparison of their methods using the covariance metric, which could enhance the paper's comprehensiveness and impact. However, the comment could be more helpful if it provided additional context or suggestions on how to effectively incorporate this comparison into the paper. Overall, the comment is mostly helpful as it highlights a critical omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests better explanation for Table 5, asking for clarification on the meaning of A, B, C, and D. It also suggests that there should be an explanation for why positive paths lead to monotonic solutions and under what scenarios. This feedback is clear and provides specific actions for the authors to take, such as adding detailed explanations or clarifications to the table and the text. The comment is explicit and concrete, guiding the authors on exactly what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the need for better explanation of the elements A, B, C, and D in the table, as well as an explanation for why positive paths lead to monotonic solutions and under what scenarios. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests clarification on the elements A, B, C, and D in Table 5 and why positive paths lead to monotonic solutions. However, it does not provide any specific reasoning, examples, or references to support these requests. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely, the need for better explanation of Table 5. It requests clarification on the meaning of the elements A, B, C, and D in the table and why positive paths lead to monotonic solutions. This feedback is clear and actionable, providing the authors with specific areas to focus on for clarification and improvement. However, the comment could be more helpful if it offered suggestions on how to enhance the explanation or provided examples of how to address these issues. Overall, the comment is mostly helpful as it guides the authors toward improving the clarity and understanding of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheap estimation. It also questions the reliability of early predictions of US accuracy as predictors of DS accuracy, referencing Appendix Fig. F6, F7, F8, and F9. While the comment highlights a potential issue and provides a specific example (Appendix Fig. F6, F7, F8, F9), it does not explicitly instruct the authors on how to address this concern or suggest specific actions. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods or provide more detailed explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the prediction of US accuracy and its relation to DS accuracy, as well as the suggestion to explore alternative methods or provide more detailed explanations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the practicality of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheap estimation. It also questions the reliability of early predictions of US accuracy as predictors of DS accuracy, referencing Appendix Fig. F6, F7, F8, and F9. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim about the reliability of early predictions. The mention of Appendix figures provides some context, but the claim remains somewhat verifiable due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a practical concern about the time-consuming nature of obtaining a single US accuracy and suggests the possibility of using a proxy or surrogate method for a cheaper estimation. It also questions the reliability of early predictions of US accuracy as predictors of DS accuracy, referencing specific figures (Appendix Fig. F6, F7, F8, F9). This feedback is somewhat helpful as it identifies a potential issue with the practicality of the current approach and suggests a direction for improvement. However, the comment could be more helpful if it provided specific suggestions or examples of how to implement a proxy or surrogate method or how to address the reliability of early predictions. Overall, the comment offers a starting point for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. This is a clear and direct action that provides the authors with a specific task to perform. The comment also specifies what needs to be addressed, namely, the impact of specific factors, which gives the authors a clear idea of what to focus on. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, it does not specify which part of the paper this recommendation pertains to, such as a particular section or result. The authors can infer that it relates to the discussion or results sections where epsilon sampling is mentioned, but this inference is not explicit. The comment is specific in suggesting the need for ablation studies to isolate factors, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\\'s strong performance. However, the comment does not provide any reasoning, examples, or references to support why such studies are necessary or how they would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct ablation studies to isolate the impact of specific factors contributing to epsilon sampling\\'s strong performance. This is a clear and actionable suggestion that provides the authors with a specific direction for improving their work. By conducting ablation studies, the authors can better understand the contributions of different factors and potentially identify areas for improvement. However, the comment could be more helpful if it provided examples of specific factors to consider or detailed guidance on how to design and execute these studies. Overall, the feedback is mostly helpful as it offers a clear direction for enhancing the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore how the proposed attack performs against the mode connectivity-based defense discussed in the ICLR paper. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions or guidance on how to carry out this task. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to a specific ICLR publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" and mentions a particular finding about the effectiveness of Fine-Tuning in recovering backdoor models. However, it does not specify which part of the paper this information is relevant to, making it weakly grounded. The comment is specific in its suggestion to explore how the proposed attack performs against the mode connectivity-based defense discussed in the ICLR paper. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of Fine-Tuning in recovering backdoor models is limited, especially when insufficient clean data is available. It references a specific ICLR publication to support this claim, providing a logical basis for the assertion. However, the comment could be strengthened by including specific examples or detailed reasoning about the limitations of Fine-Tuning in the context of backdoor recovery. The reference to the ICLR paper adds credibility but does not fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis but lacks comprehensive evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment suggests a specific direction for the authors to explore, which is to investigate how the proposed attack performs against the mode connectivity-based defense discussed in a referenced ICLR paper. This feedback is clear and actionable, as it provides a concrete area for the authors to expand their analysis and potentially strengthen their work. By addressing this suggestion, the authors could enhance the depth and relevance of their study. However, the comment could be more helpful if it included specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the transparency of the claims due to the absence of codes during the review process. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting the inclusion of codes or explaining the reasoning behind their decision. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of transparency in the claims, specifically mentioning the absence of codes during the review process. However, it does not specify which part of the paper this issue is related to, such as a particular section or method. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in terms of the issue it raises, it lacks grounding as it does not provide explicit references to sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' choice of not including the codes during the review process makes the claims less transparent. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a concern about the transparency of the claims due to the absence of codes during the review process. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the transparency of their claims. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it identifies a potential weakness but does not offer meaningful guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that a certain aspect is not necessary, which does not provide any actionable guidance for the authors. The second part encourages the authors to validate their approach in Waymax, which provides more traffic scenarios. This part is somewhat actionable as it gives a specific suggestion for future validation, but it lacks explicit instructions on how to implement this suggestion. The authors are left to infer that they should conduct this validation in Waymax, but the comment does not provide detailed guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment consists of two parts. The first part suggests that a certain aspect is not necessary, which does not provide any specific guidance or context. The second part encourages the authors to validate their approach in Waymax, which provides more traffic scenarios. This part is specific and actionable, as it suggests a future validation in a specific environment. However, the first part lacks grounding, as it does not specify which aspect is unnecessary, making it difficult for the authors to identify the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two parts. The first part suggests that a certain aspect is not necessary, which lacks any supporting evidence or reasoning. The second part encourages the authors to validate their approach in Waymax, which provides more traffic scenarios. This part is somewhat verifiable as it suggests a specific validation environment, but it does not provide detailed reasoning or evidence to support the claim that Waymax is a better choice. The authors are left to infer the potential benefits of using Waymax, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides two pieces of feedback. The first part suggests that a certain aspect is not necessary, which implies that the authors should consider removing it. However, the comment does not specify which aspect is unnecessary or why it is not necessary, leaving the authors without actionable guidance. The second part encourages the authors to validate their approach in Waymax, which provides more traffic scenarios. This suggestion is somewhat helpful as it offers a specific direction for future validation, but it lacks detailed guidance on how to conduct this validation or what aspects to focus on. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks depth and specificity in its feedback.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the technical contribution of the paper, stating that the transformer-based TAPG method has been studied in previous works like RTD-Net (ICCV2021). It highlights the main difference between RTD-Net and the proposed method, which is the consideration of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The reviewer notes that LMA has been proven effective in dance action recognition, suggesting that the use of additional features may not bring significant insights to the community. However, the comment does not provide specific guidance or suggestions on how the authors could improve their contribution or address this critique. The action is implicit and vague, as the authors are left to infer that they need to justify the significance of their work or explore alternative approaches. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the technical contribution of the paper, specifically mentioning the transformer-based TAPG method and its relation to previous works like RTD-Net (ICCV2021). It highlights the main difference between RTD-Net and the proposed method, which is the consideration of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The reviewer notes that LMA has been proven effective in dance action recognition, suggesting that the use of additional features may not bring significant insights to the community. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is not very significant, as the transformer-based TAPG method has been studied in previous works like RTD-Net (ICCV2021). The reviewer highlights that the main difference between RTD-Net and the proposed method lies in the consideration of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). While the reviewer acknowledges the effectiveness of LMA in dance action recognition, they argue that the use of additional features may not bring significant insights to the community. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the technical contribution of the paper, suggesting that the transformer-based TAPG method has been studied in previous works, such as RTD-Net (ICCV2021). It highlights the main difference between RTD-Net and the proposed method, which is the consideration of visual features, 3D pose, and action features obtained by Laban Movement Analysis (LMA). The reviewer acknowledges the effectiveness of LMA in dance action recognition but questions whether the use of additional features brings significant insights to the community. However, the comment lacks specific suggestions or actionable feedback on how the authors could improve their contribution or address this critique. While it identifies a potential weakness, it does not provide detailed guidance or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. While the comment implies that additional experiments are needed, it does not provide specific guidance on which design choices to compare or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct more experimental comparisons, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, the comment does not provide specific examples or references to support the claim that these comparisons are necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion, leaving the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. While this feedback highlights an area for improvement, it lacks specificity and does not provide detailed guidance on which design choices should be compared or how to structure these comparisons. The authors are left with a general suggestion but without actionable steps to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, it does not provide specific guidance on which design choices to compare or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct more experimental comparisons, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, it does not provide specific examples or references to support the claim that these comparisons are necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion, leaving the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. While this feedback highlights an area for improvement, it lacks specificity and does not provide detailed guidance on which design choices to compare or how to structure these comparisons. The authors are left with a general suggestion but without actionable steps to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction. However, it does not provide specific guidance on which design choices to compare or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the implementation of tree construction."}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Table 2 in the paper is incomplete and suggests that the authors should report several baselines that outperform their results, even though their results are slightly weak. This feedback is clear and provides a direct action for the authors to take, which is to include these additional baselines in their table. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Table 2 in the paper,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper hides several baselines that outperform it and suggests reporting them for completeness. This feedback is specific, as it clearly outlines what needs to be addressed in terms of completeness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 2 in the paper is incomplete because it hides several baselines that outperform the results reported in the paper. The reviewer suggests that these baselines should be reported for completeness, even though their results are slightly weak. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to the Re-BART paper, which would strengthen the justification. The authors would need to verify the claim by examining the Re-BART paper and assessing the baselines mentioned. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Table 2 in the paper, noting that it is incomplete and suggesting that the authors should report several baselines that outperform their results, even though their results are slightly weak. This feedback is clear and actionable, as it provides a direct suggestion for improvement by including additional baselines for completeness. By addressing this feedback, the authors can enhance the transparency and robustness of their results. However, the comment could be more helpful if it provided specific examples of the baselines that should be included or further guidance on how to present this information effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluations on real datasets could be more thorough and questions the choice of only three scenes from the HS-ERGB dataset. It asks why other sequences were not considered and encourages the authors to provide more comprehensive evaluations. While the comment implies that the authors should expand their evaluations, it does not explicitly instruct them to do so or provide specific guidance on which sequences to include. The action is implicit and somewhat vague, as the authors need to infer that they should conduct more thorough evaluations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluations on real datasets, specifically questioning the choice of only three scenes from the HS-ERGB dataset and asking why other sequences were not considered. This provides some level of grounding as it refers to a specific aspect of the paper, namely the evaluations on real datasets. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its request for more comprehensive evaluations, as it questions the choice of scenes and suggests considering other sequences. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the thoroughness of the evaluations on real datasets, specifically asking why only three scenes were chosen from the HS-ERGB dataset and suggesting that the performance should be evaluated on other sequences. This comment raises a valid concern about the comprehensiveness of the evaluation, but it lacks specific examples or references to support the claim that only three scenes are insufficient. The suggestion to evaluate on other sequences is a logical extension of the concern, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's evaluation on real datasets, specifically questioning the choice of only three scenes from the HS-ERGB dataset and suggesting that the performance should be evaluated on other sequences. This feedback is somewhat helpful as it points out a gap in the evaluation process and encourages the authors to consider a more comprehensive approach. However, the comment could be more helpful if it provided specific suggestions on which other sequences to include or how to conduct a more thorough evaluation. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it suggests that using 44 bits is too small and recommends using more bits without affecting computation time. Second, it questions the interpretation of bit-embeddings, particularly regarding the prediction of the rank of words and the lack of semantic relations among words with odd ranks. While the comment implies that the authors should consider these issues, it does not provide explicit guidance on how to address them. The actions are implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the use of 44 bits, which is considered too small, and the interpretation of bit-embeddings, particularly the prediction of the rank of words. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the use of 44 bits and the interpretation of bit-embeddings, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two concerns: first, it questions the use of 44 bits as being too small, suggesting that more bits could be used without affecting computation time. Second, it questions the interpretation of bit-embeddings, particularly the prediction of the rank of words, and the lack of semantic relations among words with odd ranks. The reviewer provides a logical reasoning for the first point, suggesting that using more bits would not impact computation time. However, the second point lacks specific examples or references to support the claim about the lack of semantic relations. While the reasoning is logical, the comment could be strengthened with more detailed evidence or examples to fully substantiate the claims. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises two significant concerns regarding the paper's methodology and interpretation. First, it questions the use of 44 bits, suggesting that more bits could be used without affecting computation time, which could be a valuable suggestion for the authors to consider. Second, it challenges the interpretation of bit-embeddings, pointing out that predicting the rank of words implies a specific model behavior that may not align with the authors' intended meaning. This raises an important point about the semantic relations among words, which the authors might need to address. While the comment identifies these issues, it could be more helpful if it provided specific suggestions or examples on how to address them. Overall, the comment is mostly helpful as it prompts the authors to reconsider their methodology and interpretation, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that the authors mention this limitation in the appendix but do not provide a solution for mitigation. While the comment highlights a problem, it does not explicitly instruct the authors to address this issue or suggest specific steps to mitigate it. The action is implicit and somewhat vague, as the authors can infer that they need to provide a solution for mitigation, but the comment does not offer concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, noting that the requirement for human annotation to provide semantically meaningful information can be subjective. It mentions that the authors discuss this limitation in the appendix but do not provide a solution for mitigation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a solution to mitigate the subjective nature of human annotation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires human annotation to provide semantically meaningful information, which can be subjective. This claim is somewhat verifiable as it points out a potential limitation of the method. However, the comment lacks specific examples or references to support the claim that human annotation is subjective, making it difficult for the authors to fully understand and address the issue. The mention of the limitation in the appendix provides some context but does not substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed method, specifically the requirement for human annotation to provide semantically meaningful information, which can be subjective. It notes that the authors mention this limitation in the appendix but do not provide a solution for mitigation. This feedback is somewhat helpful as it highlights a critical area for improvement and points out a potential weakness in the methodology. However, the comment could be more helpful if it suggested possible solutions or strategies for addressing the subjectivity of human annotation. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit actions for the authors to take. It instructs them to \"Pretrain a CausalLM using this dataset (mixed with other datasets used by ObscuraCoder, except obfuscated ObscuraX)\" and \"Compare its performance against ObscuraCoder to conclusively attribute any improvements to the deobfuscation objective.\" These actions are clear and provide concrete steps for the authors to follow, making the comment highly actionable. The authors know exactly what needs to be done to improve their draft, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment provides specific actions for the authors to take, such as pretraining a CausalLM and comparing its performance against ObscuraCoder. However, it does not specify which part of the paper these actions relate to, making it weakly grounded. The comment is specific in detailing what needs to be done to improve the draft, but without grounding, the authors may struggle to identify the exact sections where these actions should be applied. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests pretraining a CausalLM using a specific dataset and comparing its performance against ObscuraCoder to attribute any improvements to the deobfuscation objective. However, the comment does not provide any reasoning, evidence, or references to support why this approach would be effective or how it would help attribute improvements. Without such justification, the claim is difficult for the authors to understand and act upon. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting specific steps for the authors to take to improve their draft. It instructs them to pretrain a CausalLM using a specific dataset and compare its performance against ObscuraCoder. This feedback is valuable as it offers a concrete path for the authors to enhance their work by addressing a potential limitation or area for improvement. However, the comment could be more helpful if it explained why this approach is beneficial or how it would contribute to the overall research question. Despite this, the feedback is mostly helpful as it provides clear guidance for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the loss equation shown in lines 264-266 should have the geometric loss added to the reconstruction loss, rather than itself. This provides a clear and direct action for the authors to take, which is to correct the equation as specified. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L264-L266,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the loss equation, suggesting that the geometric loss should be added to the reconstruction loss rather than itself. This provides clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the loss equation shown in lines 264-266 should have the geometric loss added to the reconstruction loss, rather than itself. This is a factual statement that does not require verification or evidence. It is a direct observation of a potential error in the equation, which the authors can verify by reviewing the equation themselves. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a minor issue with the loss equation presented in the paper, specifically pointing out that the geometric loss should be added to the reconstruction loss, rather than itself. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the accuracy and clarity of their work. By addressing this issue, the authors can enhance the precision of their methodology and potentially strengthen their results. However, the comment could be more helpful if it explained the significance of this correction or provided additional context on why it is important. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method of MLM (Masked Language Modeling) should be employed in autoregressive language models, which are more prevalent in real-world applications. While the comment implies that the authors should consider this, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the autoregressive language models should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the method of MLM (Masked Language Modeling) should be employed in autoregressive language models, which are more prevalent in real-world applications. However, it does not specify which part of the paper discusses or employs MLM, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its suggestion to employ MLM in autoregressive language models, but it lacks grounding as it does not reference specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method of Masked Language Modeling (MLM) should be employed in autoregressive language models, which are more prevalent in real-world applications. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a necessary or beneficial change. Without specific references or detailed explanations, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method of Masked Language Modeling (MLM) should be employed in autoregressive language models, which are more prevalent in real-world applications. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this suggestion or what specific aspects of the autoregressive language models should be addressed. The feedback is somewhat helpful as it points out a potential enhancement, but it does not offer actionable steps or detailed insights, leaving the authors with limited guidance on how to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating. It questions why the proposed idea is better than GAN and suggests that the method section lacks details on how to address the issue of the vanishing gradient and model collapsing. While the comment highlights specific areas for improvement, it does not provide explicit guidance or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should address these issues in the method section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks details on how to avoid the issue of the vanishing gradient and model collapsing. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the method section is relevant, but the lack of explicit references or specific sections makes it difficult to pinpoint the exact areas needing attention. The comment is specific in detailing the issues with the proposed method, but the lack of grounding makes it challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks details on how to address the issue of the vanishing gradient and model collapsing. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of supporting evidence or detailed explanation makes the claim borderline verifiable, as it provides some insight but requires further elaboration to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises concerns about the difficulty of optimizing the GAN and the use of adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the method section lacks details on how to address the issue of the vanishing gradient and model collapsing. While the comment identifies specific areas for improvement, it lacks depth and actionable suggestions. The authors are given a direction to improve their draft by addressing these issues, but the feedback could be more detailed and comprehensive to fully guide the authors in enhancing their work. Therefore, the comment is somewhat helpful, as it provides some insight but could be more beneficial with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind the choice of models for the ablation study, specifically why the ablations are designed on BART and BART+Longformer instead of the original GraphSum model. While the comment raises a valid point about the choice of models, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should explain or justify their choice of models, but it lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of models for the ablation study, specifically why BART and BART+Longformer were used instead of the original GraphSum model. This comment is fully grounded as it explicitly mentions the \"ablation study\" and the specific models being used, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of models and prompts the authors to provide an explanation or justification for their selection. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the choice of models for the ablation study, specifically why BART and BART+Longformer were used instead of the original GraphSum model. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of models for the ablation study, specifically why BART and BART+Longformer were used instead of the original GraphSum model. This question prompts the authors to clarify their rationale for this decision, which could be important for understanding the experimental setup and results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the removal of previous reports of SciBERT, which somewhat exacerbates the earlier problem in the paper where the analyses of the models\\' outcomes were cursory and lacked deeper analyses. However, the comment suggests that it is not fair to write this as a weakness because the current paper does not mention it. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The action is implicit and vague, leaving the authors uncertain about what steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the removal of previous reports of SciBERT and its impact on the earlier problem in the paper where the analyses of the models\\' outcomes were cursory and lacked deeper analyses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem and suggesting that it is not fair to write it as a weakness, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the removal of previous reports of SciBERT somewhat exacerbates the earlier problem in the paper where the analyses of the models\\' outcomes were cursory and lacked deeper analyses. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to the previous reports or detailed explanations of how their removal impacts the analysis. As a result, the claim is not fully verifiable, as it requires additional information or evidence to be substantiated. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the removal of previous reports of SciBERT, which somewhat exacerbates the earlier problem in the paper where the analyses of the models' outcomes were cursory and lacked deeper analyses. However, the comment acknowledges that it is not fair to write this as a weakness because the current paper does not mention it. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or enhance their analysis. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out two issues: the origin of the connectivity graph $\\\\cal{G}_{F}$ and the clarity of the section on the source of patches and how they are mixed. While the comment identifies these areas as unclear, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the origin of the graph and the process of mixing patches, but the comment lacks concrete suggestions or steps on how to achieve this. Therefore, the comment is somewhat actionable, as it highlights areas needing clarification but does not offer detailed guidance on how to improve them.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'Functional connectivity encoder' section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the clarity of the section, particularly regarding the origin of the connectivity graph $\\\\cal{G}_{F}$ and the difficulty in discerning the source of patches and how they are mixed. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the origin of the connectivity graph $\\\\cal{G}_{F}$ and the clarity of the section on the source of patches and how they are mixed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper: the origin of the connectivity graph $\\\\cal{G}_{F}$ and the clarity of the section on the source of patches and how they are mixed. By pointing out these areas of confusion, the comment provides clear and actionable feedback that can help the authors improve the clarity and coherence of their draft. However, the comment could be more helpful if it offered suggestions or examples on how to address these issues, such as recommending specific clarifications or rephrasing. Overall, the comment is mostly helpful as it directs the authors' attention to critical areas needing improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the claim that Figure 4(b) indicates faster training for the proposed method, suggesting that it seems far-fetched given that all networks are trained for the same amount of epochs. It also points out the need for a longer discussion of related work in the pruning field. While the comment identifies specific issues with the claim and suggests a need for further discussion, it does not provide explicit guidance on how to address these concerns or improve the draft. The action is implicit and somewhat vague, as the authors are left to infer that they should provide a more detailed discussion of related work and clarify the claim about faster training. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4(b)\" and \"Pruning,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the claim that Figure 4(b) indicates faster training and suggesting a need for a longer discussion of related work in the pruning field. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the claim that Figure 4(b) indicates faster training for the proposed method, questioning the validity of this claim given that all networks are trained for the same amount of epochs. The reviewer also suggests that the paper would benefit from a longer discussion of related work in the pruning field. While the comment identifies a potential issue with the claim, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for a longer discussion of related work is a logical extension but is not explicitly supported by evidence or references. Therefore, the comment is somewhat verifiable, as it provides a basis for questioning the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the claim that Figure 4(b) indicates faster training for the proposed method, questioning the validity of this claim given that all networks are trained for the same amount of epochs. It also suggests that the paper would benefit from a longer discussion of related work in the pruning field. While the comment highlights a potential weakness in the paper's claims, it does not provide detailed guidance or suggestions on how to address these issues or improve the draft. The feedback is somewhat helpful as it points out a specific area for improvement but lacks depth and actionable advice, leaving the authors with a general direction to consider rather than a clear path forward. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific error in the derivative of the Lagrangian, stating that the derivative of n^{-1/2} is incorrect and should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This provides a clear and direct action for the authors to correct the error in their draft. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the derivative of the Lagrangian, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error in the derivative, identifying that the minus sign is omitted and providing the correct derivative as -1/2n^{-3/2}. This level of detail helps the authors understand what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the derivative of the Lagrangian is incorrect, specifically stating that the derivative of n^{-1/2} is -1/2n^{-3/2} rather than 1/2n^{-3/2}. This claim is fully verifiable as it provides a clear and specific correction, allowing the authors to understand and address the error. The comment is supported by logical reasoning and a precise mathematical correction, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the mathematical derivation of the Lagrangian, pointing out that the derivative of n^{-1/2} is incorrect and should be -1/2n^{-3/2} instead of 1/2n^{-3/2}. This feedback is clear and actionable, providing the authors with a precise correction to make in their draft. By addressing this error, the authors can improve the accuracy and clarity of their work. However, the comment could be more helpful if it explained the significance of this correction or provided additional context on why it is important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing correction, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s introduction is not clear because it lacks background information about cognitive models. It implies that the authors should refine their writing to address this issue. However, the comment does not provide specific guidance on what aspects of the writing need refinement or how to improve the clarity. The action is implicit and somewhat vague, as the authors know they need to improve the writing but are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s introduction is not clear because it lacks background information about cognitive models. However, it does not specify which part of the introduction is unclear or what specific information is missing. The authors can infer that the introduction is being referred to, but the comment lacks specificity in detailing what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not clear due to a lack of background information about cognitive models in the introduction. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a general observation but without sufficient support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s introduction, noting that it lacks background information about cognitive models. This feedback is somewhat helpful as it points out a gap in the paper that needs attention. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their writing. Without actionable advice or detailed feedback, the authors may find it challenging to effectively enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the paper regarding the performance of DFA on the NLP task, which is described as the \"most standard\" task. It suggests that this discrepancy is not sufficiently emphasized in the paper, particularly in the abstract, which gives readers the impression that DFA performs at near-backprop levels on this task. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the paper. The action is implicit and vague, as the authors are left to infer that they need to clarify the performance of DFA on this task. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance of DFA on the NLP task, which is described as the \"most standard\" task. However, it does not specify which part of the paper discusses this task or provides detailed feedback on how the authors should address the discrepancy between DFA and backprop performance. The authors can infer that it relates to the results or discussion sections, but the lack of specific guidance makes it difficult to pinpoint the exact area needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the performance of DFA on the NLP task is substantially lagging behind backprop performance, which is not sufficiently emphasized in the paper. The reviewer provides a logical reasoning by pointing out that the abstract gives readers the impression that DFA performs at near-backprop levels on this task, similar to other tasks. However, the comment lacks specific examples or references to support the claim about the discrepancy in performance. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable, as it provides a basis for the critique but requires further substantiation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy in the paper regarding the performance of DFA on the NLP task, which is described as the 'most standard' task. It points out that the abstract gives readers the impression that DFA performs at near-backprop levels on this task, unlike the other tasks. This feedback is somewhat helpful as it highlights a potential misrepresentation in the paper's presentation. However, the comment could be more helpful if it provided specific suggestions on how the authors could address this issue, such as revising the abstract or providing more detailed results. Overall, the comment provides a starting point for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It specifically mentions SRW and FROT as examples that should be included as baselines. This provides a clear and direct action for the authors to take, which is to include these methods as baselines in their work. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SRW and FROT,\" which are specific methods related to dimensional reduction in optimal transport estimation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the inclusion of these methods as baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation, and suggests including SRW and FROT as baselines. However, the comment does not provide specific reasoning or evidence to support why these methods are essential or how their inclusion would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks a comprehensive baseline, particularly for dimensional reduction methods in optimal transport estimation. It highlights the importance of including methods like SRW and FROT as baselines, which would provide a more robust comparison and evaluation of the proposed methods. This feedback is clear and actionable, as it directs the authors to include specific methods that would enhance the comprehensiveness and validity of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these methods into the paper. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting specific aspects to discuss or how to structure the discussion. Without actionable advice or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a gap in the discussion regarding the advantages and disadvantages of transductive learning, but it does not specify which part of the paper this issue is related to. The authors may infer that it pertains to the discussion section or a specific section where transductive learning is mentioned, but this inference is not explicit. The comment is specific in identifying the absence of a discussion on the advantages and disadvantages of transductive learning, but it lacks grounding as it does not specify the exact location in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a gap in the discussion regarding the advantages and disadvantages of transductive learning. This is a valuable observation as it highlights an area where the paper could be strengthened by providing a more comprehensive analysis. However, the comment lacks specificity and does not offer suggestions on how the authors might address this issue or what aspects of transductive learning should be discussed. Without actionable guidance, the authors may find it challenging to effectively incorporate this feedback into their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide detailed advice on how to improve it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to have the invariance of the contractivity stated formally. While the comment implies that the authors should formalize this aspect, it does not provide explicit instructions or guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they should formalize the invariance of contractivity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the invariance of the contractivity should be stated formally, but it does not specify which part of the paper this issue is related to. The authors may have an idea of where this concept is discussed, but the comment lacks explicit references to sections, tables, or figures. Additionally, the comment does not provide specific details on what needs to be addressed regarding the formalization of the invariance of contractivity. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that it would be beneficial to have the invariance of the contractivity stated formally. However, it does not provide any reasoning, examples, or references to support why this is important or how it could be formalized. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that it would be beneficial to have the invariance of the contractivity stated formally. While this feedback highlights an area for improvement, it lacks specificity and does not provide detailed guidance on how to formalize this aspect. The authors are left to infer that formalizing the invariance of contractivity is important, but the comment does not offer actionable steps or examples to achieve this. As a result, the comment is somewhat helpful, as it identifies a potential area for enhancement but does not fully support the authors in making the necessary improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the potential contribution of uncertainty saliency maps and questions the significance of their application without evaluation. It also expresses disagreement with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their paper. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to respond or what changes to make. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses the potential contribution of uncertainty saliency maps and questions their significance without evaluation. It also expresses disagreement with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses these maps or the evaluation, making it weakly grounded. The authors can infer that it relates to the discussion or results sections, but this is not explicit. The comment is specific in its critique of the claim about trustworthiness, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a claim about the significance of uncertainty saliency maps without evaluation and questions the trustworthiness of uncertainty/confidence generated from the same mechanism as the explanation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or justification makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the potential contribution of uncertainty saliency maps, noting that without evaluation, their significance is unclear. It also questions the trustworthiness of uncertainty/confidence generated from the same mechanism as the explanation, suggesting that the paper may not be suitable for acceptance. While the comment identifies a potential issue with the paper's evaluation and trustworthiness, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it points out areas for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific aspects of the diffusion model they should emphasize. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in questioning the unique contributions of the diffusion model, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the importance of using the diffusion model in style transfer, suggesting that it may offer unique advantages over other methods. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the diffusion model are particularly valuable. While it prompts the authors to consider a critical aspect of their work, the lack of actionable feedback limits its usefulness. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion or comparison in the related work section to enhance understanding of the multi-view\\'s effect. While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and how to structure it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also mentions that the multi-view training is similar to task augmentation meta-learning methods. However, the comment does not specify which part of the paper this discussion or comparison should be included in, nor does it provide detailed guidance on how to conduct the comparison or discussion. The authors can infer that it relates to the related work section, but the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact part of the paper needing revision. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also suggests that the multi-view training is similar to task augmentation meta-learning methods. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also notes that the multi-view training is similar to task augmentation meta-learning methods. The comment implies that a discussion or comparison in the related work section would enhance understanding of the multi-view\\'s effect. However, the comment lacks specific guidance on how to conduct this discussion or comparison, such as which aspects of the related work should be compared or discussed. While it identifies a potential area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should include a discussion or comparison in the related work section to enhance understanding of the multi-view\\'s effect. While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to conduct the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and how to structure it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also mentions that the multi-view training is similar to task augmentation meta-learning methods. However, the comment does not specify which part of the paper this discussion or comparison should be included in, nor does it provide detailed guidance on how to conduct the comparison or discussion. The authors can infer that it relates to the related work section, but the lack of explicit grounding and specificity makes it difficult for them to pinpoint the exact part of the paper needing revision. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the multi-view latent attack enhances the model's meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also suggests that the multi-view training is similar to task augmentation meta-learning methods. However, the comment lacks specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the assertion. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the multi-view latent attack enhances the model\\'s meta generalizability and outperforms other Adversarial Meta-Learning methods in the cross-domain setting. It also notes that the multi-view training is similar to task"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the impact of Age and FaceID features is not studied in the ablation, suggesting that this aspect should be addressed. However, the comment does not provide explicit guidance on how to conduct the ablation or what specific results should be expected. The action is implicit, as the authors need to infer that they should include an ablation study to evaluate the impact of these features, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of study on the impact of Age and FaceID features in the ablation. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the absence of an ablation study on these features, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the impact of Age and FaceID features is not studied in the ablation, suggesting that this aspect should be addressed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the absence of an ablation study to evaluate the impact of Age and FaceID features. This feedback is clear and actionable, as it points out a critical gap in the analysis that the authors should address to strengthen their work. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation study or what specific results to expect. Overall, the comment is mostly helpful as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to move the detailed discussion from the Appendix to the main manuscript, indicating that the current placement of Table 2 and Fig. 5 is problematic. It provides a clear and concrete action for the authors to take, specifying that the values in these elements should be discussed in the main manuscript. This level of detail and specificity makes the comment highly actionable, as it gives the authors a clear path to follow for improving their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the absence of discussion in the main manuscript and suggesting that the detailed discussion should be moved there. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the values in Table 2 and Fig. 5 are not discussed in the main manuscript, questioning their relevance and suggesting they should be moved to the main text. However, the comment does not provide any specific reasoning or evidence to support why these values are not discussed in the main manuscript or why they should be moved there. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim, leaving it unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manuscript regarding the ablation study, noting that Table 2 and Fig. 5 are not mentioned in the main text. It questions the relevance of these elements and suggests moving the detailed discussion from the Appendix to the main manuscript. This feedback is clear and actionable, providing the authors with a specific area to address and a clear direction for improvement. By suggesting a change in the manuscript's structure, the comment helps the authors enhance the clarity and accessibility of their work. Therefore, it is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should conduct more experiments on LLM-related results, such as llama-3-70B and Mistral-7B, in addition to the current experiments on llama2-7B and mt-bench. This feedback is clear and direct, providing the authors with a specific action to take to enhance their experimental results. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the expectation of seeing more LLM-related results, such as llama-3-70B and Mistral-7B, in addition to the current experiments on llama2-7B and mt-bench. This provides clear guidance on what the authors need to include in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should conduct more experiments on LLM-related results, such as llama-3-70B and Mistral-7B, in addition to the current experiments on llama2-7B and mt-bench. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific LLM results are crucial or why they should be included. Without such justification, the claim remains unverifiable, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by pointing out that the paper should include more LLM-related results, specifically mentioning llama-3-70B and Mistral-7B, in addition to the current experiments on llama2-7B and mt-bench. This feedback is specific and constructive, as it guides the authors to expand their experimental scope and potentially enhance the relevance and impact of their work. However, the comment could be more helpful if it provided additional context or reasoning on why these specific LLM results are important or relevant. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the similarity between the proposed \"Depth First Search-based Decision Tree\" (DFSDT) and existing techniques like self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the generalizability of DFSDT to other types of LLMs. While the comment points out potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed \"Depth First Search-based Decision Tree\" (DFSDT) and its relationship to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the generalizability of DFSDT to other types of LLMs. However, the comment does not specify which part of the paper discusses DFSDT or where the comparison to self-consistency + CoT and Tree-of-thoughts is made. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in detailing the issues with DFSDT, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed \"Depth First Search-based Decision Tree\" (DFSDT) is closely related to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the generalizability of DFSDT to other types of LLMs. However, the comment does not provide specific examples or references to support the claim about the relationship to existing techniques or the generalizability issue. This lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concerns raised. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed 'Depth First Search-based Decision Tree' (DFSDT) by pointing out its similarity to existing techniques like self-consistency + CoT and Tree-of-thoughts. It also raises a concern about the generalizability of DFSDT to other types of LLMs, such as LLaMA, GPT, and Claude. This feedback is somewhat helpful as it highlights areas where the proposed method may not be novel or where it might not be applicable to a broader range of models. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve the generalizability of their approach. To be more helpful, the comment could provide more detailed feedback or examples of how to enhance the method's applicability. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of acknowledging contributions and the inappropriateness of proposing an identical method without proper attribution. However, it does not provide explicit guidance on how the authors should address this issue. The comment lacks concrete suggestions or actions for the authors to take, such as recommending specific ways to acknowledge contributions or how to avoid claiming originality for an existing method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of proper attribution and acknowledges the importance of citing contributions, particularly in the context of ArXiv papers. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what needs to be addressed in terms of attribution or originality claims. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is inappropriate to propose an identical method without proper attribution, particularly in the context of ArXiv papers. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a critical issue regarding the proper attribution of contributions, particularly in the context of ArXiv papers. It emphasizes the importance of acknowledging others' work and the inappropriateness of claiming originality for an existing method. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as providing examples of how to properly cite or acknowledge contributions. While it identifies a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance of MMV compared to XDC, specifically why MMV shows better performance than XDC despite not exceeding its fully-supervised pertaining baseline. It also asks if MMV's better performance is due to a better backbone architecture. While the comment implies that the authors should provide an explanation for these observations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this question in their response. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific comparison between XDC and MMV, mentioning their performance relative to their fully-supervised pertaining baselines. It raises a question about why MMV shows better performance than XDC despite not exceeding its own baseline. However, the comment does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this is not explicit. The comment is specific in detailing the issue of performance comparison and the question about the better backbone architecture, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point presents a comparison between the performance of XDC and MMV, noting that XDC outperforms its R(2+1)D-18 fully-supervised baseline, while MMV does not exceed its own fully-supervised baseline. It then states that MMV shows better performance than XDC. The comment raises a question about why this is the case and whether MMV's better performance is due to a better backbone architecture. While the comment highlights a discrepancy in performance, it lacks specific reasoning or evidence to support the claim that MMV is better due to a better backbone architecture. The authors are prompted to provide an explanation, but the comment does not offer a clear path for the authors to address this question. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks detailed justification or references to support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the performance comparison between XDC and MMV, specifically why MMV shows better performance than XDC despite not exceeding its own fully-supervised baseline. It also asks if MMV's better performance is due to a better backbone architecture. This feedback is somewhat helpful as it prompts the authors to provide an explanation for the observed performance differences, which could be valuable for clarifying the results and understanding the strengths of their methods. However, the comment could be more helpful if it suggested specific areas for further analysis or detailed guidance on how to address the question. Overall, the comment provides a starting point for the authors to consider, but it lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the writing is too verbose and hard to follow, and it identifies this as the paper\\'s biggest weakness. The reviewer recommends focusing on a main idea or two and providing analyses to demonstrate why they work, rather than presenting a well-engineered system with many functions and considerations. This feedback is clear and provides a concrete action for the authors to take, such as revising the writing to be more concise and focused. The suggestion is specific and actionable, giving the authors a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment critiques the writing style, stating that it is too verbose and hard to follow, and suggests that the paper resembles an implementation paper rather than a theoretical or general advancement. It also recommends focusing on a main idea or two and providing analyses to demonstrate their effectiveness. However, the comment does not specify which sections or parts of the paper are too verbose or lack theoretical depth, making it weakly grounded. The feedback is specific in its critique of the writing style and suggests a direction for improvement, but without explicit references to sections, the authors may struggle to pinpoint where to make changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the writing is too verbose and hard to follow, suggesting that the paper resembles an implementation paper rather than a theoretical or general advancement. The reviewer recommends focusing on a main idea or two and providing analyses to demonstrate their effectiveness. While the comment provides a logical reasoning for the critique, it lacks specific examples or references to support the claim that the paper is too implementation-focused. This makes the claim somewhat verifiable, as the authors would need to infer the exact issues from the general critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s writing, noting that it is too verbose and hard to follow, resembling an implementation paper rather than a theoretical or general advancement. The reviewer suggests focusing on a main idea or two and providing analyses to demonstrate their effectiveness, rather than presenting a well-engineered system with many functions and considerations. This feedback is clear and actionable, offering a specific direction for the authors to improve the clarity and focus of their writing. By addressing this feedback, the authors can enhance the readability and impact of their paper. Therefore, the comment is rated as highly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks the provision of code and supplementary documentation, which would enhance clarity and reproducibility. It suggests that providing these resources would be beneficial for readers to understand and replicate the methodology. This feedback is clear and direct, giving the authors a specific action to take: to include code and supplementary documentation. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the lack of code and supplementary documentation in the paper, which could enhance clarity and reproducibility. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in suggesting that providing these resources would be beneficial, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks code and supplementary documentation, which could enhance clarity and reproducibility. However, the comment does not provide any specific examples or reasoning to support why this is a significant issue or how it affects the paper\\'s clarity or reproducibility. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, namely the lack of code and supplementary documentation, which could significantly enhance clarity and reproducibility. It provides a clear and actionable suggestion by recommending that the authors include these resources to facilitate understanding and replication of the methodology. This feedback is valuable as it highlights a specific area for improvement that could greatly benefit the paper. However, the comment could be more helpful if it offered additional guidance on how to structure or present the code and documentation. Overall, the comment is mostly helpful as it directs the authors to a significant area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss ensembles and uncertainty estimation in the context of offline RL, referencing a previous study on discrete Atari games. It also recommends empirically comparing the proposed method to random ensembles (REM) to incorporate value uncertainty in offline RL. While the comment explicitly states these actions, it does not provide specific guidance on how to implement these comparisons or which aspects of the method should be emphasized. The authors are given a clear direction but lack detailed instructions on execution, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and references a specific study on offline RL in the context of discrete Atari games. This provides clear guidance on which part of the paper should be addressed, making it easy for the authors to identify the relevant sections. The comment is also specific because it suggests discussing ensembles and uncertainty estimation in the paper and empirically comparing the proposed method to random ensembles (REM) to incorporate value uncertainty in offline RL. This provides clear direction on what needs to be addressed and how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ensembles have been studied before in the context of offline RL, specifically on discrete Atari games, and that random ensembles (REM) significantly outperform DQN/naive ensembling in the offline setting. The reviewer suggests that this should be discussed in the paper and empirically compared to the proposed method. While the comment references a previous study, it does not provide specific details or examples of the study or the empirical comparison, making it somewhat verifiable. The authors would need to conduct additional research or refer to the cited study to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a relevant area for discussion and comparison in the paper, specifically ensembles and uncertainty estimation in the context of offline RL. It references a previous study on discrete Atari games that found random ensembles (REM) to be more effective than DQN/naive ensembling in the offline setting. The comment suggests that this topic should be discussed and empirically compared to the proposed method, which is a valuable suggestion for incorporating value uncertainty. However, the comment could be more helpful if it provided specific guidance on how to integrate this discussion or comparison into the paper. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement but lacks detailed instructions for implementation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the combination of two methods lacks novelty, based on the author\\'s statements in the introduction and the proposed methodology. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the novelty of their work. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance the novelty of their methods. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the impression that the two methods have been cleverly combined together, lacking novelty. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the combination of two methods lacks novelty, based on the author\\'s statements in the introduction and the proposed methodology. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed methodology, suggesting that the combination of two methods lacks originality. However, it does not provide specific examples or detailed feedback on how the authors might address this concern or enhance the novelty of their work. The comment lacks actionable guidance or suggestions, leaving the authors with a general impression of a potential issue but no clear path forward. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the proposed approach, specifically noting that it appears that a different model needs to be fine-tuned for each target language. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this scalability issue or suggestions for alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the proposed approach, specifically noting that it seems that a different model needs to be fine-tuned for each target language. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in questioning the scalability of the approach, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scalability of the proposed approach, specifically noting that it seems that a different model needs to be fine-tuned for each target language. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the scalability of the proposed approach, specifically noting that it appears that a different model needs to be fine-tuned for each target language. This is a valid concern that could impact the practicality and efficiency of the approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the scalability of their approach. Without actionable feedback or additional context, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential weakness but lacks actionable advice.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details should be provided in Eq.20 for readers unfamiliar with bAbI or question answering. It specifically asks for clarification on what \"valid words\" mean in the context of possible answer words for the given story and question. While the comment implies that more explanation is needed, it does not explicitly instruct the authors to provide this additional detail. The action is somewhat implicit, as the authors can infer that more explanation is necessary, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.20,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing more details for readers unfamiliar with bAbI or question answering, and clarifying the meaning of \"valid words\" in the context of possible answer words for the given story and question. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details should be provided in Eq.20 for readers unfamiliar with bAbI or question answering, specifically regarding the meaning of \"valid words.\" While the comment implies that additional explanation is needed, it does not provide specific examples or references to support this claim. The suggestion is based on a logical assumption that readers might need clarification, but without detailed reasoning or evidence, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more details for readers unfamiliar with bAbI or question answering. It highlights the need for clarification on the meaning of \"valid words\" in the context of possible answer words for the given story and question. This feedback is clear and actionable, as it directs the authors to enhance the clarity of their explanation, which is beneficial for improving the accessibility and understanding of the paper. However, the comment could be more helpful if it provided specific suggestions on how to improve the explanation or examples of how to clarify the concept. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the interested-region-based adversarial attacking is not a novel idea, referencing an earlier work by Yao et al. This comment provides a specific reference to an existing work, \"Trust Region Based Adversarial Attack on Neural Networks,\" which CVPR 2019. However, it does not offer any guidance or suggestions on how the authors might address this issue or incorporate this information into their paper. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim that the interested-region-based adversarial attacking is not a novel idea, referencing an earlier work by Yao et al. This is a specific and concrete reference that provides a clear basis for the comment. However, it does not specify which part of the paper this critique pertains to, such as a section or a particular discussion. The authors can infer that it relates to the methodology or related work section, but this inference is not explicit. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the interested-region-based adversarial attacking is not a novel idea, referencing an earlier work by Yao et al. This claim is supported by a specific reference to a previous publication, \"Trust Region Based Adversarial Attack on Neural Networks,\" which CVPR 2019. This provides a clear and verifiable basis for the claim, allowing the authors to understand the critique and potentially address it in their work. Therefore, the comment is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the interested-region-based adversarial attacking method, referencing an earlier work by Yao et al. This provides a specific and actionable piece of feedback, allowing the authors to understand that their approach may not be entirely novel and to consider whether they need to emphasize other aspects of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue, such as how to differentiate their work from the referenced paper or what aspects of the method are truly novel. Overall, the comment is somewhat helpful as it highlights a potential weakness but lacks depth and specific guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the significance of their contribution. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not specify which components are being referred to or how they contribute to the overall contribution of the paper. This lack of specificity makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, the comment does not provide any guidance on how to address the issue or improve the contribution. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how it affects the significance of their contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the proposed methods are comprised of well-known effective components, implying that the contribution of the paper may not be significant. However, it does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions on how the authors might address this concern or enhance the significance of their contribution. Without actionable feedback or detailed guidance, the comment lacks the depth and specificity needed to be helpful for the authors. Therefore, it is rated as barely helpful, as it provides a starting point for the authors to consider but does not fully support their efforts to improve the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential issue with the dataset, specifically mentioning that the test set includes multi-turn data and that the publicly available history conversation provides some assistance in answering the final question. This suggests that there is a risk of data leakage in the dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to mitigate the risk of data leakage. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly redesign the dataset to eliminate this risk. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the dataset, mentioning that the test set includes multi-turn data and that the publicly available history conversation provides some assistance in answering the final question. This suggests a potential risk of data leakage. However, the comment does not specify which part of the paper discusses the dataset or the risk of data leakage, making it weakly grounded. The comment is specific in detailing the issue with the dataset, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the test set includes multi-turn data and that the publicly available history conversation provides some assistance in answering the final question, which could lead to a risk of data leakage in the dataset. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to specific parts of the paper or detailed explanations of how this issue might affect the dataset's integrity. As a result, the claim is somewhat verifiable, as it provides a general observation but lacks the necessary evidence or context to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the dataset, specifically noting that the test set includes multi-turn data and that the publicly available history conversation provides some assistance in answering the final question. This suggests a risk of data leakage in the dataset. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or mitigate the risk of data leakage. While it highlights an important concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the paper applies TTUR, as proposed by DMD2 (Yin et al. 2024a), and suggests that a comparison with VSD + TTUR would be more convincing. While the comment implies that the authors should consider including such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison to strengthen their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the paper applies TTUR, as proposed by DMD2 (Yin et al. 2024a), and suggests that a comparison with VSD + TTUR would be more convincing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the application of TTUR, as proposed by DMD2 (Yin et al. 2024a), in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that TTUR improves performance or why a comparison with VSD + TTUR would be more convincing. Without additional justification or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the application of TTUR, as proposed by DMD2 (Yin et al. 2024a), in Figure 7. It suggests that a comparison with VSD + TTUR would be more convincing, implying that the authors should consider including such a comparison to strengthen their work. While the comment identifies a potential area for improvement, it lacks detailed guidance or suggestions on how to conduct this comparison or what specific aspects should be evaluated. The feedback is somewhat helpful as it points out a potential enhancement but could be more comprehensive with additional details or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. It asks why the theoretical result is relevant given the apparent contradiction in the definition of OOD actions. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify the theoretical result. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 109\" and \"Assumption 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the relevance of the theoretical result given the apparent contradiction in the definition of OOD actions and the assumption made in Assumption 3.1. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. The reviewer points out a potential contradiction in the definition of OOD actions and questions the relevance of the theoretical result given this assumption. However, the comment lacks specific examples or detailed reasoning to support the claim that the theoretical result is not relevant. The authors are left to infer the significance of this issue, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the theoretical result presented in the paper, specifically regarding the definition of OOD actions and the assumption made in Assumption 3.1. It points out a potential contradiction in the definition of OOD actions, questioning the relevance of the theoretical result given this assumption. This feedback is valuable as it highlights a significant gap in the paper's theoretical framework, prompting the authors to reconsider their assumptions and potentially revise their results. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered alternative approaches to clarify the theoretical result. Overall, the comment is mostly helpful as it identifies a critical area for improvement but lacks detailed guidance on how to resolve the issue. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit action for the authors to take. It suggests that the shallow linguistic dataset analysis should be moved to the appendix if it does not enhance the paper\\'s value or clarity. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is concrete and provides a direct path for the authors to improve their draft by making specific changes to the structure and content of their paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of a shallow linguistic dataset analysis, suggesting that it lacks clear takeaways or conclusions. It also recommends moving the analysis to the appendix if it does not enhance the paper\\'s value or clarity, and suggests integrating essential details from the appendix into the main text. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the analysis section. The feedback is specific in detailing what needs to be addressed, such as the lack of clear takeaways and the integration of essential details. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s linguistic dataset analysis is shallow and lacks clear takeaways or conclusions. It suggests that the analysis might be better suited for the appendix if it does not enhance the paper\\'s value or clarity. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the analysis being shallow. This makes the claim somewhat verifiable, as it provides a general rationale but could benefit from more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s linguistic dataset analysis, noting that it lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\\'s value or clarity, it might be better suited for the appendix. Additionally, it recommends integrating essential details from the appendix, such as dataset splitting justifications, into the main text. This feedback is clear and actionable, providing the authors with a specific direction for improving the structure and content of their paper. By addressing these points, the authors can enhance the clarity and value of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the experimental results: the lack of clarity in the metric of Table 1 and the absence of details regarding the backbone choice, learning rate, and optimization schedules. While the comment points out these gaps, it does not provide explicit instructions on how to address them. The authors are left to infer that they need to clarify the metric in Table 1 and provide the missing experimental details. However, the comment lacks concrete guidance on how to implement these changes, making the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by noting the lack of clarity in the metric and the absence of details regarding the backbone choice, learning rate, and optimization schedules. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the metric of Table 1 is not clearly stated and that the experimental details like backbone choice, learning rate, and optimization schedules are missing. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed justification or evidence makes the claim somewhat verifiable, as it requires the authors to infer the nature of the problems. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the experimental results: the lack of clarity in the metric of Table 1 and the absence of details regarding the backbone choice, learning rate, and optimization schedules. This feedback is clear and actionable, as it points out areas where the authors need to provide more information to make their results more comprehensible and reproducible. By addressing these issues, the authors can enhance the clarity and robustness of their experimental setup, which is crucial for the credibility of their findings. However, the comment could be more helpful if it offered suggestions on how to clarify the metric or provide the missing details. Overall, the comment is mostly helpful as it directs the authors to improve their draft by addressing specific gaps in the experimental section.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper\\'s approach, specifically noting that the advantage of POMDPs, which assumes the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. While the comment identifies a gap in the paper\\'s discussion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the impact of previous decisions on observable data. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"POMDPs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the paper\\'s discussion of POMDPs, specifically noting that the advantage of not directly observing the target variable Y is not leveraged. The comment specifies what needs to be addressed, namely, the lack of discussion on how previous decisions affect observable data. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not leverage the advantage of POMDPs, which assumes that the decision-maker does not directly observe the target variable Y. The comment suggests that the paper does not discuss how previous decisions change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. While the comment identifies a potential issue, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact points the reviewer is addressing, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's approach by pointing out that the advantage of POMDPs, which assumes the decision-maker does not directly observe the target variable Y, is not leveraged. It suggests that the paper does not discuss how previous decisions might change the data observable to the decision-maker, as only outcomes are observed when the positive decision is given. This feedback is somewhat helpful as it highlights a gap in the paper's discussion and provides a specific area for improvement. However, it could be more helpful if it offered suggestions on how the authors might address this issue or provide examples of how to incorporate this discussion into the paper. Overall, the comment is somewhat helpful, as it directs the authors' attention to an important aspect that needs further exploration.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of pretraining tokens_per_sample (256) is small and questions whether it is sufficient for a regular-size program. It also questions the use of batch_size=64 for pretraining. While the comment identifies potential issues, it does not provide explicit guidance on how to address these concerns. The authors are left to infer that they should consider increasing the number of tokens_per_sample or adjusting the batch_size, but the comment lacks concrete suggestions or detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the small number of pretraining tokens_per_sample (256) and questions whether it is sufficient for a regular-size program. It also questions the use of batch_size=64 for pretraining. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the pretraining section, but this inference is not explicit. The comment is specific in detailing the concerns about the token size and batch size, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of pretraining tokens_per_sample (256) is extremely small and questions whether it is enough for a regular-size program. It also questions the use of batch_size=64 for pretraining. However, the comment lacks specific reasoning or evidence to support these claims, such as references to industry standards or comparable studies. Without detailed justification or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the pretraining process, noting that the tokens_per_sample is extremely small (256) and questioning whether it is sufficient for a regular-size program. It also questions the use of batch_size=64 for pretraining. While the comment highlights a potential weakness in the methodology, it does not provide detailed guidance or suggestions on how to address these concerns. The authors are left to infer that they should consider increasing the number of tokens_per_sample or adjusting the batch_size, but the comment lacks actionable advice or specific recommendations. Therefore, the feedback is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making the necessary changes. This aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the work lacks enough ablation experiments to help readers understand the proposed method. It provides a specific suggestion by asking if the clustering algorithm can be replaced with other approaches, such as K-Means, and how the model performs when applied to different-sized descendant models. This feedback is clear and concrete, giving the authors a direct action to take in terms of conducting additional ablation experiments. The comment provides specific examples of what could be explored, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ablation experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by questioning the use of the clustering algorithm and asking how the model performs when applied to different-sized descendant models. This provides a clear direction for the authors to enhance their work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the work lacks enough ablation experiments to help readers understand the proposed method. It provides a specific suggestion by asking if the clustering algorithm can be replaced with other approaches, such as K-Means, and how the model performs when applied to different-sized descendant models. This provides a clear rationale for the claim, as it highlights a potential area for improvement in the paper. However, the comment could be strengthened by providing more detailed examples or references to support the suggestion. Therefore, the comment is mostly verifiable, as it offers a logical basis for the claim but lacks full detail.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by noting the lack of ablation experiments, which could help readers understand the proposed method. It provides a specific suggestion by asking if the clustering algorithm can be replaced with other approaches, such as K-Means, and how the model performs when applied to different-sized descendant models. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their work. By addressing this suggestion, the authors can improve the comprehensiveness and robustness of their study. Therefore, the comment is highly helpful, as it provides valuable insights and actionable steps for improvement.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a comparison with the Talking Heads Transformer as the de-facto baseline for all tasks, rather than just comparing it in Table 1. The reviewer implies that this would provide a clearer understanding of the benefits of the proposed interaction modules and many-to-many formulation compared to a simpler linear transform approach. While the action is explicit, the comment does not provide detailed guidance on how to implement this comparison or which specific tasks should be included. The authors are given a clear direction but may need additional information to fully execute the suggestion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and references the \"vanilla transformer,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the comparison with the Talking Heads Transformer should be expanded to all tasks, not just those in Table 1, to better gauge the benefits of the proposed interaction modules and many-to-many formulation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Talking Heads Transformer should be the de-facto baseline for all tasks, implying that it is a widely accepted standard. The reviewer provides a rationale by noting that the comparison with the Talking Heads Transformer is currently limited to Table 1, and it would be beneficial to include this comparison for all tasks. This reasoning is logical and provides a clear justification for the claim, making the comment mostly verifiable. However, it could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a relevant baseline, the Talking Heads Transformer, and suggests that it should be used as the de-facto baseline for all tasks in the paper. This is a constructive suggestion as it provides a clear benchmark for evaluating the proposed interaction modules and many-to-many formulation. The comment also highlights the current limitation of the comparison, which is only included in Table 1, and suggests that a more comprehensive comparison would be beneficial. This feedback is actionable and provides a clear direction for improving the paper's evaluation and understanding of the proposed method's benefits. However, the comment could be more helpful if it offered specific guidance on how to implement this comparison or which tasks should be included. Overall, the comment is mostly helpful, as it effectively identifies an area for improvement and offers a clear suggestion for enhancement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should check the scenario and benchmark at least speaker identification on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. While the comment implies that the authors should verify the scenario and perform a benchmark, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to check the scenario and perform a benchmark, but the comment lacks specific guidance on how to carry out these actions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests checking the scenario and benchmarking speaker identification on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to check the scenario and benchmark speaker identification, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests checking the scenario and benchmarking speaker identification on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. However, the comment does not provide any justification or reasoning for why this is necessary or how it would improve the paper. It lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should check the scenario and benchmark at least speaker identification on the HI-MIA dataset, which is recorded in the real-time environment with noise setup and microphone array. This feedback is somewhat helpful as it provides a specific suggestion for improvement by recommending a benchmarking exercise on a relevant dataset. However, the comment lacks detailed guidance on how to conduct this benchmarking or what specific aspects to focus on, which limits its usefulness. The authors are given a direction for improvement but would benefit from more detailed instructions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit suggestion for the authors to reconsider the framing of their paper. It suggests that the paper should focus on the loss function and its applications rather than being centered around breast cancer. The comment is concrete, as it specifies the change needed in the framing and provides a rationale for why this alternative framing might be more appropriate. This level of detail and directness makes the action clear and actionable for the authors. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Introduction\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to reconsider the framing of the paper, focusing on the loss function and its applications rather than being centered around breast cancer. The comment specifies what needs to be addressed, which is a change in the framing to better align with the primary contribution of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper\\'s framing should be reconsidered, focusing on the loss function and its applications rather than being centered around breast cancer. The reviewer provides a rationale for this suggestion by noting that the paper evaluates the loss function over multiple datasets, including breast cancer and others, and that the primary contribution is a loss function applicable to any semantic segmentation network. The reviewer also mentions the paper\\'s ability to handle distribution shifts, which further supports the suggestion. However, the comment could be strengthened by providing specific examples or references to similar works that might justify this alternative framing. Overall, the comment is mostly verifiable as it offers a logical argument but lacks detailed examples or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to reconsider the framing of their paper. It identifies a potential misalignment between the focus of the introduction and the broader scope of the paper, which is centered around a loss function applicable to any semantic segmentation network. The comment offers a rationale for why an alternative framing that emphasizes the loss function and its applications might be more appropriate. This feedback is specific and actionable, as it guides the authors on how to better align their paper\\'s framing with its primary contribution. However, the comment could be more helpful if it provided additional guidance on how to reframe the introduction or suggested specific examples of how the loss function could be applied to other problems in semantic segmentation. Despite this, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. This is a clear and direct action for the authors to take, as it specifies which sections to address and what information to include. The request is concrete, as it provides a specific task and context for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 3.1 or 3.2,\" providing full grounding as the authors can accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of agreement statistics for the corpus. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for the inclusion of agreement statistics for the corpus in sections 3.1 or 3.2. It does not contain any claims, opinions, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, requesting the inclusion of agreement statistics for the corpus in sections 3.1 or 3.2. This feedback provides a specific and direct suggestion for improvement, which is valuable for the authors as it helps them identify a gap in their current draft. By addressing this request, the authors can enhance the completeness and transparency of their work. However, the comment could be more helpful if it provided additional context or guidance on why these statistics are important or how they should be presented. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but it also points out that existing LLMs are being used. It notes that the use of consecutive sub-trajectories is straightforward and highlights the novelty of cross-trajectory chaining, which is inspired by goal-conditioned RL approaches. However, the comment does not provide specific guidance or suggestions on how the authors might enhance the novelty or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, specifically focusing on the use of instruction aggregation and LLMs, as well as the novelty of cross-trajectory chaining. It mentions existing LLMs and references goal-conditioned RL approaches, such as offline goal chaining [Chebotar et al., 2021]. However, the comment does not explicitly mention which part of the paper this discussion pertains to, making it weakly grounded. The authors can infer that it relates to the novelty section or the methods section, but this is not clear. The comment is specific in detailing the novelty of the approaches and their relation to existing work, but it lacks explicit grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of using instruction aggregation and LLMs, but it also points out that existing LLMs are being used. It notes that the use of consecutive sub-trajectories is straightforward and highlights the novelty of cross-trajectory chaining, which is inspired by goal-conditioned RL approaches. However, the comment does not provide specific examples or detailed reasoning to support the claim that the use of existing LLMs diminishes the novelty of the approach. The mention of goal-conditioned RL approaches and offline goal chaining provides some context, but the comment lacks detailed justification or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the novelty of using instruction aggregation and LLMs, but it also points out that existing LLMs are being used, which may diminish the novelty of the approach. It highlights the straightforward nature of using consecutive sub-trajectories and notes the novelty of cross-trajectory chaining, which is inspired by goal-conditioned RL approaches. However, the comment lacks specific suggestions or guidance on how the authors might enhance the novelty or improve their work. While it identifies areas for potential improvement, it does not provide actionable feedback or detailed advice, leaving the authors without a clear path to follow. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It also suggests that more discussion should be conducted on this topic. While the comment identifies an area for improvement, it does not provide explicit guidance on how to address this issue or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more discussion on the topic, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It also suggests that more discussion should be conducted on this topic. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the attention module, but the lack of specific guidance on where to address this issue makes it difficult to pinpoint. The comment is specific in questioning the identity of the attention map and suggesting more discussion, but without full grounding, it is challenging for the authors to fully address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It suggests that more discussion should be conducted on this topic. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the identity of the attention map and its impact on the expressive power of the attention module. It also suggests that more discussion should be conducted on this topic. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to address the issue or what aspects of the attention module should be discussed. The authors are left with a general suggestion to conduct more discussion, but without actionable steps or examples, the feedback is somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests an explanation for why the authors are considering decoder-only transformers. This is a clear and direct action for the authors to take, as it provides a specific question that needs to be addressed in the draft. The comment does not require any inference or interpretation, making it explicit and concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly requests an explanation for why the authors are considering decoder-only transformers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to explain their choice of using decoder-only transformers. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, requesting an explanation for the choice of using decoder-only transformers. This feedback is valuable as it prompts the authors to justify their decision, which could be crucial for understanding the methodology and its implications. However, the comment does not provide specific guidance on how to address this issue or what aspects of the choice should be explained. While it identifies a gap in the draft, it lacks depth and could be more helpful with additional suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the qualitative analysis is missing important details, specifically the proportion of each error category. It also implies that the paper could be strengthened by including more detailed thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. While the comment identifies areas for improvement, it does not provide explicit guidance on how to incorporate these suggestions or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the qualitative analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing details, such as the proportion of each error category, and suggests that the contribution could be strengthened by including more detailed thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment also references a specific work, \"Turpin et al. Language Models Don\\'t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,\" which provides an example of a similar analysis. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the qualitative analysis is missing important details, specifically the proportion of each error category, and suggests that the contribution could be strengthened by including more detailed thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment provides a reference to a specific work, \"Turpin et al. Language Models Don\\'t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,\" which could be used as a basis for comparison. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. The addition of specific examples or detailed reasoning would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper's qualitative analysis, noting that it lacks details such as the proportion of each error category. It suggests that the contribution could be strengthened by including more detailed thoughts or speculations about the underlying causes of the observed issues and potential ways to mitigate them. The comment provides a reference to a relevant work, 'Turpin et al. Language Models Don\\'t Always Say What They Think: Unfaithful Explanations in Chain-of-Thought Prompting,' which could serve as a basis for comparison. While the comment highlights a gap in the analysis, it does not offer specific guidance on how to address this issue or what additional details should be included. The feedback is somewhat helpful as it points out a specific area for improvement but lacks detailed suggestions for implementation. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should try applying Reinforcement Learning, RNNs, and Wasserstein GANs with data filled by simple methods to empirically validate that these methods are not suitable for incomplete, small data. This action is explicit and provides a clear direction for the authors to follow. It also specifies the methods to be applied and the rationale for doing so, making it highly actionable. The authors know exactly what steps to take to improve their draft based on the feedback provided.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"typical MTTP baselines\" and references \"Reinforcement Learning, RNNs, Wasserstein GANs,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that these methods are not applicable to the proposed approach due to the need for significant data. The comment is specific in recommending that the authors try applying these methods with simple data filling to empirically validate their inapplicability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should empirically validate the inapplicability of Reinforcement Learning, RNNs, and Wasserstein GANs to their proposed approach by applying these methods with simple data filling. While the comment provides a logical rationale for this suggestion, it lacks specific examples or references to support the claim that these methods are not suitable for incomplete, small data. The suggestion is somewhat verifiable as it offers a clear direction for the authors to explore, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's baseline comparison, noting that the typical MTTP baselines like Reinforcement Learning, RNNs, and Wasserstein GANs require a significant amount of data to train effectively. It suggests that the authors should consider applying these methods with simple data filling to empirically validate their inapplicability to the proposed approach. This feedback is clear and actionable, providing a specific direction for the authors to improve their draft by conducting additional experiments. However, the comment could be more helpful if it included more detailed guidance on how to implement these experiments or what specific outcomes to expect. Overall, the comment is mostly helpful as it offers a clear path for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks a baseline comparison, specifically mentioning the need to demonstrate the performance of GPT-3.5 and GPT-4 using the simplest prompt and then compare it with the G-EVAL method. This provides a clear and direct action for the authors to take, which is to include a baseline comparison in their work. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"G-EVAL method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of baseline comparison, suggesting that the authors should demonstrate the performance of GPT-3.5 and GPT-4 using the simplest prompt and then compare it with the G-EVAL method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a baseline comparison, specifically mentioning the G-EVAL method and its reliance on GPT-3.5 and GPT-4. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of baseline comparison. It specifically mentions the G-EVAL method, which is entirely based on GPT-3.5 and GPT-4, and suggests that the authors should demonstrate their performance using the simplest prompt and then compare it with the G-EVAL method. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by including a baseline comparison. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a clear and explicit action for the authors to take, suggesting that they should compute expected rewards or NE gaps for different perturbations to update the weights. It also highlights the requirement for full knowledge of the game payoffs and the need to know the policies of other agents when computing NE gaps. This feedback is concrete and provides a direct path for the authors to improve their draft by addressing these specific aspects. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"weights,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the requirement for computing expected rewards or NE gaps for different perturbations, explaining why this is necessary and highlighting the need for full knowledge of game payoffs and the policies of other agents. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that computing expected rewards or NE gaps for different perturbations requires full knowledge of the game payoffs, unlike the base policies which only get updated based on observed rewards. It also suggests that computing NE gaps necessitates knowing the policies of other agents. While the comment provides a logical explanation of the requirements, it lacks specific references or examples to fully substantiate the claim. The authors might find it challenging to fully understand and address the issue without additional context or detailed examples. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but could benefit from more detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It identifies a specific area where the authors need to compute expected rewards or NE gaps for different perturbations to update the weights. The comment explains that this requires full knowledge of the game payoffs, unlike the base policies, which only get updated based on observed rewards. Additionally, it highlights the need to know the policies of other agents when computing NE gaps. This feedback is detailed and provides a clear path for the authors to enhance their draft by addressing these specific aspects. However, it could be more helpful if it included additional guidance on how to compute these values or examples of how to implement this suggestion. Overall, the comment is mostly helpful, as it offers valuable insights and actionable steps for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should expand the comparison to include other methods, clarify the comparison, or discuss the limitations of the comparison. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft based on this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a specific comparison, \"the paper primarily compares the proposed methods with DiffUCO,\" but it does not specify which part of the paper this comparison is discussed in. The authors might infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in identifying the comparison with DiffUCO, but it lacks grounding as it does not specify the exact section or part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is significant or how it affects the paper\\'s contribution or findings. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the comment and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific comparison made in the paper, which is the comparison with DiffUCO. However, it does not provide any additional context, analysis, or suggestions on how this comparison could be improved or expanded. Without further guidance or actionable feedback, the authors are left without a clear understanding of how to enhance their draft based on this comment. As a result, the comment is not helpful, as it lacks depth and specificity, aligning with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, as well as the superficial treatment of the value decomposition method. It also points out the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the definitions and provide a more detailed proof, but the lack of concrete steps or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s contribution, specifically the value decomposition and the claim of equivalence between the local policy product and the globally optimal policy. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issues with the paper\\'s exposition, such as the lack of explicit definition of local subtasks and their policies, and the absence of a complete proof of equivalence. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is repetitive and superficial in its exposition of the value decomposition method, lacking explicit definitions of local subtasks and their policies, as well as a complete proof of the equivalence between the local policy product and the globally optimal policy. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or reasoning makes the claim somewhat verifiable, as it requires the authors to infer the nature of the issues from the general statements provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's contribution, specifically the lack of clarity and depth in the exposition of the value decomposition method. It points out that the paper does not explicitly define local subtasks and their corresponding policies, nor does it provide a complete proof of the equivalence between the local policy product and the globally optimal policy. This feedback is valuable as it highlights areas where the paper could be improved to enhance its clarity and rigor. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues, such as recommending the inclusion of detailed definitions or a more comprehensive proof. Overall, the comment is somewhat helpful as it directs the authors to areas needing improvement but lacks depth in actionable guidance.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of explicit definition of local subtasks and their corresponding policies, as well as the superficial treatment of the value decomposition method. It also points out the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. However, the comment does not provide specific guidance on how to address these issues or suggest concrete steps for improvement. The authors are left to infer that they need to clarify the definitions and provide a more detailed proof, but the lack of explicit instructions makes the action somewhat vague. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s contribution, specifically the value decomposition and the claim of equivalence between the local policy product and the globally optimal policy. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issues with the paper\\'s exposition, such as the lack of explicit definition of local subtasks and their policies, and the absence of a complete proof of equivalence. However, the lack of specific guidance or examples makes it difficult for the authors to fully understand and address the issues. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper is repetitive and superficial in its exposition of the value decomposition method, lacking explicit definitions of local subtasks and their policies, as well as a complete proof of the equivalence between the local policy product and the globally optimal policy. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or reasoning makes the claim somewhat verifiable, as"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the performance curve of each algorithm during training is missing. This provides a clear and direct action for the authors to take, which is to include the performance curve in their draft. The comment is explicit and concrete, giving the authors a straightforward task to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment points out that the performance curve of each algorithm during training is missing. However, it does not specify which part of the paper this information should be included in, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the missing element, which is the performance curve, but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance curve of each algorithm during training is missing. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of including the performance curve or how it could be addressed. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the performance curve of each algorithm during training is missing. This is a clear and actionable feedback that highlights a gap in the presentation of results, which is crucial for understanding the performance of the algorithms. By pointing out this omission, the comment provides the authors with a clear direction for improvement, namely to include the performance curve in their draft. However, the comment could be more helpful if it suggested how to present the performance curve or what specific aspects should be included. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed Gaussian kernel-based graph construction method, specifically the computational expense due to the need to compute the full adjacency matrix, which has an O(N^2) time complexity for large-scale graphs. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The action is implicit, as the authors can infer that they might need to explore alternative methods or optimizations to mitigate the computational expense. However, the lack of concrete details or suggestions makes the action vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the computational expense of the proposed Gaussian kernel-based graph construction method, specifically mentioning the need to compute the full adjacency matrix, which has an O(N^2) time complexity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the computational complexity issue, but without grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed Gaussian kernel-based graph construction method requires computing the full adjacency matrix, which is computationally expensive for large-scale graphs. This claim is supported by the assertion of an O(N^2) time complexity, providing a clear and logical reasoning for the computational expense. However, the comment could be strengthened by including specific examples or references to similar methods that have addressed this issue, which would make the claim more verifiable. Overall, the comment is mostly verifiable due to its logical reasoning and the inclusion of a specific time complexity, but it could be further strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant limitation of the proposed Gaussian kernel-based graph construction method, specifically the computational expense due to the need to compute the full adjacency matrix, which has an O(N^2) time complexity for large-scale graphs. This feedback is valuable as it highlights a potential bottleneck in the scalability of the method, which is an important consideration for practical applications. However, the comment could be more helpful if it provided suggestions or alternatives for addressing this limitation, such as proposing more efficient algorithms or techniques to reduce computational complexity. Overall, the comment is mostly helpful as it points out a critical issue that the authors should consider, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of loss reweighting case (1) in Eq. (5) despite case (3) showing better performance for most widths in Table 2e. The reviewer questions the authors\\' explanation regarding the importance of different sub-networks with varying widths. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify their choice of loss reweighting or consider alternative explanations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by questioning the choice of loss reweighting case (1) despite case (3) showing better performance for most widths. The comment clearly details what needs to be addressed, namely the authors\\' explanation regarding the importance of different sub-networks with varying widths. This provides clear guidance on what the authors need to consider or explain in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of loss reweighting case (1) despite case (3) showing better performance for most widths. The reviewer questions the authors\\' explanation regarding the importance of different sub-networks with varying widths, suggesting that all sub-networks should be equally important. However, the comment lacks specific evidence or detailed reasoning to support the claim that case (3) is more appropriate. The authors are left to infer the basis of the reviewer\\'s disagreement, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy in the choice of loss reweighting case (1) despite case (3) showing better performance for most widths in Table 2e. It questions the authors' explanation regarding the importance of different sub-networks with varying widths, suggesting that all sub-networks should be equally important. This feedback is clear and actionable, as it prompts the authors to reconsider their choice of loss reweighting and provide a more compelling justification for their decision. The comment offers a specific point for improvement, making it mostly helpful. However, it could be more helpful if it provided additional suggestions or examples to support the argument. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper claims to address the unique challenges of fine-tuning multiplicity in Tabular LLMs, but the main results are general and do not leverage any unique characteristics of tabular data or LLMs. It suggests that the main result is irrelevant to the paper\\'s scope. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their results to better align with the paper\\'s scope. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the claim that the paper addresses the unique challenges of fine-tuning multiplicity in Tabular LLMs, but the main results are general and do not leverage any unique characteristics of tabular data or LLMs. It suggests that the main result is irrelevant to the paper\\'s scope. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or result. This makes it difficult for the authors to identify the exact area needing improvement. Additionally, the comment lacks specificity in detailing what aspects of the results are irrelevant or how they could be made more relevant. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper\\'s main results are general and do not leverage any unique characteristics of tabular data or LLMs, making them irrelevant to the paper\\'s scope. However, the comment does not provide specific examples or evidence to support this claim, such as detailed comparisons with other works or specific characteristics of tabular data that are not addressed. Without explicit references or detailed reasoning, the claim remains unverifiable, leaving the authors uncertain about how to address the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s main results, suggesting that they are general and do not leverage the unique characteristics of tabular data or LLMs. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s approach. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results to better align with the paper\\'s scope. Without actionable advice or detailed feedback, the authors may find it challenging to effectively respond to the critique. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions: first, it suggests that the summation should be doubled, with one over multi-layered garments and the other over vertices of the garment. Second, it asks for clarification on the function f(\u00b7) in the line just above eq. 3. Additionally, it mentions existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on a human body, and it questions whether the authors can provide details on simulating multiple layers. While the comment provides explicit questions and references to existing works, it does not offer concrete guidance on how the authors should address these issues or what specific changes to make. The authors are left with a clear understanding of what needs clarification but lack detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"eq. 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as the need for a double summation and the clarification of the function f(\u00b7). Additionally, it references existing works like TailorNet and Patel et al. 2021, providing context and suggesting areas for further discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the summation and the function f(\u00b7) in the paper. It also references existing works like TailorNet and Patel et al. 2021 that use PBS to drape garments on a human body. While the comment provides some context and references, it lacks detailed reasoning or specific examples to fully substantiate the claim that the summation should be doubled or to explain why simulating multiple layers is more challenging than single-layered clothing. The references to existing works are a step towards verification but do not fully address the specific issues raised in the comment. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several specific points that could help the authors improve their draft. It questions the summation in the paper, suggesting that it should be doubled, and provides a clear explanation of why this might be necessary. Additionally, it asks for clarification on the function f(\u00b7) in the line just above eq. 3, which is a direct request for more detailed information. The comment also references existing works like TailorNet and Patel et al. 2021, which use PBS to drape garments on a human body, and it questions whether the authors can provide details on simulating multiple layers. This feedback is mostly helpful as it identifies specific areas for clarification and improvement, giving the authors actionable steps to enhance their draft. However, it could be more helpful if it provided additional guidance or suggestions on how to address these issues. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical analysis, specifically asking why the supremum is defined as \\gamma(\\frac{B}{\\hat{d}_{\\min}^k})^{\\frac{1}{2}} and how the proposed GRADE reduces this supremum. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the theoretical analysis and potentially provide a proof of how GRADE reduces the supremum. However, the lack of concrete steps or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the theoretical analysis, specifically asking why the supremum is defined as \\gamma(\\frac{B}{\\hat{d}_{\\min}^k})^{\\frac{1}{2}} and how the proposed GRADE reduces this supremum. This provides clear guidance on what needs to be addressed in the theoretical analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the theoretical analysis, specifically asking why the supremum is defined as \\gamma(\\frac{B}{\\hat{d}_{\\min}^k})^{\\frac{1}{2}} and how the proposed GRADE reduces this supremum. This question is logical and seeks clarification on a specific aspect of the theoretical framework. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or guide the authors in addressing the issue. As a result, the comment is considered unverifiable, as it lacks the necessary justification or evidence to be actionable for the authors.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the theoretical analysis, questioning the definition of the supremum in Definition 1 and asking how the proposed GRADE reduces this supremum. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing aspect of their theoretical framework. By addressing this question, the authors can improve the clarity and rigor of their theoretical analysis. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the confusion. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking if the performance will drop on these samples. While the comment implies that the authors should conduct this analysis, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide results and analysis on lengthy dialogues, but the comment lacks concrete guidance on how to execute this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results and analysis on lengthy dialogue samples, specifically asking if the performance will drop on these samples. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for results and analysis on lengthy dialogues, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking if the performance will drop on these samples. However, the comment does not provide any evidence, reasoning, or references to support the claim that the performance might drop on lengthy dialogues. Without such support, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically asking if the performance will drop on these samples. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct this analysis or what specific results should be included. The authors are left with a general suggestion but without actionable steps or examples, making the feedback somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the datasets used in the paper only contain visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. While the comment provides a clear direction for improvement, it does not specify which datasets should be expanded or how the inclusion of additional modalities would enhance the evaluation. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the datasets used in the paper only contain visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. However, it does not specify which part of the paper discusses the datasets or the evaluation, making it weakly grounded. The comment is specific in suggesting the inclusion of additional modalities, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact sections that need revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the datasets used in the paper only contain visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. The comment provides references to existing works that discuss the importance of multimodal datasets, such as [1] Weiyao Wang et al., [2] Thomas Winterbottom et al., and [3] Ya Sun et al., which support the claim that including additional modalities could enhance the evaluation. This provides a logical basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or specific suggestions on how to incorporate these modalities, which would make it fully verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the datasets used in the paper, noting that they only contain visual modality. It suggests that including more natural modalities, such as audio and visual, could enhance the evaluation. The comment provides references to existing works that discuss the importance of multimodal datasets, which supports the suggestion. This feedback is clear and actionable, as it directs the authors to consider expanding their dataset to include additional modalities. However, the comment could be more helpful if it offered specific guidance on how to incorporate these modalities or examples of how this could improve the evaluation. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models, but these works are not discussed in the paper. While the comment highlights a potential oversight, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they should include references to these works or discuss their relevance to their own research. However, the lack of specific instructions or examples makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions the oracle-context model and its similarity to prompt tuning works, specifically Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not specify which part of the paper discusses the oracle-context model or where these prompt tuning works are mentioned. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the similarity to prompt tuning works but lacks grounding, as it does not provide a clear reference to the relevant part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the oracle-context model is similar to some prompt tuning works, specifically mentioning Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, the comment does not provide specific examples or references to these works, making it difficult for the authors to understand the exact nature of the similarity or how it should be addressed. Without detailed examples or references, the claim is not fully verifiable, as it lacks the necessary evidence to support the assertion. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential oversight in the paper by noting that the oracle-context model is similar to some prompt tuning works, such as Visual Prompt Tuning & Prompt Learning for Vision-Language Models. However, it does not provide specific examples or references to these works, nor does it suggest how the authors might address this similarity or integrate these references into their paper. The comment lacks actionable guidance or detailed feedback, leaving the authors with a general suggestion that is not fully helpful. Therefore, the comment is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide more insights into how the observed phenomenon can be used to design better resilient systems. It implies that the authors should consider proposing a defense method that resembles a hierarchical system, which would demonstrate the usefulness and significance of the observed results. While the comment implies an action, it does not explicitly instruct the authors to propose a specific defense method or provide detailed guidance on how to implement this idea. The action is somewhat vague, as it does not specify the exact steps or methods to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper\" and \"the observed phenomenon,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, which is a deeper exploration of how the observed phenomenon can be used to design better resilient systems. The comment suggests a potential approach, such as joining a proposed defense method to make it more closely resemble a hierarchical system, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks depth in exploring how the observed phenomenon can be used to design better resilient systems. It implies that the authors should provide more insights into this area. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the paper is lacking depth. The suggestion to join a proposed defense method to make it more closely resemble a hierarchical system is a potential direction for improvement but lacks detailed justification or evidence. Therefore, the comment is somewhat verifiable, as it provides a general suggestion but lacks sufficient detail to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by noting that it only discusses the observed phenomenon without delving into how these observations can be used to design better resilient systems. It suggests that the authors should provide more insights into this area, such as proposing a defense method that resembles a hierarchical system. This feedback is clear and actionable, as it directs the authors to expand their analysis and provide a more comprehensive exploration of the implications of their observations. However, the comment could be more helpful if it offered specific suggestions or examples of how to implement this idea. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors are attempting to evaluate a form of reliability or trust by examining what LLMs \"know,\" but it lacks rigorous definitions. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on what specific definitions are missing or how they should be developed. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the evaluation of reliability or trust in LLMs, but it does not specify which part of the paper this concern is related to. The authors might infer that it pertains to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in identifying the lack of rigorous definitions, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors are attempting to evaluate a form of reliability or trust by examining what LLMs \"know,\" but no rigorous definitions are provided. This claim is somewhat verifiable as it highlights a potential gap in the paper\\'s methodology or analysis. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's evaluation of reliability or trust in LLMs, noting that no rigorous definitions are provided. This feedback is somewhat helpful as it points out a gap in the paper's methodology or analysis. However, it lacks specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of specific definitions or examples. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given that forecasting horizons are larger than history lengths in many experiments. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to make any changes or provide specific guidance on how to address these questions. The action is implicit and somewhat vague, as the authors need to infer that they should explore these issues and potentially make adjustments to their methodology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given that forecasting horizons are larger than history lengths in many experiments. However, the comment does not specify which part of the paper these questions pertain to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is specific in its questions about the necessity of masked self-attention and computational efficiency, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given that forecasting horizons are larger than history lengths in many experiments. However, the comment does not provide any specific evidence, reasoning, or references to support these questions or claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and address them effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given that forecasting horizons are larger than history lengths in many experiments. While the comment identifies areas for improvement and questions that could lead to a deeper understanding of the methodology, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more actionable with detailed advice or examples. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given that forecasting horizons are larger than history lengths in many experiments. While the comment implies that the authors should consider these aspects, it does not explicitly instruct them to make any changes or provide specific guidance on how to address these questions. The action is implicit and somewhat vague, as the authors need to infer that they should explore these issues and potentially make adjustments to their methodology. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given that forecasting horizons are larger than history lengths in many experiments. However, the comment does not specify which part of the paper these questions pertain to, such as a specific section or experiment. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper that need attention. The comment is specific in its questions about the necessity of masked self-attention and computational efficiency, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred. It also inquires about the impact on computational efficiency, given that forecasting horizons are larger than history lengths in many experiments. However, the comment does not provide any specific evidence, reasoning, or references to support these questions or claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the questions and address them effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the necessity of masked self-attention in the Y-Future encoder and why ProbSparse is not preferred."}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific theoretical frameworks or methods to explore. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific area of theoretical analysis that is lacking in the paper, namely the theoretical basis for why deep layer parameters are more suitable for distillation. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in identifying the need for a theoretical analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks theoretical analysis, namely the reason why deep layer parameters are more suitable for distillation. This feedback is valuable as it points out a gap in the paper's theoretical foundation, which could be crucial for understanding the methodology and its implications. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific theoretical frameworks or methods to explore. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that a significant amount of important paper details are in the appendix, making the paper insufficiently self-contained. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting that they move important details to the main text or provide more context in the main body. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed to improve the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights that a significant amount of important paper details are in the appendix, making the paper insufficiently self-contained. However, it does not specify which parts of the paper are affected or provide details on what specific information is missing. This lack of grounding and specificity makes it difficult for the authors to identify the exact areas that need attention. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"a lot of the important paper details are in the appendix,\" suggesting that the paper is not self-contained. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment highlights a significant issue with the paper's structure, noting that a large amount of important details are in the appendix, making the paper insufficiently self-contained. This feedback is clear and actionable, as it points out a specific area where the authors can improve the readability and accessibility of their work. By addressing this issue, the authors can enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided suggestions on how to move the important details to the main text or how to structure the paper to ensure self-containment. Overall, the comment is mostly helpful as it identifies a critical issue and offers a direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the authors\\' argument about using gradient descent-based methods for clustering, which allows scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be \"large enough.\" While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their analysis. The action is implicit and vague, as the authors are left to infer that they should consider using larger datasets or exploring alternative methods. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' argument about using gradient descent-based methods for clustering, allowing scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be \"large enough.\" While the comment identifies a specific aspect of the argument, it does not specify which part of the paper this relates to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges the authors\\' argument about using gradient descent-based methods for clustering, allowing scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be \"large enough.\" While the comment identifies a potential issue, it lacks specific examples or references to support the claim that 50K points is not a large enough dataset. The reasoning is based on a subjective judgment about dataset size, which is not fully substantiated. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the authors' argument about using gradient descent-based methods for clustering, which allows scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be 'large enough.' While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback is somewhat helpful as it points out a potential limitation, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges the authors\\' argument about using gradient descent-based methods for clustering, allowing scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be \"large enough.\" While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their analysis. The action is implicit and vague, as the authors are left to infer that they should consider using larger datasets or exploring alternative methods. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' argument about using gradient descent-based methods for clustering, allowing scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be \"large enough.\" While the comment identifies a specific aspect of the argument, it does not specify which part of the paper this relates to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point acknowledges the authors' argument about using gradient descent-based methods for clustering, allowing scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be 'large enough.' While the comment identifies a potential issue, it lacks specific examples or references to support the claim that 50K points is not a large enough dataset. The reasoning is based on a subjective judgment about dataset size, which is not fully substantiated. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the authors' argument about using gradient descent-based methods for clustering, allowing scaling to large datasets. However, it raises a concern about the size of the largest dataset used, suggesting that it may not be 'large enough.' While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback is"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the assumptions made in the paper, specifically regarding the reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what steps they should consider to make the assumptions more practical. Without specific suggestions or directions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific assumption in the paper, \"overloading the library with ASD subroutines,\" which is mentioned in assumption 3.2. This allows the authors to identify the part of the paper being discussed, providing full grounding. However, the comment does not specify what aspects of the assumption are unclear or problematic, nor does it suggest how the authors might address this issue. This makes the comment specific in terms of identifying the part of the paper but under-specific in terms of what needs to be addressed. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the practicality of the assumptions made in the paper, specifically regarding the reliance on \"overloading the library with ASD subroutines.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the practicality of the assumptions made in the paper, specifically regarding the reliance on \"overloading the library with ASD subroutines\" (assumption 3.2). While it identifies a potential issue, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or improve the practicality of their assumptions. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a sentiment about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the excitement of their methodology. Without any actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a sentiment about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not specify which part of the paper this methodology is discussed in, nor does it provide any details on what aspects of the methodology are lacking excitement. Without specific references to sections or detailed feedback, the authors cannot confidently determine which part of the paper needs attention. This lack of grounding and specificity makes it difficult for the authors to address the comment effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses a subjective opinion about the methodology used in data augmentation, suggesting that it lacks excitement. However, it does not provide any specific feedback, examples, or suggestions on how the authors might enhance the excitement or improve the methodology. Without actionable guidance or detailed insights, the comment does not offer the authors a clear path to improve their draft. As a result, the feedback is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the accuracy of statements in the paper, specifically mentioning a discrepancy between the claim in section 4 and the results presented in Fig. 4. It points out that the claim \"multi-image IMP significantly can improve the quality of the LIPs in the cross-domain setting\" is incorrect, as the figure suggests otherwise. However, the comment does not provide specific guidance on how the authors should address this issue or what changes they should make to their statements. The action is implicit and vague, as the authors are left to infer that they need to correct the statements, but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the statements in section 4, particularly the claim about the performance of \"multi-image IMP\" in improving the quality of LIPs in the cross-domain setting, which is contradicted by the results shown in Fig. 4. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some statements in the paper are incorrect, specifically mentioning a discrepancy between the claim in section 4 and the results presented in Fig. 4. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the assertion, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the accuracy of statements in the paper, particularly regarding the claim in section 4 that \"multi-image IMP significantly can improve the quality of the LIPs in the cross-domain setting.\" It points out a discrepancy with the results presented in Fig. 4, which suggests that the multi-IMP shows essentially the same performance as others. This feedback is clear and actionable, as it directs the authors to revisit and correct the statements in question. However, the comment could be more helpful if it provided additional guidance on how to address the discrepancy or suggested ways to improve the clarity of the statements. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method\\'s rank on the VLN Leaderboard is 22nd and that the results are not better than existing methods, referencing specific works [1, 2, 3] as examples. While the comment identifies a potential issue with the performance of the proposed method, it does not provide explicit guidance on how the authors should address this concern or improve their results. The feedback lacks actionable steps or suggestions for enhancing the method or its evaluation. As a result, the authors are left without a clear understanding of what changes or improvements are needed to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the rank of the proposed method on the VLN Leaderboard and compares it to existing methods, specifically mentioning references [1, 2, 3]. However, it does not specify which part of the paper this information is presented in, making it weakly grounded. The comment is specific in identifying the issue of the proposed method\\'s performance not being better than existing methods, but it lacks detailed guidance on how to address this issue or improve the results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method\\'s results are not better than existing methods, referencing specific works [1, 2, 3] as examples. However, the comment does not provide detailed reasoning or analysis to support why the proposed method is not better or how it compares to the referenced works. The references are not fully explained, and the claim lacks specific details or comparisons that would help the authors understand the critique or improve their work. As a result, the claim is somewhat verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment points out that the proposed method's rank on the VLN Leaderboard is 22nd, indicating that the results are not better than existing methods. It provides specific references [1, 2, 3] to existing works that achieve better results, which is helpful in identifying areas for improvement. However, the comment lacks actionable guidance on how the authors might enhance their method or address the performance gap. While it highlights a potential issue, it does not offer detailed suggestions or steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, it does not provide any explicit or implicit actions for the authors to take to improve the discussion. There is no guidance on how to make the discussion more convincing or what specific aspects need clarification. Without actionable advice or suggestions, the authors are left without a clear understanding of how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is that it is not convincing regarding how semantic similarity is modeled with the proposed approach. This provides clear guidance on what needs to be addressed in the discussion. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 2.2 is not convincing regarding how semantic similarity is modeled with the proposed approach. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion in section 2.2, noting that it is not convincing regarding how semantic similarity is modeled with the proposed approach. However, the comment lacks actionable feedback or suggestions on how the authors might improve the discussion or provide more convincing evidence. Without additional guidance or examples, the authors are left without a clear understanding of what aspects need clarification or elaboration. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed advice for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss the uncertainty in fitted parameter values and provide sensitivity analysis due to the introduction of over 10 parameters in the SEPAI3R3O model. The comment is clear and provides a direct action for the authors to take, making it highly actionable. The suggestion is concrete, as it specifies the need for a discussion on uncertainty and sensitivity analysis, which are crucial for understanding the robustness of the model. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SEPAI3R3O model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of having over 10 parameters, which may be difficult to estimate given limited real-world observations, and suggests that the authors should discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed SEPAI3R3O model introduces over 10 parameters, which may be difficult to reliably estimate given limited real-world observations. The comment also suggests that modeling these parameters as time-varying further exacerbates the challenge of estimation from scarce data. The reviewer recommends that the authors discuss the uncertainty in fitted parameter values and provide sensitivity analysis. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the difficulty of estimating parameters. This makes the claim somewhat verifiable, as it provides a basis for the concern but could be strengthened with additional evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed SEPAI3R3O model, noting that it introduces over 10 parameters, which may be difficult to reliably estimate given limited real-world observations. The comment also highlights that modeling these parameters as time-varying further exacerbates the challenge of estimation from scarce data. The reviewer suggests that the authors discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is clear and actionable, as it points out a specific area of concern and provides a clear direction for improvement. By addressing this issue, the authors can enhance the robustness and reliability of their model. Therefore, the comment is rated as highly helpful, as it effectively guides the authors in improving their draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It also points out that the performance of the proposed method and the relative performances of MC, IB, and HSIC test would depend on how the parameters are changing across domains. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their analysis. As a result, the comment is unactionable, as it does not offer any actionable feedback for the authors to consider.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It also points out that the performance of the proposed method and the relative performances of MC, IB, and HSIC test would depend on how the parameters are changing across domains. However, the comment does not specify which part of the paper this concern relates to, making it difficult for the authors to identify the exact section that needs attention. While the comment is specific in its critique of the assumption and its implications, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the assumption that the causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC test would depend on how the parameters are changing across domains. However, the comment lacks specific examples, references, or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or examples makes the claim somewhat verifiable, as it provides a general observation but requires further elaboration for full clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the assumption that causal parameters across domains are random samples, questioning whether this assumption is a consequence of not having latent confounders in the system. It highlights the potential impact of parameter changes on the performance of the proposed method and the relative performances of MC, IB, and HSIC test. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a significant area for consideration, the feedback is somewhat helpful as it prompts the authors to reflect on the robustness of their assumptions and the implications for their results, but it does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it may not be entirely new. It also notes that the method is mentioned in the paper title, which further weakens the narrative. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the narrative. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the novelty of the structural optimization method, suggesting that it may not be entirely new. It also mentions that the method is in the paper title, which weakens the narrative. However, the comment does not specify which part of the paper discusses the structural optimization method or how it is presented. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in questioning the novelty and the impact on the narrative, but it lacks grounding, making it weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the novelty of the structural optimization method, suggesting that it may not be entirely new. However, it does not provide any specific evidence, examples, or references to support this claim. The mention of the method being in the paper title does not substantiate the claim, as it does not explain how this affects the novelty or the narrative. Without additional context or reasoning, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the novelty of the structural optimization method, suggesting that it may not be entirely new. It also points out that the method is mentioned in the paper title, which weakens the narrative. However, the comment does not provide specific examples or references to support the claim of lack of novelty, nor does it offer suggestions on how the authors might address this issue or improve the narrative. Without actionable feedback or detailed guidance, the authors are left without a clear understanding of how to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the proof, specifically noting that it requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This comment implies that the authors should revisit the proof to ensure it aligns with the standard mixup method. However, it does not provide explicit instructions on how to address this issue or what changes need to be made. The action is implicit and somewhat vague, as the authors need to infer that they should revise the proof to account for the standard mixup method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, specifically noting that it requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This suggests that the assumption in the proof may not be correct. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires the authors to infer the implications of the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This observation highlights a discrepancy that could affect the validity of the proof. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes need to be made to the proof. While it points out a critical point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This suggests that the authors should revisit the proof to ensure it aligns with the standard mixup method. However, the comment does not provide explicit instructions on how to address this issue or what changes need to be made. The action is implicit and somewhat vague, as the authors need to infer that they should revise the proof to account for the standard mixup method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, specifically noting that it requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This provides clear guidance on what needs to be addressed in the proof. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the proof requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This suggests that the assumption in the proof may not be correct. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Without detailed reasoning or evidence, the claim remains somewhat vague and unverifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proof, specifically noting that it requires lambda not to be 0.5, which is not the case in standard mixup where lambda can be 0.5. This observation highlights a discrepancy that could affect the validity of the proof. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes need to be made to the proof. While it points out a critical point, the"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to highlight which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. Additionally, it suggests extracting some of the inlined math into environments to facilitate looking up symbols, particularly on page 6. These actions are direct and specific, providing clear guidance on what the authors need to do to improve their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the paragraph above Theorem 3.1, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely highlighting the equations with the same form as the Riccati equation and suggesting the extraction of inlined math into environments for easier symbol lookup. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts: a request for clarification and a suggestion for improvement. The first part is a request for the authors to highlight specific equations, which is a factual statement and does not require verification. The second part suggests extracting inlined math into environments to facilitate symbol lookup, which is a suggestion for improvement. However, it lacks specific examples or references to support the suggestion, making it somewhat verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it provides specific and actionable feedback. It highlights a need for clarification by asking the authors to identify which set of equations have the same form as the Riccati equation in a particular paragraph. Additionally, it suggests extracting some of the inlined math into environments to facilitate symbol lookup, particularly on page 6. These suggestions are clear and provide the authors with concrete steps to improve the clarity and accessibility of their draft. However, the comment could be more helpful if it included examples of the equations in question or further guidance on how to implement the suggestion. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that certain sections of the paper would benefit from clearer structure and transitions, and it specifically mentions the need for statistical evidence to clarify subjective terms like 'significant' (e.g., line 257). While the comment provides explicit actions, such as improving structure and transitions, and suggesting the use of statistical evidence, it does not offer concrete guidance on how to achieve these improvements. The authors know they need to clarify the structure and transitions, but the comment lacks detailed instructions on how to do so. Therefore, the comment is mostly actionable, as it provides clear actions but lacks specific guidance on execution.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment suggests that certain sections of the paper would benefit from clearer structure and transitions, and it mentions the need for statistical evidence to clarify subjective terms like 'significant' (e.g., line 257). However, it does not specify which sections of the paper are affected or provide detailed guidance on how to improve clarity. The authors can infer that the comment pertains to sections that require clearer structure and transitions, but the lack of specific guidance makes it difficult to pinpoint the exact parts of the paper needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point suggests that certain sections of the paper would benefit from clearer structure and transitions, and it mentions the need for statistical evidence to clarify subjective terms like 'significant.' However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the specific areas needing improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas for improvement in the paper's clarity and structure. It suggests that certain sections would benefit from clearer transitions and provides a specific example of a subjective term, 'significant,' that could be clarified with statistical evidence, such as p-values. This feedback is actionable and provides clear guidance on how the authors can enhance the clarity and rigor of their writing. However, the comment could be more helpful if it offered additional suggestions or examples of how to implement these improvements. Overall, the comment is mostly helpful as it directs the authors' attention to specific areas needing improvement and offers a clear direction for enhancement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the detailed information for graph construction is missing, specifically mentioning the lack of information on defining edges and constructing a graph for non-euclidean datasets. This provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, guiding the authors on exactly what needs to be added to improve their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"graph construction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely, the detailed information on defining edges and constructing a graph for non-euclidean datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the detailed information for graph construction is missing, specifically mentioning the lack of information on defining edges and constructing a graph for non-euclidean datasets. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely, the missing information on graph construction, particularly regarding the definition of edges and the construction of graphs for non-euclidean datasets. This feedback is clear and actionable, as it directly points out a gap in the paper that needs to be addressed. By highlighting this omission, the authors are given a clear direction for improvement, which is to include this information in their draft. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of how it could be incorporated. Overall, the comment is mostly helpful as it guides the authors towards a specific area of improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks how the default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$ are determined. This question provides a clear and direct action for the authors to take, which is to explain the process of setting these default values. The comment is explicit and concrete, as it specifies exactly what information is needed to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"hyper-parameters $\\\\alpha$ and $\\\\beta$,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how these default settings are determined, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a question seeking clarification on the determination of default settings for hyper-parameters $\\\\alpha$ and $\\\\beta$. While it identifies a specific area that requires further explanation, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, making it somewhat helpful. The authors are given a clear question to address, but the comment does not offer insights or suggestions for improvement, limiting its value. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the visual and textual representations used in each method in Table 4. It also questions whether the end-to-end performance gain is due to the proposed attention model. This direct request for clarification and explanation provides clear guidance on what the authors need to address to improve their draft. The comment is explicit and concrete, as it directly instructs the authors to provide additional details, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for clarification on the visual and textual representations used in each method and the potential impact on the end-to-end performance gain. This provides clear guidance on what the authors should focus on to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of Table 4 regarding the visual and textual representations used in each method, and it also raises a concern about whether the end-to-end performance gain is due to the proposed attention model. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim is not fully verifiable. Therefore, the comment is categorized as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of Table 4, questioning the visual and textual representations used in each method. It also raises a critical point about whether the end-to-end performance gain is solely due to the proposed attention model. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the representations used and to clarify the contribution of the attention model. By addressing these points, the authors can enhance the clarity and impact of their paper. However, the comment could be more helpful if it suggested specific ways to improve the clarity or provided examples of how to address these issues. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights several issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. It specifies that the proof is not clear and mentions specific elements like notations and Eq. (15) that need clarification. However, the comment does not provide explicit guidance on how to address these issues or suggest concrete steps for improvement. The authors are left to infer that they need to clarify the convergence analysis, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the convergence analysis, specifically mentioning the lack of clarity in the main part of the paper and the simplicity of the proof in the appendix. It highlights issues with notations, assumptions, and the justification of Eq. (15). However, the comment does not specify which part of the paper the convergence analysis is located in, making it weakly grounded. The authors can infer that it relates to the main part of the paper, but this inference is not explicit. The comment is specific in detailing the issues with the convergence analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the convergence analysis is not clear, as the authors provide a simple proof in the appendix and do not present the convergence of the assumptions or Eq. (15). The comment provides specific examples of unclear notations and assumptions, such as D, G, and the convergence of alpha_k to alpha. However, it lacks detailed reasoning or references to support the claim that the proof is not clear or that the convergence analysis is missing. While the comment highlights specific issues, it does not provide comprehensive justification or evidence to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several specific issues with the convergence analysis, including the lack of clarity in the main part of the paper, the simplicity of the proof in the appendix, and the unclear presentation of notations and assumptions. It highlights the need for more detailed explanations and justifications, such as the convergence of the assumptions and Eq. (15). However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered specific examples of how to address these issues. While it points out significant areas for improvement, the feedback lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description of uncertainty calibration, stating that it is insufficient and unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment highlights areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors are left with a general understanding of what needs to be improved but lack concrete steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of insufficient description of uncertainty calibration, which is unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the issues are related to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, such as improving the description of uncertainty calibration and organizing the studied issues. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the studied problems are not well-driven and illustrated, specifically mentioning the insufficiency of the description of uncertainty calibration, which is unfriendly for new readers. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of uncertainty calibration, noting that it is insufficient and unfriendly for new readers. It also points out that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment highlights areas that need improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it points out a gap in the paper but lacks depth and actionable advice, leaving the authors with a general understanding of what needs to be improved but without clear steps to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the description of uncertainty calibration, noting that it is insufficient and unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment highlights areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors are left with a general understanding of what needs to be improved but lack concrete steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the description of uncertainty calibration, noting that it is insufficient and unfriendly for new readers. It also suggests that the studied issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the issues are related to the methodology or results sections, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, such as improving the description of uncertainty calibration and organizing the studied issues. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the description of uncertainty calibration is insufficient and unfriendly for new readers, and suggests that the studied issues should be further organized and summarized. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of uncertainty calibration, noting that it is insufficient"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of results exploring the incorporation of PAC-tuning with other fine-tuning techniques like pruning and data augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific experiments should be conducted. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific area of the paper that lacks exploration, namely the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the experimental section, the comment lacks full grounding. It is specific in identifying the gap in the exploration of PAC-tuning with other techniques, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no results exploring the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks exploration, namely the incorporation of PAC-tuning with other fine-tuning techniques such as pruning and data augmentation. This feedback is valuable as it points out a potential gap in the experimental evaluation that could be addressed to enhance the comprehensiveness of the study. However, the comment does not provide any suggestions or guidance on how the authors might conduct these experiments or what specific results to expect. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the experimental analysis is insufficient and should be validated on more models. It also references a specific question, implying that the authors should address this issue further. While the comment provides a clear action to take, it does not specify which models should be used or how the validation should be conducted. The action is explicit but somewhat vague, as the authors know what needs to be done but not how to execute it fully. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the analysis should be validated on more models. The comment is specific because it clearly outlines what needs to be addressed, namely, the need for additional model validation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental analysis is insufficient and should be validated on more models. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the need for additional model validation. Without this support, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the experimental analysis, which is found to be insufficient. It suggests that the analysis should be validated on more models, providing a clear direction for the authors to enhance the robustness and generalizability of their findings. However, the comment lacks depth and does not offer specific guidance on which models to include or how to conduct the validation. While it points out a critical area for improvement, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is somewhat helpful, as it provides a starting point for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method, noting that it improves over the original initialization but only demonstrates trainability on CIFAR with a network of 100 layers. It also points out that the ImageNet experiments are based on networks with various normalization layers, and the proposed method only shows marginal improvement over the baselines. The reviewer references specific works, such as [1] and [2], which provide context for the critique. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their method. The feedback is somewhat specific in identifying the limitations but lacks actionable steps for the authors to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s improvement over the original initialization, specifically mentioning the trainability of a network with 100 layers on CIFAR. It also critiques the ImageNet experiments, noting that the proposed method only shows marginal improvement over baselines when applied to networks with various normalization layers. The comment references specific works, such as [1] and [2], which provide context for the critique. However, it does not explicitly mention which part of the paper these critiques pertain to, making it weakly grounded. The comment is specific in detailing the issues with the proposed method, particularly regarding its applicability and performance on different normalization layers. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method, noting that it only shows trainability on CIFAR with a network of 100 layers and provides references to specific works, such as [1] and [2], which discuss normalization layers. However, the comment lacks detailed reasoning or specific examples to support the claim that the proposed method only shows marginal improvement over baselines on ImageNet. While the references provide some context, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the proposed method, noting that it only demonstrates trainability on CIFAR with a network of 100 layers and provides references to specific works, such as [1] and [2], which discuss normalization layers. The comment highlights that the proposed method does not show significant improvement over baselines on ImageNet, which is a more challenging dataset. This feedback is somewhat helpful as it identifies a limitation in the proposed method's applicability and suggests that the authors should consider broader datasets like ImageNet. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or improve the method's performance on ImageNet. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. While the comment implies that this comparison should be included, it does not explicitly instruct the authors to make this addition. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison. However, the suggestion is concrete enough that the authors can understand the direction they need to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to compare robustness and immunizability, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be added. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding a discussion on comparing the robustness and immunizability of the proposed method with another method from Yu et al. 2021. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would enhance the paper. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding a discussion on comparing the robustness and immunizability of the proposed method with another method from Yu et al. 2021. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for a comparative analysis. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be emphasized. To be more helpful, the comment could include suggestions on how to structure the discussion or what specific aspects of robustness and immunizability should be compared. Overall, the comment provides a direction for improvement but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the \"better\" samples produced by the algorithm and suggests that the authors clarify their assessment. It also requests a plot of the time complexity of the decoding scheme as a function of m. While the comment explicitly asks for clarification and suggests a specific plot, it does not provide detailed guidance on how to address these requests. The action is explicit but somewhat vague, as the authors know what needs to be done but may not have a clear idea of how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific point in the paper, which is the claim that the work proposes an algorithm for adaptive top-k decoding to produce \"better\" samples. It also requests clarification on the assessment and suggests a plot of the time complexity of the decoding scheme as a function of m. However, the comment does not explicitly mention which part of the paper this relates to, making it weakly grounded. The comment is specific in its request for clarification and the suggestion for a plot, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the \"better\" samples produced by the algorithm and requests clarification. It also suggests a plot of the time complexity of the decoding scheme as a function of m. However, the comment does not contain any claims or opinions that require verification. It is a request for clarification and a suggestion for additional analysis, which are factual statements. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the \"better\" samples produced by the algorithm and suggests that the authors clarify their assessment. It also requests a plot of the time complexity of the decoding scheme as a function of m. While the comment identifies a specific area for clarification and improvement, it lacks detailed guidance or suggestions on how to address these points. The authors are left with a general understanding of what needs to be clarified but without specific steps to take. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully guide the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the clarity of the postprocessing effort mentioned in footnote 2, specifically in line 313. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific details need to be clarified. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 313\" and \"footnote 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the clarity of the postprocessing effort mentioned in that footnote. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the postprocessing effort mentioned in footnote 2, specifically in line 313. However, it does not provide any supporting evidence, reasoning, or examples to justify why the postprocessing effort is unclear. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the postprocessing effort mentioned in footnote 2, specifically in line 313. However, it does not provide any suggestions or guidance on how the authors might clarify this aspect or improve the clarity of the postprocessing effort. Without actionable feedback or additional context, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it highlights a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to run the codes for multiple seeds and report the mean. This is a clear and direct action that the authors can take to address the comment. The request is specific and provides a concrete step for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the codes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is running the codes for multiple seeds and reporting the mean. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for the authors to provide additional information, specifically asking if they have run the codes for multiple seeds and reported the mean. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, asking the authors to provide additional information by running the codes for multiple seeds and reporting the mean. This feedback is specific and directly addresses a potential weakness in the paper, which could impact the reliability and reproducibility of the results. By following this suggestion, the authors can enhance the robustness of their findings and improve the overall quality of their draft. However, the comment could be more helpful if it provided additional context or guidance on why this information is important. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and why the experimental setup for these datasets is different in the paper. It specifically asks for clarification on the absence of certain models in Table 3 compared to Table 2. While the comment does not explicitly instruct the authors to make changes, it provides a clear and specific question that prompts the authors to address the differences and provide a rationale for the experimental setup. The authors can infer that they need to clarify these aspects in their draft, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the differences between the BCI and IHC4BC datasets and why the experimental setup for these datasets is different in the paper. It specifically mentions Table 3, which lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. This provides some grounding as it references specific tables, but it does not explicitly mention which part of the paper this issue is related to, such as the methodology section or the results section. The comment is specific in detailing the absence of certain models in Table 3, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and why the experimental setup for these datasets is different in the paper. It specifically asks for clarification on the absence of certain models in Table 3 compared to Table 2. However, the comment does not provide any evidence, reasoning, or references to support the claim that the experimental setup is different or why it is different. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the differences between the BCI and IHC4BC datasets and why the experimental setup for these datasets is different in the paper. It specifically points out the absence of certain models in Table 3 compared to Table 2. This feedback is somewhat helpful as it prompts the authors to clarify the differences between the datasets and the rationale behind the experimental setup. However, it lacks depth and does not provide specific suggestions or guidance on how to address these issues, such as recommending additional experiments or analyses. The authors are left with a general understanding of what needs to be clarified but without detailed instructions on how to improve their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the differences between the BCI and IHC4BC datasets and why the experimental setup for these datasets is different in the paper. It specifically asks for clarification on the absence of certain models in Table 3 compared to Table 2. While the comment does not explicitly instruct the authors to make changes, it provides a clear and specific question that prompts the authors to address the differences and provide a rationale for the experimental setup. The authors can infer that they need to clarify these aspects in their draft, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the differences between the BCI and IHC4BC datasets and why the experimental setup for these datasets is different in the paper. It specifically mentions the absence of certain models in Table 3 compared to Table 2. This provides some grounding as it references specific tables, but it does not explicitly mention which part of the paper this issue is related to, such as the methodology section or the results section. The comment is specific in detailing the absence of certain models, which helps the authors understand what needs to be addressed. However, without explicit references to the relevant sections, the comment is weakly grounded. Therefore, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the differences between the BCI and IHC4BC datasets and why the experimental setup for these datasets is different in the paper. It specifically asks for clarification on the absence of certain models in Table 3 compared to Table 2. However, the comment does not provide any evidence, reasoning, or references to support the claim that the experimental setup is different or why it is different. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the differences between the BCI and IHC4BC datasets and"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more thorough description of the results shown in Fig 4. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be done, namely, to provide a more detailed description of the results in the figure. This level of specificity and directness makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Fig 4,\" allowing the authors to accurately identify the part of the paper being addressed. This provides full grounding. The comment also specifies what needs to be addressed, namely, providing a more thorough description of the results shown in the figure. This level of specificity is clear, as it directs the authors to enhance their description of the results. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors provide a more thorough description of the results shown in Fig 4. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment is clear and actionable, instructing the authors to provide a more thorough description of the results shown in Fig 4. This feedback is specific and directly addresses a gap in the paper, guiding the authors on how to enhance their draft. By emphasizing the need for a detailed description, the comment helps the authors improve the clarity and comprehensiveness of their results section. However, it could be more helpful if it offered suggestions on what specific aspects of the results should be described in more detail or how to present this information effectively. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more detail. While the comment implies that the authors should include a comparison with [11], it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to incorporate this comparison, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more detail. However, it does not specify which part of the paper this comparison should be made in, nor does it provide specific guidance on how to incorporate this comparison. The authors can infer that it relates to the method section, but the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion to compare with [11], but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more details. However, the comment does not provide any specific reasoning or evidence to support why [11] is the most relevant literature or why it should be compared in the method part. The suggestion lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the most relevant literature is [11] and recommends comparing the work with it in the method part or in more details. While the comment identifies a specific piece of literature that could be relevant, it does not provide detailed guidance on how to incorporate this comparison or what aspects of the work should be highlighted. The feedback is somewhat helpful as it directs the authors to a potentially relevant source, but it lacks depth and specificity, leaving the authors with limited actionable information to improve their draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which provides a potential justification for the authors to consider. However, the comment does not explicitly instruct the authors to address this concern or provide a specific action to take. The suggestion is implicit and lacks concrete guidance on how to respond to the critique. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific process in the paper, namely the removal of words with identical English counterparts in the class label translation and cleaning. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which provides a potential justification for the authors to consider. However, the comment does not explicitly mention which part of the paper this process is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or data cleaning section, but this inference is not precise. The comment is specific in detailing the issue with the justification for the removal process, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which provides a potential justification for the authors to consider. However, the comment does not provide detailed reasoning or examples to support why this process might not be fully justified. The reference to the BabelNet paper is a step towards verification, but it lacks specific details or analysis to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to explore but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s methodology, specifically the process of removing words with identical English counterparts in the class label translation and cleaning. It references a specific paper, \"Ten Years of BabelNet: A Survey,\" which provides a potential justification for the authors to consider. This feedback is somewhat helpful as it points out a potential weakness in the methodology and suggests a relevant reference for further exploration. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or if it included additional references or examples. Overall, the comment offers a starting point for improvement but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. While the comment implies that the authors should expand their analysis to include additional models, it does not provide specific guidance on which models to include or how to conduct this analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve their study. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result. The authors may infer that it relates to the conclusions or discussion section, but this inference is not explicit. The comment is specific in its suggestion to study more models, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. However, the comment does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the study. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the study should consider examining more models to verify the findings, particularly regarding the conclusions drawn for large vision-language models. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which models to include or how to conduct this analysis. This limits the usefulness of the feedback for the authors, as it does not offer actionable steps or insights to enhance their study. Therefore, the comment is somewhat helpful, as it points out a potential area for expansion but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide further explanation or exploration of the reason behind the significant reduction in the norm for OpenCLIP in Figure 7, despite not showing significant improvement for object localization in Table 3. This feedback implies that the authors should investigate and clarify this discrepancy to better understand and address it. However, the comment does not explicitly instruct the authors to perform this exploration or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for further explanation and exploration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the significant reduction in the norm for OpenCLIP in Figure 7 and the lack of significant improvement for object localization in Table 3. The comment further suggests that the authors should provide further explanation or exploration of this reason. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the norm shows a significant reduction for OpenCLIP in Figure 7, but it does not show significant improvement for object localization in Table 3. The reviewer suggests that further explanation or exploration of this discrepancy would be helpful for wide adoption. However, the comment lacks specific reasoning or evidence to support the claim that the norm should show significant improvement for object localization. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides a suggestion but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the results presented in Figure 7 and Table 3, specifically regarding the norm for OpenCLIP. It points out that while the norm shows a significant reduction in Figure 7, it does not reflect significant improvement for object localization in Table 3. The comment suggests that further explanation or exploration of this discrepancy would be beneficial for the authors to address and potentially improve the adoption of their work. While the comment highlights an important issue, it lacks specific guidance or suggestions on how the authors might investigate or resolve this discrepancy. Therefore, the feedback is somewhat helpful, as it provides a direction for improvement but could be more comprehensive with additional details or actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests more details about how the 3D rendering and the GAN objective are combined, particularly regarding the use of the point cloud in this stage. The comment provides a clear and specific action for the authors to take, which is to include more information about the integration of 3D rendering and the GAN objective. This guidance is concrete and actionable, as it gives the authors a clear direction on what additional information to provide. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of details about how the 3D rendering and the GAN objective are combined, particularly regarding the use of the point cloud. This provides clear guidance on what additional information is needed to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the integration of 3D rendering and the GAN objective, specifically regarding the use of the point cloud. It requests more details about how these components are combined. While the comment does not contain an explicit claim or suggestion, it poses a logical question that prompts the authors to clarify their methodology. As it seeks clarification rather than making a claim or judgment, it aligns with a \"No\" classification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the integration of 3D rendering and the GAN objective, particularly in Section 3.3. It highlights the lack of clarity on how the point cloud is used in this stage and suggests that more details about the combination of 3D rendering and the GAN objective would be helpful. This feedback is clear and actionable, as it provides a specific area for the authors to clarify in their draft. However, it could be more helpful if it offered suggestions on how to present this information or what aspects of the combination are particularly unclear. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft by addressing a specific area of confusion.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It also questions the claim of parameter insensitivity, noting that the supporting evidence is based on simple architectures and datasets, which is not convincing. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their evidence. The action is implicit and somewhat vague, as the authors are left to infer that they need to strengthen their evidence or provide more detailed analysis. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It also questions the claim of parameter insensitivity, noting that the supporting evidence relies heavily on simple architectures and datasets. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the comparison between the LIF and QIF models, but without explicit references, it remains challenging to pinpoint the exact sections. The comment is specific in detailing the issue of parameter insensitivity and the reliance on simple datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the QIF model introduces additional hyperparameters compared to the traditional LIF model and questions the claim of parameter insensitivity, noting that the supporting evidence relies heavily on simple architectures and datasets. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the evidence is not convincing. Without additional context or references, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully support the assertion.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the QIF model, noting that it introduces additional hyperparameters compared to the traditional LIF model. It also questions the claim of parameter insensitivity, pointing out that the supporting evidence relies heavily on simple architectures and datasets, which is not convincing. This feedback is somewhat helpful as it highlights a potential weakness in the paper's claims and suggests that the authors should provide more robust evidence to support their claims. However, the comment could be more helpful if it offered suggestions on how to strengthen the evidence or provide a more comprehensive analysis. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It also questions the claim of parameter insensitivity, noting that the supporting evidence relies heavily on simple architectures and datasets, which is not convincing. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their evidence. The action is implicit and somewhat vague, as the authors are left to infer that they need to strengthen their evidence or provide more detailed analysis. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the increased complexity of hyperparameters in the QIF model compared to the traditional LIF model. It also questions the claim of parameter insensitivity, noting that the supporting evidence relies heavily on simple architectures and datasets, which is not convincing. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the comparison between the LIF and QIF models, but without explicit references, it remains challenging to pinpoint the exact sections. The comment is specific in detailing the issue of parameter insensitivity and the reliance on simple datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the QIF model introduces additional hyperparameters compared to the traditional LIF model and questions the claim of parameter insensitivity, noting that the supporting evidence relies heavily on simple architectures and datasets. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the evidence is not convincing. Without additional context or references, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully support the assertion.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the QIF model, noting that it introduces additional hyperparameters compared to"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made by using other PLMs like RoBERTa and T5. It also questions the relevance of the proposed method and experiments in the era of LLMs, such as computational costs and real-world scenarios. While the comment implies that the authors should consider these aspects, it does not provide explicit guidance on how to address these concerns or what specific improvements to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for further analysis and discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the marginal improvements over baselines and suggests that further improvements could be achieved with other PLMs like RoBERTa and T5. It also questions the relevance of the proposed method and experiments in the era of LLMs, such as computational costs and real-world scenarios. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, such as the relevance of the proposed method in the context of LLMs. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made by using other PLMs like RoBERTa and T5. It also questions the relevance of the proposed method and experiments in the era of LLMs, such as computational costs and real-world scenarios. While the comment provides a logical basis for questioning the current approach, it lacks specific examples or references to support the claim that other PLMs would yield better results. The suggestion to discuss computational costs and real-world scenarios is a valid point but is not fully substantiated by the comment. Therefore, the claim is somewhat verifiable, as it provides a basis for questioning the current approach but lacks detailed evidence or examples to fully support the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the marginal improvements achieved by the proposed method over baselines and suggests that further improvements could be made by using other PLMs like RoBERTa and T5. It also questions the relevance of the proposed method and experiments in the era of LLMs, such as computational costs and real-world scenarios. This feedback is somewhat helpful as it identifies a potential area for improvement and encourages the authors to consider broader aspects of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these concerns or if it offered guidance on how to enhance the relevance of the proposed method in the context of LLMs. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the use of soft assignment instead of hard assignment. It notes that the methodology description mentions this, but questions whether the authors have reported an experiment to prove their conjecture. While the comment highlights a potential issue with the clarity of the explanation, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the methodology or provide evidence of an experiment supporting their conjecture. However, the comment lacks concrete details on how to implement this clarification or evidence, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"explanation of using soft assignment instead of har-assignment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in whether the authors have reported an experiment to prove their conjecture. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the explanation regarding the use of soft assignment instead of hard assignment. It questions whether the authors have reported an experiment to prove their conjecture, which is a logical and reasonable concern. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding the use of soft assignment instead of hard assignment in the methodology. It notes that while the explanation is provided, it is unclear whether the authors have reported an experiment to prove their conjecture. This feedback is clear and actionable, as it directs the authors to clarify their methodology or provide evidence supporting their claims. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to improve the explanation. Overall, the comment is mostly helpful as it highlights a critical area for clarification and improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the methods presented make sense mostly in the cross-silo setting, which limits their applicability to general federated learning problems with a relatively larger number of clients. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the methods presented make sense mostly in the cross-silo setting, which limits their applicability to general federated learning problems with a relatively larger number of clients. However, it does not specify which part of the paper discusses the methods or the cross-silo setting, making it difficult for the authors to identify the exact section being addressed. The comment is specific in detailing the limitation of the methods, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the methods presented make sense mostly in the cross-silo setting, which limits their applicability to general federated learning problems with a relatively larger number of clients. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. This feedback highlights a potential limitation of the methods, providing the authors with insight into the scope of their work. However, the comment does not offer suggestions or guidance on how the authors might address this limitation or improve the applicability of their methods. While it identifies a relevant issue, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges that the methods presented are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the methods presented are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, it does not specify which part of the paper discusses the methods or the cross-silo setting, making it difficult for the authors to identify the exact section being addressed. The comment is specific in detailing the limitation of the methods, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the methods presented are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the methods presented are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of clients. This feedback highlights a potential limitation of the methods, providing the authors with insight into the scope of their work. However, the comment does not offer suggestions or guidance on how the authors might address this limitation or improve the applicability of their methods. While it identifies a relevant issue, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges that the methods presented are mostly applicable in the cross-silo setting, which limits their generalizability to broader federated learning problems with a larger number of"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that interpolate training data. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or incorporate it into their work. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that interpolate training data. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to the discussion or analysis of distributional generalization, but this is not explicitly stated. The comment is specific in its question about the concept of distributional generalization in regression, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that interpolate training data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim, making it difficult to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that interpolate training data. While the comment identifies a potential area for clarification or further exploration, it does not provide specific guidance or suggestions on how the authors might address this issue or incorporate it into their work. The feedback lacks actionable steps or detailed insights, making it somewhat helpful. The authors may find it useful for gaining a deeper understanding of the concept but are left without clear direction for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that interpolate training data. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or incorporate it into their work. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that interpolate training data. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors might infer that it relates to the discussion or analysis of distributional generalization, but this is not explicitly stated. The comment is specific in its question about the concept of distributional generalization in regression, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that interpolate training data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim, making it difficult to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the concept of distributional generalization in the context of regression. It suggests that the phenomenon might be less surprising in a regression setting due to the nature of smooth regression models that"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the references and baselines are outdated and recommends including more recent research. It also provides a specific suggestion to search for items like \"Item Frequencies of Data Streams\" to find additional results. While the comment implies that the authors should update their references and baselines, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to update their references and baselines, but the comment lacks concrete guidance on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the references and baselines are outdated and recommends including more recent research. It also provides a specific suggestion to search for items like \"Item Frequencies of Data Streams.\" However, it does not specify which parts of the paper these references and baselines are mentioned in, making it difficult for the authors to identify the exact sections that need updating. The comment is specific in its suggestion to include more recent research and provides a clear direction for improvement, but it lacks grounding as it does not specify the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the references and baselines are outdated and recommends including more recent research. However, it does not provide specific examples or references to support the claim that the current references and baselines are outdated or why they should be updated. The comment lacks detailed reasoning or evidence to substantiate the need for these updates, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by noting that the references and baselines are outdated and suggests that more recent research should be included. It provides a clear and actionable suggestion to search for items like 'Item Frequencies of Data Streams' to find additional results. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered specific examples of recent research or detailed guidance on how to integrate these findings into the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a discrepancy between the introduction's emphasis on computational challenges in high-dimensional action spaces and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. While the comment implies that the authors should conduct additional experiments or analysis in high-dimensional spaces, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issue. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the introduction and Section 5, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the discrepancy between the introduction's emphasis on computational challenges in high-dimensional action spaces and the experimental analysis in Section 5, which focuses on lower-dimensional spaces. The comment also suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the introduction highlights the computational challenges of scaling quadratic programs to high-dimensional action spaces, while the experimental analysis in Section 5 primarily explores action constraints in relatively lower-dimensional spaces. The reviewer suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This claim is somewhat verifiable as it points out a discrepancy between the introduction and the experimental analysis, but it lacks specific examples or references to support the claim fully. The authors would need to infer the extent of the discrepancy and the potential benefits of deeper analysis, which makes the comment somewhat verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the introduction's emphasis on the computational challenges of scaling quadratic programs to high-dimensional action spaces and the experimental analysis in Section 5, which primarily explores action constraints in lower-dimensional spaces. It suggests that the performance of ARAM in high-dimensional action spaces, such as complex robotic manipulators, would benefit from more in-depth analysis. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by expanding its experimental analysis. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects should be explored. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of information regarding the computational requirements of the model, suggesting that the good results may be due to excessive parameters or computation. It implies that the authors should provide this information to better understand the model\\'s performance. However, the comment does not explicitly instruct the authors to include this information or provide specific guidance on how to measure and report the computational requirements. The action is implicit and somewhat vague, as the authors need to infer that they should include this information, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of information regarding the computational requirements of the model, specifically questioning whether the good results are due to excessive parameters or computation. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its critique, suggesting that providing the same computational resources as the original transformers could reveal the true performance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the good experimental results are likely due to excessive parameters or computation, suggesting that the authors should provide information on computational requirements. However, the comment lacks specific evidence or examples to support this claim, making it difficult for the authors to understand the basis of the assertion. The suggestion to compare the model with the original transformers is a logical step, but it does not provide a clear rationale or evidence for why this would be a meaningful comparison. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experimental results, specifically questioning the computational requirements needed to achieve good results. It suggests that the performance may be due to excessive parameters or computation, and it provides a specific suggestion for the authors to make their model have the same computational resources as the original transformers to better understand the performance. This feedback is clear and actionable, offering a concrete way for the authors to address the concern and improve the transparency and comprehensiveness of their results. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is mostly helpful, as it guides the authors towards a specific area for improvement and provides a clear direction for addressing the issue.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation and results are not convincing due to inconsistent trends and statistically insignificant improvements. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the presentation of their results. The comment lacks actionable details, such as recommending specific statistical tests or suggesting ways to enhance the consistency of the results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the evaluation and results sections, indicating that the results are not convincing due to inconsistent trends and statistically insignificant improvements. However, it does not specify which part of the paper these issues are found in, such as particular sections or figures. This lack of specificity makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment highlights a concern, it does not provide enough detail to be fully actionable. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the evaluation and results are not convincing due to inconsistent trends and statistically insignificant improvements. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant issue with the evaluation and results sections, noting that the results do not show consistent trends and some improvements are not statistically significant. This feedback is valuable as it highlights a critical area for improvement, allowing the authors to address potential weaknesses in their analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to enhance the consistency and significance of the results. Overall, the comment is somewhat helpful as it points out a significant issue but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the subjective nature of some questions and suggests that it would be useful to highlight the percentage of the error rate that is made up of subjective questions. The reviewer provides a specific action by suggesting to look at agreement among humans to determine this percentage. This explicit suggestion, along with the concrete guidance on how to address the issue, makes the comment highly actionable. The authors know exactly what action to take to improve their draft based on the feedback provided.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding subjective questions in the paper, suggesting that it would be useful to highlight the percentage of the error rate that is made up of subjective questions. The reviewer provides a concrete suggestion to look at agreement among humans to determine this percentage, which is a clear and specific action. This makes the comment fully grounded, as it explicitly mentions the subject of subjective questions, and specific because it provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the subjective nature of some questions and suggests that it would be useful to highlight the percentage of the error rate that is made up of subjective questions. The reviewer provides a logical reasoning by suggesting that looking at agreement among humans could determine this percentage, which would be problematic if it is significantly high. However, the comment lacks specific examples or references to support the claim about the percentage of subjective questions or the potential impact on the error rate. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the subjective nature of some questions in the paper and suggests that it would be useful to highlight the percentage of the error rate that is made up of subjective questions. The reviewer provides a specific action by suggesting to look at agreement among humans to determine this percentage, which could be problematic if it is significantly high. This feedback is clear and actionable, offering a concrete way for the authors to address the issue of subjectivity in their work. However, the comment could be more helpful if it provided additional context or examples of subjective questions or how they might impact the results. Overall, the comment is mostly helpful as it guides the authors towards a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the evaluation is weak due to the use of a single dataset and limited NLP tasks (intent recognition). It suggests that the paper would improve if additional NLP tasks such as sentiment classification and named-entity recognition were considered. This feedback is clear and provides a direct action for the authors to take, which is to expand the evaluation to include more NLP tasks. The suggestion is concrete and actionable, as it specifies the types of tasks that should be added. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the evaluation section of the paper, specifically mentioning the use of a single dataset and limited NLP tasks (intent recognition). This provides some grounding as the authors can identify the part of the paper being discussed, but it is not fully grounded because it does not specify which section or subsection this evaluation is in. The comment is specific in suggesting that additional NLP tasks like sentiment classification and named-entity recognition should be considered, which provides clear guidance on how to improve the evaluation. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is weak due to the use of a single dataset and limited NLP tasks (intent recognition). The reviewer suggests that the paper would improve if additional NLP tasks such as sentiment classification and named-entity recognition were considered. However, the comment lacks specific examples or references to support the claim that these additional tasks would enhance the evaluation. While the suggestion is logical, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the evaluation section of the paper, noting that it is based on a single dataset and limited NLP tasks (intent recognition). The reviewer suggests that the paper would benefit from considering additional NLP tasks such as sentiment classification and named-entity recognition. This feedback is clear and actionable, as it provides specific suggestions for expanding the evaluation to enhance the paper\\'s comprehensiveness and robustness. By offering concrete examples of additional tasks, the comment empowers the authors to make meaningful improvements to their draft. However, the comment could be more helpful if it included specific guidance on how to integrate these additional tasks or what benefits they might bring to the evaluation. Overall, the comment is mostly helpful, as it directs the authors toward a clear area for improvement and provides a solid foundation for enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a specific change to the labeling of \"class semantic feature\" in Figure 3, recommending that it be labeled as \"s\" instead of \"c\". This is an explicit and concrete action, as it provides a clear and specific instruction for the authors to make the necessary change. The comment does not require any inference or interpretation from the authors, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the labeling of \"class semantic feature,\" suggesting that it should be labeled as \"s\" instead of \"c.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a specific change to the labeling of \"class semantic feature\" in Figure 3, recommending that it be labeled as \"s\" instead of \"c.\" However, the comment does not provide any reasoning or justification for this suggestion, nor does it offer any context or explanation as to why this change is necessary or beneficial. Without additional information or evidence, the claim lacks verifiability, as it does not help the authors understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the labeling of \"class semantic feature\" in Figure 3, recommending that it be labeled as \"s\" instead of \"c.\" This feedback is clear and directly addresses a potential issue with the figure, offering a straightforward way for the authors to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it explained why this change is necessary or how it might impact the interpretation of the figure. Despite this, the feedback is mostly helpful as it guides the authors in making a specific and beneficial change to their draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a distinction between de-identification and face swapping, noting that the method proposed in the paper is essentially a form of face swapping. It suggests that the authors should compare their method with state-of-the-art face swapping algorithms. While the comment implies that the authors should conduct a comparison, it does not provide explicit instructions on how to perform this comparison or which specific algorithms to consider. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the distinction between de-identification and face swapping, specifically noting that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology. It suggests that the authors should compare their method with state-of-the-art face swapping algorithms. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodological approach and comparison with existing techniques. The authors can infer that it relates to the methodology section, but the comment does not provide explicit references to specific parts of the paper. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology, and suggests that the authors should compare their method with state-of-the-art face swapping algorithms. The claim is based on the observation that the key difference between the proposed method and deepfake technology is the source of the target face (3DMM vs. real individual), which does not create a clear distinction. The reviewer provides a logical reasoning for the claim, suggesting that the authors should conduct a comparison to clarify the distinction. However, the comment lacks specific references or examples of state-of-the-art face swapping algorithms, which would further strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a distinction between de-identification and face swapping, noting that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology. It suggests that the authors should compare their method with state-of-the-art face swapping algorithms to clarify the distinction. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by conducting a comparison with relevant algorithms. However, the comment could be more helpful if it included specific examples of state-of-the-art face swapping algorithms or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for maximum benefit.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not as compelling as those on Gaussian embeddings, which is the chief baseline from the literature. However, it does not provide specific guidance on how the authors might improve the results or what aspects of the word embeddings need further exploration or analysis. The comment lacks explicit instructions or concrete suggestions for addressing the issue, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results on word embeddings compared to Gaussian embeddings, which is the chief baseline from the literature. This provides clear guidance on what needs to be addressed in the tables. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not as compelling as those on Gaussian embeddings, which is the chief baseline from the literature. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experimental results, noting that the results on word embeddings in Tables 1 and 2 are not as compelling as those on Gaussian embeddings, which is the chief baseline from the literature. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the results or address the perceived lack of compellingness. To be more helpful, the comment could include suggestions for further analysis or improvements to the experimental setup. Therefore, the comment is rated as somewhat helpful, as it points out a weakness but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method does not seem to differ significantly from previous studies, except for a change in the task and reward function. It suggests that the contribution is small if this is the only difference. However, the comment does not provide specific guidance or suggestions on how the authors could enhance the contribution or differentiate their work from previous studies. The feedback lacks actionable details, leaving the authors without a clear path to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method, specifically mentioning that it does not seem to differ from previous studies, such as Shi et al., 2018, and Ghosh et al., 2021. It highlights the similarity in the methods, except for a change in the task and reward function, and questions the contribution of the work. However, the comment does not specify which part of the paper discusses these methods or the proposed changes, making it weakly grounded. The comment is specific in identifying the issue of similarity and the need for a more significant contribution, but without explicit references to the paper, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is not significantly different from previous studies, except for a change in the task and reward function, and questions the contribution of the work. The reviewer provides references to previous studies, which supports the claim by allowing the authors to compare their work with existing literature. However, the comment could be strengthened by providing more detailed reasoning or examples of how the proposed method differs from the previous studies. Overall, the comment is mostly verifiable, as it provides a basis for the claim but could be more robust with additional evidence or analysis.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed method, noting that it does not seem to differ significantly from previous studies, except for a change in the task and reward function. The reviewer questions the contribution of the work, suggesting that the change in task and reward function may not be enough to justify a new contribution. This feedback is somewhat helpful as it points out a potential weakness in the paper's novelty and encourages the authors to consider whether there are additional aspects of their work that could be highlighted. However, the comment could be more helpful if it provided specific suggestions on how the authors might differentiate their work or enhance its contribution. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects of the paper could be improved. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, it does not specify which parts of the paper are being addressed or what specific aspects of the novelty are perceived as limited. This lack of grounding makes it difficult for the authors to identify the exact parts of the paper that need revision. The comment is specific in identifying the main contribution as a new dataset, but it does not provide detailed guidance on how to enhance the novelty of the work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific references, examples, or detailed explanations, the authors are left without a clear understanding of the basis for this critique. As a result, the claim is unverifiable, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the novelty of the paper is limited and that the main contribution is a new IT-related dataset. While it identifies a potential issue with the novelty of the work, it lacks specific details or suggestions on how the authors might enhance the novelty or address the perceived limitations. The comment provides a general observation but does not offer actionable feedback or guidance on how to improve the draft. As a result, the comment is somewhat helpful, as it highlights an area for potential improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks an ablation study related to query embedding, suggesting that such a study would provide insights into the significance and impact of this component. This feedback is clear and direct, giving the authors a specific action to take: conduct an ablation study on query embedding. The comment provides a concrete suggestion on what needs to be added to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ablation study\" and \"query embedding,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing: an ablation study related to query embedding, which would provide insights into the significance and impact of this component. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study related to query embedding, which would provide insights into the significance and impact of this component. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why such an ablation study is necessary or how it would enhance the paper. Without additional context or explanation, the claim remains unverifiable, as it lacks the necessary details to help the authors understand the importance of this suggestion or how to address it. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth: an ablation study related to query embedding. This feedback is clear and actionable, as it points out a gap in the analysis that could provide valuable insights into the significance and impact of this component. By suggesting the inclusion of an ablation study, the comment offers a concrete way for the authors to enhance the depth and rigor of their analysis. However, the comment could be more helpful if it provided additional guidance on how to conduct such a study or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works, referencing specific references [1, 2, 3]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their contribution. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the paper compared to previous works, referencing specific references [1, 2, 3]. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution are considered marginal. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which part needs improvement. Additionally, the comment lacks specificity in detailing what aspects of the contribution are marginal or how they compare to previous works. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion that the contribution is marginal compared to previous works, referencing specific references [1, 2, 3]. However, the comment does not provide any reasoning, evidence, or detailed comparison to support the claim that the contribution is marginal. Without additional context or justification, the authors may find it challenging to understand the basis of this opinion. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses an opinion that the contribution is marginal compared to previous works, referencing specific references [1, 2, 3]. However, it does not provide any specific feedback or suggestions on how the authors might address this concern or improve their contribution. Without actionable guidance or detailed critique, the comment lacks value for the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential issue but does not offer constructive feedback or suggestions for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider in their response. Without actionable advice or suggestions, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the loss of performance of w2gm against w2g in the analysis of SWCS. However, it does not specify which part of the paper this analysis is discussed in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in asking for an explanation of the performance loss, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question posed by the reviewer, seeking clarification on the performance loss of w2gm against w2g in the analysis of SWCS. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question to the authors regarding the loss of performance of w2gm against w2g in the analysis of SWCS. While it identifies a specific area for clarification, it does not provide any guidance or suggestions on how the authors might address this issue or what aspects of the analysis could be improved. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper discusses overoptimization as a motivation but does not directly evaluate it. It suggests that the evaluation should focus on calibration and human evaluation instead. The reviewer also mentions that current works often address overoptimization issues with early stopping, such as AlignProp, and recommends that the paper should evaluate without early stopping to explore the tradeoffs of the proposed solutions. Additionally, the comment suggests discussing the benefits of not doing early stopping. While the comment provides a clear direction for improvement, it does not specify how the authors should implement these suggestions or what specific aspects of the evaluation should be changed. The action is explicit but somewhat vague, as it does not provide detailed guidance on how to carry out the suggested evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper talks about overoptimization as the motivation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should directly evaluate for overoptimization, calibration, and human evaluation, and mentions the current practice of using early stopping to address overoptimization issues. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s evaluation, specifically questioning why it does not directly evaluate for overoptimization. The reviewer suggests that the paper should evaluate for calibration and human evaluation instead, and mentions that current works often address overoptimization issues with early stopping, such as AlignProp. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the paper should evaluate for overoptimization. While the suggestion is logical and based on common practices in the field, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper\\'s evaluation, specifically noting that the paper discusses overoptimization as a motivation but does not directly evaluate for it. It suggests that the evaluation should focus on calibration and human evaluation instead. The reviewer also points out that current works often address overoptimization issues with early stopping, such as AlignProp, and recommends that the paper should evaluate without early stopping to explore the tradeoffs of the proposed solutions. Additionally, the comment suggests discussing the benefits of not doing early stopping. This feedback is clear and actionable, providing the authors with specific areas to address and improve upon. By offering detailed guidance on how to enhance the evaluation and discussion, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include an analysis demonstrating the equivalence of the proposed TW model to TR, specifically by showing how the core tensor C can be represented as a TR and how this fusion with the cores G_n leads to a TR representation equivalent to the TW model. The reviewer also requests a discussion justifying the use of TW over TR. While the action is explicit, the comment does not provide detailed guidance on how to conduct this analysis or what specific aspects should be emphasized in the discussion. The authors are given a clear direction but may need to infer the exact steps to take, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the proposed TW model is equivalent to TR, and it provides a specific analysis of how this equivalence can be demonstrated by representing the core tensor C as a TR and fusing it with the cores G_n. This analysis is clearly specified, providing the authors with a concrete understanding of what needs to be addressed. The comment also requests a discussion justifying the use of TW over TR, which further clarifies the issue. However, the comment does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed TW model is equivalent to TR, and it provides a specific analysis of how this equivalence can be demonstrated by representing the core tensor C as a TR and fusing it with the cores G_n. This analysis is supported by logical reasoning, as it explains the equivalence between the two models. However, the comment could be strengthened by providing more detailed examples or references to existing literature that support the equivalence claim. The suggestion to include a discussion justifying TW over TR adds depth to the feedback, but it is not fully verifiable due to the lack of specific examples or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential equivalence between the proposed TW model and TR, suggesting that the authors should include an analysis demonstrating this equivalence. It provides a specific suggestion for the authors to represent the core tensor C as a TR and discuss how this fusion with the cores G_n leads to a TR representation equivalent to the TW model. Additionally, the comment requests a discussion justifying the use of TW over TR. This feedback is clear and actionable, offering the authors a concrete direction for improving their draft by clarifying the relationship between their proposed model and existing TR models. However, the comment could be more helpful if it provided additional guidance on how to present this analysis or discussed the implications of this equivalence. Overall, the comment is mostly helpful, as it provides valuable insights and suggestions for enhancing the paper's clarity and depth.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the transferability of their toolset and experiment to create a general toolset for all tasks. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for further experimentation, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the transferability of the toolset, specifically mentioning that the toolset for the VQA task and the toolset for the reasoning task are not the same. This provides some grounding as it allows the authors to identify the relevant part of the paper, but it does not specify which sections or figures are being discussed. The comment is specific in suggesting that the authors should experiment to create a general toolset for all tasks, but it lacks detailed guidance on how to conduct these experiments or what aspects to focus on. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the toolset for the VQA task and the toolset for the reasoning task are not the same, implying that the authors should discuss the transferability of their toolset. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the transferability of the toolset, noting that the toolset for the VQA task and the toolset for the reasoning task are not the same. It suggests that the authors should discuss this transferability and experiment to create a general toolset for all tasks. This feedback is somewhat helpful as it points out a gap in the current work and offers a direction for improvement. However, it lacks specific guidance on how to conduct the experiments or what aspects of the toolset should be considered for transferability. To be more helpful, the comment could provide more detailed suggestions or examples of how to approach this issue. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this approach could help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the comment implies an action, it does not explicitly instruct the authors to implement this suggestion or provide detailed guidance on how to conduct the evaluation. The action is somewhat implicit and concrete, as the authors can infer the need for a specific evaluation method but may need to work out the details themselves. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this approach could help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. However, the comment does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a method to evaluate the impact of feature order variability, but without explicit grounding, it is challenging for the authors to fully understand the context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the model\\'s performance using multiple random feature orders to assess the impact of feature order variability. It implies that this approach could help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. While the suggestion is logical and could be beneficial, it lacks specific examples or references to support the claim that duplicating information is a concern. The comment provides a general idea but does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests evaluating the model's performance using multiple random feature orders to assess the impact of feature order variability. This approach could help determine if the benefits of feature reordering are due to the specific order found by the meta-controller or can be achieved by exposing the model to diverse orders. The suggestion is clear and provides a specific method for evaluating the model's performance, which could be beneficial for the authors to consider. However, the comment could be more helpful if it included additional guidance on how to implement this evaluation or discussed the potential implications of the results. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the related work section is severely lacking and mentions a specific area of omission, namely lexically constrained decoding methods. It also suggests that these methods should be included both in the related work section and as baselines for comparison. This provides a clear and direct action for the authors to take, which is to add these references and methods to their draft. The comment is explicit and concrete, giving the authors a clear path forward in improving their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the related work section, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the severe lack of references and the omission of lexically constrained decoding methods, both in the related work section and as baselines for comparison. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section is severely lacking, particularly for omitting lexically constrained decoding methods. However, the comment does not provide specific examples or references of these methods, nor does it explain why their inclusion is crucial. This lack of detail makes it difficult for the authors to understand the extent of the issue or how to address it. As a result, the claim is barely verifiable, as it requires additional information to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the related work section of the paper, specifically noting that it lacks references to lexically constrained decoding methods. This is a critical omission, as these methods are relevant to the field and could provide valuable context for the paper. The comment is clear and actionable, as it directs the authors to include these references both in the related work section and as baselines for comparison. By addressing this feedback, the authors can enhance the comprehensiveness and relevance of their paper. However, the comment could be more helpful if it provided specific examples of lexically constrained decoding methods or suggested how to integrate them into the paper. Overall, the comment is mostly helpful, as it highlights a significant gap in the paper and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison is not comprehensive due to the absence of important baseline models and datasets. It explicitly mentions two specific references, SimVLM and OFA, which the authors should consider including for a more comprehensive comparison. This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what needs to be done to improve their draft by adding these references to their comparison. Therefore, the comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper\\'s comparison, noting that important baseline models and datasets are missing. It explicitly mentions two references, SimVLM and OFA, which the authors should consider including for a more comprehensive comparison. This provides full grounding, as the authors can accurately identify the parts of the paper being addressed, and it is specific because it clearly specifies what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. It provides specific references, SimVLM and OFA, which the authors should consider including for a more comprehensive comparison. This provides a clear and logical basis for the claim, making it fully verifiable. The references to specific works support the assertion that these models and datasets are important for a comprehensive comparison, ensuring that the authors can effectively address the feedback. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s comparison, noting that important baseline models and datasets are missing, which makes the comparison incomplete. It provides specific references, SimVLM and OFA, which the authors should consider including for a more comprehensive comparison. This feedback is clear and actionable, offering the authors a direct path to improve the comprehensiveness of their work. By addressing this feedback, the authors can enhance the robustness and relevance of their study. Therefore, the comment is rated as highly helpful, as it provides valuable guidance for improving the draft.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the manuscript is framed as a dataset paper but does not present new data. It clarifies that the paper presents derivative data, specifically 3D pose estimates from existing datasets. This feedback highlights a discrepancy between the paper\\'s framing and its actual content, which could be disappointing for readers expecting new data. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the paper. The action is implicit and vague, as the authors are left to infer that they need to clarify the paper\\'s focus or provide additional context. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the framing of the manuscript as a dataset paper, specifically pointing out that there is no new data collected or released, and that the paper presents derivative data, such as 3D pose estimates from existing datasets. This feedback is fully grounded as it explicitly mentions the \"derivative data\" aspect, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper\\'s framing and the nature of the data presented. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the manuscript is framed as a dataset paper but does not present new data, which is disappointing for readers. The reviewer supports this claim by stating that the paper presents derivative data, specifically 3D pose estimates from existing datasets. This provides a clear and logical explanation of why the claim is valid, making the comment mostly verifiable. However, the comment could be strengthened by providing specific examples or references to existing datasets used for comparison, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the manuscript\\'s framing as a dataset paper and the actual content, which does not present new data but rather derivative data from existing datasets. This feedback is clear and actionable, as it highlights a significant issue that the authors should address to align their paper\\'s claims with its actual content. By pointing out this discrepancy, the comment provides a clear direction for the authors to improve the clarity and accuracy of their paper. However, it could be more helpful if it offered suggestions on how to reframe the paper or what additional information could be included to make it more valuable. Overall, the comment is mostly helpful as it effectively guides the authors in addressing a critical issue in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods require a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their analysis. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods require a specific learning rate schedule for experiments on CIFAR and Face Verification. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section being addressed. The comment lacks specificity in detailing what aspects of the critique are problematic or how the authors might address it. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods require a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the authors\\' critique is unfounded. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary details for the authors to understand and address the critique effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors for their criticism of L-softmax and A-softmax, noting that these methods require a specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any additional context, reasoning, or suggestions on how the authors might address this critique or improve their analysis. Without actionable feedback or specific guidance, the comment fails to offer meaningful assistance to the authors in enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the analysis of results and the importance of certain features, such as the handle, in detecting a chair. It suggests that the authors should consider the consistency and prominence of features across a wide range of chairs. While the comment implies that the authors should explore these aspects, it does not provide explicit instructions or concrete steps on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"quantitative and qualitative analysis\" and the \"comparison between AE to diffusion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the analysis of results and asks for clarification on what elements are crucial for detecting a chair, such as the handle, and whether it is consistent across a wide range of chairs. The comment provides clear guidance on what aspects need further exploration or clarification, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the analysis of results and the importance of certain features, such as the handle, in detecting a chair. It suggests that the authors should consider the consistency and prominence of features across a wide range of chairs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the analysis is primarily focused on the comparison between AE and diffusion. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the focus of the analysis, which is primarily on the comparison between AE and diffusion, rather than on the analysis of the results themselves. It questions the authors\\' approach and suggests that they should consider the visualizations to determine which elements are crucial for detecting a chair, such as the handle. The comment provides a clear direction for the authors to explore, encouraging them to expand their analysis to include the consistency and prominence of features across a wide range of chairs. This feedback is actionable and could significantly enhance the paper by guiding the authors to a more comprehensive analysis. However, the comment could be more helpful if it included specific suggestions or examples of how to conduct this analysis. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential error in the text, suggesting that the phrase \"at least\" should be replaced with \"at most\" in the beginning of Section 2.2. It provides a specific example of the worst-case scenario, where the competitive ratio would be b, and explains that this is consistent with the rest of the cases where the ratio is either b/x or eventually 1. This feedback is explicit and provides a clear action for the authors to correct the text, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"beginning of Section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, suggesting that the phrase \"at least\" should be replaced with \"at most\" and providing a detailed explanation of the reasoning behind this correction. The comment includes a specific example to illustrate the point, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific claim about the text in Section 2.2, suggesting that the phrase \"at least\" should be replaced with \"at most.\" It provides a detailed explanation of the reasoning behind this claim, using a specific example to illustrate the issue. The reviewer explains that the worst-case scenario would be x=1, where the ratio would be b, and that in all other cases, the ratio is either b/x or eventually 1. This detailed explanation supports the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific error in the text of Section 2.2, suggesting that the phrase \"at least\" should be replaced with \"at most.\" It provides a detailed explanation of the reasoning behind this correction, using a specific example to illustrate the issue. By highlighting this error and offering a clear correction, the comment is highly helpful as it empowers the authors to make a significant improvement in their draft. The feedback is actionable and provides a clear path for the authors to enhance the accuracy and clarity of their work. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification about the notation \"D^{alpha}_{x}\" in Theorem.1, specifically whether it denotes the derivatives of the probabilistic measure \\mu. This request is direct and specific, providing the authors with a clear action to take: to clarify the notation in their draft. The comment is explicit and concrete, as it directly instructs the authors on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification about the notation \"D^{alpha}_{x}.\" This question specifies what needs to be addressed in terms of understanding the notation, providing clear guidance to the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification about the notation \"D^{alpha}_{x}\" in Theorem.1, asking whether it denotes the derivatives of the probabilistic measure \\mu. This is a factual question seeking clarification and does not contain any subjective opinions, claims, or suggestions. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly actionable as it explicitly requests clarification about a specific notation, \"D^{alpha}_{x}\", in Theorem.1. This feedback is clear and direct, guiding the authors to address a potential source of confusion in their draft. By providing a specific question, the reviewer helps the authors improve the clarity and understanding of their work. This level of detail and specificity makes the comment highly helpful, as it empowers the authors to make a direct and impactful improvement to their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the third face image in Figure 2 is missing a proper expression. This provides a clear and direct action for the authors to take, which is to ensure that the expression for the third face image is included in the figure. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing proper expression for the third face image. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual observation about the missing expression for the third face image in Figure 2. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the third face image in Figure 2, noting that it is missing a proper expression. This feedback is clear and actionable, as it directs the authors to ensure that the expression is included in the figure. However, the comment could be more helpful if it provided suggestions on how to include the expression or what type of expression is expected. Overall, the comment is mostly helpful as it highlights a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. While the comment implies that this comparison could be beneficial, it does not explicitly instruct the authors to make this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison and how to execute it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section, table, or figure. Without explicit references, the authors may find it challenging to determine where to incorporate this suggestion. Additionally, the comment lacks specificity as it does not provide details on what aspects of the example or comparison should be emphasized or how they could enhance the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any reasoning, evidence, or justification for why this comparison would be beneficial or how it could improve the paper. Without specific examples or explanations, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This is a specific and actionable suggestion that could potentially enhance the paper by providing a clearer understanding of the proposed model\\'s performance compared to a well-known baseline. However, the comment does not provide further details or guidance on how to implement this suggestion, such as which specific aspects of the example should be highlighted or how the comparison could be structured. While the suggestion is clear, it lacks depth and could be more helpful with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the dataset size of Vault and CSN should be the same for the code summarization and code search tasks to demonstrate that Vault is better in terms of data quality than CSN. This is an explicit action that provides a clear direction for the authors to take, as it specifies what needs to be done to address the issue. The comment is concrete, as it outlines a specific change that would improve the comparison between the datasets. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the dataset size of Vault and CSN should be the same for the code summarization and code search tasks to demonstrate that Vault is better in terms of data quality than CSN. However, it does not specify which part of the paper discusses these tasks or the datasets, making it weakly grounded. The comment is specific in its suggestion to address the issue of dataset size, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset size of Vault and CSN should be the same for the code summarization and code search tasks to demonstrate that Vault is better in terms of data quality than CSN. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it would impact the comparison between the datasets. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the dataset size of Vault and CSN should be the same for the code summarization and code search tasks to demonstrate that Vault is better in terms of data quality than CSN. This feedback is clear and actionable, as it provides a specific recommendation for improving the comparison between the datasets. By addressing this suggestion, the authors can enhance the validity of their results and make their paper more robust. However, the comment could be more helpful if it explained why this is a critical issue or provided additional context on how the dataset size affects the comparison. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific concepts that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" It suggests that these terms should be explained more carefully, implying that the authors should provide clarifications or definitions for these concepts. While the comment does not explicitly instruct the authors to do so, the action is clear and concrete, as the authors know exactly what needs to be addressed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies specific concepts that are not explained well in the paper, such as \"action-repeat\" and \"dithering phenomenon.\" However, it does not specify which sections or parts of the paper these terms appear in, making it difficult for the authors to pinpoint the exact areas that need improvement. While the authors can infer that these terms are related to the methodology or results sections, the comment lacks full grounding. It is specific in identifying the need for clarification on these concepts, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some important concepts are not explained well in the paper, specifically mentioning \"action-repeat\" and \"dithering phenomenon.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity, particularly regarding the concepts of \"action-repeat\" and \"dithering phenomenon.\" It suggests that these terms should be explained more carefully, implying that the authors should provide clarifications or definitions for these concepts. While the comment highlights a critical issue, it lacks depth and does not offer specific suggestions or examples on how to improve the explanations. This limits its helpfulness, as the authors may find it challenging to fully address the feedback without additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a specific alternative approach to the current method, where the authors create an instruction embedding g(f(s)) from the state encoding f(s) and pass it directly to the executor. It also proposes adding an auxiliary objective to bring g(f(s)) closer to the gold instruction encoding. This feedback provides a clear and concrete action for the authors to consider, as it outlines a specific change to the current method and suggests a potential improvement. The comment is explicit in its suggestion and provides a detailed rationale for the proposed change, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests an alternative approach to the current method, where the authors create an instruction embedding g(f(s)) from the state encoding f(s) and pass it directly to the executor. It also proposes adding an auxiliary objective to bring g(f(s)) closer to the gold instruction encoding. While the comment does not explicitly mention a specific part of the paper, it is clear that it relates to the method or approach described in the paper. The authors can infer that it pertains to the sections discussing the current method or the proposed changes. The comment is specific in detailing the suggested changes and their potential benefits, providing clear guidance on how to improve the current approach. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an alternative approach to the current method, proposing to create an instruction embedding g(f(s)) from the state encoding f(s) and pass it directly to the executor. The reviewer claims that this approach might work better as it avoids discretization and potential errors in decoding. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that this approach would be more effective. The suggestion is based on a logical argument about the potential benefits of avoiding discretization, but without further evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a constructive suggestion for improving the current method by proposing an alternative approach. It suggests creating an instruction embedding g(f(s)) from the state encoding f(s) and passing it directly to the executor, rather than generating text and then re-encoding it. Additionally, the comment suggests adding an auxiliary objective to bring g(f(s)) closer to the gold instruction encoding. This feedback is clear and actionable, offering a specific way to enhance the current method and potentially improve its performance. By providing a detailed suggestion with a rationale, the comment is highly helpful, as it empowers the authors to make significant improvements to their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the novelty of the proposed model is not significant, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of the model could be improved to enhance its novelty. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the novelty of the proposed model is not significant, but it does not specify which part of the paper this assessment is based on. The authors cannot determine which section or aspect of the model is being evaluated for novelty. Additionally, the comment lacks specificity regarding what aspects of the model are considered unnovel or how the authors might address this issue. Without clear grounding or specific guidance, the authors are unable to understand what needs to be revised or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the proposed model is not significant, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without any justification or examples, the authors are left without guidance on how to address the issue or improve the novelty of their model. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a concern about the novelty of the proposed model, stating that it is not significant. However, it lacks any specific details or examples to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without actionable feedback or suggestions for improvement, the comment does not provide the authors with a clear path to enhance their draft. Therefore, it is rated as not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses a concern about the novelty of the proposed model, stating that it is not significant. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their model or what specific aspects need improvement. Without actionable suggestions or directions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the proposed model, stating that it is not significant. However, it does not specify which part of the paper this assessment is based on, making it difficult for the authors to identify the specific section or aspect being addressed. Additionally, the comment lacks specificity regarding what aspects of the model are considered unnovel or how the authors might enhance its novelty. Without clear grounding or detailed guidance, the authors are unable to understand what needs to be revised or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the novelty of the proposed model is not significant, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without any justification or examples, the authors are left without guidance on how to address the issue or improve the novelty of their model. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses a concern about the novelty of the proposed model, stating that it is not significant. However, it lacks any specific details, examples, or suggestions for improvement, making it difficult for the authors to understand the basis of the critique or how to address it. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment expresses a concern about the novelty of the proposed model, stating that it is not significant. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their model or what specific aspects need improvement. Without actionable suggestions or directions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the proposed model, stating that it is not significant. However, it does not specify which part of the paper this assessment"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class used for the pool subset makes the dataset easier rather than harder. It points out that the accuracy might not be a good measure of the quality due to the imbalance in class distribution. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their analysis. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the dataset\\'s class distribution, specifically the proportion of each class used for the pool subset. It suggests that this distribution makes the dataset easier rather than harder, as it reduces ambiguity between similar classes. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the dataset description or analysis, but this inference is not explicit. The comment is specific in detailing the issue with the dataset\\'s class distribution and its impact on accuracy as a measure of quality. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class makes the dataset easier rather than harder. The reviewer provides a specific example of the class distribution, noting that there are very few observations of 9, a few of 6, and 5 times less 7 than 1. This observation implies that the accuracy might not be a good measure of the quality due to the imbalance in class distribution. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the reviewer provides a logical argument, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the dataset\\'s class distribution, suggesting that the proportion of each class used for the pool subset makes the dataset easier rather than harder. It points out that the accuracy might not be a good measure of the quality due to the imbalance in class distribution, particularly noting the low frequency of certain classes. This feedback is somewhat helpful as it identifies a potential issue with the dataset that could affect the results and suggests that the authors consider alternative measures of quality. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or alternative measures to consider. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the reviewer\\'s agreement with the statement \"prediction is not done in isolation\" but questions the main contribution of the paper regarding the \"task of prediction may have strategic aspects.\" The reviewer asks for clarification on the \"true\" payoff in Table 1 and suggests looking into Vapnik\\'s work on teaching a learner with side information. While the comment identifies areas for improvement and provides specific references, it does not explicitly instruct the authors on how to address these issues or what changes to make. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the payoff in Table 1 and consider Vapnik\\'s work, but the comment lacks concrete guidance on how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that \"prediction is not done in isolation\" and questions the main contribution of showing that the \"task of prediction may have strategic aspects.\" It also asks for clarification on the \"true\" payoff in Table 1 and suggests looking into Vapnik\\'s work on teaching a learner with side information. However, the comment does not specify which part of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the discussion or results sections, but this is not explicitly mentioned. The comment is specific in its questions and suggestions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the reviewer\\'s agreement with the statement \"prediction is not done in isolation\" but questions the main contribution of the paper regarding the \"task of prediction may have strategic aspects.\" The reviewer asks for clarification on the \"true\" payoff in Table 1 and suggests looking into Vapnik\\'s work on teaching a learner with side information. While the comment raises valid points and provides references for further exploration, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to look into Vapnik\\'s work is a logical extension but could be strengthened with more detailed references or explanations. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the reviewer's agreement with the statement 'prediction is not done in isolation' but questions the main contribution of the paper regarding the 'task of prediction may have strategic aspects.' It prompts the authors to clarify the 'true' payoff in Table 1 and suggests looking into Vapnik's work on teaching a learner with side information. While the comment identifies areas for improvement and provides references for further exploration, it lacks specific guidance on how to address these issues or what changes to make. The feedback is somewhat helpful as it points out areas that need clarification but does not offer detailed suggestions or actionable steps for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore another unsupervised domain adaptation (UDA) method based on self-training, given that self-training is a prominent and effective approach in the field. While the comment implies that the authors should consider this alternative method, it does not provide explicit guidance on how to implement or integrate it into their work. The action is implicit and somewhat vague, as the authors need to infer that they should explore another UDA method based on self-training. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, given that self-training is a prominent and effective approach in the field. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or method. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting an alternative method, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the proposed method focuses solely on domain-alignment methods and recommends exploring another UDA method based on self-training. However, the comment does not provide any specific reasoning, examples, or references to support why this is a significant issue or why another method would be more effective. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the proposed method, which focuses solely on domain-alignment methods. It suggests exploring another unsupervised domain adaptation (UDA) method based on self-training, which is a prominent and effective approach in the field. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in improving their work. By suggesting an alternative method, the comment offers a valuable perspective that could enhance the scope and effectiveness of the proposed approach. However, the comment could be more helpful if it provided additional context or guidance on how to integrate self-training into the existing framework. Overall, the comment is mostly helpful, as it directs the authors to a potential area of improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliability diagrams, specifically the accuracy vs confidence plots (Fig 1, top), which are not supportive of the proposed methods. It questions whether these pathologies are due to dataset issues or variance in the proposed methods. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to investigate and possibly correct the issues with the reliability diagrams. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the reliability diagrams, specifically the \"high-accuracy spikes in low confidence regimes,\" and questions whether this is a property of the dataset or a reflection of variance in the proposed methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability diagrams, specifically the accuracy vs confidence plots (Fig 1, top), which are not supportive of the proposed methods. It questions whether these pathologies are due to dataset issues or variance in the proposed methods. The comment provides a logical reasoning by pointing out the \"high-accuracy spikes in low confidence regimes,\" which is a common issue in reliability diagrams. However, it lacks specific examples or references to support the claim that these pathologies are a result of dataset issues or variance in the methods. This makes the claim somewhat verifiable, as it provides a basis for questioning but requires further elaboration or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the reliability diagrams, noting that they do not support the proposed methods and exhibit notable pathologies, such as high-accuracy spikes in low confidence regimes. It raises a question about whether these issues are due to dataset pathologies or variance in the proposed methods. This feedback is somewhat helpful as it points out a potential weakness in the paper's presentation and encourages the authors to investigate and address this issue. However, the comment could be more helpful if it provided suggestions on how to resolve the identified problem or offered alternative approaches to improve the reliability diagrams. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the paper\\'s evaluation, specifically that it does not consider the possibility of more advanced attacks by the attacker. It suggests that the paper should evaluate the effectiveness of the proposed method against a wider range of attacks, including the scenario where the attacker fine-tunes on a partial subset of the dataset. The comment also points out that the paper does not discuss other state-of-the-art (SOTA) methods for backdoor removal. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific aspects of the evaluation should be expanded. The authors are left with a general understanding of what needs to be added but without concrete steps on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a potential limitation in the paper\\'s evaluation, specifically the lack of consideration for more advanced attacks by the attacker. It highlights a scenario where the attacker could fine-tune on a partial subset of the dataset, which could still contain the poisoned data, making it difficult for the customer to verify misbehaviors. The comment also points out that the paper does not discuss state-of-the-art (SOTA) methods for backdoor removal. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the discussion on evaluation methods. While the authors can infer that it pertains to the evaluation section, the comment lacks explicit grounding. The specificity is clear as it identifies a gap in the paper\\'s evaluation and suggests areas for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s evaluation, specifically regarding the potential for more advanced attacks by the attacker. It highlights a scenario where the attacker could fine-tune on a partial subset of the dataset, which could still contain the poisoned data, making it difficult for the customer to verify misbehaviors. The comment also points out that the paper does not discuss state-of-the-art (SOTA) methods for backdoor removal. While the claim is logical and based on common knowledge about the limitations of evaluating against specific attacks, it lacks specific references or examples to fully substantiate the claim. The authors would need to infer the relevance of these points to their work, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's evaluation, specifically the lack of consideration for more advanced attacks by the attacker. It highlights a scenario where the attacker could fine-tune on a partial subset of the dataset, which could still contain the poisoned data, making it difficult for the customer to verify misbehaviors. The comment also points out that the paper does not discuss state-of-the-art (SOTA) methods for backdoor removal. While the comment raises important issues that the authors should address, it lacks specific suggestions or guidance on how to incorporate these considerations into the paper. The feedback is somewhat helpful as it points out areas for improvement but does not provide detailed actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the use of the original GCN (Kipf and Welling) in the paper and the conventional graph convolutional operation. It questions the reason for not using the normalized adjacency matrix with renormalization trick, as mentioned in the original GCN. While the comment implies that the authors should provide an explanation or conduct an ablation study to justify their choice, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional context or evidence for their decision. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of the original GCN (Kipf and Welling) and the difference in the adjacency matrix used compared to the conventional graph convolutional operation. It explicitly mentions the original GCN and the adjacency matrix, providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the reason for not using the conventional graph convolutional operation and suggests an explanation or ablation study. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of the original adjacency matrix without explanation or ablation study, referencing the normalized adjacency matrix with renormalization trick used in the original GCN (Kipf and Welling). The comment implies that there might be a reason for not using the conventional graph convolutional operation, but it does not provide specific reasoning or evidence to support this claim. The authors are left to infer that there is a reason for the choice, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a discrepancy in the use of the original GCN (Kipf and Welling) compared to the conventional graph convolutional operation. It questions the reason for not using the normalized adjacency matrix with renormalization trick, as mentioned in the original GCN, and suggests that the authors should provide an explanation or conduct an ablation study to justify their choice. This feedback is clear and actionable, as it prompts the authors to address a potential oversight in their methodology and provides a specific direction for improvement. However, the comment could be more helpful if it included suggestions on how to conduct the ablation study or what aspects of the conventional graph convolutional operation are relevant to the paper's context. Overall, the comment is mostly helpful, as it effectively guides the authors towards a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the absence of a link for WMT\\'14 training corpora, given that a link for WMT\\'15 is provided. However, it does not explicitly instruct the authors to provide a link for WMT\\'14 or explain why this is necessary. The action is implicit and somewhat vague, as the authors can infer that they should provide a link for WMT\\'14, but the comment lacks specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the absence of a link for WMT\\'14 training corpora, given that a link for WMT\\'15 is provided. However, it does not specify which part of the paper this issue is related to, such as a section or table where the links are mentioned. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed, such as whether the absence of a link is a technical issue or a documentation oversight. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the absence of a link for WMT\\'14 training corpora, given that a link for WMT\\'15 is provided. However, the comment does not provide any reasoning, evidence, or context to support why this is a significant issue or why it should be addressed. Without additional explanation or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the availability of links for WMT\\'14 training corpora, given that a link for WMT\\'15 is provided. While it identifies a potential inconsistency or oversight, it does not provide any further context, reasoning, or suggestions on why this might be problematic or how it could be addressed. The comment lacks actionable feedback or guidance for the authors to improve their draft, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the upper and lower bounds for adaptive matrices A_t and B_t need to be known in order to pick other hyperparameters. This provides a clear and direct action for the authors to take, namely to identify and specify these bounds. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"upper and lower bounds for adaptive matrices A_t and B_t,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to know these bounds to pick other hyperparameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the upper and lower bounds for adaptive matrices A_t and B_t need to be known in order to pick other hyperparameters. However, the comment does not provide any reasoning, examples, or references to support why this is necessary or how it impacts the model. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need to know the upper and lower bounds for adaptive matrices A_t and B_t in order to pick other hyperparameters. This feedback is clear and actionable, providing the authors with a concrete step to take in refining their work. By addressing this issue, the authors can enhance the clarity and robustness of their methodology. However, the comment could be more helpful if it offered additional guidance or suggestions on how to determine these bounds or how they might impact the model. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. It implies that the authors should consider providing experimental results on the PDBbind dataset to demonstrate the effectiveness of their approach. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include experimental results on the PDBbind dataset to enhance the novelty of their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. It implies that the authors should consider providing experimental results on the PDBbind dataset to demonstrate the effectiveness of their approach. However, the comment does not specify which part of the paper this suggestion pertains to, such as the introduction or methodology sections. The authors can infer that it relates to the novelty aspect of the work, but the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in suggesting a potential area for improvement, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the novelty of the work is not particularly high, as most techniques used have been proposed and demonstrated before. It suggests that the authors should consider providing experimental results on the PDBbind dataset to demonstrate the effectiveness of their approach. While the comment identifies a potential area for improvement, it lacks specific guidance on how to enhance the novelty or what aspects of the work could be further developed. The suggestion to include experimental results on the PDBbind dataset is a step in the right direction, but the comment could be more helpful if it provided more detailed advice or examples. Overall, the comment is somewhat helpful as it highlights a potential weakness but lacks depth and actionable suggestions for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding error bars to the results comparing pairs of models to demonstrate that the differences are significant and not due to noise. This is a clear and direct action for the authors to take, providing them with a specific and concrete way to improve their draft. The suggestion is actionable because it offers a clear path for enhancing the presentation of the results, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"results on comparing pairs of models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to add error bars to show the significance of the differences between equally performant models. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding error bars to the results comparing pairs of models to demonstrate the significance of the differences. This is a logical suggestion based on common statistical practices, as error bars are a standard way to indicate the variability or uncertainty in data. However, the comment does not provide specific examples or references to support the claim that the differences are indeed exceeding what would be expected from noise. This makes the claim somewhat verifiable, as it provides a general suggestion but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the presentation of results by recommending the addition of error bars to demonstrate the significance of the differences between equally performant models. This feedback is specific and provides a concrete way for the authors to enhance the clarity and robustness of their results. By addressing this suggestion, the authors can better communicate the reliability and significance of their findings, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a specific issue with the definition of \"full state\" on page 2, line 81. It asks what is included in a full state, which is a clear and direct request for clarification. This feedback provides the authors with a specific area to address, making it explicit and concrete. The authors know exactly what needs to be done to improve the draft, namely, to clarify the definition of \"full state.\" Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of \"full state\" and asks for clarification on what is included in a full state. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the definition of \"full state\" on page 2, line 81. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definition of \"full state\" on page 2, line 81. It prompts the authors to clarify what is included in a full state, which is a clear and actionable suggestion for improvement. By providing a direct question for clarification, the comment helps the authors address a potential confusion in their draft. However, it could be more helpful if it offered suggestions on how to improve the definition or provided examples of what constitutes a full state. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a perceived lack of new proposals for neural architecture encoding in the study, despite it being an empirical analysis. While it acknowledges the value of the empirical approach, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details or actionable steps for the authors to take, such as recommending specific areas for new proposals or providing examples of what could be considered novel. As a result, the authors are left without a clear understanding of how to improve their work based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is lacking new proposals for neural architecture encoding. It lacks specificity because it does not detail what specific aspects of the analysis are missing or how the authors could address this issue. Without explicit references to sections or elements of the paper, the authors cannot confidently determine what needs to be revised. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the study is \"lacking of new proposals for neural architecture encoding,\" despite being an empirical analysis. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges the value of the empirical study but points out a perceived lack of new proposals for neural architecture encoding. While it identifies a potential area for improvement, the comment lacks specificity and actionable guidance. It does not provide examples of what new proposals might be considered or how the authors could address this issue, leaving the authors without clear direction on how to enhance their work. Therefore, the comment is barely helpful, as it highlights a potential weakness but does not offer sufficient guidance for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that the paper should include an empirical comparison with existing algorithms, which is an explicit action. However, it does not provide specific guidance on which algorithms to compare with or how to conduct the comparison. The second part of the comment provides a detailed critique, including a recommendation to evaluate the paper as \"Marginally above the acceptance threshold\" due to the lack of empirical results and theoretical comparison with existing algorithms. It also raises concerns about the practical usefulness of the algorithm and the potential communication cost between the master and workers. While the comment provides valuable feedback, it lacks concrete guidance on how to address the issues raised, making it somewhat actionable. Therefore, the comment is rated as 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.5\" and references specific elements like \\u0394_i, \\u0394_{med}, and \\u2207_i, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the lack of empirical comparison with existing algorithms and the theoretical comparison with GD. The comment provides clear guidance on what needs to be addressed, such as including empirical results and addressing concerns about practical usefulness and communication cost. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part suggests that the paper lacks empirical comparison with existing algorithms, which is a claim that requires justification. The second part provides a detailed critique, including a recommendation to evaluate the paper as \"Marginally above the acceptance threshold\" due to the lack of empirical results and theoretical comparison with existing algorithms. It also raises concerns about the practical usefulness of the algorithm and the potential communication cost between the master and workers. While the critique is detailed, it lacks specific references or examples to fully substantiate the claim about the lack of empirical comparison. Therefore, the comment is mostly verifiable, as it provides some support but could be strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of empirical comparisons with existing algorithms. This is a critical point that could impact the paper\\'s contribution and relevance. The reviewer provides a detailed critique, suggesting that the paper should be evaluated as \"Marginally above the acceptance threshold\" due to the lack of empirical results and theoretical comparison with existing algorithms. Additionally, the comment raises concerns about the practical usefulness of the algorithm, particularly regarding the communication cost between the master and workers. While the comment highlights important areas for improvement, it could be more helpful if it offered suggestions on how to conduct the empirical comparisons or addressed the concerns about practical usefulness. Overall, the comment is mostly helpful as it provides clear feedback on the paper\\'s shortcomings and areas for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy between the performance of the proposed approach in simulations and its performance in real data, questioning the practical advantage of the method. It suggests including more real data analyses or comparisons to support the method. While the comment implies that the authors should include more real data analyses, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as it does not provide specific guidance on how to conduct these analyses or what aspects to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed approach in simulations versus real data, questioning the practical advantage of the method. However, it does not specify which part of the paper discusses the simulations or real data analyses, making it weakly grounded. The comment is specific in pointing out the discrepancy between the performance in simulations and real data, suggesting that including more real data analyses or comparisons could support the method. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed approach performs well in simulations but poorly in real data, questioning its practical advantage. However, the comment does not provide any specific examples, data, or reasoning to support this claim. Without detailed evidence or analysis, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed approach, noting that it performs well in simulations but poorly in real data. This observation questions the practical advantage of the method. The comment suggests including more real data analyses or comparisons to support the method, which provides a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct these analyses or what aspects to focus on. Overall, the feedback is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' claim regarding the low discrimination risk of their solution, which is said to be achieved with minimal sacrifice of utility. It also highlights the importance of maintaining the underlying data distribution after imputation, which affects the effectiveness of the models. However, the comment does not provide specific guidance or suggestions on how the authors should address these issues or improve their claims. The feedback lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the authors\\' claim about the low discrimination risk of their solution and the improvement in fairness. It also mentions the importance of maintaining the underlying data distribution after imputation, which affects the effectiveness of the models. However, the comment does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. While the comment is specific in terms of the issues it raises, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the authors\\' claim regarding the low discrimination risk of their solution, which is said to be achieved with minimal sacrifice of utility. It also highlights the importance of maintaining the underlying data distribution after imputation, which affects the effectiveness of the models. However, the comment does not provide specific evidence, examples, or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the authors\\' claim regarding the low discrimination risk of their solution, which is said to be achieved with minimal sacrifice of utility. It also highlights the importance of maintaining the underlying data distribution after imputation, which directly affects the effectiveness of the models. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their claims. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice on how to strengthen the paper. As a result, the comment is somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors could further utilize the ReferIt dataset before moving on to other datasets. While the comment implies that more of the ReferIt data could be exploited, it does not provide explicit guidance on how much more data should be used or how this exploitation could be achieved. The action is implicit and somewhat vague, as the authors need to infer the extent of exploitation and the specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. However, the comment does not provide any reasoning, evidence, or examples to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. While this is a logical suggestion, it lacks specificity and does not provide detailed guidance on how to exploit the dataset more effectively or what specific aspects of the dataset could be further utilized. The feedback is somewhat helpful as it points out an area for potential improvement, but it does not offer actionable steps or examples to guide the authors in implementing this suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. However, it does not provide explicit guidance on how much more of the ReferIt data should be used or how this exploitation could be achieved. The action is implicit and somewhat vague, as the authors need to infer the extent of exploitation and the specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. However, it does not provide any reasoning, evidence, or examples to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. While this is a logical suggestion, it lacks specificity and does not provide detailed guidance on how to exploit the dataset more effectively or what specific aspects of the dataset could be further utilized. The feedback is somewhat helpful as it points out an area for potential improvement, but it does not offer actionable steps or examples to guide the authors in implementing this suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. However, it does not provide explicit guidance on how much more of the ReferIt data should be used or how this exploitation could be achieved. The action is implicit and somewhat vague, as the authors need to infer the extent of exploitation and the specific steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"792,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors could further exploit the ReferIt dataset before moving on to other datasets. This provides clear guidance on what needs to be addressed in the paper"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the explanation in sections 243-245 and provides specific questions for the authors to address. The reviewer asks for clarification on why the multiplication is 5*3 instead of 5*2, why k-NN was chosen over other classifiers, and what the k value and distance metric are. These questions are explicit and provide clear guidance on what the authors need to address to improve the clarity of their explanation. The feedback is concrete, as it specifies the exact parts of the paper that need clarification and what aspects need to be elaborated upon. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"243-245,\" allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly outlines the issues with the explanation, such as the unclear multiplication factor, the choice of k-NN over other classifiers, and the need for clarification on the k value and distance metric used. This provides clear guidance on what the authors need to address to improve the clarity of their explanation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification on specific aspects of the paper, such as the multiplication factor, the choice of classifier, and the distance metric used. These questions are not claims but rather requests for information or clarification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that is unclear, namely sections 243-245. It provides detailed questions that the authors need to address to clarify their explanation. The reviewer asks for elaboration on the multiplication factor, the choice of k-NN classifier, and the distance metric used. This feedback is clear and actionable, as it guides the authors to provide more detailed explanations and justifications for their choices. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the explanation or provided examples of how to address these issues. Overall, the comment is mostly helpful as it directs the authors to improve the clarity of their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the background of Sharpness-Aware Minimization (SAM) should be described in detail. This provides a clear and direct action for the authors to take, which is to include a detailed description of SAM in their paper. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper this information should be included in, nor does it provide any context or details about why this is necessary. Without explicit references to sections or specific parts of the paper, the authors cannot confidently determine where to make these changes. Additionally, the comment lacks specificity regarding what aspects of SAM's background should be detailed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without such evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the background of Sharpness-Aware Minimization (SAM) should be described in detail. While this is a valid suggestion, it lacks specificity and does not provide any guidance on what aspects of SAM's background are particularly important to include or how this information could enhance the paper. Without additional context or detailed feedback, the authors may find it challenging to determine how to address this suggestion effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It provides specific examples of how incorporating image guidance, such as using related reference normal images or color-augmentation for the kNN baseline, could enhance the evaluation. The comment also suggests a thorough examination of both language-based and vision-based assistance to strengthen the evaluation of LAFT\\'s efficacy. This feedback is explicit and provides concrete steps for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as incorporating image guidance with related reference normal images or color-augmentation for the kNN baseline. This feedback clearly specifies what needs to be addressed in the experimental setup to enhance the evaluation of LAFT\\'s efficacy. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental setup lacks comprehensive comparisons, particularly between language-assisted and vision-assisted approaches. It provides specific examples of how incorporating image guidance, such as using related reference normal images or color-augmentation for the kNN baseline, could enhance the evaluation. This feedback is mostly verifiable as it offers a clear suggestion for improvement based on logical reasoning and specific examples. However, it could be strengthened by providing more detailed reasoning or references to support the claim that these additions would be valuable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the experimental setup, noting the lack of comprehensive comparisons between language-assisted and vision-assisted approaches. It provides actionable suggestions for improvement by suggesting the incorporation of image guidance, such as using related reference normal images or color-augmentation for the kNN baseline, to enhance the evaluation of LAFT\\'s efficacy. This feedback is clear and provides concrete steps for the authors to take, making it highly helpful. By offering specific examples and reasoning, the comment empowers the authors to significantly improve their draft, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out a missing related work, specifically mentioning 'collective entity linking' as a relevant area that the paper does not address. It suggests that the proposed model is a special case of collective entity linking, implying that the authors should include this line of work in their discussion. While the comment explicitly identifies the need for inclusion, it does not provide specific guidance on how to integrate this related work into the paper. The action is clear but somewhat vague, as the authors know what needs to be added but may not know the exact details of how to integrate it. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'collective entity linking' and suggests that the proposed model is a special case of this line of work. This allows the authors to accurately identify the part of the paper being addressed, which is the discussion of related work. The comment is also specific because it clearly specifies what is missing in the paper, namely the inclusion of a related line of work that considers multiple mentions in the same document. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the proposed model is a special case of collective entity linking, which is a closely related line of work. The reviewer provides a logical reasoning by suggesting that the model's focus on multiple mentions in the same document aligns with collective entity linking. However, the comment lacks specific references or examples to support this claim, making it somewhat verifiable. The authors would need to conduct further research or analysis to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's discussion of related work, specifically mentioning a closely related line of work in collective entity linking. It points out that the proposed model is a special case of collective entity linking, which is a relevant area that the paper does not address. This feedback is clear and actionable, as it directs the authors to include this related work in their discussion, thereby enhancing the comprehensiveness and depth of their paper. However, the comment could be more helpful if it provided specific suggestions on how to integrate this related work or examples of how it could be discussed. Overall, the comment is mostly helpful as it highlights a critical omission and offers a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part suggests that truncating the log likelihood function can lower sensitivity and proposes a comparison to explore this. This is an explicit action that provides a clear direction for the authors to take. The second part raises a minor comment about the consistency of query functions in Algorithm 1 and the general framework. It suggests that the query functions for all d data sources are the same, which is not consistent with the general framework stating they can be different. The reviewer questions how to design a customized query function for each data source or proposes removing the subscript. While this part is more of a suggestion for clarification, it is still somewhat actionable as it provides a specific point for the authors to consider. Overall, the comment is mostly actionable due to the explicit suggestion to compare the truncation of the log likelihood function and the somewhat actionable minor comment on query functions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The review point is fully grounded as it explicitly mentions \"algorithm 1\" and \"the general framework,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the log likelihood function truncation and the query functions for all d data sources, providing clear guidance on what needs to be addressed. The comment is specific in detailing the need for a comparison and suggesting improvements to the algorithm and framework. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part suggests that truncating the log likelihood function can lower sensitivity and proposes a comparison to explore this. This is a claim that requires some justification, as it is not immediately clear why truncation would lower sensitivity. The second part raises a minor comment about the consistency of query functions in Algorithm 1 and the general framework, suggesting that the query functions for all d data sources are the same, which is not consistent with the general framework stating they can be different. This part is somewhat verifiable as it points out a potential inconsistency but lacks specific examples or references to support the claim. Overall, the comment is mostly verifiable due to the first part, which requires further explanation, and the second part, which is somewhat verifiable with a minor suggestion for clarification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides two distinct pieces of feedback. First, it suggests that truncating the log likelihood function can lower sensitivity and proposes a comparison to explore this issue. This is a clear and actionable suggestion that could significantly enhance the paper by offering a comparative analysis. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects to focus on, which limits its helpfulness. The second part of the comment raises a minor issue regarding the consistency of query functions in Algorithm 1 and the general framework, suggesting that the query functions for all d data sources are the same, which is not consistent with the general framework stating they can be different. The reviewer questions how to design a customized query function for each data source or proposes removing the subscript. While this part provides some insight into potential areas for clarification, it does not offer detailed guidance or suggestions for improvement. Overall, the comment is mostly helpful as it identifies a potential area for improvement and suggests a comparison, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of the method should be expanded to include a larger and more diverse dataset, including more complex molecules and materials. While the comment implies that the authors should consider this improvement, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to broaden their dataset, but the comment lacks specific guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the evaluation to include a larger and more diverse dataset, specifically mentioning the MD17 dataset. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include more complex molecules and materials, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding it to a larger and more diverse dataset. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that a larger and more diverse dataset would be beneficial. The comment implies that the current evaluation may not fully represent the method\\'s capabilities, but it does not provide detailed evidence or examples to substantiate this claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the evaluation of the method, specifically noting that it is limited to a small set of molecules from the MD17 dataset. It suggests that the method's performance should be evaluated on a larger and more diverse dataset, including more complex molecules and materials. This feedback is valuable as it points out a potential area for improvement that could enhance the robustness and generalizability of the method's evaluation. However, the comment could be more helpful if it provided specific examples of how a larger and more diverse dataset could be constructed or suggested ways to address the complexity of the molecules. Overall, the comment is mostly helpful as it directs the authors to a critical aspect of their work that needs attention, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential similarity between the current work and the StreamingLLM paper [1], suggesting that the current work may be similar in terms of setting sink tokens and performing local attention. The reviewer implies that the differences between the two papers should be clarified, as the StreamingLLM paper has recently been uploaded. However, the comment does not provide explicit guidance on how the authors should clarify these differences or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer that they should clarify the differences, but without detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions the StreamingLLM paper [1] and suggests that the current work is similar in terms of setting sink tokens and performing local attention. It implies that the sink tokens may correspond to specific categories, such as $C_{special}$ and $C_{punct}$. However, the comment does not explicitly mention which part of the paper this similarity is discussed in, making it weakly grounded. The comment is specific in identifying the potential similarities and suggesting that the differences between the two papers should be clarified. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current work is similar to the StreamingLLM paper [1] and suggests that the differences between the two should be clarified. The reviewer provides a logical reasoning by mentioning the potential similarities in setting sink tokens and performing local attention, which could correspond to specific categories like $C_{special}$ and $C_{punct}$. However, the comment lacks specific examples or detailed references to the StreamingLLM paper, making it somewhat verifiable. The authors would need to investigate the StreamingLLM paper further to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential similarity between the current work and the StreamingLLM paper [1], suggesting that the current work may be similar in terms of setting sink tokens and performing local attention. The reviewer implies that the differences between the two papers should be clarified, as the StreamingLLM paper has recently been uploaded. This feedback is somewhat helpful as it points out a potential area of overlap and suggests that the authors should clarify the differences in their work. However, the comment lacks specific guidance on how to address this similarity or what aspects of the differences should be emphasized. To be more helpful, the comment could provide more detailed suggestions or examples of how to highlight the unique contributions of the current work. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results section, specifically mentioning a comparison with ConceptWeaver. This provides some grounding as the authors can identify the relevant part of the paper, but it is not fully grounded because it does not specify which sections or figures are being discussed. The comment is specific in pointing out the lack of significant improvement compared to ConceptWeaver, which can handle more than two concepts. However, it lacks detailed guidance on how to address this issue or improve the qualitative results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed comparisons or evidence to substantiate the assertion that ConceptWeaver outperforms the current work in terms of qualitative results. Without additional context or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. It references a specific paper (Gihyun Kwon, Simon Jenni, Dingzeyu Li, Joon-Young Lee, Jong Chul Ye, and Fabian Caba Heilbron. Concept weaver: Enabling multi-concept fusion in text-to-image models. In Proceedings of the IEEE/CVF (CVPR), pp. 8880\u20138889, June 2024) to support the claim. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their qualitative results. While it highlights a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. The authors would benefit from more detailed guidance on how to enhance their qualitative results, which would make the comment more actionable and helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the qualitative results section, specifically mentioning a comparison with ConceptWeaver, which can handle more than two concepts. This provides some grounding as the authors can identify the relevant part of the paper, but it is not fully grounded because it does not specify which sections or figures are being discussed. The comment is specific in pointing out the lack of significant improvement compared to ConceptWeaver, which can handle more than two concepts. However, it lacks detailed guidance on how to address this issue or improve the qualitative results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that there is a lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed comparisons or evidence to substantiate the assertion that ConceptWeaver outperforms the current work in terms of qualitative results. Without additional context or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment highlights a perceived lack of significant improvement in qualitative results compared to ConceptWeaver, which can handle more than two concepts. It references a specific paper (Gihyun Kwon, Simon Jenni, Dingzeyu Li, Joon-Young Lee, Jong Chul Ye, and Fabian Caba Heilbron. Concept weaver: Enabling multi-concept fusion in text-to-image models. In Proceedings of the IEEE/CVF (CVPR), pp"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the problem of subspace clustering with missing data can be addressed by alternating between matrix completion and subspace clustering. However, it does not provide explicit guidance on how the authors should implement this approach or where in the paper this suggestion should be applied. The action is implicit and somewhat vague, as the authors need to infer that they should explore this method but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the problem of subspace clustering with missing data can be addressed by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the problem of subspace clustering with missing data can be addressed by alternating between matrix completion and subspace clustering. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an approach to address the problem of subspace clustering with missing data by alternating between matrix completion and subspace clustering. This is a relevant and potentially insightful suggestion for the authors to consider. However, the comment lacks specificity and does not provide detailed guidance on how to implement this approach or where in the paper it should be applied. While it offers a direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the reliance of CCKT-Det++ on teacher models, suggesting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to consider the quality and alignment of teacher models, but the comment lacks concrete steps or suggestions on how to mitigate these risks. Therefore, the comment is somewhat actionable, as it points out a potential problem but does not offer specific guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the reliance of CCKT-Det++ on teacher models and highlights the potential for limitations or biases in these models to propagate to the system, affecting performance and introducing unintended biases. However, it does not specify which part of the paper discusses the teacher models or how they are integrated into CCKT-Det++. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the potential issue but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that CCKT-Det++ is heavily reliant on the quality and alignment of teacher models, which could propagate limitations or biases to the system. This claim is somewhat verifiable as it provides a logical reasoning that the reliance on teacher models could introduce biases. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the reliance of CCKT-Det++ on teacher models, highlighting that limitations or biases in these models could propagate to the system, affecting performance and introducing unintended biases. This is a valuable insight that could help the authors understand the implications of their approach and consider ways to mitigate these risks. However, the comment lacks specific suggestions or guidance on how to address this issue, such as exploring alternative methods or evaluating the robustness of the teacher models. While it points out a critical area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting the use of more recent comparison objects or providing specific recommendations for improvement. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the comparison objects used in the experiment, stating that they are outdated and that the performance has not significantly improved. However, it does not specify which part of the paper this comparison is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in pointing out the issue with the outdated comparison objects, but it lacks grounding as it does not mention a specific section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the comparison objects used in the experiment are outdated and that the performance has not significantly improved. This feedback is somewhat helpful as it identifies a potential issue with the experimental setup that could affect the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the comparison objects. Without actionable advice or further elaboration, the authors may find it challenging to fully utilize this feedback. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks about the handling of masks in CNN layers, specifically in the representation block. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what aspects of the handling of masks should be addressed or how the authors might improve this aspect of their work. Without specific instructions or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how masks are handled in CNN layers, specifically in the representation block. However, it does not specify which part of the paper discusses this topic, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this information is located, the comment lacks full grounding. It is specific in asking about the handling of masks, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about how masks are handled in CNN layers, specifically in the representation block. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about how masks are handled in CNN layers, particularly in the representation block. While it identifies a potential area for improvement or clarification, it does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects need to be considered. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful, as it provides a starting point for the authors but does not fully support their efforts to enhance the paper.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment requests an explanation for why \"without dropout\" has a larger training loss, given that activation clipping may reduce the model capacity. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. However, the comment does specify what needs to be addressed, which makes it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests an explanation for why \"without dropout\" has a larger training loss, given that activation clipping may reduce the model capacity. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests an explanation for why \"without dropout\" has a larger training loss, given that activation clipping may reduce the model capacity. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The authors are left without guidance on how to address the issue or what specific aspects of the model or training process might be contributing to the observed phenomenon. Therefore, the comment is unverifiable, as it lacks the necessary justification or evidence to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 8, questioning why \"without dropout\" has a larger training loss despite activation clipping potentially reducing model capacity. This feedback is somewhat helpful as it points out a potential inconsistency that the authors should address. However, it lacks depth and does not provide guidance on how the authors might investigate or resolve this issue. The comment could be more helpful with additional context or suggestions on how to explore this phenomenon further. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the significance of the paper, specifically highlighting the importance of establishing a large-scale matting dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this point or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the significance of the paper, specifically highlighting the importance of establishing a large-scale matting dataset. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the paper could be improved or how the authors might address this point. Without specific grounding or guidance, the authors cannot effectively identify the parts of the paper that need attention or how to improve them. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the significance of the paper, specifically highlighting the importance of establishing a large-scale matting dataset. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses an opinion about the significance of the paper, specifically highlighting the importance of establishing a large-scale matting dataset. However, it does not provide any actionable feedback or suggestions on how the authors might address this point or improve their work. Without specific guidance or examples, the authors are left without a clear direction for enhancing their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential area of importance but lacks actionable content.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the number of adversarial examples is too small to demonstrate some distribution. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as increasing the number of adversarial examples or suggesting alternative methods to demonstrate the distribution. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the number of adversarial examples is too small to demonstrate some distribution. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs attention. This lack of grounding makes it difficult for the authors to address the comment effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the number of adversarial examples is too small to demonstrate some distribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the number of adversarial examples used in the study, suggesting that it may be too small to effectively demonstrate the distribution. However, it does not provide any specific guidance or suggestions on how the authors might address this issue, such as increasing the number of examples or proposing alternative methods to demonstrate the distribution. Without actionable advice or detailed feedback, the comment lacks depth and does not offer the authors a clear path to improve their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point identifies a potential issue with the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. It also points out that the analysis experiments or 'Qualitative Studies' in Section 5.2 are done with a subset of common corruptions, which may not generalize to the full set. The reviewer suggests that it would be better to conduct these experiments with the full set for thoroughness and comparability with other results. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments with the full set. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"5)\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed channel-sparse gradients, explaining why they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. The comment further suggests that the analysis experiments or \"Qualitative Studies\" in Section 5.2 should be conducted with the full set of common corruptions for thoroughness and comparability with other results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed channel-sparse gradients may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. The reviewer provides a logical reasoning by explaining that zeroing out a particular channel may not alter the computation performed, as most frameworks require dense gradients for inputs and parameters. Additionally, the comment suggests that the analysis experiments or \"Qualitative Studies\" in Section 5.2 should be conducted with the full set of common corruptions for thoroughness and comparability with other results. While the reasoning is clear, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of frameworks. Therefore, the comment is mostly verifiable, as it provides a logical argument but lacks detailed evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed channel-sparse gradients, suggesting that they may not save time or memory in practice due to the limitations of most frameworks supporting only dense gradients. It provides a logical explanation for why zeroing out a particular channel may not alter the computation performed. Additionally, the comment points out that the analysis experiments or 'Qualitative Studies' in Section 5.2 are done with a subset of common corruptions, which may not generalize to the full set. The reviewer suggests that it would be better to conduct these experiments with the full set for thoroughness and comparability with other results. This feedback is clear and actionable, offering specific guidance on how the authors can improve their study's validity and generalizability. However, it could be more helpful if it provided additional suggestions or examples on how to conduct these experiments with the full set. Overall, the comment is mostly helpful, as it provides valuable insights and actionable advice for enhancing the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the proof, suggesting that it seems to use concentration-of-measure, which implies a connection to low rank. The reviewer questions the claim that the authors do not consider low rank, suggesting that the results may be a simple extension of existing results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their claims. The action is implicit and vague, leaving the authors uncertain about what specific steps to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the proof and its connection to low rank. It explicitly mentions \"2)\", which allows the authors to identify the part of the paper being discussed. The comment also provides a specific critique, questioning the claim that the authors do not consider low rank and suggesting that the results may be a simple extension of existing results. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the proof, suggesting that it seems to use concentration-of-measure, which implies a connection to low rank. The reviewer questions the claim that the authors do not consider low rank, implying that the results may be a simple extension of existing results. However, the comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to support the claim. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some justification but lacks sufficient detail to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the proof, suggesting that it seems to use concentration-of-measure, which implies a connection to low rank. The reviewer questions the claim that the authors do not consider low rank, implying that the results may be a simple extension of existing results. This feedback is somewhat helpful as it identifies a potential inconsistency in the paper's claims and suggests that the authors might need to clarify their stance on low rank. However, the comment lacks specific guidance or suggestions on how the authors could address this issue or improve their draft. While it points out a potential area for clarification, it does not provide detailed feedback or actionable steps, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the Limitations section is too concise, contrasting it with the detailed writing style of the main body. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to expand the Limitations section or what specific aspects should be included. The comment lacks actionable details, leaving the authors without a clear understanding of how to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the \"Limitations\" section, noting that it is too concise compared to the detailed writing style of the main body. However, it does not specify which part of the \"Limitations\" section is too concise or what specific aspects need to be expanded. This lack of detail makes it difficult for the authors to identify the exact areas that need improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the \"Limitations\" section is too concise compared to the detailed writing style of the main body. However, the comment does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the \"Limitations\" section, noting that it is too concise compared to the detailed writing style of the main body. This feedback highlights a potential inconsistency in the paper\\'s writing style, which could impact the clarity and completeness of the discussion. However, the comment does not provide any suggestions or guidance on how to address this issue, such as expanding the limitations section or offering specific examples of what should be included. Without actionable advice, the comment is limited in its usefulness for the authors. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is weak, suggesting that it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. While the comment identifies a potential issue with the novelty, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit, as the authors can infer that they need to clarify the novelty of their method or provide additional details to distinguish it from existing work. However, the comment lacks concrete steps or examples on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, suggesting that it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, it does not specify which part of the paper discusses the novelty or the specific sections where this comparison is made. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue of novelty but lacks grounding, as it does not pinpoint the exact sections of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the proposed method, suggesting that it may be a modified version of previous work, specifically PatchCore, with the addition of a denoising process to the memory bank. While the comment points out a potential weakness in the novelty, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. The feedback lacks depth and actionable advice, making it somewhat helpful. The authors are left with a general understanding of the issue but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to provide more details about each challenge, suggesting that this information should be included in an extensive version of Table 1 or in the appendix, similar to the approach taken in binpwn. Additionally, the comment recommends listing all the prompts used in the evaluation, either in the appendix or on GitHub. These actions are clear and specific, giving the authors a direct path to improve their draft by providing additional details and ensuring transparency. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"the appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, providing more details about each challenge and listing all prompts used in the evaluation. This level of detail ensures that the authors can effectively address the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the code is not executable due to a lack of clear instructions on installation and running. This is a factual statement that does not require verification, as it is based on the reviewer\\'s experience. However, the suggestion to provide more details about each challenge and list all prompts used in the evaluation is a recommendation rather than a claim. Therefore, the comment is primarily factual, with a suggestion that does not require verification. This aligns with a score of 3: Somewhat Verifiable, as it provides a clear suggestion but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's reproducibility, specifically noting that the code is not executable due to a lack of clear instructions on installation and running. This feedback is actionable and provides a clear recommendation for improvement, suggesting that the authors should provide more detailed instructions or include them in an extensive version of Table 1 or the appendix. Additionally, the comment recommends listing all prompts used in the evaluation, which is another important aspect for reproducibility. This feedback is mostly helpful as it guides the authors on how to enhance the clarity and accessibility of their work, enabling them to improve the draft significantly. However, it could be more helpful if it included specific examples or detailed suggestions on how to structure the additional information. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. However, it does not provide explicit guidance on how the authors should address this issue or what changes they should make to align their results with the major claim. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 3' and 'global representation g_v,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the results slightly depart from the major claim of interpretable VQA, suggesting that the global representation is more crucial than other components. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the model ablation results in Table 3 suggest that the global representation g_v is more crucial than other components, which opens a 'back door' for grounded QA. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks detailed justification or references to external works that could substantiate the assertion. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the model ablation results in Table 3 and the major claim of interpretable VQA, suggesting that the global representation g_v is more crucial than other components. This observation is relevant and highlights a potential inconsistency in the paper's findings. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results to align with the major claim. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors would benefit from more detailed guidance on how to reconcile these findings or enhance the interpretability of their VQA model.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion to avoid using the notation $f^{-1} = g$ in the notation paragraph of section 3. It explains the reasoning behind this suggestion, noting that $f$ cannot be an invertible function when $d<D$ due to its domain being defined as $\\mathbb{R}^D$. The reviewer recommends using the language of left inverses instead. This feedback is explicit and provides a clear action for the authors to take, making it highly actionable. The authors know exactly what needs to be changed and how to implement the suggested notation. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"sec 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the notation, explaining that $f^{-1} = g$ should be avoided because $f$ cannot be an invertible function when $d<D$. The reviewer provides a detailed explanation of the reasoning behind the suggestion, including the domain of $f$ and the potential use of left inverses instead. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation $f^{-1} = g$ should be avoided because $f$ cannot be an invertible function when $d<D$, as it is defined on $\\mathbb{R}^D$. The reviewer provides a logical explanation, noting that the domain of $f$ is $\\mathbb{R}^D$ and that $f$ cannot be invertible when $d<D$. This reasoning is clear and provides a strong basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion regarding the notation used in the paper. It identifies a potential issue with the notation $f^{-1} = g$ and explains why it might be problematic, particularly when considering the domain of $f$ as $\\mathbb{R}^D$. The reviewer offers a clear alternative, recommending the use of left inverses instead. This feedback is valuable as it helps the authors improve the clarity and correctness of their notation, which is crucial for the understanding and reproducibility of their work. The comment is detailed and actionable, making it highly helpful for the authors to enhance their draft. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in Table 4. This action is clear and concrete, as it specifies the exact comparison that should be made to provide a more comprehensive understanding of the model\\'s effectiveness. The comment also provides a specific reference to a relevant work, which further clarifies the action. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1], in the ablation studies on the motion tokenizer. This provides clear guidance on how to improve the draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation studies on the motion tokenizer in Table 4 should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1]. This claim is somewhat verifiable as it provides a specific suggestion for improvement by referencing a relevant work (MoMask) that could be used for comparison. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to conduct further research or experimentation to fully understand the implications of this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that the ablation studies on the motion tokenizer in Table 4 should include comparisons with state-of-the-art RVQ-VAE models, such as MoMask [1]. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the comprehensiveness of the study by comparing the proposed approach with existing benchmarks. By following this advice, the authors can better demonstrate the effectiveness of their model and provide a more robust evaluation. However, the comment could be more helpful if it included additional context or reasoning about why these comparisons are important. Overall, the comment is mostly helpful, as it guides the authors toward a specific improvement that could significantly enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. While it identifies a specific issue, it does not provide explicit guidance on how the authors should address this problem. The comment suggests that the authors need to clarify the distinction between the \"primary-secondary\" relationship and nuclearity, but it does not offer concrete steps or examples on how to achieve this. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the \"primary-secondary\" relationship and its unclear distinction from nuclearity, but it does not specify which part of the paper discusses these concepts. The authors can infer that it relates to sections where these terms are mentioned, but the lack of explicit references makes it weakly grounded. The comment is specific in pointing out the need for clarification regarding the distinction between the two concepts. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the \"primary-secondary\" relationship is mentioned frequently in the paper but lacks clarity and precise definition compared to the concept of nuclearity. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that the 'primary-secondary' relationship is mentioned frequently but lacks clarity and precise definition compared to the concept of nuclearity. This feedback is somewhat helpful as it points out a potential area for improvement in the paper's clarity and consistency. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as somewhat helpful, as it highlights a problem but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the observation that the effect of the mask ratio varies across different datasets, leading to the need for more tuning. It also notes that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be beneficial. While the comment implies that the authors should include a discussion on the impact of the mask ratio and provide guidance on choosing the ratio, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this issue in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the observation that the effect of the mask ratio varies across different datasets, leading to more tuning. It also notes that the impact of the mask ratio is missing from the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. However, the comment does not specify which part of the paper this observation is based on, making it weakly grounded. The authors can infer that it relates to the limitations section or the discussion on the mask ratio, but this is not explicitly mentioned. The comment is specific in detailing what is missing and suggesting improvements, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effect of the mask ratio varies across different datasets, leading to more tuning, and that this insight is missing from the discussions. The reviewer suggests that an intuitive guide for choosing the mask ratio would be helpful. While the comment identifies a potential issue with the paper, it lacks specific examples or references to support the claim about the varying effects of the mask ratio across datasets. The suggestion for an intuitive guide is a logical response to the observation, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper, noting that the effect of the mask ratio varies across different datasets, which could lead to more tuning. It highlights that this insight is missing from the discussions and suggests that an intuitive guide for choosing the mask ratio would be beneficial. This feedback is clear and actionable, as it points out a gap in the paper's analysis and provides a specific suggestion for improvement. However, the comment could be more helpful if it offered additional guidance or examples on how to develop this intuitive guide. Overall, the comment is mostly helpful as it directs the authors to an area that needs further exploration and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not provide specific guidance on which sections need improvement or what aspects of the writing are unclear. The authors are left with a general idea of what needs to be addressed but without concrete steps or examples. This makes the comment somewhat actionable, as it highlights a need for improvement but lacks detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. However, it does not specify which sections are problematic or what aspects of the writing are unclear. This makes it difficult for the authors to identify the exact parts of the paper that need revision. The comment lacks specificity and does not provide clear guidance on what needs to be addressed, leaving the authors without a clear understanding of how to improve the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper could benefit from another round of proof-reading because some sections are difficult to follow. However, the comment does not provide specific examples or detailed reasoning to support why certain sections are unclear or how they could be improved. This lack of specificity and detailed justification makes the claim somewhat verifiable, as the authors may need to infer the issues themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the paper could benefit from another round of proof-reading, indicating that there are sections that are difficult to follow. While it acknowledges the need for improvement, it lacks specificity and does not provide detailed guidance on which sections are problematic or what aspects of the writing are unclear. This makes it somewhat helpful, as it highlights an area for improvement but does not offer actionable feedback to guide the authors in addressing the issue. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential inconsistency in the manuscript regarding the term \"STG layer\" in Figure 2, which has not been mentioned elsewhere in the text. The reviewer speculates that it might refer to stochastic gates but is uncertain. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address it. The action is implicit, as the authors need to infer that they should clarify the term \"STG layer\" or its relation to stochastic gates. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the manuscript being addressed. It also specifies the issue by questioning the absence of the term \"STG layer\" in the manuscript and suggesting that it might refer to stochastic gates, although the reviewer is not entirely sure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript, which is a factual statement. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks context or explanation, making it difficult for the authors to understand the basis of the claim. Without additional information or justification, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential inconsistency in the manuscript regarding the term 'STG layer' in Figure 2, which has not been mentioned elsewhere in the text. The reviewer speculates that it might refer to stochastic gates but is uncertain about this. This feedback highlights a gap in the manuscript's consistency and clarity, prompting the authors to clarify the term or its relation to stochastic gates. However, the comment lacks specific guidance on how to address this issue, such as suggesting where to introduce the term or how to explain its relation to stochastic gates. While it points out a potential problem, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the improvements resulting from the proposed methodology are limited in some instances and even underperform compared to the baseline in specific cases. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these issues or improve their methodology. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the limitations of the proposed methodology, specifically mentioning that it underperforms compared to the baseline in certain cases, such as FiQA and CONALA. However, it does not specify which part of the paper discusses these results or where the methodology is described. The authors can infer that it relates to the methodology section or experimental results, but this inference is not explicit. The comment is specific in detailing the limitations but lacks grounding, as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements resulting from the proposed methodology are limited and even underperform compared to the baseline in specific cases, such as FiQA and CONALA. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a limitation of the proposed methodology, noting that it underperforms compared to the baseline in specific cases, such as FiQA and CONALA. This feedback is somewhat helpful as it identifies a critical area where the methodology needs improvement. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance their methodology. Without actionable advice or detailed feedback, the authors may find it challenging to effectively improve their draft based on this comment. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of comparisons with [1] and asks for clarification on the contributions or advantages beyond [1]. While the comment explicitly requests more information, it does not provide specific guidance on how to address this issue or what additional details should be included. The action is implicit, as the authors need to infer that they should provide more context or clarification on their contributions, but it is concrete because the direction is clear. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the comparison with a specific reference, [1], which is fully grounded as it allows the authors to identify the part of the paper being discussed. However, the comment is specific in its request for clarification on the contributions or advantages beyond [1], which is a clear and direct question. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of comparisons with a specific reference, [1], and requests clarification on the contributions or advantages beyond that work. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of comparisons with a specific reference, [1], and asks for clarification on the contributions or advantages beyond that work. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing more detailed explanations or comparisons. However, the comment lacks depth and does not offer suggestions on how to enhance the clarity or provide additional context. To be more helpful, the comment could include specific examples or guidance on how to address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It explicitly instructs the authors to provide a well-explained reason for using the average feature of previous samples to stop the training of the uni-modal branch. This feedback is clear and direct, giving the authors a specific action to take in improving their draft. The comment provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the re-balancing step method, which is used to make multi-modal learning less greedy, and notes that it is not well described and analyzed in the full text. It specifically mentions the need for a well-explained reason for using the average feature of previous samples to stop the training of the uni-modal branch. This provides full grounding as it explicitly mentions the re-balancing step method and the specific issue with its description and analysis. The comment is also specific because it clearly identifies what needs to be addressed, namely, the need for a detailed explanation of the method and its rationale. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the re-balancing step method is not well described and analyzed in the full text, and suggests that the authors should provide a detailed explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. While the comment identifies a gap in the paper's explanation, it lacks specific examples or references to support the claim. The authors are left to infer the nature of the issue and the reasoning behind the suggestion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description and analysis of the re-balancing step method, which is used to make multi-modal learning less greedy. It points out that the method is not well described and suggests that the authors should provide a detailed explanation of why using the average feature of previous samples can stop the training of the uni-modal branch. This feedback is clear and actionable, as it directs the authors to improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided specific suggestions or examples of how to enhance the explanation. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises two questions regarding Section 4.1. The first question asks for clarification on the differences and advantages of the \"Reduce\" part compared to EATA. The second question suggests using entropy instead of energy to identify harmful out-of-distribution (OOD) instances. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should provide detailed explanations and comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.1\" and \"Reduce part,\" allowing the authors to accurately identify the specific section being addressed. It also specifies what needs to be addressed by asking for clarification on the differences and advantages over EATA and suggesting the use of entropy instead of energy to identify harmful OOD instances. This provides clear guidance on what aspects of the paper need further explanation or revision. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions seeking clarification and suggestions for improvement. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions regarding the \"Reduce\" part in Section 4.1. The first question asks for clarification on the differences and advantages of the \"Reduce\" part compared to EATA, which is a relevant and constructive inquiry for the authors to address. The second question suggests using entropy instead of energy to identify harmful out-of-distribution instances, offering a potential improvement or alternative approach. While the comment identifies areas for clarification and improvement, it does not provide detailed guidance or suggestions on how to implement these changes. The feedback is somewhat helpful as it prompts the authors to consider specific aspects of their work that could be further explored or improved, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not explicitly instruct the authors to conduct this comparison or explain why it would be beneficial. The action is implicit and somewhat vague, as the authors are left to infer that they should consider this comparison but are not given concrete guidance on how to implement it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests exploring the comparison of the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or result. The authors may infer that it relates to the comparison section or the results, but this inference is not explicit. The comment is specific in suggesting a potential comparison, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. However, it does not provide any specific reasoning, evidence, or examples to support why this comparison would be relevant or beneficial. The claim lacks detailed justification or references to existing literature, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it might be interesting to compare the proposed method against deterministic control, given the popularity of deterministic policies. While this suggestion is somewhat helpful, it lacks specificity and does not provide detailed guidance on why such a comparison would be relevant or how it could enhance the paper. The comment does not offer actionable steps or insights for the authors to consider, leaving them with a vague idea of what could be improved. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential inconsistency in Table 4, suggesting that the 3r column should not be named ATE. It also questions whether Corr is also Cau-Ant. While the comment identifies a specific issue with the naming of the column, it does not provide explicit guidance on how to resolve this inconsistency or clarify the relationship between Corr and Cau-Ant. The action is implicit, as the authors need to infer that they should correct the naming and clarify the relationship, but it lacks concrete details on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the naming of the 3r column and suggesting that it should not be named ATE. Additionally, it raises a concern about the relationship between Corr and Cau-Ant. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the naming of the 3r column in Table 4, suggesting that it should not be named ATE. It also raises a concern about the relationship between Corr and Cau-Ant. However, the comment lacks specific reasoning or evidence to support why the naming should be changed or why Corr is not Cau-Ant. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the labeling of columns in Table 4, suggesting that the 3r column should not be named ATE. It also questions the relationship between Corr and Cau-Ant, implying that there might be a misunderstanding or inconsistency in the table. While the comment points out a potential error, it does not provide detailed guidance on how to correct the issue or clarify the relationship between Corr and Cau-Ant. The feedback is somewhat helpful as it highlights a specific area for improvement, but it lacks depth and actionable suggestions, leaving the authors with a general direction to follow. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the paper, specifically regarding the anchoring of the mechanism in prior work and the difficulty in understanding the significance of the differences in the figures. It suggests that more information about the methods and their basis in prior work could be helpful. Additionally, it recommends annotating or zooming in on the figures to provide quantitative grounding. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to implement these suggestions. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two main issues: the lack of anchoring of the mechanism in prior work and the difficulty in understanding the significance of the differences in the figures. It suggests that more information about the methods and their basis in prior work could be helpful, and it recommends annotating or zooming in on the figures to provide quantitative grounding. However, the comment does not specify which sections of the paper these issues are present in, making it weakly grounded. The feedback is specific in identifying the need for more information about the methods and the figures, but without explicit references to sections, the authors may struggle to pinpoint where these improvements are needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the paper, specifically regarding the anchoring of the mechanism in prior work and the difficulty in understanding the significance of the differences in the figures. The reviewer suggests that more information about the methods and their basis in prior work could be helpful, and that annotating or zooming in on the figures would aid in grounding them quantitatively. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is somewhat verifiable as it provides a general direction for improvement but lacks detailed guidance or evidence to substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement: the anchoring of the mechanism in prior work and the clarity of the figures. It suggests that more information about the methods and their basis in prior work could be helpful, which is a clear and actionable suggestion. Additionally, it points out the difficulty in understanding the significance of the differences in the figures and recommends annotating or zooming in to provide quantitative grounding. While the comment provides valuable insights, it could be more helpful if it offered specific examples or detailed guidance on how to improve the clarity of the figures. Overall, the feedback is mostly helpful as it directs the authors to specific areas for improvement and offers actionable suggestions, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to few-shot graph learning. It suggests that the main idea is plausible but not exciting and somewhat complicated. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how to enhance the novelty or simplify the approach. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to the task of few-shot graph learning. It suggests that the main idea is plausible but not exciting and somewhat complicated. However, the comment does not specify which part of the paper this concern relates to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact areas needing attention. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to the task of few-shot graph learning. It suggests that the main idea is plausible but not exciting and somewhat complicated. However, the comment lacks specific examples or references to support the claim of limited novelty or the complexity of the approach. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the limited novelty of the paper, specifically noting that the key contribution is the pre-trained mechanism applied to the task of few-shot graph learning. It suggests that the main idea is plausible but not exciting and somewhat complicated. While the comment identifies a potential issue with the novelty of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their contribution. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper provides empirical validation of setups and parameters for test-time training but lacks theoretical understanding of why these do not collapse. While it identifies a gap in the paper\\'s theoretical foundation, it does not provide explicit guidance or suggestions on how the authors might address this issue. The comment implies that the authors should explore theoretical explanations, but it does not specify what kind of theoretical understanding is needed or how to achieve it. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of theoretical understanding in the paper, specifically regarding why certain setups and parameters do not collapse. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for theoretical understanding, but without grounding, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks theoretical understanding of why certain setups and parameters do not collapse, despite providing empirical validation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting that while it provides empirical validation of setups and parameters for test-time training, it lacks a theoretical understanding of why these do not collapse. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\\'s depth and comprehensiveness. However, the comment could be more helpful if it provided suggestions on how the authors might address this gap or what kind of theoretical understanding is needed. Overall, the comment is somewhat helpful as it points out a critical area for enhancement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the source of the visual analysis, but it lacks concrete details on how to implement this clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec.4.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual analysis, questioning whether it is based on training or test images. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the visual analysis in Section 4.4, specifically questioning whether it is based on training or test images. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the visual analysis in Section 4.4, specifically questioning whether the results are based on training or test images. This feedback is somewhat helpful as it points out a gap in the presentation that could affect the understanding of the results. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their analysis. To be more helpful, the comment could include examples or suggestions for how to clarify the distinction between training and test images. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an interesting exploration of applying the DEER method to other methods like LEM or UnICORNN. It poses questions about the performance of these methods when trained with the DEER method and whether better performance could be achieved due to faster training. While the comment implies that the authors should consider this exploration, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the performance of these methods with the DEER method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an interesting exploration of applying the DEER method to other methods such as LEM or UnICORNN. It poses questions about the performance of these methods when trained with the DEER method and whether better performance could be achieved due to faster training. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The authors might infer that it pertains to the discussion or conclusion sections, but this is not explicitly mentioned. The comment is specific in detailing what could be explored, but without clear grounding, it is challenging for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an interesting exploration of applying the DEER method to other methods like LEM or UnICORNN. It poses questions about the performance of these methods when trained with the DEER method and whether better performance could be achieved due to faster training. While the comment is speculative, it is based on a logical reasoning that the DEER method could potentially improve performance by allowing faster training. However, it lacks specific examples or references to support the claim that these methods could be trained faster or that better performance could be achieved. The suggestion is somewhat verifiable, as it provides a plausible line of reasoning but requires further substantiation to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests an interesting exploration of applying the DEER method to other methods such as LEM or UnICORNN. It poses questions about the performance of these methods when trained with the DEER method and whether better performance could be achieved due to faster training. This suggestion could potentially strengthen the paper by broadening its impact and offering new insights into the performance of these methods. However, the comment does not provide specific guidance on how to conduct this exploration or what aspects to focus on, leaving the authors with a general idea but without detailed instructions. Therefore, the comment is somewhat helpful, as it identifies an interesting direction for further exploration but lacks depth and specificity in its guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to simplify the notations or what specific changes should be made. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve the presentation. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the presentation, noting that it is difficult to follow due to the use of too many notations. However, it does not specify which sections or parts of the paper contain these notations, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in identifying the issue but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation is difficult to follow due to the use of too many notations. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed evidence or examples, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation, noting that it is difficult to follow due to the use of too many notations. While this feedback highlights a potential area for improvement, it lacks depth and does not provide any suggestions or guidance on how the authors might simplify the notations or improve the presentation. Without actionable advice or specific examples, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in improving their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including results from GPT-4V, noting that while its API is not yet released, experiments through ChatGPT\\'s UI are sufficient. This is an explicit action for the authors to take, as it provides a clear direction to include additional results in their draft. The suggestion is concrete, as it specifies the type of experiments that could be conducted and the method of execution (through ChatGPT\\'s UI). Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including results from GPT-4V, noting that while its API is not yet released, experiments through ChatGPT\\'s UI are sufficient. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include results from GPT-4V, but without grounding, the authors may struggle to identify the exact section where this information should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including results from GPT-4V, noting that while its API is not yet released, experiments through ChatGPT\\'s UI are sufficient. This is a suggestion for additional experimentation or analysis, which is a request for information rather than a claim. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests including results from GPT-4V, noting that while its API is not yet released, experiments through ChatGPT\\'s UI are sufficient. This is a clear and actionable suggestion that provides the authors with a specific direction for enhancing their draft. By suggesting a method for incorporating results from GPT-4V, the comment offers a concrete way to improve the paper\\'s completeness and relevance. However, it could be more helpful if it provided additional context or examples of how these results could be integrated or what specific aspects of GPT-4V should be explored. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss more about the implications of their theoretical analysis. It implies that the authors should provide a clearer explanation of why CoPur could perform better than baselines. However, the comment does not provide specific guidance on how to achieve this or what aspects of the analysis should be discussed. The action is implicit and somewhat vague, as the authors need to infer the details of the discussion required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss more about the implications of their theoretical analysis, particularly in comparison to baselines. However, it does not specify which part of the paper this analysis is in or where the authors should provide more discussion. This lack of grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to discuss the implications of the analysis, but without clear grounding, it is weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper provides an extensive theoretical analysis but lacks discussion on its implications. It implies that the authors should discuss why CoPur could perform better than baselines. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the paper's extensive theoretical analysis should be accompanied by a discussion on its implications. It specifically asks why CoPur could perform better than baselines, which is a relevant question for the authors to address. However, the comment lacks specific guidance or suggestions on how to enhance the discussion or what aspects of the analysis should be emphasized. While it identifies an area for improvement, the feedback is somewhat helpful as it provides a direction for the authors to consider but does not offer detailed or actionable advice. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies several issues with the reported metrics and evaluation protocol. It points out that the metrics are mostly focused on 3D NVS and lack metrics related to dynamics, specifically mentioning the keypoint distance metric. The comment also questions the clarity of the evaluation protocol, particularly regarding the consistency of camera parameters across different frames. While the comment highlights specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest concrete steps for the authors to take. The feedback is somewhat actionable as it points out specific areas for improvement but lacks detailed instructions on how to implement those changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Result/eval,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the reported metrics, particularly the lack of metrics related to dynamics and the clarity of the evaluation protocol. The comment specifies that the keypoint distance metric only assesses the size of motions and questions the consistency of camera parameters across frames. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the evaluation metrics and protocol used in the paper. It claims that the reported metrics are mostly focused on 3D NVS and lack metrics related to dynamics, specifically mentioning the keypoint distance metric. The comment also questions the clarity of the evaluation protocol, particularly regarding the consistency of camera parameters across different frames. While the comment provides some reasoning by pointing out the lack of metrics related to dynamics, it lacks specific examples or references to support the claim fully. The suggestion to clarify the evaluation protocol is a logical deduction but could be strengthened with more detailed evidence or examples. Therefore, the comment is somewhat verifiable, as it provides some reasoning but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several issues with the reported metrics and evaluation protocol. It points out that the metrics are mostly focused on 3D NVS and lack metrics related to dynamics, specifically mentioning the keypoint distance metric, which only assesses the size of motions but not their quality. Additionally, the comment questions the clarity of the evaluation protocol, particularly regarding the consistency of camera parameters across different frames. This feedback is mostly helpful as it provides clear and actionable suggestions for improvement, such as recommending the inclusion of additional metrics related to dynamics and clarifying the evaluation protocol. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of alternative metrics that could be used. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the two parts of pretraining and regularization are presented as incremental additions rather than naturally integrated components, which detracts from the coherence of the paper. It explicitly suggests that this issue needs to be addressed. However, the comment does not provide specific guidance on how to integrate these components or what changes should be made to achieve coherence. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the presentation of pretraining and regularization, suggesting that they are presented as incremental additions rather than naturally integrated components. However, it does not specify which parts of the paper these additions are discussed in, making it weakly grounded. The comment is specific in identifying the issue with the presentation, suggesting that the authors need to address this to improve the coherence of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the presentation of pretraining and regularization is disjointed, which detracts from the coherence of the paper. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues and how to address them. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of pretraining and regularization, noting that they are presented as incremental additions rather than naturally integrated components. This observation is relevant as it could affect the coherence and clarity of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending ways to integrate these components or improve the flow of the paper. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of explanation regarding the importance of Renyi divergence and its relevance to differential privacy. It suggests that the importance of Renyi divergence is not well explained, particularly for readers unfamiliar with differential privacy. However, the comment does not provide specific guidance on how the authors should improve this explanation or what aspects of Renyi divergence should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of Renyi divergence and its significance in the context of differential privacy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of explanation regarding the importance of Renyi divergence and its relevance to differential privacy. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a clearer explanation of Renyi divergence, particularly for readers unfamiliar with differential privacy. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the importance of Renyi divergence is not well explained, particularly for readers unfamiliar with differential privacy. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the explanation of the importance of Renyi divergence in the context of differential privacy. It highlights that the importance of Renyi divergence is not well explained, particularly for readers who are not familiar with differential privacy. This feedback is somewhat helpful as it points out a gap in the paper\\'s explanation, but it lacks depth and does not provide specific suggestions on how the authors might address this issue. The authors are left with a general understanding of the problem but without actionable guidance on how to improve the explanation. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. While the comment implies that the authors should consider revising their approach to emphasize simplicity and clarity, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should pay more attention to simplicity and clarity, rather than relying solely on mathematical theories. However, it does not specify which part of the paper this advice pertains to, making it difficult for the authors to identify the exact sections that need improvement. The comment lacks specificity in terms of what aspects of simplicity and clarity should be emphasized or how the mathematical theories could be better integrated. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should focus more on simplicity and clarity rather than relying solely on mathematical theories. However, the comment does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should focus more on simplicity and clarity in their work, rather than relying solely on mathematical theories. While the comment identifies a potential area for improvement, it lacks specificity and does not provide actionable guidance on how to achieve this. The authors are left to infer that they should simplify their approach or clarify their explanations, but without detailed suggestions or examples, the feedback remains somewhat vague. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ablation study in the work is limited and recommends further studies to explore the impact of the pre-defined threshold \u03f5. While the comment implies that the authors should conduct additional studies, it does not provide explicit guidance on how to conduct these studies or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the ablation study, specifically mentioning the impact of the pre-defined threshold \u03f5. This provides some grounding as it allows the authors to identify the part of the paper being discussed, which is the ablation study. However, the comment does not specify which sections or figures are related to the ablation study, making it weakly grounded. It is specific in suggesting that the impact of the pre-defined threshold \u03f5 should be further studied, but it lacks detailed guidance on how to conduct these studies. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ablation study in the work is limited, specifically mentioning the impact of the pre-defined threshold \u03f5. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the ablation study is limited or why the impact of the threshold \u03f5 should be further studied. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the ablation study, specifically mentioning the need to further explore the impact of the pre-defined threshold \u03f5. This feedback is somewhat helpful as it points out a specific area where the authors could expand their analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct these additional studies or what specific aspects to focus on. To be more helpful, the comment could include suggestions on how to design or conduct the additional studies or what specific outcomes to expect from them. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully guide the authors in making the necessary enhancements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that only Rouge-L is used for evaluation, which may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what alternative metrics or approaches could be used. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of Rouge-L as the sole evaluation metric, suggesting that it may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. However, it does not specify which part of the paper discusses the evaluation metrics or where the use of Rouge-L is mentioned. The authors can infer that it relates to the evaluation section, but the lack of explicit reference makes it weakly grounded. The comment is specific in identifying the issue with the evaluation metric, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that using only Rouge-L as the evaluation metric makes the evaluation unreliable, especially for classification tasks where Rouge-L is not sensitive enough. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the evaluation metrics used in the paper, specifically noting that only Rouge-L is used and suggesting that it may not be reliable, especially for classification tasks where Rouge-L is not sensitive enough. This feedback is somewhat helpful as it points out a limitation in the evaluation process, which could be addressed by using additional metrics or methods. However, the comment lacks specific suggestions or guidance on how to improve the evaluation, such as recommending alternative metrics or approaches. Without actionable advice, the feedback provides some insight but does not fully support the authors in enhancing their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a specific issue with the definitions of variables in lines 580-588, stating that they do not match the formula (Equation 3) and that the variable n_k is missing. This provides a clear and direct action for the authors to take, which is to correct the definitions to match the formula and ensure that all variables are accounted for. The feedback is explicit and concrete, giving the authors a clear path to follow for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 580-588,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula (Equation 3) and the missing variable n_k. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definitions of variables do not match the formula (Equation 3) and that the variable n_k is missing. This is a factual observation that can be verified by reviewing the specific lines mentioned. However, the comment does not provide additional context or reasoning to support why this is a significant issue or how it affects the paper. The lack of detailed explanation or examples makes it somewhat verifiable, as the authors would need to investigate the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the definitions of variables in lines 580-588, noting that they do not match the formula (Equation 3) and that the variable n_k is missing. This feedback is clear and actionable, as it directs the authors to correct the definitions to ensure consistency with the formula. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested ways to improve the clarity of the definitions. Despite this, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the sufficiency of a single vector for each class in the context of large variances in the semantic space. It also points out that such a strategy might conflict with the sample-specific assumption of the paper. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what experiments are missing. The action is implicit and vague, as the authors are left to infer that they need to clarify or provide additional experiments. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses a specific aspect of the paper, namely the use of a single vector for each class in the context of large variances in the semantic space. It questions the sufficiency of this approach and its potential conflict with the sample-specific assumption of the paper. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the single vector strategy and its potential conflict with the sample-specific assumption. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the sufficiency of a single vector for each class in the context of large variances in the semantic space. It also questions whether this strategy conflicts with the sample-specific assumption of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a critical question about the sufficiency of a single vector for each class in the context of large variances in the semantic space. It also points out a potential conflict with the sample-specific assumption of the paper, suggesting that some key experiments are missing. This feedback is valuable as it highlights an important area for clarification and improvement, prompting the authors to consider the implications of their approach and potentially revisit their experimental design. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or what additional experiments might be necessary. Overall, the comment is mostly helpful as it directs the authors' attention to a significant area for refinement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a key limitation of the work, which is the assumption of known number of intent classes during graph construction. It raises a concern about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, especially in the context of intent discovery evaluation. The reviewer acknowledges the authors\\' acknowledgment of this limitation but suggests that further clarification is needed to ensure a fair comparison with the baselines. While the comment implies that the authors should clarify the intent discovery experiment setting, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that clarification is necessary. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the assumption of known number of intent classes during graph construction, particularly in the context of the IntenDD experiments reported in Table 1. The comment specifies that the authors need to clarify the intent discovery experiment setting to ensure a fair comparison with baselines. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the work assumes a known number of intent classes during graph construction, which is a limitation. It questions the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, especially in the context of intent discovery evaluation. The reviewer acknowledges the authors\\' acknowledgment of this limitation but suggests that further clarification is needed to ensure a fair comparison. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the comparability of the experiments. This makes the claim somewhat verifiable, as the authors would need to investigate further to fully understand and address the concern.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a key limitation of the work, specifically the assumption of known number of intent classes during graph construction, which is particularly relevant for the intent discovery evaluation. It raises a concern about the comparability of the IntenDD experiments reported in Table 1 to the cited baselines, suggesting that further clarification is needed to ensure a fair comparison. The comment acknowledges the authors' acknowledgment of this limitation but emphasizes the need for additional clarification. While it highlights an important issue, the feedback could be more helpful if it provided specific suggestions on how to address this limitation or offered alternative approaches to consider. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks depth and actionable guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment appreciates the rigorous experimentation in the work but points out that the significance of the results is limited due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions that the experiments on corrupted CIFAR and ImageNet require the knowledge of corruption labels, which would simplify the problem. The reviewer provides references to related work that could be relevant. However, the comment does not offer specific guidance or suggestions on how the authors might address these limitations or improve the significance of their results. While it highlights potential issues, it lacks actionable steps or concrete advice for the authors to follow. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed guidance on how to address them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment appreciates the rigorous experimentation in the work but points out that the significance of the results is limited due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also mentions that the experiments on corrupted CIFAR and ImageNet require the knowledge of corruption labels, which would simplify the problem. The reviewer provides references to related work that could be relevant. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the results and suggesting potential improvements, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point appreciates the rigorous experimentation in the work but questions the significance of the results due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. The reviewer also points out that the experiments on corrupted CIFAR and ImageNet require the knowledge of corruption labels, which would simplify the problem. The comment provides references to related work that could be relevant, such as [1] and [2]. However, the claim lacks detailed reasoning or specific examples to fully substantiate the critique. While the references provide a basis for the claim, the comment could be strengthened by elaborating on how the limitations affect the significance of the results or by offering suggestions for improvement. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment appreciates the rigorous experimentation in the work but points out that the significance of the results is limited due to the application of d-separation criteria in the intervened graph with known variables and causal relationships. It also notes that the experiments on corrupted CIFAR and ImageNet require the knowledge of corruption labels, which would simplify the problem. The reviewer provides references to related work that could be relevant. However, the comment lacks specific suggestions or guidance on how the authors might address these limitations or improve the significance of their results. While it identifies potential areas for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. The authors would benefit from more specific advice or examples to enhance their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the alignment between gradient-based saliency methods and the feature selection mechanisms in the human brain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what alternative methods they could consider. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the alignment between gradient-based saliency methods and the feature selection mechanisms in the human brain. However, it does not specify which part of the paper this critique pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the methodology or results sections where these methods are discussed. The comment is specific in its critique, as it highlights a potential mismatch between the methods used and the underlying mechanisms in the human brain. However, without explicit grounding, the authors cannot confidently determine the exact part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the alignment between gradient-based saliency methods and the feature selection mechanisms in the human brain. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to existing literature, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the alignment between gradient-based saliency methods and the feature selection mechanisms in the human brain. This critique highlights a potential mismatch between the methods used in the paper and the underlying biological processes, which could be a significant issue for the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or detailed suggestions, the authors may find it challenging to effectively respond to this critique. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the use of Pythia as the model choice, noting that it is not state-of-the-art (SOTA) but has the advantage of available checkpoints. While the comment acknowledges the limitations of the model choice, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should consider using a different model or how to address the limitations of Pythia. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the choice of model, specifically mentioning \"Pythia,\" which provides some grounding as it allows the authors to identify the part of the paper being discussed. However, it does not specify which section or part of the paper this choice is discussed in, making it weakly grounded. The comment is specific in noting that Pythia is not state-of-the-art but has the advantage of available checkpoints, providing a clear direction for the authors to consider alternative models or justify their choice. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper uses Pythia, which is not state-of-the-art (SOTA), but has the advantage of available checkpoints. This claim is somewhat verifiable as it provides a logical reasoning for the choice of Pythia, noting its availability of checkpoints as a benefit. However, the comment lacks specific examples or references to compare Pythia with other state-of-the-art models, which would strengthen the claim. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but could be more robust with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the choice of model, noting that Pythia is not state-of-the-art (SOTA) but has the advantage of available checkpoints. While it points out a limitation, it does not provide any suggestions or guidance on how the authors might address this issue or improve their model choice. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, the comment is rated as barely helpful, as it highlights a concern but does not offer constructive advice or suggestions for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more information or resources should be provided to challenge the community to solve the image observation version of Franka Kitchen. It also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment further asks if the task can be intuitively completed with the provided offline data and suggests considering alternative data sources if not. While the comment provides a clear direction for improvement, it lacks specific guidance on how to address these issues or what additional information or resources should be provided. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing more information or resources to challenge the community to solve the image observation version of Franka Kitchen. It also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment further asks if the task can be intuitively completed with the provided offline data and suggests considering alternative data sources if not. While the comment does not explicitly mention a specific part of the paper, it is clear that it relates to the Franka Kitchen task and the evaluation of existing works. The authors can infer that it pertains to the methodology or results sections, but the comment lacks explicit grounding. The specificity is clear as it provides detailed questions and suggestions for improvement. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the challenges faced by existing works in the Franka Kitchen task, particularly regarding the image observation version. It suggests that the failure of these works might be attributed to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment also questions whether the task can be intuitively completed with the provided offline data and suggests considering alternative data sources. While the comment provides a logical framework for questioning the current state of the field, it lacks specific references or detailed reasoning to fully substantiate the claims. The authors would need to explore these questions further to address them effectively. Therefore, the comment is somewhat verifiable, as it provides a basis for inquiry but requires additional support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important questions about the Franka Kitchen task, particularly regarding the challenges faced by existing works. It suggests that more information or resources should be provided to challenge the community to solve the image observation version of the task. The comment also questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. Additionally, it asks if the task can be intuitively completed with the provided offline data and suggests considering alternative data sources if not. This feedback is clear and actionable, providing the authors with specific areas to consider for improvement and suggesting ways to enhance the challenge and scope of their work. However, the comment could be more helpful if it offered concrete suggestions or examples of how to provide additional resources or data. Overall, the comment is mostly helpful, as it guides the authors toward meaningful enhancements to their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks for an explanation of why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. While the comment implies that the authors should provide a rationale for this observation, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to explain the performance difference, but it lacks concrete guidance on how to address this issue. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but requires the authors to deduce the specific action needed.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for an explanation of why the multilingual model is \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification or explanation, as it seeks an understanding of why the multilingual model is \"noticeably weaker\" on specific evaluations. It does not contain a claim or an opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the performance of the multilingual model, asking for an explanation of why it is \"noticeably weaker\" on certain evaluations. This feedback is somewhat helpful as it prompts the authors to provide a detailed explanation or analysis of the model\\'s performance, which could be valuable for improving the paper. However, the comment lacks depth and does not offer suggestions on how to address the issue or improve the model\\'s performance. Therefore, it is rated as somewhat helpful, as it identifies a gap in the paper but does not fully guide the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the meaning of the numbers in brackets in tables #1 and #2. This is a clear and direct request for information, providing the authors with a specific action to take. The comment is explicit and concrete, as it directly instructs the authors to clarify the meaning of the numbers in brackets. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"tables #1,2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of the numbers in brackets, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the meaning of numbers in brackets in specific tables. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it directly requests clarification on the meaning of the numbers in brackets in specific tables. This feedback provides the authors with a specific area to address, which can help them improve the clarity and understanding of their results. However, the comment does not offer suggestions on how to rephrase or explain the numbers, which could enhance the guidance for the authors. Despite this, the comment is mostly helpful as it directs the authors to a specific area needing clarification, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the connection between the presented RDRO results and the listed limitations of previous fairness notions. It asks how these results relate to long-term fairness, as claimed in the paper. While the comment identifies a potential gap in the paper\\'s argument, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the connection between the results and the limitations. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the connection between the presented RDRO results and the limitations of previous fairness notions, specifically questioning how these results relate to long-term fairness. However, it does not specify which part of the paper discusses these connections, making it weakly grounded. The comment is specific in its inquiry about the relationship between the results and the limitations, providing a clear direction for the authors to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the connection between the presented RDRO results and the limitations of previous fairness notions, specifically in the context of long-term fairness. The reviewer acknowledges understanding the paper\\'s focus on repeated distributionally robust optimization and its convergence analysis but expresses uncertainty about how these results relate to the limitations discussed. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim or guide the authors in addressing the issue. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the concern and provide a response. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the connection between the presented RDRO results and the limitations of previous fairness notions, specifically in the context of long-term fairness. While it identifies a potential gap in the paper's argument, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment highlights an area that requires clarification but lacks actionable feedback, such as prompting the authors to provide a detailed explanation or analysis of the connection between the results and the limitations. As a result, the comment is somewhat helpful, as it points out a potential weakness but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the connection between the presented RDRO results and the limitations of previous fairness notions, specifically in the context of long-term fairness. While it identifies a potential gap in the paper\\'s argument, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the connection between the results and the limitations. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the connection between the presented RDRO results and the limitations of previous fairness notions, specifically questioning how these results relate to long-term fairness, as claimed in the paper. However, it does not specify which part of the paper discusses these connections, making it weakly grounded. The comment is specific in its inquiry about the relationship between the results and the limitations, providing a clear direction for the authors to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the connection between the presented RDRO results and the limitations of previous fairness notions, specifically in the context of long-term fairness. The reviewer acknowledges understanding the paper's focus on repeated distributionally robust optimization and its convergence analysis but expresses uncertainty about how these results relate to the limitations discussed. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim or guide the authors in addressing the issue. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the concern and provide a response. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the connection between the presented RDRO results and the limitations of previous fairness notions, specifically in the context of long-term fairness. While it identifies a potential gap in the paper's argument, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment highlights an area that requires clarification but lacks actionable feedback, such as prompting the authors to provide a detailed explanation or analysis of the connection between the results and the limitations. As a result,"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether the errors are normalized to per datapoint position errors and, if so, whether an error of 5 cm with HDR-IL is reasonable. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns. The action is implicit, as the authors need to infer that they should investigate and possibly clarify the normalization of errors or provide additional context. However, the comment lacks concrete details on how to implement these actions, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns about the accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. The reviewer questions whether the errors are normalized to per datapoint position errors and, if so, whether an error of 5 cm with HDR-IL is reasonable. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the accuracy of 29 percent with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether the errors are normalized to per datapoint position errors and, if so, whether an error of 5 cm with HDR-IL is reasonable. While the comment identifies specific issues, it lacks detailed reasoning or evidence to fully substantiate the claim about the normalization of errors or the reasonableness of the error units. The authors would need to provide additional context or analysis to fully address these concerns. Therefore, the comment is somewhat verifiable, as it provides a basis for inquiry but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the accuracy and error units in the paper, particularly regarding the 29 percent accuracy with table assembly tasks and the high Euclidean distance error units in Table 1. It questions whether the errors are normalized to per datapoint position errors and, if so, whether an error of 5 cm with HDR-IL is reasonable. This feedback is clear and actionable, as it prompts the authors to clarify the normalization of errors and potentially revisit the accuracy and error units in their analysis. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered alternative approaches for improving the accuracy and error reporting. Overall, the comment is mostly helpful as it directs the authors' attention to specific areas needing clarification or improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the article provides a fresh perspective but notes that it does not reach a conclusion. It suggests that the article implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific conclusions they should reach. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a conclusion or further discussion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges that the article provides a fresh perspective but notes that it does not reach a conclusion. It suggests that the article implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment does not specify which part of the paper this observation is based on, nor does it provide detailed guidance on how the authors might address this issue or what specific conclusions they should reach. The lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and how to improve it. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the article provides a fresh perspective but notes that it does not reach a conclusion. It suggests that the article implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the article provides a fresh perspective but notes that it does not reach a conclusion. It suggests that the article implies that existing sentiment analysis models are capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific guidance or actionable feedback on how the authors might address this issue or what conclusions they should reach. While it identifies a potential area for improvement, the feedback is vague and does not provide detailed suggestions for enhancing the draft. Therefore, the comment is barely helpful, as it provides some insight but does not fully support the authors in improving their work.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm is based on a pre-defined labeler strategy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the theoretical results. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the theoretical results, stating that they are not surprising and have limited contribution to the algorithm design. However, it does not specify which part of the paper these results are discussed in, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in detailing what aspects of the theoretical results are problematic or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm is based on a pre-defined labeler strategy. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the theoretical results, stating that they are not surprising and have limited contribution to the algorithm design, as the algorithm is based on a pre-defined labeler strategy. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve the theoretical results. Without detailed guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling, planning, and reduces the research contribution. While the comment highlights areas that need clarification, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues, such as by providing more detailed explanations or expanding the research contribution. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two concerns: first, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, and second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment does not specify which part of the paper these concerns relate to, such as specific sections or figures. This makes it difficult for the authors to identify the exact areas needing attention. Additionally, the comment lacks specificity in detailing what needs to be addressed or improved in these areas. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two claims: (1) \"How reverse chain proved to be effective in multi-API planning is not delineated in detail,\" and (2) \"This article focuses on comparing multiple tools or methods in API calling & planning & reduces research contribution.\" The first claim is based on the observation that the effectiveness of reverse chain in multi-API planning is not explained in detail, which is a subjective judgment. The second claim is also subjective, as it suggests that the article lacks originality or contribution by focusing on comparisons rather than novel research. Both claims are based on the reviewer\\'s interpretation and lack specific evidence or references to support them, making them difficult to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two specific areas for improvement in the paper. First, it questions the lack of detail on how reverse chain proved to be effective in multi-API planning, suggesting that this aspect is not adequately explained. Second, it notes that the article focuses on comparing multiple tools or methods in API calling and planning, which may reduce the research contribution. While the comment highlights important areas for clarification and improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need further development but does not provide detailed advice on how to enhance the paper. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly recommends rejection of the paper due to the perceived weaknesses in experimental rigour and the significant editing required to address other issues. However, it does not provide any specific guidance or suggestions on how the authors might address these weaknesses or improve the paper. The action is clear, but the lack of detailed advice on how to address the issues makes it somewhat actionable. The authors know that rejection is being recommended, but they are left without concrete steps to take to improve their draft. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the weaknesses in the review above,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with experimental rigour and the unrealistic nature of the required editing, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a recommendation for rejection based on perceived weaknesses in experimental rigour and the unrealistic nature of the required editing. However, the comment lacks specific evidence, reasoning, or examples to support these claims. The authors are left without detailed guidance on how to address these issues or why they are considered significant. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the recommendation for rejection.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable recommendation for rejection of the paper, citing the weaknesses in experimental rigour and the unrealistic nature of the required editing. However, it lacks specific details or suggestions on how the authors might address these issues or improve the paper. While the feedback is clear in its stance, it does not offer actionable guidance or constructive suggestions for improvement, leaving the authors with a strong recommendation but no clear path forward. Therefore, the comment is somewhat helpful, as it identifies a significant issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison between the standalone Medusa and Medusa+ParallelSpec setups. It questions whether the speedup gain is due to the change in draft model architecture or the ability to predict draft tokens in parallel. The reviewer suggests providing a baseline where only the draft model architecture is altered, or renaming the modified setting to avoid confusion. This feedback is explicit in its suggestion to address the issue by providing a baseline or renaming the setting, but it does not provide detailed guidance on how to implement these suggestions. The action is concrete, as it specifies what needs to be done, but it could be more detailed in terms of how to execute these steps. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 266-267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparison between the standalone Medusa and Medusa+ParallelSpec setups, questioning the fairness of the competition and suggesting the need for a baseline or a different name for the modified setting. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between the standalone Medusa and Medusa+ParallelSpec setups. It questions whether the speedup gain is due to the change in draft model architecture or the ability to predict draft tokens in parallel. The reviewer suggests providing a baseline where only the draft model architecture is altered or renaming the modified setting to avoid confusion. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the unfair competition. The suggestion for a baseline or a different name provides some guidance, but the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between the standalone Medusa and Medusa+ParallelSpec setups, questioning whether the speedup gain is due to the change in draft model architecture or the ability to predict draft tokens in parallel. It suggests providing a baseline where only the draft model architecture is altered or renaming the modified setting to avoid confusion. This feedback is clear and actionable, as it points out a specific area for improvement and provides a clear direction for addressing the issue. However, it could be more helpful if it included specific suggestions on how to implement the suggested changes or examples of how to structure the comparison. Overall, the comment is mostly helpful, as it effectively guides the authors in improving their draft by addressing a potential weakness in the experimental setup.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reason behind the focus on Masked Language Models and whether experiments did not work with an autoregressive LM. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the reason for focusing on Masked Language Models and whether experiments did not work with an autoregressive LM. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the reasons behind the choice of Masked Language Models, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the rationale behind the focus on Masked Language Models and whether experiments did not work with an autoregressive LM. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the reason for focusing on Masked Language Models and whether experiments did not work with an autoregressive LM. While it identifies a potential area for clarification, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as barely helpful, as it provides some insight but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate suggestions. The first part asks how the map is encoded, which is a specific question that requires the authors to provide more details about their methodology. The second part suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. This is an explicit action that provides a clear direction for the authors to improve their draft by including additional experimental results. However, the comment lacks concrete guidance on how to encode the map or what specific aspects of the method should be demonstrated. While the actions are clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment consists of two parts. The first part asks about the encoding of the map, which is a specific question that requires clarification. The second part suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. While the first part is somewhat vague, the second part is specific and provides a clear direction for improvement. However, the comment does not specify which part of the paper these questions or suggestions relate to, making it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two parts. The first part is a question asking how the map is encoded, which is a factual inquiry that does not require verification. The second part suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. This is a claim that requires justification, as it implies that the authors should include additional experiments to validate their method. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment consists of two parts. The first part asks about the encoding of the map, which is a specific question that requires clarification. This part provides a clear direction for the authors to improve their draft by seeking more detailed information about their methodology. The second part suggests that the authors should demonstrate the effectiveness of their method on the experiments proposed in YNet. This is a constructive suggestion that encourages the authors to expand their experimental validation, which is important for establishing the robustness and applicability of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects of the method should be demonstrated. Overall, the comment is mostly helpful as it identifies areas for improvement and provides clear directions for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, it does not provide any explicit or implicit actions for the authors to take. There is no suggestion or guidance on how the authors might address this issue or improve their model. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific comparison between the proposed model and the MSA Transformer, focusing on the r2 metric. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in identifying the issue of the proposed model not being significantly better than the MSA Transformer in terms of r2, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of r2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comparison or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment points out a specific issue with the proposed model, suggesting that it is not significantly better than the MSA Transformer in terms of r2. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their model. Without actionable feedback or additional context, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a problem but does not offer constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests more mathematical details regarding the concept of an \"ensemble of independent measures on the full feature space\" and its relevance to the scaling explanation. This feedback provides a clear and direct action for the authors to take, which is to include additional mathematical details to clarify the concept. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"top of page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the explanation of the concept of an \"ensemble of independent measures on the full feature space\" and requests more mathematical details. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of a concept mentioned in the paper, specifically \"ensemble of independent measures on the full feature space,\" and requests more mathematical details to understand its relevance to the scaling explanation. The comment does not contain a claim or an opinion that requires verification. It is a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper where the authors need to provide more mathematical details. It highlights a lack of clarity regarding the concept of an \"ensemble of independent measures on the full feature space\" and its relevance to the scaling explanation. By pointing out this gap, the comment provides a clear and actionable suggestion for the authors to enhance the mathematical rigor and clarity of their explanation. This feedback is mostly helpful as it guides the authors in improving the technical depth and understanding of their work, but it could be more comprehensive by offering specific suggestions on how to elaborate on the mathematical details. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using BlenderBot 2.0 with incorporated knowledge to improve the quality of dialogs. While the comment implies that this could be an interesting direction, it does not provide explicit instructions or guidance on how to implement this idea. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this option but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests an idea for improvement by suggesting that the authors consider using BlenderBot 2.0 with incorporated knowledge to improve the quality of dialogs. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion but lacks grounding, as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an idea for improvement by suggesting that the authors consider using BlenderBot 2.0 with incorporated knowledge to improve the quality of dialogs. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it could be implemented. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting idea for improvement by suggesting that the authors consider using BlenderBot 2.0 with incorporated knowledge to enhance the quality of dialogs. This feedback is somewhat helpful as it provides a specific direction for potential enhancement, but it lacks depth and does not offer detailed guidance on how to implement this idea. The authors are left with a general suggestion rather than a comprehensive plan for improvement. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for further exploration but does not fully address the authors\\' needs for improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. It also assumes that the samples should overlap, as the paper calculates Krippendorff \\u03b1. While the comment identifies a specific issue that needs clarification, it does not provide explicit instructions on how the authors should address this. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the overlap of samples, but they may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff \\u03b1. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in identifying the issue of clarity regarding sample overlap, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. The reviewer assumes that the samples should overlap, as the paper calculates Krippendorff \\u03b1, which is a measure of inter-rater reliability. However, the comment does not provide specific examples or references to support this assumption, making it difficult for the authors to understand the basis of the claim. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks detailed reasoning or references to substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the paper regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff \\u03b1, which is a measure of inter-rater reliability. While the comment points out a potential area for improvement, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it highlights a gap in the paper's clarity, but it does not offer actionable steps for improvement, leaving the authors with limited guidance on how to enhance their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. It assumes that the samples should overlap, as the paper calculates Krippendorff \\u03b1. While the comment identifies a specific area that needs clarification, it does not provide explicit instructions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the overlap of samples, but they may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation. It assumes that the samples should overlap, as the paper calculates Krippendorff \\u03b1, which is a measure of inter-rater reliability. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in identifying the issue of clarity regarding sample overlap, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of samples rated by GPT-4 and whether they overlap with the samples used in human evaluation are not clearly stated. It assumes that the samples should overlap, as the paper calculates Krippendorff \\u03b1, which is a measure of inter-rater reliability. However, the comment does not provide specific examples or references to support this assumption, making it difficult for the authors to understand the basis of the claim. Without additional context or evidence, the claim remains"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between arg-wise consistency and accuracy, suggesting that the authors clarify these concepts. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. However, the comment does not explicitly instruct the authors to clarify these concepts or provide specific guidance on how to address the confusion. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms and their relationship. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the difference between arg-wise consistency and accuracy, suggesting that the authors clarify these concepts. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification and provides a logical reasoning for the confusion, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difference between arg-wise consistency and accuracy, suggesting that the authors clarify these concepts. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or provide context for the confusion. Without additional information or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the difference between arg-wise consistency and accuracy, suggesting that the authors clarify these concepts. It also provides an intuition about the relationship between pred-wise consistency and label annotation agreement, which could be helpful for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address the confusion or improve the clarity of the concepts. While it identifies an area for improvement, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding how position embeddings are being provided, could enhance reproducibility. Additionally, it recommends sharing the code of the implementation, which is a common expectation for reproducibility. While the comment implies that these actions would improve the paper, it does not explicitly instruct the authors to take these steps. The actions are concrete and can be inferred, but the lack of explicit guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings. It also recommends sharing the code of the implementation for reproducibility. However, the comment does not specify which part of the paper these details should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that providing more details on the neural network parametrization of the reverse process, specifically regarding position embeddings, could enhance reproducibility. It also recommends sharing the code of the implementation, which is a common expectation for reproducibility. While the comment provides a logical reasoning for the need for additional details and code, it lacks specific examples or references to support the claim. The suggestion is mostly verifiable as it offers a clear rationale for the need for additional information, but the lack of detailed examples or references makes it somewhat less robust. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides actionable feedback by suggesting that the authors should provide more details on the neural network parametrization of the reverse process, specifically regarding how position embeddings are being provided. This feedback is valuable as it highlights a specific area that could enhance the reproducibility of the work. Additionally, the comment recommends sharing the code of the implementation, which is a common expectation for reproducibility. While the comment identifies a clear area for improvement, it could be more helpful if it offered specific suggestions or examples of what additional details or code would be beneficial. Overall, the comment is mostly helpful as it guides the authors towards improving the reproducibility of their work, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the draft, noting that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is explicit and provides a clear action for the authors to take, which is to identify and remove the repeated content. The comment is concrete, as it specifies the exact section and issue, allowing the authors to address the problem directly. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the first paragraph contains a repeated paragraph, providing clear guidance on what needs to be addressed. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific issue with the draft, noting that the first paragraph of section 3.3 contains a repeated paragraph. This is a factual observation that does not require any supporting evidence or reasoning. It is a straightforward statement of a problem that the authors can easily verify by reviewing their draft. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, noting that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is clear and actionable, as it directs the authors to a specific area where they need to make corrections. By highlighting this redundancy, the comment provides a concrete step for the authors to take to improve the clarity and efficiency of their writing. However, the comment could be more helpful if it offered suggestions on how to rephrase or restructure the content to avoid repetition. Overall, the comment is mostly helpful as it points out a specific issue that the authors can address to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sustainability and reusability of synthetic data, which is generated on-the-fly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to improve the sustainability and reusability of their synthetic data. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the sustainability and reusability of synthetic data generated on-the-fly. However, it does not specify which part of the paper this concern relates to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the sustainability and reusability of synthetic data, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sustainability and reusability of synthetic data generated on-the-fly. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might impact the paper. Without any context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the sustainability and reusability of synthetic data generated on-the-fly, which is an important consideration for the authors. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or improve the sustainability of their synthetic data. Without actionable advice or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out two issues with the paper: the lack of examination of alternative RNA structures and the need to consider RNA abundance when building datasets. While the comment identifies these areas for improvement, it does not provide explicit guidance on how to address them. The authors are left to infer that they should explore alternative RNA structures and incorporate RNA abundance into their dataset building process, but the comment lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the introduction of the ProbTransfomer model and its application to the challenge of RNA folding. It points out that the likelihood of alternative RNA structures is mostly dictated by biological circumstances, which the authors do not examine. Additionally, it suggests considering RNA abundance when building datasets. However, the comment does not specify which part of the paper discusses the ProbTransfomer model or the RNA folding challenge, making it weakly grounded. The comment is specific in identifying the need to examine alternative RNA structures and the importance of considering RNA abundance, but it lacks explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. It also suggests that authors should consider RNA abundance when building datasets. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that the authors have not examined alternative RNA structures or the importance of considering RNA abundance. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issues. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two areas for improvement in the paper. First, it points out that the authors do not examine the likelihood of alternative RNA structures arising, which are mostly dictated by biological circumstances. This suggests that the authors should consider biological factors more thoroughly. Second, the comment recommends that the authors should also consider RNA abundance when building datasets. These suggestions are clear and actionable, providing the authors with specific areas to address in their work. However, the comment could be more helpful if it offered additional guidance or examples on how to incorporate these considerations into the study. Overall, the feedback is mostly helpful as it directs the authors to important aspects of their work that need further exploration and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\u03b7=1200). It suggests that this coefficient might be weak, resulting in sparse couplings that favor the authors\\' method. The reviewer acknowledges that the method may not be beneficial in the strong-regularization regime but emphasizes the need for this issue to be addressed in the paper. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address it, such as suggesting alternative regularization coefficients or methods to explore. The action is implicit and somewhat vague, as the authors are left to infer the need for a more thorough discussion or analysis of the regularization term. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the numerical results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a potential issue with the use of a single entropic regularization coefficient (\\u03b7=1200) and suggests that this might be a weak term resulting in sparse couplings. The comment further acknowledges that the method may not be beneficial in the strong-regularization regime but emphasizes the need for this issue to be acknowledged in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the use of a single entropic regularization coefficient (\\u03b7=1200) in the numerical results. The reviewer suggests that this coefficient might be weak, leading to sparse couplings that favor the authors\\' method. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim that the regularization term is weak. The suggestion to acknowledge this issue in the paper is a reasonable one, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the numerical results, specifically the use of a single entropic regularization coefficient (\\u03b7=1200). It suggests that this coefficient might be weak, resulting in sparse couplings that favor the authors' method. The reviewer acknowledges that the method may not be beneficial in the strong-regularization regime but emphasizes the need for this issue to be acknowledged in the paper. This feedback is somewhat helpful as it points out a potential weakness in the methodology and encourages the authors to address it in their paper. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or alternative approaches to consider. Overall, the comment offers some guidance but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the information provided about the Vlachos and Riedel 2014 dataset. It states that the dataset has no Evidence, but the paper mentions that the authors collected sources used by the journalists in the analysis. This suggests that the authors should clarify or correct the information in Table 1 to accurately reflect the dataset\\'s content. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the necessary corrections. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the discrepancy between the claim that the Vlachos and Riedel 2014 dataset has no Evidence and the paper\\'s statement about collecting sources used by the journalists. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy in the information provided about the Vlachos and Riedel 2014 dataset. It claims that the dataset has no Evidence, but the paper mentions that sources were collected for the analysis. This discrepancy is supported by the specific reference to the paper\\'s statement about collecting sources, which provides a clear basis for the claim. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks some depth in its explanation.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a discrepancy in the information provided about the Vlachos and Riedel 2014 dataset. It points out that the dataset is claimed to have no Evidence, but the paper mentions that sources were collected for the analysis. This feedback is clear and actionable, as it prompts the authors to clarify or correct the information in Table 1 to accurately reflect the dataset's content. However, the comment could be more helpful if it provided specific suggestions on how to address the discrepancy or offered additional context on why this clarification is important. Overall, the comment is mostly helpful as it guides the authors towards improving the accuracy of their dataset description, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include details about the parameters used in each simulator, such as whether they used the GPU pipeline in IsaacGym, the CPU pipeline, the number of substeps for physics simulation, and the total number of vertices in the simulation. This provides a clear and direct action for the authors to take, specifying exactly what information needs to be added to their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"simulators,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of details about the parameters used in each simulator, such as the GPU pipeline, CPU pipeline, substeps for physics simulation, and the total number of vertices in the simulation. This provides clear guidance on what information should be added to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that different simulators have varying parameters that can significantly impact performance. It requests the inclusion of details about the parameters used in each simulator, such as the GPU pipeline, CPU pipeline, substeps for physics simulation, and the total number of vertices in the simulation. While the comment highlights the importance of parameter details, it does not provide specific examples or references to support the claim that these details are crucial. The suggestion is logical and reasonable, but without additional evidence or examples, it is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical aspect of the paper that requires attention: the potential impact of different simulator parameters on performance. It provides a clear and actionable suggestion by explicitly instructing the authors to include details about the parameters used in each simulator, such as the GPU pipeline, CPU pipeline, substeps for physics simulation, and the total number of vertices in the simulation. This feedback is highly helpful as it guides the authors on what specific information to include to enhance the transparency and reproducibility of their work. By addressing this point, the authors can improve the clarity and robustness of their experimental setup, which is essential for the credibility of their findings. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of the hyperparameters $s$ and $k$ in the proposed method, noting that their choice is crucial for the effectiveness of the method. It points out that the empirical selection of $s$ and $k$ as 5 in the Supplementary Material A.3 reduces the generalizability of the proposed loss function. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for selecting these hyperparameters. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more robust justification or method for selecting $s$ and $k$. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the empirical selection of hyperparameters $s$ and $k$, noting that this reduces the generalizability of the proposed loss function. The comment provides a clear direction for improvement, suggesting that the authors should provide a more robust justification or method for selecting these hyperparameters. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the empirical selection of hyperparameters $s$ and $k$ as 5 in the Supplementary Material A.3 reduces the generalizability of the proposed loss function. This claim is somewhat verifiable as it provides a logical reasoning for the concern, but it lacks specific examples or detailed explanations of how the empirical selection affects generalizability. The authors would need to provide more context or evidence to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the proposed method, specifically the empirical selection of hyperparameters $s$ and $k$ in the Supplementary Material A.3. It highlights that this empirical choice reduces the generalizability of the proposed loss function, which is a significant concern for the effectiveness of the method. The comment provides a clear and actionable suggestion for the authors to provide a more robust justification or method for selecting these hyperparameters, which would enhance the generalizability of the proposed loss function. This feedback is valuable as it guides the authors towards improving the robustness and applicability of their method. However, the comment could be more helpful if it offered specific suggestions or examples of alternative methods for selecting hyperparameters. Overall, the comment is mostly helpful, as it effectively directs the authors to address a critical aspect of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare the optimization times of their approach with OpenTuner, which can adaptively use different search techniques. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for a comparison, but it lacks concrete details on how to execute this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"OpenTuner\" and \"simulated annealing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a comparison of optimization times with OpenTuner, which can adaptively use different search techniques. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should compare the optimization times of their approach with OpenTuner, which can adaptively use different search techniques. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would benefit the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a comparison between the optimization times of the authors\\' approach and OpenTuner, which can adaptively use different search techniques. This feedback is somewhat helpful as it provides a specific direction for the authors to improve their work by comparing their method with a more adaptive approach. However, the comment lacks depth and does not offer detailed guidance on how to conduct the comparison or what specific aspects to focus on. To be more helpful, the comment could include suggestions on how to measure and compare optimization times or provide examples of how this comparison could enhance the paper. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited novelty of the work, noting that many previous works have introduced diffusion models into the anomaly detection area. It also mentions specific examples of such works. The reviewer further points out that while the paper introduces NCSN as a branch of the diffusion model, it is not an original idea to introduce this model into anomaly detection. Additionally, the comment suggests that the work only makes minor adjustments to NCSN by combining popular techniques like time step embedding and establishing a correspondence between anomaly and score in the diffusion model. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve the novelty of their work. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to enhance the originality of their contribution. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the work, specifically mentioning that there are many previous works that have introduced diffusion models into the anomaly detection area. It also highlights that the work introduces NCSN as a branch of the diffusion model but does not consider it an original idea. The comment further notes that the work only makes minor adjustments to NCSN by combining popular techniques like time step embedding and establishing a correspondence between anomaly and score in the diffusion model. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The feedback is specific in identifying the lack of originality and the limited adjustments made to NCSN. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work lacks novelty due to the introduction of diffusion models into the anomaly detection area, referencing specific works as examples. It also suggests that the work only makes minor adjustments to NCSN by combining popular techniques like time step embedding and establishing a correspondence between anomaly and score in the diffusion model. While the comment provides references to previous works, it lacks detailed reasoning or specific examples to fully substantiate the claim about the lack of originality. The references are not elaborated upon, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the paper, noting that many previous works have introduced diffusion models into the anomaly detection area. It specifically mentions examples of such works, which provides some context and evidence for the claim. The comment also points out that the paper introduces NCSN as a branch of the diffusion model but does not consider it an original idea. Additionally, it highlights that the work only makes minor adjustments to NCSN by combining popular techniques like time step embedding and establishing a correspondence between anomaly and score in the diffusion model. While the comment identifies a significant issue with the novelty of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the originality of their contribution. The feedback is somewhat helpful as it points out a critical area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: grammar errors and the lack of labeled axes in Figure 2. While the comment identifies these issues, it does not provide explicit guidance on how to correct them. The authors are left to infer that they need to address these errors, but the lack of detailed instructions makes the action vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: grammar errors and the lack of labeled axes in Figure 2. The first point is fully grounded as it explicitly mentions \"The paper has many grammar errors,\" allowing the authors to accurately identify the parts of the paper that need attention. The second point is also fully grounded, as it refers to \"Figure 2's axes are not labeled,\" providing clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about grammar errors and the lack of labeled axes in Figure 2. These are objective observations that do not require verification or evidence. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: grammar errors and the lack of labeled axes in Figure 2. While it points out these problems, it does not provide detailed guidance or suggestions on how to correct them. The authors are left to infer the nature of the grammar errors and the specific elements that need labeling in Figure 2. This feedback is somewhat helpful as it highlights areas that need attention, but it lacks depth and actionable advice, making it difficult for the authors to effectively address the issues. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the error analysis in section 5.2 is \"crappy\" and suggests that more quantitative error analysis would be beneficial. This feedback provides a clear and direct action for the authors to take, which is to conduct a more quantitative error analysis. The comment is explicit and concrete, giving the authors a specific direction to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the error analysis, suggesting that more quantitative error analysis would be beneficial. This provides clear guidance on what needs to be improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis in section 5.2 is \"crappy\" and suggests that more quantitative error analysis would be beneficial. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the current analysis is inadequate. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to improve their analysis. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the error analysis in section 5.2, labeling it as \"crappy\" and suggesting that more quantitative error analysis would be beneficial. This feedback is clear and actionable, providing the authors with a specific area to improve in their draft. By highlighting the need for more quantitative analysis, the comment offers a clear direction for enhancing the rigor and depth of the error analysis. However, the comment could be more helpful if it provided examples or guidance on how to conduct a more quantitative error analysis. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that they should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between the distributions. Additionally, it points out a potential issue with Fig. 6c and 6d, suggesting that the authors should cross-check if the Proxy-A distance is close. These actions are clear and provide concrete guidance on how the authors can improve their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance. Additionally, it points out a potential issue with the figures, asking the authors to cross-check if the Proxy-A distance is close. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between the distributions. This is a logical suggestion based on the common practice of using multiple methods to validate results. The comment also points out a potential issue with Fig. 6c and 6d, suggesting that they may be identical, which the authors should verify. While the suggestion is based on logical reasoning, it lacks specific references or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but could be strengthened with additional evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides actionable feedback by suggesting that the authors should not rely solely on t-SNE for evaluating distribution alignment and recommends measuring the Proxy-A distance between the distributions. This is a constructive suggestion that could enhance the robustness of the evaluation. Additionally, the comment points out a potential issue with Fig. 6c and 6d, suggesting that they may be identical and recommending the authors to cross-check the Proxy-A distance. This feedback is clear and provides specific guidance on how the authors can improve their work, making it mostly helpful. However, it could be more helpful if it included additional context or examples to further support the suggestion. Therefore, the comment aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding the rationale behind using cross entropy for the first (P \u00e2\u20ac\u201c floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. While the questions imply that the authors should provide explanations or comparisons, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these explanations or comparisons in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L216-217,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the rationale behind using cross entropy for the first (P \u00e2\u20ac\u201c floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. This provides clear guidance on what the authors need to clarify or explain in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions seeking clarification on the rationale behind using cross entropy for the first (P \u00e2\u20ac\u201c floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. These questions are factual inquiries that do not express an opinion, judgment, or suggestion. They do not require verification or evidence, as they are seeking information rather than making claims. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions regarding the rationale behind using cross entropy for the first (P \u00e2\u20ac\u201c floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. This feedback is clear and actionable, as it prompts the authors to provide detailed explanations or comparisons that could enhance the clarity and comprehensiveness of their work. By addressing these questions, the authors can improve the transparency and understanding of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it included suggestions on how to present these explanations or comparisons in the draft. Overall, the comment is mostly helpful, as it identifies areas for improvement and provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS, but the paper does not discuss these works in the related work section. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include these references in their related work section, but it does not specify how to integrate them or what additional context should be provided. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the absence of discussion on the validation of the proposed cross-modality adaptation in related works, specifically mentioning BEVDepth and 2DPASS. However, it does not specify which part of the paper this issue is related to, such as the introduction or the related work section. The authors can infer that it pertains to the related work section, but the lack of explicit mention makes it weakly grounded. The comment is specific in identifying the absence of discussion on the validation of the proposed method in related works, but it does not provide detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper does not discuss the validation of the proposed cross-modality adaptation in related works, specifically mentioning BEVDepth and 2DPASS. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out a potential oversight in the paper's related work section, specifically mentioning that the proposed cross-modality adaptation has been validated in BEVDepth and 2DPASS but are not discussed in the paper. This feedback is somewhat helpful as it identifies a gap in the literature review that the authors should address. However, the comment lacks specificity and does not provide guidance on how the authors might integrate these references or what additional context should be included. To be more helpful, the comment could suggest specific ways to incorporate these references or explain why they are relevant to the paper's contribution. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that Table 1 lacks generation results like BLEU scores, which are crucial for assessing the quality of output. This feedback is clear and direct, instructing the authors to include these metrics in their table. The action is explicit and concrete, as it specifies exactly what needs to be added to improve the table. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the table, namely the inclusion of generation results like BLEU scores to assess the quality of output. This provides clear guidance on what needs to be added to improve the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 only presents test loss as a metric for performance degradation, without including generation results such as BLEU scores. This is a factual observation rather than a claim or suggestion that requires verification. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that it only presents test loss as a metric for performance degradation without including generation results like BLEU scores. This feedback is clear and actionable, as it directs the authors to include additional metrics to assess the quality of output. By highlighting this omission, the comment provides a concrete suggestion for improvement, making it mostly helpful. However, it could be more helpful if it offered additional guidance on how to incorporate these metrics or why they are important. Overall, the comment is mostly helpful as it points out a critical gap in the presentation of results and offers a clear direction for enhancement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper, which is primarily theoretical, could be improved by including experiments to validate the analysis, particularly for discussions on different regimes. While the comment implies that experiments should be included, it does not specify which experiments are necessary or how they should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact experiments to include and how they should be designed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper, which is primarily theoretical, could be improved by including experiments to validate the analysis, particularly for discussions on different regimes. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or discussion. The authors may have to infer that it relates to the theoretical analysis or discussions on different regimes. While the comment provides a general direction for improvement, it lacks specificity in terms of which part of the paper needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that including experiments would be beneficial to validate the analysis, particularly for discussions on different regimes. However, the comment does not provide any specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. Without additional context or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that including experiments in the paper would be beneficial, particularly for validating the analysis and supporting discussions on different regimes. This feedback is somewhat helpful as it identifies a potential area for improvement that could enhance the paper's credibility and comprehensiveness. However, the comment lacks specificity regarding which experiments should be included or how they would contribute to the analysis. To be more helpful, the comment could provide more detailed guidance or examples of experiments that could be conducted. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks depth and actionable details.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. While the action is explicit, it lacks concrete details on how to implement these baselines or what specific insights they might offer. The authors are given a clear direction to include these baselines, but the comment does not provide guidance on how to structure or present the results. Therefore, the comment is somewhat actionable, as it identifies a specific action but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors may infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in its suggestion to include two naive baselines, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. However, it does not provide any reasoning or evidence to support why these specific baselines would be beneficial or how they might contribute to the understanding of the benchmark. The comment lacks detailed justification or examples, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including two naive baselines with only text and a single center frame to provide insights into the benchmark. This feedback is somewhat helpful as it offers a specific suggestion for improving the experimental setup by adding additional baselines. However, the comment lacks detailed guidance on how these baselines should be implemented or what specific insights they might provide. To be more helpful, the comment could include examples of how these baselines might be constructed or what kind of insights they could offer. Overall, the feedback is somewhat helpful as it points out a potential enhancement but could be more comprehensive with additional details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a specific issue with the description of advantage-weighted regression, noting that it lacks clarity regarding the Q function being w.r.t. \\\\mu, which is crucial for understanding the constrained optimization in Eq. 4. While the comment points out a specific area that needs clarification, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they should clarify the description of the Q function in relation to \\\\mu, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it highlights a specific area for improvement but does not provide detailed instructions on how to implement the change.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the description of advantage-weighted regression\" and \"Eq. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the description lacks clarity regarding the Q function being w.r.t. \\\\mu, which is crucial for understanding the constrained optimization in Eq. 4. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the description of advantage-weighted regression is unclear, specifically regarding the Q function being w.r.t. \\\\mu, which is crucial for understanding the constrained optimization in Eq. 4. The comment provides a logical reasoning by explaining the importance of this clarification for the readers' understanding. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the clarification needed, which limits the comment's verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion in the paper regarding the description of advantage-weighted regression. It points out a critical piece of information missing from the explanation, namely that the Q function is w.r.t. \\\\mu, which is essential for understanding the constrained optimization in Eq. 4. This feedback is clear and actionable, as it directs the authors to clarify this aspect in their draft. However, the comment could be more helpful if it provided suggestions on how to rephrase or expand the explanation to make it clearer. Overall, the comment is mostly helpful as it highlights a specific area for improvement and provides a clear direction for the authors to enhance the clarity of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method has multiple stages, making it cumbersome compared to existing pruning methods that do not require fine-tuning. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the algorithm or address the issue of multiple stages. Without specific suggestions or directions, the authors are left without a clear understanding of what changes to make to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the overall algorithm being cumbersome due to multiple stages, comparing it to existing pruning methods that do not require fine-tuning. However, it does not specify which part of the paper discusses the algorithm or the multiple stages, making it weakly grounded. The comment is specific in pointing out the issue of multiple stages and the comparison to existing methods, but it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is cumbersome due to having multiple stages, while many existing pruning methods do not require fine-tuning. However, the comment lacks specific examples or references to existing pruning methods that do not require fine-tuning, making it difficult for the authors to understand the basis of the claim. Without detailed comparisons or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that while each part of the proposed method is effective, the overall algorithm is cumbersome due to having multiple stages. It contrasts this with existing pruning methods that do not require fine-tuning. This feedback highlights a potential area for improvement in the paper, suggesting that the authors might consider simplifying their algorithm or comparing it to existing methods that do not require fine-tuning. However, the comment lacks specific suggestions or guidance on how to achieve this simplification or comparison, leaving the authors with a general idea of what could be improved but without actionable steps. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not provide detailed guidance for the authors to follow.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the claim that the new quantile function (3) is advantageous over the existing function (2), particularly regarding its sensitivity to tail parameters. It highlights that the paper does not provide supporting data to justify this claim. However, the comment does not offer explicit guidance or suggestions on how the authors might address this issue or provide the necessary data. The action is implicit and vague, as the authors are left to infer that they need to provide supporting data or evidence to justify the claim. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses a specific claim about the advantages of a new quantile function (3) compared to an existing one (2). It highlights a change in the multiplicative factors and suggests that the paper does not present supporting data to justify the reduced sensitivity. However, the comment does not specify which part of the paper discusses these functions or where the supporting data should be included. While the authors can infer that it relates to the comparison of the two functions, the lack of explicit grounding makes it difficult to pinpoint the exact section. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is not justified, as it changes the multiplicative factors into an additive term, making the function less sensitive to tail parameters when they are large. However, the comment lacks specific supporting data or evidence to substantiate this claim. It does not provide examples or references to demonstrate why the reduced sensitivity is undesired or how it affects the overall performance of the function. Without detailed reasoning or references, the claim remains unverifiable, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the claim that the new quantile function (3) is advantageous over the existing function (2), particularly regarding its sensitivity to tail parameters. It points out that the paper does not provide supporting data to justify the reduced sensitivity of the new function when the tail parameters are large. This feedback is somewhat helpful as it identifies a gap in the paper's argument and suggests that the authors should provide evidence to support their claim. However, the comment could be more helpful if it offered specific suggestions on how to present this supporting data or what kind of data would be necessary. Overall, the comment provides a clear direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the claim that the new quantile function (3) is advantageous over the existing function (2), particularly regarding its sensitivity to tail parameters. It highlights that the paper does not present supporting data to justify this claim. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or provide the necessary data. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to provide supporting data or evidence to justify the claim, but the comment does not offer specific steps or examples. Therefore, this comment aligns with a score of 2.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses a specific claim about the advantages of a new quantile function (3) compared to an existing one (2). It highlights a change in the multiplicative factors and suggests that the paper does not present supporting data to justify the reduced sensitivity when tail parameters are large. However, the comment does not specify which part of the paper discusses these functions or where the supporting data should be included. While the authors can infer that it relates to the comparison of the two functions, the lack of explicit grounding makes it difficult to pinpoint the exact section. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the advantage of the new quantile function (3) compared to the existing function (2) is not justified, as it changes the multiplicative factors into an additive term, making the function less sensitive to tail parameters when they are large. However, the comment lacks specific supporting data or evidence to substantiate this claim. It does not provide examples or references to demonstrate why the reduced sensitivity is undesired or how it affects the overall performance of the function. Without detailed reasoning or references, the claim remains unverifiable, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \""}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with Figure 3, suggesting that it is confusing and needs improvement. It also critiques the contribution of the benchmark, pointing out that the contribution over SWE-Bench is low due to the inclusion of testing fault localization and LLM\\'s capability of discovering issues itself. The reviewer provides two points of clarification: (1) that fault localization is necessary for bug fixing, and (2) that unit test failures can be automatically passed to an LLM via scripts, making the LLM unnecessary for issue generation. While the comment highlights areas for improvement, it does not explicitly instruct the authors on how to address these issues or provide specific suggestions for improvement. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the figure is confusing and critiques the contribution of the benchmark, particularly regarding the contribution over SWE-Bench. The comment provides specific reasoning and examples to support the critique, such as the necessity of fault localization for bug fixing and the automatic passing of unit test failures to an LLM. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of claims and observations. It critiques the contribution of the benchmark, stating that the contribution over SWE-Bench is low due to the inclusion of testing fault localization and LLM\\'s capability of discovering issues itself. The reviewer provides logical reasoning to support these claims, explaining that fault localization is necessary for bug fixing and that unit test failures can be automatically passed to an LLM via scripts, making the LLM unnecessary for issue generation. This reasoning is clear and well-supported, providing the authors with a strong basis for understanding and addressing the critique. Therefore, the comment is fully verifiable, aligning with a score of 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, suggesting that it is confusing and needs improvement. It also critiques the contribution of the benchmark, pointing out that the contribution over SWE-Bench is low due to the inclusion of testing fault localization and LLM\\'s capability of discovering issues itself. The reviewer provides logical reasoning to support these claims, explaining that fault localization is necessary for bug fixing and that unit test failures can be automatically passed to an LLM via scripts, making the LLM unnecessary for issue generation. This feedback is clear and actionable, offering the authors a detailed understanding of how to improve their draft. However, it could be more helpful if it provided specific suggestions or examples for enhancing the clarity of Figure 3 or improving the contribution of the benchmark. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that some key descriptions are missing, specifically regarding the selection of topics for complementary attributes in topic control experiments. It provides a clear and explicit action for the authors to take by asking them to clarify how to select the topics to constitute the complementary attribute {a^{\\prime}}. This feedback is direct and provides a concrete step for the authors to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper regarding the missing descriptions of key aspects, particularly in the context of topic control experiments. It explicitly mentions the need to clarify how topics are selected to constitute the complementary attribute {a^{\\prime}}. This provides full grounding, as the authors can accurately identify the part of the paper being addressed, which is the discussion or methodology section related to topic control experiments. The comment is also specific, as it clearly specifies what needs to be addressed regarding the selection of topics for complementary attributes. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the missing descriptions in the paper, specifically regarding the selection of topics for complementary attributes in topic control experiments. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the paper\\'s clarity or comprehensibility. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks clarity, namely the description of key aspects related to topic control experiments. It highlights a gap in the explanation by questioning how topics are selected to constitute the complementary attribute {a^{\\prime}}. This feedback is clear and actionable, as it directs the authors to provide more detailed information on this aspect, which is crucial for understanding the methodology and results. However, the comment could be more helpful if it suggested how the authors might address this issue or provided examples of how to improve the description. Overall, the comment is mostly helpful as it points out a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of convincing evidence for the general applicability of the system identification method to improve sim-to-real policy deployment. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what additional evidence or analysis could be provided to strengthen their claims. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the real-world manipulation case, which is mentioned as a single case. However, it does not specify which part of the paper this case is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its critique, questioning the general applicability of the system identification method for sim-to-real policy deployment. However, without explicit grounding, the authors may struggle to identify the exact part of the paper needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the real-world manipulation case is not convincing and questions the general applicability of the system identification method for sim-to-real policy deployment. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the lack of convincing evidence for the general applicability of the system identification method to improve sim-to-real policy deployment, specifically noting that the real-world manipulation case is a single instance. This feedback highlights a potential weakness in the paper's claims and suggests that the authors need to provide more comprehensive evidence or examples to support their method's effectiveness. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as providing additional case studies or experimental results. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the quality of the ShortcutQA dataset, specifically questioning whether the edits introduced ambiguity that could degrade performance. It suggests providing details on how \"answerable\" the distracted texts are and requests examples and qualitative results to support the claim. While the comment implies that the authors should address these concerns, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional details and examples. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ShortcutQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the quality of the dataset, particularly regarding the \"answerable\" nature of the \"distracted texts\" and requests examples and qualitative results to support the claim. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the quality of the ShortcutQA dataset, specifically questioning whether the edits introduced ambiguity that could degrade performance. The reviewer provides a logical reasoning by pointing out that while the edits are manually verified to not change semantics, they may still introduce ambiguity. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim. The request for details on the \"answerable\" nature of the distracted texts and examples of qualitative results provides some direction for the authors to address the concern, but it does not fully support the claim with evidence or references. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the quality of the ShortcutQA dataset, specifically questioning whether the edits introduced ambiguity that could degrade performance. It suggests providing details on the 'answerable' nature of the 'distracted texts' and requests examples and qualitative results to support the claim. This feedback is clear and actionable, as it prompts the authors to address a potential issue that could impact the validity of their results. By providing specific guidance on what additional information is needed, the comment offers valuable insights for improving the draft. However, it could be more helpful if it included suggestions on how to address the ambiguity or provide evidence of the dataset's quality. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement and provides a clear path forward.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" This feedback implies that the authors should add a reference or explanation to clarify the term \"deep\" in the text. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as specifying where the reference should be added or how it should be structured. The authors know they need to address the issue but may need additional guidance on the exact steps to take. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests adding a forward pointer to the definition of \"deep,\" which implies that the authors should clarify the term \"deep\" in the text. However, it does not specify which part of the paper this clarification is needed, making it weakly grounded. The comment is specific in its suggestion to include a forward pointer, but without explicit references to the text, the authors may struggle to pinpoint the exact location where this clarification is necessary. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the text would be clearer with a forward pointer to the definition of \"deep.\" However, it does not provide any reasoning, examples, or references to support why this would improve clarity or what specific issues the term \"deep\" might be causing. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the text would be clearer if it included a forward pointer to the definition of \"deep.\" While this feedback is specific and actionable, it does not provide any context or explanation about why the term \"deep\" is unclear or how it could be better explained. Without additional guidance or examples, the authors may find it challenging to fully understand the issue and implement the suggested improvement. Therefore, the comment is somewhat helpful, as it identifies a potential area for clarification but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a practical concern about the number of archetypes, k, and suggests that there should be a way to perform model selection to identify an appropriate k. While the comment implies that the authors should consider implementing a model selection process, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore model selection to address the concern about the number of archetypes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a practical concern about the number of archetypes, k, and suggests that there should be a way to perform model selection to identify an appropriate k. However, it does not specify which part of the paper this concern relates to, such as a specific section or figure. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its suggestion to perform model selection, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a practical concern about the number of archetypes, k, and suggests that there should be a way to perform model selection to identify an appropriate k. However, the comment does not provide any specific reasoning, examples, or references to support the claim that model selection is necessary or how it would be beneficial. Without additional context or evidence, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered borderline verifiable, as it provides a vague suggestion without sufficient justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a practical concern about the number of archetypes, k, and suggests that there should be a way to perform model selection to identify an appropriate k. This feedback is somewhat helpful as it points out a potential area for improvement in the methodology section, specifically regarding the selection of the number of archetypes. However, the comment lacks depth and does not provide specific guidance on how to implement model selection or what criteria should be used to determine the appropriate k. To be more helpful, the comment could include suggestions on how to conduct model selection or references to existing methods. Therefore, the comment is rated as somewhat helpful, as it identifies a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to identify and separate Theorem 1 from the other mathematical statements (Assumptions, Lemmas, and Theorems) on page 6. This feedback is clear and direct, providing a specific action for the authors to take. It also specifies where the issue lies, making it easy for the authors to understand and address the problem. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the absence of Theorem 1 and suggesting that it should be separated from the other mathematical statements. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Theorem 1 is missing from the paper, specifically mentioning that it is not present on page 6 where Theorem 2 is located. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the absence of Theorem 1, which is mentioned on page 6. It provides a clear and actionable suggestion to separate counting between Assumptions, Lemmas, and Theorems. This feedback is valuable as it helps the authors to improve the organization and clarity of their paper by ensuring that each mathematical statement is properly labeled and presented. However, the comment could be more helpful if it provided additional guidance on how to effectively separate these elements or suggested specific ways to improve the presentation. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or explore its implications. The action is implicit and vague, as the authors are left to infer that they should consider the generalizability of this assumption to different tasks. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the concern about the generalizability of the assumption, but without grounding, it is difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. While the comment highlights a potential issue, it lacks specific examples, references, or detailed reasoning to support the claim. The authors are left to infer the relevance of this concern to their work, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. While the comment identifies a potential weakness in the methodology, it lacks specific suggestions or guidance on how the authors might address this issue or explore its implications. The feedback is somewhat helpful as it points out a critical area for consideration, but it could be more actionable with additional insights or suggestions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or explore its implications. The action is implicit and lacks specificity, making it barely actionable. The authors are left to infer that they should consider the generalizability of this assumption to different tasks, but without concrete steps or examples, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. However, the comment does not specify which part of the paper this assumption is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the concern about the generalizability of the assumption, but without grounding, it is difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of QA. It questions whether this assumption generalizes to long document summarization. While the comment highlights a potential issue, it lacks specific examples, references, or detailed reasoning to support the claim. The authors are left to infer the relevance of this concern to their work, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is straightforward and suggests that the novelty is marginal. It also raises a question about the clarity of the method, specifically mentioning line 180 and the possibility of multiple different graphs. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the clarity of their method. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed method, suggesting that it is straightforward and lacks significant novelty. It also raises a specific question about the clarity of the method, particularly regarding line 180 and the possibility of multiple different graphs. However, the comment does not explicitly mention which part of the paper this relates to, making it weakly grounded. The authors can infer that it pertains to the method section, but this inference is not direct. The comment is specific in questioning the clarity of the method, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is straightforward and lacks significant novelty, suggesting that some parts are unclear. However, the comment does not provide specific examples or detailed reasoning to support these claims. The mention of line 180 and the question about multiple different graphs provides some context, but it lacks detailed explanations or references to substantiate the claim. Without additional evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a perceived lack of novelty in the proposed method, suggesting that it is straightforward and lacks significant innovation. It also raises a specific question about the clarity of the method, particularly regarding line 180 and the possibility of multiple different graphs. While the comment highlights an area of concern, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve the clarity of their method. The feedback is somewhat helpful as it points out a potential weakness, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the proposed method is straightforward and lacks significant novelty, suggesting that some parts are unclear. It raises a specific question about the clarity of the method, particularly regarding line 180 and the possibility of multiple different graphs. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the clarity of their method. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed method, noting that it is straightforward and lacks significant novelty. It also raises a specific question about the clarity of the method, particularly regarding line 180 and the possibility of multiple different graphs. However, the comment does not explicitly mention which part of the paper this relates to, making it weakly grounded. The authors can infer that it pertains to the method section, but this inference is not direct. The comment is specific in questioning the clarity of the method, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method is straightforward and lacks significant novelty, suggesting that some parts are unclear. However, the comment does not provide specific examples or detailed reasoning to support these claims. It raises a question about the clarity of the method, particularly regarding line 180 and the possibility of multiple different graphs, but lacks detailed explanations or references to substantiate the claim. Without additional evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a perceived lack of novelty in the proposed method, suggesting that it is straightforward and lacks significant innovation. It also raises a specific question about the clarity of the method, particularly regarding line 180 and the possibility of multiple different graphs. However, the comment"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments are limited in scope and could be expanded by including more examples of learning geometry on more complex manifolds. While the comment implies that the authors should consider adding such examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include more complex manifolds. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments are limited in scope and mentions specific examples of simulations on a unit sphere and spiral curves. However, it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its suggestion to include an example of learning geometry on a more complicated manifold, which provides clear guidance on what could be added to improve the scope of the experiments. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited in scope, particularly in terms of the manifolds used for learning geometry. It mentions specific examples, such as a unit sphere and spiral curves, and implies that these examples may not fully represent the complexity of real-world manifolds. However, the comment does not provide detailed reasoning or evidence to support why these examples are insufficient or why more complex manifolds are necessary. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the extent of the limitation themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the scope of the experiments, specifically noting that the current experiments are limited to a unit sphere and spiral curves, which may not fully represent the complexity of real-world manifolds. It suggests that including an example of learning geometry on a more complicated manifold would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their experiments and improve the scope of their work. However, the comment could be more helpful if it offered additional guidance on how to select or design such experiments. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the authors\\' observation that the current knowledge relies on a specific template, which lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not specify which part of the paper this observation is based on, nor does it provide any guidance on how the authors might address this issue. Without specific references to sections or parts of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity in terms of what needs to be improved or how to enhance the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the comment lacks verifiability, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any actionable feedback or suggestions on how the authors might address this issue or improve their work. Without specific guidance or examples, the comment lacks depth and does not offer the authors a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not specify which part of the paper this observation is based on, nor does it provide any guidance on how the authors might address this issue. Without specific references to sections or parts of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity in terms of what needs to be improved or how to enhance the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the comment lacks verifiability, making it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not provide any actionable feedback or suggestions on how the authors might address this issue or improve their work. Without specific guidance or examples, the comment lacks depth and does not offer the authors a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment acknowledges the authors\\' observation about the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the Large Language Model (LLM). However, it does not"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the number of baselines is small, which affects the universality and generality of the work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might increase the number of baselines or improve the universality and generality of their work. As a result, the authors are left without a clear understanding of what steps to take to address this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of a small number of baselines, which affects the universality and generality of the work. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the experimental section or the discussion of baselines, the comment lacks full grounding. It is specific in identifying the impact of a small number of baselines on universality and generality, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the number of baselines is small, which degrades the universality and generality of the work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the number of baselines used in the study, noting that it may limit the universality and generality of the work. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a concern but does not offer meaningful feedback or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there is no information about the tokenizer training, specifically mentioning the lack of details on the mixture of corpus size used and the software stack. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should include this information in their draft. However, the comment lacks concrete details on what specific information should be included or how it should be presented. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of information about the tokenizer training, specifically mentioning the mixture of corpus size used and the software stack. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying the issue with the lack of details on the tokenizer training, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no information about the tokenizer training, specifically mentioning the lack of details on the mixture of corpus size used and the software stack. This claim is somewhat verifiable as it points out a specific area where the paper lacks detail, but it does not provide specific examples or references to support the claim. The authors would need to infer the importance of this information and its potential impact on the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks information, namely the tokenizer training. It points out the absence of details regarding the mixture of corpus size used and the software stack, which are known to be important factors in practice. This feedback is clear and actionable, as it directs the authors to include this information in their draft to provide a more comprehensive understanding of their methodology. However, the comment could be more helpful if it provided suggestions on how to present this information or examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it highlights a critical gap in the paper and offers a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It questions whether the complexity is warranted and suggests that the paper does not address this issue. The comment also points out that the results are good but lacks clarity on the necessity of the co-training, positive mining, and alternate optimization steps, which are considered the main contributions of the paper over prior work. While the comment identifies a potential issue and highlights areas for improvement, it does not provide explicit guidance or concrete steps for the authors to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the necessity of these steps in their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed positive mining framework, comparing it to a simple multi-view contrastive objective. It questions whether the additional complexity is warranted and suggests that the paper does not address this question. The comment also points out that the results are good but lacks clarity on the necessity of the co-training, positive mining, and alternate optimization steps, which are considered the main contributions of the paper over prior work. However, the comment does not specify which part of the paper these steps are discussed in, making it weakly grounded. The authors can infer that the discussion is related to the methodology or results section, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed, namely the necessity of the proposed steps. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It questions whether the complexity is warranted and suggests that the paper does not address this issue. The comment also points out that the results are good but lacks clarity on the necessity of the co-training, positive mining, and alternate optimization steps, which are considered the main contributions of the paper over prior work. While the comment provides a logical basis for questioning the necessity of these steps, it lacks specific examples or references to support the claim fully. The authors are left to infer the need for further clarification or justification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the additional complexity of the proposed positive mining framework compared to a simple multi-view contrastive objective. It questions whether the complexity is warranted and suggests that the paper does not address this issue. The comment also points out that the results are good but lacks clarity on the necessity of the co-training, positive mining, and alternate optimization steps, which are considered the main contributions of the paper over prior work. This feedback is valuable as it prompts the authors to reconsider the necessity of their proposed steps and to provide a clearer justification for their complexity. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided specific examples of how to improve the clarity of the paper. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential issue with the scalability of the approach due to the computational complexity of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is needed to address this concern. While the comment implies that a detailed discussion on computational cost and scalability is necessary, it does not provide specific guidance on how to conduct this discussion or what aspects should be included. The action is implicit and somewhat vague, as the authors know they need to address the scalability issue but may not have a clear idea of how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the computational cost of the approach, specifically mentioning multi-marginal OT and spline calculations. However, it does not specify which part of the paper discusses these topics, making it weakly grounded. The comment is specific in identifying the issue of scalability and suggesting a need for a more comprehensive discussion, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the computational complexity of multi-marginal OT and spline calculations may limit the scalability of the approach for large datasets, which could be problematic for real-world applications. This claim is somewhat verifiable as it provides a logical reasoning based on the complexity of the calculations. However, it lacks specific examples or references to support the claim fully. The authors would need to conduct further research or provide additional context to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the scalability of the approach due to the computational complexity of multi-marginal OT and spline calculations. It suggests that a more comprehensive discussion is needed to address this concern, which is a valuable insight for the authors. However, the comment lacks specific guidance on how to conduct this discussion or what aspects should be included. While it points out a critical area for improvement, the feedback could be more actionable with detailed suggestions or examples. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point challenges the authors' claim that non-uniform label noise is not too common in practice by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. It provides a concrete example of a real-world dataset where non-uniform label noise exists, which is a clear and specific action for the authors to address. By citing a relevant paper, the comment offers a direct way for the authors to substantiate their claim or refute it with evidence from the literature. This provides a clear and actionable direction for the authors to improve their draft. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment challenges the authors\\' claim that non-uniform label noise is not too common in practice by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. This provides a clear and specific reference to the literature, allowing the authors to accurately identify the part of the paper being addressed. The comment also specifies the issue by pointing out the existence of non-uniform label noise in real-world datasets, which is a relevant point for the authors to consider. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the authors\\' claim about the prevalence of non-uniform label noise by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. This provides a concrete example and a source for the authors to consider, making the claim somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or evidence about why the referenced paper is relevant or by discussing how the findings from the paper challenge the authors\\' claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment challenges the authors' claim about the prevalence of non-uniform label noise by referencing a specific dataset, Clothing1M, and a paper by Kun Yi and Jianxin Wu. This provides a concrete example and a source for the authors to consider, making the comment somewhat helpful. However, the feedback could be more helpful if it offered additional context or suggestions on how the authors might address this issue in their work. Overall, the comment identifies a potential weakness in the authors' claim but lacks depth and actionable guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the evaluation in Section 6.2, specifically mentioning that the sample size of 10 may lead to biased findings due to the small scale of the experiment. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to expand their sample size or provide a more robust analysis to mitigate the potential bias. However, the lack of specific instructions or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, noting that the limited sample size of 10 may lead to biased findings due to the small scale of the experiment. This provides clear guidance on what needs to be addressed in the section, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation in Section 6.2 is based on only 10 samples, which may lead to biased findings due to the small scale of the experiment. This claim is somewhat verifiable as it identifies a potential issue with the sample size, but it lacks specific examples or references to support the claim. The authors would need to conduct a more detailed analysis to fully understand the implications of this claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the evaluation in Section 6.2, noting that the sample size of 10 may lead to biased findings due to the small scale of the experiment. This feedback is clear and actionable, as it highlights a potential weakness in the study's methodology that the authors should address. By pointing out this limitation, the comment provides a valuable insight that can help the authors improve the robustness and reliability of their findings. However, the comment could be more helpful if it suggested ways to address the issue, such as recommending a larger sample size or alternative methods to mitigate bias. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential limitation of the method's generalizability to significantly different combinatorial optimization problems, noting that the paper acknowledges this but does not address it experimentally. While the comment identifies a gap in the paper's experimental evaluation, it does not provide explicit guidance on how the authors should address this limitation. The action is implicit, as the authors need to infer that they should conduct additional experiments to address the generalizability issue. However, the comment lacks concrete details on what specific experiments should be conducted or how to evaluate the method's generalizability. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses a potential limitation of the method's generalizability to significantly different combinatorial optimization problems, noting that the paper acknowledges this but does not address it experimentally. However, it does not specify which part of the paper discusses the method's generalizability or where the experimental evaluation is lacking. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in identifying the issue of generalizability, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the method is tailored to similar MILP tasks and may not generalize well to significantly different combinatorial optimization problems. This claim is somewhat verifiable as it acknowledges the limitation but does not provide specific examples or detailed reasoning to support why the method might not generalize. The comment lacks explicit references to experimental results or comparisons that could substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the method's generalizability to significantly different combinatorial optimization problems, noting that the paper acknowledges this but does not address it experimentally. This feedback is somewhat helpful as it points out an area where the paper could be improved by conducting additional experiments to evaluate the method's generalizability. However, the comment lacks specific suggestions or guidance on how to conduct these experiments or what aspects to focus on. To be more helpful, the comment could provide more detailed advice or examples of how to address this limitation. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a concern about the authors\\' attempt to explain their baseline in the Results section, specifically mentioning lines 256-261. The reviewer notes difficulty in understanding how these baselines work and their relation to InterFair, as well as whether they are competitive. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the baselines and their relation to InterFair, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the Results section, specifically lines 256-261, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding how the baselines work and their relation to InterFair, as well as whether they are sufficiently competitive. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' attempt to explain their baseline in the Results section is unclear, making it difficult to understand how the baselines work and their relation to InterFair. However, the comment does not provide specific examples or detailed reasoning to support this claim, leaving the authors without a clear understanding of what aspects need clarification. The lack of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to infer the specific issues from the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the explanation of the baseline in the Results section, particularly regarding the baselines denoted as Rerank and Adv. It highlights the difficulty in understanding how these baselines work and their relation to InterFair, as well as whether they are sufficiently competitive. This feedback is clear and actionable, as it directs the authors to clarify these aspects in their draft. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or offered specific examples of what needs to be clarified. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting additional baselines to include or how to improve the comparison. Without specific guidance or suggestions, the authors are left without a clear understanding of what changes or additions are needed to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights an issue with the comparison to other baselines on cycle counting and ZINC, but it does not specify which part of the paper this comparison is discussed in. The authors may have an idea of where this comparison is mentioned, but the comment lacks explicit references to specific sections, figures, or tables. Additionally, the comment does not provide specific details on what aspects of the comparison are insufficient or how they could be improved. This makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient, but it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper could be improved, namely the comparison to other baselines on cycle counting and ZINC. However, it lacks detail and does not provide any suggestions or guidance on how the authors might enhance this comparison or what specific aspects need improvement. Without actionable feedback or examples, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer constructive guidance for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is effective, while most similar ones are not. However, it does not provide explicit guidance on how to achieve this explanation or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the effectiveness of the chosen combination of mask snippets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from a clear explanation of why a specific combination of mask snippets is effective, while most similar ones are not. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its suggestion to provide a detailed explanation of the effectiveness of the chosen combination of mask snippets, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while most similar ones are not. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this explanation is necessary or how it would improve the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is effective, while most similar ones are not. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, namely the need for a more detailed explanation of the effectiveness of the chosen combination of mask snippets. However, the comment lacks specific guidance or suggestions on how to provide this explanation, such as which aspects should be highlighted or how to structure the discussion. To be more helpful, the comment could include examples or references to similar studies that effectively explain the effectiveness of specific combinations. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the performance of SLQ, as quantified by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. It specifically mentions that SLQ shows worse performance than CRD in Figure 3 and a very small improvement over ACL in Figure 4. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these issues or improve the performance of SLQ. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that SLQ shows worse performance than CRD in Figure 3 and a very small improvement over ACL in Figure 4. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of SLQ, as quantified by F1 score and conductance values, appears to be less competitive compared to previous CRD methods. It provides specific examples from Figures 3 and 4, which helps to ground the claim. However, the comment lacks detailed reasoning or analysis to fully substantiate the claim, such as comparisons with other relevant works or detailed explanations of why SLQ's performance is considered limited. While the references to specific figures provide some support, the lack of comprehensive justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the performance of SLQ, comparing it to previous CRD methods. It highlights that SLQ shows worse performance than CRD in Figure 3 and a very small improvement over ACL in Figure 4. This feedback is somewhat helpful as it points out areas where the authors' work may need improvement. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address these issues or enhance the performance of SLQ. Without additional context or specific recommendations, the authors are left with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should add more baselines to their study to perform robust performance comparisons. This feedback is clear and direct, providing a specific action for the authors to take. It also gives a clear rationale for why this addition is necessary, as it acknowledges the limited baselines currently used, which are naive or outdated. The comment is highly actionable because it offers a concrete and direct suggestion for improvement, allowing the authors to understand exactly what needs to be done to enhance their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the selection of baselines in the paper, noting that the current baselines are limited to naive or outdated models. It suggests adding more baselines to perform robust performance comparisons. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to add more baselines is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the selection of baselines is limited to naive or outdated models, suggesting that more baselines should be added for robust performance comparisons. However, the comment does not provide specific examples or references to support the claim that the current baselines are naive or outdated. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the selection of baselines, noting that the current choices are limited to naive or outdated models. It provides a clear and actionable suggestion for improvement by encouraging the authors to add more baselines to perform robust performance comparisons. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and validity of their study. However, the comment could be more helpful if it offered specific examples of additional baselines that could be considered or detailed reasons why these additions would be beneficial. Despite this, the feedback is mostly helpful as it directs the authors toward a clear path for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the choice of target structures in Table 2 and suggests that the authors either justify their selection or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. The comment explicitly states that the authors should either justify their choice or conduct additional experiments, providing clear guidance on what actions are needed to address the issue. This feedback is concrete and actionable, as it gives the authors a specific direction to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structures and suggests that the authors either justify their selection or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This feedback is detailed and provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the choice of target structures in Table 2, questioning why only one target structure was evaluated. It suggests that the authors should either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability to different target structures. This feedback is somewhat verifiable as it points out a potential limitation in the evaluation process but lacks specific examples or references to support the claim. The authors would need to provide more detailed reasoning or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of target structures in Table 2, questioning why only one target structure was evaluated. It suggests that the authors should either justify their choice or provide additional experiments to demonstrate the method\\'s adaptability to various target structures. This feedback is clear and actionable, as it points out a potential limitation in the evaluation process and provides a specific direction for improvement. By addressing this concern, the authors can enhance the generalizability and applicability of their method. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s scope could be expanded by exploring applications in more realistic scenarios, such as medical diagnosis, which would enhance the paper\\'s impact and relevance. While the comment implies that the authors should consider expanding the application scope, it does not provide specific guidance on how to achieve this or which aspects of the knapsack problem could be adapted to these new scenarios. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the research\\'s scope is limited to the knapsack problem and lacks exploration of more realistic scenarios, such as medical diagnosis. However, it does not specify which part of the paper discusses the knapsack problem or where the exploration of medical diagnosis should be included. This makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its suggestion to explore applications in healthcare, but it lacks grounding as it does not explicitly mention the relevant sections of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s scope is limited to the knapsack problem and lacks exploration of more realistic scenarios, such as medical diagnosis. The reviewer claims that expanding the application scope would significantly increase the paper\\'s impact and relevance. However, the comment does not provide specific examples or references to support the claim that exploring medical diagnosis would be more impactful. While the suggestion is logical, the lack of detailed justification or evidence makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s scope, specifically noting that the research primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. This feedback is valuable as it highlights an area where the paper could be expanded to increase its impact and relevance. However, the comment could be more helpful if it provided specific suggestions on how the authors might adapt their approach to include medical diagnosis or other realistic scenarios. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks detailed guidance on how to implement the suggested expansion.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that the method improves robustness and sensitivity, as it is not supported by the results shown in Figure 3. The reviewer points out that the new method is noisier in two domains and equally noisy as the competitors in the rest. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their claims. The action is implicit and vague, as the authors are left to infer that they need to provide more evidence or clarify their claims. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the method, noting that it does not improve robustness and sensitivity as claimed, and provides a detailed observation about the results in Figure 3. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method does not improve robustness and sensitivity as claimed in the motivation, referencing Figure 3. However, the comment lacks specific details or evidence to support this claim, such as detailed comparisons or analysis of the results. Without additional context or justification, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the claim that the method improves robustness and sensitivity, as it is not supported by the results shown in Figure 3. It points out that the new method is noisier in two domains and equally noisy as the competitors in the rest. This feedback is somewhat helpful as it identifies a specific area where the authors' claims are not substantiated. However, the comment lacks depth and does not provide suggestions on how the authors might address this issue or improve their claims. To be more helpful, the comment could include specific recommendations or examples of how the authors might strengthen their argument. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or what specific aspects they should consider when evaluating the robustness of their conclusion. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without explicit references, the authors may find it challenging to identify the exact area being addressed. Additionally, the comment lacks specificity regarding what aspects of the conclusion should be evaluated against more sophisticated or aggressive removal methods. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the robustness of the conclusion against more sophisticated or aggressive removal methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might affect the conclusion. Without additional context or explanation, the authors may find it difficult to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the robustness of the conclusion against more sophisticated or aggressive removal methods. This is a valuable point as it challenges the authors to consider the limitations of their conclusion and potentially strengthen their argument. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what aspects of their conclusion could be further evaluated. While it prompts the authors to think critically about their results, it does not provide actionable feedback or detailed advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s introduction, which mentions explainable AI, and the focus on interpretable methods. It also points out that the authors do not define interpretability or explain the difference between explainable and interpretable methods. Additionally, the comment notes that the paper does not cite relevant work in this area. While the comment identifies specific areas that need clarification and references, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the definitions and provide references to relevant work, but the lack of concrete guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issues with the paper, namely the lack of explanation for the definitions of interpretability and the difference between explainable and interpretable methods, as well as the absence of references to relevant work. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper introduces explainable AI in the introduction but focuses on interpretable methods, without providing a clear explanation of the difference between the two concepts. The comment also notes that the authors do not define interpretability or provide references to relevant work. This claim is somewhat verifiable as it highlights a discrepancy between the introduction and the focus of the paper, but it lacks specific examples or references to support the claim fully. The authors would need to infer the exact issues and how to address them, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's focus and content. It points out that the introduction mentions explainable AI, which is not the focus of the paper, and that the authors do not provide a clear definition of interpretability or explain the difference between explainable and interpretable methods. Additionally, the comment notes that the paper does not cite relevant work in this area. This feedback is clear and actionable, as it highlights specific areas where the paper needs clarification and improvement. By addressing these points, the authors can enhance the clarity and coherence of their work. However, the comment could be more helpful if it provided suggestions on how to define interpretability or how to integrate relevant work into the paper. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification about the training data used in the compositionality and transitivity experiments. This question provides a clear and direct action for the authors to take, which is to specify the training data used in these experiments. The comment is explicit and concrete, as it directly instructs the authors on what information is needed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"compositionality and transitivity experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be clarified, namely, the training data used in these experiments. This provides clear guidance on what information is missing or needs further explanation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the training data used in the compositionality and transitivity experiments. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, which is why it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a direct and actionable request for clarification regarding the training data used in the compositionality and transitivity experiments. By asking for this information, the reviewer provides a clear direction for the authors to improve their draft by ensuring transparency and reproducibility. This feedback is specific and valuable, as it helps the authors address a critical aspect of their work that could impact the credibility and utility of their findings. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises concerns about the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It also suggests that there are ways to perform bi-directional beam search for such applications. However, the comment does not provide explicit guidance on how to address these issues or improve the clarity of the explanation. The authors are left to infer that they need to clarify the meaning of 'parts thereof' and strengthen their argument, but the lack of specific suggestions makes it difficult to know exactly what changes to make. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks concrete guidance on how to implement those changes.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'L133-134,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. Additionally, it suggests a potential solution by referencing a method for bi-directional beam search. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to do bi-directional beam search for such applications, which could be a potential solution. However, the comment does not provide specific examples or detailed reasoning to support the claim that the explanation is unclear or the argument is unconvincing. The reference to a method for bi-directional beam search is a step towards verification but lacks detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed support to fully substantiate the claim.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion in the paper, namely the explanation of 'not only the complete captions but also parts thereof.' It questions the clarity of this explanation and the argument about why filling in the blanks is difficult. The comment also suggests a potential solution by referencing a method for bi-directional beam search, which could be relevant for the application discussed. However, the comment lacks detailed guidance on how to improve the clarity of the explanation or how to apply the suggested method. While it points out an area for improvement, the feedback could be more actionable and comprehensive to be considered highly helpful. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a specific issue with the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It also suggests a potential solution by referencing a method for bi-directional beam search. However, the comment does not provide explicit guidance on how to address the clarity issue or how to implement the suggested method. The authors are left to infer that they need to clarify the explanation and consider the method for improvement, but the lack of concrete steps makes the comment somewhat actionable. Therefore, it aligns with a score of 3.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'L133-134,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. Additionally, it suggests a potential solution by referencing a method for bi-directional beam search. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the clarity of the explanation regarding the complete captions and parts thereof, as well as the argument about why filling in the blanks is difficult. It suggests that there are ways to do bi-directional beam search for such applications, which could be a potential solution. However, the comment does not provide specific examples or detailed reasoning to support the claim that the explanation is unclear or the argument is unconvincing. The reference to a method for bi-directional beam search is a step towards verification but lacks detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but requires more detailed support to fully substantiate the claim.\", 'verifiability_label': '3', 'help"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the use of reverse KL in training flows, questioning the differentiability of the function $g$ and the mode-seeking nature of the reverse KL. It suggests that this limitation is crucial for applications in rare event sampling and references recent work to overcome it. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or incorporate the referenced work into their study. The action is implicit and somewhat vague, as the authors are left to infer that they should consider these issues and possibly explore the referenced work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of reverse KL in training flows, specifically mentioning the assumption of differentiability of the function $g$ and the mode-seeking nature of the reverse KL. It also references recent work in normalizing flows to overcome these limitations. However, the comment does not specify which part of the paper discusses the use of reverse KL or the training process, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the issues with the reverse KL and suggesting a potential limitation in the application of flows, particularly in rare event sampling. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the use of reverse KL in training flows, specifically questioning the differentiability of the function $g$ and the mode-seeking nature of the reverse KL. It suggests that this limitation is crucial for applications in rare event sampling and references recent work to overcome it. However, the comment lacks specific examples or detailed reasoning to support the claim about the differentiability of $g$ or the mode-seeking nature of the reverse KL. The reference to recent work is a step towards verification, but it does not provide explicit details or evidence to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to fully support the argument.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises important concerns about the use of reverse KL in training flows, specifically questioning the differentiability of the function $g$ and the mode-seeking nature of the reverse KL. It highlights the potential limitations of this approach, particularly in applications involving rare event sampling, where it is crucial to cover all modes of a density. The comment also references recent work in normalizing flows that address these limitations, providing a direction for the authors to explore. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might incorporate these insights into their study or address the limitations. Overall, the comment is mostly helpful as it identifies a critical issue and provides a potential avenue for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. It implies that a detailed analysis of the curated dataset is needed to address this issue. However, the comment does not explicitly instruct the authors to perform this analysis or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors can infer the need for analysis but lack specific instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ViStruct Suite,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that annotations in the visual event detection stage might contain noises due to the use of an off-the-shelf semantic role labeling system. The comment further suggests a need for a detailed analysis of the curated dataset to address this issue. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that annotations in the visual event detection stage of ViStruct Suite might contain noises due to the use of an off-the-shelf semantic role labeling system. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the annotations in the visual event detection stage of ViStruct Suite, noting that they might contain noises due to the use of an off-the-shelf semantic role labeling system. It suggests that a detailed analysis of the curated dataset would be needed to address this concern. While the comment highlights a potential weakness, it does not provide specific guidance or suggestions on how to conduct the analysis or what aspects to focus on. This limits the usefulness of the feedback, as the authors are left with a general idea of what needs to be addressed but without detailed instructions on how to improve their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model implementation should be better justified, specifically mentioning the stopping rule with n consecutive identical samples as arbitrary and lacking neural/behavioral parallels. It also points out the need to discuss sensitivity with regard to n. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to justify the model implementation or address the concerns about the stopping rule. The authors are left with a general understanding of what needs to be improved but without detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Model implementation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out two particular issues: the stopping rule with n consecutive identical samples being arbitrary and lacking neural/behavioral parallels, and the need to discuss sensitivity with regard to n. This provides clear guidance on what needs to be addressed in the model implementation. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the stopping rule with n consecutive identical samples is arbitrary and lacks neural/behavioral parallels. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to discuss sensitivity with regard to n is also vague and lacks detailed reasoning. As a result, the claim is barely verifiable, as it requires more detailed justification or evidence to be fully understood and addressed by the authors. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the model implementation, noting that the stopping rule with n consecutive identical samples seems arbitrary and lacks neural/behavioral parallels. It also points out the need to discuss sensitivity with regard to n. This feedback is clear and actionable, providing the authors with concrete areas to address and improve upon. However, the comment could be more helpful if it offered suggestions on how to justify the stopping rule or provided examples of how to discuss sensitivity. Overall, the comment is mostly helpful as it directs the authors to important aspects of their work that need further development.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of time complexity analysis for the proposed algorithms and the discrepancy between the proposed method being a \"learn-to-search\" algorithm and its adoption of a heuristics node pair selection policy. The first part of the comment explicitly instructs the authors to provide the time complexity analysis, which is a clear and direct action. The second part suggests an interesting comparison with state-of-the-art algorithms to demonstrate the proposed method\\'s efficiency. While the comment does not specify how to conduct this comparison, the authors are given a clear direction to improve their draft. Therefore, the comment is mostly actionable, as it provides explicit guidance on what needs to be addressed and how to improve the draft, but the lack of detailed instructions for the second part makes it somewhat vague. Overall, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the lack of time complexity analysis for the proposed algorithms and the discrepancy between the proposed method being a \"learn-to-search\" algorithm and its adoption of a heuristics node pair selection policy. It explicitly mentions the \"maximum common subgraph detection problem\" and the \"proposed method,\" providing full grounding as to which parts of the paper are being addressed. The comment is also specific in detailing what needs to be addressed, such as providing time complexity analysis and comparing the proposed method with state-of-the-art algorithms. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should provide the time complexity analysis for the proposed algorithms, as the maximum common subgraph detection problem is NP-hard. The comment also points out a discrepancy between the proposed method being a \"learn-to-search\" algorithm and its adoption of a heuristics node pair selection policy, suggesting that it might be interesting to see if the proposed method reduces search time compared to state-of-the-art algorithms. While the comment provides a logical basis for the claim, it lacks specific references or detailed examples to fully substantiate the suggestion. The authors are left with a general understanding of what needs to be addressed but without explicit guidance on how to conduct the analysis or comparison. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires more detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two key areas for improvement in the paper. First, it points out the lack of time complexity analysis for the proposed algorithms, which is crucial for understanding the efficiency of the methods. This feedback is clear and actionable, as it directly instructs the authors to provide this analysis, which is essential for evaluating the practicality and scalability of their approach. Second, the comment highlights a discrepancy between the proposed method being described as a 'learn-to-search' algorithm and its adoption of a heuristics node pair selection policy. It suggests that it would be interesting to see if the proposed method significantly reduces search time compared to state-of-the-art algorithms as the number of nodes increases. This suggestion provides a direction for further exploration and comparison, which could enhance the paper's contribution. Overall, the comment is mostly helpful as it identifies specific areas for improvement and offers actionable suggestions for enhancing the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of quality control measures, such as filtering or manual evaluation, in the data collection process, which is automated using a model-based approach. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific steps to implement quality control measures. The action is implicit and somewhat vague, as the authors need to infer that they should consider implementing quality control measures but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of quality control measures, such as filtering or manual evaluation, in the data collection process. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in identifying the absence of quality control measures, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no quality control, such as filtering or manual evaluation, on the data collected through an automated model-based approach. This claim is somewhat verifiable as it highlights a potential issue with the data collection process. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the data collection process, specifically the lack of quality control measures like filtering or manual evaluation. This is an important point as it could affect the reliability and validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending alternative methods for quality control or suggesting ways to improve the data collection process. While it highlights a significant concern, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that for most tasks, a small set of labeled data is available, and it mentions that snorkel also relies on a small dev set for tuning hyperparameters. The comment implies that using these labels could provide a bound on the performance of a classifier, and it suggests comparing a confidence interval from a small dev set with the Frechet bound. While the action is implicit, the comment provides a clear direction for the authors to explore, suggesting a specific comparison that could enhance the analysis. However, it lacks explicit instructions on how to conduct this comparison or what specific results to expect. The action is concrete enough for the authors to understand the direction but not fully detailed on how to execute it. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"snorkel,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that using a small set of labeled data could provide a bound on the performance of a classifier and comparing it with the Frechet bound. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that using a small set of labeled data could provide a bound on the performance of a classifier, referencing snorkel as an example. It implies that comparing a confidence interval from a small dev set with the Frechet bound would be interesting. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that this comparison would be beneficial. While the suggestion is logical, it lacks sufficient evidence or justification to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the suggestion but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement by suggesting that using a small set of labeled data could provide a bound on the performance of a classifier. It references snorkel as an example and implies that comparing a confidence interval from a small dev set with the Frechet bound would be interesting. This feedback is somewhat helpful as it points out a specific aspect of the paper that could be further explored to enhance the analysis. However, the comment lacks depth and does not provide detailed guidance on how to conduct this comparison or what specific insights it might yield. The authors are left with a general suggestion but without actionable steps to implement it, making the comment somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed method, stating that it is only applicable to problems with low-dimensional input spaces. It provides specific evidence by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling. However, the comment does not offer any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method. The feedback is descriptive and informative but lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the proposed method, stating that it is only applicable to problems with low-dimensional input spaces. It provides a specific example by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically the section or experiment where this issue is discussed. The comment is also specific, as it clearly identifies the limitation and provides a rationale for it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces, citing the largest dimensionality in the experiments as 3. This claim is supported by the specific example of the experiments, providing a clear and logical reasoning for the limitation. However, the comment could be strengthened by including references to the curse of dimensionality or additional examples to further substantiate the claim. Overall, the comment is mostly verifiable, as it provides a clear rationale but lacks some additional evidence or references to fully support the claim. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation of the proposed method, noting that it is only applicable to problems with low-dimensional input spaces. It provides specific evidence by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling. This feedback is valuable as it highlights a critical area for improvement, allowing the authors to consider expanding the applicability of their method to higher-dimensional problems. However, the comment could be more helpful if it suggested potential strategies or approaches to address this limitation, such as exploring dimensionality reduction techniques or alternative modeling strategies. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies a limitation of the proposed method, stating that it is only applicable to problems with low-dimensional input spaces. It provides specific evidence by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling. However, the comment does not offer any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method. The feedback is descriptive and informative but lacks actionable guidance, leaving the authors without a clear path for improvement. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the proposed method, stating that it is only applicable to problems with low-dimensional input spaces. It provides a specific example by mentioning that the largest dimensionality in the experiments is 3, which is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically the section or experiment where this issue is discussed. The comment is also specific, as it clearly identifies the limitation and provides a rationale for it. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is only applicable to problems with low-dimensional input spaces, citing the largest dimensionality in the experiments as 3. This is due to the curse of dimensionality caused by the use of a finite set of points for surrogate modeling. The comment provides a clear and logical reasoning for the limitation, making it mostly verifiable. However, it could be strengthened by including references to the curse of dimensionality or additional examples to further substantiate the claim. Overall, the comment is mostly verifiable, as it provides a clear rationale"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their claims. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the results presented in Table 1 and Table 2, providing specific references to these sections. This allows the authors to accurately identify the parts of the paper being discussed, making the comment fully grounded. Additionally, the comment specifies the issue by questioning the claim that the presented method is significantly better than others due to the results being within their standard deviations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the claim that the presented method is significantly better than others by noting that the results are usually within their standard deviations. This is a logical and reasonable critique, as it questions the basis of the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that the results are indeed within their standard deviations, which would strengthen the verifiability. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the critique but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the claim that the presented method is significantly better than others, based on the observation that the results are usually within their standard deviations. This feedback is somewhat helpful as it identifies a potential weakness in the paper's claims and provides a specific point for the authors to consider. However, the comment lacks depth and does not offer suggestions on how the authors might address this issue or improve their claims. To be more helpful, the comment could include specific recommendations or examples of how the authors might strengthen their claims or provide additional evidence to support their conclusions. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for the authors but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the non-trivial nature of generating synthetic tabular data due to various factors, including the presence of multiple entries associated with the same entity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the challenges of generating synthetic tabular data, specifically mentioning the issue of multiple entries associated with the same entity. However, it does not specify which part of the paper this issue is relevant to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in detailing the challenge but lacks grounding, as it does not reference a particular section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides an example of a common issue in generating synthetic tabular data, specifically mentioning the presence of multiple entries associated with the same entity. However, it does not provide any additional context, reasoning, or references to support why this is a significant issue or how it affects the paper. Without further elaboration or evidence, the claim lacks depth and clarity, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights a specific challenge in generating synthetic tabular data, noting that multiple entries associated with the same entity can lead to additional relationships in the table. This observation is relevant and provides a clear insight into a potential issue that the authors might face. However, the comment does not offer any suggestions or guidance on how the authors might address this challenge or improve their approach. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the overemphasis on the AmbiQT benchmark without considering its applicability to other datasets. It suggests that the authors should provide a broader context or validation on other datasets to address this concern. However, the comment does not explicitly instruct the authors to include this broader context or validation, nor does it provide specific guidance on how to achieve it. The action is implicit and somewhat vague, as the authors can infer the need for a broader context but lack detailed instructions on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the creation of the AmbiQT benchmark and suggests that an overemphasis on this benchmark without broader context or validation on other datasets could lead to questions about its applicability. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with overemphasis and suggesting the need for broader context, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the overemphasis on the AmbiQT benchmark without considering its applicability to other datasets. It suggests that this could lead to questions about the benchmark\\'s relevance. However, the comment lacks specific examples or references to support the claim that the benchmark is overemphasized or to explain why it might not be applicable to other scenarios. This makes the claim somewhat verifiable, as it provides a general observation but lacks detailed evidence or reasoning to fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the overemphasis on the AmbiQT benchmark without considering its applicability to other datasets. It suggests that the authors should provide a broader context or validation on other datasets to address this concern. This feedback is clear and actionable, as it directs the authors to consider the broader implications of their work and encourages them to expand their analysis. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate this broader context or validation. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks annotation training details and guidelines, which is important for professional translators dealing with non-standard tasks. It also mentions the absence of information about the tool used. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include annotation training details and guidelines, as well as provide information about the tool used. However, the comment lacks concrete guidance on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of annotation training details and guidelines, as well as the lack of information about the tool used. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in identifying the missing elements, such as annotation training details and guidelines, and the tool used, which provides some clarity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks annotation training details and guidelines, which is important for professional translators dealing with non-standard tasks. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper by pointing out the absence of annotation training details and guidelines, which is particularly relevant for professional translators dealing with non-standard tasks. It also mentions the lack of information about the tool used, which is important for reproducibility and understanding the methodology. While the comment highlights significant areas for improvement, it does not provide specific suggestions or guidance on how to address these issues, such as what details should be included or how to present the information about the tool. This limits the usefulness of the feedback, as the authors are left to infer the necessary steps to take. Therefore, the comment is somewhat helpful, as it identifies important areas for improvement but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding Table 1. The first question asks whether the values \"EX/NORB\" should be bold-faced, and the second question queries the statistical significance of the difference between the values 0.59+/-0.12 and 0.58+/-0.11. While the questions provide specific areas for the authors to consider, they do not offer explicit instructions on how to address these issues. The authors are left to infer that they should review the formatting and statistical significance of the data in Table 1. However, the lack of concrete guidance makes the action implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the formatting of \"EX/NORB\" and the statistical significance of the difference between the values 0.59+/-0.12 and 0.58+/-0.11. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions regarding the formatting of \"EX/NORB\" in Table 1 and the statistical significance of the difference between two values. These questions are factual and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions regarding the presentation and statistical significance of data in Table 1. The first question asks whether the values \"EX/NORB\" should be bold-faced, which is a formatting inquiry. The second question queries the statistical significance of the difference between two values, suggesting a need for further clarification or analysis. While the comment identifies areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors are left to infer that they should review the formatting and statistical significance of the data in Table 1, but the feedback does not provide actionable steps or examples. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on the metric used for the video level supervision experiment, noting that it does not use tracklet-based metrics and that the paper lacks details on this. This request provides a clear and direct action for the authors to take, which is to include the metric used in the experiment. The comment is explicit and concrete, as it specifies exactly what information is missing and how it should be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the video level supervision experiment,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the metric used for this experiment, noting that it does not use tracklet-based metrics and asking for details. This provides clear guidance on what needs to be clarified or added to the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of a specific metric for the video level supervision experiment, noting that it does not use tracklet-based metrics as mentioned in the paper. However, the comment lacks detailed reasoning or evidence to support why this is a concern or how it affects the experiment. The absence of specific examples or references to justify the claim makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides a vague suggestion for clarification but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the metric used for the video level supervision experiment, noting that it does not use tracklet-based metrics as mentioned in the paper. This feedback is clear and actionable, as it prompts the authors to clarify the metric used in their experiments, which is an important aspect of reproducibility and understanding the results. However, the comment could be more helpful if it provided suggestions on how to address this issue or if it pointed out the potential impact of using a different metric. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why \"person blocking\" affects the models, as shown in Figure 4. It suggests that models might learn person-related features to classify the input image, which is undesirable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to investigate or explain this phenomenon. The action is implicit and vague, as the authors are left to infer that they need to provide an explanation or justification for the observed effect. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the impact of \"person blocking\" on the models and suggests a potential reason for this effect, which is that models learn person-related features. This provides clear guidance on what aspect of the results needs further explanation or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of \"person blocking\" on the models, as shown in Figure 4. It suggests that models might learn person-related features to classify the input image, which is undesirable. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the impact of 'person blocking' on the models, as shown in Figure 4. It suggests that models might learn person-related features to classify the input image, which is undesirable. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or provide further explanation. The feedback is somewhat helpful as it prompts the authors to consider an aspect of their results that may require clarification, but it does not offer detailed or actionable advice. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about whether the authors have tried the combination of TF-IDF and dense retrieval for evidence sentence extraction. While it does not explicitly instruct the authors to perform this combination, it implies that it could be a potential area of exploration. The action is implicit, as the authors can infer that they should consider this combination, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable, as it provides a suggestion for further exploration but does not specify the exact steps to take.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"TF-IDF and dense retrieval,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the authors have tried a particular combination for evidence sentence extraction, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking whether the authors have tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about whether the authors have tried a specific combination of TF-IDF and dense retrieval for evidence sentence extraction. While it does not provide any guidance or suggestions for improvement, it does prompt the authors to consider an alternative approach that could potentially enhance their work. However, the comment lacks actionable feedback or detailed advice, making it somewhat helpful. The authors may find it useful to explore this suggestion, but the feedback does not fully address their needs for improving the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where countries like UK and Russia were incorrectly correlated. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment implies that the authors should provide these examples and explanations, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors know what information to include to address the feedback. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset, where countries like UK and Russia were incorrectly correlated. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion or results section where the time-series prediction is analyzed. The authors can infer that it relates to the sections where the COVID-19 dataset is discussed, but the comment does not provide explicit references. The suggestion is specific, as it clearly outlines what information should be included to address the issue. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where countries like UK and Russia were incorrectly correlated. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these issues are common or significant. The authors are left to infer the relevance and importance of these points, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the paper should include examples where time-series prediction did not perform well, such as in the COVID-19 dataset where countries like UK and Russia were incorrectly correlated, despite not being neighboring countries. It also asks for information on countries where predictions were not great and how their trajectories relate to the top eigenvectors of the Laplacian. This feedback is clear and actionable, as it provides specific areas for the authors to consider and improve upon in their analysis. By addressing these points, the authors can enhance the robustness and comprehensiveness of their work. Therefore, the comment is rated as highly helpful, as it offers detailed and constructive suggestions for improvement.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their claims. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. However, it does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its critique, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the claims of proposing a \"learning framework\" are overblown, suggesting that it is not a new framework but rather a modified loss and architecture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but rather a modified loss and architecture. While it identifies a potential issue with the claims, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this critique or enhance their claims, leaving the authors without a clear path forward. Therefore, the comment is barely helpful, as it highlights a concern but does not provide actionable insights for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2. It suggests that this limitation may hinder cross-model generalization and proposes exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the comment identifies a potential issue and suggests a direction for improvement, it does not provide explicit guidance on how to achieve this. The authors are left to infer that they should explore alternative approaches to prompt design or optimization, but the comment lacks concrete steps or examples. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, and suggests that this may limit cross-model generalization. It proposes exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion or methodology sections where the learned prompts are discussed. The authors can infer that it relates to these sections, but the comment lacks explicit references to specific parts. The suggestion to explore more universal features or independent optimization is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that learned prompts are customized for specific transformer-based architectures, such as CLIP and DINOv2, which may limit their cross-model generalization. The comment suggests exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. While the claim is logical and based on the premise of customization potentially hindering generalization, it lacks specific examples or references to support the claim fully. The suggestion to explore more universal features is a reasonable direction for improvement, but the comment could be strengthened with additional evidence or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the customization of learned prompts for specific transformer-based architectures, such as CLIP and DINOv2, which may hinder cross-model generalization. It suggests that separate training of prompts for each new architecture could be limiting. The comment proposes exploring the possibility of designing prompts with more universal features or optimizing them independently of the model architecture. This feedback is clear and actionable, as it provides a direction for the authors to consider in improving the applicability of their work across different models. However, the comment could be more helpful if it included specific suggestions or examples of how to achieve this universality. Overall, the comment is mostly helpful as it offers a valuable insight into a potential limitation and a direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of baselines in the paper, which raises concerns about the antiquated nature of the model architecture. It suggests that the current methodology may not be more effective or novel compared to contemporary time-series forecasting architectures. The reviewer provides a specific suggestion to include comparisons with other models, such as those available in the \"Time-Series Library\" repository. This feedback is explicit and provides a clear action for the authors to take, which is to include additional baselines for comparison. The suggestion is concrete, as it specifies the type of models to consider and where to find them. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the absence of baselines in the paper, which raises concerns about the antiquated nature of the model architecture. It suggests that the current methodology may not be more effective or novel compared to contemporary time-series forecasting architectures. The reviewer provides a specific suggestion to include comparisons with other models, such as those available in the \"Time-Series Library\" repository. This feedback is fully grounded as it explicitly mentions the absence of baselines and provides a specific suggestion for improvement. The comment is also specific, as it clearly identifies the issue and offers a concrete solution. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the absence of baselines raises concerns about the antiquated nature of the model architecture and suggests that the current methodology may not be more effective or novel compared to contemporary time-series forecasting architectures. The reviewer provides a specific suggestion to include comparisons with other models, such as those available in the \"Time-Series Library\" repository. This feedback is mostly verifiable as it offers a logical reasoning for the claim and provides a specific reference for the authors to consider. However, it could be strengthened by including more detailed examples or comparisons to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the absence of baselines in the paper, which raises concerns about the antiquated nature of the model architecture. It highlights that without comparisons to other models, there is no evidence that the current methodology is more effective or novel for fMRI forecasting compared to contemporary time-series forecasting architectures. The reviewer provides a clear and actionable suggestion by recommending the inclusion of additional baselines, such as those available in the \"Time-Series Library\" repository. This feedback is highly helpful as it not only points out a critical weakness but also offers a specific and practical solution for improvement, enabling the authors to enhance the robustness and relevance of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include at least one strong baseline in one of the tasks, given that the only baselines presented are standard MLPs. While the comment implies that the authors should consider adding a strong baseline, it does not explicitly instruct them to do so or provide guidance on which specific baseline to include. The action is implicit and somewhat vague, as the authors need to infer that they should add a strong baseline but are not given detailed instructions on how to implement this suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include at least one strong baseline in one of the tasks, given that the only baselines presented are standard MLPs. However, it does not specify which tasks or baselines should be considered, making it difficult for the authors to identify the exact part of the paper that needs revision. The comment lacks specificity in terms of what specific baselines should be added or how they should be integrated into the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper should include at least one strong baseline in one of the tasks, given that the only baselines presented are standard MLPs. The reviewer acknowledges that the paper is primarily theoretical but argues that including a strong baseline would enhance the paper\\'s value. However, the comment lacks specific examples or references to what constitutes a strong baseline or how it would improve the paper. This makes the claim somewhat verifiable, as it provides a general suggestion but lacks detailed justification or evidence to fully support the need for a strong baseline. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the paper should include at least one strong baseline in one of the tasks, given that the only baselines presented are standard MLPs. While the comment identifies a potential weakness in the lack of diverse baselines, it does not provide specific guidance on which strong baselines should be considered or how they could be integrated into the paper. This limits the usefulness of the feedback, as it does not offer actionable steps for the authors to improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to more clearly compare their proposed method to two prior works cited in the paper. It also suggests including these prior works for comparison in the experimental results tables. This feedback is clear and provides specific actions for the authors to take, such as revising the comparison section and updating the tables. The instructions are concrete, allowing the authors to understand exactly what changes are needed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"two prior works\" and \"the tables of experimental results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the need for a clearer comparison of the proposed method with these prior works and their inclusion in the experimental results tables. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is very similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the experimental results tables. While the comment identifies a potential issue with the lack of clarity in the comparison, it does not provide specific examples or detailed reasoning to support the claim. The suggestion to include prior works for comparison is a logical step, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, noting that the proposed method is very similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the experimental results tables. This feedback is clear and actionable, as it provides specific guidance on how the authors can enhance the clarity and completeness of their work. By addressing this suggestion, the authors can improve the differentiation of their method and provide a more comprehensive analysis of its novelty and contributions. Therefore, the comment is rated as highly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the clarity of the broader goals identified in the paper, questioning the validity of the claim that there are no visualization systems built for interpretable reinforcement learning that address these goals. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might clarify or substantiate their claim, such as suggesting specific goals or examples to consider. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses a claim about the non-existence of visualization systems for interpretable reinforcement learning that address broader goals. However, it does not specify which part of the paper this claim is based on, making it weakly grounded. The comment is specific in questioning the clarity of the broader goals, which is a valid point for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point challenges a claim about the non-existence of visualization systems for interpretable reinforcement learning that address broader goals. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the claim that there are no visualization systems built for interpretable reinforcement learning that effectively address broader goals. It points out that the claim is not clear, specifically questioning what these broader goals are. This feedback is somewhat helpful as it highlights a gap in the paper's argument and prompts the authors to clarify their goals or provide more context. However, the comment could be more helpful if it suggested ways for the authors to address this issue or provided examples of existing systems that might be relevant. Overall, the comment provides a starting point for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the independence of the introduced AAL and SLS, as well as the slight improvements observed in Table 1-4. It questions whether applying AAL or SLS separately still provides a stable improvement. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to improve their work. As a result, the authors are left without any actionable steps to take, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the independence of the introduced AAL and SLS, as well as the slight improvements observed in Table 1-4. It questions whether applying AAL or SLS separately still provides a stable improvement. However, the comment does not specify which part of the paper these elements are discussed in, making it weakly grounded. The authors can infer that it relates to the sections or tables mentioned, but this inference is not explicit. The comment is specific in detailing the issue with the independence and improvements of AAL and SLS, as well as the question about their stability. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the independence of the introduced AAL and SLS, as well as the slight improvements observed in Table 1-4. However, the comment lacks specific examples or detailed reasoning to support the claim that applying AAL or SLS separately does not provide a stable improvement. Without further elaboration or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the independence of the introduced AAL and SLS, as well as the slight improvements observed in Table 1-4. It questions whether applying AAL or SLS separately still provides a stable improvement. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their work. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps or detailed advice for the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should explore the effects of their method on different tasks or utilize multiple datasets for the same task to gain deeper insights. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The comment specifies what additional experiments or datasets should be considered, giving the authors a concrete path forward in improving their draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the limitations of the experiments, specifically mentioning the limited task and dataset. It suggests exploring the effects on different tasks or utilizing multiple datasets for the same task. However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or the introduction. While the authors can infer that it relates to the experimental setup, the lack of explicit mention of a section makes it weakly grounded. The comment is specific in suggesting ways to expand the experiments, providing clear guidance on how to address the limitation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to only one task and one dataset, suggesting that exploring different tasks or datasets would provide deeper insights. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires the authors to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments, specifically noting that the experiments are limited to only one task (sentiment classification) and one dataset (SST2). It suggests that exploring the effects on different tasks or utilizing multiple datasets for the same task would provide deeper insights. This feedback is clear and actionable, as it directs the authors to expand their experimental setup to gain a more comprehensive understanding of their method\\'s performance. By providing a specific direction for improvement, the comment is mostly helpful, as it empowers the authors to enhance their draft with additional experiments. However, it could be more helpful if it included suggestions on how to select or define these additional tasks or datasets. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments using the Heat Equation, Damped Wave, and Navier-Stokes are simulated and not real-world data. It implies that using simulated data might make it easier to fit the results. However, the comment does not provide explicit guidance on how the authors should address this issue or whether they should consider using real-world data instead. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of real-world data. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental designs, specifically mentioning the Heat Equation, Damped Wave, and Navier-Stokes. However, it does not specify which part of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in questioning the use of simulated data instead of real-world data and suggesting that simulated data might be easier to fit. However, it lacks detailed guidance on how the authors should address this issue or what specific changes are needed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments using the Heat Equation, Damped Wave, and Navier-Stokes are simulated and not real-world data, suggesting that using simulated data might make it easier to fit the results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental designs, specifically questioning the use of simulated data for the Heat Equation, Damped Wave, and Navier-Stokes experiments. It suggests that using simulated data might make it easier to fit the results, implying that real-world data could be more challenging to fit. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their experimental design. While it highlights a potential area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. While the comment explicitly states the need for these metrics, it does not provide specific guidance on how to implement them or what additional information they might provide. The action is clear but lacks detailed instructions on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. However, the comment does not specify which part of the paper this limitation is addressed in, making it weakly grounded. The suggestion is specific, as it clearly indicates what needs to be added to improve the evaluation and comparison of models. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study lacks a dedicated image quality metric for evaluating the performance of image generation models, suggesting that the inclusion of metrics like inter-class or intra-class Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. The comment provides a logical reasoning for the claim by highlighting the absence of a specific metric and suggesting a potential improvement. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to explore the literature or consult with experts to fully understand the implications of this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating the performance of image generation models. It suggests that including metrics like inter-class or intra-class Frechet Inception Distance (FID) would greatly enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By suggesting a particular metric, the comment offers a concrete way to address the limitation, making it highly helpful. However, it could be more helpful if it provided additional context or examples of how these metrics could be integrated into the study. Overall, the comment is mostly helpful, as it effectively guides the authors towards enhancing their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential application of the mechanism in vision transformers. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should explore this application, conduct experiments, or provide a rationale for why it might not be applicable. Without any actionable steps or suggestions, the authors are left without a clear direction on how to address this comment. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the potential application of the mechanism in vision transformers. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. Additionally, the comment lacks specificity as it does not provide any context or details about the mechanism or its current applications. Without clear grounding and specificity, the authors cannot effectively address the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking whether the mechanism can be used in vision transformers. It does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the potential application of the mechanism in vision transformers. While it identifies a specific area for exploration, it does not provide any guidance or suggestions on how the authors might address this question or what aspects of the mechanism could be adapted for use in vision transformers. The comment lacks actionable feedback or detailed suggestions, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, why the precision of IMLE is better than the proposed Adaptive IMLE, and second, whether the proposed method can be applied to different domains. While the questions provide a direction for the authors to consider, they do not explicitly instruct them to address these points or suggest specific actions to take. The comments are implicit and somewhat vague, as the authors can infer that they need to provide more information or justification for the observed differences in precision and domain applicability. However, the lack of explicit guidance on how to address these questions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions regarding the precision of IMLE compared to the proposed Adaptive IMLE and the applicability of the proposed method to different domains. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questions, as it seeks clarification on the observed differences in precision and the method\\'s applicability. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions that seek clarification on the precision of IMLE compared to the proposed Adaptive IMLE and the applicability of the proposed method to different domains. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions that seek clarification on the precision of IMLE compared to the proposed Adaptive IMLE and the applicability of the proposed method to different domains. While these questions are relevant and could prompt the authors to provide more detailed explanations or comparisons, they do not offer specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it identifies areas for improvement but lacks actionable advice, leaving the authors with a general direction to explore without detailed instructions on how to proceed. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of all the modules used in the experiments, suggesting that the experimental results may be lacking. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific modules might be unnecessary. The action is implicit and vague, as the authors are left to infer that they should review and potentially simplify their experimental setup. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules are necessary. However, it does not specify which part of the paper discusses the experimental results or which modules are being referred to. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique of the experimental setup, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of all the modules used in the experiments, suggesting that the experimental results may be lacking. However, the comment does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the completeness of the experimental results, specifically questioning whether all the modules used are necessary. This feedback is somewhat helpful as it prompts the authors to consider whether their experimental setup is comprehensive and whether any modules are redundant. However, the comment lacks specific guidance or suggestions on how to address this issue, such as identifying which modules might be unnecessary or how to streamline the experimental setup. Without actionable advice, the feedback is limited in its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the necessity of all the modules used in the experiments, suggesting that the experimental results may be lacking. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific modules might be unnecessary. The action is implicit and vague, as the authors are left to infer that they should review and potentially simplify their experimental setup. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the experimental results, specifically questioning whether all the modules used are necessary. However, it does not specify which part of the paper discusses the experimental results or which modules are being referred to, making it difficult for the authors to identify the exact sections that need attention. Without clear grounding, the comment is weakly grounded. It is specific in its critique of the experimental setup, but the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of all the modules used in the experiments, suggesting that the experimental results may be lacking. However, it does not provide any specific examples or reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the completeness of the experimental results, specifically questioning whether all the modules used are necessary. This feedback is somewhat helpful as it prompts the authors to consider whether their experimental setup is comprehensive and whether any modules might be redundant. However, the comment lacks specific guidance or suggestions on how the authors should address this issue, such as identifying which modules might be unnecessary or how to streamline the experimental setup. Without actionable advice, the feedback is limited in its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the necessity of all the modules used in the experiments, suggesting that the experimental results may be lacking. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific modules might be unnecessary. The action is implicit and vague, as the authors are left to infer that they should review and potentially simplify their experimental setup. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider using more layers in their GNNs, specifically mentioning 32 and 64 layers. This is an explicit suggestion that provides a clear action for the authors to take, which is to expand their experiments to include these additional layers. The comment also highlights the potential issue of oversmoothing, which adds context to the suggestion. However, it does not provide detailed guidance on how to implement this change or what specific results to expect. While the action is clear, the lack of detailed instructions makes it somewhat actionable. Therefore, the comment aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using more layers in their GNNs, specifically mentioning 32 and 64 layers. However, it does not specify which part of the paper discusses the number of layers or the experiments conducted, making it weakly grounded. The comment is specific in its suggestion to explore additional layers, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact sections that need to be addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider using more layers in their GNNs, specifically mentioning 32 and 64 layers. It references the known issue of oversmoothing in GNNs as more layers are added, which provides a logical basis for the suggestion. However, the comment lacks specific examples or references to support the claim about oversmoothing, making it somewhat verifiable. The authors would need to conduct additional research or experimentation to fully understand the implications of this suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should consider using more layers in their GNNs, specifically mentioning 32 and 64 layers. This is a clear and actionable suggestion that could significantly expand the scope of the study and potentially address the issue of oversmoothing, which is known to occur as more layers are added. By exploring these additional layers, the authors could gain valuable insights into the behavior of their network. However, the comment could be more helpful if it provided a rationale for why these specific numbers of layers were chosen or if it suggested how the authors might analyze the results of these additional experiments. Overall, the comment is mostly helpful as it directs the authors to an important area for further investigation, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform significance tests to ensure the reliability of the experimental results. This is a clear and direct action that the authors can take to address the concern about the limited improvement of MT over ST. The comment provides a specific and concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the improvement of MT over ST, suggesting that the authors should perform significance tests to ensure the reliability of the experimental results. However, it does not specify which part of the paper this improvement is discussed in, making it weakly grounded. The comment is specific in suggesting a method to address the issue of limited improvement, but without grounding, the authors may struggle to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvement of MT over ST is \"very limited\" and suggests performing significance tests to ensure the reliability of the experimental results. However, the comment lacks specific evidence or examples to support the claim that the improvement is indeed limited. It does not provide detailed reasoning or references to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the improvement of MT over ST is \"very limited.\" It provides a clear and actionable suggestion for the authors to perform significance tests to ensure the reliability of their experimental results. This feedback is valuable as it guides the authors on how to strengthen their analysis and improve the robustness of their findings. However, the comment could be more helpful if it included specific guidance on which significance tests to perform or how to interpret the results. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the model-agnostic nature of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer questions the performance of the framework on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, especially those employing LSTM-like aggregation. While the comment highlights a potential limitation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should evaluate the framework on a broader range of GNN blocks. However, the comment is somewhat specific in suggesting particular GNN blocks to consider. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the model-agnostic nature of the framework, particularly in light of the evaluation under different GCN architectures. The comment further suggests exploring the performance on different GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the model-agnostic nature of the proposed framework, specifically questioning its evaluation under different GCN architectures. The reviewer suggests that the framework should be evaluated on a broader range of GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, including those employing LSTM-like aggregation. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that the framework is not truly model-agnostic. The suggestion for broader evaluation is logical and reasonable, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the model-agnostic nature of the proposed framework, noting that it is only evaluated under different GCN architectures. The reviewer suggests that the framework's performance should be evaluated on a broader range of GNN blocks, such as GAT, GraphSAGE, GIN, and Geniepath, including those employing LSTM-like aggregation. This feedback is constructive as it points out a potential limitation in the current evaluation and suggests a direction for further exploration. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these evaluations. Overall, the comment is mostly helpful as it identifies an area for improvement and offers a clear direction for the authors to enhance their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components fails. It specifically mentions the possibility of GPT-4O missing details and asks what happens in such a scenario. While the comment implies that the authors should conduct an error analysis, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for an error analysis, but it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components fails. It specifically mentions the possibility of GPT-4O missing details and asks what happens in such a scenario. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors can infer that it relates to the method or components discussed in the paper, but without explicit references, it remains unclear. The comment is specific in detailing what kind of analysis is needed, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components fails. It specifically mentions the possibility of GPT-4O missing details and asks what happens in such a scenario. While the comment highlights a potential issue with the method's robustness, it lacks specific examples or references to support the claim that the method has many moving parts or that an error analysis is necessary. The suggestion for an error analysis is logical, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the method's robustness by noting that it has many components. It suggests that the authors should conduct an error analysis to understand how the approach behaves when one of its components fails, such as when GPT-4O misses details. This feedback is somewhat helpful as it points out a critical area for improvement and provides a specific direction for the authors to enhance the robustness of their method. However, the comment could be more helpful if it offered additional guidance on how to conduct the error analysis or suggested specific components to focus on. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components fails. It specifically mentions the possibility of GPT-4O missing details and asks what happens in such a scenario. While the comment implies that the authors should conduct an error analysis, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for an error analysis, but it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components fails. It specifically mentions the possibility of GPT-4O missing details and asks what happens in such a scenario. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The authors can infer that it relates to the method or components discussed in the paper, but without explicit references, it remains unclear. The comment is specific in detailing what kind of analysis is needed, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method has many components and requests an error analysis to understand how the approach behaves when one of its components fails. It specifically mentions the possibility of GPT-4O missing details and asks what happens in such a scenario. While the comment highlights a potential issue with the method's robustness, it lacks specific examples or references to support the claim that the method has many moving parts or that an error analysis is necessary. The suggestion for an error analysis is logical, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the method's robustness"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the approach due to the higher computational cost during training. It suggests that the authors should include perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the comment explicitly states the action to include these scores, it does not provide specific guidance on how to present or interpret them. The suggestion is concrete but lacks detailed instructions on how to implement it, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the computational cost of the reversible version and questions its practicality, suggesting that it might be more expensive than necessary. It also mentions the need to include perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. However, the comment does not specify which part of the paper discusses the computational cost or the gating mechanism, making it weakly grounded. The suggestion to include specific scores is specific, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practicality of the approach due to the higher computational cost during training. It questions whether the approach is actually practical given the current state of memory costs. The comment also suggests including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the suggestion is logical and provides a basis for further investigation, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to conduct additional analysis to fully address the concern, making the claim somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the practicality of the approach due to the higher computational cost during training, suggesting that it might be more expensive than necessary. It also recommends including perplexity/BLEU scores for NF-Rev{GRU, LSTM} to verify the necessity of the gating mechanism. While the comment identifies a potential issue and provides a suggestion for further analysis, it lacks specific guidance on how to present or interpret these scores. The feedback is somewhat helpful as it highlights an important consideration for the authors but could be more comprehensive with detailed suggestions or examples.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there is no mention of an error analysis, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. This provides a clear and direct action for the authors to take, namely to include an error analysis in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be added to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of an error analysis in the paper, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, it does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in its suggestion to include an error analysis, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for this addition. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no mention of an error analysis in the paper, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the absence of an error analysis. This is a valuable suggestion as it highlights the importance of understanding the limitations of SetCSE in certain scenarios. By pointing out this omission, the comment provides clear guidance for the authors to include an error analysis, which would enhance the comprehensiveness and robustness of their work. However, the comment could be more helpful if it offered additional suggestions on how to conduct or present the error analysis. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, especially in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to consider these possibilities and possibly explore alternative methods. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issues with measuring tool-knowledge, but the lack of grounding makes it difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. While it highlights a potential issue, the lack of evidence or detailed explanation makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model's ability to use a tool. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. The feedback is somewhat helpful as it points out a potential limitation, but it does not provide actionable steps or detailed insights that could help the authors enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or improve their approach. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly what steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issues with measuring tool-knowledge, but the lack of grounding makes it difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of measuring tool-knowledge through prompting, particularly in scenarios where model weights are shared. It suggests that unintentional fine-tuning or alternative prompts might recover or elicit the model\\'s ability to use a tool. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. While it highlights a potential issue, the lack of evidence or detailed explanation makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', '"}
{"generated_text": "{'actionability_rationale': 'The review point provides an implicit suggestion for the authors to find other tasks or even artificial tasks to demonstrate the effectiveness of HA3C. While the action is not explicitly stated, it is clear that the reviewer believes the current experimental results do not fully support the effectiveness of HA3C, and they suggest a specific course of action to address this. The suggestion is concrete, as it provides a clear direction for the authors to explore. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the experimental results, specifically mentioning the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks. It provides a rationale for this observation, suggesting that the benefit of HA3C may be due to the structure of the problem, where the causal relationship based on the history is simple. However, the comment does not specify which part of the paper this analysis is based on, making it weakly grounded. The suggestion to find other tasks or artificial tasks to demonstrate the effectiveness of HA3C is specific, but the initial part of the comment lacks grounding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point presents a claim that the improvement of HA3C is marginal over baseline algorithms on MuJoCo control tasks, but it does not provide specific evidence or reasoning to support this claim. The reviewer suggests that the benefit of HA3C relies on the structure of the problem, where the causal relationship based on the history is simple. However, the comment lacks detailed examples or references to substantiate this claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experimental results, specifically noting that the improvement of HA3C is marginal over baseline algorithms on MuJoCo control tasks. The reviewer provides a rationale for this observation, suggesting that the benefit of HA3C may be due to the structure of the problem, where the causal relationship based on the history is simple. This insight could be valuable for the authors to consider when interpreting their results. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided additional context to support the claim. Overall, the comment is somewhat helpful as it highlights a potential weakness in the experimental results but lacks depth and actionable guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should focus on the insights derived from the data rather than just reporting aggregate numbers. It explicitly states that the paper does not fully address this aspect and provides a specific request for key insights or takeaways that are generalizable and hold broader significance for the community. This feedback is clear and provides a direct action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the novelty of the dataset and the key contributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of focus on insights derived from the data to deepen understanding of LLM capabilities. The reviewer suggests that the paper should report key takeaways beyond the general message that LLM performance does not align with human abilities. This provides clear guidance on what the authors need to address to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not fully address the key contributions, specifically focusing on the insights derived from the data to deepen understanding of LLM capabilities. The reviewer suggests that the paper primarily reports aggregate numbers without presenting key takeaways that are generalizable and hold broader significance for the community. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the exact nature of the missing insights or takeaways, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's focus, suggesting that the novelty does not lie in the dataset itself but rather in the insights derived from the data. It highlights that the paper lacks a clear focus on these insights, which could deepen the understanding of LLM capabilities. The reviewer provides a specific suggestion for improvement, recommending that the authors report key takeaways or insights that are generalizable and hold broader significance for the community. This feedback is clear and actionable, offering the authors a concrete direction for enhancing their draft. However, it could be more helpful if it provided examples or detailed guidance on how to derive these insights. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to a critical area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the claim in Section 3.1 is false and ignores a significant number of active and important works in the community. It provides specific examples of alternative vocoders, such as WaveNet, WaveRnn, and diffusion-based approaches, which are not mentioned in the paper. This feedback is explicit and provides concrete guidance on what the authors should consider when revising their paper. By highlighting the false claim and suggesting alternative vocoders, the comment offers clear and actionable advice for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"GAN has been the de facto choice for vocoders,\" noting that it ignores a large array of active and important works in the community. The comment provides specific examples of alternative vocoders, such as WaveNet, WaveRnn, and diffusion-based approaches, which are not mentioned in the paper. This level of detail helps the authors understand what needs to be addressed in their paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"GAN has been the de facto choice for vocoders\" is false and ignores a large array of active and important works in the community. The reviewer provides specific examples of alternative vocoders, such as WaveNet, WaveRnn, and diffusion-based approaches, which are not mentioned in the paper. This provides a clear and specific counterpoint to the original claim, making the comment mostly verifiable. However, it could be strengthened by providing more detailed references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a false claim in the paper, specifically in Section 3.1, where it states that GAN has been the de facto choice for vocoders. The reviewer provides a detailed critique, pointing out that this claim ignores a large array of active and important works in the community, such as WaveNet, WaveRnn, and diffusion-based approaches. By offering specific examples of alternative vocoders, the comment offers actionable feedback that can help the authors improve their understanding and presentation of the field. This feedback is clear and provides a clear direction for the authors to consider when revising their paper, making it highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the approach, while straightforward and sensible, contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific steps they should take to improve the explanation or justification of these choices. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and empirical justifications for their design choices. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the design choices in the approach, specifically mentioning the choice of token similarity metric as an example. However, it does not specify which part of the paper these design choices are discussed in, making it weakly grounded. The comment is specific in identifying the issue of lacking explanation and empirical justification for these choices, but it does not provide detailed guidance on how to address this. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the approach contains design choices that are not fully explained or empirically justified, specifically mentioning the choice of token similarity metric as an example. However, the comment does not provide specific examples or detailed reasoning to support why these choices are not justified. The lack of detailed evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, noting that while the approach is straightforward and sensible, it lacks full explanation and empirical justification for some design choices, such as the choice of token similarity metric. This feedback is somewhat helpful as it points out a potential weakness in the paper's methodology and suggests that the authors should provide more detailed explanations and justifications for their design choices. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the explanations or justifications. Overall, the comment provides a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point identifies specific inconsistencies in the notation of Equations (4) and (6), pointing out that the left-hand side (LHS) has terms like T and W, while the right-hand side (RHS) does not. It also notes that the formulas for the mean and variance have a variable 'j' on the LHS but not on the RHS. This feedback is explicit and provides clear guidance for the authors to correct these inconsistencies. The authors know exactly what needs to be done to address the issues, namely, to ensure consistency in notation throughout the equations. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation (4)\" and \"Equation (6),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistencies in notation, particularly the presence of terms like T and W on the LHS but not on the RHS, and the presence of the variable \"j\" in the formulas for the mean and variance. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point identifies specific inconsistencies in the notation of Equations (4) and (6), noting that the left-hand side has terms like T and W, while the right-hand side does not, and that the formulas for the mean and variance have a variable 'j' on the LHS but not on the RHS. This is a factual observation that does not require any additional justification or evidence. Therefore, the comment is classified as 'No', as it does not contain a claim or suggestion that requires verification.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies specific inconsistencies in the notation of Equations (4) and (6), pointing out that the left-hand side has terms like T and W, while the right-hand side does not, and that the formulas for the mean and variance have a variable 'j' on the LHS but not on the RHS. This feedback is clear and actionable, as it directly points out areas where the authors need to ensure consistency in their notation. By addressing these inconsistencies, the authors can improve the clarity and professionalism of their draft. However, the comment could be more helpful if it provided suggestions on how to correct these inconsistencies or offered guidance on maintaining consistency throughout the paper. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights several issues with the evaluation, including the insufficient number of models constructed, the lack of evaluation regarding the distortion of the image after warping, and the absence of discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their evaluation, include more models, and discuss potential countermeasures, but the comment lacks concrete steps or examples on how to implement these changes. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the evaluation section, specifically mentioning the insufficient number of models constructed and the lack of evaluation regarding the distortion of the image after warping. It also points out the absence of discussion on potential countermeasures against the proposed approach. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the evaluation section. The comment is specific in detailing what is missing, such as the need for more models and discussion on countermeasures. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the evaluation is insufficient due to the limited number of models constructed and the lack of evaluation regarding the distortion of the image after warping. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies several areas where the paper could be improved, specifically regarding the evaluation section. It points out that the number of models constructed during evaluations is insufficient, suggesting that more models should be evaluated to demonstrate the effectiveness of the approach. Additionally, the comment highlights the lack of evaluation regarding the distortion of the image after warping and the absence of discussion on potential countermeasures against the proposed approach. While the comment provides clear areas for improvement, it could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the feedback is mostly helpful as it directs the authors to enhance their evaluation and consider additional aspects, but it could be more comprehensive with more detailed guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify whether all the discourse particles in Table A3 are discourse particles or discourse + imported vocab. It also suggests that if they are the latter, the authors should consider putting them in separate tables and include glosses for better understanding. This feedback is clear and provides a direct action for the authors to take, making it highly actionable. The comment specifies what needs to be addressed and how to implement the suggested changes, giving the authors a clear path forward.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether all the discourse particles in the table are discourse particles or discourse + imported vocab, and it suggests a potential solution by recommending separate tables and the inclusion of glosses. This provides clear guidance on what needs to be addressed in the table, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the classification of discourse particles in Table A3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual question seeking additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific issue with Table A3, questioning whether all the discourse particles are correctly classified. It suggests that if they are a mix of discourse and imported vocab, the authors should consider separating them into separate tables and include glosses for better understanding. This feedback provides a clear direction for the authors to improve the clarity and organization of their data presentation. However, the comment could be more helpful if it offered additional suggestions or examples of how to implement these changes. Overall, the comment is somewhat helpful as it points out a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind formula (4), specifically why it involves a maximum over all possible pieces for unoccupied squares. While the comment identifies a lack of understanding, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify or explain the purpose of the formula. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the formula, questioning the rationale behind the maximum over all possible pieces for unoccupied squares. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the rationale behind formula (4), specifically why it involves a maximum over all possible pieces for unoccupied squares. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the rationale behind formula (4), particularly why it involves a maximum over all possible pieces for unoccupied squares. This feedback is clear and actionable, as it prompts the authors to clarify or explain the purpose of the formula, which is essential for understanding and improving the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to address the issue. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experiments lack a comparison to state-of-the-art subset selection methods. This provides a clear and direct action for the authors to take, which is to include such a comparison in their experiments. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparison to state-of-the-art subset selection methods. This provides clear guidance on what needs to be addressed in the experiments section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments lack a comparison to state-of-the-art subset selection methods. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a comparison to state-of-the-art subset selection methods in the experiments. This feedback is clear and actionable, as it directs the authors to include such a comparison to enhance the comprehensiveness and relevance of their work. By addressing this issue, the authors can strengthen their paper by providing a more robust evaluation of their methods against existing techniques. However, the comment could be more helpful if it suggested specific subset selection methods to consider or how to integrate these comparisons into the paper. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the novelty of the paper is somewhat vague and needs to be more concise. It also notes that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific guidance on how to enhance the novelty or clarify the integration of these elements. The authors are left with a general understanding of what needs to be improved but without concrete steps or suggestions on how to achieve this. As a result, the comment is somewhat actionable, as it identifies a need for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the novelty of the paper is somewhat vague and needs to be more concise. It also mentions that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not specify which part of the paper is being addressed or how the novelty could be improved. The authors can infer that it relates to the introduction or discussion sections, but this inference is not explicit. The comment lacks specificity in detailing what aspects of the novelty are unclear or how they could be clarified. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is somewhat vague and needs to be more concise. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a concern about the novelty of the paper, noting that it seems to integrate elements from previous works, such as SCL, Aligned, and CLNN. This feedback highlights a potential issue with the originality of the research, which is an important aspect for authors to consider when revising their draft. However, the comment lacks specific guidance or suggestions on how to enhance the novelty or differentiate the paper from existing works. Without actionable advice, the authors may find it challenging to address the feedback effectively. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback is explicit, as it directly instructs the authors to include such benchmarks to enhance the usability and availability of the benchmark to the community. The action is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to use evaluation benchmarks to enhance the usability and availability of the benchmark, but without grounding, the authors may struggle to identify the exact section where this improvement is needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that using evaluation benchmarks of the user simulator would be important to demonstrate how smaller models perform as user simulators. However, the comment does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the usability and availability of the benchmark. Without such evidence or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that using evaluation benchmarks of the user simulator would be important to demonstrate how smaller models perform as user simulators. This feedback is somewhat helpful as it identifies a potential area for improvement in terms of benchmark usability and availability. However, the comment lacks specificity and does not provide detailed guidance on how to implement this suggestion or what specific benchmarks should be used. To be more helpful, the comment could include examples of existing benchmarks or detailed steps on how to incorporate them into the evaluation process. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects of the method might be affected by open-set detectors. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft in response to this question. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of open-set detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section or result. The authors may infer that it relates to the experimental section or the discussion of the proposed method, but this inference is not explicit. The comment is specific in asking about the impact of open-set detectors, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the impact of open-set detectors on the performance of the proposed method. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry that does not claim or imply any specific issues or errors in the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the impact of open-set detectors on the performance of the proposed method. While it identifies a relevant area for exploration, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the method might be affected by open-set detectors. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate issues. The first issue is about the lack of explanation for the star (*) symbol in Table 1, which is explicitly stated as a request for clarification. The second issue concerns the \"from-scratch\" label in Table 5, which is also explicitly stated as a request for clarification. Both comments provide clear and direct actions for the authors to take, such as providing an explanation for the symbol or clarifying the \"from-scratch\" label. These actions are explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the symbols and labels in these tables, providing clear guidance on what needs to be clarified or corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate issues. The first issue is about the lack of explanation for the star symbol in Table 1, which is explicitly stated as a request for clarification. The second issue concerns the \"from-scratch\" label in Table 5, which is also explicitly stated as a request for clarification. Both claims are clear and direct, requiring no additional justification or evidence. Therefore, the comment is fully verifiable, as it provides explicit requests for clarification that are straightforward to address. This aligns with a score of 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies two specific issues in the paper that need clarification. First, it points out the absence of an explanation for the star symbol in Table 1, which is crucial for understanding the context of \"oracle goals.\" This feedback is clear and actionable, as it directly instructs the authors to provide an explanation for the symbol. Second, it questions the \"from-scratch\" label in Table 5, suggesting that the authors clarify whether the model was randomly initialized or pre-trained on some text corpus. This part of the comment also provides a clear request for clarification. Overall, the comment is mostly helpful as it highlights specific areas where the paper lacks clarity and provides actionable suggestions for improvement. However, it could be more helpful if it offered additional guidance or examples on how to address these issues. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the expected relationship between transferability and noise intensity, suggesting that it might not be as expected based on the intuition that increased noise would lead to misclassification. However, the comment does not provide explicit guidance or suggestions for the authors to address this issue. It lacks concrete actions or detailed advice on how to investigate or explain this phenomenon further. The authors are left to infer that they should explore this unexpected result, but without specific steps or suggestions, the comment remains vague and unactionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 1,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the expected relationship between transferability and noise intensity, suggesting that the results may not align with intuition. The comment provides a clear rationale for the concern, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a question about the expected relationship between transferability and noise intensity, suggesting that it might not be as expected based on the intuition that increased noise would lead to misclassification. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the expected relationship between transferability and noise intensity, suggesting that it might not align with intuition. It points out that as inputs are increasingly deformed by noise, different neurons should be activated to reduce confidence in the source samples, leading to increased misclassification. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore it further. While it identifies a potential area for improvement, the feedback lacks actionable advice, making it somewhat helpful. The authors are left to infer that they should investigate this unexpected result, but without detailed guidance, the comment remains incomplete.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several actions for the authors to take. First, it recommends conducting ablation studies with only importance weighting or the rejection to better understand their effects. This is an explicit and concrete suggestion, providing a clear direction for the authors to improve their work. Additionally, the comment points out issues with the font size in figures and questions about the results in Fig. 6(a). While these are not explicitly stated as actions, they provide specific areas for the authors to address, making the comment mostly actionable overall.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig. 6 (a)\" and \"ChopperCommand results,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, such as conducting ablation studies and explaining the results in Fig. 6(a). The comment is specific in detailing the issues with the font size and the perceived difficulty of learning, providing clear guidance on what the authors need to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that adding ablation studies with only importance weighting or the rejection would help understand their effects better. It also points out issues with the font size in figures and questions about the results in Fig. 6(a). However, the comment lacks specific examples or references to support the claim about the ablation studies or the perceived difficulty of learning. The suggestion about the font size is clear, but the reasoning behind the perceived difficulty of learning in Fig. 6(a) is not fully explained. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks detailed justification or examples to fully support the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides several actionable suggestions for improvement. It recommends conducting ablation studies to better understand the effects of importance weighting and rejection, which is a concrete and specific suggestion that can enhance the paper's analysis. Additionally, the comment points out issues with the font size in figures and questions about the results in Fig. 6(a), prompting the authors to clarify or explain these aspects. While the comment does not fully address the font size issue, it provides clear guidance on what the authors need to consider. Overall, the feedback is mostly helpful as it offers actionable insights and suggestions for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a weakness in the technical clarity, specifically mentioning that the main learning framework Equation (18) is not explained. It also asks for clarification on how to implement the balancing term and the penalty term. While the comment explicitly states what needs to be addressed, it lacks concrete guidance on how to implement these clarifications. The authors know they need to provide more detailed explanations and examples, but the comment does not specify the exact steps or details required. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the technical clarity, specifically mentioning Equation (18) as not being explained. It also asks for clarification on how to implement the balancing term and the penalty term. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the explanation of Equation (18) and the implementation of the balancing and penalty terms. The comment is also specific because it clearly specifies what needs to be addressed in terms of technical clarity and implementation details. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical clarity is weak, specifically mentioning that the main learning framework Equation (18) is not explained. It also asks for clarification on how to implement the balancing term and the penalty term. While the comment identifies a specific area of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the exact issues with the technical clarity and implementation, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of weakness in the paper, namely the lack of clarity in the technical framework, particularly regarding Equation (18). It highlights the need for more detailed explanation and implementation guidance for the balancing term and the penalty term. This feedback is clear and actionable, as it provides the authors with a specific area to focus on for improvement. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or provided examples of how to implement these terms. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the decision boundary generation and the use of 2D projections to represent high-dimensional boundaries. It highlights that the projection results and Voronoi tessellations should be updated as feature vectors update during training. The comment suggests clarifying how well these fixed tessellations capture the model\\'s behavior with updated predictions. Additionally, it questions the use of 2D projections and the potential variability in results based on the selected projection method and parameters. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the figures\" and \"the figures, the projection results and the Voronoi tesselation results,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the projection results and decision boundaries should be updated as feature vectors update during training, and it questions the use of 2D projections to represent high-dimensional boundaries. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the decision boundary generation, noting that the projection results and Voronoi tessellations appear fixed across multiple rounds, despite the feature vectors updating during training. The reviewer suggests that these fixed tessellations should be updated to better capture the model\\'s behavior. Additionally, the comment questions the use of 2D projections to represent high-dimensional boundaries, noting that results can vary significantly based on the selected projection method and parameters. While the comment provides a logical reasoning for the concerns, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires further elaboration for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical concern regarding the decision boundary generation, noting that the projection results and Voronoi tessellations appear fixed across multiple rounds, despite the feature vectors updating during training. This observation is important as it highlights a potential limitation in the model's adaptability and the need for clarification. The comment also raises concerns about the use of 2D projections to represent high-dimensional boundaries, suggesting that results can vary significantly based on the selected projection method and parameters. This feedback is valuable as it points out areas where the paper could be improved, such as updating the decision boundaries and clarifying the use of projections. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these concerns. Overall, the comment is mostly helpful as it identifies significant issues and provides a direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that an ablation study is missing and that there is no comparison to methods from the past decade. This provides clear and direct actions for the authors to take, namely to include an ablation study and compare their methods to those from the past decade. The feedback is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment points out the absence of an ablation study and the lack of comparison to methods from the past decade. However, it does not specify which part of the paper these elements should be included in, making it weakly grounded. The comment is specific in identifying the need for an ablation study and a comparison to past methods, but without explicit references to sections or figures, the authors may struggle to pinpoint where these additions should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is no ablation study and no comparison to methods from the past decade. However, it does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two critical areas for improvement: the absence of an ablation study and the lack of comparison to methods from the past decade. These are important aspects that can significantly enhance the paper's contribution and understanding of the research. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors strengthen their work. However, the comment could be more helpful if it offered suggestions on how to conduct an ablation study or which past methods to compare with. Overall, the comment is mostly helpful as it directs the authors' attention to essential areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. While the comment implies that the authors should expand their theoretical analysis, it does not provide specific guidance on which models to include or how to conduct the additional analysis. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. However, it does not specify which sections or parts of the paper should include these additional results, making it difficult for the authors to identify the exact areas that need revision. The comment lacks specificity in terms of what specific models or aspects of the models should be included, leaving the authors with a vague understanding of what needs to be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. However, the comment does not provide any specific examples, references, or reasoning to support why these additional results are necessary or how they would enhance the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include more theoretical results on more complicated models, in addition to the existing results on SVC. While this feedback identifies an area for improvement, it lacks specificity and does not provide guidance on which models or aspects of the models should be included. The comment does not offer detailed suggestions or examples of how to expand the theoretical analysis, leaving the authors with a vague understanding of what is expected. As a result, the comment is somewhat helpful, as it points out a potential area for enhancement but does not fully support the authors in making the necessary improvements. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It specifies that the existing results in Fig. 11 are not sufficient to demonstrate this necessity. This feedback is clear and direct, providing a specific action for the authors to take. It also gives a clear indication of what needs to be added or improved, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, referencing Fig. 11 as an existing result. This provides some grounding by mentioning a specific figure, but it does not explicitly identify the part of the paper where the ablation studies should be included. The comment is specific in its suggestion to demonstrate the necessity of the proposed DA Inversion, but the lack of explicit mention of the section makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion, referencing Fig. 11 as an existing result. However, the comment does not provide specific examples or detailed reasoning to support why additional ablation studies are necessary or how they would enhance the demonstration of the DA Inversion\\'s necessity. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It references a specific figure (Fig. 11) as an existing result that may not be sufficient to demonstrate the necessity of the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by conducting additional studies. However, the comment could be more helpful if it offered suggestions on how to design or interpret these ablation studies. Overall, the comment is mostly helpful as it guides the authors towards a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a question about the necessity of clustering in the second phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. It suggests that a clear ablation study should be presented to address this issue. While the comment implies that an ablation study is necessary, it does not explicitly instruct the authors to conduct such a study or provide detailed guidance on how to perform it. The action is implicit and somewhat vague, as the authors need to infer that an ablation study is required and how to execute it. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of clustering in the second phase of training and suggests a clear ablation study to address this issue. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the necessity of clustering in the second phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. The comment suggests that a clear ablation study should be presented to address this issue. However, the comment lacks specific examples or references to support the claim that clustering is unnecessary or that an ablation study is required. The reasoning is based on a logical deduction, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of clustering in the second phase of training, given that a linear regressor is used on top of the discovered keypoints for evaluation. It suggests that a clear ablation study should be presented to address this issue, which is a constructive and actionable suggestion. By pointing out this potential redundancy and recommending a specific type of analysis, the comment provides the authors with a clear direction for improving their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it identifies a potential area for improvement and offers a clear direction for the authors to enhance their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the forgetting in Fig2a is not as drastic as in class incremental and even shows a slight increase near epoch 150. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their figures or analysis. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the forgetting in the figure is not as drastic as in class incremental and even shows a slight increase near epoch 150. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the forgetting in Fig2a is not as drastic as in class incremental and even shows a slight increase near epoch 150. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the forgetting in Fig2a, noting that it is not as drastic as in class incremental and even shows a slight increase near epoch 150. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable advice or detailed feedback, the comment leaves the authors with a general understanding of the problem but without a clear path to resolution. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. While the comment implies that this is a relevant aspect to address, it does not explicitly instruct the authors to make this change or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in the abstract. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. However, it does not specify which part of the paper this information should be included in, nor does it provide detailed guidance on how to present this information. The authors can infer that it pertains to the results section or the abstract, but the lack of specificity makes it difficult to pinpoint the exact location. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. However, it does not provide any reasoning, evidence, or examples to support why this is important or how it affects the paper. Without such justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should highlight the data-dependent nature of their approximation results, possibly in the abstract. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on how to present this information or why it is important. The comment does not offer actionable advice or examples of how to incorporate this information, leaving the authors with a general idea but no clear path forward. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in making the necessary changes. This aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the meaning of RMSD in Figure 3. It specifies two possible interpretations: RMSD between a docking pose and the ground truth from PDB, or RMSD between docking poses obtained with different methods to quantify consensus. This provides a clear and direct action for the authors to take, which is to clarify the meaning of RMSD in their figure. The comment is explicit and concrete, guiding the authors on exactly what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, clarifying the meaning of RMSD in the figure. The comment distinguishes between RMSD as the difference between a docking pose and the ground truth from PDB, or RMSD between docking poses obtained with different methods to quantify consensus. This provides clear guidance on what the authors need to clarify, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the meaning of RMSD in Figure 3, specifically whether it refers to the RMSD between a docking pose and the ground truth from PDB, or between docking poses obtained with different methods to quantify consensus. This is a factual question seeking clarification and does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, providing a specific request for clarification regarding the meaning of RMSD in Figure 3. It distinguishes between two possible interpretations: RMSD between a docking pose and the ground truth from PDB, or RMSD between docking poses obtained with different methods to quantify consensus. This feedback is valuable as it helps the authors clarify their presentation and ensure that their results are accurately represented. By addressing this point, the authors can improve the clarity and interpretability of their data, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It also questions whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore the necessity of phase transitions and consider alternative scenarios. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It also questions whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it pertains to the sections discussing regret scaling and phase transitions, but this inference is not explicit. The comment is specific in its suggestion to explore the necessity of phase transitions and the possibility of a smooth regret scaling. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It questions whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The authors are left to infer the necessity of addressing this issue, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the paper should provide a more thorough treatment of the necessity of phase transitions in the 'actual regret scaling' compared to the asymptotic bounds. It also questions whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's analysis. However, it lacks specific guidance or suggestions on how the authors might address this issue, such as recommending additional experiments or theoretical considerations. While it points out an area that could be expanded, the comment could be more helpful with more detailed advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It also questions whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore the necessity of phase transitions and consider alternative scenarios. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It also questions whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it pertains to the sections discussing regret scaling and phase transitions, but this inference is not explicit. The comment is specific in its suggestion to explore the necessity of phase transitions and the possibility of a smooth regret scaling, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review comment suggests that the paper should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds. It also questions whether there could be a smooth regret scaling without phase transitions for which the proven bounds still hold. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The authors are left to infer the necessity of addressing this issue, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks a comparison to previous robust reinforcement learning (RL) methods, despite citing them (e.g., RARL). It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. While the comment implies that the authors should include a comparison to these methods, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to address the lack of comparison, but it lacks concrete guidance on how to implement this change. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment points out a potential issue with the paper regarding the lack of comparison to previous robust RL methods, despite citing them (e.g., RARL). It suggests that if GAD or EG already include these prior works, the authors should be explicit about it. However, the comment does not specify which sections of the paper are affected by this issue, making it weakly grounded. The authors can infer that it relates to the discussion or results sections, but this is not explicitly mentioned. The comment is specific in identifying the need for a comparison to robust RL methods and suggesting that the authors be explicit about including these prior works if they are already covered in GAD or EG. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to previous robust RL methods, despite citing them (e.g., RARL). However, the comment does not provide specific examples or references to these methods, nor does it explain why such a comparison is necessary or how it would enhance the paper. Without detailed justification or examples, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out the lack of comparison to previous robust reinforcement learning (RL) methods, despite citing them (e.g., RARL). It suggests that if other works like GAD or EG already include these prior works, the authors should be explicit about it. This feedback is somewhat helpful as it highlights an area where the paper could be strengthened by providing a more comprehensive comparison. However, the comment could be more helpful if it provided specific suggestions on how to include these comparisons or examples of how to do so. Overall, the comment offers a direction for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. This feedback is clear and direct, giving the authors a specific action to take: to provide additional details about these aspects. The comment is explicit and concrete, as it clearly outlines what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details should be provided about the choice of $k_1,k_2,k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its request for additional details, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details should be provided about the choice of parameters ($k_1,k_2,k_3$), networks, and learning objectives. However, it does not provide any specific reasoning or evidence to support why these details are necessary or how they might impact the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the significance of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more details should be provided about the choice of parameters ($k_1,k_2,k_3$), the networks, and the learning objectives. This feedback is clear and actionable, as it directs the authors to enhance the transparency and comprehensiveness of their methodology. However, the comment could be more helpful if it provided examples or suggestions on how to elaborate on these aspects. Overall, the comment is mostly helpful as it highlights a critical area for improvement but could be more detailed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relationship between HIS and the negative inverse of mean response time, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their draft. The comment lacks any actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to a specific section or discussion, but this inference is not explicit. The comment is specific in questioning the relationship between the two variables, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the relationship between HIS and the negative inverse of mean response time, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, which is a specific and relevant point for the authors to consider. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve their understanding of the relationship. It lacks actionable feedback or detailed explanations, leaving the authors without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their draft. The comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to a specific section or discussion, but this inference is not explicit. The comment is specific in questioning the relationship between the two variables, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the relationship between HIS and the negative inverse of mean response time, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, which is a specific and relevant point for the authors to consider. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve their understanding of the relationship. It lacks actionable feedback or detailed explanations, leaving the authors without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their draft. The comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to a specific section or discussion, but this inference is not explicit. The"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it questions the rationale behind choosing a specific sparse representation learning method and suggests that the experiments should include a comparison with FTA as a baseline. Second, it points out the inconsistency in comparing the performance in a supervised learning setting but omitting it in a reinforcement learning (RL) setting, questioning the validity of the comparison. The reviewer provides a clear and explicit action for the authors to take, which is to justify their choice of method and include a comparison with FTA in the RL setting. This feedback is concrete and provides specific guidance on how to address the issues, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises two main concerns: the rationale behind choosing a specific sparse representation learning method and the inclusion of FTA as a baseline in the experiments. It also questions the consistency in comparing performance in supervised and reinforcement learning settings. While the comment does not explicitly mention specific sections of the paper, it provides clear guidance on what needs to be addressed, such as justifying the choice of method and including a comparison with FTA in the RL setting. This makes the comment somewhat specific but not fully grounded, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main concerns. First, it questions the rationale behind choosing a specific sparse representation learning method and suggests that the experiments should include a comparison with FTA as a baseline. This part of the comment is somewhat verifiable as it provides a logical reasoning for the inclusion of FTA, but it lacks specific examples or references to support the claim fully. The second part of the comment questions the consistency in comparing performance in supervised and reinforcement learning settings, which is a valid concern but lacks detailed justification or examples. Overall, the comment is somewhat verifiable due to the logical reasoning provided but with gaps in supporting evidence.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises two important points. First, it questions the rationale behind choosing a specific sparse representation learning method and suggests that the experiments should include a comparison with FTA as a baseline. This feedback is actionable and provides a clear direction for the authors to improve their draft by justifying their methodological choices and ensuring a comprehensive comparison. Second, the comment points out an inconsistency in the experimental setup, questioning why the comparison is made in a supervised learning setting but omitted in a reinforcement learning setting. This observation highlights a potential gap in the paper's analysis and suggests that a rigorous comparison is necessary. Overall, the comment is mostly helpful as it identifies specific areas for improvement and provides clear guidance on how to enhance the paper's rigor and comprehensiveness. However, it could be more helpful if it offered additional suggestions or examples for addressing these issues. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors describe a choice of shift and scaling on page 4, line 154, but fail to explain why this choice is more appropriate. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should provide an explanation for the choice of shift and scaling. However, the comment lacks concrete details on how to structure this explanation, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation for why the choice of shift and scaling is more appropriate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors describe a choice of shift and scaling but fail to explain why this choice is more appropriate. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is more appropriate or why it should be explained. Without additional context or justification, the claim remains unverifiable, as the authors may not understand the basis for the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the authors describe a choice of shift and scaling but fail to explain why this choice is more appropriate. This feedback is valuable as it highlights a gap in the paper's explanation, which could potentially impact the reader\\'s understanding of the methodology. However, the comment does not provide any guidance on how the authors might address this issue or what aspects of the choice should be explained. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should revise the use of \"partial inference of GFlowNets\" in the title and elsewhere. This provides a clear and direct action for the authors to take, which is to make the necessary changes to the title and other instances where \"partial inference\" is used. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the use of \"partial inference of GFlowNets\" in the title and elsewhere, providing full grounding as it allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the need for revision regarding the use of \"partial inference.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a concern about the use of \"partial inference of GFlowNets\" in the title and elsewhere, suggesting that it should be revised. However, the comment does not provide any reasoning, examples, or references to support why this term is problematic or why it should be changed. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the title and other instances of \"partial inference\" in the paper, suggesting that these should be revised. This feedback is clear and actionable, as it provides a direct suggestion for improvement. By addressing this issue, the authors can enhance the clarity and accuracy of their title and other relevant sections. However, the comment could be more helpful if it provided additional context or examples of how the revision could be made. Overall, the comment is mostly helpful as it guides the authors towards improving their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only uses bertscore to measure the similarity of the newly generated text and suggests that there are other matrices that could measure the stealthiness of the generated content. However, it does not provide specific guidance on which matrices to consider or how to incorporate them into the analysis. The action is implicit, as the authors need to infer that they should explore additional metrics, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of bertscore as the sole metric for measuring the similarity of the newly generated text, suggesting that there are other matrices that could measure the stealthiness of the generated content. However, it does not specify which part of the paper discusses the use of bertscore or where the suggestion to explore additional metrics should be made. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding makes it difficult to pinpoint the exact location. The comment is specific in suggesting the need for additional metrics but lacks grounding, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only measures similarity using bertscore and suggests that there are other matrices that could measure the stealthiness of the generated content. However, the comment does not provide specific examples or references to these additional metrics, making it difficult for the authors to understand or address the suggestion. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the nature of the additional metrics themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's evaluation, specifically noting that the paper only uses bertscore to measure the similarity of the newly generated text. It suggests that there are other matrices that could measure the stealthiness of the generated content, which is a valid observation. However, the comment lacks specificity and does not provide examples or guidance on which additional metrics could be used or how they might be incorporated into the analysis. While it highlights an area for improvement, the feedback is somewhat helpful as it prompts the authors to consider broader metrics but does not offer detailed suggestions for implementation. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the need to clearly highlight the issues with existing estimators for more convenient applications, and the lack of defined basic notation, which makes certain terms like \"dimensionality p,\" \"unit ball S p,\" \"outer product (v) \u2297 2,\" \"constraint set \u0398,\" and \"constant d 2\" mysterious. While the comment identifies specific areas that need clarification, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should clarify the notation and provide more context for the estimators, but the lack of concrete steps or examples makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the need to highlight issues with existing estimators for more convenient applications and the lack of defined basic notation, which makes certain terms mysterious. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with notation and the need for clarity, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two concerns: the need to highlight issues with existing estimators for more convenient applications and the lack of defined basic notation, which makes certain terms mysterious. The comment provides specific examples of terms that are unclear, such as \"dimensionality p,\" \"unit ball S p,\" \"outer product (v) \u2297 2,\" \"constraint set \u0398,\" and \"constant d 2.\" However, it does not provide detailed reasoning or references to support why these terms are unclear or how they should be clarified. The lack of specific examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the exact issues and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas for improvement in the paper. First, it suggests that the issues with existing estimators need to be clearly highlighted for more convenient applications. This is a valuable point as it directs the authors to address a potential weakness in their work. Second, the comment points out that basic notation is not defined, making certain terms mysterious. This feedback is actionable as it provides clear guidance on what needs to be clarified. However, the comment could be more helpful if it offered suggestions on how to define the notation or provide more context for the estimators. Overall, the comment is mostly helpful as it identifies key areas for improvement and provides some direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper mentions three perceptual loss functions for PSR, two of which are new, but does not elaborate on what makes these loss functions novel. It suggests that the authors should provide more details about the new aspects of these loss functions. While the comment implies that the authors should clarify the novelty of the loss functions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on the novelty of the loss functions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"three perceptual loss functions for PSR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking the authors to elaborate on which parts of the loss functions are new, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper mentions three perceptual loss functions for PSR, two of which are new, but the neural network and loss functions used are not novel. The reviewer suggests that the authors should elaborate on which parts of the loss functions are new. While the comment identifies a potential issue with the novelty of the loss functions, it lacks specific examples or references to support the claim. The reasoning is based on the authors\\' assertion of newness, which is not substantiated by detailed evidence or comparisons. Therefore, the claim is somewhat verifiable, as it provides a basis for the assertion but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the loss functions mentioned in the paper, despite the authors' claim that two of the perceptual loss functions are new. It suggests that the authors should elaborate on which parts of the loss functions are novel, providing a clear and actionable feedback. This feedback is helpful as it prompts the authors to clarify their claims and potentially enhance the originality of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to elaborate on the novelty of the loss functions. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a concern about the experimental results, noting that they do not exhibit significant improvement in real-life datasets and suggesting that the comparison on the ZINC dataset is lacking. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve their experimental results. The comment lacks actionable details, such as recommending specific improvements or changes to the experimental setup. As a result, the authors are left without clear instructions on how to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'experimental results' and references 'Table 5 in [1]', allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the experimental results do not exhibit significant improvement in real-life datasets and that the comparison on the ZINC dataset is lacking. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the experimental results do not exhibit significant improvement in real-life datasets and that the comparison on the ZINC dataset is lacking. However, the comment does not provide specific examples or detailed reasoning to support these claims. The mention of 'Table 5 in [1]' provides some context, but it does not substantiate the claim with detailed analysis or evidence. Without additional justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experimental results, noting that they do not exhibit significant improvement in real-life datasets. It also critiques the comparison on the ZINC dataset, referencing Table 5 in [1] as an example. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve their experimental results. While it points out a potential weakness, it does not provide concrete steps or recommendations for the authors to take, leaving them without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity in its feedback.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that the SLM performs better than larger models due to limited data availability. It provides examples from experiments, such as Figure 3(b) and the comparison between LucaOne and BSM models, to support the argument that larger models generally perform better. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to refute or explain the observed results. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more robust explanation or evidence to support their claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3(b)\" and provides specific examples, such as LucaOne and BSM models, to support its claim. This allows the authors to accurately identify the part of the paper being addressed and understand what needs to be addressed. The comment is specific because it details the issue with the claim that the SLM performs better than larger models due to limited data availability, and it provides evidence from experiments to support the argument that larger models generally perform better. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim that the SLM may not perform better than larger models due to limited data availability, but it is contradicted by experimental results showing that larger models perform better. The reviewer provides specific examples, such as Figure 3(b) and the comparison between LucaOne and BSM models, to support the argument that larger models generally perform better. This provides a clear and detailed justification for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that the SLM performs better than larger models due to limited data availability. It provides specific examples from experiments, such as Figure 3(b) and the comparison between LucaOne and BSM models, to support the argument that larger models generally perform better. This feedback is clear and actionable, as it directs the authors to consider and address the evidence presented in the experiments. However, the comment could be more helpful if it offered suggestions on how to refute or explain the observed results or provided additional context to strengthen the argument. Overall, the comment is mostly helpful as it provides valuable insights for the authors to consider in revising their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out inconsistencies in the notation, specifically mentioning the issue with the notation for nu in Figures 2 & 3, which doesn\\'t match the notation in Algorithm 1. It also notes that the notation changes again on Page 4 & Figure 4. While the comment identifies specific areas of inconsistency, it does not provide explicit guidance on how to resolve these issues. The authors are left to infer that they need to ensure consistency in notation throughout the paper, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it highlights the need for improvement but does not provide detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figures 2 & 3 and Page 4 & Figure 4, allowing the authors to accurately identify the sections being addressed. It also specifies the issue by noting inconsistencies in the notation, particularly with the variable nu. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notation is inconsistent, specifically mentioning the issue with the notation for nu in Figures 2 & 3, which doesn\\'t match the notation in Algorithm 1. It also notes that the notation changes again on Page 4 & Figure 4. While the comment identifies specific areas of inconsistency, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the extent of the inconsistency and the need for correction. Therefore, the comment is somewhat verifiable, as it provides some evidence but requires more detailed justification to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation in the paper, noting inconsistencies in the use of the variable nu across different sections, such as Figures 2 & 3 and Page 4 & Figure 4. This feedback is clear and actionable, as it highlights a potential source of confusion for readers and provides a specific area for the authors to address. By pointing out these inconsistencies, the comment helps the authors improve the clarity and consistency of their notation, which is crucial for a technical paper. However, the comment could be more helpful if it suggested ways to resolve the inconsistencies or provided examples of how to maintain consistency. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct additional experiments in more challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of their proposed method. While the comment implies that more experiments are needed, it does not provide explicit instructions on how to conduct these experiments or what specific aspects should be focused on. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know how to implement this suggestion in detail. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments in challenging tasks, specifically dexterous manipulations in Adroit. However, it does not specify which part of the paper this recommendation pertains to, such as a particular section or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in suggesting additional experiments, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments in more challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. However, the comment does not provide specific reasoning or evidence to support why these additional experiments are necessary or how they would enhance the validation of the proposed method. The suggestion is based on a reference to Adroit, but without further elaboration or justification, it remains vague and difficult for the authors to understand and address. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient detail or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests conducting additional experiments in more challenging tasks, specifically dexterous manipulations in Adroit, to validate the effectiveness of the proposed method. This feedback is somewhat helpful as it identifies a specific area for improvement and provides a clear direction for enhancing the experimental validation of the method. However, the comment could be more helpful if it offered additional guidance on how to design these experiments or what specific aspects of the proposed method should be tested in these challenging tasks. Overall, the comment provides a useful direction for the authors to consider, but it lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the summary in the introduction regarding the assumptions made by various papers. It specifically questions the assumption of linear separability and suggests that it may be an even stronger assumption. The reviewer provides a link to a specific type of data, \"orthogonally separable data,\" which could be relevant to the discussion. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to improve the fairness of the summary. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the assumptions made in the summary. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the summary, questioning the fairness of the assumptions made by various papers, particularly regarding linear separability. The comment further provides a link to a specific type of data, \"orthogonally separable data,\" which could be relevant to the discussion. This level of detail helps the authors understand what needs to be addressed in the introduction. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the fairness of the summary in the introduction regarding the assumptions made by various papers. It questions the assumption of linear separability and suggests that it may be an even stronger assumption. The comment provides a link to a specific type of data, \"orthogonally separable data,\" which could be relevant to the discussion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim about the fairness of the summary. While the link provides a potential direction for further exploration, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the summary in the introduction, specifically regarding the assumptions made by various papers. It questions the assumption of linear separability and suggests that it may be an even stronger assumption. The comment provides a link to a specific type of data, \"orthogonally separable data,\" which could be relevant to the discussion. This feedback is somewhat helpful as it prompts the authors to consider the fairness of their summary and potentially revise it to address the stronger assumptions. However, the comment could be more helpful if it provided specific suggestions or examples on how to improve the fairness of the summary. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliability of the per-sample weight tuning method, specifically regarding the influence function. It highlights that the theoretical approximation of each sample\\'s contribution is not valid when the weights are far from 0 during training iterations. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method\" and the \"influence function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the influence function, explaining that it holds only when the upweight is very close to 0 and that the theoretical approximation of each sample\\'s contribution is not valid when weights are far from 0 during training iterations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the reliability of the per-sample weight tuning method, specifically regarding the influence function. It claims that the theoretical approximation of each sample\\'s contribution is not valid when the weights are far from 0 during training iterations. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. While it highlights a potential issue, the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the per-sample weight tuning method, specifically regarding the influence function. It points out that the theoretical approximation of each sample's contribution is not valid when the weights are far from 0 during training iterations, suggesting that the influence function might not reflect each sample's influence correctly. This feedback is somewhat helpful as it highlights a specific area of concern that could impact the reliability of the results. However, the comment lacks detailed guidance on how the authors might address this issue or improve the method. To be more helpful, the comment could provide suggestions or references to alternative approaches or methods that could be considered. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more comprehensive.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential issue with the per-sample weight tuning method, specifically regarding the influence function. It highlights that the theoretical approximation of each sample's contribution is not valid when the weights are far from 0 during training iterations. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"per-sample weight tuning method\" and the \"influence function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the influence function, explaining that the theoretical approximation of each sample\\'s contribution is not valid when the weights are far from 0 during training iterations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the reliability of the per-sample weight tuning method, specifically regarding the influence function. It claims that the theoretical approximation of each sample\\'s contribution is not valid when the weights are far from 0 during training iterations. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. While it highlights a potential issue, the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the per-sample weight tuning method, specifically regarding the influence function. It points out that the theoretical approximation of each sample's contribution is not valid when the weights are far from 0 during training iterations, suggesting that the influence function might not reflect each sample's influence correctly. This feedback is somewhat helpful as it highlights a specific area of concern that"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with centering in partial shapes and scenes, suggesting that the authors should address this limitation. It also mentions an experiment with up to 50% missing points, which is presented as an augmentation with the ground-truth center provided. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of centering in partial shapes and scenes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of centering in partial shapes and scenes, specifically mentioning that centering may not be well-defined for partial shapes or scenes. It also points out an experiment with up to 50% missing points, suggesting that this is an augmentation with the ground-truth center provided. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with centering in partial shapes and scenes and the need for addressing it, but it lacks explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of centering as a canonicalization method for complete shapes versus partial shapes or scenes. It suggests that centering may not be well-defined for partial shapes or scenes, which is a logical claim. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The mention of an experiment with up to 50% missing points is relevant but does not directly address the issue of centering in partial shapes or scenes. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some context but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with centering in partial shapes and scenes, suggesting that the authors should address this limitation. It points out that centering may not be well-defined for partial shapes or scenes, which is a valid concern. Additionally, the comment notes that the experiment with up to 50% missing points is an augmentation with the ground-truth center provided, which may not be the case in general when training with partial shapes. This feedback is somewhat helpful as it highlights an important consideration for the authors to address, but it could be more helpful if it provided specific suggestions or guidance on how to address this issue. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an action for the authors to take, which is to try ensembling models trained with the proposed negative augmentations and without them to see if it improves performance. This is an explicit suggestion with concrete details on how to implement the action, providing clear guidance on what the authors should do to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, suggesting an action related to the texture semantics and negative samples. It mentions the paper\\'s proposed method of adding negative samples that share texture semantics with the anchor images and suggests trying ensembling models trained with these augmentations and without them. This provides full grounding as it explicitly mentions the proposed method and the action to be taken. The comment is also specific because it clearly outlines what needs to be addressed, namely the potential improvement in performance through ensembling. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an action for the authors to take, which is to try ensembling models trained with the proposed negative augmentations and without them to see if it improves performance. However, the comment does not provide any reasoning or evidence to support why this action might be beneficial or how it could lead to improved performance. Without specific justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method of adding negative samples that share texture semantics with the anchor images, suggesting that this approach may not fully utilize the texture semantics. It provides a specific suggestion for improvement by recommending the authors try ensembling models trained with the proposed negative augmentations and without them to assess the impact on performance. This feedback is clear and actionable, offering a concrete way for the authors to enhance their draft and potentially improve the results. However, the comment could be more helpful if it provided additional context or reasoning about why ensembling might be beneficial. Overall, the comment is mostly helpful as it guides the authors towards a specific improvement that could significantly enhance their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities and points out a discrepancy between the use of buffer series in Appendix B and the current partitioning method. It also references a claim about sample efficiency in Eq. 7 over Eq. 7. While the comment highlights specific areas of concern, it does not provide explicit guidance or suggestions on how the authors should address these issues. The authors are left to infer that they need to ensure the guarantee of D_i and clarify the discrepancy, but the lack of concrete steps or examples makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 6\" and references specific claims about sample efficiency on page 5 and Appendix B. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions the guarantee of D_i going through all possible transition probabilities and points out a discrepancy between the use of buffer series in Appendix B and the current partitioning method. It also references a claim about sample efficiency, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the guarantee of D_i going through all possible transition probabilities and points out a discrepancy between the use of buffer series in Appendix B and the current partitioning method. It also references a claim about sample efficiency in Eq. 7 over Eq. 7. However, the comment does not provide specific evidence, examples, or references to support the claim about sample efficiency or the guarantee of D_i. The lack of detailed reasoning or references makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a specific concern about the guarantee of D_i going through all possible transition probabilities, which is relevant to the sample efficiency of the methods discussed in the paper. It also points out a discrepancy between the use of buffer series in Appendix B and the current partitioning method. By highlighting these issues, the comment provides the authors with valuable feedback on areas that need clarification or further investigation. However, the comment could be more helpful if it offered suggestions or guidance on how to address these concerns or improve the analysis. Overall, the comment is somewhat helpful as it identifies weaknesses but lacks detailed actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the authors form clusters for tokens in Figure 1, indicating that this process is unclear in Section 3. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the process of forming clusters for tokens in Figure 1. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by asking about the process of forming clusters for tokens, which is unclear in Section 3. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the process of forming clusters for tokens in Figure 1, indicating that it is unclear in Section 3. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the process is unclear. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the process of forming clusters for tokens in Figure 1, indicating that it is unclear in Section 3. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing aspect of their work. By addressing this issue, the authors can improve the clarity and understanding of their methodology, which is crucial for readers. However, the comment could be more helpful if it provided suggestions on how to clarify the process or examples of how it could be explained more effectively. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with SimNPO, noting that it introduces two additional hyperparameters that must be manually adjusted for optimal performance. This increases the complexity and time cost of experiments, limiting the method\\'s potential application for large language models in real-world settings. While the comment identifies a problem, it does not provide specific guidance or suggestions on how the authors might address this issue, such as proposing alternative methods or strategies to manage the complexity. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a solution to the complexity issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of SimNPO introducing additional hyperparameters that require manual adjustment for optimal performance, which increases the complexity and time cost of experiments. However, it does not specify which part of the paper discusses these hyperparameters or how they are introduced. The authors can infer that it relates to the methodology or experimental setup sections, but this inference is not explicit. The comment is specific in detailing the issue with the additional hyperparameters and their impact on the method\\'s application, but it lacks grounding as it does not pinpoint the exact section of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that SimNPO introduces two additional hyperparameters that require manual adjustment for optimal performance, which significantly increases the complexity and time cost of experiments. This claim is somewhat verifiable as it provides a logical reasoning for the increased complexity and time cost, but it lacks specific examples or references to support the assertion about the impact on large language models in real-world settings. The authors would need to further explore the implications of these additional hyperparameters to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with SimNPO, noting that it introduces two additional hyperparameters that require manual adjustment for optimal performance. This complexity and time cost increase limit the method's potential application, particularly for large language models in real-world settings. The comment provides a clear and actionable insight into a critical aspect of the method's practicality and scalability. However, it could be more helpful if it offered suggestions on how to address this issue, such as proposing alternative methods or strategies to manage the complexity. Overall, the comment is mostly helpful as it highlights a significant limitation and provides a direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the work places too much emphasis on affordance prompting, which is overengineered, and provides a specific example of the Pick&place example not demonstrating the advantage of affordance prompting. While the comment identifies a potential issue, it does not explicitly instruct the authors on how to address it or suggest specific changes. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider the emphasis on affordance prompting and its implementation, but the comment lacks concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of overemphasis on affordance prompting and provides a specific example, the Pick&place example, to illustrate this point. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the overengineering of affordance prompting and the lack of demonstration of its advantage in the Pick&place example. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work places too much emphasis on affordance prompting, which is overengineered, and provides a specific example of the Pick&place example not demonstrating the advantage of affordance prompting. However, the comment lacks detailed reasoning or evidence to support the claim that affordance prompting is overengineered or that the Pick&place example does not demonstrate its advantage. Without specific examples or references, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the work places too much emphasis on affordance prompting, which is overengineered. It provides a concrete example, the Pick&place example, to illustrate this point, highlighting that it does not effectively demonstrate the advantage of affordance prompting. This feedback is clear and actionable, as it directs the authors to reconsider the emphasis on affordance prompting and its implementation in the paper. However, the comment could be more helpful if it suggested ways to address the issue or provided additional guidance on how to improve the presentation of affordance prompting. Overall, the comment is mostly helpful, as it provides valuable insights for the authors to consider in revising their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. While the comment implies that such studies should be conducted, it does not provide explicit instructions on how to perform these studies or which specific parts of the pipeline should be tested. The action is implicit and somewhat vague, as the authors can infer the need for ablation studies but may not know how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, it does not specify which parts of the pipeline are being discussed or where these studies should be conducted within the paper. This lack of specificity makes it difficult for the authors to identify the exact sections that need attention. While the comment implies that the methodology section might be relevant, it does not provide explicit guidance on which parts to focus on. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. However, the comment does not provide specific examples or references to support why these studies are necessary or how they would be conducted. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that ablation studies are needed to demonstrate the necessity of each part of the proposed algorithmic pipeline. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper, specifically the need for more detailed analysis to validate the importance of each component. However, the comment lacks specificity and does not provide guidance on how to conduct these studies or which parts of the pipeline should be tested. To be more helpful, the comment could include suggestions on how to structure the ablation studies or what specific aspects should be examined. Therefore, the comment is rated as somewhat helpful, as it points out a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to this extra cost. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to strengthen their conclusion. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of the additional training cost on performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage, which is a specific part of the paper. It raises a concern about the potential impact of additional training and tuning costs introduced by this stage, questioning whether the performance improvement could be attributed to these costs. This provides some level of grounding as it refers to a specific part of the paper, but it lacks specificity in detailing how the authors should address this concern or what specific aspects need to be considered. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to this extra cost. While the comment provides a logical reasoning by pointing out the potential impact of additional costs, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a basis for questioning the conclusion but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the conclusion regarding the necessity of the instruction-tuning stage in MoE models. It questions whether the performance improvement could be attributed to the additional training and tuning costs introduced by this stage, suggesting that the authors should consider this possibility. This feedback is constructive as it prompts the authors to critically evaluate their conclusion and consider alternative explanations for the observed performance improvements. However, the comment could be more helpful if it provided specific suggestions on how to address this concern or additional analyses that could be conducted to strengthen the conclusion. Overall, the comment is mostly helpful as it directs the authors' attention to a potential weakness in their argument, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to this extra cost. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to strengthen their conclusion. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of the additional training cost on performance. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the conclusion about the necessity of the instruction-tuning stage, which is a specific part of the paper. It raises a concern about the potential impact of additional training and tuning costs introduced by this stage, questioning whether the performance improvement could be attributed to these costs. This provides some level of grounding as it refers to a specific part of the paper, but it lacks specificity in detailing how the authors should address this concern or what specific aspects need to be considered. The comment suggests a potential issue but does not offer actionable guidance on how to resolve it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the conclusion regarding the necessity of the instruction-tuning stage, suggesting that the addition of this stage may introduce additional training and tuning costs. It questions whether the performance improvement could also be attributed to this extra cost. While the comment provides a logical reasoning by pointing out the potential impact of additional costs, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as it provides a basis for questioning the conclusion but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the conclusion regarding the necessity of the instruction-tuning stage in the paper. It questions whether the performance improvement could be attributed to the additional"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the evaluation setup is outdated and suggests that the authors update it to reflect the current state of the field. It provides specific examples of models that have advanced since the evaluation setup was created (Llama-1 and Mistral-v0.1) and recommends testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST. This feedback is clear and provides concrete guidance on how the authors can improve their evaluation setup. The suggestion to test on a more challenging setup is also specific, giving the authors a clear direction for enhancing the robustness of their results. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Evaluation setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the evaluation setup is outdated and suggests testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation setup is outdated and suggests that the authors update it to reflect the current state of the field. It provides specific examples of models that have advanced since the evaluation setup was created (Llama-1 and Mistral-v0.1) and recommends testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST. This provides a clear rationale for the claim, as it references specific models and suggests a more challenging setup for testing. However, the comment could be strengthened by providing additional references or examples to further substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a strong basis for the claim but lacks full detail.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation setup, noting that it is outdated and does not reflect the current state of the field. It provides specific examples of models that have advanced since the evaluation setup was created, such as Llama-1 and Mistral-v0.1, and suggests that the authors update their evaluation to include more recent models like Llama-3, Llama-3.1, Qwen-2.5, and gemma-2. Additionally, the comment recommends testing the approach on a more challenging and representative fine-tuning setup, such as instruction tuning on Alpaca/OASST or other instruction fine-tuning datasets. This feedback is clear and actionable, offering the authors a concrete path to improve the robustness and relevance of their evaluation. The suggestion to test on a more challenging setup provides a specific direction for enhancing the paper\\'s impact and credibility. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of logical coherence in the second section, noting that many related works are presented but the content remains somewhat disorganized. While the comment identifies a specific issue, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they need to improve the logical structure of the section, but the comment lacks concrete suggestions or examples of how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"second section,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of logical coherence and the resulting disorganized content. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the second section lacks logical coherence due to the presentation of many related works, resulting in disorganized content. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the second section of the paper, noting that while many related works are presented, the content lacks logical coherence, resulting in a disorganized structure. This feedback is somewhat helpful as it highlights a critical area for improvement, but it lacks depth and specificity. The authors are aware of the issue but may need additional guidance on how to address it, such as suggestions on how to organize the related works or improve the logical flow. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for improvement but requires further elaboration.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention the language they focus on when retrieving Reddit posts. This is a clear and direct action that the authors can take to address the comment. The request is specific and provides a concrete step for improvement, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"language,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is mentioning the language used to retrieve Reddit posts. This provides clear guidance on what the authors need to include in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to specify the language they use to retrieve Reddit posts. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, providing a specific request for the authors to mention the language they use to retrieve Reddit posts. This feedback is valuable as it directs the authors to a specific aspect of their methodology that needs clarification, which can help improve the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested how mentioning the language could enhance the paper or provided examples of how other studies have addressed this issue. Despite this, the comment is mostly helpful as it offers a clear direction for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper lacks comparisons with recent works, specifically mentioning [1] as an example. This provides a clear and direct action for the authors to take, which is to include comparisons with the referenced work. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of comparisons with recent works, specifically mentioning [1] as an example. This provides full grounding as it explicitly references a specific work, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the paper, namely comparisons with recent works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons with recent works, specifically mentioning [1] as an example. However, the comment does not provide any reasoning, evidence, or context to support why these comparisons are necessary or how they would enhance the paper. Without additional explanation or references, the claim remains unverifiable, as it lacks the necessary justification for the authors to understand the significance of the claim or how to address it. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of comparisons with recent works, specifically mentioning [1] as an example. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their draft by including relevant comparisons. However, the comment could be more helpful if it offered suggestions on how to incorporate these comparisons or what specific aspects of the recent works should be highlighted. Despite this, the comment is mostly helpful as it directs the authors to a critical area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should investigate this issue, explore alternative models, or provide a response to the question. Without any actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the applicability of TSG in a particular context, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is relevant or important. The comment lacks depth and does not offer any context or explanation for the authors to understand the significance of this inquiry. As a result, the claim is unverifiable, as it does not provide sufficient information for the authors to address the question effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timestep, such as UViT. While the comment identifies a potential area for exploration or clarification, it does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of TSG might be affected by this absence of class labels. Without actionable feedback or detailed suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but lacks depth and specificity.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to release their training code, dialogue dataset, and model checkpoints to enhance reproducibility. It provides a clear and concrete action for the authors to take, which is to attach their code and datasets via anonymous repositories in the paper submission. This guidance is specific and actionable, allowing the authors to understand exactly what steps they need to take to improve the reproducibility of their work. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of limited reproducibility, specifically mentioning the need for the authors to release their training code, dialogue dataset, and model checkpoints. This provides full grounding as it explicitly mentions the parts of the paper that need to be addressed. The comment is also specific because it clearly outlines what needs to be done to enhance reproducibility, such as attaching the code and datasets via anonymous repositories. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks reproducibility due to the absence of training code, dialogue dataset, and model checkpoints. The reviewer suggests attaching these resources via anonymous repositories to enable verification and replication of the claims. While the comment highlights a critical issue, it lacks specific examples or references to support the claim of limited reproducibility. The suggestion to attach resources is a logical step to address the issue, but the comment could be strengthened with more detailed reasoning or evidence. Therefore, the comment is somewhat verifiable, as it provides a clear direction but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's reproducibility, specifically noting that the authors need to release their training code, dialogue dataset, and model checkpoints to enable reviewers to reproduce the claims and verify the results. This feedback is clear and actionable, providing a direct suggestion for enhancing the paper's transparency and verifiability. By encouraging the authors to attach these resources, the comment offers a concrete step that could significantly improve the paper's impact and credibility. However, the comment could be more helpful if it included specific examples of how the lack of reproducibility might affect the paper's conclusions or if it suggested additional steps beyond attaching resources. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear path forward.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the main result is somewhat obvious because gradient boosting minimizes objectives in functional space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their results. Without any actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity as it does not provide details on what aspects of the result are considered obvious or how the authors might address this concern. Without clear grounding and specificity, the authors cannot effectively respond to the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the main result is obvious because gradient boosting minimizes objectives in functional space. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to explain why this conclusion is obvious or how it relates to the paper\\'s findings. Without detailed justification or references, the claim remains unverifiable, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the main result is obvious because gradient boosting minimizes objectives in functional space. While it identifies a potential issue with the originality of the result, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer any guidance on how the authors might address this concern or enhance the originality of their work. As a result, the comment is not helpful, as it does not provide the authors with a clear path to improve their draft. Therefore, it aligns with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the contribution of the work is insufficient and lacks explicit expression in the paper. It also mentions that the work appears incomplete due to limited related work and inadequate analysis. While the comment identifies areas for improvement, it does not provide specific guidance or suggestions on how the authors might address these issues. The lack of actionable details or concrete steps makes it difficult for the authors to know exactly what changes to make to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the contribution of the work, suggesting that it is insufficient and not explicitly expressed in the paper. It also mentions that the work appears incomplete due to limited related work and inadequate analysis. However, the comment does not specify which part of the paper lacks explicit expression of the contribution or where the related work is mentioned. This makes it difficult for the authors to pinpoint the exact sections that need improvement. The comment is weakly grounded because it does not provide specific guidance on where to focus the improvements, and it is not specific in detailing what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the contribution of the work is insufficient and not explicitly expressed in the paper, suggesting that the work appears incomplete. However, the comment lacks specific examples or detailed reasoning to support these claims. It mentions limited related work and inadequate analysis but does not provide concrete evidence or references to substantiate these points. Without additional context or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's contribution, stating that it is insufficient and not explicitly expressed. It also notes that the work appears incomplete due to limited related work and inadequate analysis. This feedback is valuable as it highlights a critical area for improvement, providing the authors with a clear direction to enhance the clarity and depth of their contribution. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address these issues, such as recommending additional related work or analysis. Overall, the comment is mostly helpful as it points out a significant weakness but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies two issues with the results presentation in Figure 2a and Figure 2b. It points out that the x-axis label 'item' in Figure 2b is unclear and suggests that the training steps might refer to outer-loop iterations or raw experience. Additionally, it recommends that Figure 2a should also be presented with iterations or training steps as the x-axis. These suggestions are explicit and provide clear guidance on how the authors can improve their figures by clarifying the x-axis labels and ensuring consistency in the presentation of results. The feedback is concrete and actionable, allowing the authors to make direct changes to their draft. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the clarity of the x-axis labels in Figure 2b and suggesting that Figure 2a should be presented with iterations or training steps as the x-axis. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the x-axis labels in Figure 2b and suggests that Figure 2a should also be presented with iterations or training steps as the x-axis. While the comment identifies a potential issue with the labeling, it does not provide specific examples or detailed reasoning to support why this is problematic or how it affects the interpretation of the results. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the significance of the issue based on the comment alone. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the presentation of results in Figures 2a and 2b. It points out that the x-axis label 'item' in Figure 2b is unclear and suggests that the training steps might refer to outer-loop iterations or raw experience. Additionally, it recommends that Figure 2a should also be presented with iterations or training steps as the x-axis. This feedback is clear and actionable, as it provides specific guidance on how to improve the clarity and consistency of the figures. By addressing these issues, the authors can enhance the readability and interpretability of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind using different metrics (flops, latency, and 1/FPS) for different devices instead of a uniform cost. While it implies that the authors should consider using a consistent metric, it does not explicitly instruct them to do so or provide guidance on which metric would be more appropriate. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of a uniform metric and determine which one would be most suitable. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of metrics used to evaluate different devices, specifically why different metrics like flops, latency, and 1/FPS are used instead of a uniform cost. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where these metrics are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its question about the choice of metrics, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of different metrics (flops, latency, and 1/FPS) for evaluating different devices instead of a uniform cost. However, the comment does not provide any reasoning, examples, or references to support why a uniform cost might be more appropriate or beneficial. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of metrics used to evaluate different devices, specifically why different metrics like flops, latency, and 1/FPS are used instead of a uniform cost. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what alternative metrics could be considered. Without actionable feedback or detailed reasoning, the comment does not offer the authors a clear path to improve their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the maximum iterations used in the experiments and questions whether these iterations might significantly slow down the training speed. However, it does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending a specific number of iterations or suggesting alternative methods to improve efficiency. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly optimize the number of iterations. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of the two-dimensional Wasserstein distance and the application of the Sinkhorn algorithm to obtain an approximate solution. It raises a question about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in detailing the issue with the maximum iterations and their potential impact on training speed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of the two-dimensional Wasserstein distance, which does not have a closed-form solution, and the application of the Sinkhorn algorithm to approximate it. The reviewer questions the maximum number of iterations used in the experiments and whether these iterations might significantly slow down the training speed. While the comment highlights a potential issue, it lacks specific details or examples to fully substantiate the claim. The authors are left to infer the relevance and severity of the concern, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the use of the two-dimensional Wasserstein distance, which does not have a closed-form solution, and the application of the Sinkhorn algorithm to approximate it. It questions the maximum number of iterations used in the experiments and whether these iterations might significantly slow down the training speed. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or optimize their approach. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the maximum number of iterations used in the experiments and questions whether these iterations might significantly slow down the training speed. However, it does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending a specific number of iterations or suggesting alternative methods to improve efficiency. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and possibly optimize the number of iterations. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the use of the two-dimensional Wasserstein distance and the application of the Sinkhorn algorithm to obtain an approximate solution. It raises a question about the maximum iterations used in the experiments and whether these iterations might significantly slow down the training speed. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in detailing the issue with the maximum iterations and their potential impact on training speed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of the two-dimensional Wasserstein distance, which does not have a closed-form solution, and the application of the Sinkhorn algorithm to approximate it. It questions the maximum number of iterations used in the experiments and whether these iterations might significantly slow down the training speed. However, the comment lacks specific details or examples to fully substantiate the claim. The authors are left to infer the relevance and severity of the concern, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the use of the two-dimensional Wasserstein distance, which does not have a closed-form solution, and the application of the Sinkhorn algorithm to approximate it. It questions the maximum number of iterations used in the experiments and whether these iterations might significantly slow down the training speed. While the comment identifies a potential"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a major weakness in the paper\\'s soundness, specifically regarding the teacher policy\\'s ability to perform correct distribution matching. It suggests that the authors should provide theoretical results to support their approach. While the comment implies that the current method is more like a heuristic, it does not explicitly instruct the authors to include theoretical results or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should include theoretical results to strengthen their approach. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the paper\\'s soundness, particularly regarding the teacher policy\\'s ability to perform correct distribution matching. It suggests that the authors should provide theoretical results to support their approach, which is a clear and specific request. The comment is fully grounded as it explicitly mentions the soundness of the paper and the need for theoretical results, allowing the authors to accurately identify the part of the paper being addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s soundness is a major weakness, specifically questioning the teacher policy\\'s ability to perform correct distribution matching. The reviewer suggests that theoretical results should be provided to support the approach. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim. The suggestion for theoretical results is a logical response to the concern, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the paper's soundness, specifically questioning the teacher policy's ability to perform correct distribution matching. It suggests that the authors should provide theoretical results to support their approach, which is a constructive and actionable feedback. However, the comment could be more helpful if it offered specific guidance on how to develop these theoretical results or examples of what kind of results would be beneficial. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should analyze and discuss the reasons why the proposed method does not perform well in some classes, as indicated in Table 3. While the comment implies that an analysis and discussion are needed, it does not provide specific guidance on what aspects of the method or results should be examined or how to conduct the analysis. The action is implicit and somewhat vague, as the authors need to infer the details of the analysis and discussion required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the performance of the proposed method in some classes and the need for analysis and discussion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed method does not perform well in some classes and recommends analyzing and discussing the reasons for this. However, the comment does not provide any specific examples, data, or reasoning to support why the method performs poorly or what aspects of the method might be contributing to this issue. Without detailed evidence or analysis, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of the proposed method in certain classes, as indicated in Table 3. It suggests that the authors should analyze and discuss the reasons behind this performance, which is a valuable piece of feedback. However, the comment lacks depth and does not provide specific guidance on how to conduct the analysis or what aspects of the method should be examined. While it highlights an important area for improvement, the feedback could be more actionable and comprehensive. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some experimental settings are not rigorously designed, specifically mentioning the need for MTT to test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer the need for more rigorous experimental design and detailed discussion of results, but they may not know exactly how to implement these suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of experimental settings being not rigorously designed, specifically mentioning the need for MTT to test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental design and results sections. The authors can infer that it relates to these sections, but the comment does not provide exact references. The suggestion to discuss the variation of model behavior is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experimental settings are not rigorously designed, specifically mentioning the need for MTT to test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to test on unseen tasks is a logical step to ensure robustness, but without further elaboration, the comment remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experimental design, noting that some settings are not rigorously tested, particularly the need for MTT to test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, specifically regarding the variation of model behavior under different datasets or settings. This feedback is clear and actionable, as it provides specific areas for improvement in the experimental design and analysis. However, the comment could be more helpful if it offered suggestions on how to implement these improvements or provided examples of how to discuss the variation of model behavior. Overall, the comment is mostly helpful as it directs the authors to enhance the rigor of their experimental design and analysis, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the randomization of data collection for the 5 layouts, suggesting that the data was collected in the same order, which could introduce learning effects. While the comment points out a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should investigate the randomization of data collection and possibly adjust their methodology to mitigate learning effects. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the data collection process for the 5 layouts, specifically asking if it was randomized. However, it does not specify which part of the paper this question pertains to, such as a methodology section or results section. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its inquiry about the randomization of data collection, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the randomization of data collection for the 5 layouts, suggesting that the data was collected in the same order, which could introduce learning effects. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the randomization of data collection for the 5 layouts, suggesting that the data was collected in the same order, which could introduce learning effects across different layouts. This feedback is valuable as it points out a potential issue that could affect the validity of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern, such as recommending a randomized data collection process or suggesting ways to mitigate learning effects. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it prompts the authors to consider an important aspect of their methodology but does not fully guide them in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should clarify, remove, or modify this aspect of their work. Without any actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"In order to cover the random ordering of the atoms in a specific point in the composition space,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of node ordering in this context, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the relevance of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. However, it does not provide any supporting evidence, reasoning, or references to justify why node ordering should not be relevant. Without additional context or explanation, the claim remains unverifiable, as the authors may not understand the basis of the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relevance of node ordering in the context of covering random ordering of atoms in a specific point in the composition space. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the novelty of the work due to the presence of a similar benchmark in previous work. It provides links to relevant references, including [5] which presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not offer any explicit guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The feedback is vague and lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions a previous work [5] that presents a dexterous manipulation benchmark with musculoskeletal hands, suggesting that this work detracts from the novelty of the current submission. However, it does not specify which part of the paper this critique pertains to, such as the introduction or discussion sections, making it weakly grounded. The comment is specific in identifying the potential issue with novelty but lacks grounding, as it does not provide explicit references to sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the previous work [5] presents a dexterous manipulation benchmark with musculoskeletal hands, which detracts from the novelty of the current work. However, the comment does not provide specific details or examples of how the previous work is similar or how it affects the novelty of the current submission. The references provided are not detailed enough to substantiate the claim, leaving the authors without a clear understanding of how to address the issue. As a result, the claim is barely verifiable, as it lacks sufficient evidence or explanation to support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the work due to the presence of a similar benchmark in previous work. It provides links to relevant references, including [5], which presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. While it highlights a potential weakness, it does not offer actionable advice or constructive feedback that could help the authors improve their draft. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not provide detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the selection of datasets is a main contribution and should be made clearer. It provides specific examples of works, such as OpenML100 and OpenML CC-18, which could be used as references. Additionally, it highlights the need for more detail on the selection of the splitting procedure and split ratios. While the comment implies that the authors should provide more information on these aspects, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors know what information to include to address the feedback. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection of datasets as a main contribution, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as clarifying the selection process, providing examples of works like OpenML100 and OpenML CC-18, and detailing the selection of the splitting procedure and split ratios. This provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the selection of datasets is a main contribution and should be made clearer. It provides examples of works, such as OpenML100 and OpenML CC-18, which could be used as references. Additionally, it suggests that the selection of the splitting procedure and split ratios is ad-hoc and lacks detail. The comment is mostly verifiable as it provides specific examples and references to support the claim, but it could be strengthened by including more detailed reasoning or evidence about why these aspects are crucial for the main contribution. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a critical area for improvement in the paper, specifically the selection of datasets, which is claimed to be a main contribution. It provides a clear and actionable suggestion by recommending that the selection process be made more explicit, including details on the pool of datasets and the criteria used for selection. The comment also offers examples of works, such as OpenML100 and OpenML CC-18, which could be used as references for clarity. Additionally, it highlights the need for more detail on the selection of the splitting procedure and split ratios, which is another area that could benefit from further explanation. This feedback is detailed and provides specific guidance on how the authors can enhance the clarity and robustness of their contribution, making it highly helpful for improving the draft. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the ablation study lacks a critical comparison, specifically mentioning the need for a baseline where an unconditional diffusion model is first refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. This feedback is clear and direct, providing a specific action for the authors to take: to include this comparison in their study. The comment also suggests that comparing to a model initiated with random parameters is not a relevant benchmark, further guiding the authors on what to avoid. This level of detail and specificity makes the comment highly actionable, as it gives the authors a clear path to improve their draft by addressing the identified gap in their study.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the ablation study, which lacks a critical comparison. The comment suggests including a baseline where an unconditional diffusion model is refined using the suggested architectural changes, followed by either consistency or progressive distillation. This provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ablation study lacks a critical comparison, specifically mentioning the need for a baseline where an unconditional diffusion model is first refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. The reviewer suggests that this comparison would be valuable to determine if the proposed method outperforms conventional baselines under the same computational constraints. The comment provides a logical reasoning for the claim, as it highlights the importance of a relevant comparison to assess the effectiveness of the proposed method. However, it could be strengthened by providing specific examples or references to support the claim further. Overall, the comment is mostly verifiable, as it offers a clear rationale for the claim but could benefit from additional supporting evidence.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the ablation study, specifically the lack of a critical comparison. It suggests that the study should include a baseline where an unconditional diffusion model is first refined using the suggested architectural changes, followed by either consistency distillation or progressive distillation. This comparison would help determine if the proposed method outperforms conventional baselines under the same computational constraints. The comment also points out that comparing to a model initiated with random parameters is not a relevant benchmark, providing clear and actionable feedback for the authors to improve their study. This level of detail and specificity makes the comment highly helpful, as it guides the authors on how to enhance the robustness and validity of their results. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects for inspiration to design more diverse tasks. However, it does not provide specific guidance on which tasks to refer to or how to incorporate these tasks into the paper. The action is implicit and somewhat vague, as the authors need to infer which tasks to refer to and how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects for inspiration to design more diverse tasks. However, it does not specify which tasks are being discussed or which parts of the paper these tasks are presented in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to refer to other projects, but it lacks grounding as it does not specify the tasks or sections in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects for inspiration to design more diverse tasks. However, the comment does not provide specific examples or references to these projects, making it difficult for the authors to understand the basis of the claim. Without detailed examples or references, the authors may find it challenging to implement the suggested changes effectively. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient evidence or examples to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the tasks in the paper are too homogeneous in terms of difficulty and recommends referring to other projects for inspiration to design more diverse tasks. While the comment identifies a potential issue with the homogeneity of tasks, it lacks specificity and does not provide examples or references to the suggested projects. This limits the usefulness of the feedback, as the authors may find it challenging to implement the suggestion without additional guidance. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer detailed or actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the comparison in Table 2 is unfair due to the difference in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. It suggests that the settings are aligned with lines 349-360 and references a specific work, LUMOS, for further information. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the comparison to ensure fairness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to the difference in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. The comment references a specific work, LUMOS, which provides additional context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison in Table 2 is unfair due to the difference in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. It references a specific work, LUMOS, which provides additional context. However, the comment lacks detailed reasoning or specific examples to substantiate the claim that the training data size is larger for LEPA. While the reference to LUMOS adds credibility, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the fairness of the comparison in Table 2, specifically noting that the training data size for LEPA may be larger than the 'Without Plan/Without Self-Reflection' settings. It references a specific work, LUMOS, which provides additional context. However, the comment lacks detailed guidance on how the authors should address this issue or what specific steps they should take to ensure fairness in the comparison. While it highlights an important aspect to consider, the feedback could be more helpful with additional suggestions or examples. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully guide the authors in improving their draft.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the comparison in Table 2 is unfair due to the difference in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. It suggests that the settings are aligned with lines 349-360 and references a specific work, LUMOS, for further information. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to the comparison. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the comparison to ensure fairness. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to the difference in training data size between the LEPA and \"Without Plan/Without Self-Reflection\" settings. The comment references a specific work, LUMOS, which provides additional context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the comparison in Table 2 is unfair due to the difference in training data size between the LEPA and 'Without Plan/Without Self-Reflection' settings. It references a specific work, LUMOS, which provides additional context. However, the comment lacks detailed reasoning or specific examples to substantiate the claim that the training data size is larger for LEPA. While the reference to LUMOS adds credibility, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the fairness of the comparison in Table 2, specifically noting that the training data size for LEPA may be larger than the 'Without Plan/Without Self-Reflection' settings. It references a specific work, LUMOS, which provides additional context. However, the comment lacks detailed guidance on how the authors should address this issue or what specific steps they should take to"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly suggests that the authors should experiment with real datasets, specifically mentioning the GLUE benchmark and real-world diversity datasets. It provides a clear and concrete action for the authors to take, which is to include results from these datasets. The comment also questions why the authors have only used synthetic datasets, implying that real datasets should be considered. This feedback is explicit and provides detailed guidance on how the authors can improve their draft by expanding their experimental setup. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the use of synthetic datasets and suggests the use of real datasets from the GLUE benchmark and real-world diversity datasets. This provides clear guidance on what part of the paper needs to be addressed and what specific changes are recommended. The comment is specific because it identifies the lack of results with real datasets and suggests specific benchmarks to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the authors' decision to use only synthetic datasets and suggests that they should consider using real datasets from the GLUE benchmark and real-world diversity datasets. The comment provides a logical reasoning by suggesting that using real datasets would be more relevant and practical for evaluating the model's performance. However, it lacks specific examples or references to support the claim that real datasets would be more appropriate. The suggestion is based on common knowledge in the field, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's experimental setup by noting that the authors have only used synthetic datasets and have not shown results with real datasets. It suggests that the authors should consider using datasets from the GLUE benchmark, which includes tasks like QQP, and real-world diversity datasets. This feedback is clear and actionable, as it provides specific examples of datasets that could be used to enhance the paper's experimental validation. By addressing this suggestion, the authors can strengthen their work by demonstrating the practical applicability of their model. However, the comment could be more helpful if it included additional guidance on how to integrate these datasets or what specific results to expect. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear direction for enhancing their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific area for enhancement, making it highly actionable. The authors know exactly what needs to be done and how to implement the suggested change, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding details on how to solve the optimization in the main paper, which is a specific area of the paper. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to add details on solving the optimization, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for this addition. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should add details on how to solve the optimization in the main paper, indicating that this information is currently lacking. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it could be addressed. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should add details on how to solve the optimization in the main paper. This is a clear and actionable suggestion that can help the authors enhance the clarity and completeness of their draft. By providing a specific area for improvement, the comment offers valuable guidance that can lead to a more comprehensive and understandable paper. However, the comment could be more helpful if it included additional context or examples to further explain the importance of this information. Overall, the feedback is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly questions the exclusion of LLaVA-series and Qwen-VL from the evaluation, suggesting that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and direct, as it specifies what needs to be added to the evaluation to enhance its comprehensiveness. The authors are given a concrete action to take, which is to include these models in their comparison, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the evaluation section or the discussion of models. The authors can infer that it relates to the comparison section, but the comment does not specify the exact part of the paper being addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. The comment is based on a logical argument that these models are commonly adopted and would enhance the evaluation. However, it lacks specific references or examples to support the claim that these models are commonly adopted or how their inclusion would improve the comparison. This makes the claim somewhat verifiable, as it provides a logical basis but requires additional evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a pertinent question about the exclusion of specific models, LLaVA-series and Qwen-VL, from the evaluation. It suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is clear and actionable, as it identifies a gap in the evaluation that could be addressed to enhance the paper\\'s comprehensiveness and relevance. By pointing out the omission of these models, the comment offers a specific direction for improvement, making it mostly helpful. However, it could be more helpful if it provided additional context or suggestions on how to integrate these models into the evaluation. Overall, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include captions or descriptions along with OCR heavy datasets. While it implies that these additions are necessary, it does not provide explicit instructions on how to incorporate them or what specific datasets should be included. The action is somewhat vague, as the authors need to infer that they should add captions or descriptions to their work, but the comment does not specify how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include captions or descriptions along with OCR heavy datasets, which implies that it is addressing a specific aspect of the paper related to data presentation or dataset usage. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or table. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting the inclusion of captions or descriptions for OCR datasets, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include captions or descriptions along with OCR heavy datasets. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without specific justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include captions or descriptions along with OCR heavy datasets. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on why these additions are necessary or how they would enhance the paper. The comment does not offer examples of how captions or descriptions could be used effectively or what specific datasets should be included. As a result, the feedback is somewhat helpful, as it points out a potential enhancement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between Assumption 3.1, which states that the loss of TKD is assumed less than IYOR, and Equation 7, which contradicts this assumption. However, the comment does not provide any explicit or implicit actions for the authors to take. It simply points out the inconsistency without suggesting how the authors should address it. As a result, the authors are left without guidance on what steps to take to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"eqn.7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the assumption and the equation, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption that the loss of TKD is less than IYOR is contradicted by the equation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption that the loss of TKD is less than IYOR is contradicted by the equation. This feedback is somewhat helpful as it points out a potential inconsistency that the authors should address. However, the comment lacks depth and does not provide specific guidance on how to resolve the discrepancy or what implications it might have for the paper. To be more helpful, the comment could include suggestions for how to reconcile the assumption with the equation or what steps the authors should take to address this issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of question 3, which is mentioned as a weakness. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should take to clarify the question. Without specific instructions or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the clarity of question 3, which is mentioned as a weakness. However, it does not explicitly mention which part of the paper this question is related to, making it weakly grounded. The comment is specific in questioning the clarity of the question, but it lacks detailed guidance on how to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of question 3, which is mentioned as a weakness. However, it does not provide any specific reasoning, examples, or references to support why this question is unclear or how it relates to the other weaknesses. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of question 3, which is mentioned as a weakness. However, it does not provide any specific guidance or suggestions on how the authors might clarify this question or address the identified weaknesses. Without actionable feedback or detailed explanations, the comment lacks the depth and specificity needed to be helpful. The authors are left without a clear understanding of what needs to be improved or how to enhance their draft. Therefore, the comment is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, suggesting that other works have found middle layers to be more effective. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or what alternative approaches they might consider. The action is implicit and vague, as the authors are left to infer that they should explore the use of middle layers or provide a rationale for their choice. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the choice of using the last-layer hidden states for the classifier, referencing the finding that middle layers are more effective in other works. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the effectiveness of the last-layer hidden states, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of using the last-layer hidden states for the classifier, referencing the finding that middle layers are more effective in other works. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the choice of using the last-layer hidden states for the classifier, referencing the finding that middle layers are more effective in other works. This feedback is somewhat helpful as it prompts the authors to consider alternative approaches or justify their choice. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this concern or what alternative methods might be more effective. To be more helpful, the comment could include references to the works mentioned or provide a rationale for why the last-layer choice is appropriate. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the choice of using the last-layer hidden states for the classifier, referencing the finding that middle layers are more effective in other works. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or what alternative approaches they might consider. The action is implicit and lacks specificity, leaving the authors to infer that they should explore the use of middle layers or provide a rationale for their choice. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the choice of using the last-layer hidden states for the classifier, referencing the finding that middle layers are more effective in other works. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the effectiveness of the last-layer hidden states, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the choice of using the last-layer hidden states for the classifier, referencing the finding that middle layers are more effective in other works. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient support.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a question about the choice of using the last-layer hidden states for the classifier, referencing the finding that middle layers are more effective in other works. This feedback prompts the authors to consider alternative approaches or justify their choice, which is a valuable point for improvement. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this concern or what alternative methods might be more effective. To be more helpful, the comment could include references to the works mentioned or provide a rationale for why the last-layer choice is appropriate. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the motivation behind the use cases and the arbitrary nature of using GUE to determine modeling decisions. It suggests that the representations learned may have limited generalizability. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the motivation. The feedback lacks actionable steps or concrete suggestions, leaving the authors uncertain about how to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the motivation behind the use cases and the arbitrary nature of using GUE to determine modeling decisions. It suggests that the representations learned may have limited generalizability. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in detailing the issue with the motivation and generalizability, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the motivation for using GUE is poorly justified and that the use of GUE to determine modeling decisions is arbitrary and potentially incongruous. The reviewer provides a logical reasoning by suggesting that the representations learned using these modeling decisions may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues from the general reasoning provided, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two main issues: the lack of motivation for the use cases and the arbitrary nature of using GUE to determine modeling decisions. It points out that the representations learned may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment lacks specific suggestions or actionable steps for the authors to address these issues. While it highlights important areas for improvement, the feedback could be more helpful if it provided concrete guidance or examples on how to enhance the motivation or address the limitations of GUE. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and actionable advice.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the motivation behind the use cases and the arbitrary nature of using GUE to determine modeling decisions. It suggests that the representations learned may have limited generalizability. However, the comment does not provide explicit guidance on how the authors should address these issues or improve the motivation. The feedback lacks actionable steps or concrete suggestions, leaving the authors uncertain about how to enhance their draft. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the motivation behind the use cases and the arbitrary nature of using GUE to determine modeling decisions. It suggests that the representations learned may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in detailing the issue with motivation and generalizability, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point critiques the motivation behind the use cases and the arbitrary nature of using GUE to determine modeling decisions. It suggests that the representations learned may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues from the general reasoning provided, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two main issues: the lack of motivation for the use cases and the arbitrary nature of using GUE to determine modeling decisions. It points out that the representations learned may have limited generalizability due to the narrow set of tasks presented in GUE. However, the comment lacks specific suggestions or actionable steps for the authors to address these issues. While it highlights important areas for improvement"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper reads clunkily due to significant grammar and spelling errors and needs a major editing pass. This provides a clear and direct action for the authors to take, which is to address the grammar and spelling issues and perform a thorough editing process. The feedback is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of grammar and spelling errors in the paper, stating that it reads clunkily due to these errors. However, it does not specify which sections or parts of the paper contain these errors, making it weakly grounded. The comment is specific in identifying the issue of grammar and spelling errors, but without grounding, the authors may struggle to pinpoint where these errors occur. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper reads clunkily due to significant grammar and spelling errors, requiring a major editing pass. However, the comment does not provide specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issues effectively. Without explicit examples or references to specific errors, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it reads clunkily due to grammar and spelling errors. It provides a clear and actionable suggestion for the authors to address these issues, which is essential for improving the clarity and professionalism of the paper. However, the comment lacks specific guidance on how to correct the errors or what areas to focus on, which could make it more helpful. Overall, the feedback is somewhat helpful as it highlights a critical issue but could be more comprehensive with additional details or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. While the comment identifies specific areas for clarification and potential issues, it does not provide explicit actions or suggestions for how the authors should address these concerns. The authors are left to infer that they need to clarify these points, but the lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. While the comment does not explicitly mention specific sections, it is clear that it pertains to the methodology and theoretical aspects of the paper. The authors can infer that it relates to the sections discussing the SITE estimator and the assumptions made in the analysis. However, the comment lacks specificity in detailing what needs to be addressed or improved in these sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. While the comment identifies specific areas for clarification, it does not provide detailed reasoning or evidence to support these claims. The authors are left to infer the relevance and importance of these questions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several important questions about the consistency of the SITE estimator and the assumptions required for it to be a valid estimator of the causal effect. It also questions the implicit nature of the objective function for the regression and whether it causes issues due to the loss function being defined over minibatches. These are critical points that could significantly impact the validity and applicability of the results presented in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their analysis. While it identifies areas for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises several questions about the consistency of the SITE estimator, the assumptions required for it to be a valid estimator of the causal effect, and the implicit nature of the objective function for the regression. It also questions whether the loss function being defined over minibatches causes any issues. While the comment identifies specific areas for clarification and potential concerns, it does not provide explicit actions or suggestions for how the authors should address these points. The authors are left to infer that they need to clarify these aspects, but the lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions about the consistency of the SITE estimator, the assumptions required for it to be a valid estimator of the causal effect, and the implicit nature of the objective function for the regression. It also questions whether the loss function being defined over minibatches causes any issues. While the comment does not explicitly mention specific sections, it is clear that it pertains to the methodology and theoretical aspects of the paper. The authors can infer that it relates to the sections discussing the SITE estimator and the assumptions made in the analysis. However, the comment lacks specificity in detailing what needs to be addressed or improved in these sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions about the consistency of the SITE estimator, the assumptions required for it to be a valid estimator of the causal effect, and the implicit nature of the objective function for the regression. It also questions whether the loss function being defined over minibatches causes any issues. While the comment identifies specific areas for clarification, it does not provide detailed reasoning or evidence to support these claims. The authors are left to infer the relevance and importance of these questions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several important questions about the consistency of the SITE estimator, the assumptions required for it to"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation where the method may struggle to shift focus to a new target object if it changes between clicks, due to constraints from previous masks. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The authors are left to infer that they need to explore or discuss this limitation in their paper, but the comment lacks concrete suggestions or steps on how to do so. Therefore, the comment is somewhat actionable, as it points out a potential issue but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation where the method may struggle to shift focus to a new target object if it changes between clicks, due to constraints from previous masks. This feedback is fully grounded as it explicitly mentions \"OIS\" and \"Object-level Understanding,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly details the issue with the method\\'s ability to handle multiple objects and the potential limitations this poses. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a potential limitation where the method may struggle to shift focus to a new target object if it changes between clicks, due to constraints from previous masks. The comment provides a logical reasoning based on the current understanding of the method and its limitations, which is somewhat verifiable. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but requires more detailed evidence to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the method's ability to handle interactive segmentation for multiple objects simultaneously. It highlights a specific concern where the method may struggle to shift focus to a new target object if it changes between clicks, due to constraints from previous masks. This feedback is somewhat helpful as it points out a potential weakness in the method's practical utility. However, the comment could be more helpful if it provided suggestions on how the authors might address this limitation or discuss potential solutions. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It highlights the importance of understanding the domain and the knowledge of concepts. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or what steps they should take to improve their draft. The comment lacks actionable details, leaving the authors uncertain about how to respond or what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It highlights the importance of understanding the domain and the knowledge of concepts. However, it does not specify which part of the paper this concern relates to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the assumption but lacks grounding, as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It highlights the importance of understanding the domain and the knowledge of concepts. However, the comment does not provide specific examples or references to support the claim that this assumption is unrealistic. The reasoning is based on general observations about anomaly detection systems, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the realism of the assumption that anomalies would be aligned with concepts in the proposed system. It highlights the importance of understanding the domain and the knowledge of concepts, which is a relevant point for the authors to consider. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are given a direction to consider but are left without detailed steps to take. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that there is a lack of discussion on the limitations and challenges of HLOP, as well as the experimental design. It suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. This feedback is clear and provides a direct action for the authors to take, which is to include a discussion on these aspects. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HLOP\" and \"the experimental design,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of discussion on limitations and potential downsides, as well as the evaluation process. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of discussion on the limitations and challenges of HLOP and the experimental design, making it difficult to judge the tradeoffs between using HLOP versus other approaches. The reviewer suggests that the authors include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issues that need to be addressed, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the lack of discussion on the limitations and challenges of HLOP and the experimental design. This feedback is clear and actionable, as it highlights an area where the authors can provide more context and depth to their work. By suggesting the inclusion of a discussion on the potential downsides of HLOP and the limitations of the evaluation process, the comment offers specific guidance on how the authors can improve their draft. This constructive feedback is valuable as it helps the authors address a critical aspect of their work, making the comment mostly helpful. However, it could be more helpful if it provided examples or specific suggestions for what aspects of the limitations and challenges should be discussed. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate the effectiveness of the proposed gating scheme on language models like FlanT5 and Llama, which have been released after GPT-2. This feedback provides a clear and explicit action for the authors to take, as it specifies which language models to consider and why evaluating them would enhance the contribution. The comment also offers concrete guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the effectiveness of the proposed gating scheme on language models like FlanT5 and Llama, which have been released after GPT-2. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in suggesting that evaluating these models would enhance the contribution, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area where this evaluation should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating the effectiveness of the proposed gating scheme on language models like FlanT5 and Llama would enhance the contribution. However, the comment does not provide specific reasoning or evidence to support why these models are relevant or why evaluating them would be beneficial. The claim is somewhat verifiable as it suggests a potential area for improvement, but it lacks detailed justification or examples, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors should evaluate the effectiveness of the proposed gating scheme on language models like FlanT5 and Llama, which have been released after GPT-2. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the contribution of their work. By evaluating the proposed scheme on these models, the authors can demonstrate the broader applicability and potential impact of their work. However, the comment could be more helpful if it included specific suggestions on how to conduct these evaluations or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should cite and compare their work with some recent works that might be highly correlated, such as the work by Wang et al. (cvpr2020). While the comment implies that these works should be included in the paper, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and discuss their relevance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should cite and compare their work with some recent works that might be highly correlated, such as the work by Wang et al. (cvpr2020). However, it does not specify which part of the paper this suggestion pertains to, such as the related work section or the discussion of related methods. This makes it difficult for the authors to identify the exact section where this information should be included. Additionally, the comment lacks specificity as it does not detail why these works are relevant or how they should be integrated into the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should cite and compare their work with some recent works that might be highly correlated, such as the work by Wang et al. (cvpr2020). However, the comment does not provide specific reasoning or evidence to support why these works are relevant or how they might impact the proposed method. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should cite and compare their work with some recent works that might be highly correlated, such as the work by Wang et al. (cvpr2020). This is a constructive suggestion that could help the authors situate their work within the broader context of related research. However, the comment lacks specificity and does not provide detailed guidance on how to integrate these references or what aspects of the comparison should be emphasized. While it identifies an area for improvement, the feedback could be more actionable and comprehensive to be rated as highly helpful. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding more detail about how UNKs (unknown tokens) are handled by the neural decoder, or at least providing a citation to the dictionary-based replacement strategy being used. This feedback is explicit and provides a clear action for the authors to take, which is to include additional information or a citation. The suggestion is concrete, as it specifies what needs to be added or referenced. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding more detail about how UNKs are handled by the neural decoder or providing a citation to the dictionary-based replacement strategy. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to add more detail or a citation, but without grounding, the authors may struggle to identify the exact section where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding more detail about how UNKs are handled by the neural decoder or providing a citation to the dictionary-based replacement strategy. This is a request for additional information or reference, which does not contain a claim or opinion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests adding more detail about how UNKs (unknown tokens) are handled by the neural decoder, or providing a citation to the dictionary-based replacement strategy being used. This feedback is clear and actionable, as it identifies a specific area where the authors can enhance the clarity and completeness of their work. By addressing this suggestion, the authors can improve the transparency and comprehensibility of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it provided examples or specific details about what additional information should be included. Overall, the comment is mostly helpful, as it guides the authors toward improving their draft with specific suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. While the comment implies that such comparisons would be beneficial, it does not provide explicit instructions on how to conduct these comparisons or which specific pre-trained models to use. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to implement the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the authors\\' code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors may infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in suggesting a comparison with SOTA methods, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. However, the comment does not provide any specific examples or references to support the claim that such comparisons would be beneficial. Without detailed reasoning or evidence, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should compare their code summarization method with other state-of-the-art (SOTA) methods, specifically mentioning the use of pre-trained models. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for comparative analysis with existing methods. However, the comment lacks specificity regarding which specific SOTA methods should be compared or how the comparison should be conducted. To be more helpful, the comment could provide examples of relevant SOTA methods or suggest specific metrics for comparison. Overall, the feedback offers a direction for improvement but could be more detailed and actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding the results in Table 3. The first question asks for an explanation of why AttendOut has lower variance, and the second question seeks clarification on the statistical significance value when comparing Scheduled Bernoulli and AttendOut. While the questions provide a clear direction for the authors to address, they do not explicitly instruct them to perform specific analyses or provide detailed guidance on how to conduct these comparisons. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take to address the questions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for the lower variance in AttendOut and requests clarification on the statistical significance value when comparing Scheduled Bernoulli and AttendOut. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions seeking clarification on the results in Table 3. The first question asks for an explanation of why AttendOut has lower variance, and the second question requests the statistical significance value when comparing Scheduled Bernoulli and AttendOut. These questions are factual inquiries that do not express an opinion, judgment, or suggestion. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions regarding the results in Table 3. The first question seeks an explanation for why AttendOut has lower variance compared to Scheduled Bernoulli, while the second question asks for clarification on the statistical significance value when comparing these two methods. By addressing these questions, the authors can gain a better understanding of their results and potentially improve the clarity and robustness of their findings. However, the comment does not provide detailed guidance or suggestions on how to address these issues, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the prediction lengths in the experimental results do not align with the definition of \"long-term.\" It provides a specific suggestion to follow the same settings as the original dataset, such as {96, 192, 336, 720}. This feedback is clear and direct, giving the authors a concrete action to take in order to improve the consistency and accuracy of their experimental setup. The suggestion is specific and provides a clear path for the authors to follow, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the prediction lengths do not align with the definition of \"long-term\" and suggests following the same settings as the original dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prediction lengths in the experimental results do not align with the definition of \"long-term.\" However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that the prediction lengths do not accurately reflect the definition of \"long-term.\" It provides a clear and actionable suggestion by recommending that the authors follow the same settings as the original dataset, such as {96, 192, 336, 720}. This feedback is valuable as it helps the authors ensure consistency and accuracy in their experimental setup, which is crucial for the validity of their results. The comment is specific and actionable, offering a clear path for improvement, making it highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the confidence and accuracy for a single sample when using it in Equation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to follow to resolve it. Without specific instructions or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a discrepancy between the confidence and accuracy for a single sample when using it in Equation. However, it does not specify which equation or part of the paper is being referred to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the issue with the confidence and accuracy, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the difference between confidence and accuracy for a single sample is not reasonable when using it in Equation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the confidence and accuracy of a single sample when used in Equation. However, it lacks detail and does not provide any guidance on how to address this discrepancy or improve the analysis. Without actionable suggestions or examples, the authors are left without a clear path to enhance their draft. The feedback is vague and does not offer meaningful insights or constructive advice, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the approach used to calculate the divergence between a sample and the data, specifically mentioning the use of residuals. It questions the applicability of this approach when the sample is shifted from the data distribution and suggests exploring ways to account for the shift. While the comment implies that the authors should consider alternative methods or adjustments to address this issue, it does not provide explicit guidance on how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the calculation of divergence between a sample and the data, which is calculated using residuals. It raises a concern about the approach's applicability when the sample is shifted from the data distribution and suggests exploring ways to account for this shift. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing the issue with the approach and suggesting a potential solution, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the method used to calculate the divergence between a sample and the data, specifically when the sample is shifted from the data distribution. The reviewer suggests exploring ways to account for this shift. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current approach may fail in such settings. This lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to infer the potential issues and explore alternative methods themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the applicability of the method used to calculate the divergence between a sample and the data, specifically when the sample is shifted from the data distribution. It suggests that the authors consider exploring ways to account for this shift, which is a constructive and actionable suggestion. However, the comment lacks specific guidance or examples on how to address this issue, such as alternative methods or approaches to consider. While it identifies a potential weakness, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the applicability of the method used to calculate the divergence between a sample and the data, specifically when the sample is shifted from the data distribution. It suggests exploring ways to account for this shift, implying that the authors should consider alternative methods or adjustments to address this issue. However, the comment does not provide explicit guidance on how to implement these changes or which specific methods to explore. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the calculation of divergence between a sample and the data, which is calculated using residuals. It raises a concern about the applicability of this approach when the sample is shifted from the data distribution and suggests exploring ways to account for this shift. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing the issue with the approach and suggesting a potential solution, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the method used to calculate the divergence between a sample and the data, specifically when the sample is shifted from the data distribution. It suggests exploring ways to account for this shift, implying that the current approach may fail in such settings. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the method may fail. This makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered somewhat verifiable, as it provides a general suggestion but lacks sufficient evidence or guidance to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the applicability of the method used"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the context-dependent nature of word replacements, specifically asking if replacing a word independent of its context could lead to incoherent text. It suggests that replacing entire phrases might be preferable. While the comment raises a valid concern, it does not explicitly instruct the authors to make this change or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should consider replacing entire phrases instead of individual words. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 076-079,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the context-dependent nature of word replacements and suggests that replacing entire phrases might be preferable to avoid incoherent text. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the context-dependent nature of word replacements, specifically asking if replacing a word independent of its context could lead to incoherent text. It suggests that replacing entire phrases might be preferable. While the comment raises a valid concern, it lacks specific examples or references to support the claim that replacing individual words could create incoherent text. The suggestion to replace entire phrases is a logical response to the question, but without further evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the context-dependent nature of word replacements, specifically asking if replacing a word independent of its context could lead to incoherent text. It suggests that replacing entire phrases might be preferable to avoid this issue. While the comment identifies a potential problem, it lacks specific guidance or examples on how to address this concern. The authors are left with a general suggestion but without detailed instructions on how to implement it. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully guide the authors in making the necessary changes. This aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods, which is a clear and explicit action for the authors to take. However, it does not provide specific guidance on which methods to compare or how to conduct the comparison. While the action is explicit, the lack of detailed instructions on execution makes it somewhat vague. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks concrete details on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests including a runtime comparison of different deep learning-based methods, which is a clear and explicit action for the authors to take. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this comparison should be included. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the comment is specific in its suggestion to include a runtime comparison, which provides clear guidance on what needs to be added. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a runtime comparison of different deep learning-based methods, which is a clear and explicit action for the authors to take. However, the comment does not provide any reasoning, examples, or references to support why this comparison is desirable or how it would benefit the paper. Without additional context or justification, the claim is difficult for the authors to understand and act upon. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including a runtime comparison of different deep learning-based methods, which is a clear and actionable suggestion for the authors to enhance their paper. This feedback provides a specific direction for improving the paper by comparing the performance of different methods, which could help readers better understand the efficiency and effectiveness of the proposed approach. However, the comment could be more helpful if it provided examples of which methods to compare or how to structure the comparison. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the ECG encoder, which currently uses only 1-D CNN layers and average pooling, could be improved by incorporating ECG-specific architectures that use SSL or transformer-based approaches. The reviewer implies that these architectures should be compared and explored, similar to how different methods were examined for the other parts of the framework. While the comment explicitly states that the ECG encoder could be improved by incorporating more advanced architectures, it does not provide specific guidance on which architectures to use or how to implement these changes. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the ECG encoder. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ECG encoder,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the current limitations of the ECG encoder, suggesting that it could be improved by incorporating more advanced architectures like SSL or transformer-based approaches. The comment further implies that these architectures should be compared and explored, similar to how different methods were examined for the other parts of the framework. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ECG encoder, which is part of the MEIT framework, could be improved by incorporating more advanced architectures like SSL or transformer-based approaches. The comment implies that these architectures could significantly enhance the current ECG encoder. However, the comment does not provide specific examples or references to support the claim that these architectures would improve the ECG encoder. Without detailed reasoning or evidence, the claim is somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the ECG encoder, which is part of the MEIT framework. It suggests that the current use of 1-D CNN layers and average pooling could be enhanced by incorporating more advanced architectures like SSL or transformer-based approaches. The comment implies that these architectures should be compared and explored, similar to how different methods were examined for the other parts of the framework. This feedback is clear and actionable, as it provides a specific direction for improvement by suggesting a comparison of different architectures. However, the comment could be more helpful if it included specific examples or references to these architectures, which would further guide the authors in implementing the suggested improvements. Overall, the comment is mostly helpful as it offers a clear direction for enhancing the ECG encoder, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly instructs the authors to rephrase the abstract to accurately reflect the focus on explainability rather than defense methodology. This provides a clear and direct action for the authors to take, making the comment highly actionable. The feedback is specific and concrete, guiding the authors on how to improve their draft by correcting a misrepresentation in the abstract. Therefore, this comment is rated as highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'abstract' part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the abstract, which inaccurately suggests a defense methodology is proposed when the paper actually presents a model-agnostic explainability technique for deep neural networks. The comment provides a clear direction for improvement by suggesting a rephrasing of the abstract to accurately reflect the focus on explainability. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the abstract inaccurately suggests a defense methodology is proposed, while the paper actually presents a model-agnostic explainability technique for deep neural networks. The reviewer provides a clear explanation of the discrepancy, suggesting that the abstract should be rephrased to accurately reflect the focus on explainability. This reasoning is logical and provides a clear justification for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific issue with the abstract, noting that it inaccurately suggests a defense methodology is proposed when the paper actually presents a model-agnostic explainability technique for deep neural networks. The comment provides a clear and actionable suggestion to rephrase the abstract to accurately reflect the focus on explainability. This feedback is valuable as it helps the authors correct a potential misinterpretation of their work, ensuring that the abstract more accurately represents the content of the paper. By addressing this issue, the authors can improve the clarity and effectiveness of their communication. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for INRs, specifically mentioning FINER, Incode, and SL2A-INR. While the comment identifies a gap in the paper\\'s analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include these comparisons, but the comment lacks concrete details on how to implement these comparisons or what specific aspects to focus on. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a gap in the paper\\'s comparison, specifically mentioning the lack of comparisons to recent methods like FINER, Incode, and SL2A-INR, which propose new or adaptive activation functions for INRs. However, it does not specify which part of the paper this comparison should be included in, such as the related work section or the experimental results section. This makes it difficult for the authors to pinpoint the exact area where the comparison should be added. While the comment is specific in identifying the need for comparisons to these recent methods, it lacks full grounding as it does not provide explicit references to sections of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for INRs, specifically mentioning FINER, Incode, and SL2A-INR. However, the comment does not provide any specific reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. Without detailed justification or references to the relevance of these methods, the claim remains unverifiable. The authors are left without guidance on how to address this issue, making the comment difficult to act upon. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a gap in the paper's comparison, specifically noting the lack of comparisons to recent methods that propose new or adaptive activation functions for INRs. It mentions specific examples such as FINER, Incode, and SL2A-INR, which could be relevant for the authors to consider. However, the comment does not provide detailed guidance on how the authors should incorporate these comparisons or what specific aspects of these methods are relevant. While it highlights an important area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. The authors are given a direction to consider but are left to determine the specifics of the comparison themselves. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a gap in the paper's comparison, specifically mentioning the lack of comparisons to recent methods that propose new or adaptive activation functions for INRs, such as FINER, Incode, and SL2A-INR. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include these comparisons, but the comment lacks concrete details on what aspects of these methods should be compared or how to structure the comparisons. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a gap in the paper\\'s comparison, specifically mentioning the lack of comparisons to recent methods that propose new or adaptive activation functions for INRs, such as FINER, Incode, and SL2A-INR. However, it does not specify which part of the paper this comparison should be included in, such as the related work section or the experimental results section. This makes it difficult for the authors to pinpoint the exact area where the comparison should be added. While the comment is specific in identifying the need for comparisons to these recent methods, it lacks full grounding as it does not provide explicit references to sections of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comparisons to recent methods that propose new or adaptive activation functions for INRs, specifically mentioning FINER, Incode, and SL2A-INR. However, the comment does not provide any specific reasoning or evidence to support why these comparisons are necessary or how they would enhance the paper. Without detailed justification or references to the relevance of these methods, the claim remains unverifiable. The authors are left without guidance on how to address this issue, making the comment difficult to act upon. Therefore, the comment is classified as 1: Unverifiable.',"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a straightforward method, such as the one referenced in the URL, works well in practice and challenges the value of research on length extrapolation when using finetuned models. It implies that the evaluation setting could be improved. However, the comment does not provide specific guidance on how to improve the evaluation setting or what aspects of the current evaluation could be enhanced. The action is implicit and somewhat vague, as the authors need to infer that they should consider revising their evaluation setting but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation when using finetuned models. It implies that the evaluation setting could be improved. However, it does not specify which part of the paper this critique pertains to, such as a particular section or method. The authors might infer that it relates to the evaluation or experimental setup, but this inference is not explicit. The comment is specific in its critique of the evaluation setting and its implications for research, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation when using finetuned models. However, it does not provide specific examples or references to support the claim that the method is straightforward or how it challenges the value of research. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation when using finetuned models. It implies that the evaluation setting could be improved. However, the comment does not provide specific guidance on how to improve the evaluation setting or what aspects of the current evaluation could be enhanced. While it identifies a potential issue, it lacks actionable advice or detailed suggestions, making it somewhat helpful. The authors might find some inspiration for improvement, but the feedback is not comprehensive enough to be highly actionable. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify which environment is used for training and which for testing in Section 2.4. It also suggests that cross-validation should be performed to demonstrate the robustness of the results. This feedback is clear and direct, providing the authors with a specific action to take: identifying the training and testing environments and conducting cross-validation. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the autoencoder training and testing, asking for clarification on which environment is used for training and which for testing. Additionally, it suggests that cross-validation should be performed to demonstrate the robustness of the results. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the methodology used in Section 2.4, specifically regarding the training and testing of the autoencoder across different environments. The reviewer suggests that it is preferable to conduct cross-validation to demonstrate the robustness of the results. While the comment does not provide specific examples or references to support the claim, it is based on a logical assumption that cross-validation is a standard practice to ensure the robustness of results. The authors can infer that the suggestion is reasonable and should be considered, but the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific issue with the methodology described in Section 2.4, where the autoencoder is trained on one environment and tested on all others. The reviewer suggests that it is preferable to conduct cross-validation to demonstrate the robustness of the results better. This feedback is clear and actionable, providing the authors with a specific area to address and a clear direction for improvement. By suggesting cross-validation, the comment helps the authors enhance the reliability and generalizability of their results. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the number of refinements is mentioned, it does not provide evidence of an actual improvement. The comment implies that the authors should include a comparison to show the effectiveness of the refinement process. However, it does not explicitly instruct the authors to perform this comparison or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison, but they are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It mentions the statistic of the number of refinements, which provides some grounding as it refers to a specific aspect of the paper. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the need for a comparison to show improvement, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to demonstrate the improvement in generation quality due to refinement during inference. The comment suggests that while the number of refinements is mentioned, it does not provide evidence of an actual improvement. This claim is somewhat verifiable as it points out a specific area where the paper could be improved, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the need for a comparison and understand the implications of the lack thereof. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It points out that while the number of refinements is mentioned, it does not provide evidence of an actual improvement. This feedback is clear and actionable, as it directs the authors to include a comparison to substantiate the effectiveness of the refinement process. However, the comment could be more helpful if it suggested specific methods or metrics for conducting this comparison. Overall, the comment is mostly helpful as it provides a clear direction for enhancing the paper's quality and impact.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions. The first question asks about the missing threshold in the PMI calculation, implying that the authors should clarify or provide this information. The second question asks if the partitions were done randomly, suggesting that the authors should explain their methodology. While the questions provide some guidance, they are not explicit in their actions. The authors can infer that they need to clarify the missing threshold and explain the random partitioning, but the comments lack concrete details on how to address these issues. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment consists of two parts, each addressing a specific issue. The first part refers to line 336, where it mentions \"PMI\" and suggests that something is missing, possibly a threshold. The second part refers to line 371, questioning whether the partitions were done randomly. While the comment provides specific references to lines in the paper, it does not explicitly mention the sections or figures being discussed, making it weakly grounded. However, it is specific in identifying the issues with the PMI calculation and the random partitioning. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions, one asking about the missing threshold in the PMI calculation and the other questioning the randomness of the partitions. These questions are factual inquiries seeking clarification and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions, one asking about the missing threshold in the PMI calculation and the other questioning the randomness of the partitions. While these questions are relevant and could help the authors clarify their methodology, they do not provide specific guidance or suggestions for improvement. The feedback lacks depth and does not offer actionable advice on how to address these issues or enhance the clarity and rigor of the paper. As a result, the comment is somewhat helpful, as it identifies areas for clarification but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for the training time comparison between the MDP and ImageNet pretraining + individual dataset fine-turning. This request provides a clear and direct action for the authors to take, as it specifies what information is needed to address the concern. The comment is explicit and concrete, giving the authors a clear path to follow in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a question about the training time of the MDP and requests a comparison with ImageNet pretraining and individual dataset fine-turning. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this information might be discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its request for a training time comparison, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for additional information, specifically asking for a comparison of training times between the MDP and ImageNet pretraining + individual dataset fine-turning. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the training time of the MDP, suggesting that the authors provide a comparison with ImageNet pretraining and individual dataset fine-turning. This feedback is clear and actionable, as it prompts the authors to include additional information that could enhance the comprehensiveness of their study. By addressing this question, the authors can provide more context and detail about their experimental setup, which is valuable for readers and reviewers. However, the comment could be more helpful if it included specific suggestions on how to present this comparison or what aspects of the training time should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, noting that its structure is an incremental improvement over GraphCON[1]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this critique or what changes they should make to their claims. The comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, noting that its structure is an incremental improvement over GraphCON[1]. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in detailing the critique of the claim, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, noting that its structure is an incremental improvement over GraphCON[1]. The comment provides a specific reference to GraphCON[1] as the basis for the incremental improvement, which supports the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the critique, making it somewhat verifiable. The authors would need to provide more context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the claim that G-PDE is intentionally designed to leverage the advantages of both spike ODE and graph ODE, noting that its structure is an incremental improvement over GraphCON[1]. While the comment identifies a potential issue with the claim, it does not provide specific suggestions or guidance on how the authors might address this critique or improve their argument. The feedback lacks actionable advice or detailed insights, making it somewhat helpful. The authors may find it useful to consider the critique but would need to make additional efforts to incorporate it into their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the proposed method, noting that it does not outperform Jiang et al. significantly in certain metrics. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed method or what specific changes should be made. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed method compared to Jiang et al., specifically mentioning metrics like Penetration(Dep), CR, and Sim-Disp(Mean). However, it does not specify which part of the paper discusses these metrics or where the comparison is made, making it weakly grounded. The comment is specific in detailing the performance gaps between the proposed method and Jiang et al., providing clear information on where the proposed method falls short. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method does not outperform Jiang et al. significantly, providing specific examples of metrics where the proposed method performs worse or only slightly better. However, the comment lacks detailed reasoning or evidence to substantiate the claim, such as comparisons with other relevant works or detailed analysis of the performance metrics. This makes the claim somewhat verifiable, as the authors would need to conduct further analysis to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the proposed method, noting that it does not outperform Jiang et al. significantly in certain metrics. It provides specific examples, such as the performance gaps in Penetration(Dep), CR, and Sim-Disp(Mean), which helps the authors understand where their method falls short. However, the comment lacks actionable suggestions or guidance on how to address these issues or improve the performance of the proposed method. While it highlights a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues: first, it questions the relevance of the term \"vFSAD\" and suggests that it refers to OOD detection in time-series data, which is a large and unexplored area. It also points out that this area has not been compared with or mentioned in the paper. Second, it critiques the related work subtitles of \"Policy\" and \"Evaluation tasks,\" stating that they are not descriptive and seem unrelated to the actual content. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the term \"vFSAD\" and improve the description of the related work subtitles, but the lack of concrete steps or examples makes the action implicit and vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two separate issues: the term \"vFSAD\" and the related work subtitles. Regarding \"vFSAD,\" the comment provides a specific example of Kaur et al. \"CODiT,\" suggesting that the term refers to OOD detection in time-series data and questioning why it has not been compared or mentioned in the paper. This part is fully grounded as it explicitly mentions a specific example and provides a clear context for the critique. However, the comment does not specify how the authors should address this issue, such as by including comparisons or references to related work. Regarding the related work subtitles, the comment notes that they are not descriptive and seem unrelated to the actual content, but it does not provide specific suggestions for improvement. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises two claims. First, it questions the relevance of the term \"vFSAD\" and suggests that it refers to OOD detection in time-series data, which is a large and unexplored area. This claim is somewhat verifiable as it provides a specific example of related work (Kaur et al.'s \"CODiT\") to support the suggestion that \"vFSAD\" is related to OOD detection in time-series data. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper. First, it questions the relevance of the term 'vFSAD' and suggests that it refers to OOD detection in time-series data, which is a large and unexplored area. It provides an example of related work (Kaur et al.'s \"CODiT\") to support this claim. This feedback is valuable as it prompts the authors to clarify the term 'vFSAD' and its relation to the paper's content. Second, the comment critiques the related work subtitles of 'Policy' and 'Evaluation tasks,' noting that they are not descriptive and seem unrelated to the actual content. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of clarity and coherence, but it lacks specific suggestions or guidance on how to address these issues. Overall, the comment provides some actionable insights but could be more detailed and comprehensive, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that an ablation study should be added to justify the selection of memory size. This action is clear and direct, as it provides a specific recommendation for improving the paper. The comment also specifies what needs to be included in the ablation study, which further clarifies the action. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding an ablation study to justify the selection of memory size, which is a specific suggestion for improvement. However, it does not specify which part of the paper this recommendation pertains to, such as a particular section or experiment. The authors can infer that it relates to the discussion or results sections where memory size is mentioned, but this inference is not explicit. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the effect of memory size is ambiguous and recommends adding an ablation study to justify the memory size selection. However, the comment does not provide specific examples or detailed reasoning to support why the effect of memory size is ambiguous or how an ablation study would address this issue. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by suggesting that the effect of memory size is ambiguous and recommending the addition of an ablation study to justify the memory size selection. This feedback is clear and actionable, providing a concrete step for the authors to take to enhance the clarity and robustness of their work. By addressing this suggestion, the authors can strengthen their paper's methodology and results, making the comment highly helpful. However, it could be more helpful if it provided additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful, as it directs the authors towards a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the use of the abbreviation \"GNN\" in the paper. It notes that the abbreviation appears on page 1 but is not fully defined until Section 2, on page 2. This comment implies that the authors should ensure consistency in the use of abbreviations throughout the paper. However, it does not explicitly instruct the authors to make this change or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should correct the inconsistency in abbreviation usage. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abbreviation \"GNN\" and specifies the pages where it appears, allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback by pointing out the inconsistency in the definition of \"GNN,\" which is not provided until much later in the paper. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a discrepancy in the use of the abbreviation \"GNN,\" noting that it appears on page 1 but is not fully defined until Section 2, on page 2. This observation is factual and does not require any supporting evidence or reasoning. It is a straightforward statement of a potential issue in the paper\\'s presentation, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations in the paper, noting that the abbreviation \"GNN\" appears on page 1 but is not fully defined until Section 2, on page 2. This feedback is clear and actionable, as it points out a potential inconsistency in the paper\\'s presentation that could lead to confusion for readers. By highlighting this issue, the comment provides the authors with a specific area to address, which could significantly improve the clarity and readability of their work. However, the comment could be more helpful if it suggested how the authors might resolve this issue, such as by providing the full definition earlier in the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, comparing it with state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of baseline methods on the DAVIS dataset, comparing it with state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion section, but this inference is not explicit. The comment is specific in detailing the concern about the performance comparison and the potential limitations of the proposed loss function. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance of baseline methods on the DAVIS dataset is low, comparing it with state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. The comment provides a reference to a specific work, \"Luiten, J., Zulfikar, I.E., & Leibe, B. (2020). UnOVOST: Unsupervised Offline Video Object Segmentation and Tracking,\" which could be used to support the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim. While the reference provides a basis for the claim, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights a concern about the performance of baseline methods on the DAVIS dataset, comparing it with state-of-the-art results. It suggests that the effectiveness of the proposed loss function on these algorithms may not guarantee its effectiveness on top-performing ones. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their results. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results for the proposed two-step decoding method, specifically asking if they are reported in the paper. It also inquires about the performance of the two-step method compared to the results in Table 1 with decoder downsampling. While the comment does not explicitly instruct the authors to report the results, it does provide a clear and specific question that the authors can address. The authors are given a direct action to clarify the results of the two-step method, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the results for the proposed two-step decoding method, specifically asking if they are reported in the paper. It also inquires about the performance of the two-step method compared to the results in Table 1 with decoder downsampling. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or table. While the authors can infer that it relates to the results section or Table 1, the lack of explicit grounding makes it difficult to pinpoint the exact location. The comment is specific in its request for clarification about the results and the performance of the two-step method. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the results for the proposed two-step decoding method, specifically asking if they are reported in the paper. It also inquires about the performance of the two-step method compared to the results in Table 1 with decoder downsampling. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the results are missing or unclear. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the results for the proposed two-step decoding method, asking if they are reported in the paper and how much worse the two-step method performs compared to the results in Table 1 with decoder downsampling. This feedback is clear and actionable, as it prompts the authors to clarify and provide additional information about their results. By addressing this question, the authors can enhance the transparency and comprehensiveness of their paper. However, the comment could be more helpful if it suggested how the authors might present this information or what specific details should be included. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to increase the font size in the figures to improve readability. This is a clear and direct action that the authors can take to address the issue. The comment provides specific guidance on what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"figures,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the font size is too small, providing clear guidance on what needs to be improved. This makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for a specific action, namely increasing the font size in figures to improve readability. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the figures, noting that the font size is too small, which can affect readability. It provides a clear and actionable suggestion for improvement by instructing the authors to increase the font size. This feedback is valuable as it helps the authors enhance the clarity and accessibility of their figures, which is an important aspect of technical writing. However, the comment could be more helpful if it offered additional guidance on how to achieve this improvement or suggested specific font sizes to use. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that only synthetic problems are considered in the experiments, implying that the authors should consider real-world problems as well. However, the comment does not provide explicit guidance on how to incorporate real-world problems or what specific aspects of the current synthetic problems could be improved. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include real-world scenarios. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that only synthetic problems are considered in the experiments, implying that the authors should consider real-world problems as well. However, it does not specify which part of the paper discusses the experiments or where the consideration of synthetic problems is mentioned. This makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion to include real-world problems, but it lacks grounding as it does not specify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that only synthetic problems are considered in the experiments, implying that the authors should also consider real-world problems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential limitation in the experiments, specifically noting that only synthetic problems are considered. This feedback is somewhat helpful as it highlights an area where the authors might need to expand their work to include real-world problems. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this limitation. Without additional context or actionable advice, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as somewhat helpful, as it identifies a potential issue but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should compare their explainer, which generates natural language explanations, with other NLE interpretability tools. This is a clear and direct action for the authors to take, as it specifies what additional comparisons are needed to enhance the paper. The comment provides concrete guidance on how to improve the draft by including relevant baselines, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"NLE baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to compare the explainer, which generates natural language explanations, with other NLE interpretability tools. This provides clear guidance on what additional comparisons are necessary to strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should compare their explainer, which generates natural language explanations, with other NLE interpretability tools. This is a logical suggestion based on the current state of the paper, which only compares to feature attribution type of explanations. The claim is supported by the observation that the current comparison is limited and could be expanded to include a broader range of interpretability tools. However, the comment does not provide specific examples or references to other NLE interpretability tools, which would further strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a clear rationale for the suggestion but lacks detailed examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's evaluation by pointing out the absence of comparisons with NLE (Natural Language Explanations) baselines. It highlights that the authors have only compared their explainer, which generates natural language explanations, with feature attribution type of explanations. This feedback is clear and actionable, as it suggests that the authors should expand their comparison to include other NLE interpretability tools. By addressing this gap, the authors can provide a more comprehensive evaluation of their method's performance and impact. However, the comment could be more helpful if it provided specific examples or references to other NLE interpretability tools that could be included in the comparison. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point explicitly identifies a specific issue with Eq. (5) in the paper, noting that it only uses one pertinent positive data point while there are many data points that satisfy Eq. (1) and Eq. (2). It further points out that these data points contribute equally to Eq. (3) but have different perturbation directions, and suggests that Eq. (5) does not include an exhaustive test over the diversity of all these data points. This feedback is explicit and provides a clear action for the authors to take, which is to ensure that Eq. (5) includes an exhaustive test over the diversity of all data points. The comment is concrete in its suggestion, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. (5)\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with Eq. (5), noting that it only uses one pertinent positive data point while there are many data points that satisfy Eq. (1) and Eq. (2). The comment specifies that these data points contribute equally to Eq. (3) but have different perturbation directions, and suggests that Eq. (5) does not include an exhaustive test over the diversity of all these data points. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Eq. (5) only uses one pertinent positive data point, while there are many data points that satisfy Eq. (1) and Eq. (2). It further suggests that these data points contribute equally to Eq. (3) but have different perturbation directions, and that Eq. (5) does not include an exhaustive test over the diversity of all these data points. The comment provides a logical reasoning by pointing out the discrepancy in the use of data points and the need for an exhaustive test. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact data points being referred to and the need for an exhaustive test, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the use of data points in Eq. (5), noting that only one pertinent positive data point is used while there are many data points that satisfy Eq. (1) and Eq. (2). It further points out that these data points contribute equally to Eq. (3) but have different perturbation directions, and suggests that Eq. (5) does not include an exhaustive test over the diversity of all these data points. This feedback is clear and actionable, as it provides a specific area for improvement by recommending an exhaustive test to ensure the diversity of data points is considered. The comment is mostly helpful as it offers a detailed insight into a potential weakness in the paper's methodology, guiding the authors toward a more comprehensive analysis. However, it could be more helpful if it provided additional suggestions or examples on how to implement this improvement. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of their results with existing supervised retrievers to demonstrate the additional performance boost that document augmentation can provide. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors can infer the need for a comparison but may not know exactly how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results\" and \"document augmentation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is to include a comparison of the results with existing supervised retrievers to demonstrate the additional performance boost that document augmentation can provide. This feedback is clear and actionable, providing a direct suggestion for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the results should be compared with existing supervised retrievers to demonstrate the additional performance boost that document augmentation can provide. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the rationale behind the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's evaluation, specifically the lack of comparison with existing supervised retrievers. It suggests that including such a comparison would provide a more comprehensive understanding of the effectiveness of the proposed method. The comment is clear and actionable, offering a specific direction for improvement that could significantly enhance the paper's impact and relevance. By addressing this feedback, the authors can demonstrate the added value of their approach in the context of existing supervised retrievers. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of discussion regarding the cache hierarchy, specifically the order in which the three dimensions are applied and whether they share data. It also notes that while the individual levels are discussed in terms of their construction and details, there is no explanation of how they are applied together. The comment highlights a contradiction with the initial claim of an independent hierarchy. While the comment identifies a specific area that needs clarification, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should discuss the cache hierarchy and its application, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of discussion regarding the cache hierarchy, specifically the order in which the three dimensions are applied and whether they share data. It also points out that while the individual levels are discussed in terms of their construction and details, there is no explanation of how they are applied together. The comment highlights a contradiction with the initial claim of an independent hierarchy. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the cache hierarchy, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the cache hierarchy is not discussed, specifically the order in which the three dimensions are applied and whether they share data. It also notes that while the individual levels are discussed in terms of their construction and details, there is no explanation of how they are applied together. The comment highlights a contradiction with the initial claim of an independent hierarchy. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's discussion regarding the cache hierarchy, specifically the order in which the three dimensions are applied and whether they share data. It highlights that while the individual levels are discussed in terms of their construction and details, there is no explanation of how they are applied together. This is a critical oversight, as it contradicts the initial claim of an independent hierarchy. The comment provides clear and actionable feedback, guiding the authors to address this omission and clarify the cache hierarchy's application. However, it could be more helpful by suggesting specific ways to discuss the cache hierarchy or providing examples of how this information could be integrated into the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about managing GPU memory during pretraining, specifically regarding the need for forward propagation 3 times before 1 backprop. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to manage GPU memory or prevent the OOM (Out-Of-Memory) issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss memory management strategies. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the management of GPU memory during pretraining, particularly regarding the need for forward propagation 3 times before 1 backprop. This provides clear guidance on what aspect of the paper needs clarification or improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the management of GPU memory during pretraining, specifically regarding the need for forward propagation 3 times before 1 backprop. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the management of GPU memory during pretraining, particularly regarding the need for forward propagation 3 times before 1 backprop. This is a relevant and important issue for the authors to address, as it impacts the efficiency and feasibility of their approach. However, the comment does not provide any suggestions or guidance on how the authors might manage their GPU memory or prevent the OOM (Out-Of-Memory) issue. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to \"rewrite and well present your contributions\" in the Abstract. This provides a clear and direct action for the authors to take, which is to improve the clarity and presentation of their contributions in the Abstract. The feedback is specific and actionable, as it gives a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Abstract, which is that it is not well-written and difficult to understand the contributions. The comment provides a clear direction for improvement by recommending a rewrite. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Abstract is not well-written and difficult to understand, recommending a rewrite to better present contributions. However, the comment does not provide specific examples or detailed reasoning to support why the current Abstract is unclear or how it could be improved. This lack of detailed justification makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the Abstract, noting that it is not well-written and difficult to understand the contributions. It provides a clear and actionable suggestion by recommending a rewrite to better present the contributions. This feedback is valuable as it directs the authors to improve a critical section of their paper, enhancing its clarity and effectiveness. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the writing. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more detailed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point continues a previous point by mentioning that ADE is a dataset for Image parsing and may be biased among different scenes, favoring the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this potential bias or what steps they should consider to mitigate it. As a result, the comment lacks actionable content, leaving the authors without a clear understanding of what changes or improvements are needed. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment continues a previous point, suggesting that ADE is a dataset for Image parsing and may be biased among different scenes, favoring the performance of the proposed method. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its claim about potential bias in the dataset, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that ADE is a dataset for Image parsing and may be biased among different scenes, favoring the performance of the proposed method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment continues a previous point by mentioning that ADE is a dataset for Image parsing and may be biased among different scenes, favoring the performance of the proposed method. While it highlights a potential issue with the dataset, it does not provide specific guidance or suggestions on how the authors might address this bias or improve their analysis. The comment lacks actionable advice or detailed feedback, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of two matrices for each relation in section 2.1.2 and suggests that the matrices may be redundant. It also notes that many matrices are not used in the following text. While the comment identifies a potential issue with the representation of matrices, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the use of matrices or potentially simplify the representation. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of two matrices for each relation and notes that many matrices are not used in the following text. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the use of two matrices for each relation in section 2.1.2, suggesting that the matrices may be redundant. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the representation of matrices in section 2.1.2, questioning why two matrices are used for each relation when they seem to be the same. It also notes that many matrices are not used in the following text, suggesting a redundancy or inefficiency in the current approach. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue or simplify their representation. The feedback is somewhat helpful as it points out a potential problem, but it could be more actionable with additional insights or recommendations. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the semantics of the upsampled feature map being stronger than the original one, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or clarify the concept. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the semantics of the upsampled feature map being stronger than the original one, providing a clear direction for the authors to address this point. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific claim made in the paper, \"the semantics of the upsampled feature map can be stronger than the original one.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry that seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific claim made in the paper, \"the semantics of the upsampled feature map can be stronger than the original one.\" This feedback is somewhat helpful as it prompts the authors to clarify or explain this concept, which could be important for the readers' understanding. However, the comment lacks depth and does not provide any guidance on how the authors might address this issue or improve the clarity of their explanation. To be more helpful, the comment could suggest specific areas for clarification or provide examples to illustrate the concept. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically referencing [1] as an example. However, it does not provide explicit guidance on how to clarify these differences or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to compare their method with [1] but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests clarifying the differences between the current method and other methods for predicting user\\'s personality, specifically referencing [1] as an example. However, it does not specify which part of the paper this clarification should be addressed in, making it weakly grounded. The comment is specific in its suggestion to clarify the differences with [1], but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it is necessary to clarify the differences between the current method and other methods for predicting user\\'s personality, specifically referencing [1] as an example. However, the comment does not provide any specific reasoning or evidence to support why this clarification is necessary or how it would improve the paper. The mention of [1] does not offer detailed comparisons or analysis, leaving the authors without a clear understanding of what aspects of the current method need to be clarified or how they should address the differences. Therefore, the claim is unverifiable due to the lack of supporting evidence or reasoning.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that it is necessary to clarify the differences between the current method and other methods for predicting user's personality, specifically referencing [1] as an example. This feedback is somewhat helpful as it points out a potential area for improvement by highlighting the need for a clearer differentiation between methods. However, the comment lacks specific guidance on how to clarify these differences or what aspects should be emphasized. While it provides a direction for improvement, the feedback could be more actionable and comprehensive to fully benefit the authors. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the theoretical basis for the empirical verification of LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not provide explicit or implicit actions for the authors to take. The first comment questions the theoretical basis of the empirical verification, but it does not suggest how the authors should address this issue. The second comment questions the necessity of step size tuning, but it does not offer guidance on how to resolve this concern. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two separate issues: the theoretical basis of LoRA tuning and the necessity of step size tuning despite theoretical claims. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in detailing the theoretical concerns, but without grounding, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two claims. The first claim questions the theoretical basis of LoRA tuning, suggesting that imposing B to be the basis and A to be the coordinate should not accelerate convergence, as they cover the same X space. The second claim questions the necessity of step size tuning despite theoretical claims. While the reviewer provides a logical reasoning for the first claim, it lacks specific references or examples to fully substantiate the argument. The second claim is more verifiable, as it references the theoretical claims about constant step size and the need for step size tuning in experiments. However, it could be strengthened with more detailed reasoning or examples. Overall, the comment is mostly verifiable, as it provides some logical reasoning and references to support the claims, but it could be more robust with additional evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises two concerns regarding the theoretical basis of LoRA tuning and the necessity of step size tuning despite theoretical claims. The first point questions the theoretical justification for the empirical verification, suggesting that the imposed structure of B and A might not lead to the expected acceleration of convergence. The reviewer provides a logical argument based on the theoretical framework, questioning the validity of the empirical results. The second point questions the necessity of step size tuning, despite the theoretical claim that a constant step size is sufficient. This raises a concern about the practical implications of the theoretical findings. While the comment identifies important areas for clarification and improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider and potentially revise their theoretical claims, but it could be more actionable with detailed suggestions or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors conduct more ablation studies or analysis on problems other than the shortest path problem. While the comment implies that additional experiments are needed to strengthen the paper\\'s claims, it does not explicitly instruct the authors to perform these experiments or provide specific guidance on which problems to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more ablation studies or analysis on problems other than the shortest path problem. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of the PathGNN architecture. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct additional studies, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experimental environments are closely related to the shortest path problem and that the architecture (PathGNN) includes a bias towards this problem. The reviewer recommends conducting more ablation studies or analysis on problems other than shortest path problems to make the findings more convincing. However, the comment lacks specific examples or references to support the claim about the bias or the need for additional studies. While the suggestion is logical, it requires more detailed justification or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the experimental design, noting that most experimental environments are closely related to the shortest path problem. It suggests that the authors conduct more ablation studies or analysis on problems other than shortest path problems to make their findings more convincing. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their results. By addressing this suggestion, the authors can strengthen their paper by demonstrating the applicability of their approach beyond a single problem domain. Therefore, the comment is rated as highly helpful, as it offers a clear and constructive suggestion for improvement.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. While the comment implies that the authors should consider adding these models, it does not provide specific examples or guidance on which models to include or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer which models to add and how to incorporate them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. However, it does not specify which sections or parts of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include more recent models, but without grounding, the authors may struggle to identify the exact sections where this improvement is needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. However, the comment does not provide specific examples or references to these models, making it difficult for the authors to understand which models would be most relevant or how to incorporate them into their work. Without detailed guidance or examples, the claim is not fully verifiable, as it lacks the necessary evidence to support the suggestion. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper could include more recent models in its comparisons, particularly in multilingual settings or other languages beyond English. This feedback is somewhat helpful as it points out a potential area for improvement in the paper\\'s scope and relevance. However, the comment lacks specificity and does not provide examples or guidance on which specific models should be included or how they could enhance the paper. To be more helpful, the comment could specify which recent models are relevant or provide a rationale for why these models are important. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks depth and detail.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and insight into the approach. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific steps to enhance the visualization or analysis. The feedback is vague and lacks concrete details, leaving the authors uncertain about how to implement the suggested changes. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the lack of visualization of the learned context token, which is a specific aspect of the paper. It also points out the simplicity and effectiveness of the approach but notes that its novelty is limited and lacks insight. This provides some grounding as it mentions a specific part of the paper (the visualization of context tokens) and highlights areas for improvement. However, the comment does not specify which sections or figures should include this visualization or how the analysis of the approach could be enhanced. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and insight into the approach. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or references limits the verifiability of the claim, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement, noting the lack of visualization of the learned context token, which could help illustrate the difference between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty and insight into the approach. While the comment highlights important aspects for improvement, it does not provide specific suggestions or guidance on how to enhance the visualization or analysis. The feedback is somewhat helpful as it directs the authors' attention to a critical area for enhancement, but it lacks depth and actionable details, leaving the authors with a general sense of what needs to be addressed without clear steps to take. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern with the experimental section, specifically noting that the current results show only small benefits over the baseline model. It suggests that reporting results for other models, such as MetaOptNet, would strengthen the paper by emphasizing the generality of the method and demonstrating its ability to improve multiple baseline models. While the comment explicitly states the action needed to address the concern, it does not provide specific guidance on which other models to include or how to structure the additional results. The action is concrete but could be more detailed, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current results showing only small benefits over the baseline model and suggests that reporting results for other models would strengthen the paper. The comment provides a clear direction for improvement, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current results show only small benefits over the baseline model and suggests that reporting results for other models would strengthen the paper. However, the comment does not provide specific examples or detailed reasoning to support why reporting results for other models would be more convincing. The lack of detailed justification or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific concern with the experimental section of the paper, noting that the current results show only small benefits over the baseline model. It provides a clear suggestion for improvement by recommending that the authors report results for other models, such as MetaOptNet, to emphasize the generality of the method and demonstrate its ability to improve multiple baseline models. This feedback is actionable and provides a concrete direction for enhancing the paper's strength and impact. However, the comment could be more helpful if it offered additional guidance on which other models to consider or how to structure the additional results. Overall, the comment is mostly helpful as it effectively directs the authors towards a meaningful enhancement of their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. While the comment implies that the authors should expand their comparison, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to include additional comparisons, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. However, it does not specify which part of the paper should include these comparisons or where these methods are mentioned. The authors can infer that the comparison section might need expansion, but the comment lacks specificity in identifying the exact sections or elements that need to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, indicating that including these methods would provide a more comprehensive evaluation of the proposed method. However, the comment lacks specific references or examples of how these methods are used in the field, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparison by including well-established methods such as FTML and LFW. This feedback is valuable as it provides a clear direction for the authors to enhance the comprehensiveness of their evaluation. By suggesting specific methods to include, the comment offers actionable guidance that can help the authors improve the robustness and relevance of their work. However, the comment could be more helpful if it provided additional context or examples of how these methods are typically used in the field. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the underperformance of the proposed CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded. Additionally, it points out that location embeddings provide additional information on the main dataset but not in the extra dataset, implying that they may be useful for specific types of datasets. However, the comment does not provide specific guidance on how the authors should adjust their focus or what aspects of the paper should be revised. The feedback lacks actionable details, leaving the authors uncertain about how to address the issues raised. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded due to the underperformance. Additionally, it points out that location embeddings provide additional information on the main dataset but not in the extra dataset, implying that they may be useful for specific types of datasets. However, the comment does not specify which sections of the paper discuss these aspects, making it weakly grounded. The authors can infer that it relates to the experimental results and discussion sections, but this is not explicitly mentioned. The comment is specific in detailing the issues with the performance and the potential usefulness of location embeddings, but it lacks explicit grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed CRF variants underperform hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded. Additionally, it notes that location embeddings provide additional information on the main dataset but not in the extra dataset, implying that they may be useful for specific types of datasets. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The mention of \"extra dataset\" in Appendix D provides some context, but the lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant issue with the performance of the proposed CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. It suggests that the focus on modeling the task using a CRF should be downgraded due to this underperformance. Additionally, it points out that location embeddings provide additional information on the main dataset but not in the extra dataset, implying that they may be useful for specific types of datasets. However, the comment lacks detailed guidance on how the authors should adjust their focus or what specific aspects of the paper should be revised to address these issues. While it highlights important areas for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of the training-testing inconsistency, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects they should consider. The comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of the training-testing inconsistency, but it does not specify which part of the paper this issue is discussed in. The authors may have an idea of where this inconsistency is mentioned, but the comment lacks explicit references to sections, tables, or figures. Additionally, the comment does not provide specific details on what aspects of the impact are unclear or how they should be addressed. This makes it difficult for the authors to pinpoint the exact part of the paper that needs revision and limits their ability to address the issue effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the impact of the training-testing inconsistency, but it does not contain any claims, opinions, or suggestions that require verification. It is a factual statement seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about the impact of the training-testing inconsistency, which is a relevant and important aspect to consider in the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or what specific impact it might have on their results. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for improvement but does not offer actionable insights or suggestions.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the condition for y membership being unclear due to the disjoint nature of sets S, and claims that are not backed up, specifically mentioning the second line after Eq. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific instructions or suggestions on how to clarify the condition or support the claims makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the clarity of the condition for y membership and the lack of support for claims, particularly mentioning the second line after Eq. This provides some level of grounding as it refers to a specific part of the paper, but it does not explicitly mention which section or equation is being discussed. The authors can infer that it relates to the section or equation mentioned, but the lack of explicit reference makes it weakly grounded. The comment is specific in detailing the issues with clarity and support, making it specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear due to the disjoint nature of sets S, as defined above. It also notes that some claims are not backed up, specifically mentioning the second line after Eq. The comment provides a logical reasoning for the claim by explaining the disjoint nature of sets S and the lack of support for claims. However, it lacks specific examples or references to support the claim fully. While the reasoning is clear, the absence of detailed examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper: the clarity of the condition for y membership, which is unclear due to the disjoint nature of sets S, and the lack of support for some claims, particularly the second line after Eq. While the comment points out these weaknesses, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it highlights areas that need clarification or support, but it lacks depth and actionable advice, leaving the authors with a general understanding of what needs improvement but no clear path forward. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies two specific issues: the clarity of the condition for y membership due to the disjoint nature of sets S, and the lack of support for claims, particularly the second line after Eq. While the comment points out these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific suggestions or actionable steps makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the clarity of the condition for y membership, which is unclear due to the disjoint nature of sets S, and the lack of support for claims, particularly the second line after Eq. This provides some level of grounding as it refers to specific parts of the paper, but it does not explicitly mention which section or equation is being discussed. The authors can infer that it relates to the section or equation mentioned, but the lack of explicit reference makes it weakly grounded. The comment is specific in detailing the issues with clarity and support, making it specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the condition for y membership is unclear due to the disjoint nature of sets S, as defined above. It also notes that some claims are not backed up, specifically mentioning the second line after Eq. The comment provides a logical reasoning for the claim by explaining the disjoint nature of sets S and the lack of support for claims. However, it lacks specific examples or references to support the claim fully. While the reasoning is clear, the absence of detailed examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper: the clarity of the condition for y membership, which is unclear due to the disjoint nature of sets S, and the lack of support for claims, particularly the second line after Eq. While the comment points out these weaknesses, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it highlights areas that need clarification or support, but it lacks"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that certain key references that are highly related are not compared or explained in the paper. However, it does not provide specific guidance on which references are missing or how the authors should address this issue. The comment lacks explicit instructions or concrete suggestions on what actions the authors should take to improve their draft. As a result, the authors are left without a clear understanding of how to address the feedback, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of comparison with key references that are highly related to the work. However, it does not specify which references are missing or how they should be compared, leaving the authors without clear guidance on what to address. The comment is weakly grounded as it does not provide explicit references or sections of the paper where these comparisons should be made. It is also not specific because it lacks detailed instructions on how to improve the draft. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that certain key references are not compared or explained in the paper. However, it does not provide specific examples or references of these key works, nor does it explain why their inclusion would be beneficial. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that certain key references that are highly related are not compared or explained. This feedback is valuable as it highlights a gap in the paper's analysis and suggests that the authors should consider including these references to provide a more comprehensive comparison. However, the comment lacks specific guidance on which references are missing or how they should be integrated into the paper. While it points out an area for improvement, the feedback could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is somewhat helpful, as it directs the authors to an important aspect of their work that needs attention but lacks full guidance on how to address it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the analysis of SCL in section 5.2 regarding few-shot ability, suggesting that the results in Figure 7(c) and (d) do not meet the authors\\' expectations. It points out that COCO-LM achieves significant improvements with fewer labels but that these improvements gradually diminish with more labels. The comment also suggests that the authors should check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment identifies specific areas for improvement and provides a clear direction for the authors to address these concerns, it does not explicitly instruct them to make these changes or provide detailed guidance on how to implement them. The action is implicit but concrete, as the authors know what needs to be done but may require additional effort to fully understand and execute the suggestions. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d)\", allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly details the issue with the analysis of SCL regarding few-shot ability, noting that the results do not meet expectations and suggesting that the authors check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the analysis of SCL in section 5.2 regarding few-shot ability, suggesting that the results in Figure 7(c) and (d) do not meet the authors\\' expectations. It claims that COCO-LM achieves significant improvements with fewer labels but that these improvements gradually diminish with more labels. The comment also suggests that the authors should check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the improvements in Figure 7(c) and (d). This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the analysis of SCL in section 5.2, particularly in the context of few-shot ability. It points out that the results in Figure 7(c) and (d) do not meet the authors' expectations, suggesting that COCO-LM achieves significant improvements with fewer labels but that these improvements gradually diminish with more labels. The comment also provides a suggestion for further investigation, recommending that the authors check if COCO-LM brings benefits to sentence retrieval tasks with the learned anisotropy text representations. This feedback is clear and actionable, offering the authors a direction for improving their analysis and results. However, it could be more helpful if it provided specific guidance on how to address the issues or further details on the expected outcomes. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to a critical area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct more experiments on other LLMs to demonstrate the generalization of the proposed framework. While the action is explicit, it lacks concrete guidance on which specific LLMs to focus on or how to structure these additional experiments. The comment provides a clear direction but does not offer detailed instructions on implementation, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments, but without grounding, the authors may struggle to identify the exact section or context where this feedback is relevant. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting more experiments on other LLMs to demonstrate the generalization of the proposed framework. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on other LLMs to demonstrate the generalization of the proposed framework. While this is a valid suggestion for improving the robustness and applicability of the framework, the comment lacks specificity and does not provide guidance on which specific LLMs to focus on or how to structure these additional experiments. This limits the usefulness of the feedback, as it does not offer actionable steps for the authors to take. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide detailed guidance or suggestions for implementation.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors need to clarify the distinction between short and long videos to determine the appropriate downsample layers. It also recommends conducting an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples that were added. While the comment explicitly states the need for clarification and suggests a specific comparison, it does not provide detailed guidance on how to implement these suggestions. The authors are aware of what needs to be done but may require additional information to fully execute the actions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the need for clarity on the distinction between short and long videos to determine the downsample layers. Additionally, it provides a specific suggestion for improvement by recommending an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to clarify the distinction between short and long videos to determine the appropriate downsample layers. It also recommends conducting an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the need for this clarification or comparison. The claim is somewhat verifiable as it highlights a potential area for improvement but requires more detailed justification or evidence to fully substantiate the need for these changes. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a need for clarification regarding the distinction between short and long videos, which is crucial for determining the appropriate downsample layers. It also suggests conducting an apple-apple comparison of SOTA VLM/ Video-LLM outputs for qualitative examples, providing a specific and actionable recommendation for improvement. This feedback is clear and provides the authors with a clear direction for enhancing their draft, making it mostly helpful. However, it could be more helpful if it included additional details or examples to further guide the authors. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation in terms of efficiency when generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting ways to improve efficiency or optimize the process. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the efficiency of generating multiple objects, which is mentioned in the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation in terms of efficiency, particularly for scenes with a high number of objects or complex interactions. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that generating multiple objects takes longer, depending on the number of objects, indicating a potential limitation in terms of efficiency. However, the comment does not provide any supporting evidence, such as data, examples, or references to similar studies, to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in terms of efficiency when generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This observation is relevant and could help the authors understand the practical implications of their approach. However, the comment lacks specific suggestions or guidance on how to address this limitation or improve efficiency. While it highlights an important area for consideration, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit guidance for the authors, suggesting that they focus on finding additional applications and deeply evaluating their approach. This feedback is concrete and provides a clear direction for improvement, indicating that the authors know exactly what actions to take to enhance their draft. The comment also implies that this could lead to identifying additional properties of the representation that could be emphasized in future versions, further guiding the authors on how to improve the manuscript. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the technical contribution of the paper, specifically mentioning the algorithm proposed and the use of the interpolative decomposition. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that the authors focus on finding additional applications and deeply evaluating their approach, which could lead to identifying additional properties of the representation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution is thin because the algorithm proposed uses an interpolative decomposition that is not proposed by the paper. This claim is somewhat verifiable as it provides a specific observation about the algorithm's novelty. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The suggestion to focus on finding additional applications and evaluating the approach is a logical response to the perceived lack of novelty, but it does not provide specific guidance on how to achieve this. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the technical contribution of the paper, suggesting that the algorithm proposed may be considered incremental due to the use of an interpolative decomposition that is not proposed by the paper. The reviewer provides a constructive suggestion for the authors to focus on finding additional applications and deeply evaluating their approach. This feedback is actionable and provides a clear direction for the authors to enhance the value of their manuscript by exploring new applications and evaluating their approach more thoroughly. However, the comment could be more helpful if it offered specific examples or guidance on how to find these additional applications or evaluate the approach more deeply. Overall, the comment is mostly helpful, as it offers valuable insights and suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to provide details on the neural network library used for implementing the system. This is a clear and direct request, giving the authors a specific action to take. The comment does not provide additional guidance on how to implement this action, but the explicit nature of the request makes it actionable. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"neural network library\" and \"implementation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for details on the neural network library used for implementing the system. This provides full grounding and specificity, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for information, specifically asking the authors to provide details on the neural network library used for implementing the system. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, asking the authors to provide details on the neural network library used for implementing the system. This is a specific and important piece of information that can help readers understand the technical aspects of the work. However, the comment does not offer suggestions or guidance on how to address this issue or improve the draft. While it identifies a gap in the paper, it lacks depth and actionable advice, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some descriptions are unclear, specifically mentioning undefined math notations and missing details in Figure illustrations. It also suggests that the reviewer will provide more details in their questions. While the comment identifies specific areas that need clarification, it does not explicitly instruct the authors to address these issues or provide concrete steps on how to improve them. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the undefined notations and add missing details, but the comment lacks detailed guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the clarity of descriptions, mentioning undefined math notations and missing details in Figure illustrations. However, it does not specify which parts of the paper these issues are found in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying undefined notations and adding missing details in figures. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some descriptions are unclear, specifically mentioning undefined math notations and missing details in Figure illustrations. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address the concerns. The lack of detailed evidence or references leaves the claim somewhat verifiable, as the authors would need to infer the specific areas needing clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific areas where the descriptions are unclear, mentioning undefined math notations and missing details in Figure illustrations. It provides a clear indication of what needs to be addressed, which is helpful for the authors to improve the clarity of their work. However, the comment could be more helpful if it offered suggestions on how to clarify these issues or provided examples of how to address them. Overall, the feedback is somewhat helpful as it directs the authors' attention to specific areas needing improvement but lacks detailed guidance for implementation. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should mention the meaning of the notation \\u03ba in the text, in addition to the explanation provided in Algorithm 1. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to improve the draft. The suggestion is concrete, as it provides a specific element to address, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need to mention the meaning of the notation \\u03ba in the text, in addition to the explanation provided in Algorithm 1. This provides clear guidance on what the authors should include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should mention the meaning of the notation \\u03ba in the text, in addition to the explanation provided in Algorithm 1. This is a request for clarification and does not contain a claim or opinion that requires verification. It is a factual statement that does not require evidence or justification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, namely the lack of explanation for the notation \\u03ba in the text, in addition to the explanation provided in Algorithm 1. This feedback is clear and actionable, as it directs the authors to include the meaning of \\u03ba in the text, which is a crucial step in improving the clarity and comprehensibility of the draft. By addressing this suggestion, the authors can enhance the readability and understanding of their work for readers. Therefore, the comment is mostly helpful, as it provides a specific and actionable piece of feedback that can significantly improve the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an interesting observation about the performance of using noise robust loss on pseudo-labels compared to positive learning from Eq 9. It suggests that the model might be underfit due to the accuracy of pseudo-labels, questioning whether positive learning provides better feedback than a noise robust loss. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to investigate or resolve it. The action is implicit and somewhat vague, as the authors need to infer that they should explore the potential underfitting issue and consider the implications of the pseudo-labels. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment refers to \"appendix A.4\" and mentions \"noise robust loss\" and \"positive learning from Eq 9,\" providing specific references to the parts of the paper being discussed. This allows the authors to accurately identify the sections being addressed, making the comment fully grounded. Additionally, the comment is specific as it questions the performance of the noise robust loss compared to positive learning and speculates on the potential cause of underfitting. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a claim about the performance of using noise robust loss on pseudo-labels compared to positive learning from Eq 9. It suggests that the model might be underfit due to the accuracy of pseudo-labels, questioning whether positive learning provides better feedback than a noise robust loss. However, the comment lacks specific evidence, detailed reasoning, or references to support the claim about the underfitting issue. The authors are left to infer the potential cause of underfitting, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises an interesting observation about the performance of using noise robust loss on pseudo-labels compared to positive learning from Eq 9. It questions whether the model might be underfit due to the accuracy of pseudo-labels, suggesting that positive learning provides better feedback than a noise robust loss. This feedback is somewhat helpful as it prompts the authors to consider the implications of their pseudo-labels and the potential causes of underfitting. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue or further investigate the performance of the models. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim made in line 248, questioning why an additional exponentiation would significantly increase the runtime to the point of being a consideration for the attacker. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the claim. Without actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim about the runtime increase due to an additional exponentiation, providing a clear point of confusion for the authors to address. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about a claim made in the paper regarding the runtime increase due to an additional exponentiation. The reviewer expresses confusion about why this would significantly impact the runtime, questioning the basis of the claim. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or address the reviewer\\'s confusion. As a result, the claim is not verifiable, as it lacks the necessary justification or evidence to support the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about a claim made in the paper regarding the runtime increase due to an additional exponentiation. It expresses confusion about why this would significantly impact the runtime, questioning the basis of the claim. While the comment identifies a potential area of concern, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or clarify the claim. Without actionable feedback or detailed insights, the comment is somewhat helpful, as it prompts the authors to consider revising their explanation but does not fully support their efforts to improve the draft. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of comparison with state-of-the-art (SOTA) methods, specifically mentioning \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" While the comment highlights a potential area for improvement, it does not explicitly instruct the authors to include these comparisons or provide specific guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should compare their methods with these SOTA methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the introduction and abstract sections, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the need for comparisons with related works, such as \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies,\" and questions the lack of comparison with state-of-the-art (SOTA) methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments are lacking in comparison with state-of-the-art (SOTA) methods, specifically mentioning \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" However, the comment does not provide specific details or evidence to support why these comparisons are necessary or how they would enhance the paper. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of comparison with state-of-the-art (SOTA) methods, specifically mentioning \"Rubi: Reducing unimodal biases in visual question answering\" and \"Removing bias in multi-modal classifiers: Regularization by maximizing functional entropies.\" This feedback is valuable as it highlights an area where the authors can significantly enhance the depth and relevance of their work. By suggesting the inclusion of these comparisons, the comment provides clear and actionable guidance for the authors to improve their draft. However, the comment could be more helpful if it offered specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the experiments demonstrate the proposed method\\'s enhancement in performance, but it suggests that this is not surprising because the method introduces more learnable parameters, such as the temperature, which has been proven effective in previous works. While the comment highlights a potential limitation, it does not provide explicit guidance or suggestions for how the authors might address this issue or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond to this observation. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experiments and suggests that the proposed method\\'s performance enhancement is not surprising because it introduces more learnable parameters, such as the temperature, which has been proven effective in previous works. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section being discussed. Additionally, the comment lacks specificity in detailing what aspects of the method or parameters are being discussed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed method\\'s performance enhancement is not surprising because it introduces more learnable parameters, such as the temperature, which has been proven effective in previous works. However, the comment lacks specific references or examples to support the claim that the effectiveness of these parameters has been previously demonstrated. Without detailed evidence or citations, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges that the experiments demonstrate the proposed method's enhancement in performance but suggests that this is not surprising because it introduces more learnable parameters, such as the temperature, which has been proven effective in previous works. While the comment identifies a potential limitation, it lacks actionable feedback or suggestions for how the authors might address this issue or improve their work. Without specific guidance or recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it provides some insight but does not offer actionable advice.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what changes they should make to their work. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not specify which part of the paper this feedback pertains to, such as a specific section, figure, or method. Without explicit references or detailed information, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity regarding what aspects of the inspiration from neuroscience research are unnecessary or distracting. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making it distracting. However, it does not provide any specific examples or detailed feedback on how this inspiration could be simplified or removed. Without actionable suggestions or further explanation, the authors are left without a clear understanding of how to address this issue or improve their work. As a result, the comment is not helpful, as it lacks the depth and specificity needed to guide the authors in enhancing their draft. Therefore, it aligns with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly instructs the authors to update Table 3 by adding information about the source dataset in the caption. It also suggests that the image and table captions should contain all necessary information about the experiment, ensuring that the reader does not need to search for this information in the main text. The comment provides a clear and direct action for the authors to take, making it highly actionable. The feedback is specific and concrete, guiding the authors on exactly what needs to be done to improve the clarity and accessibility of their presentation. Therefore, this comment is rated as highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 3,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the caption, which does not provide information about the source dataset. The comment suggests adding this information to the caption and emphasizes the importance of including all necessary information in the captions to avoid the need for readers to search for it in the main text. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the caption in Table 3 is unclear regarding the source dataset used. It suggests adding information about the source dataset to the caption and emphasizes the importance of including all necessary information in the captions to avoid the need for readers to search for it in the main text. The comment provides a clear and specific suggestion for improvement, which is supported by logical reasoning and a request for clarification. However, it lacks specific references or examples to further substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Table 3, noting that the caption does not provide information about the source dataset used. It provides a clear and actionable suggestion to update the caption to include this information, ensuring that the reader does not need to search for it in the main text. The comment also offers a general piece of advice about the importance of including all necessary information in captions, which is relevant and helpful for improving the clarity and accessibility of the presentation. However, the comment could be more helpful if it provided additional guidance on how to effectively present this information or if it suggested other areas where similar improvements could be made. Overall, the comment is mostly helpful as it directs the authors to a specific issue and offers a clear solution, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the lack of explicit description of the specific architectures of value networks, policy networks, and uncertainty-aware networks used in the paper. It highlights that this omission makes it difficult for readers to replicate and evaluate the applicability of the approach. The comment provides a clear and direct action for the authors to take, which is to include explicit descriptions of these architectures. This guidance is concrete and actionable, as it specifies exactly what needs to be added to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the lack of explicit description of specific architectures, such as value networks, policy networks, and uncertainty-aware networks. This provides full grounding, as the authors can accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of detailed descriptions of these architectures, which is crucial for replicability and evaluation of the approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks explicit descriptions of the specific architectures used for value networks, policy networks, and uncertainty-aware networks. This makes it difficult for readers to replicate and evaluate the approach. The comment is somewhat verifiable as it identifies a specific issue related to the lack of detailed descriptions, which could be addressed by providing more information about the architectures. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of explicit descriptions of the architectures used for value networks, policy networks, and uncertainty-aware networks. This omission makes it difficult for readers to replicate and evaluate the approach. By pointing out this gap, the comment provides clear and actionable feedback that can help the authors improve the clarity and replicability of their work. However, the comment could be more helpful if it offered suggestions on how to provide these descriptions or examples of how to include them. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as assuming the transition model P is true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and assuming learned models are consistent. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve their approach. The comment lacks actionable details, leaving the authors without a clear path to follow for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several assumptions that might make EMCTS inapplicable to real complex problems, such as the assumption of the transition model P being true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and the assumption of consistent learned models. However, it does not specify which part of the paper these assumptions are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in detailing the assumptions that might be problematic, it lacks grounding as it does not explicitly mention the sections or parts of the paper where these assumptions are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some assumptions might make EMCTS inapplicable to real complex problems, citing specific assumptions such as the transition model P being true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and learned models being consistent. However, the comment lacks detailed reasoning or evidence to support why these assumptions are problematic or how they might affect the applicability of EMCTS. While the claim is based on logical reasoning, it would be strengthened by providing specific examples or references to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional details to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as the assumption of the transition model P being true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and the assumption of consistent learned models. This feedback is somewhat helpful as it points out potential limitations in the assumptions underlying the EMCTS approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these issues or improve their approach. Without actionable advice or detailed explanations, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as somewhat helpful, as it highlights areas for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies several assumptions that might make EMCTS inapplicable to real complex problems, such as the assumption of the transition model P being true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and the assumption of consistent learned models. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve their approach. The comment lacks actionable details, leaving the authors without a clear path to follow for improvement. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several assumptions that might make EMCTS inapplicable to real complex problems, such as the assumption of the transition model P being true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and the assumption of consistent learned models. However, it does not specify which part of the paper these assumptions are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in detailing the assumptions that might be problematic, it lacks grounding as it does not explicitly mention the sections or parts of the paper where these assumptions are discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some assumptions might make EMCTS inapplicable to real complex problems, citing specific assumptions such as the transition model P being true, Theorem 1 requiring $Q^{\\pi}$ to be linear, and learned models being consistent. However, the comment lacks detailed reasoning or evidence to support why these assumptions are problematic or how they might affect the applicability of EMCTS. While the claim is based on logical reasoning, it would be strengthened by providing specific examples or references to substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional details to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the relationship between explicitness and size may be related to the dataset, and that the different capacity requirements in the 3rd paragraph could be due to input modality differences. It also implies that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. However, the comment does not explicitly instruct the authors to explore this relationship or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the relationship between explicitness, size, and dataset, and consider the capacity and training time requirements for DCI evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"3rd paragraph,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the relationship between explicitness, size, and the dataset, as well as the potential impact of input modality differences on capacity requirements. The comment further suggests that the evaluation of disentanglement should provide enough capacity and training time and considers the influence of training time, cost, and learning rate on the final value of DCI. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the relationship between explicitness and size may be related to the dataset, and that the different capacity requirements in the 3rd paragraph could be due to input modality differences. It also implies that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The reasoning is somewhat logical, but the lack of detailed evidence or references makes the claim borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a detailed analysis of the relationship between explicitness, size, and the dataset, suggesting that these factors may be highly related. It also points out that the different capacity requirements in the 3rd paragraph could be due to input modality differences. The comment further recommends that the evaluation of disentanglement should provide enough capacity and training time to achieve the DCI evaluation. Additionally, it suggests that if the capacity of probing needs to be evaluated, then the training time, cost, and learning rate may also be considered. This feedback is clear and actionable, offering specific guidance on how the authors can improve their analysis and evaluation. However, it could be more helpful if it provided examples or detailed explanations of how to implement these suggestions. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper title should not include abbreviations. While this is a clear and direct suggestion, it does not provide any specific guidance on why this change is necessary or how it might impact the title. The authors are left with the knowledge that the title should be revised but without detailed instructions on how to make the change. Therefore, the comment is somewhat actionable, as it identifies an action but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper title should not include abbreviations. However, it does not specify which part of the paper this title is associated with, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding why abbreviations should be removed or what impact this change might have on the title. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper title should not include abbreviations. However, it does not provide any reasoning or justification for this claim, such as explaining why abbreviations are unnecessary or how they might affect the title\\'s clarity or professionalism. Without supporting evidence or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the paper title should not include abbreviations. While this is a clear and direct piece of feedback, it does not provide any rationale or explanation for why abbreviations are unnecessary or how their removal might improve the title. Without additional context or reasoning, the authors may find it challenging to understand the significance of this suggestion or how it could impact the overall presentation of their work. Therefore, the comment is somewhat helpful, as it identifies a potential issue but lacks depth and actionable guidance. It aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper title should not include abbreviations. While this is a clear and direct suggestion, it does not provide any specific guidance on why this change is necessary or how it might impact the title. The authors are left with the knowledge that the title should be revised but without detailed instructions on how to make the change. Therefore, the comment is somewhat actionable, as it identifies an action but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper title should not include abbreviations. However, it does not specify which part of the paper this title is associated with, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity regarding why abbreviations should be removed or what impact this change might have on the title. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper title should not include abbreviations. However, it does not provide any reasoning or justification for this claim, such as explaining why abbreviations are unnecessary or how they might affect the title\\'s clarity or professionalism. Without supporting evidence or explanation, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the paper title should not include abbreviations. While this is a clear and direct piece of feedback, it does not provide any rationale or explanation for why abbreviations are unnecessary or how their removal might improve the title. Without additional context or reasoning, the authors may find it challenging to understand the significance of this suggestion or how it could impact the overall presentation of their work. Therefore, the comment is somewhat helpful, as it identifies a potential issue but lacks depth and actionable guidance. It aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the paper title should not include abbreviations. While this is a clear and direct suggestion, it does not provide any specific guidance on why this change is necessary or how it might impact the title. The authors are left with the knowledge that the title should be revised but without detailed instructions on how to make the change. Therefore, the comment is somewhat actionable, as it identifies an action but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper title should not include abbreviations, but it does not specify which part of the paper this"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore whether the discriminator can transfer to other tasks and domains without further training and whether it can be effectively trained with very little data. It also mentions that the authors have already shown in the paper that the discriminator can be small, which is an important insight. While the comment implies that these aspects should be discussed, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that these points should be addressed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L400,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should discuss whether the discriminator can transfer to other tasks and domains without further training and whether it can be effectively trained with very little data. Additionally, it highlights the importance of the insight that the discriminator can be small. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should explore whether the discriminator can transfer to other tasks and domains without further training and whether it can be effectively trained with very little data. It also mentions that the authors have already shown in the paper that the discriminator can be small, which is an important insight. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or justification makes it difficult for the authors to fully understand and address the suggestions. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a suggestion for further exploration by the authors, specifically regarding the transferability of the discriminator to other tasks and domains without further training, and whether it can be effectively trained with very little data. It also highlights an important insight mentioned in the paper, namely that the discriminator can be small. While the comment identifies an area for improvement, it does not offer specific guidance or suggestions on how to address these points. The feedback is somewhat helpful as it points out potential areas for expansion but lacks detailed actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the current SOTA GNN-QE should be included as a baseline and compared with the proposed approach. This is a clear and direct action for the authors to take, providing them with a specific and concrete instruction on how to improve their draft. The comment does not leave any ambiguity or require the authors to infer the action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the current SOTA GNN-QE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the current SOTA GNN-QE as a baseline and its comparison with the proposed approach. This provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the current SOTA GNN-QE should be included as a baseline and compared with the proposed approach, but it does not provide any reasoning or evidence to support why this is necessary. The comment lacks specific examples or references to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or explanation, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant omission in the paper by pointing out that the current state-of-the-art (SOTA) GNN-QE is not included as a baseline, despite being the closest work in terms of components to the proposed approach. This is a critical observation that could impact the comprehensiveness and validity of the study. The comment suggests that including the SOTA GNN-QE as a baseline would be beneficial for a fair comparison. This feedback is clear and actionable, as it provides a specific recommendation for improvement that could enhance the paper\\'s rigor and relevance. However, the comment could be more helpful if it offered additional guidance on how to integrate this baseline or what specific aspects of the SOTA GNN-QE should be compared with the proposed approach. Overall, the comment is mostly helpful, as it directs the authors to a significant area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the pretraining data and its impact on GPT-2 understanding language. It suggests that the authors address these concerns to prove the correctness of their findings. However, the comment does not provide explicit guidance on how to address these concerns or what specific actions should be taken. The authors are left to infer that they need to provide evidence or explanations to support their claims, but the lack of concrete details makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the pretraining data and its impact on GPT-2 understanding language. It suggests that the authors should address this issue to prove the correctness of their findings. However, the comment does not specify which part of the paper discusses the pretraining data or the specific aspects that need clarification. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique, as it highlights a potential issue with the pretraining data and its impact on GPT-2. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the pretraining data and its impact on GPT-2 understanding language. It suggests that the authors should address this issue to prove the correctness of their findings. However, the comment lacks specific evidence or references to support the claim that GPT-2 cannot understand language with the pretraining data mentioned. The reasoning is based on a subjective assumption rather than a logical argument or empirical evidence. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the pretraining data and its impact on GPT-2 understanding language, suggesting that the authors should address this issue to prove the correctness of their findings. While the comment identifies a potential weakness in the methodology, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is somewhat helpful as it points out an area for improvement, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is not thoroughly explained, specifically mentioning the missing computation of terms in equation (4) and the optimization algorithm. It also suggests that every term in the math formulas should be clearly explained, except for those that are extremely obvious. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should provide detailed explanations for the missing computations and optimization steps. However, the comment lacks concrete guidance on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (4)\" and \"optimization algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the missing computation of terms in equation (4) and the optimization algorithm, including the calculation of $p(x_k|d)$. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not thoroughly explained, specifically mentioning the missing computation of terms in equation (4) and the optimization algorithm. The reviewer provides a logical reasoning by suggesting that every term in the math formulas should be clearly explained, except for those that are extremely obvious. This reasoning is clear and provides a basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is mostly verifiable, as it provides a strong foundation for the claim but lacks detailed examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the clarity and completeness of the proposed method. It points out that the computation of some terms in equation (4) is missing, along with the optimization algorithm, specifically mentioning the calculation of $p(x_k|d)$. This feedback is clear and actionable, as it directs the authors to provide detailed explanations for these missing components, which are crucial for understanding the method. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the explanations or provided examples of how to address these issues. Overall, the comment is mostly helpful as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments makes the experimental results non-reproducible. It also highlights the difficulty in assessing the fairness of comparison with existing methods and the significance of the experimental results due to the lack of implementation details. The comment provides a clear and concrete action for the authors to take, which is to provide a thorough description of the implementation details. This guidance is explicit and provides a clear path for the authors to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses several specific aspects of the paper, including the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It also highlights the difficulty in assessing the fairness of comparison with existing methods and the significance of the experimental results due to the lack of implementation details. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed, such as providing implementation details. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental results are not reproducible due to the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. The reviewer also notes that the lack of implementation details makes it difficult to assess the fairness of comparison with existing methods and the significance of the experimental results. While the comment highlights the importance of providing implementation details, it does not provide specific examples or references to support the claim that the results are not reproducible or that the comparisons are unfair. This makes the claim somewhat verifiable, as it lacks detailed evidence or examples to fully substantiate the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's reproducibility, specifically noting the lack of implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. This lack of detail makes the experimental results non-reproducible, which is a significant concern for the validity and impact of the study. The comment also highlights the difficulty in assessing the fairness of comparison with existing methods and the significance of the experimental results due to the lack of implementation details. By pointing out these issues, the comment provides clear and actionable feedback, encouraging the authors to include detailed implementation information. This guidance is valuable as it helps the authors improve the reproducibility and credibility of their work, making the comment mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks like general LLM, summarization, and machine translation. However, it notes that the application of MoE in text detection is relatively new, implying that the authors should be aware of this context. While the comment provides some context, it does not explicitly instruct the authors to make any changes or improvements to their draft. The action is implicit and vague, as the authors are left to infer that they should be aware of the context but are not given specific guidance on how to address it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment discusses the concept of employing a mixture of experts (MoE) in various tasks, including general LLM, summarization, and machine translation, and notes that its application in text detection is relatively new. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its observation about the novelty of MoE in text detection, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. This claim is supported by logical reasoning, as it provides a clear explanation of the widespread use of MoE in different contexts, which helps the authors understand the context and relevance of the application in text detection. However, the comment could be strengthened by providing specific examples or references to these applications, which would make it fully verifiable. Therefore, the comment is mostly verifiable, as it provides a strong basis for the claim but lacks full detail.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment acknowledges that the concept of employing a mixture of experts (MoE) is not unusual, as it has been widely applied in various tasks such as general LLM, summarization, and machine translation. It notes that while the application of MoE in text detection is relatively new, it is not a groundbreaking concept in terms of its fundamental idea. This feedback provides some context and perspective on the novelty of the application in text detection, which could be helpful for the authors to consider. However, the comment lacks specific suggestions or actionable advice on how the authors might address this issue or improve their work. As a result, while it offers some insight, it does not fully support the authors in enhancing their draft, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper\\'s methodology, specifically the lack of statistical analysis to support the claim of significant performance improvement for SpaceTGN compared to other baselines. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to conduct the statistical analysis or which specific tests should be performed. The action is implicit, as the authors need to infer that they should include statistical analysis to substantiate their claims. However, the comment is somewhat actionable because it clearly identifies the need for statistical support, but the authors are left to determine the exact steps to take. Therefore, this comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim of significant performance improvement for SpaceTGN compared to other baselines, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of statistical analysis to support this claim. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' assertion of significant performance improvement for SpaceTGN is not supported by statistical analysis. This claim is somewhat verifiable as it identifies a gap in the methodology but lacks specific details or examples of what statistical analysis should be conducted to substantiate the claim. The comment suggests that the authors should include statistical analysis to support their claims, but it does not provide explicit guidance on which statistical methods to use or how to conduct the analysis. This makes the claim somewhat verifiable, as it highlights a critical area for improvement but requires further elaboration for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical gap in the paper's methodology by pointing out that the authors claim significant performance improvement for SpaceTGN compared to other baselines, but they do not provide statistical analysis to support this claim. This feedback is valuable as it highlights a potential weakness in the paper's evidence and suggests a necessary step for the authors to strengthen their claims. However, the comment could be more helpful if it provided guidance on how to conduct the statistical analysis or which specific tests should be performed. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential source of confusion regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify or reorganize the presentation of scores to resolve the confusion. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the clarity of presenting scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in terms of the issue it raises, it lacks grounding as it does not provide explicit references to the parts of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of presenting scores, specifically questioning why certain scores are excerpted versus reproduced. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the presentation of scores, specifically questioning why certain scores are excerpted versus reproduced. While it points out a potential issue, it lacks depth and does not provide specific suggestions or guidance on how the authors might clarify or improve this aspect of their draft. Without actionable feedback or detailed advice, the comment does not effectively assist the authors in enhancing their work. Therefore, it is rated as barely helpful, as it provides some insight but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the novelty of the method, specifically noting that it is somewhat similar to existing generative models. It suggests that the authors should provide more explanation on how consistency models achieve something that previous generative models cannot. While the comment implies that the authors should clarify the novelty of their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context on the novelty of their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the novelty of the method, specifically noting that it is somewhat similar to existing generative models. It suggests that the authors should provide more explanation on how consistency models achieve something that previous generative models cannot. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment is specific in its suggestion to provide more explanation on the novelty of the method, it lacks grounding as it does not reference specific parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the novelty of the method, specifically noting that it is somewhat similar to existing generative models. It suggests that the authors should provide more explanation on how consistency models achieve something that previous generative models cannot. However, the comment lacks specific examples or references to support the claim that consistency models are a recent rising trend or that they achieve something unique. The suggestion to provide more explanation is a logical inference but lacks detailed justification or evidence. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the method, noting that it is somewhat similar to existing generative models. It suggests that the authors should provide more explanation on how consistency models achieve something that previous generative models cannot. This feedback is somewhat helpful as it points out a potential weakness in the novelty of the approach and offers a specific suggestion for improvement. However, the comment could be more helpful if it provided more detailed guidance or examples on how to enhance the novelty of the method. Overall, the comment provides a direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation metric in Table 2 only uses MSE, which does not accurately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue. There is no guidance on whether they should consider additional metrics, modify the existing ones, or provide a more detailed explanation of the limitations of MSE. Without specific actions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that the use of MSE alone does not accurately reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric in Table 2 only uses MSE, which does not accurately reflect the accuracy of nowcasting. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the evaluation metric used in Table 2, noting that it only uses MSE, which may not accurately reflect the accuracy of nowcasting. This feedback is somewhat helpful as it points out a potential limitation in the evaluation process. However, it lacks depth and does not provide suggestions on how the authors might address this issue or improve the evaluation metric. Without additional guidance or actionable advice, the comment provides some insight but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the evaluation metric in Table 2 only uses MSE, which may not accurately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue, such as recommending the inclusion of additional metrics or suggesting ways to improve the evaluation process. Without specific guidance or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation metric, noting that the use of MSE alone does not accurately reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the evaluation metric in Table 2 only uses MSE, which may not accurately reflect the accuracy of nowcasting. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the evaluation metric used in Table 2, noting that it only uses MSE, which may not accurately reflect the accuracy of nowcasting. This feedback is somewhat helpful as it points out a potential limitation in the evaluation process. However, it lacks depth and does not provide suggestions on how the authors might address this issue or improve the evaluation metric. Without additional guidance or actionable advice, the comment provides some insight but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the evaluation metric in Table 2 only uses MSE, which may not accurately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions for how the authors should address this issue, such as recommending the inclusion of additional metrics or suggesting ways to improve the evaluation process. Without specific guidance or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2,\""}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP) and points out that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains the same across various privacy budgets, including $\\epsilon = 0$. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their empirical evaluation. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP), specifically mentioning the performance gap between the vanilla LoRA and the proposed FFA-LoRA. It highlights that the performance gap remains the same across various privacy budgets, including $\\epsilon = 0$. This provides some grounding as it refers to a specific aspect of the paper, but it does not specify which part of the paper this evaluation is based on, such as a particular section or figure. The comment is specific in detailing the issue with the empirical evaluation, but the lack of explicit grounding makes it weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the benefit of FFA-LoRA on differential privacy (DP) is not well backed by empirical evaluation, as the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains the same across various privacy budgets, including $\\epsilon = 0$. The reviewer provides a logical reasoning by pointing out that the empirical result suggests that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA. This reasoning is clear and provides a basis for the claim, making the comment mostly verifiable. However, it could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the empirical evaluation of the benefit of FFA-LoRA on differential privacy (DP). It points out that the performance gap between the vanilla LoRA and the proposed FFA-LoRA remains the same across various privacy budgets, including $\\epsilon = 0$. This observation suggests that the impact of DP noise is the same on both the vanilla LoRA and the proposed FFA-LoRA, which is a critical finding that could impact the validity of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their empirical evaluation. While it highlights a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add specific ablation studies to the existing ablation study of ENGINE. It provides a clear and concrete suggestion by specifying the additional combinations of Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA that should be included. Additionally, it recommends giving more detailed analysis to the ablation results. This feedback is explicit and provides clear guidance on how the authors can improve their draft by expanding the ablation study and offering more detailed analysis. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ablation study of ENGINE,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be added by suggesting the inclusion of specific combinations of Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA, as well as recommending more detailed analysis of the ablation results. This provides clear guidance on how to improve the ablation study, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the ablation study of ENGINE is incomplete and provides specific suggestions for additional combinations to include. It also recommends giving more detailed analysis to the ablation results. While the comment provides a clear suggestion for improvement, it lacks specific references or detailed reasoning to fully substantiate the claim that the ablation study is incomplete. The suggestion is based on the reviewer\\'s understanding of the study\\'s scope, but without additional evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper by noting that the ablation study of ENGINE is incomplete. It provides a clear and actionable suggestion for the authors to include additional combinations, such as Cap-CapNE-ClipNE-EA and Cap-CapNE-ClipNE-NE-EA, based on the overview model of ENGINE. Additionally, the comment recommends giving more detailed analysis to the ablation results, which is a constructive and specific piece of feedback. This feedback is highly helpful as it guides the authors on how to enhance the completeness and depth of their analysis, thereby improving the quality of their draft. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the mode coverage in GAN optimization, specifically why it is poor in GDIM and good in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. While the comment implies that the authors should include these additional results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more challenging datasets to support their findings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the mode coverage in GAN optimization, specifically why it is poor in GDIM and good in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this is not explicit. The comment is specific in detailing what additional results would be beneficial, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the mode coverage in GAN optimization, specifically why it is poor in GDIM and good in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. The claim is based on the observation that methods that work well with certain datasets might struggle with others. However, the comment lacks specific references or detailed reasoning to support the claim that methods working with CIFAR-10/Celeb-64 might have a hard time with LSUN/ImageNet. This makes the claim somewhat verifiable, as it provides a logical basis but requires further substantiation with evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the mode coverage in GAN optimization, specifically why it is poor in GDIM and good in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting additional experiments that could enhance the robustness of the results. However, the comment could be more helpful if it provided specific guidance on how to conduct these additional experiments or what aspects of the results should be emphasized. Overall, the comment offers a direction for improvement but lacks depth and detail, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the mode coverage in GAN optimization, specifically why it is poor in GDIM and good in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. While the comment implies that the authors should include these additional results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more challenging datasets to support their findings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the mode coverage in GAN optimization, specifically why it is poor in GDIM and good in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this is not explicit. The comment is specific in detailing what additional results would be beneficial, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the mode coverage in GAN optimization, specifically why it is poor in GDIM and good in DDGAN. It suggests that providing results on more challenging high-resolution datasets like LSUN and ImageNet would make the findings more convincing. The claim is based on the observation that methods that work well with certain datasets might struggle with others. However, the comment lacks specific references or detailed reasoning to support the claim that methods working with CIFAR-10/Celeb-64 might have a hard time with LSUN/ImageNet. This makes the claim somewhat verifiable, as it provides a logical basis but requires further substantiation with evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"Each attribute of the table feature represents a scene\" in Section 5.1. While it prompts the authors to clarify this point, it does not provide explicit guidance on how to address the issue or what specific clarification is needed. The action is implicit and somewhat vague, as the authors are left to infer that they should provide a clearer explanation of the concept. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the meaning of \"Each attribute of the table feature represents a scene.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on a specific aspect of the paper, \"Each attribute of the table feature represents a scene.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry that does not claim or imply any particular stance or conclusion. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the interpretation of a statement in Section 5.1, specifically regarding the meaning of \"Each attribute of the table feature represents a scene.\" While it identifies a potential area of confusion, it does not provide any additional context or suggestions for clarification. The comment lacks depth and actionable guidance, leaving the authors with a basic understanding of what needs to be clarified but no clear direction on how to address it. Therefore, it is rated as somewhat helpful, as it points out a specific area for improvement but does not offer detailed feedback or suggestions for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It suggests that the authors should provide such a study to determine the relative benefits of each method. Additionally, it questions the compatibility of the token reweighting scheme with existing token-to-token classifiers like CTX and FRN, and it asks for clarification on how the logsumexp aggregator compares to direct addition. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to conduct the ablation study or compare the aggregation schemes. The authors are left to infer that they should include these comparisons, but the lack of detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ablation study\" and \"logsumexp aggregation scheme,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of comparison between the logsumexp aggregation and direct addition, as well as the compatibility of the token reweighting scheme with existing classifiers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It questions the relative benefits of each method and suggests that the authors should provide such a study. Additionally, it points out the compatibility of the token reweighting scheme with existing classifiers and asks for clarification on how the logsumexp aggregator compares to direct addition. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim about the relative benefits of the methods. The suggestion for an ablation study is clear, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study comparing the impact of token reweighting versus the logsumexp aggregation scheme. It questions the relative benefits of these methods and suggests that the authors should provide such a study to better understand their performance. Additionally, the comment highlights the compatibility of the token reweighting scheme with existing classifiers and asks for clarification on how the logsumexp aggregator compares to direct addition. This feedback is clear and actionable, as it directs the authors to conduct a specific analysis that could significantly enhance the paper's depth and rigor. However, the comment could be more helpful if it provided examples or guidance on how to conduct the ablation study. Overall, the comment is mostly helpful as it identifies a critical area for improvement and offers a clear direction for the authors to follow.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limitation of the current dataset size and suggests considering larger-scale datasets from references [1] and [2]. While the comment implies that the authors should expand their dataset to include these larger-scale datasets, it does not provide explicit instructions on how to do so or what specific aspects of the datasets should be expanded. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the limitation of the current dataset size, suggesting that the authors should consider using larger-scale datasets from references [1] and [2]. However, it does not specify which part of the paper discusses the datasets or how the authors should incorporate these suggestions. The authors can infer that the comment pertains to the dataset section or experimental setup, but this inference is not explicit. The comment is specific in suggesting the use of specific datasets, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the current dataset size is insufficient to evaluate the effectiveness of ECGs and suggests considering larger-scale datasets from references [1] and [2]. The claim is supported by references to specific works that provide larger-scale datasets, which gives some verifiability. However, the comment could be strengthened by providing more detailed reasoning or examples of how the larger-scale datasets would improve the evaluation. Therefore, the comment is mostly verifiable, as it provides a logical basis for the claim but lacks full detail.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a limitation in the current dataset size, noting that only five datasets are used to evaluate the effectiveness of ECGs. It suggests considering larger-scale datasets from references [1] and [2], which could provide more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to expand their dataset to include larger-scale datasets, thereby enhancing the robustness and generalizability of their results. However, the comment could be more helpful if it provided specific guidance on how to incorporate these datasets or what aspects of the evaluation would benefit from this expansion. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper should acknowledge the limitation of analyzing only fully connected ResNets and include this in the Broader Impact section. This provides a clear and direct action for the authors to take, as it specifies what needs to be addressed and where it should be addressed. The comment is explicit and concrete, giving the authors a straightforward path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the paper, namely the analysis of fully connected ResNets, which is not representative of the typical use of ResNets in practice. It suggests that the authors should acknowledge this limitation and include it in the Broader Impact section. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the limitations or broader impact sections. The suggestion to include this limitation in the Broader Impact section provides a clear direction for improvement. However, the comment lacks specificity in terms of how the limitation should be addressed or what specific aspects should be discussed in the Broader Impact section. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper only analyzes fully connected ResNets, which is not representative of the typical use of ResNets in practice. The comment suggests that the authors should acknowledge this limitation and include it in the Broader Impact section. While the claim is logical and based on common knowledge about ResNet architectures, it lacks specific examples or references to support the assertion that fully connected ResNets are not typical. The suggestion to include this limitation in the Broader Impact section is a reasonable one, but the comment could be strengthened with more detailed reasoning or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the paper, noting that it only analyzes fully connected ResNets, which is not representative of the typical use of ResNets in practice. It suggests that the authors should acknowledge this limitation and include it in the Broader Impact section. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the comprehensiveness and relevance of their work. By highlighting this limitation, the comment helps the authors to better understand the scope of their analysis and how it relates to broader implications. Therefore, the comment is rated as highly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10, and mentions that standard knowledge distillation (KD) methods have surpassed the reported KD performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this information or what changes they should make to their draft. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the performance of a student model trained on the training set, specifically mentioning the use of ResNet18 as a medium-sized model. It compares the model\\'s performance on MNIST, SVHN, and CIFAR10 datasets, referencing standard knowledge distillation (KD) methods. However, the comment does not specify which part of the paper this information is relevant to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment provides some specificity in terms of the datasets and methods mentioned, it lacks full grounding due to the lack of explicit references to specific parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. It also mentions that early KD methods have surpassed the reported KD performance. However, the comment does not provide specific examples or references to support the claim that the student model\\'s performance is not as strong as expected. While the general comparison is informative, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a detailed comparison of the student model's performance on various datasets, including MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. It highlights that early KD methods have surpassed the reported KD performance. However, the comment does not offer specific suggestions or guidance on how the authors might improve their model's performance or address the comparison. While it provides valuable information, the lack of actionable feedback limits its usefulness for the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment provides a detailed comparison of the student model's performance on various datasets, including MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. It highlights that early KD methods have surpassed the reported KD performance. However, the comment does not provide any explicit or implicit actions for the authors to take, such as suggesting improvements or changes to their model or methodology. Without actionable guidance, the authors are left without a clear direction for addressing the feedback. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the performance of a student model trained on the training set, specifically mentioning the use of ResNet18 as a medium-sized model. It compares the model\\'s performance on MNIST, SVHN, and CIFAR10 datasets and references standard knowledge distillation (KD) methods. However, the comment does not specify which part of the paper this information is relevant to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment provides some specificity in terms of the datasets and methods mentioned, it lacks full grounding due to the lack of explicit references to specific parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point provides a detailed comparison of the student model\\'s performance on various datasets, including MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods. It highlights that early KD methods have surpassed the reported KD performance. However, the comment does not provide specific examples or references to support the claim that the student model\\'s performance is not as strong as expected. While the general comparison is informative, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a detailed comparison of the student model"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically mentions that some GCN variants, such as Geniepath and Gated GNN, learn the message and passing routes in a coupled way, which could potentially break the causal graph assumption. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or whether it is a significant concern. The action is implicit and vague, as the authors are left to infer that they need to consider the implications of these GCN variants on their framework. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically mentions Geniepath and Gated GNN as examples of GCN variants that learn the message and passing routes in a coupled way, which could potentially break the causal graph assumption. However, the comment does not specify which part of the paper this assumption is made in, making it weakly grounded. The authors can infer that it relates to the methodology or assumptions section, but this is not explicitly mentioned. The comment is specific in detailing the issue with the causal graph assumption and the potential implications of certain GCN variants. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically mentions Geniepath and Gated GNN as examples of GCN variants that learn the message and passing routes in a coupled way, which could potentially break the causal graph assumption. However, the comment does not provide specific evidence or references to support the claim that these GCN variants indeed break the causal graph assumption. The mention of Geniepath and Gated GNN provides some context, but the lack of detailed reasoning or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically mentions Geniepath and Gated GNN as examples of GCN variants that learn the message and passing routes in a coupled way, which could potentially break the causal graph assumption in the proposed framework. This feedback is valuable as it challenges the authors' assumptions and prompts them to consider the implications of these GCN variants on their framework. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or explore alternative approaches. Overall, the comment is mostly helpful as it identifies a significant area for consideration and improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a list of the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1. This action is explicit and concrete, as it clearly instructs the authors to include specific information that would help readers understand the gap between NAS models and human-engineered SOTA architectures. The comment provides a clear and actionable suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, such as pre-processing, message-passing, and post-processing, which are relevant to the discussion of graph neural networks (GNNs). It also mentions the importance of message-passing layers and suggests that the authors should list the performance of SOTA algorithms in each dataset discussed in Table 1. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the inclusion of performance data for SOTA algorithms in the datasets. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should include the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1 to better understand the gap between NAS models and human-engineered SOTA architectures. The comment provides a logical reasoning by pointing out that different tasks may require different pre- and post-processing modules, which could affect the performance of message-passing layers. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of this suggestion based on the general logic provided, which limits the level of verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by pointing out that the authors have only considered message-passing layers and that it is commonly regarded as the most important part of graph neural networks (GNNs). However, the comment notes that different tasks may require different pre- and post-processing modules, which could affect the performance of message-passing layers. To address this, the reviewer suggests that the authors should list the performance of state-of-the-art (SOTA) algorithms in each dataset discussed in Table 1. This feedback is clear and actionable, as it provides a specific suggestion for improving the comprehensiveness of the analysis. By including performance data for SOTA algorithms, the authors can better illustrate the gap between NAS models and human-engineered SOTA architectures. Therefore, the comment is rated as mostly helpful, as it offers a clear direction for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be useful to demonstrate the advantage of learning directly, given the claim that the advantage is a quantity of interest. However, it does not provide explicit guidance on how to show this or what specific evidence should be included. The action is implicit and somewhat vague, as the authors can infer that they need to provide more evidence, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be useful to demonstrate the advantage of learning directly, given the claim that the advantage is a quantity of interest. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors can infer that it relates to the discussion of the advantage, but without explicit references, it remains challenging to pinpoint the exact area needing attention. The comment is specific in its suggestion to show the advantage of learning directly, but it lacks grounding, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be useful to demonstrate the advantage of learning directly, given the claim that the advantage is a quantity of interest. However, it does not provide specific examples or evidence to support why this is important or how it could be demonstrated. The comment lacks detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that it would be beneficial to demonstrate the advantage of learning directly, given the claim that the advantage is a quantity of interest. It questions the importance of learning it directly with the proposed method compared to other methods. This feedback is somewhat helpful as it identifies a potential area for improvement and highlights a gap in the paper's evidence. However, it lacks specific guidance on how to demonstrate the advantage or what evidence should be provided. The authors are left with a general suggestion but without detailed instructions on how to implement it, making the comment somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding explanations about the meaning of variable symbols like \u03c2, r_i, \u03b1_i, etc., in the appended algorithms. While the comment implies that these explanations should be included, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to provide these explanations, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, etc., in the appended algorithms. However, it does not specify which part of the paper these symbols are used in or where these explanations should be added. This makes it difficult for the authors to identify the exact sections that need revision. While the comment implies that the authors should provide these explanations, it lacks specificity and does not provide clear guidance on how to address the issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests adding explanations about the meaning of variable symbols in the appended algorithms. However, it does not provide any specific examples or reasoning to support why these explanations are necessary or how they would improve the paper. Without detailed justification or references, the claim lacks verifiability. The authors would need to infer the importance of these explanations, making the comment barely verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests adding explanations about the meaning of variable symbols such as \u03c2, r_i, \u03b1_i, etc., in the appended algorithms. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by providing clearer definitions for these symbols. However, the comment lacks depth and does not offer specific suggestions on how to enhance the explanations or what aspects of the symbols' meanings are unclear. To be more helpful, the comment could provide examples of how these explanations could be improved or what specific information should be included. Therefore, the comment is rated as somewhat helpful, as it points out a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the limited performance gains indicate a lack of innovation in the method, which may only represent incremental changes to established methods. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the innovation of their method. The comment lacks actionable details, leaving the authors without a clear path forward. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the limited performance gains of the method, suggesting that it lacks innovation and may only represent incremental changes to established methods. However, it does not specify which part of the paper discusses the performance gains or the innovation of the method, making it weakly grounded. The comment is specific in its critique of the method\\'s lack of innovation, but without grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the limited performance gains suggest a lack of innovation in the method, which may only represent incremental changes to established methods. However, the comment does not provide specific examples or evidence to support this claim, such as comparisons with existing methods or detailed analysis of the performance gains. Without additional context or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the limited performance gains of the method, suggesting that it may lack innovation and represent incremental changes to established methods. This feedback is somewhat helpful as it points out a critical area for improvement, namely the need for more significant innovation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the innovation of their method. Without actionable advice, the authors may find it challenging to effectively respond to this feedback. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback implies that the authors should conduct a broader comparison to provide a clearer picture of the relative strengths and weaknesses of their proposed system. While the action is explicit, it lacks concrete guidance on how to conduct this analysis or which specific methods or systems to compare with. The authors are aware of the need for a comparative analysis but may need additional direction on how to implement it effectively. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or table where such analysis could be included. This lack of grounding makes it difficult for the authors to identify the exact area where the suggestion applies. The comment is specific in its suggestion to conduct a comparative analysis, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, indicating that a comparative analysis would help clarify the strengths and weaknesses of the proposed system. However, the comment lacks specific examples or references to existing methods or systems for comparison, which would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by comparing their proposed system with others. By conducting such an analysis, the authors could better understand the relative strengths and weaknesses of their system, which could lead to improvements in its design and functionality. However, the comment could be more helpful if it provided examples of existing methods or systems that could be compared with, or if it suggested specific aspects of the analysis that should be focused on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the practical usefulness of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ due to its theoretical guarantees and limited performance on the real dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the performance of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the performance of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ on the real dataset. It explicitly mentions \"long-range graph benchmark,\" which allows the authors to accurately identify the part of the paper being discussed. However, the comment does not specify what needs to be addressed in terms of improving the performance or the theoretical guarantees. While the authors can infer that the performance needs to be improved, the comment lacks specificity in detailing the exact issues or suggestions for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prediction performance of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ does not outperform existing methods on the real dataset, which limits its practical usefulness. However, the comment lacks specific examples or references to existing methods for comparison, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient support or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ on the real dataset, noting that it does not outperform existing methods. This is a relevant observation that could help the authors understand the limitations of their approach. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the performance of the method. Without specific recommendations or steps for improvement, the feedback is somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a concern regarding the performance of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ on the real dataset, noting that it does not outperform existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the performance of their method. Without specific guidance or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the performance of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ on the real dataset. It explicitly mentions \"long-range graph benchmark,\" which allows the authors to accurately identify the part of the paper being discussed. However, the comment does not specify what needs to be addressed in terms of improving the performance or the theoretical guarantees. While the authors can infer that the performance needs to be improved, the comment lacks specificity in detailing the exact issues or suggestions for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the prediction performance of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ does not outperform existing methods on the real dataset, which limits its practical usefulness. However, the comment lacks specific examples or references to existing methods for comparison, making it difficult for the authors to understand the basis of the claim. Without detailed evidence or references, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient support or evidence to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance of $\\mathrm{PH-GDN}_{\\mathrm{C}}$ on the real dataset, noting that it does not outperform existing methods. This is a relevant observation that could help the authors understand the limitations of their approach. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the performance of the method. Without specific recommendations or steps for improvement, the feedback is somewhat helpful but incomplete. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, stating that it is unfair because the target of those algorithms is not to find an equilibrium. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their comparison. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, stating that it is unfair because the target of those algorithms is not to find an equilibrium. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on how the comparison is unfair or what specific aspects of the comparison are problematic. This lack of grounding and specificity makes it difficult for the authors to identify the exact part of the paper that needs revision and how to address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agents because the target of those algorithms is not to find an equilibrium. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how it affects their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agents, stating that it is unfair because the target of those algorithms is not to find an equilibrium. While the comment identifies a potential issue with the comparison, it lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. Without actionable feedback or detailed explanations, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a potential weakness but does not provide sufficient guidance for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the paper should clarify its unique contributions in methodology and purpose by providing more detailed comparisons to similar works. It explicitly states that the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks, implying that the authors should address this overlap. The comment also provides a specific suggestion to include more detailed comparisons to similar works, which are referenced as [1-4]. This guidance is clear and concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment addresses the overlap with prior work, specifically mentioning the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and their coverage in prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose, with more detailed comparisons to similar works. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the methodology or related work sections. The suggestion to include more detailed comparisons is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. It suggests that the paper should clarify its unique contributions in methodology and purpose, with more detailed comparisons to similar works. The comment provides references to prior works [1-4], which supports the claim by offering examples of related studies. However, the comment could be strengthened by providing more detailed comparisons or specific examples of how the paper's contributions differ from these prior works. Despite this, the general direction and the references to prior works make the claim mostly verifiable, as the authors can follow up on the references to gain a clearer understanding of the comparison. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential overlap with prior work in the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014and suggests that the paper should clarify its unique contributions in methodology and purpose. It provides a specific recommendation to include more detailed comparisons to similar works, referencing [1-4] as examples. This feedback is clear and actionable, offering the authors a concrete way to enhance the originality and impact of their work. By addressing this suggestion, the authors can better position their paper within the existing literature, making the comment highly helpful. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the statement \"human perception is usually invariant to the texture resampling\" in Section 1 lacks support materials. However, it does not provide any explicit or implicit guidance on what specific support materials are needed or how to incorporate them. The comment lacks actionable details, leaving the authors uncertain about what steps to take to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of support materials for the statement \"human perception is usually invariant to the texture resampling.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement \"human perception is usually invariant to the texture resampling\" lacks support materials. However, the comment does not provide any specific examples, references, or reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that the statement 'human perception is usually invariant to the texture resampling' lacks support materials in Section 1. This feedback is clear and actionable, as it directs the authors to provide additional evidence or references to support this claim. However, the comment could be more helpful if it suggested specific types of support materials or examples that could be included. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks, particularly by conducting additional experiments on a broader range of tasks. This feedback is explicit, as it directly instructs the authors to expand their experimental scope. The action is also concrete, as it provides a clear direction for the authors to enhance the generalizability of their method. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the generality of the paper, specifically mentioning the MiPKD method and its application to SR tasks. It suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks, which is a specific and actionable suggestion. However, the comment does not explicitly mention which part of the paper this feedback pertains to, such as a specific section or experiment. While the authors can infer that it relates to the discussion or results sections, this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper\\'s focus on MiPKD\\'s performance in SR tasks may not fully demonstrate its generality, as it is not specifically designed for SR tasks. The reviewer recommends conducting additional experiments on a broader range of tasks to enhance the method\\'s perceived generalizability. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that MiPKD is not designed for SR tasks. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's focus on MiPKD's performance in SR tasks, suggesting that the method may not be specifically designed for this task. It provides a clear and actionable suggestion for the authors to demonstrate the applicability of MiPKD to other CV tasks by conducting additional experiments on a broader range of tasks. This feedback is valuable as it guides the authors in expanding the scope of their work and enhancing its perceived generalizability. However, the comment could be more helpful if it provided specific examples of other CV tasks or suggested which tasks would be most relevant to demonstrate the method's applicability. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Equations 21 and 22, which describe an alternative scheme, are not used and may be omitted without affecting the flow of the section. This provides a clear and explicit action for the authors to consider removing these equations. The suggestion is concrete, as it specifies which equations to omit, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that these equations are not used and may be omitted without affecting the flow of the section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Equations 21 and 22 are not used and may be omitted without affecting the flow of the section. This is a subjective claim as it is based on the reviewer\\'s perception of the paper\\'s content and structure. The comment lacks specific reasoning or evidence to support why these equations are not used or how their omission would impact the flow. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Equations 21 and 22, noting that they describe an alternative scheme that is not actually used. It suggests that these equations may be omitted without affecting the flow of the section. This feedback is clear and actionable, as it provides the authors with a specific area to consider for simplifying their draft. However, the comment could be more helpful if it offered additional guidance on how to integrate the remaining content or if it provided suggestions for alternative ways to present the information. Overall, the comment is mostly helpful as it directs the authors to a potential area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the optimization module applies a simple iteration strategy to optimize two loss functions, and it questions whether the overall model is incremental and stands on the shoulders of traditional approaches. While the comment implies that the authors should consider whether their approach is truly innovative or incremental, it does not provide explicit guidance or suggestions on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should explore the novelty of their approach. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the optimization module, specifically mentioning the use of a simple iteration strategy to optimize two loss functions. This provides some grounding as it allows the authors to identify the relevant part of the paper. However, the comment lacks specificity regarding what aspects of the optimization module are incremental or how it stands on the shoulders of traditional approaches. Without further details or examples, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the optimization module applies a simple iteration strategy to optimize two loss functions, suggesting that the overall model is incremental and stands on the shoulders of traditional approaches. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the optimization module, noting that it applies a simple iteration strategy to optimize two loss functions. It suggests that the overall model may be incremental and standing on the shoulders of traditional approaches. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their approach. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing of the paper could be improved, specifically by clarifying the choice of F(X) for the E(d) case. It requests that the authors elaborate on how to construct F(X) in the main paper and provide examples for the other two cases in the appendix. This feedback is explicit and provides concrete guidance on what the authors need to do to improve their draft. The suggestion is clear and actionable, as it outlines specific steps for the authors to take to enhance the clarity and detail of their paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the writing of the paper could be improved, specifically regarding the choice of F(X) for the E(d) case. It requests that the authors elaborate on this choice and provide examples of how to construct F(X) in the main paper, with the option to include additional examples in the appendix. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the main paper or the appendix where the choice of F(X) is discussed. The comment is specific in detailing what needs to be addressed, namely the choice of F(X) and its construction. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing of the paper could be improved, specifically regarding the choice of F(X) for the E(d) case. It requests that the authors elaborate on this choice and provide examples of how to construct F(X) in the main paper, with the option to include additional examples in the appendix. While the comment identifies a potential area for improvement, it does not provide specific reasoning or examples to support the claim that the choice of F(X) is unclear or poorly explained. The request for elaboration and examples is a logical suggestion but lacks detailed justification or evidence, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the writing, and provides a clear suggestion for clarification. It points out a particular choice, F(X) for the E(d) case, and requests that the authors elaborate on this choice in the main paper, with the option to provide additional examples in the appendix. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and detail of their paper. However, the comment could be more helpful if it included specific examples or suggestions for how to improve the explanation of F(X). Overall, the comment is mostly helpful as it guides the authors on how to improve their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the implicit assumptions the paper adopts to make few-shot learning successful. It suggests that the paper might have a meta-distribution assumption or a distribution-closeness assumption. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions they should consider. The action is implicit and vague, as the authors are left to infer that they need to identify and address these assumptions, but without concrete steps or examples, the action remains unclear. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the implicit assumptions the paper adopts to make few-shot learning successful. It suggests that the paper might have a meta-distribution assumption or a distribution-closeness assumption. However, it does not specify which part of the paper discusses these assumptions or where they might be found. The authors can infer that the question pertains to the methodology or theoretical framework, but the lack of explicit grounding makes it difficult to pinpoint the exact sections needing attention. The comment is specific in its inquiry about the assumptions, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the implicit assumptions the paper adopts to make few-shot learning successful. It suggests that the paper might have a meta-distribution assumption or a distribution-closeness assumption. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without additional context or reasoning, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the implicit assumptions the paper adopts to make few-shot learning successful. It suggests that the paper might have a meta-distribution assumption or a distribution-closeness assumption. However, the comment does not provide any specific guidance or suggestions on how the authors might address these assumptions or where they might be found in the paper. While it identifies a potential area for improvement, the lack of actionable feedback or detailed guidance limits its usefulness. Therefore, the comment is somewhat helpful, as it points out an area for consideration but does not fully support the authors in improving their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should expand their comparison to prior work by considering other tasks and large-scale models. It also recommends including results for more standard benchmarks to facilitate comparison. While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to implement these suggestions, such as which specific tasks or benchmarks to include. The actions are concrete, but the lack of specific details makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should expand their comparison to prior work by considering other tasks and large-scale models, and also provides results for more standard benchmarks. However, it does not specify which part of the paper this comparison is currently lacking, making it weakly grounded. The comment is specific in suggesting what additional comparisons and benchmarks should be included to enhance the paper\\'s comprehensiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison to prior work could be more thorough by considering other tasks and large-scale models, and by providing results for more standard benchmarks. This feedback is based on a logical reasoning that expanding the comparison would enhance the paper\\'s comprehensiveness and facilitate better comparison. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact tasks or benchmarks that should be included, which adds a layer of uncertainty. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should expand their comparison to prior work by considering other tasks and large-scale models, and by providing results for more standard benchmarks. This feedback is clear and actionable, as it provides specific directions for enhancing the paper's comprehensiveness and comparability. By following this advice, the authors can strengthen their paper's contribution and make it more impactful. However, the comment could be more helpful if it included examples of specific tasks or benchmarks that would be beneficial to include. Overall, the comment is mostly helpful as it offers clear guidance for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific guidance or suggestions on how to enhance the contribution. The comment lacks explicit or implicit actions for the authors to take, making it unactionable. The authors are left without a clear understanding of what changes or improvements are needed to address the feedback.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based on, nor does it provide detailed feedback on how the manuscript could be improved. The authors may have an idea of where the comment applies, but the lack of specificity makes it difficult to pinpoint the exact sections needing attention. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it relates to the manuscript. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific suggestions or guidance on how to enhance the contribution. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific guidance or suggestions on how to enhance the contribution. The authors are left without a clear understanding of what changes or improvements are needed to address the feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based on, nor does it provide detailed feedback on how the manuscript could be improved. The authors may have an idea of where the comment applies, but the lack of specificity makes it difficult to pinpoint the exact sections needing attention. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it relates to the manuscript. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific guidance or suggestions on how to enhance the contribution. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path to improve their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved, but it does not provide specific guidance or suggestions on how to enhance the contribution. The authors are left without a clear understanding of what changes or improvements are needed to address the feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this assessment is based"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with the three claimed benefits of the paper. It notes that Benefit 1 is abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their claims. The feedback is vague and does not offer concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific points related to the three claimed benefits of the paper, which are difficult to grasp. It identifies that Benefit 1 is abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references. However, the comment does not specify which part of the paper these benefits are discussed in, making it weakly grounded. The authors can infer that the comment pertains to the sections discussing the claimed benefits, but this inference is not explicit. The comment is specific in detailing the issues with the benefits, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three claimed benefits are difficult to grasp, with Benefit 1 being too abstract and lacking contextual detail. It also notes that Benefit 3 includes broad statements that are not supported by references. The comment provides specific examples of the issues, such as the lack of contextual detail in Benefit 1 and the absence of references in Benefit 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claims. Overall, the comment is mostly verifiable as it offers some support but lacks comprehensive justification, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail. It also critiques Benefit 3 for including broad statements that are not supported by references. This feedback is somewhat helpful as it highlights areas where the paper could be improved in terms of clarity and substantiation. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered specific guidance on how to make the benefits more concrete and supported. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their claims. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific points related to the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references. However, the comment does not specify which part of the paper these benefits are discussed in, making it weakly grounded. The authors can infer that the comment pertains to the sections discussing the claimed benefits, but this inference is not explicit. The comment is specific in detailing the issues with the benefits, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the three claimed benefits of the paper are difficult to grasp, with Benefit 1 being too abstract and lacking contextual detail. It also notes that Benefit 3 includes broad statements that are not supported by references. The comment provides specific examples of the issues, such as the lack of contextual detail in Benefit 1 and the absence of references in Benefit 3. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claims. Overall, the comment is mostly verifiable as it offers some support but lacks comprehensive justification, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies specific issues with the three claimed benefits of the paper, noting that Benefit 1 is too abstract and lacks contextual detail, while Benefit 3 includes broad statements that are not supported by references. This feedback is somewhat helpful as it highlights areas where the paper could be improved"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness based on a few pictures. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and vague, as the authors are left to infer that they need to include quantitative results to strengthen their paper. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness based on a few pictures. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the results section or the discussion of the Human Shape Bases Synchronization problem. The authors can infer that it relates to these areas, but the comment does not provide explicit guidance on where to find this information. The specificity is somewhat limited, as it does not detail what specific quantitative results are missing or how they could be included. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the absence of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness based on a few pictures. This is a logical claim that highlights a potential weakness in the paper\\'s evaluation. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of this comment to their work and consider the implications of the lack of quantitative results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the lack of quantitative results for the Human Shape Bases Synchronization problem, noting that the qualitative results are impressive but difficult to judge effectiveness based on a few pictures. This feedback is important as it highlights a potential weakness in the paper's evaluation and suggests that quantitative results would be beneficial for a more comprehensive assessment. However, the comment does not provide specific guidance on how to include these results or what kind of quantitative metrics would be appropriate. While it identifies a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the categorization of the paper under \"Fairness/Accountability/Transparency,\" implying that the authors might be missing something. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what specific aspects might be missing. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the categorization of the paper under \"Fairness/Accountability/Transparency,\" implying that the authors might be missing something. However, it does not specify which part of the paper is being addressed or what aspects are unclear. The authors cannot confidently determine which part of the paper the comment refers to, nor does the comment provide specific guidance on what needs to be addressed. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the categorization of the paper under \"Fairness/Accountability/Transparency,\" implying that the authors might be missing something. However, the comment does not provide any supporting evidence, reasoning, or context to explain why this categorization is incorrect or incomplete. Without additional information or justification, the claim remains unverifiable. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the categorization of the paper under \"Fairness/Accountability/Transparency,\" implying that the authors might be missing something. However, it does not provide any specific feedback or suggestions on what aspects of the paper are unclear or need clarification. Without actionable guidance or detailed explanations, the comment does not offer the authors meaningful insights or steps to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including a machine learning 2-step baseline to compare with the proposed NaviFormer. This action is explicit, as it directly instructs the authors to include a specific type of baseline for comparison. The comment also provides a rationale for why this comparison is important, as it could help determine whether the improvement is due to the algorithm class or the joint tackling of the routing and path planning problem. This level of detail and specificity makes the action concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a machine learning 2-step baseline for comparison with the proposed NaviFormer. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result section. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its suggestion to include a 2-step baseline, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the comparison with baselines is not sufficient because all approaches are heuristic methods. It proposes including a machine learning 2-step baseline to determine if the improvement is due to the algorithm class or the joint tackling of the routing and path planning problem. The comment provides a logical reasoning for the inclusion of a more robust baseline, which is a form of verification. However, it lacks specific examples or references to support the claim that the current baselines are insufficient. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the comparison of the proposed method, NaviFormer, with baselines. It points out that all approaches are heuristic methods and suggests including a machine learning 2-step baseline to ensure that the improvement is not solely due to the algorithm class. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the comparison and evaluation of the proposed method. By including a more robust baseline, the authors can better substantiate their claims and address potential concerns about the novelty of their approach. However, the comment could be more helpful if it provided additional guidance on how to implement the suggested baseline or discussed the implications of using such a baseline. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct a fair comparison by applying the planning and layering method to the design images generated by other image generative models. This action is explicit and provides a clear direction for the authors to improve their results. The comment also specifies what needs to be done, making it highly actionable. The authors know exactly how to address the feedback by conducting additional experiments or comparisons, ensuring a direct path to improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the comparison of results with other methods, specifically mentioning that the results seem better than other compared methods. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting a fair comparison by applying the planning and layering method to design images generated by other image generative models. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results are better than other compared methods but questions whether this is due to a better image generative model. The reviewer suggests conducting a fair comparison by applying the planning and layering method to design images generated by other image generative models. While the suggestion is logical and provides a way to address the concern, the comment lacks specific examples or references to support the claim that the results are better due to a better generative model. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results, questioning whether the better performance is due to a better image generative model rather than the planning and layering method. It suggests conducting a fair comparison by applying the planning and layering method to design images generated by other image generative models. This feedback is clear and actionable, providing a specific direction for the authors to improve their results and ensure a more robust evaluation. However, the comment could be more helpful if it included specific examples or references to other image generative models or planning methods. Overall, the comment is mostly helpful as it guides the authors toward a more comprehensive analysis, but it could be further enhanced with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison with more advanced baseline methods, such as SOTA methods like Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019), to strengthen their comparative study. The comment also questions the validity of the authors\\' claim about the information of the modality-missing data not being well exploited, given the lack of comparison with these SOTA methods. While the comment explicitly suggests including more advanced baselines, it does not provide specific guidance on how to incorporate these methods or what aspects of the comparison would be most effective. The action is implicit but concrete, as the authors know what needs to be done to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"comparative study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the inclusion of more advanced baseline methods like SOTA methods, such as Ma et al. (2021b), Tran et al. (2017), Chen & Zhang (2020), Liu et al. (2021), and Suo et al. (2019). This provides clear guidance on how to improve the comparative study. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparative study should include more advanced baseline methods, such as SOTA methods, to justify the authors\\' claim about the information of the modality-missing data not being well exploited. The reviewer provides specific examples of SOTA methods, which supports the claim by offering a clear rationale for the inclusion of these methods. However, the comment could be strengthened by providing more detailed reasoning or evidence on why these specific methods are relevant or by referencing additional literature to further substantiate the claim. Despite this, the feedback is mostly verifiable due to the provision of specific examples and the logical reasoning behind the suggestion.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's comparative study by suggesting that the authors should include more advanced baseline methods, such as SOTA methods, in their analysis. This feedback is valuable as it highlights the need for a more comprehensive comparison to strengthen the authors' claims about the effectiveness of their proposed method. By pointing out the lack of comparison with SOTA methods, the comment provides a clear direction for improvement, encouraging the authors to expand their analysis and potentially enhance the paper's impact. However, the comment could be more helpful if it offered specific suggestions on how to integrate these methods or what aspects of the comparison would be most beneficial. Overall, the comment is mostly helpful as it identifies a critical area for enhancement and provides a clear path for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a confusing aspect in the discussion of the dataset, specifically mentioning lines 329-334. It points out that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets,\" which may be irrelevant to the experiments. The reviewer suggests that if these elements are not relevant, they should not be included in the discussion. While the comment implies that the authors should remove or clarify these elements, it does not explicitly instruct them to do so. The action is implicit but concrete, as the authors know what needs to be addressed but may need to infer the exact steps to take. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions lines 329-334, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of the dataset, noting that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets.\" The comment suggests that if these elements are not relevant to the experiments, they should not be included. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion of the dataset is confusing, particularly regarding the task of plain polarity classification versus the mention of \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these elements are not relevant to the experiments, they should not be included. While the comment identifies a potential issue with the clarity of the discussion, it lacks specific examples or references to support the claim. The authors may find it challenging to address the issue without additional context or guidance. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks detailed justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion of the dataset, noting that the task is described as plain polarity classification but also mentions \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these elements are not relevant to the experiments, they should not be included in the discussion. This feedback is clear and actionable, as it points out a potential confusion in the paper and provides a specific suggestion for improvement. By addressing this issue, the authors can enhance the clarity and focus of their discussion, making the comment highly helpful. However, the comment could be more helpful if it provided additional guidance on how to clarify the discussion or suggested alternative ways to present the information. Overall, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point continues from a previous comment, suggesting that the authors are unnecessarily restricting the capsule networks. It points out that the group CapNet is deeper than the simple CapNet and that the authors do not provide the number of parameters in the group CapNet, making it difficult to assess the benefits of enforcing equivariance strictly. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and vague, as the authors are left to infer that they need to provide the number of parameters or clarify the benefits of enforcing equivariance. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment continues from a previous comment, suggesting that the authors are unnecessarily restricting the capsule networks. It points out that the group CapNet is deeper than the simple CapNet and that the authors do not provide the number of parameters in the group CapNet, making it difficult to assess the benefits of enforcing equivariance strictly. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the lack of parameter information and the difficulty in assessing the benefits of enforcing equivariance. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors are unnecessarily restricting the capsule networks due to the deeper group CapNet and the lack of parameter information. However, the comment lacks specific examples or detailed reasoning to support this claim. It mentions that the group CapNet is deeper than the simple CapNet, but it does not provide a comparison or analysis of the impact of this depth on the equivariance. Additionally, the comment questions the authors\\' decision not to provide the number of parameters in the group CapNet, which is crucial for assessing the benefits of enforcing equivariance. Without further elaboration or evidence, the claim remains vague and difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment continues from a previous comment, addressing the issue of unnecessarily restricting the capsule networks. It points out that the group CapNet is deeper than the simple CapNet and that the authors do not provide the number of parameters in the group CapNet, making it difficult to assess the benefits of enforcing equivariance strictly. While the comment highlights a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their analysis. The feedback is somewhat helpful as it identifies a gap in the paper's presentation, but it does not provide actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the challenge of obtaining meaningful gradients with respect to noisy (intermediate) images, as discussed on page 4. It then provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue. However, the comment does not explicitly instruct the authors to adopt these approaches or suggest how they might implement them. While the comment provides valuable information on existing solutions, it lacks actionable guidance on how the authors could apply these suggestions to improve their work. Therefore, the comment is somewhat actionable, as it provides some insight but does not offer clear instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the challenge of obtaining meaningful gradients with respect to noisy images and provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), that have addressed this issue. The comment suggests that these approaches could be relevant to the authors\\' work, offering a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges the challenge of obtaining meaningful gradients with respect to noisy images, as discussed on page 4. It then provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue. The comment suggests that these approaches could be relevant to the authors\\' work, offering a potential solution. However, the comment does not provide specific details or examples of how these approaches could be applied or integrated into the authors\\' work, leaving the authors with a general idea but without actionable guidance. Therefore, the comment is somewhat verifiable, as it provides some support but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the challenge of obtaining meaningful gradients with respect to noisy images, as discussed on page 4. It then provides examples of previous approaches, such as DiME, FastDiME, and [He et al.](https://openreview.net/forum?id=o3BxOLoxm1), which have addressed this issue. By mentioning these approaches, the comment offers the authors a potential direction for improvement or inspiration for their own work. However, the comment does not provide specific guidance or suggestions on how the authors might apply these approaches or integrate them into their own framework. While it identifies a relevant area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial for the authors to include an evaluation of inference speed on the hardware. While the action is explicit, it lacks concrete details on how to conduct this evaluation or which specific hardware should be considered. The authors are aware of the need to address this aspect but may need additional guidance on how to implement it effectively. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include an evaluation of inference speed on the hardware. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in its suggestion to evaluate inference speed, but without grounding, the authors may struggle to identify the exact section where this evaluation should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial for the authors to include an evaluation of inference speed on the hardware. However, the comment does not provide any reasoning, examples, or references to support why this evaluation is necessary or how it would enhance the paper. Without such justification, the claim is not verifiable, as it lacks the necessary evidence or explanation to guide the authors in understanding the importance of this suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial for the authors to include an evaluation of inference speed on the hardware. While this is a valid suggestion, it lacks specificity and does not provide any guidance on how to conduct this evaluation or why it is important. The authors are left with a general idea of what could be improved but without actionable steps or context. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights that the modified problem is convex and can be solved via an SDP, but it does not specify where the SDP formulation is located in the paper. While it implies that the authors should include the SDP formulation, it does not provide explicit guidance on where to find it or how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should look for the SDP formulation in their draft. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'modified problem' and specifies that it is convex and can be solved via an SDP. This allows the authors to accurately identify the part of the paper being addressed, which is the formulation of the SDP. The comment is also specific because it clearly identifies what needs to be addressed, namely the inclusion of the SDP formulation. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the modified problem is convex and can be solved via an SDP. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The comment identifies a specific issue with the paper, noting that the modified problem is convex and can be solved via an SDP. However, it lacks actionable guidance by not specifying where the SDP formulation is located or how it should be incorporated into the paper. While it points out a potential area for improvement, the feedback is incomplete and does not provide the authors with a clear path to address the issue. Therefore, the comment is somewhat helpful, as it highlights a weakness but does not fully support the authors in improving their draft.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review point highlights that the modified problem is convex and can be solved via an SDP, but it does not specify where the SDP formulation is located in the paper. While it implies that the authors should include the SDP formulation, it does not provide explicit guidance on where to find it or how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should look for the SDP formulation in their draft. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'modified problem' and specifies that it is convex and can be solved via an SDP. This allows the authors to accurately identify the part of the paper being addressed, which is the formulation of the SDP. The comment is also specific because it clearly identifies what needs to be addressed, namely the inclusion of the SDP formulation. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the modified problem is convex and can be solved via an SDP, but it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The comment identifies a specific issue with the paper, noting that the modified problem is convex and can be solved via an SDP. However, it lacks actionable guidance by not specifying where the SDP formulation is located or how it should be incorporated into the paper. While it points out a potential area for improvement, the feedback is incomplete and does not provide the authors with a clear path to address the issue. Therefore, the comment is somewhat helpful, as it highlights a weakness but does not fully support the authors in improving their draft.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review point highlights that the modified problem is convex and can be solved via an SDP, but it does not specify where the SDP formulation is located in the paper. While it implies that the authors should include the SDP formulation, it does not provide explicit guidance on where to find it or how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should look for the SDP formulation in their draft. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'modified problem' and specifies that it is convex and can be solved via an SDP. This allows the authors"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues: the lack of information on the number of new task combinations used to evaluate compositional generalizability in line 558, and the limited number of composite instructions in Table 7. While the comment explicitly identifies these areas that need clarification, it does not provide concrete guidance on how the authors should address these issues. The authors are left to infer that they need to provide more details on the number of task combinations and ensure that the results in Table 7 are based on a sufficient number of composite instructions. However, the lack of specific instructions on how to implement these changes makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking for clarification on the number of new task combinations used to evaluate compositional generalizability and the limited number of composite instructions in Table 7. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the lack of information regarding the number of new task combinations used to evaluate compositional generalizability and the limited number of composite instructions in Table 7. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of information on the number of new task combinations used to evaluate compositional generalizability, and the limited number of composite instructions in Table 7. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors improve the clarity and completeness of their results. However, the comment could be more helpful if it suggested ways to address these issues, such as recommending additional experiments or providing more detailed explanations. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the paper, particularly the figures, is not well-formatted or laid out. However, it does not provide any explicit or implicit actions for the authors to take to improve the layout. There is no guidance on how to address the issue, such as suggesting specific formatting changes or providing examples of good layout practices. Without actionable advice or suggestions, the authors are left without a clear understanding of what needs to be done to improve the layout. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"the figures\" as a part of the paper that is not well-formatted, but it does not specify which figures are affected or provide details on what aspects of the layout are problematic. This lack of specificity makes it difficult for the authors to identify the exact sections that need improvement. While the comment implies that the figures are not well-formatted, it does not provide enough detail to be fully grounded. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper, particularly the figures, is not well-formatted or laid out. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or references to what constitutes a good layout, the authors may find it challenging to understand and address the issue. The lack of supporting details makes the claim somewhat verifiable, as it provides a general observation but requires further elaboration for the authors to effectively improve their draft. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that the figures are not well-formatted or laid out. However, it lacks actionable guidance or suggestions on how the authors might improve the layout of their figures. Without detailed advice or examples, the authors are left without a clear understanding of what changes are needed to enhance the presentation of their figures. While the comment highlights a problem, it does not provide the authors with the necessary steps to address it, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights the need for clear differentiation from existing works and detailed comparison with similar techniques, suggesting that the paper's contributions may be perceived as incremental or lacking substantial novelty. However, it does not provide explicit guidance on how to achieve this differentiation or comparison. The authors are left to infer that they need to conduct a thorough review of existing literature and provide detailed comparisons in their work. While the action is implicit, it is concrete in terms of what needs to be done to address the issue. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment addresses the need for clear differentiation from existing works and detailed comparison with similar techniques, suggesting that the paper's contributions may be perceived as incremental or lacking substantial novelty. However, it does not specify which part of the paper should include this differentiation or comparison, making it weakly grounded. The comment is specific in its critique of the paper's perceived lack of novelty, but without explicit references to sections or elements, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper's contributions may be perceived as incremental or lacking substantial novelty due to a lack of clear differentiation from existing works and detailed comparison with similar techniques. The comment provides a logical reasoning by suggesting that without such differentiation and comparison, the work may not stand out in the NLP community. However, the comment lacks specific examples or references to existing works for comparison, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but could be more robust with additional evidence or examples.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the paper's contributions, noting that without clear differentiation from existing works and detailed comparison with similar techniques, the paper's contributions may be perceived as incremental or lacking substantial novelty. This feedback is valuable as it highlights a potential weakness in the paper's presentation and suggests that the authors need to address this issue to enhance the perceived value of their work. However, the comment could be more helpful if it provided specific suggestions on how to differentiate the work or conduct a detailed comparison. Overall, the comment is mostly helpful as it directs the authors' attention to a significant area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to explain the difference between the baseline results in Table 2 and those from Table 3 in [3]. This request provides a clear and direct action for the authors to take, as it specifies what information needs to be clarified or elaborated upon. The comment is explicit and concrete, giving the authors a clear path to follow in addressing the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly asks for an explanation of the difference between the baseline results in these two tables. The mention of [3] provides additional context, but the comment does not specify what aspects of the difference need to be explained. However, this does not affect the classification since the authors can still determine the context. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the difference between baseline results in two tables, without making any subjective claims or judgments. It does not express an opinion, suggestion, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, asking the authors to explain the difference between the baseline results in Table 2 and those from Table 3 in [3]. This request provides a direct and actionable feedback that can help the authors clarify and potentially improve their presentation of results. By addressing this question, the authors can enhance the transparency and comprehensibility of their work, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it suggested how the authors might resolve the discrepancy or provided additional context for understanding the difference. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly identifies a misleading use of the term \"execution feedback\" in the title and Figure 2, explaining that it is not actually used in the work but is approximated based on structural perturbations in the AST. It also points out a potential issue with the definition of EF in Equation 1, suggesting that there is no guarantee that perturbations will result in test failures. While the comment provides clear guidance on the specific issues with the terminology and definitions, it does not offer concrete suggestions on how to address these issues or improve the draft. The authors are left with a clear understanding of what needs to be revised but without explicit instructions on how to do so. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"execution feedback\" in the title and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the definition of \"execution feedback\" and the potential mismatch between the title and the actual use of the term. The comment is specific in detailing what is wrong with the current use of \"execution feedback\" and how it is approximated based on structural perturbations in the AST. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"execution feedback\" is misleading because it is not actually used in the work but is approximated based on structural perturbations in the AST. The reviewer provides specific references to lines 233-238 and Equation 1, which support the claim by explaining the discrepancy between the title and the actual use of \"execution feedback.\" This provides a clear and detailed explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing more examples or references to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of \"execution feedback\" in the title and Figure 2, explaining that it is misleading because it is not actually used in the work but is approximated based on structural perturbations in the AST. The reviewer provides specific references to lines 233-238 and Equation 1, which help the authors understand the discrepancy between the title and the actual use of \"execution feedback.\" This feedback is clear and actionable, as it highlights a potential confusion in terminology and encourages the authors to clarify the use of \"execution feedback\" in their work. However, the comment could be more helpful if it suggested ways to address this issue, such as proposing alternative terminology or explaining the approximation method more clearly. Overall, the comment is mostly helpful, as it provides valuable insights for improving the clarity and accuracy of the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the paper lacks detail and provides specific suggestions for improvement. It explicitly asks for information on what \"40 target words\" are used and how \"a sequence of dots\" are used to remove bias in the model. Additionally, it requests more detail on the bias part, including how many games are sampled to demonstrate the severity of the bias problem. These requests are clear and specific, providing the authors with explicit actions to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Similar,\" which likely refers to a previous section or point in the paper, allowing the authors to accurately identify the part being addressed. It also specifies what needs to be addressed, such as the lack of information on \"40 target words\" and the use of \"a sequence of dots\" to remove bias, as well as the need for more detail on the bias part, including the number of games sampled. This provides clear guidance on what the authors need to address in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the lack of information regarding the \"40 target words\" and the use of \"a sequence of dots\" to remove bias in the model. It also questions the detail provided on the bias part, specifically the number of games sampled to demonstrate the severity of the bias problem. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed evidence or examples makes the claim somewhat verifiable, as it requires the authors to infer the nature of the issues based on their own understanding of the paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail and clarity, providing clear and actionable feedback. It highlights the need for more information on the \"40 target words\" and the use of \"a sequence of dots\" to remove bias in the model. Additionally, it questions the level of detail regarding the bias part, specifically the number of games sampled to demonstrate the severity of the bias problem. This feedback is valuable as it guides the authors to address gaps in their paper, ensuring that their work is more comprehensive and transparent. However, the comment could be more helpful if it provided suggestions on how to improve the clarity or additional details that could be included. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance their draft with specific, actionable feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. While it identifies issues with the experimental setup, it does not provide explicit guidance on how the authors should address these concerns. The comment lacks specific suggestions or actions for improvement, such as recommending the use of more realistic datasets or suggesting alternative methods for data generation. As a result, the authors are left without clear instructions on how to enhance their experimental design. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically mentioning that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic. However, it does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity in detailing what aspects of the experimental setup are unrealistic or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two issues with the experimental setup: the use of simple datasets and the unrealistic nature of the uniformly random missing data. While it points out potential limitations, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their experimental design. The comment lacks actionable advice or detailed feedback, leaving the authors without clear steps to enhance their draft. Therefore, the comment is rated as barely helpful, as it highlights areas for improvement but does not offer sufficient guidance for the authors to effectively address these concerns.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Figure 4 lacks legends, making it difficult to interpret. It provides a clear and specific suggestion to include what each data point or plot corresponds to. This feedback is direct and concrete, giving the authors a clear action to take: adding legends to the figure. The comment provides explicit guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, which is the lack of legends, making it difficult to interpret. The comment provides a clear suggestion to include what each data point or plot corresponds to, giving the authors a specific action to take. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 4 lacks legends, making it difficult to interpret. This is a factual observation rather than a subjective claim or suggestion. It does not require any supporting evidence or justification, as it is a straightforward statement of fact. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 4, noting that it lacks legends, which makes the plots difficult to interpret. It provides a clear and actionable suggestion by recommending the inclusion of what each data point or plot corresponds to. This feedback is valuable as it guides the authors on how to improve the clarity and interpretability of their figures, which is an important aspect of data presentation. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate the legends or suggested specific examples of what information should be included. Despite this, the feedback is mostly helpful as it directs the authors toward a clear and actionable improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific aspects of the paper that are concerned with sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models as well. It also requests clarification on whether there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models. While the comment implies that the authors should clarify these points, it does not provide explicit instructions or concrete guidance on how to address these questions. The action is implicit and somewhat vague, as the authors need to infer the specific actions required to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the specific aspects of the paper that are concerned with sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models as well. It also requests clarification on whether there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models. However, the comment does not specify which part of the paper should be addressed or provide detailed guidance on what needs to be clarified or improved. The authors can infer that the question pertains to the methodology or results sections, but the lack of specific guidance makes it difficult for them to pinpoint the exact areas needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question and a request for clarification, which do not contain claims or opinions that require verification. The comment seeks clarification on whether the paper is specifically concerned with sequence-to-sequence models and whether the proposed robustness-aware quantization scheme benefits these models. It does not make any subjective judgments or suggest changes that would require justification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific aspects of the paper that are concerned with sequence-to-sequence models and suggests that the general quantization-aware training strategy could be applicable to other models as well. It also requests clarification on whether there is anything specific about the proposed robustness-aware quantization scheme that benefits sequence-to-sequence models. While the comment identifies a potential area for clarification, it lacks depth and does not provide actionable feedback or suggestions for improvement. The authors are left with a general inquiry that does not offer guidance on how to address the question or enhance the draft. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a specific aspect of their work but does not fully support their efforts to improve the draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to provide more ablation on the behavior of the algorithm and how the accuracy of its Q estimates changes as the hyperparameter lambda changes. This is a clear and direct action for the authors to take, as it specifies what additional analysis or experiments are needed to address the reviewer\\'s concern. The request is concrete, as it outlines a specific area for improvement and provides a clear path for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is more ablation on how the algorithm\\'s behavior and accuracy of Q estimates change as the hyperparameter lambda changes. This provides clear guidance on what additional analysis or experiments are needed to address the reviewer\\'s concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for more ablation on the behavior of the algorithm and how the accuracy of its Q estimates change as the hyperparameter lambda changes. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it requests more ablation on the behavior of the algorithm and how the accuracy of its Q estimates change as the hyperparameter lambda changes. This feedback provides a specific area for the authors to explore and improve their understanding of the algorithm, which can lead to a more robust analysis and better presentation of results. However, the comment could be more helpful if it included suggestions on how to conduct the ablation or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the base encoder of the proposed model, asking whether it is a pre-trained model or if it is trained from scratch. This question is explicit and directly prompts the authors to clarify this aspect of their model. However, it does not provide any guidance on how to address this question or what specific information should be included in the response. The action is clear but lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the base encoder of the proposed model, asking whether it is a pre-trained model or if it is trained from scratch. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors might infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in its question about the base encoder, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the base encoder of the proposed model, asking whether it is a pre-trained model or trained from scratch. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the base encoder of the proposed model, asking whether it is a pre-trained model or if it is trained from scratch. This question is relevant and could help the authors clarify an important aspect of their methodology. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what specific information should be included in their response. While it prompts the authors to clarify a key point, it lacks actionable feedback or detailed suggestions, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the Ethical Statement should be extended with a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment implies that the authors should expand their discussion, it does not provide specific guidance on how to address these challenges or what aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors know they need to expand the discussion but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending the inclusion of a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This provides a clear direction for the authors to enhance their discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Ethical Statement is well-written but suggests it should be extended with a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment acknowledges the current state of the Ethical Statement, it lacks specific examples or detailed reasoning to support the need for additional discussion. The suggestion is somewhat vague and does not provide explicit guidance on how to address these challenges, making it difficult for the authors to fully understand and implement the feedback. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the Ethical Statement is well-written but suggests that it could be improved by expanding its discussion to address challenges not covered in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their discussion of ethical considerations. By addressing these challenges, the authors can improve the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered suggestions on how to incorporate these discussions or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the transition from $$\\hat{m}_t$$ and $$g_t$$ in equation (13) to $$x$$ in equation (14). While it identifies a potential issue with clarity, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the confusion or improve the clarity of the equations. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (13)\" and \"equation (14)\", allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the transition from $$\\hat{m}_t$$ and $$g_t$$ to $$x$$ in these equations, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the transition from $$\\hat{m}_t$$ and $$g_t$$ to $$x$$ in equations (13) and (14), respectively. However, it does not provide any supporting evidence, reasoning, or examples to explain why this transition is unclear or problematic. Without additional context or justification, the comment lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the transition from $$\\hat{m}_t$$ and $$g_t$$ in equation (13) to $$x$$ in equation (14), suggesting a potential issue with clarity. While it identifies a specific area that needs clarification, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the non-integer nature of the mini-batch size, tau_t, and suggests that it should be clarified to ensure there are no side effects. It specifically asks about the implications of a very small tau_t value, such as whether the analysis remains valid. While the comment identifies a potential issue and suggests clarification, it does not provide explicit guidance on how to address this concern or what specific steps to take to ensure the analysis remains valid. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to clarify the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the non-integer nature of the mini-batch size, tau_t, and raises a concern about potential side effects. It explicitly mentions \"mini-batches tau_t,\" providing full grounding by identifying the specific part of the paper being addressed. The comment is also specific as it questions the implications of a very small tau_t value, such as whether the analysis remains valid. This level of detail allows the authors to accurately pinpoint the area needing clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the non-integer nature of the mini-batch size, tau_t, and questions the potential side effects, particularly when tau_t is very small. The reviewer suggests that the analysis may not be valid in such cases. However, the comment lacks specific examples or references to support the claim about the potential side effects or the validity of the analysis. While the concern is raised, the lack of detailed evidence or reasoning makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific concern about the non-integer nature of the mini-batch size, tau_t, and questions the potential side effects, particularly when tau_t is very small. It prompts the authors to clarify this aspect to ensure the analysis remains valid. While the comment identifies a potential issue, it lacks detailed guidance on how to address it or what specific steps to take to clarify the analysis. The feedback is somewhat helpful as it points out a critical area for improvement but could be more actionable with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that it is important to examine the computational cost associated with the inference process of the SCALE model. It identifies a specific aspect of the model that needs attention, namely the inference cost, which involves two types of decoding: STM decoding and LLM decoding. This provides a clear and direct action for the authors to take, namely to investigate and report on the computational cost of the inference process. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Inference cost,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the importance of examining the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that it is important to examine the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. However, the comment does not provide any specific reasoning, examples, or references to support why this is a critical aspect to consider. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the computational cost associated with the inference process of the SCALE model. It highlights the importance of examining the computational cost, which involves two types of decoding: STM decoding and LLM decoding. This feedback is clear and actionable, providing the authors with a concrete direction to address a potential weakness in their work. By addressing this issue, the authors can enhance the practicality and feasibility of their model. However, the comment could be more helpful if it included suggestions on how to measure or analyze the computational cost or provided references to similar studies. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights two main issues: the lack of performance comparisons with state-of-the-art models and the peculiar experimental results, specifically mentioning the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific suggestions or actionable steps makes it difficult for the authors to know exactly what changes to make to improve their draft. Therefore, the comment is somewhat actionable, as it points out areas for improvement but lacks detailed instructions on how to implement those changes.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses two specific issues: the lack of performance comparisons with state-of-the-art models and the peculiar experimental results, particularly mentioning the unsupervised result outperforming the supervised result in the 5th row of Table 2. This provides full grounding as it explicitly mentions the section (Table 2) and the specific row (5th row) where the issue is observed. The comment is also specific because it clearly identifies the problem with the experimental results and suggests a potential issue with the comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the article lacks performance comparisons with state-of-the-art models and highlights peculiar experimental results, such as the unsupervised result outperforming the supervised result in a specific row of Table 2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two significant issues with the paper: the lack of performance comparisons with state-of-the-art models and the peculiar experimental results, specifically mentioning the unsupervised result outperforming the supervised result in a specific row of Table 2. This feedback is valuable as it points out areas where the paper could be strengthened, providing clear guidance on what the authors need to address to improve the draft. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or how to interpret the unusual results. Overall, the comment is mostly helpful as it highlights critical areas for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further explained. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to clarify or elaborate on this concept, nor is there a suggestion for what specific information should be added. As a result, the authors are left without a clear understanding of what needs to be addressed or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the phrase \"lacks inherent semantic meaning,\" but it does not specify which part of the paper this phrase is used in or where it is problematic. This lack of grounding makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in pointing out the issue with the phrase, but without grounding, it is not actionable. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the phrase \"lacks inherent semantic meaning,\" noting that it is used but not further explained. However, it does not provide any guidance or suggestions on how the authors might clarify or elaborate on this concept. Without actionable feedback or specific advice, the comment does not offer the authors a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several issues with the paper, including the lack of details and justification for using a large number of hidden units and an additional elementwise function. It also points out the potential bias introduced by treating unobserved ratings as zeros, which is not justified. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the paper, such as the use of a large number of hidden units, an additional elementwise function, and the treatment of unobserved ratings as zeros. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the methodology and potential bias, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function. It also criticizes the treatment of unobserved ratings as zeros, suggesting that this may introduce bias. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several specific issues with the paper, including the lack of details and justification for using a large number of hidden units and an additional elementwise function. It also points out a potential bias introduced by treating unobserved ratings as zeros, which is not justified. However, the comment does not provide actionable suggestions or guidance on how the authors might address these issues or improve their methodology. While it highlights important areas for consideration, the lack of detailed feedback limits its usefulness for the authors. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the robustness of the motivation claim, noting that MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, but this accuracy can be achieved with 100% accuracy using other tools. While the comment identifies a potential issue with the motivation claim, it does not provide explicit guidance on how the authors should address this concern or improve their motivation. The feedback lacks actionable details, such as suggesting specific areas to clarify or expand upon, leaving the authors without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the robustness of the motivation claim, specifically mentioning the high accuracy of 93.03% achieved by MathGLM on a constructed dataset for complex computations. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in pointing out the issue with the motivation claim, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for the work is not robust, citing the high accuracy of 93.03% achieved by MathGLM on a constructed dataset for complex computations. However, the comment does not provide specific examples or detailed reasoning to support the claim that this accuracy can be achieved with 100% accuracy using other tools. The lack of detailed evidence or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the robustness of the motivation claim, noting that MathGLM achieves a high accuracy of 93.03% on the constructed dataset for complex computations, but this accuracy can be achieved with 100% accuracy using other tools. While the comment identifies a potential issue with the motivation, it lacks specific suggestions or guidance on how the authors might address this concern or improve their motivation. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps or detailed insights that could help the authors strengthen their motivation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant weakness in the paper, noting that the reliance on synthetic datasets for evaluation does not accurately reflect event-based dense tracking in real-world settings. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve their evaluation or what specific steps they should consider to better align their work with event-based dense tracking. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of a dedicated event-based dense tracking dataset and the reliance on synthetic datasets for evaluation. It highlights that this approach does not truly reflect event-based dense tracking in real-world settings, which is a significant weakness. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or evaluation sections, but this is not explicitly mentioned. The comment is specific in identifying the issue of relying on synthetic datasets for evaluation, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reliance on synthetic datasets for evaluation does not accurately reflect event-based dense tracking in real-world settings, which is a significant weakness. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, noting that the reliance on synthetic datasets for evaluation does not accurately reflect event-based dense tracking in real-world settings. This is a critical point that the authors should address to ensure the validity and applicability of their findings. However, the comment lacks specific suggestions or guidance on how the authors might improve their evaluation or dataset selection to better align with real-world scenarios. While it highlights an important issue, the feedback could be more helpful if it provided actionable advice or examples of how to address this limitation. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of clarity in the paper\\'s motivation and suggests that the experiments are weak due to limited dataset and LLM size. It also points out that the results are unconvincing and could potentially mislead the community if not thoroughly validated. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns or improve their motivation. The feedback is somewhat actionable as it points out areas for improvement but lacks concrete suggestions on how to enhance the paper\\'s motivation or experimental design. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation of the paper, suggesting that it is unclear and opposing a common understanding of the importance of diversity in instruction-tuning data. It also critiques the experiments, noting that they are weak due to limited dataset and LLM size, and that the results are unconvincing. However, the comment does not specify which part of the paper discusses the motivation or the experiments, making it weakly grounded. The feedback is specific in identifying the issues with the motivation and experiments, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the paper is unclear and that the experiments are weak due to limited dataset and LLM size. The reviewer provides a logical reasoning by referencing existing research that recognizes the importance of diversity in instruction-tuning data and suggesting that the paper contradicts this understanding without strong justification. The reviewer also notes that the results are unconvincing and could potentially mislead the community if not thoroughly validated. While the comment provides a clear rationale for its claims, it lacks specific examples or references to support the assertion about the limited dataset and LLM size. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's motivation, suggesting that it is unclear and appears to contradict existing research on the importance of diversity in instruction-tuning data. The reviewer points out that the experiments are weak due to limited dataset and LLM size, which could lead to unconvincing results that might mislead the community if not thoroughly validated. While the comment highlights a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or enhance the motivation of their work. The feedback is somewhat helpful as it points out a significant concern but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks why there are no confidence intervals on the substitution ASR in Table 3. This is a clear and direct request for the authors to provide an explanation or justification for the absence of confidence intervals. The action is explicit, as it specifies what needs to be addressed, and it is concrete because it provides a clear direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks why there are no confidence intervals on the substitution ASR in that table. This provides a clear direction for the authors to address the issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual question seeking clarification about the absence of confidence intervals in Table 3. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, asking why there are no confidence intervals on the substitution ASR in Table 3. This question prompts the authors to consider whether the absence of confidence intervals is justified or if they should be included for a more comprehensive analysis. While the comment identifies a potential area for improvement, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it highlights a gap in the presentation of results, but it could be more beneficial with additional context or suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about estimating the mean element mu_g for different kernel spaces, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps to follow to clarify the estimation process. Without specific instructions or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about estimating the mean element mu_g for different kernel spaces, but it does not specify which part of the paper this issue is related to. The authors might infer that it pertains to a section discussing kernel spaces or experimental results, but this inference is not explicit. The comment is specific in asking for clarification on how to estimate mu_g, but it lacks grounding as it does not mention a specific section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about estimating the mean element mu_g for different kernel spaces, but it does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment raises a question about estimating the mean element mu_g for different kernel spaces, which is a specific and relevant issue for the authors to address. However, it does not provide any guidance or suggestions on how to estimate mu_g or what methods might be used. While it identifies a potential area of improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a specific area for clarification but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, would make the story more complete. While the comment implies that the authors should include these datasets in their analysis, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include these datasets but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the discussion of baselines or experimental setup, but this is not explicitly stated. The comment is specific in its suggestion to include larger datasets, but it lacks grounding as it does not pinpoint a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, would make the story more complete. However, the comment does not provide any specific reasoning or evidence to support why these datasets would be beneficial or how they would enhance the completeness of the story. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that considering datasets with larger numbers of clusters, such as ImageNet with reduced samples and feature dimensions, would make the story more complete. While the comment identifies a potential area for improvement by suggesting the inclusion of more challenging datasets, it lacks specificity and does not provide detailed guidance on how to implement this suggestion. The authors are left with a general idea of what could be added but are not given actionable steps or examples to follow. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the suitability of using cosine similarity score in biometric verification compared to the Euclidean distance when computing Decidability. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether they should explore the use of cosine similarity, compare it with the Euclidean distance, or provide any other specific direction. Without actionable advice or suggestions, the authors are left without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of cosine similarity score in biometric verification compared to the Euclidean distance when computing Decidability. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where these methods are discussed. The authors may have an idea of where this discussion might be, but the comment lacks explicit grounding. Additionally, the comment is specific in questioning the suitability of cosine similarity in the context of biometric verification, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the suitability of using cosine similarity score in biometric verification compared to the Euclidean distance when computing Decidability. However, it does not provide any supporting evidence, reasoning, or references to justify why cosine similarity might be more appropriate or why the Euclidean distance might not be suitable. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the question and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the suitability of using cosine similarity score in biometric verification compared to the Euclidean distance when computing Decidability. While it identifies a potential area for exploration, it does not provide any specific guidance or suggestions on how the authors might address this question or what aspects of the study could be improved. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to follow for enhancing their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights several issues with the experiments, including the lack of a robust experimental design and the absence of comparisons with other methods. It explicitly states that the experiments are weak and that the current submission's experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment does not provide specific guidance on how to improve the experiments or what additional experiments should be conducted. While the action is clear in terms of identifying the need for stronger experiments, the lack of detailed instructions on how to achieve this makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the experiments conducted in the paper, specifically mentioning the toy experiment and the real-world dataset experiment. It also points out the absence of comparisons with other counterpart methods. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experiments, such as the lack of robustness and the absence of comparisons, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the experiments are weak due to the lack of robustness and the absence of comparisons with other methods. The comment provides a logical reasoning by stating that the current submission's experimental results are insufficient to validate the effectiveness of the proposed method. However, it lacks specific examples or references to other methods for comparison, which would strengthen the claim. The absence of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to infer the extent of the issue based on the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several weaknesses in the experimental section of the paper, specifically noting the lack of robustness in the experiments and the absence of comparisons with other methods. It highlights that the current submission's experimental results are insufficient to validate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides specific areas for improvement, such as conducting more comprehensive experiments or including comparisons with other methods. However, the comment could be more helpful if it offered suggestions on how to strengthen the experiments or what specific comparisons would be beneficial. Overall, the comment is mostly helpful as it directs the authors' attention to critical areas needing improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment identifies several issues with the experiments, including the lack of robustness and the absence of comparisons with other methods. It explicitly states that the current submission's experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment does not provide specific guidance on how to improve the experiments or what additional experiments should be conducted. While the action is clear in terms of identifying the need for stronger experiments, the lack of detailed instructions on how to achieve this makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the experiments conducted in the paper, specifically mentioning the toy experiment and the real-world dataset experiment. It also points out the absence of comparisons with other counterpart methods. However, it does not specify which sections of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the experiments, such as the lack of robustness and the absence of comparisons, which provides clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with the label 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the experiments are weak due to the lack of robustness and the absence of comparisons with other methods. It provides a logical reasoning by stating that the current submission's experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment lacks specific examples or references to other methods for comparison, which would strengthen the claim. The absence of detailed evidence or references makes the claim somewhat verifiable, as the authors would need to infer the extent of the issue based on the general statement. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant weakness in the experimental section of the paper, specifically noting the lack of robustness and the absence of comparisons with other methods. It highlights that the current submission's experimental results are insufficient to validate the effectiveness of the proposed method. This feedback is clear and actionable, as it directs the authors' attention to critical areas needing improvement. However, the comment could be more helpful if it provided specific suggestions on how to strengthen the experiments or what additional"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. While it identifies a specific issue, it does not provide explicit guidance on how the authors should address this. The authors are left to infer that they need to ensure these figures are referenced in the appropriate sections, but the comment lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the figures related to completion errors, noting that they are not referenced in the relevant analysis sections of the appendix. This provides some grounding as it mentions a specific part of the paper, but it does not specify which sections or figures are affected. The comment is specific in identifying the issue of un referenced figures, but it lacks full grounding because it does not explicitly mention the sections or figures involved. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This is a factual statement that does not require verification or evidence, as it is a direct observation of the paper\\'s content. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This feedback is clear and actionable, as it points out a gap in the paper\\'s organization and suggests that the authors should ensure these figures are properly integrated into the analysis sections. However, the comment could be more helpful if it provided additional guidance on how to integrate these figures or suggested specific sections where they should be included. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the consistency of perplexity measurements across validation sets at different levels. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider to ensure consistency. Without specific instructions or suggestions, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the consistency of perplexity measurements across validation sets at different levels. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in questioning the consistency of measurements, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the consistency of perplexity measurements across validation sets at different levels. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it might impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the consistency of perplexity measurements across validation sets at different levels. While it identifies a potential issue, it does not provide any further context, reasoning, or suggestions on how the authors might address this concern. Without additional guidance or examples, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential weakness but lacks actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion that the setting and algorithm lack originality, suggesting they may seem like incremental combinations of existing methods. However, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the originality of their work. The comment lacks actionable details, leaving the authors without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the originality of the setting and algorithm, suggesting they may seem like incremental combinations of existing methods. However, it does not specify which parts of the paper are being discussed or provide detailed feedback on what aspects need improvement. The authors cannot confidently determine which part of the paper is being addressed, nor do they receive specific guidance on what needs to be revised. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses an opinion about the originality of the setting and algorithm, suggesting they may seem like incremental combinations of existing methods. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or detailed explanations, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the setting and algorithm lack originality, suggesting they may seem like incremental combinations of existing methods. While it identifies a potential issue with the originality of the work, it does not provide specific feedback or suggestions on how the authors might address this concern or improve the originality of their approach. The comment lacks actionable guidance, leaving the authors without a clear path to follow for enhancing the originality of their work. Therefore, the comment is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about using the state-action of the current policy in the target environment as regularization, which could potentially harm learning due to the use of a suboptimal policy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about using the state-action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the potential harm caused by using a suboptimal policy for regularization, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about using the state-action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the use of state-action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. This feedback is somewhat helpful as it identifies a potential issue that the authors should consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable advice or detailed explanations, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about using the state-action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about using the state-action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its critique of the potential harm caused by using a suboptimal policy for regularization, but it lacks grounding as it does not reference a specific part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about using the state-action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about using the state-action of the current policy in the target environment as regularization, suggesting that it could harm learning due to the use of a suboptimal policy. This feedback is somewhat helpful as it identifies a potential issue that the authors should consider. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable advice or detailed explanations, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on base classes. It explicitly suggests that the authors should discuss how this issue could be mitigated to maintain performance on the base classes. This feedback provides a clear and direct action for the authors to take, which is to address the potential degradation in performance and propose mitigation strategies. The comment is explicit and concrete, offering a specific direction for improvement. Therefore, it is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the feature compactness loss and sharpness-aware minimization, which is mentioned in the context of reducing distances among base classes. However, it does not explicitly mention a specific section or part of the paper where this discussion is relevant, making it weakly grounded. The comment is specific in that it raises a concern about the potential negative impact on the model\\'s performance on base classes and suggests discussing mitigation strategies. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential negative impact of the feature compactness loss and sharpness-aware minimization on the model\\'s performance on base classes. It suggests that the authors should discuss how this issue could be mitigated to maintain performance. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this operation might negatively impact performance. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the feature compactness loss and sharpness-aware minimization, suggesting that these operations might negatively impact the model's performance on base classes. It provides a clear and actionable suggestion for the authors to discuss how this issue could be mitigated to maintain performance on the base classes. This feedback is valuable as it highlights a critical area for improvement and offers a specific direction for the authors to address in their draft. However, the comment could be more helpful if it provided additional context or examples to support the claim or suggested specific mitigation strategies. Overall, the comment is mostly helpful, as it guides the authors towards a meaningful improvement in their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the insight of the work and asks for guidance on preventing attention collapse in Continual Learning (CL). However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks specific suggestions or directions on how the authors might address these issues, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the insight of the work and its potential to develop new methods, specifically regarding preventing attention collapse in Continual Learning (CL). However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity in terms of what aspects of the work are unclear or need further development. Without clear grounding or specific guidance, the authors may struggle to address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the insight of the work and its potential to develop new methods, specifically regarding preventing attention collapse in Continual Learning (CL). It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the insight of the work and its potential to develop new methods, specifically regarding preventing attention collapse in Continual Learning (CL). While it identifies a relevant area for improvement, the comment lacks specificity and actionable guidance. It does not provide any suggestions or examples of how the authors might address this issue or what specific insights could be developed. As a result, the feedback is vague and does not offer the authors a clear path to improve their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the impact of the CHC model on the capabilities of MLLMs. It explicitly asks for clarification on how the CHC model affects these capabilities and what specific attributes or behaviors a powerful MLLM grounded in CHC theory would exhibit. The comment also suggests the need for case studies or pilot experiments to illustrate the significance of this influence. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to conduct these experiments or what aspects to focus on. The authors know they need to address the question, but the comment lacks detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"CHC model\" and the \"main content,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on how the CHC model affects the capabilities of MLLMs and what specific attributes or behaviors a powerful MLLM grounded in CHC theory would exhibit. The comment also suggests the need for case studies or pilot experiments to illustrate the significance of this influence. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of the CHC model on the capabilities of MLLMs, asking for clarification on specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. The comment does not contain any claims or opinions that require verification. It is a request for further explanation or evidence, which is a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the impact of the CHC model on the capabilities of MLLMs, asking for clarification on how the CHC model affects these capabilities and what specific attributes or behaviors a powerful MLLM grounded in CHC theory would exhibit. It also suggests the need for case studies or pilot experiments to illustrate the significance of this influence. This feedback is clear and actionable, providing the authors with a specific area to explore and improve upon in their paper. However, it could be more helpful if it offered suggestions on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it guides the authors in addressing a critical gap in their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider integrating more up-to-date pretraining models to showcase the significance and practical usage of their approach. It provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This feedback is explicit and provides concrete guidance on how the authors can improve their work by incorporating more recent and powerful pretraining models. The suggestion is clear and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the pretraining model \"Pre-GNN (Hu et al., 2020)\" and provides a specific suggestion to consider integrating more up-to-date pretraining models. It also provides examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the pretraining model, Pre-GNN (Hu et al., 2020), is relatively old in the context of molecular pretraining and suggests that integrating more up-to-date pretraining models would showcase the significance and practical usage of the approach. The reviewer provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This provides a clear and detailed justification for the claim, making it fully verifiable. The references to recent works support the suggestion, allowing the authors to understand the context and potential benefits of incorporating these models. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the pretraining model, Pre-GNN (Hu et al., 2020), is relatively old in the context of molecular pretraining. It suggests that integrating more up-to-date pretraining models would enhance the significance and practical usage of the authors\\' approach. The comment provides specific examples of recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which the authors could consider. This feedback is actionable and provides clear guidance on how the authors can improve their work by incorporating more recent and powerful pretraining models. The suggestion is detailed and constructive, offering a path for the authors to enhance their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential engineering challenge related to the model\\'s input, which involves the difference between current object pose and target object pose. It acknowledges that this can be challenging due to difficulties in object segmentation and pose tracking in the real world. However, the comment does not provide any explicit or implicit actions for the authors to take. It simply notes that the authors have documented their approach well in Section A.3. Without any guidance or suggestions on how the authors might address this challenge or improve their approach, the comment lacks actionable content. Therefore, it is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the model\\'s input, specifically mentioning the use of the difference between current object pose and target object pose. It also notes the potential engineering challenge associated with this input, particularly in the context of object segmentation and pose tracking in the real world. However, the comment does not specify which section of the paper discusses this aspect, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in detailing the challenge and the authors\\' documentation of their approach, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential engineering challenge related to the model\\'s input, specifically the difference between current object pose and target object pose. It acknowledges that this can be challenging due to difficulties in object segmentation and pose tracking in the real world. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this is a significant challenge. The mention of the authors\\' documentation in Section A.3 provides some context but does not substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential engineering challenge related to the model's input, specifically the difference between current object pose and target object pose. It acknowledges that this can be challenging due to difficulties in object segmentation and pose tracking in the real world. However, the comment does not provide any actionable suggestions or guidance on how the authors might address this challenge or improve their approach. While it highlights a potential issue, it lacks depth and specificity, making it barely helpful. The authors are left with a general understanding of the challenge but without clear steps to take to overcome it. Therefore, the comment aligns with a score of 2.\", 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment highlights a potential engineering challenge related to the model\\'s input, specifically the difference between current object pose and target object pose. It acknowledges that this can be challenging due to difficulties in object segmentation and pose tracking in the real world. However, the comment does not provide any explicit or implicit actions for the authors to take to address this challenge or improve their approach. Without actionable guidance or suggestions, the authors are left without a clear path for improvement. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a potential engineering challenge related to the model\\'s input, specifically the difference between current object pose and target object pose. It acknowledges that this can be challenging due to difficulties in object segmentation and pose tracking in the real world. However, the comment does not specify which part of the paper discusses this aspect, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in detailing the challenge and the authors\\' documentation of their approach, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a potential engineering challenge related to the model\\'s input, specifically the difference between current object pose and target object pose. It acknowledges that this can be challenging due to difficulties in object segmentation and pose tracking in the real world. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this is a significant challenge. The mention of the authors\\' documentation in Section A.3 provides some context but does not substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential engineering challenge related to the model's input, specifically the difference between current object pose and target object pose. It acknowledges that this can be challenging due to difficulties in object segmentation and"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more downstream performance of their controllable text generation models, connecting them to real NLG applications and demonstrating the advantage of their model. It specifically mentions style transfer as a potential starting point. While the comment implies that the authors should take these steps, it does not provide explicit instructions on how to implement them. The action is somewhat vague, as the authors need to infer the specific steps to take, such as which applications to focus on and how to demonstrate the model\\'s advantage. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 116-117,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should provide more downstream performance of their controllable text generation models and connect them to real NLG applications. The comment further specifies that style transfer could be a good starting point. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more downstream performance of their controllable text generation models, connecting them to real NLG applications. It implies that the current discussion about downstream applications is insufficient and lacks demonstration of the model\\'s advantage. However, the comment does not provide specific examples or references to support the claim that more downstream performance is necessary or how it would demonstrate the model\\'s advantage. This makes the claim somewhat verifiable, as it lacks detailed evidence or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should provide more downstream performance of their controllable text generation models, connecting them to real NLG applications. It implies that the current discussion about downstream applications is insufficient and lacks demonstration of the model's advantage. The comment provides a specific suggestion, such as style transfer, as a potential starting point. However, it does not offer detailed guidance on how to implement this suggestion or what specific applications to focus on. While the comment identifies an area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the test set performance on the GLUE datasets and questions whether the labels for these sets are not available to the public. While the comment raises a valid concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to clarify or provide more information about the availability of labels, but the comment lacks concrete details on how to implement this action. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the test set performance on the GLUE datasets and questions the availability of labels for these sets. However, it does not specify which part of the paper this issue is related to, such as a specific section or table where this information is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its question about the availability of labels, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the availability of labels for the test sets used in the GLUE datasets. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or references to the datasets or labels in question, making it difficult for the authors to address the concern effectively. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the test set performance on the GLUE datasets and questions the availability of labels for these sets. While it identifies a potential issue, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern. The comment does not offer actionable feedback or insights that could help the authors improve their draft. Therefore, it is rated as barely helpful, as it highlights a potential area of concern but does not provide actionable advice for the authors to address it.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that Section 3.2 could be shortened by removing equations that are not original to the work, as they are well-known in the community. This action is explicit and provides a clear direction for the authors to save space and include more important details. The suggestion is concrete, as it specifies what should be removed and why. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Section 3.2,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the section could be shortened by removing equations that are not original to the work, as they are well-known in the community. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that Section 3.2 could be shortened by removing equations that are not original to the work, as they are well-known in the community. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim that these equations are indeed well-known. The comment implies that the authors should consider the community's knowledge base when deciding what to include in the section, but without further evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that Section 3.2 could be shortened by removing equations that are not original to the work, as they are well-known in the community. This feedback is actionable and provides a clear rationale for streamlining the section, which could save space and allow for the inclusion of more important details. By offering a specific suggestion for improvement, the comment is mostly helpful, as it guides the authors in making their draft more concise and focused. However, it could be more helpful if it provided examples of which equations could be removed or how the space saved could be used to enhance the paper. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks about the evaluation methods used in Figure 3, Table 3, and Figure 5, specifically whether they are based on automatic or human evaluation. This is a clear and direct request for clarification, providing the authors with a specific action to take: to specify the evaluation methods used in these figures. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures and tables (Figure 3, Table 3, and Figure 5), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly asks about the evaluation methods used in these figures, providing a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the evaluation methods used in specific figures and tables, which is a factual inquiry. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it explicitly requests clarification about the evaluation methods used in specific figures and tables (Figure 3, Table 3, and Figure 5). This feedback is valuable because it prompts the authors to provide more detailed information about their evaluation process, which is crucial for understanding and validating the results presented in the paper. By addressing this question, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested how the authors might present this information or provided examples of how to clarify the evaluation methods. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the understanding of the results, specifically regarding the coverage rate and its relation to the theorem. It asks the authors to clarify their understanding or provide additional assumptions to achieve the desired coverage rate. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify their understanding or provide additional assumptions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific time points (1 -> 0.9, t=5: 0.9 -> 1) and a particular observation about the coverage rate. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the understanding of the results, particularly regarding the coverage rate and its relation to the theorem. It asks for clarification or additional assumptions to achieve the desired coverage rate. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the understanding of the results, specifically regarding the coverage rate and its relation to the theorem. It does not contain any subjective claims, opinions, or suggestions that require verification. Instead, it is a request for clarification or additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the understanding of the results, particularly regarding the coverage rate and its relation to the theorem. It highlights a potential misunderstanding or discrepancy and asks for clarification or additional assumptions to achieve the desired coverage rate. While the comment identifies a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to clarify their understanding, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting the use of multiple translators or providing additional context on the choice of a single translator. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the use of a single translator, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. However, the comment lacks specific examples or references to support the claim that different translators have different choices, making it difficult for the authors to understand the basis of the concern. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the use of a single translator per language, suggesting that this approach may not be sufficient due to the variability in translator choices. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable advice or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide detailed feedback or suggestions for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the order of actions (\"people wear a hat and play guitar not vice-versa\") and suggests that it is unclear why this is the case. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes they should consider. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the order of actions (\"people wear a hat and play guitar not vice-versa\") and suggests that it is unclear why this is the case. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in this context. Without clear grounding or detailed guidance, the authors cannot effectively respond to the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question about the order of actions (\"people wear a hat and play guitar not vice-versa\") and an implicit suggestion that it is unclear why this is the case. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the question and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the order of actions (\"people wear a hat and play guitar not vice-versa\") and suggests that it is unclear why this is the case. However, it does not provide any context, explanation, or guidance on how this issue might impact the paper or what changes could be made to address it. Without actionable feedback or suggestions for improvement, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that 2000 examples may be insufficient for the model to learn the transformation correctly. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to increase the number of examples, explore alternative datasets, or consider other factors that might affect the model\\'s learning. Without specific actions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that 2000 examples may be insufficient for the model to learn the transformation correctly, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or experiment this comment pertains to, making it weakly grounded. The comment is specific in identifying the potential insufficiency of the dataset size, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that 2000 examples may be insufficient for the model to learn the transformation correctly. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the dataset size, suggesting that 2000 examples may be insufficient for the model to learn the transformation correctly. However, it lacks specificity and does not provide any guidance on how the authors might address this concern, such as suggesting additional data collection or alternative approaches. Without actionable advice or detailed feedback, the comment is not helpful in guiding the authors on how to improve their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the differences between Algorithm 1 and variational inference, specifically regarding how Algorithm 1 approximates the target distribution using a Gaussian distribution. While the comment highlights a potential area of confusion or difference, it does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the distinction. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation or comparison between the two methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the differences between Algorithm 1 and variational inference, asking for clarification on how the algorithm approximates the target distribution using a Gaussian distribution and what advantages it offers. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the differences between Algorithm 1 and variational inference, specifically regarding how Algorithm 1 approximates the target distribution using a Gaussian distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the differences between Algorithm 1 and variational inference, specifically regarding how Algorithm 1 approximates the target distribution using a Gaussian distribution. While it identifies a potential area of confusion or difference, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the distinction. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it highlights a potential area for clarification but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the entailment exercise lacks basic details and recommends either removing it from the paper or providing more empirical and analyzed information. While the action of removing the exercise is explicit, the suggestion to provide more information is vague and lacks specific guidance on what kind of information should be added or how to present it. The authors know that more information is needed, but the comment does not provide concrete steps on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies a need for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the entailment exercise, which is a specific part of the paper. This provides full grounding, as the authors can accurately identify the part being addressed. The comment specifies that the exercise lacks basic details and suggests either removing it or providing more empirical and analyzed information. This level of detail is specific, allowing the authors to understand what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the entailment exercise lacks basic details, making it difficult to assess the technique\\'s efficacy. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the entailment exercise, noting that it lacks basic details, making it difficult to assess the technique\\'s efficacy. The reviewer suggests either removing the exercise or providing more empirical and analyzed information. This feedback is clear and actionable, as it highlights a critical area for improvement and offers a specific recommendation. However, the comment could be more helpful if it provided examples of what kind of additional information would be beneficial or how the exercise could be improved. Overall, the comment is mostly helpful as it guides the authors toward addressing a significant weakness in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific lines (225 and 227) where the mathematical expression of the Gaussian distribution is ambiguous. However, it does not provide any guidance or suggestions on how the authors should address this ambiguity. The comment lacks explicit instructions or concrete steps for the authors to take, leaving them uncertain about how to improve the draft. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 225\" and \"line 227,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the ambiguity in the mathematical expression of the Gaussian distribution. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the mathematical expression of the Gaussian distribution is ambiguous in lines 225 and 227. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the mathematical expression of the Gaussian distribution in lines 225 and 227, noting that it is ambiguous. This feedback is clear and actionable, as it directs the authors to a specific area of the paper that requires clarification. However, the comment could be more helpful if it provided suggestions on how to resolve the ambiguity or offered examples of how to improve the expression. Overall, the comment is mostly helpful as it highlights a critical area for improvement but lacks depth in its guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. However, it does not provide specific guidance on which additional types of responses should be considered or how to incorporate them into the testing process. The action is implicit, as the authors need to infer that they should expand their testing to include more types of responses, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. However, it does not specify which part of the paper this feedback pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the testing methodology or results, but this inference is not explicit. The comment is specific in its suggestion to consider additional types of responses, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the current testing approach using only certain tokens is insufficient and recommends considering additional types of responses. However, the comment does not provide any specific examples or reasoning to support why additional types of responses are necessary or how they would improve the testing process. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the testing approach, suggesting that only certain tokens are used and questioning the sufficiency of this approach. It implies that additional types of responses should be considered, which could enhance the comprehensiveness of the testing. However, the comment lacks specificity and does not provide guidance on which additional types of responses should be considered or how they might be incorporated into the testing process. While it highlights an area for improvement, the feedback is somewhat helpful as it prompts the authors to consider expanding their testing methodology, but it does not offer detailed suggestions or actionable steps. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the privacy protection capability, noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also points out that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. While the comment highlights a potential problem, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should explore alternative methods or techniques to ensure effective privacy protection. However, the comment lacks concrete details on how to implement these changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the privacy protection capability, specifically mentioning the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issue with privacy protection and the limitations of using chatGPT and temperature manipulation. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the privacy protection capability is insufficient due to the use of chatGPT for text paraphrasing and the reliance on manipulating the temperature (T) for text privacy protection. However, the comment lacks specific examples or references to support the claim that chatGPT does not guarantee the removal of privacy information or that manipulating the temperature alone is not effective for text sanitization. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical issue with the privacy protection capability, specifically noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information in the rewritten text. It also points out that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. This feedback is valuable as it highlights a potential weakness in the current approach and suggests that the authors need to explore alternative methods or techniques to ensure effective privacy protection. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Overall, the comment is mostly helpful as it directs the authors' attention to a significant area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the approach described in the manuscript is not significant enough, specifically mentioning the use of word embeddings to define the weight of each lexicon term. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their approach. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the \"General Discussion\" section of the manuscript, which is fully grounded as it explicitly mentions the part of the paper being discussed. However, the comment lacks specificity as it does not provide detailed feedback on what aspects of the novelty are not significant or how the authors might improve the novelty of their approach. Without specific guidance or examples, the authors may find it challenging to address the feedback effectively. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the novelty of the approach described in the manuscript is not significant enough, specifically mentioning the use of word embeddings to define the weight of each lexicon term. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the approach described in the manuscript, specifically mentioning the use of word embeddings to define the weight of each lexicon term. However, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the novelty of their approach. Without actionable feedback or detailed insights, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but does not fully support the authors in improving their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper would benefit from comparing its method to non-NeRF methods on the mentioned tasks. This action is clear and direct, as it provides a specific direction for the authors to enhance their draft by including additional comparisons. The comment also implies that this comparison would help readers understand the proposed method\\'s advantages relative to conventional methods. The action is concrete, as it specifies what needs to be added to the paper, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. However, it does not specify which tasks or methods are being referred to, making it difficult for the authors to identify the exact part of the paper that needs this comparison. The comment is specific in its suggestion to include comparisons with non-NeRF methods, but it lacks grounding as it does not specify where in the paper this comparison should be made. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. This is a logical suggestion that aligns with the reviewer\\'s understanding of the field and the potential benefits of such comparisons. However, the comment does not provide specific examples or references to support the claim, which could make it more robust. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper could benefit from comparing its method to non-NeRF methods on the mentioned tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including additional comparisons. By comparing their method to conventional methods, the authors can better understand the advantages and limitations of their approach, which is crucial for improving the paper\\'s comprehensiveness and impact. The suggestion is detailed and constructive, offering a clear path for the authors to improve their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some of the lower-level tasks are considered NLU or syntactic tasks. While it identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment lacks concrete actions or detailed advice on what the authors should do to clarify this point. As a result, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"178:181,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether some of the lower-level tasks are considered NLU or syntactic tasks, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. However, it does not provide any additional context, reasoning, or evidence to support why this distinction is important or how it might impact the paper. The lack of detailed explanation or references makes it difficult for the authors to understand the significance of the question and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the classification of lower-level tasks as NLU or syntactic tasks, referencing a specific literature (LINSPECTOR) as an example. While it identifies a potential area of confusion, it does not provide any guidance or suggestions on how the authors might address this issue or clarify their terminology. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it highlights a potential area of concern but does not offer actionable advice or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the relationship of their idea to traditional attempts in computer vision, specifically those related to motion segmentation. While the comment implies that this addition would enhance the theoretical and academic value of the approach, it does not provide explicit instructions on how to incorporate this discussion or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors can infer the need for a discussion but lack detailed guidance on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"long-term motion trajectories\" and references a specific paper by Keuper et al. (2015) as an example of traditional attempts in computer vision. This provides clear guidance on which part of the paper the comment addresses, making it fully grounded. The comment is also specific because it suggests that the authors discuss the relationship of their idea to these traditional attempts, which would enhance the theoretical and academic value of their approach. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using long-term motion trajectories is a traditional idea in computer vision and suggests that the authors discuss the relationship of their idea to these traditional attempts. The comment provides a reference to a specific paper by Keuper et al. (2015) as an example of traditional attempts in motion segmentation. This reference offers a clear and specific example of how the authors could relate their work to existing literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential gap in the paper's discussion by noting that the use of long-term motion trajectories is a traditional idea in computer vision. It suggests that the authors should briefly discuss the relationship of their idea to these traditional attempts, which could enhance the theoretical and academic value of their approach. The comment provides a specific reference to a relevant paper (Keuper et al., 2015) that the authors could build upon. This feedback is clear and actionable, offering a concrete suggestion for improvement that could significantly strengthen the paper's contribution. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the \"problem formalization\" section, noting that it lacks a clear description of the specific task types addressed on graph data and focuses primarily on formalizing the challenges faced. The comment highlights that the purpose of this section is unclear because it fails to convey the author\\'s task objectives. This feedback is explicit in pointing out the lack of clarity and suggests that the authors need to provide a more detailed description of the tasks addressed. However, it does not offer specific guidance on how to achieve this, such as suggesting particular tasks or methodologies to include. While the action is clear, the lack of detailed instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"problem formalization\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the section, which is the lack of clarity in describing the specific task types addressed on graph data. The comment highlights that the purpose of this section is unclear due to its focus on formalizing challenges rather than conveying task objectives. This provides clear guidance on what needs to be addressed to improve the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"problem formalization\" section lacks clarity in describing the specific task types addressed on graph data, focusing primarily on formalizing challenges rather than conveying task objectives. This claim is somewhat verifiable as it identifies a specific issue with the clarity of the section\\'s purpose. However, the comment lacks detailed examples or specific references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the 'problem formalization' section of the paper, noting that it lacks a clear description of the specific task types addressed on graph data. The comment highlights that the section focuses primarily on formalizing challenges rather than conveying the author's task objectives, making it unclear in terms of purpose. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors need to clarify the tasks addressed and their objectives. However, the comment could be more helpful if it offered suggestions on how to achieve this clarity or provided examples of how to structure the section effectively. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the lack of an ablation study on training techniques, such as Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their specific impact and compare YOSO\\'s performance with other models. The comment provides a clear and concrete action for the authors to take, which is to conduct an ablation study to evaluate the impact of these techniques. This feedback is explicit and provides detailed guidance on how to improve the draft, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of an ablation study on training techniques, specifically referring to the introduction of Informative Prior Initialization (IPI) and v-prediction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014a detailed ablation study\u2014to provide a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of an ablation study on training techniques, such as Informative Prior Initialization (IPI) and v-prediction, makes it difficult to assess their specific impact and compare YOSO\\'s performance with other models. The comment provides a logical reasoning by explaining that the absence of an ablation study hinders the evaluation of the effectiveness of these techniques. However, it lacks specific examples or references to other models that could leverage these techniques, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but could be more robust with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's methodology by pointing out the absence of an ablation study on training techniques, specifically Informative Prior Initialization (IPI) and v-prediction. This feedback is highly actionable as it highlights a critical area for improvement, allowing the authors to conduct a detailed analysis of the impact of these techniques on YOSO's performance. By suggesting an ablation study, the comment provides a clear path for the authors to enhance the comprehensiveness and robustness of their evaluation. This feedback is valuable as it offers a specific and constructive suggestion for improving the draft, making it highly helpful.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper\\'s content is limited and identifies instances of redundant descriptions, such as the two paragraphs from line 229 to line 272. It suggests that the authors should present a small-scale validation experiment using the datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. While the comment explicitly states the need for a validation experiment, it does not provide detailed guidance on how to conduct this experiment or which datasets to use. The suggestion is concrete in terms of what needs to be done, but the lack of specific instructions on execution makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific lines (229 to 272) where redundant descriptions are found, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of redundancy and suggests a solution by recommending a small-scale validation experiment using the datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s content is limited and identifies instances of redundant descriptions. It provides specific examples by mentioning the two paragraphs from line 229 to line 272, which redundantly describe the motivation and work approach already covered in the introduction. Additionally, the reviewer suggests presenting a small-scale validation experiment using the datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. This feedback is mostly verifiable as it provides clear examples of redundancy and offers a specific suggestion for improvement. However, it could be strengthened by providing more detailed guidance on how to conduct the validation experiment or which datasets to use. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s content, noting that it is rather limited and contains redundant descriptions. It specifically points out that the two paragraphs from line 229 to line 272 redundantly describe the motivation and work approach already covered in the introduction. This feedback is valuable as it highlights a common problem in academic writing and provides a specific example for the authors to address. Additionally, the comment suggests a solution by recommending a small-scale validation experiment using the datasets mentioned in the paper to address the lack of domain knowledge in LLMs for specific tasks. This actionable suggestion offers a concrete way for the authors to improve their work. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a clear direction for enhancing the paper. However, it could be more helpful if it included more detailed guidance on how to conduct the validation experiment. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to re-write the section on theoretical contributions to make its connections with the proposed method clearer. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the draft. The feedback is concrete and actionable, as it gives a specific direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"theoretical contributions\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical contributions, which is their perceived abstractness and lack of connection to the proposed method. The comment suggests re-writing the section to clarify these connections, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contributions are too abstract and unclear, as they do not provide a clear connection to the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or detailed explanations of how the theoretical contributions are disconnected from the method, making it difficult for the authors to understand and address the issue. As a result, the claim is barely verifiable, as it requires more detailed justification or evidence to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical contributions, noting that they seem too abstract and disconnected from the proposed method. It provides a clear and actionable suggestion to re-write the section to clarify the connections between the theoretical contributions and the method. This feedback is valuable as it guides the authors in revising their draft to improve its clarity and coherence. However, the comment could be more helpful if it offered specific examples or suggestions on how to make the connections clearer. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises an issue regarding the clarity of whether the code will be released, particularly noting that the GCN implementation might be challenging to reproduce without the original code. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify this point, but it does not specify what information or details should be included to make the code more reproducible. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of code release and the potential difficulty in reproducing the GCN implementation without the original code. However, it does not specify which part of the paper discusses the code or the GCN implementation, making it weakly grounded. The comment is specific in identifying the challenge of reproducibility and the need for clarification, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the reproducibility of the GCN implementation, noting that it may be challenging without the original code. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the GCN implementation is hard to reproduce. The mention of detailed descriptions and information in the supplement provides some context but does not substantiate the claim fully. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the reproducibility of the GCN implementation, noting that it may be challenging without the original code. While it identifies a potential issue, the comment lacks specificity and actionable guidance on how the authors might address this concern. It does not provide suggestions for improving the reproducibility of the code or offer alternative ways to present the information. As a result, the feedback is somewhat helpful, as it highlights an important aspect to consider but does not offer detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of second-order Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. However, it does not provide any explicit guidance or suggestions on how the authors should proceed. The comment lacks concrete details or actions for the authors to take, such as recommending the use of differential functions or explaining why the Taylor expansions are necessary. As a result, the authors are left without a clear understanding of what changes are needed or how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of second-order Taylor expansions instead of differential functions and asks why this choice was made. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the use of second-order Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. However, the comment does not provide any reasoning, examples, or references to support why this choice is problematic or why the differential functions should be used instead. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of second-order Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. While it identifies a potential issue, it does not provide any further explanation or guidance on why this choice might be problematic or how it could be improved. The comment lacks depth and actionable suggestions, leaving the authors without a clear path to address the concern. Therefore, it is rated as barely helpful, as it provides a starting point for the authors but does not fully support their efforts to improve the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to related work, including [1] by Pourdamghani and Knight, [2] by He et al., and [3] by Ryskina et al., which discuss similar topics. However, the comment does not explicitly instruct the authors to include the missing recall values or to discuss these references in their paper. While the comment provides valuable information, it lacks explicit guidance on how to address the issue, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the missing recall on lemmas/forms seen in training for the en-cs BPE to character results. Additionally, the comment provides references to related work, which further clarifies the context and potential improvements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the en-cs BPE to character results in Table 3 are missing the recall on lemmas/forms seen in training. It provides references to related work, including [1] by Pourdamghani and Knight, [2] by He et al., and [3] by Ryskina et al., which discuss similar topics. However, the comment does not provide specific examples or detailed reasoning on how these references relate to the missing recall values or why they are important. While the references are relevant to the topic, the lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to explore the references further to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Table 3, noting that the en-cs BPE to character results are missing the recall on lemmas/forms seen in training. It provides references to related work, including [1] by Pourdamghani and Knight, [2] by He et al., and [3] by Ryskina et al., which discuss similar topics. This feedback is valuable as it directs the authors' attention to a potential gap in their results and suggests relevant literature for further exploration. However, the comment could be more helpful if it offered specific guidance on how to address the missing recall values or how the references might inform the analysis. Overall, the comment is mostly helpful as it highlights an important area for improvement and provides a starting point for further investigation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the impact of the proposed method on the MLSC setup, despite the claim that better word-alignment improves many-to-many translation. It suggests that Section 4 should provide an explanation for this observation. However, the comment does not explicitly instruct the authors to include an explanation or to clarify the discrepancy. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation in their draft. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 3' and 'Section 4,' allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the proposed method has no impact on the MLSC setup despite the claim about better word-alignment improving many-to-many translation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a question about the impact of the proposed method on the MLSC setup, despite the claim that better word-alignment improves many-to-many translation. It suggests that Section 4 should provide an explanation for this observation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or the need for an explanation. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a critical question about the impact of the proposed method on the MLSC setup, despite the claim that better word-alignment improves many-to-many translation. It highlights a discrepancy that the authors need to address, specifically why the method has no impact on the MLSC setup as detailed in Table 3. The comment is somewhat helpful as it identifies a potential weakness in the paper's claims and suggests that Section 4 should provide an explanation for this observation. However, it could be more helpful if it offered specific guidance or suggestions on how to address this issue or what kind of explanation is needed. Overall, the comment provides a starting point for the authors to consider, but it lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation of the method, specifically its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. The comment implies that the authors should consider expanding the applicability of their method to online settings. However, it does not provide explicit guidance on how to achieve this or suggest specific steps to address the limitation. The action is implicit and somewhat vague, as the authors need to infer that they should explore online applicability but are not given concrete advice on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the method, namely its restriction to an offline setting. It points out that the method requires pre-collected offline datasets and cannot be applied in an online setting where policies interact with the environment. This feedback is fully grounded as it explicitly mentions the offline setting and the inability to apply the method in an online setting, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the method\\'s applicability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is restricted to an offline setting and cannot be applied in an online setting where policies interact with the environment. This claim is somewhat verifiable as it provides a logical reasoning for the limitation, suggesting that the method's reliance on pre-collected datasets makes it unsuitable for online applications. However, the comment lacks specific examples or references to support the claim fully. The authors would need to infer the extent of the limitation and how it affects the applicability of the method. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant limitation of the method, specifically its restriction to an offline setting where it requires pre-collected datasets and cannot be applied in an online setting. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should consider expanding the applicability of their method to online settings. However, the comment could be more helpful if it provided suggestions on how to address this limitation or explored potential solutions. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for enhancement but lacks detailed guidance on how to achieve it. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the evaluation of the learned representation is limited to a linear evaluation setting, suggesting that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for a more comprehensive evaluation. While the comment implies that the authors should consider these additional tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include these tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the learned representation, specifically mentioning the linear evaluation setting. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in suggesting that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for a more comprehensive evaluation. This provides clear guidance on what the authors should consider expanding their evaluation to include. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of the learned representation is insufficient because it is only evaluated on the linear evaluation setting. The reviewer suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for a more comprehensive evaluation. While the comment provides a logical argument for expanding the evaluation, it lacks specific references or examples to support the claim fully. The suggestion is based on common knowledge in the field, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the evaluation of the learned representation, specifically noting that it is only evaluated on the linear evaluation setting. It suggests that other downstream tasks, such as fine-tuning, detection, and segmentation, could be used for a more comprehensive evaluation. This feedback is clear and actionable, as it provides the authors with a specific direction for improving their evaluation methodology. By suggesting additional tasks, the comment offers a concrete way to enhance the robustness and relevance of the evaluation. However, the comment could be more helpful if it provided examples or references to support the suggestion. Overall, the comment is mostly helpful as it guides the authors towards a more comprehensive evaluation approach, but it could be further enhanced with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the novelty of the work, noting that stage-wise and progressive training have been proposed for a long time and are widely used. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects need to be revised. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the work, specifically mentioning stage-wise and progressive training, which have been proposed for a long time and are widely used. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. The authors may have an idea of where this critique applies, but it is not explicitly mentioned, making the comment weakly grounded. The comment is specific in identifying the issue of lack of novelty in the use of stage-wise and progressive training, but it lacks detailed guidance on how to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the work is very low because stage-wise and progressive training have been proposed for a long time and are widely used. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses a concern about the novelty of the work, noting that stage-wise and progressive training have been proposed for a long time and are widely used. This feedback highlights a potential issue with the originality of the approach. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might enhance the novelty of their work. Without detailed feedback or constructive advice, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, as it identifies a concern but does not offer actionable insights or suggestions for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the extension of the analysis to more general cases, specifically regarding the handling of more general Markov chains and the inclusion of FFN and nonlinearity on top of the attention layer. While the comment implies that the authors should address these aspects, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these extensions but are not given concrete steps or suggestions on how to approach them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the extension of the analysis to more general cases, specifically regarding the handling of more general Markov chains and the inclusion of FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the generalizability of the analysis and the potential inclusion of additional components, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification on the generalizability of the analysis and the handling of more general Markov chains, including the presence of FFN and nonlinearity on top of the attention layer. These questions are not claims but rather inquiries seeking additional information or explanation. Therefore, they do not fit the criteria for a claim, and the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the generalizability of the analysis and the handling of more general Markov chains, including the presence of FFN and nonlinearity on top of the attention layer. These questions are relevant and could help the authors expand the scope of their work and address potential limitations. However, the comment does not provide specific guidance or suggestions on how to address these issues, such as recommending additional experiments or theoretical considerations. While it prompts valuable reflections, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the discussion regarding [19] in section 3.1, specifically questioning whether it uses the same Fine state automaton or if there are any differences. While the comment highlights a potential issue with the clarity of the discussion, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the use of the Fine state automaton in their discussion. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.1\" and \"line 57,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in the discussion regarding the use of [19] and the Fine state automaton. The comment questions whether [19] uses the same Fine state automaton or if there are any differences, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of the discussion regarding [19] in section 3.1, specifically questioning whether it uses the same Fine state automaton or if there are any differences. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the discussion regarding [19] in section 3.1, questioning whether it uses the same Fine state automaton or if there are any differences. This feedback is clear and actionable, as it directs the authors to clarify this point in their discussion. However, the comment could be more helpful if it provided additional context or suggestions on how to address the issue, such as specific examples or references to similar discussions. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the auto_weight scheme in Algorithm 1, specifically mentioning that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to two external works, FedGP and FLamby, which address similar issues in federated learning. However, the comment does not explicitly instruct the authors to address this issue or suggest how to mitigate the memory requirement. The action is implicit and somewhat vague, as the authors need to infer that they should consider optimizing the memory usage or exploring alternative approaches. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the auto_weight scheme, specifically mentioning the requirement for intermediate gradients for each domain, which could lead to high memory usage. The comment further provides references to external works, FedGP and FLamby, which address similar issues in federated learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the auto_weight scheme in Algorithm 1 requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to two external works, FedGP and FLamby, which address similar issues in federated learning. This provides some support for the claim by linking it to relevant literature, but the comment could be strengthened by offering more detailed reasoning or examples on how these references specifically relate to the issue. The lack of specific details or examples makes the claim somewhat verifiable, as the authors would need to explore the references further to fully understand the implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the auto_weight scheme in Algorithm 1, specifically noting that it requires intermediate gradients for each domain, which could lead to high memory usage. It provides references to two external works, FedGP and FLamby, which address similar issues in federated learning. This feedback is valuable as it highlights a critical aspect of the algorithm that could impact its practical implementation and scalability. By referencing relevant literature, the comment offers a pathway for the authors to explore potential solutions or optimizations. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address the memory issue or if it discussed alternative approaches. Overall, the comment is mostly helpful as it directs the authors' attention to a significant concern and provides a starting point for further investigation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the backbone is constrained to a double LSTM, while transformers are not involved, and this may be a limitation. It suggests that the application of the method to more extensive model structures is a potential concern. While the comment highlights an issue, it does not provide explicit guidance on how the authors should address this limitation or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should consider incorporating transformers or exploring more extensive model structures. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of the double LSTM as the backbone, noting that popular transformers are not involved. It also mentions that the application of the method to more extensive model structures is a potential concern, particularly regarding the limitation of not covering pre-trained language models. However, the comment does not specify which part of the paper discusses the backbone or the application of the method, making it weakly grounded. The comment is specific in identifying the issue with the lack of transformers and the potential limitations in applying the method to more extensive structures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of a double LSTM as the backbone is a limitation, as transformers are not involved, and this may be a concern for the application of the method to more extensive model structures. However, the comment lacks specific examples or references to support the claim that transformers are not well-suited for the task or that the method's application to more extensive structures is a concern. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the use of a double LSTM as the backbone, noting that popular transformers are not involved. It highlights that this limitation may affect the application of the method to more extensive model structures, such as pre-trained language models. The comment also points out that the limitations are mentioned in Section 6 but suggests that they may not be sufficient. While the comment correctly identifies an area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or enhance the method's applicability. The feedback is somewhat helpful as it points out a potential issue but does not provide actionable steps for improvement, leaving the authors with a general direction to consider.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the contribution and novelty of the paper are limited, as it combines existing techniques such as structure learning regularization (NOTEARS), missing value imputation, and variational inference for model parameter learning. However, it does not provide any explicit or implicit suggestions for how the authors might enhance the novelty or contribution of their work. There is no guidance on what additional techniques, approaches, or insights the authors could explore to make their paper more innovative. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution and novelty of the paper, stating that the model proposed combines existing techniques. However, it does not specify which sections or parts of the paper this critique pertains to, making it difficult for the authors to identify the exact areas needing improvement. The comment lacks specificity in detailing what aspects of the existing techniques are being combined or how the paper could be more innovative. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution and novelty of the paper are limited because it combines existing techniques, such as structure learning regularization (NOTEARS), missing value imputation, and variational inference for model parameter learning. However, the comment does not provide specific examples or references to these existing techniques, nor does it explain how the combination of these techniques makes the paper less innovative. Without detailed justification or references, the claim is difficult for the authors to verify and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the contribution and novelty of the paper, noting that it combines existing techniques such as structure learning regularization, missing value imputation, and variational inference for model parameter learning. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might enhance the novelty or contribution of their work. Without additional context or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment points out that the contribution and novelty of the paper are limited, as it combines existing techniques such as structure learning regularization, missing value imputation, and variational inference for model parameter learning. However, it does not provide any explicit or implicit suggestions for how the authors might enhance the novelty or contribution of their work. There is no guidance on what additional techniques, approaches, or insights the authors could explore to make their paper more innovative. As a result, the comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the contribution and novelty of the paper, noting that it combines existing techniques such as structure learning regularization, missing value imputation, and variational inference for model parameter learning. However, it does not specify which sections or parts of the paper this critique pertains to, making it difficult for the authors to identify the exact areas needing improvement. The comment lacks specificity in detailing what aspects of the existing techniques are being combined or how the paper could be more innovative. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the contribution and novelty of the paper are limited because it combines existing techniques, such as structure learning regularization (NOTEARS), missing value imputation, and variational inference for model parameter learning. However, the comment lacks specific examples or references to these existing techniques, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim is challenging to verify, leaving the authors without a clear understanding of how to address the issue. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the contribution and novelty of the paper, noting that it combines existing techniques such as structure learning regularization, missing value imputation, and variational inference for model parameter learning. However, it does not provide specific suggestions or guidance on how the authors might enhance the novelty or contribution of their work. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment highlights that the contribution and novelty of the paper are limited, as it"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an interesting comparison between MSLR and a late-fusion model with separate learning rates for each modality. It implies that the authors should consider this comparison to better understand the efficiency and effectiveness of their approach. However, the comment does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should explore this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison between MSLR and a late-fusion model with separate learning rates for each modality. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare the two approaches, but without explicit references to sections or figures, the authors may struggle to pinpoint where this comparison should be made. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a comparison between MSLR and a late-fusion model with separate learning rates for each modality. It claims that MSLR requires knowing the optimal learning rates in advance, which necessitates additional resources for tuning and discarding unimodal models. The reviewer proposes that this comparison would be interesting, especially with a similar or less compute budget. However, the comment lacks specific examples or references to support the claim about the necessity of knowing optimal learning rates in advance. While the suggestion is logical, it could be strengthened with more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable basis for the claim but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests an interesting comparison between MSLR and a late-fusion model with separate learning rates for each modality. It highlights a potential limitation of MSLR, which requires knowing the optimal learning rates in advance, and proposes that this could be compared to a more efficient approach. This feedback is somewhat helpful as it identifies a potential area for improvement and suggests a comparison that could enhance the paper's analysis. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment offers a direction for further exploration but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the ambiguity of the notation for L_{flow}(X) and suggests that L_{flow}(F) or L_{flow}(F,S) might be more appropriate to reflect the actual inputs. While the comment implies that the authors should consider revising the notation, it does not explicitly instruct them to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should address the ambiguity in the notation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"notation for L_{flow}(X)\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the ambiguity of the notation and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the ambiguity of the notation for L_{flow}(X) and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these alternatives are more appropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the notation for L_{flow}(X) and suggests alternatives, such as L_{flow}(F) or L_{flow}(F,S), to better reflect the actual inputs. This feedback is clear and actionable, as it provides a specific suggestion for improving the clarity and consistency of the notation. By addressing this issue, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it explained why these alternatives are more appropriate or provided examples of how they might be used. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the necessity of using 8-bit representation for input and points out that 8-bit batch normalization has been proposed before. While it questions the novelty of the work, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve their draft. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their work. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment raises a question about the necessity of using 8-bit representation for input and references a previous work on 8-bit batch normalization. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in questioning the novelty of the work by pointing out the prior existence of 8-bit batch normalization. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the novelty of the work by pointing out that 8-bit batch normalization has been proposed before. It provides a specific reference to a previous work (https://arxiv.org/pdf/1805.11046.pdf), which supports the claim that the proposed method is not entirely novel. This provides a clear and specific justification for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment raises a pertinent question about the necessity of using 8-bit representation for input, suggesting that 8-bit batch normalization has been proposed before. This critique challenges the novelty of the work, which is a valuable insight for the authors to consider. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice on how to improve the draft. Therefore, the comment is somewhat helpful, as it highlights an important area for consideration but lacks depth in its guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve the practical relevance of their framework. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the practical relevance of the proposed framework in the context of Graph Neural Networks (GNNs) being dominant in the graph representation learning domain. However, it does not specify which part of the paper this critique pertains to, such as a particular section, table, or figure. The authors may infer that it relates to the introduction or discussion section, but this inference is not explicit. The comment is specific in its critique of the practical relevance of the framework, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the practical relevance of the proposed framework may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a potential limitation of the proposed framework, suggesting that its practical relevance may be limited due to the current dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. This feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and specificity. The authors are left with a general understanding of the challenge but without actionable guidance on how to address it or improve the practical relevance of their framework. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of including $X$ in the calculation of M_{t}, suggesting that an experiment should be added to demonstrate this. While the comment implies that the authors should conduct this experiment to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add an experiment to demonstrate the necessity of $X$. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the calculation of M_{t} using only $C$ without $X$, suggesting that an experiment should be added to demonstrate the necessity of $X$. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to add an experiment to address the necessity of $X$, but without grounding, the authors may struggle to identify the exact section where this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the calculation of M_{t} using only $C$ without $X$, suggesting that an experiment should be added to demonstrate the necessity of $X$. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the calculation of M_{t}, specifically asking how the results would be affected if only $C$ is used without $X$. It suggests that an experiment should be added to demonstrate the necessity of including $X$. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct the experiment or what specific results should be expected. The authors are left with a general suggestion but without actionable steps or detailed feedback, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses an observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any guidance or suggestions for the authors to address or improve this observation. There is no explicit or implicit action for the authors to take, nor is there any concrete advice on how to incorporate this observation into the paper. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any details on why this observation is relevant or how it could be addressed. Without clear grounding and specificity, the authors cannot effectively respond to the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a subjective claim about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an observation about the complexity of problems involving MLPs compared to those involving FBDDs and perceptrons. However, it does not provide any context, analysis, or suggestions on how this observation might impact the paper or what implications it has for the authors. Without actionable feedback or guidance, the comment does not offer the authors any meaningful insights or steps to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should discuss the generalizability of the observations, particularly those in Figure 4, and how various hyperparameters might influence implicit biases in the algorithm. It provides a specific example of hyperparameters that could be considered, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling. However, the comment does not explicitly instruct the authors to discuss these aspects or provide detailed guidance on how to incorporate this discussion into their paper. While the suggestion is clear, it lacks concrete instructions on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the generalizability of observations, specifically those in Figure 4, and how various hyperparameters might influence implicit biases in the algorithm. It provides a specific example of hyperparameters that could be considered, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling. However, the comment does not explicitly mention which part of the paper this discussion should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, as it highlights the importance of discussing the generalizability of observations and the influence of hyperparameters. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss the generalizability of observations, such as those in Figure 4, and how various hyperparameters might influence implicit biases in the algorithm. While the comment provides a logical reasoning for why this discussion is important, it lacks specific examples or references to support the claim. The suggestion is based on common knowledge about the influence of hyperparameters on implicit biases, but without detailed evidence or examples, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should discuss the generalizability of their observations, particularly those in Figure 4, and how various hyperparameters might influence implicit biases in the algorithm. It provides a specific example of hyperparameters that could be considered, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling. This feedback is clear and actionable, as it guides the authors to address a potential limitation of their work and suggests a direction for improvement. However, the comment could be more helpful if it provided specific examples of how these hyperparameters might affect the results or offered suggestions on how to incorporate this discussion into the paper. Overall, the comment is mostly helpful as it identifies a relevant area for improvement and provides a clear direction for the authors to follow.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honst\" in section 4. It suggests using \"honest-but-curious\" instead, which is a more standard term. While the comment identifies a specific issue with terminology, it does not provide explicit guidance on how to reorganize the paper or suggest specific changes to improve its organization. The action is implicit and somewhat vague, as the authors need to infer that they should address the organization and terminology issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of non-standard terminology, particularly the term \"semi-honst\" and suggests using \"honest-but-curious\" instead. This provides clear guidance on how to improve the terminology. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not well-organized and uses non-standard terminology, specifically mentioning the term \"semi-honst\" in section 4. It suggests using \"honest-but-curious\" instead, which is a more standard term. The comment provides a specific example of a terminology issue and offers a suggestion for improvement, making it mostly verifiable. However, it could be strengthened by providing additional examples or references to support the claim about the standard terminology. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the organization of the paper and the use of non-standard terminology. It points out the term 'semi-honst' and suggests using 'honest-but-curious' instead, which is a more standard term. This feedback is clear and actionable, as it provides a specific correction that can improve the clarity and professionalism of the paper. However, the comment could be more helpful if it offered additional guidance on how to reorganize the paper or suggested other areas that might benefit from similar improvements. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification on three specific aspects of the experimental details: the optimizer, initialization, and PPO-zero. Each question provides a clear and direct action for the authors to take, which is to specify these details in their draft. The comments are concrete and specific, giving the authors a clear path to follow in addressing the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lots of experimental details are missing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the missing details about the optimizer, initialization, and PPO-zero. This provides clear guidance on what the authors need to include in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a series of questions asking for clarification on specific experimental details, such as the optimizer, initialization, and PPO-zero. These are factual inquiries that do not express an opinion, judgment, or suggestion. They are purely descriptive and seek additional information to understand the experimental setup better. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks clarity and detail, namely the optimizer, initialization, and PPO-zero. By pointing out these missing details, the comment provides clear and actionable feedback that can help the authors improve the transparency and reproducibility of their experimental setup. However, the comment could be more helpful if it suggested how to address these issues or provided examples of how to include this information in the draft. Overall, the comment is mostly helpful as it directs the authors to important areas needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that a detailed comparison of efficiency analysis, including total model parameters, FLOPs, and memory, is needed. It also suggests that this comparison should be made with and without the additional components like the detector and LaVIT. This provides a clear and direct action for the authors to take, specifying what needs to be included in the analysis. The comment is explicit and concrete, guiding the authors on how to improve their draft by addressing the efficiency and complexity of their proposed method. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the efficiency and complexity of the proposed method, specifically mentioning the use of two image encoders and a detector in the decoding process. It points out that other existing works do not require such additional components. The comment suggests a detailed comparison of efficiency analysis, including total model parameters, FLOPs, and memory, with and without these additional components. While the comment does not explicitly mention specific sections of the paper, it is clear that it pertains to the efficiency and complexity discussion. The authors can infer that it relates to the methodology or results sections, but the lack of explicit section references makes it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the efficiency analysis, making it specific. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires additional components like LaVIT and Eva-CLIP for encoding and a detector for decoding, which is not common in other existing works. The reviewer suggests that a detailed comparison of efficiency analysis, including total model parameters, FLOPs, and memory, is needed to justify the necessity of these additional components. While the comment provides a logical argument for the need for such a comparison, it lacks specific references or detailed examples to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires additional evidence or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in terms of efficiency and complexity analysis. It points out that the proposed method requires additional components like LaVIT and Eva-CLIP for encoding and a detector for decoding, which is not common in other existing works. The comment suggests that a detailed comparison of efficiency analysis, including total model parameters, FLOPs, and memory, should be conducted with and without these additional components. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their analysis and improving the comprehensiveness of their work. By addressing this suggestion, the authors can better justify the necessity of the additional components and provide a more robust evaluation of their method. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the paper\\'s claim that extrapolation error is a major issue in MARL, noting that the authors do not provide any evidence to support this claim. It also critiques the proposed techniques for bias/variance reduction, suggesting they are not directly related to extrapolation error. The comment highlights the lack of evidence that the proposed method mitigates extrapolation error, which is crucial for better performance. However, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to take. The feedback is implicit and somewhat vague, as it does not offer concrete steps for the authors to take to substantiate their claims or improve their methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"extrapolation error\" claim and the two proposed techniques for bias/variance reduction. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the lack of evidence supporting the claim about extrapolation error and the relevance of the proposed techniques. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim about extrapolation error being a major issue in MARL is not supported by evidence. It also critiques the proposed techniques for bias/variance reduction, suggesting they are not directly related to extrapolation error. The comment provides a logical argument by questioning the relevance of the proposed methods to the issue of extrapolation error and the lack of evidence for improved performance. However, it lacks specific examples or references to substantiate the claim, making it somewhat verifiable. The authors would need to provide additional evidence or examples to fully address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's claim that extrapolation error is a major issue in MARL, noting that the authors do not provide any evidence to support this claim. It also critiques the proposed techniques for bias/variance reduction, suggesting they are not directly related to extrapolation error. The comment highlights the lack of evidence that the proposed method mitigates extrapolation error, which is crucial for better performance. However, the feedback could be more helpful if it provided specific suggestions on how the authors might substantiate their claims or improve their methods. Overall, the comment is mostly helpful as it points out a critical weakness in the paper's argument and offers a direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment provides a clear and explicit action for the authors to take. It suggests that the authors should include detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME's efficiency over conventional FFNs. The comment also emphasizes the need for additional information, such as benchmark configurations, hardware, and input shapes, to ensure fair comparisons. These suggestions are concrete and provide specific guidance on what the authors need to do to improve their draft. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Tables 4 and 8,' allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the authors include detailed on-device results across ablation and comparison studies to substantiate claims about SCHEME's efficiency over conventional FFNs. Additionally, it highlights the need for additional information, such as benchmark configurations, hardware, and input shapes, to ensure fair comparisons. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that SCHEME's on-device efficiency is underexplored and suggests that only limited throughput comparisons are presented in Tables 4 and 8. The reviewer proposes that including detailed on-device results across ablation and comparison studies would substantiate claims about SCHEME's efficiency. Additionally, the comment emphasizes the need for additional information, such as benchmark configurations, hardware, and input shapes, to ensure fair comparisons. While the comment provides a logical argument for the need for more detailed on-device results, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's evaluation, specifically the lack of detailed on-device results to substantiate claims about SCHEME's efficiency over conventional FFNs. It provides a clear and actionable suggestion by recommending the inclusion of detailed on-device results across ablation and comparison studies. Additionally, the comment emphasizes the need for additional information, such as benchmark configurations, hardware, and input shapes, to ensure fair comparisons. This feedback is specific and provides the authors with a clear direction for improving their draft, making it highly helpful. However, it could be further enhanced by offering more detailed guidance on how to present these results or by suggesting specific benchmarks or metrics to include. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM), which could potentially mislead readers. However, the comment does not provide any explicit guidance or suggestions on how to change the name or what alternative name might be more appropriate. The action is implicit and vague, as the authors are left to infer that they should change the name but are not given concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM), which could potentially mislead readers. However, it does not specify which part of the paper this name appears in, making it weakly grounded. The comment is specific in its critique of the name, suggesting that it might be misleading, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM), which could potentially mislead readers. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM), which could potentially mislead readers. While the comment identifies a potential issue with the name, it lacks specific guidance or suggestions on how to address this concern or what alternative name might be more appropriate. The feedback is somewhat helpful as it points out a potential confusion but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment states that the proposed method is not the best performer in both robustness and fidelity, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or improve their method. The comment lacks specificity and does not offer any suggestions for further experimentation or analysis. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"experiments results\" and \"proposed method,\" but it does not specify which part of the paper these results are from or which specific experiments are being discussed. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in pointing out that the proposed method is not the best performer in both robustness and fidelity, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is not the best performer in both robustness and fidelity, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific data, comparisons, or references to other methods, the authors are left without a clear understanding of the basis for this assertion. As a result, the claim is unverifiable, as it lacks the necessary details to support the authors\\' efforts to improve their work. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the proposed method is not the best performer in both robustness and fidelity, which is a critical observation. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their method. Without actionable feedback or detailed insights, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a problem but does not offer constructive feedback or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a lack of clarity in the paper regarding the motivation and logical connections between the concepts of isometry, OT, and disentanglement. It suggests that the authors should explain these connections more clearly in the revision. While the comment explicitly states that the authors need to clarify the connections, it does not provide specific guidance on how to achieve this. The action is implicit but concrete, as the authors know what needs to be done to improve the draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity in the paper regarding the motivation and logical connections between the concepts of isometry, OT, and disentanglement. It explicitly mentions these concepts, providing full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely, the need for a clearer explanation of the connections between these concepts. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation and logical connections in the paper are unclear, specifically regarding the concepts of isometry, OT, and disentanglement. The reviewer suggests that the authors should explain the connections between these concepts more clearly. While the comment identifies a potential issue, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact points of confusion or lack of clarity, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s clarity regarding the motivation and logical connections between the concepts of isometry, OT, and disentanglement. It points out that the authors claim that adding geometrical constraints (isometry) can help disentanglement, but this connection is not explained well in the paper. The reviewer also questions why OT is required for isometry and suggests that the authors should clarify these connections more clearly in the revision. This feedback is clear and actionable, as it provides specific areas for improvement and guidance on how the authors can enhance the clarity of their paper. However, it could be more helpful if it offered suggestions on how to explain these connections or provided examples of how to clarify them. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement and offers a clear direction for revision.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of the results on regular languages, suggesting that they may not be helpful for explaining how and why real-world language models work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what additional information or analysis could be included to make the results more relevant. As a result, the comment lacks actionable guidance, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the relevance of the results on regular languages, suggesting that they may not be helpful for explaining how and why real-world language models work. However, it does not specify which part of the paper discusses these results or how they are currently presented. The authors might infer that it relates to the results section, but this inference is not explicit. The comment lacks specificity in detailing what aspects of the results are unclear or how they could be improved to better explain real-world language models. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the relevance of the results on regular languages, suggesting that they may not be helpful for explaining how and why real-world language models work. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the relevance of the results on regular languages, suggesting that they may not be helpful for explaining how and why real-world language models work. While it identifies a potential issue, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this concern or improve the relevance of their results. Without actionable feedback or additional context, the authors are left without a clear direction for enhancing their draft. Therefore, the comment is rated as barely helpful, as it highlights a potential weakness but does not offer constructive guidance for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty of the paper in relation to the Venom paper [1]. It specifically asks whether the V:N:M proposed in the paper differs from the Venom paper [1]. While the comment highlights a potential area of overlap or novelty, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the differences between their work and the Venom paper, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the paper in relation to the Venom paper [1]. It specifically asks whether the V:N:M proposed in the paper differs from the Venom paper [1]. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the novelty and differentiation of the proposed work from the Venom paper. The authors can infer that it relates to the introduction or discussion sections where the novelty of the paper is presented. However, the comment lacks specificity as it does not detail what aspects of the paper need to be clarified or how the authors should address the question of novelty. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the novelty of the paper in relation to the Venom paper [1]. It specifically asks whether the V:N:M proposed in the paper differs from the Venom paper [1]. While the comment is a question seeking clarification, it does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry that seeks additional information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the paper in relation to the Venom paper [1]. It specifically asks whether the V:N:M proposed in the paper differs from the Venom paper [1]. While the comment identifies a potential area of overlap or novelty, it does not provide specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. The feedback is somewhat helpful as it prompts the authors to clarify the differences between their work and the Venom paper, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses dissatisfaction with the attribution maps, noting that the attended areas of the image do not seem to be related to the actual task, such as in 3D tasks where the 3D worth pixels are not attended. It also mentions clusters of attended pixels without clear semantic meaning. However, the comment acknowledges that the resulting analysis using the attribution maps is effective, suggesting that there is a quantitative value. The reviewer questions the lack of qualitative value in the attribution maps. While the comment identifies a potential issue with the qualitative interpretation of the maps, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the maps. The action is implicit and vague, as the authors are left to infer that they need to enhance the qualitative interpretation of the maps, but without concrete steps on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the attribution maps, noting that the attended areas of the image do not seem to be related to the actual task and that there are clusters of attended pixels without clear semantic meaning. The comment further acknowledges that the resulting analysis using the attribution maps is effective, suggesting that there is a quantitative value. However, it questions the lack of qualitative value in the attribution maps. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the qualitative interpretation of attribution maps, noting that the attended areas of the image do not seem to be related to the actual task, such as in 3D tasks where the 3D worth pixels are not attended. It also mentions clusters of attended pixels without clear semantic meaning. However, the comment acknowledges that the resulting analysis using the attribution maps is effective, suggesting that there is a quantitative value. While the comment provides some reasoning and examples, it lacks specific references or detailed explanations to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration for full clarity and support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the attribution maps, noting that the attended areas of the image do not seem to be related to the actual task, such as in 3D tasks where the 3D worth pixels are not attended. It also mentions clusters of attended pixels without clear semantic meaning, suggesting a lack of qualitative value in the maps. However, the comment acknowledges that the resulting analysis using the attribution maps is effective, indicating that there is a quantitative value. While the comment highlights a potential weakness in the qualitative interpretation of the maps, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the maps. The feedback is somewhat helpful as it points out a concern but lacks actionable advice, leaving the authors with a general direction to consider.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns. First, it suggests that the title overclaims the contribution of the paper, as it does not include results from \"large language models (LLMs) such as Llama2-70b.\" This implies that the authors should provide empirical justification for the scalability of their proposed method to LLMs. Second, it points out a minor issue with consistency in terminology, specifically regarding the use of \"ROBERTA\" and \"RoBerta.\" While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to update the title to reflect the actual scope of the results and ensure consistency in terminology. The feedback is somewhat actionable as it provides clear guidance on what needs to be addressed but lacks detailed instructions on how to implement these changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two main issues: the title and the consistency of terminology. Regarding the title, it suggests that the title overclaims the contribution of the paper by not including results from \"large language models (LLMs) such as Llama2-70b.\" This implies that the authors should provide empirical justification for the scalability of their proposed method to LLMs. The comment is fully grounded as it explicitly mentions the title and the specific issue with the results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed regarding the title and the scalability of the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two concerns: the title and the consistency of terminology. Regarding the title, the reviewer claims that it overclaims the contribution of the paper by not including results from \"large language models (LLMs) such as Llama2-70b.\" This claim is somewhat verifiable as it points out a specific gap in the results, but it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to show empirical justification for the scalability of the proposed method to LLMs is a logical extension of the initial observation. The comment also highlights a minor issue with terminology consistency, which is addressed in a separate part of the comment. Overall, the comment provides some support for the claims but could be strengthened with more detailed reasoning or examples. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two main areas for improvement in the paper. First, it critiques the title, suggesting that it overclaims the contribution of the paper by not including results from 'large language models (LLMs) such as Llama2-70b.' This feedback is actionable as it prompts the authors to provide empirical justification for the scalability of their proposed method to LLMs, which is a critical aspect of the paper's contribution. Second, the comment points out a minor issue with terminology consistency, specifically regarding the use of 'ROBERTA' and 'RoBerta' in different sections of the paper. This feedback is also helpful as it guides the authors to ensure consistency in terminology throughout the paper. Overall, the comment provides clear and actionable feedback that can significantly improve the clarity and accuracy of the paper, making it mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of motivation for choosing date and country as possible spurious correlating variables with gender. It suggests that the paper should provide a more specific rationale for these choices. However, the comment does not explicitly instruct the authors to include this rationale or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer that they need to justify their choices, but the comment does not offer concrete steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the lack of motivation for choosing date and country as possible spurious correlating variables with gender. It explicitly mentions \"date and country,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the lack of motivation for these choices. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide a specific motivation for choosing date and country as possible spurious correlating variables with gender. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it lacks a clear motivation for choosing date and country as possible spurious correlating variables with gender. While the comment points out a gap in the paper, it does not provide any suggestions or guidance on how the authors might address this issue or improve their rationale. This limits the usefulness of the feedback, as it does not offer actionable steps or insights for the authors to enhance their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the incremental nature of the contribution regarding exchanging channels, noting that it is achieved using BN. It also questions the rationale of Theorem 1, suggesting that it is based on [38] and appears to be a simple fact. However, the comment does not provide explicit guidance or suggestions for the authors to address these concerns. The action is implicit and vague, as the authors are left to infer that they need to clarify the incremental nature of their contribution and the rationale behind Theorem 1. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific point about the contribution of exchanging channels and its reliance on BN. It questions the incremental nature of the contribution and suggests that the rationale of Theorem 1 is based on [38], implying that it may be a simple fact. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or theorem, making it weakly grounded. The comment is specific in its critique of the incremental nature of the contribution and the rationale of Theorem 1, but without explicit grounding, it is challenging for the authors to pinpoint the exact part of the paper needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the incremental nature of the contribution regarding exchanging channels, noting that it is achieved using BN. It also questions the rationale of Theorem 1, suggesting that it is based on [38] and appears to be a simple fact. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the critique. The mention of [38] provides some context, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the incremental nature of the contribution regarding exchanging channels, noting that it is achieved using BN. It also questions the rationale behind Theorem 1, suggesting that it is based on [38] and appears to be a simple fact. While the comment identifies specific areas for improvement, it lacks detailed guidance or suggestions on how the authors might address these concerns or enhance their contribution. The feedback provides some insight into potential weaknesses in the paper but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns. First, it questions whether the main contribution and practical method are adequately supported by in-depth studies, suggesting that more research is needed to establish the improvement in damping for second-order methods. This implies that the authors should conduct additional studies to substantiate their claims. Second, it asks for clarification on the meaning of \"K\" and whether it is equal to \"NC,\" which is a minor point. While the first part of the comment provides a clear action for the authors to take, the second part is a minor clarification request. Overall, the comment is mostly actionable as it explicitly directs the authors to conduct additional studies and provides a specific clarification question, but it could be more detailed in terms of the scope and depth of the required studies.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the depth of studies needed to establish the improvement in damping for second-order methods, and it asks for clarification on the meaning of \"K\" and whether it equals \"NC.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two concerns. First, it questions whether the main contribution and practical method are adequately supported by in-depth studies, suggesting that more research is needed to establish the improvement in damping for second-order methods. This is a logical claim that requires the authors to provide evidence or justification for their claims. Second, it asks for clarification on the meaning of \"K\" and whether it equals \"NC,\" which is a minor point. Overall, the comment is mostly verifiable as it provides a logical claim for the first part and a specific question for the second part, but it lacks detailed reasoning or references to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises two concerns. First, it questions whether the main contribution and practical method are adequately supported by in-depth studies, suggesting that more research is needed to establish the improvement in damping for second-order methods. This feedback is actionable and provides a clear direction for the authors to strengthen their claims by conducting additional studies. Second, it asks for clarification on the meaning of \"K\" and whether it equals \"NC,\" which is a minor point. While this part of the comment is not as impactful as the first, it still contributes to the overall helpfulness by prompting the authors to clarify a minor point. Overall, the comment is mostly helpful as it identifies a significant area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends more analysis of the running time or complexity, specifically mentioning the impact of k and N on the running time. Additionally, it raises a minor comment about a potential mismatch between Figure 2 and the corresponding description. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes. The actions are implicit but concrete, as the authors can infer what needs to be done to enhance the draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2\" and the corresponding description, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, an in-depth analysis of the parameters k and N in the ablation study and more analysis of the running time or complexity. This provides clear guidance on what aspects of the paper require attention. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends more analysis of the running time or complexity, specifically mentioning the impact of k and N on the running time. Additionally, it raises a minor comment about a potential mismatch between Figure 2 and the corresponding description. While the suggestion for more analysis is logical and could be beneficial, the comment does not provide specific examples or references to support the claim about the mismatch in Figure 2. This makes the claim somewhat verifiable, as it provides a general suggestion but lacks detailed evidence or examples to fully substantiate the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides actionable feedback by suggesting that an in-depth analysis of the parameters k and N in the ablation study would enhance readers\\' understanding of the algorithm. It also recommends more analysis of the running time or complexity, specifically mentioning the impact of k and N on the running time. This feedback is clear and provides specific areas for improvement, making it mostly helpful. However, it could be more helpful if it included detailed suggestions or examples on how to conduct this analysis. Overall, the comment offers valuable insights that can guide the authors in enhancing their draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the lack of standard deviation in the results presented in Appendix B, despite the mention of averaging over 10 runs. It also inquires about the nature of these 10 runs, whether they involve random hyperparameter configurations for all baselines or the best selected values. While the comment identifies a potential issue with the presentation of results, it does not explicitly instruct the authors to address this concern or provide specific guidance on how to improve the draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the standard deviation and the nature of the 10 runs. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Appendix B,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the absence of standard deviation in the results, asking why this information is missing and whether the 10 runs were conducted with random or best hyperparameter configurations. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a question about the lack of standard deviation in the results presented in Appendix B, despite the mention of averaging over 10 runs. It also inquires about the nature of these 10 runs, whether they involve random or best hyperparameter configurations. The comment is based on a logical question about the completeness of the reported results, which is a common concern in scientific reporting. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully address the reviewer's concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the presentation of results in Appendix B, specifically regarding the lack of standard deviation despite averaging over 10 runs. It also inquires about the nature of these 10 runs, whether they involve random or best hyperparameter configurations for all baselines. This feedback is valuable as it prompts the authors to clarify and potentially improve the transparency and robustness of their results. However, the comment could be more helpful if it provided suggestions on how to address these issues, such as recommending the inclusion of standard deviation or a discussion on the implications of the hyperparameter configurations. Overall, the comment is mostly helpful as it identifies a significant area for improvement but lacks detailed guidance on how to implement the suggested changes.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that more details about the task generation process should be included in the main text, not just in the appendix. This provides a clear and direct action for the authors to take, which is to move the relevant information to the main text. The suggestion is concrete, as it specifies what needs to be done and where it should be placed, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more details about the task generation process should be included in the main text, not just in the appendix. This provides a clear and specific direction for the authors to improve their paper. It explicitly mentions the task generation process, allowing the authors to accurately identify the part of the paper being addressed. The comment also specifies what needs to be addressed, namely, the inclusion of more details in the main text. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more details about the task generation process should be included in the main text, not just in the appendix. This is a logical suggestion based on the reviewer\\'s understanding of the importance of providing comprehensive information for readers to fully grasp the experimental setup. However, the comment does not provide specific examples or references to support why this is necessary or how it would strengthen the paper\\'s presentation. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of this suggestion themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, suggesting that more details about the task generation process should be included in the main text, not just in the appendix. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the clarity and comprehensiveness of the paper\\'s presentation. By addressing this point, the authors can improve the reader\\'s understanding of the experimental setup, which is crucial for the paper\\'s overall impact. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate these details effectively. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more detailed.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should clarify the representation of entropy in the paragraphs \"Individual-level entropy\" and \"Group-level entropy\" by indicating that entropy depends on a datapoint, such as $H(p^a|x)$. This feedback provides a clear and direct action for the authors to take, which is to make the formulas more understandable. The suggestion is concrete, as it specifies what needs to be changed and how to do it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"Individual-level entropy\" and \"Group-level entropy\" paragraphs, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is clarifying the representation of entropy to make formulas more understandable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a change in notation to clarify that entropy depends on a datapoint, such as $H(p^a|x)$. This is a logical suggestion that aims to improve the clarity and understandability of the formulas. However, the comment does not provide specific examples or references to support the claim that this change would make the formulas more understandable. While the suggestion is reasonable, it lacks detailed justification or evidence, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the clarity of the paper by suggesting that the authors clarify the representation of entropy in the paragraphs \"Individual-level entropy\" and \"Group-level entropy.\" It specifies that the entropy should be represented as $H(p^a|x)$ to make formulas like $\\text{argmax}_{x \\in U, a \\in A} H^a$ more understandable. This feedback is specific and provides a direct way for the authors to enhance the clarity and comprehensibility of their work. However, it could be more helpful if it included additional guidance on how to implement this change or if it pointed out other areas where similar clarifications might be needed. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for full comprehensiveness.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper connects tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this suggestion should be implemented or what specific changes are needed to achieve this connection. Without actionable steps or detailed instructions, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of this method need to be addressed or improved. Without clear grounding or detailed guidance, the authors cannot effectively respond to the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any context, explanation, or justification for why this approach is beneficial or how it could improve the paper. Without specific guidance or examples, the authors are left without actionable feedback on how to implement this suggestion or why it is relevant to their work. As a result, the comment is not helpful, as it lacks depth and actionable insights for the authors to improve their draft. Therefore, it aligns with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any explicit or implicit actions for the authors to take, nor does it offer guidance on how to implement this suggestion. Without actionable steps or detailed instructions, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of this method need to be addressed or improved. Without clear grounding or detailed guidance, the authors are left without a clear understanding of how to respond to the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any context, explanation, or justification for why this approach is beneficial or how it could improve the paper. Without specific guidance or examples, the authors are left without actionable feedback on how to implement this suggestion or why it is relevant to their work. As a result, the comment is not helpful, as it lacks depth and actionable insights for the authors to improve their draft. Therefore, it aligns with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': \"The review comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any explicit or implicit actions for the authors to take, nor does it offer guidance on how to implement this suggestion. Without actionable steps or detailed instructions, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests a"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO). It points out that the only difference between the two is the use of entropy to capture the difference between distributions, and it questions the advantage of this specific distance metric. The reviewer suggests that the authors provide a more comprehensive illustration of this relationship. While the comment identifies a specific area for improvement and suggests a course of action, it does not provide explicit guidance on how to address this issue or what specific aspects of the illustration should be included. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the relationship with Distributionally Robust Optimization and the specific difference between the proposed DD risk and DRO risk, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the advantage of the specific distance metric used and suggests providing a more comprehensive illustration. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO), noting that the only difference is the use of entropy to capture the difference between distributions. It references existing works in the DRO literature that use different distance metrics and suggests that the authors provide a more comprehensive illustration of this relationship. While the comment questions the advantage of the specific distance metric and suggests further exploration, it does not provide specific examples or references to support the claim. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the relationship between the proposed DD risk and Distributionally Robust Optimization (DRO), noting that the only difference is the use of entropy to capture the difference between distributions. It points out that there are works in the DRO literature using different distance metrics, such as $f$-divergence, Wasserstein distance, and MMD distance, and questions the advantage of the specific distance metric used in the proposed DD risk. The reviewer suggests that the authors provide a more comprehensive illustration of this relationship. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper by questioning the uniqueness or advantage of the proposed distance metric. However, it lacks specific guidance on how the authors might address this issue or what aspects of the illustration should be expanded upon. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the nature of the T-REx dataset, suggesting that it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment raises a valid point about the dataset\\'s labeling, it does not provide explicit guidance on how the authors should address this issue. The question implies that the authors should consider evaluating their model on annotated datasets, but it does not offer concrete steps or suggestions on how to implement this evaluation. The action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the nature of the T-REx dataset, suggesting it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the dataset description or evaluation section. The authors can infer that it relates to the methodology or experimental setup, but the comment does not specify which part of the paper this question addresses. The comment is specific in its inquiry about the possibility of evaluating the model on annotated datasets, but it lacks full grounding as it does not directly reference a section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the nature of the T-REx dataset, suggesting it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment raises a valid point about the dataset\\'s labeling, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest why evaluating on annotated datasets would be beneficial. The lack of justification or examples makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the question. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the nature of the T-REx dataset, suggesting it is a distantly supervised dataset without human labels. It then asks if it is possible to evaluate the model over an annotated dataset, such as TACRED or FewRel. While the comment identifies a potential issue with the dataset's labeling, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their evaluation. The question is clear and raises an important point about the dataset's limitations, but it lacks actionable advice or detailed feedback on how to proceed. Therefore, the comment is somewhat helpful, as it prompts the authors to consider an important aspect of their dataset but does not fully guide them in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the appendix should be proofread using NeurIPS 2021 style files. It also provides specific examples of issues in the text, such as \"P6: \u201cposter mean\u201d, \u201cpeicewise-linear\u201d\" and \"P9: \u201csugggest\u201d,\" which the authors can address. Additionally, the comment suggests that the limitations and societal impacts are discussed but could be further elaborated. While the action is explicit, the comment does not provide detailed guidance on how to address the specific issues mentioned, such as how to correct the errors or expand on the societal impacts. The feedback is mostly actionable because it identifies specific areas for improvement but lacks detailed instructions on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the appendix, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the use of NeurIPS 2021 style files and provides examples of specific errors in the text, such as \"P6: \u201cposter mean\u201d, \u201cpeicewise-linear\u201d\" and \"P9: \u201csugggest\u201d.\" This level of detail helps the authors understand what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the appendix is not using NeurIPS 2021 style files and suggests giving it a proofread. It also points out specific issues in the text, such as \"P6: \u201cposter mean\u201d, \u201cpeicewise-linear\u201d\" and \"P9: \u201csugggest\u201d,\" which the authors should address. The comment provides specific examples of where the issues occur, making it somewhat verifiable. However, it lacks detailed reasoning or references to support the claim about the style file issue, which could be improved with more explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the use of NeurIPS 2021 style files in the appendix, suggesting that the authors should give it a proofread. It also points out specific errors in the text, such as 'P6: \u201cposter mean\u201d, \u201cpeicewise-linear\u201d' and 'P9: \u201csugggest\u201d', which the authors can address. Additionally, the comment highlights that the limitations and societal impacts are discussed but could be further elaborated. This feedback is mostly helpful as it provides clear and actionable suggestions for improvement, allowing the authors to enhance the quality and completeness of their draft. However, it could be more helpful if it offered specific guidance on how to expand on the societal impacts. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to examine the training and validation curves of different losses and to determine if the model can simultaneously reduce all three losses. It also asks about any tricks related to weighing these losses. While the comment implies that the authors should investigate these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should analyze the training and validation curves and consider weighing the losses. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests looking at training and validation curves of different losses and questions whether the model can simultaneously reduce all three losses. It also inquires about any tricks related to weighing these losses. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these curves are discussed. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its request for information about the model\\'s performance and potential tricks for weighing losses, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests looking at training and validation curves of different losses and questions whether the model can simultaneously reduce all three losses. It also inquires about any tricks related to weighing these losses. However, the comment does not provide any specific reasoning, examples, or references to support the claim that examining these curves would be beneficial or to explain why the model might not be able to reduce all three losses simultaneously. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests examining the training and validation curves of different losses to determine if the model can simultaneously reduce all three losses. It also questions whether there are any tricks related to weighing these losses. This feedback is somewhat helpful as it provides a specific area for the authors to investigate, which could lead to improvements in the model's performance. However, the comment lacks depth and does not offer detailed guidance or suggestions on how to analyze the curves or address the weighing of losses. To be more helpful, the comment could include specific recommendations or examples of how to approach this analysis. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper\\'s claim of NP-hardness for computing the GOSPA metric. It points out that the paper lacks a rigorous theoretical argument or proof, and it questions the validity of the claim. The reviewer suggests that the paper\\'s assumption of access to the optimal assignment matrix limits its applicability. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to strengthen their argument. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"NP-hardness\" and references specific claims made in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim of NP-hardness, questioning the lack of a rigorous theoretical argument or proof and suggesting that the paper\\'s assumption of access to the optimal assignment matrix limits its applicability. The reviewer provides a logical reasoning and references external works, such as the claim that the assignment problem is not generally NP-hard, which supports the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of NP-hardness for computing the GOSPA metric is not generally true for assignment problems and suggests that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. The reviewer provides a logical reasoning by questioning the validity of the claim and suggesting a potential reduction, which supports the critique. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s claim of NP-hardness for computing the GOSPA metric. It points out that the paper lacks a rigorous theoretical argument or proof, questioning the validity of the claim. The reviewer provides a logical reasoning by suggesting that the claim may not be generally true for assignment problems and that it may be possible to reduce GOSPA to an exact polynomial-time computable assignment problem. Additionally, the comment highlights a potential inconsistency in the paper\\'s assumption of access to the optimal assignment matrix, which could limit the applicability of the results. While the comment effectively identifies a critical weakness in the paper, it could be more helpful if it provided suggestions on how the authors might address these issues or improve their argument. Overall, the comment is mostly helpful as it provides clear and actionable feedback, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include an algorithmic writeup of the solution to the pricing problem. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include an algorithmic writeup. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or subsection. Without explicit references to specific parts of the paper, the authors may find it challenging to determine where to incorporate this information. Additionally, the comment lacks specificity regarding what aspects of the algorithmic writeup are needed or how it should be structured. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it would be helpful to have an algorithmic writeup of the solution to the pricing problem. However, it does not provide any specific reasoning, examples, or references to support why this would be beneficial or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include an algorithmic writeup of the solution to the pricing problem. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the algorithmic writeup should be included or how it could enhance the paper. Without actionable advice or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for enhancement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off requires intelligent exploration and gradual updates during initialization, but it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should clarify or provide additional explanation regarding the role of model averaging in their technique. However, it lacks concrete suggestions or detailed steps on how to improve the draft. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward, specifically regarding the need for intelligent exploration and gradual updates during initialization. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the effectiveness of model averaging and suggesting potential mechanisms, but without explicit references to the paper, the authors may struggle to pinpoint the exact section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off requires intelligent exploration and gradual updates during initialization, but it does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the need for model averaging or the effectiveness of the proposed technique in achieving the trade-off. As a result, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the effectiveness of model averaging in balancing the trade-off between KL divergence and reward. It suggests that achieving this trade-off effectively requires intelligent exploration and gradual updates during initialization, but it does not provide specific examples or references to support this claim. While the comment identifies a potential area for improvement, it lacks detailed guidance or actionable suggestions for the authors to address this issue. The feedback is somewhat helpful as it prompts the authors to clarify or expand on their approach, but it could be more comprehensive and actionable with additional insights or suggestions. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss a possible generalization with a different distribution for the size of the batches. While the comment implies that this discussion is necessary, it does not provide explicit guidance on how to conduct this discussion or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer the details of the discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss a different distribution for the size of the batches, but without explicit references to the paper, the authors may struggle to pinpoint the exact section where this discussion should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a possible discussion regarding a generalization with a different distribution for the size of the batches. However, it does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it could impact the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a potential area for discussion regarding a generalization with a different distribution for the size of the batches. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on how to conduct this discussion or what aspects should be considered. The comment identifies a potential area for improvement but does not offer actionable advice or examples, making it somewhat helpful. The authors may find it useful to consider this suggestion but would need to further develop it themselves. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis only considers a batch size of 1 and questions the impact of the batch size on the effective initialization scale. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific steps they should consider to explore the effect of batch size on the initialization scale. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue: the lack of consideration of different batch sizes and the unclear impact on the effective initialization scale. This provides clear guidance on what needs to be addressed in the analysis section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis only considers a batch size of 1 and questions the impact of the batch size on the effective initialization scale. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the analysis, noting that it only considers a batch size of 1 and does not address how the batch size affects the effective initialization scale. This feedback is somewhat helpful as it highlights an area where the authors could expand their analysis to provide a more comprehensive understanding of their results. However, the comment lacks depth and does not offer suggestions on how the authors might explore the impact of different batch sizes or what specific aspects of the analysis could be improved. To be more helpful, the comment could include suggestions for additional experiments or analyses that could be conducted to address this limitation. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the results shown in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It asks for an explanation, such as why sampling 50% of the data yields better results than sampling 100%. While the comment implies that the authors should provide an explanation for this observation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this question in their draft. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results shown in the figure, specifically why more data leads to lower results on the ImageNet linear evaluation and why sampling 50% of the data seems to yield better results than sampling 100%. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a question about the results shown in Figure 7, specifically why more data leads to lower results on the ImageNet linear evaluation. It asks for an explanation, such as why sampling 50% of the data yields better results than sampling 100%. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest why this might be the case. Without additional context or justification, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a specific question about the results shown in Figure 7, questioning why more data leads to lower results on the ImageNet linear evaluation. It provides a clear and detailed inquiry, asking for an explanation or justification for this observation. This feedback is actionable as it prompts the authors to address a potential issue in their results and provides a specific area for improvement. However, the comment could be more helpful if it suggested how the authors might investigate or explain this phenomenon. Overall, the comment is mostly helpful as it directs the authors' attention to a critical aspect of their results that needs further exploration.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of comprehensive evaluation, specifically mentioning the absence of quantitative results on FVD, a widely recognized metric for evaluating temporal video prediction. It suggests including FVD to enhance the paper\\'s credibility and comparability to other video generation methods. While the comment implies that the authors should include FVD in their evaluation, it does not provide explicit instructions on how to incorporate this metric or what specific results should be presented. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of comprehensive evaluation, specifically mentioning the absence of quantitative results on FVD, a widely recognized metric for evaluating temporal video prediction. It suggests including FVD to enhance the paper\\'s credibility and comparability to other video generation methods. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the evaluation section. The authors can infer that it relates to the results or discussion sections, but the comment does not provide explicit references to specific parts. The feedback is specific in detailing what is missing and how it could be improved, but the lack of explicit section references makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks comprehensive evaluation, specifically mentioning the absence of quantitative results on FVD, a widely recognized metric for evaluating temporal video prediction. The reviewer suggests that including FVD would enhance the paper\\'s credibility and comparability to other video generation methods. While the comment provides a logical argument for the inclusion of FVD, it lacks specific references or examples to fully substantiate the claim. The suggestion is mostly verifiable, as it offers a clear rationale for the inclusion of FVD, but the lack of detailed evidence or examples makes it somewhat verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper\\'s evaluation, specifically the lack of quantitative results on FVD, a widely recognized metric for evaluating temporal video prediction. It suggests that including FVD would enhance the paper\\'s credibility and comparability to other video generation methods. The comment also points out the limited novelty and insufficient methodological depth of the work, which detracts from its overall impact as a research paper. While the feedback highlights important areas for improvement, it could be more helpful if it provided specific guidance on how to incorporate FVD or other metrics into the evaluation. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the technical details in section 2.2 are difficult to follow. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify the technical details or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"2.2,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. However, the comment does not specify what is wrong with the technical details or suggest how they could be improved. It lacks specificity regarding the issues with the technical details, making it difficult for the authors to understand exactly what needs to be addressed. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the technical details in section 2.2 are hard to follow, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the technical details in section 2.2, noting that they are difficult to follow. However, it lacks actionable feedback or suggestions on how the authors might clarify or improve the technical details. Without additional guidance or specific recommendations, the authors are left without a clear path to address the issue. Therefore, the comment is barely helpful, as it points out a problem but does not provide actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the improvements offered by EVA over the backbone models, specifically OT-Flow. It asks for clarification on how the addition of geometry information and motif-interpolation benefits the design choices. While the comment identifies a gap in the paper's presentation, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the improvements and benefits of EVA over the backbone models. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the empirical evaluation of EVA and its comparison with the backbone models, specifically OT-Flow. It questions the improvements offered by EVA over these models, particularly in the context of the RFDiffusion benchmark. The comment is fully grounded as it explicitly mentions the RFDiffusion benchmark and the comparison with OT-Flow, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of understanding the improvements offered by EVA and the potential benefits of the design choices. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the improvements offered by EVA over the backbone models, specifically OT-Flow. It highlights that in most experiments on the RFDiffusion benchmark, backbone models perform better in terms of designability and success rates. The comment seeks clarification on how EVA offers improvements over these models. While the comment poses a valid question, it does not provide specific evidence or reasoning to support the claim that EVA does not offer improvements. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to provide additional information to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical question about the improvements offered by the work over existing backbone models, such as OT-Flow. It highlights that in most experiments on the RFDiffusion benchmark, these models perform better in terms of designability and success rates. The comment seeks clarification on how the proposed method, EVA, offers improvements over the backbone models. This feedback is valuable as it prompts the authors to provide a detailed explanation of the enhancements and benefits of their approach, which is crucial for understanding the main contribution of the work. However, the comment could be more helpful if it suggested specific areas where the authors should focus their explanation or provided examples of how EVA improves upon the backbone models. Overall, the comment is mostly helpful as it identifies a key area for clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address the issue, such as suggesting ways to rephrase or eliminate redundant sentences. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the presence of too many identical sentences in the Abstract, Introduction, and Conclusion sections. However, it does not specify which sentences are identical or provide guidance on how to address this issue. The authors can infer that the comment pertains to these sections, but the lack of specificity makes it difficult for them to pinpoint the exact sentences that need revision. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific examples or detailed explanation, the authors may find it challenging to understand the issue and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that there are too many identical sentences in the Abstract, Introduction, and Conclusion sections. This feedback is clear and actionable, as it highlights a common issue that can affect the clarity and flow of the paper. However, the comment does not provide specific suggestions on how to address this issue, such as recommending ways to rephrase or eliminate redundant sentences. While it points out a problem, it lacks depth and actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification about the reward function used in the ablation studies, specifically questioning whether it is sEH. This request provides a clear and direct action for the authors to take, which is to specify the reward function used in their study. The comment is explicit and concrete, as it directly instructs the authors on what information is needed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Reward Function,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification about the reward function used in the ablation studies, particularly whether it is sEH. This provides clear guidance on what information is needed to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the reward function used in the ablation studies, specifically questioning whether it is sEH. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, which is why it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and specific, asking for clarification about the reward function used in the ablation studies. This is an important detail that could impact the understanding and reproducibility of the results. By identifying this gap, the comment provides a direct and actionable suggestion for the authors to include this information in their draft. However, it could be more helpful if it offered additional context or guidance on why this information is crucial. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional context. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the comparison between self-generated code and a placeholder code, noting that the self-generated code is not a fair comparison due to the sampling process. However, it does not provide explicit guidance on how the authors should address this issue or improve the comparison. The comment lacks concrete suggestions or actions for the authors to take, making it unactionable. The authors are left without a clear understanding of what changes are necessary to make the comparison fairer. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the comparison between self-generated code and a placeholder code, noting that the self-generated code is not a fair comparison due to the sampling process. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the comparison, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that using self-generated code instead of a placeholder is not a fair comparison due to the sampling process. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison between self-generated code and a placeholder code, noting that the self-generated code is not a fair comparison due to the sampling process. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the comparison. Without detailed feedback or concrete steps, the authors are left without a clear understanding of what changes are necessary to make the comparison fairer. Therefore, the comment is rated as barely helpful, as it provides some insight but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a specific issue with the paper, noting that sections 3 and 4, which are crucial for the main contributions, are compressed into a single page. It specifically mentions the absence of precise mathematical definitions of quantum states in Eq (4), making it difficult to follow. While the comment identifies a problem, it does not provide explicit guidance on how to address it, such as suggesting the addition of these definitions or expanding the sections. The action is implicit and somewhat vague, as the authors need to infer that they should expand the sections and include the missing definitions. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'sections 3 and 4,' allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the lack of precise mathematical definitions of quantum states in Eq (4), making it difficult to follow. This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that sections 3 and 4 are compressed and lack precise mathematical definitions, making it difficult to follow. However, the comment does not provide specific examples or references to support the claim, such as which definitions are missing or how they impact the paper's clarity. Without detailed evidence or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that sections 3 and 4, which are crucial for the main contributions, are compressed into a single page. It highlights a particular area where the paper lacks precision, specifically mentioning the absence of precise mathematical definitions of quantum states in Eq (4), making it difficult to follow. This feedback is clear and actionable, as it directs the authors to expand these sections and include the necessary definitions to improve the paper's clarity and comprehensibility. However, the comment could be more helpful if it provided suggestions on how to structure the sections or what specific information should be included. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting specific analyses or methodologies to ensure fairness. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its concern about fairness and discrimination, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or references, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important concern about the fairness of the results with respect to under-represented groups, specifically mentioning the possibility of discrimination against females or blacks in the recommendations of LLMs. This is a critical issue that the authors should address to ensure the ethical and responsible use of their work. However, the comment lacks specificity and does not provide actionable guidance on how to investigate or mitigate these concerns. While it highlights a significant area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides three specific comments for improvement. The first comment suggests that the paragraph describing Co-variance in Section 1 is too long, which reduces the legibility of the paper. The second comment highlights that the paper only provides two illustrations for generating long-tailed datasets, and more details should be added to support the experiments. The third comment suggests that the tables and figures are dense due to limited pages, and the authors can use more pages to emphasize the experiments on long-tailed datasets. Each comment provides a clear and specific action for the authors to take, making the feedback mostly actionable. The authors know exactly what needs to be addressed in each case, ensuring a high level of actionability.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 1\" and \"Co-variance,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the length of the paragraph describing Co-variance and the need for more details on the generation of long-tailed datasets and the experiments on them. Additionally, it suggests using more pages for the experiments on long-tailed datasets due to the density of the tables and figures. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of three minor comments, each suggesting specific improvements to the paper. The first comment critiques the length of the paragraph describing Co-variance, which affects the legibility of the paper. The second comment points out that the paper only provides two illustrations for generating long-tailed datasets, suggesting that more details should be added to support the experiments. The third comment addresses the density of the tables and figures due to limited pages, recommending the use of more pages for the experiments on long-tailed datasets. While the comments provide suggestions for improvement, they do not contain claims or opinions that require verification. Therefore, the comments are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides three specific and actionable suggestions for improvement. It identifies that the paragraph describing Co-variance in Section 1 is too long, which reduces the legibility of the paper. It also points out that the paper only provides two illustrations for generating long-tailed datasets, suggesting that more details should be added to support the experiments. Additionally, it notes that the tables and figures are dense due to limited pages and recommends using more pages for the experiments on long-tailed datasets. These suggestions are clear and provide the authors with specific areas to address, making the comment mostly helpful. However, it could be more helpful if it offered additional guidance or examples on how to implement these suggestions. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what specific changes are needed or how to implement them. Without actionable steps or suggestions, the authors are left without a clear understanding of what modifications are necessary. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the necessary changes to make EC-Diffusers work on real-world data. However, it does not specify which part of the paper this question pertains to, nor does it provide any specific details or examples of what changes are needed. Without explicit references to sections, tables, or figures, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity in terms of what changes are necessary or how to implement them. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification on the necessary changes to make EC-Diffusers work on real-world data. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the necessary changes to make EC-Diffusers work on real-world data. While it identifies a potential area for improvement, it lacks specificity and actionable guidance. The authors are left without clear direction on what specific changes are needed or how to address the issue. The feedback is vague and does not provide detailed suggestions or examples, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. However, it does not provide explicit instructions or guidance on how the authors should conduct such a study or what specific aspects of the evaluation protocol need to be improved. The action is implicit and somewhat vague, as the authors can infer the need for a human study but lack detailed instructions on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for a human study to assess the evaluation protocol, but without grounding, it is weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the evaluation is unreliable or lacks efficacy. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the reliability of the evaluation and suggests the need for a human study to gauge the efficacy of the evaluation protocol. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s methodology, prompting the authors to consider additional validation methods. However, the comment lacks specific guidance on how to conduct a human study or what aspects of the evaluation protocol should be assessed. To be more helpful, the comment could provide more detailed suggestions or examples of how a human study could be designed and integrated into the evaluation process. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point expresses a concern about the novelty of the work, comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what specific aspects of their work could be improved to enhance its novelty. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the work, comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, it does not specify which part of the paper this comparison is based on, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in detailing what aspects of the work are incremental or how it could be improved to enhance its novelty. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the work is somewhat incremental compared to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or references, the authors may find it challenging to understand the basis of the comparison and address the concern effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient evidence or justification to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment expresses a concern about the novelty of the work, comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). While it identifies a potential issue, the comment lacks specificity and actionable guidance. It does not provide detailed feedback on how the authors might address this concern or what aspects of their work could be improved to enhance its novelty. Without actionable suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a potential weakness but does not offer constructive feedback for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of the quality of questions and answers generated by the LLM for the performance of PromptMix. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. While the comment implies that such an analysis would be valuable, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to perform it. The action is implicit and somewhat vague, as the authors can infer the need for an analysis but lack detailed instructions on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of PromptMix, specifically noting that it depends on the quality of questions and answers generated by the LLM. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the performance and implementation aspects of PromptMix. The authors can infer that it relates to the methodology or results sections, but the comment does not provide explicit references to specific parts. The suggestion is specific, as it outlines what kind of analysis would be helpful. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of PromptMix depends on the quality of questions and answers generated by the LLM. It implies that using a high-quality model is essential for the success of the task. The reviewer suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. While the comment provides a logical reasoning for the importance of the quality of questions and answers, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a direction for further investigation but requires additional evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights an important aspect of the paper's performance, noting that the quality of questions and answers generated by the LLM is crucial for the success of PromptMix. It suggests that an analysis of which open-source LLMs would work with this approach or finding a parameter count cutoff (e.g., 7B) below which performance would degrade would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to explore in terms of improving the robustness and applicability of their approach. By addressing this point, the authors could enhance the credibility and utility of their work. Therefore, the comment is rated as mostly helpful, as it offers valuable insights and guidance for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the submodularity approach, specifically mentioning the SATURATE algorithm and its scaling with N^5. It suggests that the authors should comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. While the comment implies that the authors should provide more information on the scalability and performance of their approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed information on the scalability and runtimes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"appendix D.4\" and \"Section 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the scalability of the submodularity approach, particularly the use of the SATURATE algorithm and its scaling with N^5. The comment further suggests that the authors should comment on the feasibility of this approach by addressing the runtimes of the simulations for large models in Section 6. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the complexity of the submodularity approach, which uses the SATURATE algorithm, scales with N^5, as mentioned in appendix D.4. The reviewer suggests that it is worth commenting on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. While the comment raises a valid concern about the scalability of the approach, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of \"Krause et al., 2008\" provides some context, but the comment could be strengthened with additional references or detailed analysis. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to fully support the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the scalability of the submodularity approach, specifically mentioning the SATURATE algorithm and its scaling with N^5. It suggests that the authors should comment on the feasibility of this approach, particularly by addressing the runtimes of the simulations for large models in Section 6. This feedback is somewhat helpful as it points out a critical aspect of the paper's methodology that needs further exploration and clarification. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue, such as recommending alternative approaches or providing more detailed analysis of the scalability. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the explanation of inference at test time could be improved by providing more details. However, it does not specify what aspects of the inference process need more detail or how the authors should expand their explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide additional details but are not given clear guidance on what those details should be. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Inference at test time,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the explanation of inference at test time could benefit from more details. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the explanation of inference at test time could be improved by providing more details. However, it does not provide any specific examples, reasoning, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific area where the paper could be improved by providing more details about inference at test time. This feedback is clear and actionable, as it directs the authors to enhance their explanation, which could potentially clarify the methodology and improve the paper\\'s comprehensibility. However, the comment could be more helpful if it provided specific suggestions on what aspects of the inference process need more detail or how the authors might expand their explanation. Overall, the comment is mostly helpful as it highlights a specific area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the evaluation of CodeChain, including the alignment of program correctness with human preference, the effectiveness of sub-module generation, and the performance drop in the 5th iteration of self-revise prompting. However, it does not provide explicit guidance or suggestions on how the authors should address these issues. The comments are vague and lack concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses several specific issues related to the evaluation of CodeChain, including the alignment of program correctness with human preference, the effectiveness of sub-module generation, and the performance drop in self-revise prompting. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the concerns, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the evaluation of CodeChain, including the alignment of program correctness with human preference, the effectiveness of sub-module generation, and the performance drop in self-revise prompting. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of evidence or references leaves the claims somewhat verifiable, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas for improvement in the paper, including the evaluation of CodeChain's correctness and soundness. It points out that the evaluation of program correctness and reusability is unclear, particularly in relation to human preference. Additionally, it questions the effectiveness of sub-module generation and highlights a slight performance drop in the 5th iteration of self-revise prompting. While the comment raises important issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their evaluation methods. The feedback is somewhat helpful as it provides a starting point for the authors to consider, but it could be more actionable with detailed recommendations or examples.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the claim made in lines 306-307 regarding the higher overall accuracy of deferring classifiers at a given minimum subgroup accuracy. It prompts the authors to consider whether this implies that the error rate on other subgroups is smaller, leading to a less evenly distributed error rate and thus less fairness. While the comment raises an important point for consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the implications of this claim and potentially revise their analysis or conclusions accordingly. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lines 306-307,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim made in those lines, asking whether it implies a certain relationship between error rates across subgroups. The comment provides a clear direction for the authors to consider, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the claim made in lines 306-307 regarding the higher overall accuracy of deferring classifiers at a given minimum subgroup accuracy. It prompts the authors to consider whether this implies a specific relationship between error rates across subgroups. While the comment does not contain an explicit claim, it does pose a logical question that requires the authors to clarify or address the implications of their claim. Since it does not make a subjective claim or suggest a specific action, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the claim made in lines 306-307 regarding the higher overall accuracy of deferring classifiers at a given minimum subgroup accuracy. It prompts the authors to consider whether this implies a specific relationship between error rates across subgroups, questioning the fairness implications of the claim. This feedback is valuable as it challenges the authors to reconsider their analysis and potentially revise their conclusions to address the fairness aspect. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might explore or address this issue. Overall, the comment is mostly helpful as it directs the authors to an important area for further consideration and analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the claim about the relational embedding module improving object classification is not supported by results, and it suggests that reporting the improvement directly on object classification would strengthen the paper. This feedback is clear and provides a direct action for the authors to take, which is to include the requested results. The comment is explicit and concrete, guiding the authors on how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that the relational embedding module improves object classification, noting that no results are provided to support this claim. The comment suggests that reporting the improvement directly on object classification would strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim about the relational embedding module improving object classification is not supported by results. This is a factual statement that does not require verification, as it is based on the absence of supporting evidence. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the claim about the relational embedding module improving object classification is not supported by results. It provides a clear and actionable suggestion for the authors to report the improvement directly on object classification, in addition to the overall scene graph results. This feedback is valuable as it guides the authors on how to strengthen their paper by providing concrete evidence for their claims. However, the comment could be more helpful if it offered additional guidance on how to present these results or what specific improvements should be highlighted. Overall, the comment is mostly helpful, as it effectively directs the authors to improve their draft by addressing a critical gap in their paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer suggests that the novelty of the manuscript is relatively small, as it primarily adds self-supervised learning on top of existing work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph. It references a specific CVPR 2020 paper as a comparison, suggesting that the novelty of the manuscript is relatively small because it primarily adds self-supervised learning on top of existing work. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point critiques the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer suggests that the novelty of the manuscript is relatively small, as it primarily adds self-supervised learning on top of existing work. However, the comment lacks specific examples or detailed comparisons to substantiate the claim about the novelty being small. While the reference to the CVPR 2020 paper provides some context, it does not fully support the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the scope of the paper, noting that it combines self-supervised learning with multimodal representation learning based on hypergraph, which has been explored in a previous CVPR 2020 paper. The reviewer suggests that the novelty of the manuscript is relatively small, as it primarily adds self-supervised learning on top of existing work. While the comment identifies a potential issue with the novelty of the paper, it lacks specific suggestions or guidance on how the authors might enhance the novelty or address this critique. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps or detailed advice for improvement, leaving the authors with limited guidance on how to address the issue. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the difficulty of finding intuitive attention examples, specifically referencing Figure 4. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps to consider. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the difficulty of finding intuitive attention examples, specifically referring to Figure 4. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in asking about the difficulty of finding intuitive examples, but without explicit references to the paper, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the difficulty of finding intuitive attention examples, specifically referring to Figure 4. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the difficulty of finding intuitive attention examples, specifically referring to Figure 4. While it identifies a potential area for improvement, it lacks actionable feedback or suggestions for the authors to address this issue. Without specific guidance or examples, the comment does not provide the authors with a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it offers a starting point for consideration but does not fully support the authors in improving their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks a question about the difference between 01 and 10 in Figure 1, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific information needs to be clarified. Without any actionable steps or suggestions, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks a clear question about the difference between 01 and 10 in the figure, providing a specific area for the authors to clarify. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question asking for clarification about the difference between 01 and 10 in Figure 1. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a question asking for clarification about the difference between 01 and 10 in Figure 1. While it identifies a specific area that needs further explanation, it does not provide any guidance or suggestions on how the authors might address this issue or improve the clarity of their presentation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors separate the \"Related Work\" section from the \"Introduction\" section, as the current structure makes the introduction repetitive. It provides a clear and concrete action by recommending the relocation of specific bullet points to the \"Related Work\" section. This feedback is direct and provides a specific step for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the \"Introduction\" section and suggests moving specific bullet points to the \"Related Work\" section. This provides full grounding, as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed by suggesting the relocation of certain bullet points. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the current structure of the paper, with the \"Introduction\" section containing both an introduction and related work, is confusing. It recommends moving the \"Traditional AES\", \"Deep Neural AES\", and \"Pre-training AES\" bullet points to a separate \"Related Work\" section. This suggestion is based on the reviewer\\'s perception of the current structure, which is subjective but logical. However, the comment lacks specific examples or references to support the claim that this structure is confusing or ineffective. Therefore, the claim is somewhat verifiable, as it provides a logical reasoning but lacks detailed evidence or examples to fully substantiate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to improve the structure of the paper by separating the \"Related Work\" section from the \"Introduction.\" It identifies a redundancy in the current structure, where the introduction is repeated with related work bullet points, and suggests a more logical and concise organization. This feedback is specific and actionable, offering a straightforward way for the authors to enhance the clarity and flow of their paper. However, it could be more helpful if it included additional guidance on how to effectively present the related work or suggested specific examples of how to integrate the related work into the paper. Despite this, the comment is mostly helpful as it directs the authors toward a clear improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by presenting the overall process and rationale for constructing the benchmark more clearly. While it implies that the authors should address this issue, it does not provide explicit guidance on how to achieve this clarity. The action is implicit and somewhat vague, as the authors need to infer the specific steps or changes required to improve the clarity of the presentation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the presentation of the rules and data augmentation methods used in constructing the benchmark, but it does not specify which part of the paper this information is located in. The authors can infer that it relates to the methodology section, but this inference is not explicit. The comment is specific in suggesting that the overall process and rationale for construction could be presented more clearly, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be improved by presenting the overall process and rationale for constructing the benchmark more clearly. However, it does not provide specific examples, references, or detailed reasoning to support why this is necessary or how it could be improved. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the rules and data augmentation methods used in constructing the benchmark are described in detail but the overall process and rationale for construction are not presented clearly. This feedback is somewhat helpful as it highlights a gap in the paper\\'s clarity and suggests that the authors should improve the presentation of the construction process. However, the comment lacks specific guidance on how to enhance the clarity or what aspects of the process should be emphasized. To be more helpful, the comment could provide examples of how to present the process more clearly or suggest specific sections where this information could be improved. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of content in the paper, specifically mentioning the absence of a literature review on recent advances in active learning communities, particularly in Bayesian learning. It suggests that the paper should include a review of the Bayesian Coreset, which is relevant to the work, and mentions other works that discuss similar directions. The comment also implies that the current setup is more advanced than related studies. While the comment identifies areas for improvement, it does not provide explicit instructions on how to incorporate these suggestions or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer the need for a literature review but lack detailed guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of content in the paper, specifically the absence of a literature review on recent advances in active learning communities, particularly in Bayesian learning. It provides a specific example of the Bayesian Coreset, which is relevant to the work, and suggests that the paper should include this review. Additionally, it mentions other works that discuss similar directions, such as [1] and [2], and implies that the current setup is more advanced than related studies. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comprehensive literature review on recent advances in active learning communities, particularly in Bayesian learning, and suggests that the paper should include a review of the Bayesian Coreset, which is relevant to the work. The comment also mentions other works that discuss similar directions and implies that the current setup is more advanced than related studies. However, the comment lacks specific references or detailed examples to support the claim, making it somewhat verifiable. The authors would need to conduct additional research to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the lack of a comprehensive literature review on recent advances in active learning communities, particularly in Bayesian learning. It specifically mentions the absence of a review of the Bayesian Coreset, which is relevant to the work, and suggests that this omission could lead to a less reliable uncertainty measurement compared to other approaches. The comment also points out other works that discuss similar directions, such as combining uncertainty with Coreset, and implies that the current setup is more advanced than related studies. This feedback is clear and actionable, as it provides specific suggestions for improvement by recommending the inclusion of a literature review and highlighting relevant works. However, the comment could be more helpful if it offered additional guidance on how to integrate these suggestions into the paper. Overall, the comment is mostly helpful, as it effectively directs the authors to address a critical gap in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the \"one-to-many relationship\" in Fig 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. While it identifies a specific issue with the figure, it does not provide explicit guidance on how to address these problems. The authors are left to infer that they need to clarify the relationship or reduce the noise in the plots, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is somewhat actionable, as it highlights a specific area for improvement but does not provide detailed guidance on how to implement the suggested changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the \"one-to-many relationship\" and the presence of noise in the plots, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"one-to-many relationship\" in Fig 2 makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Fig 2, noting that the \"one-to-many relationship\" makes it difficult to understand the presented trends and that the plots contain a considerable amount of noise. This feedback is somewhat helpful as it points out a potential problem with the visual representation of data, which could hinder the reader\\'s comprehension. However, the comment lacks detailed guidance on how to address these issues, such as suggesting ways to clarify the relationship or reduce noise. Without actionable advice, the authors may find it challenging to effectively improve their draft based on this feedback. Therefore, the comment is rated as somewhat helpful, as it highlights an area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of the comparison with existing algorithms like Performer and Reformer, which are often not deeply optimized. It also questions whether DFSSATTEN supports training from scratch, suggesting that this aspect should be studied. While the comment identifies potential issues and areas for improvement, it does not provide explicit guidance on how to address these concerns or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to consider the fairness of their comparisons and the training from scratch aspect, but the comment lacks concrete details on how to implement these considerations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the comparison of DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that the comparison might be unfair due to the lack of deep optimization in these algorithms. It also questions whether DFSSATTEN supports training from scratch, which is a significant direction in the field. However, the comment does not specify which part of the paper discusses these comparisons or the training from scratch aspect, making it weakly grounded. The comment is specific in identifying potential issues with the comparison and the need for further investigation into training from scratch. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the fairness of the comparison with existing algorithms like Performer and Reformer, which are often not deeply optimized. It suggests that directly comparing DFSSATTEN with these algorithms might be unfair. Additionally, it questions whether DFSSATTEN supports training from scratch, which is a significant direction in the field. The comment provides some logical reasoning by pointing out the potential unfairness of the comparison and the importance of training from scratch. However, it lacks specific examples or references to support the claim about the unfairness of the comparison, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important points regarding the comparison of DFSSATTEN with existing algorithms like Performer and Reformer. It highlights that these algorithms are often not deeply optimized, which could affect the fairness of the comparison. Additionally, the comment questions whether DFSSATTEN supports training from scratch, which is a significant direction in the field. By pointing out these issues, the comment provides valuable feedback that could help the authors improve their draft. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided specific examples of how to make the comparison more fair. Overall, the comment is mostly helpful as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, specifically when it was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their evaluation. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting, specifically when it was evaluated on a defended model. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity in terms of what needs to be addressed or improved in this context. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the evaluation. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their evaluation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their evaluation. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity in terms of what needs to be addressed or improved in this context. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the evaluation. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their evaluation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the evaluation of the VMI-SI-TI-DI-FDSM method on a black-box setting when it was evaluated on a defended model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide specific details or examples of what aspects need clarification. The comment refers to the \"questions section\" for more information, but without explicit guidance or examples, the authors are left without a clear understanding of what specific elements need to be addressed. This lack of detail makes it difficult for the authors to know exactly how to improve the clarity of their method description. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the clarity of the proposed method\\'s description could be improved, but it does not specify which part of the paper this description is found in. The authors might infer that it relates to the methods section, but this is not explicitly mentioned. The comment is specific in its suggestion to refer to the \"questions section\" for details, but without full grounding, the authors may struggle to pinpoint the exact part of the paper needing improvement. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the clarity of the proposed method\\'s description could be improved, but it does not provide any specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the need for improvement, making it difficult for the authors to understand the basis of the suggestion. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the clarity of the proposed method's description could be improved, but it does not provide specific details or examples of what aspects need clarification. While it identifies a potential area for improvement, the lack of actionable feedback or guidance makes it difficult for the authors to address the issue effectively. Without detailed suggestions or examples, the comment does not offer meaningful assistance in enhancing the clarity of the method description. Therefore, the comment is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and it asks whether this observation has been made in the empirical evaluations or if the authors can explain why such correlations are not considered. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to investigate or explain the correlations. The action is implicit and somewhat vague, as the authors need to infer that they should explore this observation further. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the independence of pruning strategies across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and it asks whether this observation has been made in the empirical evaluations or if the authors can explain why such correlations are not considered. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the pruning strategy and its application across layers. The authors can infer that it relates to the methodology or results sections, but the comment does not provide explicit references to specific sections. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the independence of pruning strategies across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and it asks whether this observation has been made in the empirical evaluations or if the authors can explain why such correlations are not considered. The comment does not contain an explicit claim or suggestion but rather poses a question for the authors to consider. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the independence of pruning strategies across different layers in the GNN. It suggests that if an edge is pruned in one layer, it should also be pruned in other layers, and it asks whether this observation has been made in the empirical evaluations or if the authors can explain why such correlations are not considered. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what additional analyses or explanations could be provided. The feedback is somewhat helpful as it prompts the authors to consider a specific aspect of their work that may require further exploration, but it does not offer detailed or actionable advice. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit and vague, as the authors are left to infer that they need to consider the generalizability of their results to other datasets. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the generalizability of conclusions to other in-distribution datasets, but it lacks detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires the authors to infer the significance of the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the experimental validation, specifically noting that it only considers CIFAR-10/100 as in-distribution data. The reviewer questions whether the conclusions would generalize to other in-distribution datasets or if some should be nuanced. This feedback is somewhat helpful as it highlights an important aspect of the experimental setup that may affect the generalizability of the results. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what additional experiments could be conducted to improve the generalizability of their findings. While it prompts the authors to consider broader implications, it does not provide detailed actionable advice, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alpha-divergence in Table 8 to provide insights. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as which specific aspects of the gradient conflicts ratio should be highlighted or how to present this information effectively. The authors are aware of the action but may need more guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests showing the gradient conflicts ratio for AlphaNets trained with alpha-divergence to provide insights. This feedback is clear and actionable, giving the authors a clear direction on what to include in their table to enhance its utility. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that AlphaNets trained with alpha-divergence do not benefit from the method described in the paper, and it recommends showing the gradient conflicts ratio to provide insights. However, the comment does not provide any evidence, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results presented in Table 8, specifically noting that AlphaNets trained with alpha-divergence do not seem to benefit from the method described in the paper. It suggests that showing the gradient conflicts ratio for these AlphaNets could provide insights. This feedback is somewhat helpful as it points out a specific area where the results may be unclear or lacking in detail. However, it could be more helpful if it provided additional context or guidance on how to present the gradient conflicts ratio or what insights it might reveal. Overall, the comment offers a direction for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a question about the explicit SDF supervision and suggests that it could be simplified by applying the loss on the 3D location without occlusion reasoning. It also implies that a good reason or ablation study is missing to justify the current setup. While the comment identifies a potential issue and suggests a simpler approach, it does not explicitly instruct the authors to make these changes or conduct an ablation study. The action is implicit and somewhat vague, as the authors need to infer the specific modifications to make. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Sec. 3.2' and specific lines (165 and 173) where the issue is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions the necessity of the explicit SDF supervision with occlusion handling and view-awareness, suggesting a simpler approach. It further implies that a good reason or ablation study is missing to justify the current setup. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the necessity of the explicit SDF supervision with occlusion handling and view-awareness, suggesting a simpler approach. The reviewer provides a logical reasoning by questioning the complexity of the current setup and suggesting a more straightforward method. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the implications of the suggestion and justify their current approach. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the explicit SDF supervision, specifically regarding the occlusion handling and view-awareness mentioned in the paper. It suggests that the current setup might be unnecessarily complex and proposes a simpler approach by sampling a subset of the sparse point cloud for loss calculation. The comment also implies that a good reason or ablation study is missing to justify the current setup. While the comment identifies a potential area for simplification and improvement, it lacks specific suggestions or guidance on how to implement these changes. The authors would need to infer the exact modifications to make, which limits the comment's helpfulness. Therefore, it is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a question about the explicit SDF supervision and suggests a simpler approach by applying the loss on the 3D location without occlusion reasoning. It also implies that a good reason or ablation study is missing to justify the current setup. While the comment identifies a potential issue and suggests a simpler approach, it does not explicitly instruct the authors to make these changes or conduct an ablation study. The action is implicit and somewhat vague, as the authors need to infer the specific modifications to make. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Sec. 3.2' and specific lines (165 and 173) where the issue is discussed. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it questions the necessity of the explicit SDF supervision with occlusion handling and view-awareness, suggesting a simpler approach. It further implies that a good reason or ablation study is missing to justify the current setup. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the necessity of the explicit SDF supervision with occlusion handling and view-awareness, suggesting a simpler approach by applying the loss on the 3D location without occlusion reasoning. The reviewer provides a logical reasoning for this suggestion but lacks specific examples or references to support the claim fully. While the comment identifies a potential area for simplification, it does not provide detailed evidence or justification, making it somewhat verifiable. The authors would need to infer the implications of the suggestion and justify their current approach. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the explicit SDF supervision, specifically regarding the occlusion handling and view-awareness mentioned in the paper. It suggests a simpler approach by applying the loss on the 3D location without occlusion reasoning, implying that a good reason or ablation study is missing to justify the current setup. While the comment identifies a potential area for simplification and improvement, it lacks specific suggestions or guidance on how"}
