{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, implying that the current method is flawed. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or revise their description of HIERENC. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, noting that using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. This provides clear guidance on what needs to be addressed in the description of HIERENC. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that using the average of all instantiations of context filled by every possible entity in the vocabulary is a poor approach because it introduces noise. The reviewer provides a logical reasoning by questioning the validity of averaging multiple instantiations, which could lead to noise. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issue and potential improvements from the reviewer\\'s reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation should be correct, implying that the current method is flawed. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a potential solution. However, the comment could be more helpful if it offered additional guidance on how to clarify the description or address the noise issue. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should correct the wording 'on par or better' to address a perceived cognitive bias among NLP researchers. While the comment implies that the authors should make this correction, it does not provide explicit guidance on how to rephrase the results or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact changes to make. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the line number (l.791), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential cognitive bias among NLP researchers and suggesting a correction to the wording. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that there is a general cognitive bias among NLP researchers to map instances where they perform worse to 'on par' and all the rest to 'better'. While the reviewer provides a rationale for this claim, it lacks specific examples or references to support the assertion. The comment suggests that the authors should correct this wording, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the phrasing of the experimental results, suggesting that the authors might be using 'on par or better' to mask instances where they perform worse, which is a common cognitive bias among NLP researchers. The reviewer recommends correcting this wording, which is a constructive suggestion for improving the clarity and accuracy of the results. However, the comment could be more helpful if it provided specific examples or guidance on how to rephrase the results to avoid this bias. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A for Chinese MOS-Q and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOS-V. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the interpretation. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues to be addressed, such as the interpretation of results regarding the comparison of NVSB with GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOS-V. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of questions seeking clarification on the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOS-V. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the interpretation of results in Table 3, specifically regarding the comparison of NVSB with GT Mel A for Chinese MOS-Q and the overlap of 95% CI for Baseline and NVSB in Chinese and English MOS-V. While it identifies areas where clarification is needed, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve the interpretation of their results. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the paper should include an ablation study to demonstrate the importance of the post-processing steps used to filter out 'false-positive' neurons. While the comment implies that such a study is necessary, it does not explicitly instruct the authors to conduct an ablation study or provide detailed guidance on how to perform it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and how to execute it. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the use of integrated gradients for attribution measurement and the inclusion of post-processing steps to filter out 'false-positive' neurons. It suggests that the paper lacks an ablation study to demonstrate the importance of these post-processing steps. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in suggesting an ablation study to address the importance of the post-processing steps. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper's use of integrated gradients for attribution measurement has been studied in existing papers and suggests that the paper lacks an ablation study to demonstrate the importance of the post-processing steps used to filter out 'false-positive' neurons. The comment provides a logical reasoning by referencing existing work on integrated gradients and suggesting that an ablation study would be beneficial. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to conduct further research or refer to the existing literature to fully understand the claim's validity. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's methodology by noting that the use of integrated gradients for attribution measurement has been studied in existing papers. It also points out that the paper proposes post-processing steps to filter out 'false-positive' neurons but does not demonstrate the importance of these steps. The comment suggests that an ablation study could be beneficial to address this issue. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to conduct the ablation study or what specific aspects should be examined. The feedback is somewhat helpful as it provides a clear direction for enhancing the paper's methodology but could be more comprehensive with additional details or examples.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the paper should include an ablation study to demonstrate the importance of the post-processing steps used to filter out 'false-positive' neurons. While the comment implies that such a study is necessary, it does not explicitly instruct the authors to conduct an ablation study or provide detailed guidance on how to execute it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and how to execute it. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the use of integrated gradients for attribution measurement and the inclusion of post-processing steps to filter out 'false-positive' neurons. It suggests that the paper lacks an ablation study to demonstrate the importance of these post-processing steps. However, the comment does not specify which part of the paper discusses these topics, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in suggesting an ablation study to address the importance of the post-processing steps, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the use of integrated gradients for attribution measurement has been studied in existing papers and suggests that the paper lacks an ablation study to demonstrate the importance of the post-processing steps used to filter out 'false-positive' neurons. The comment provides a logical reasoning by referencing existing work on integrated gradients and suggesting that an ablation study would be beneficial. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to conduct further research or refer to the existing literature to fully understand the claim's validity. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's methodology by noting that the use of integrated gradients for attribution measurement has been studied in existing papers. It also points out that the paper proposes post-processing steps to filter out 'false-positive' neurons but does not demonstrate the importance of these steps. The"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it highlights a potential issue with the proposed method of matching the head of noun phrases. The comment implies that the authors should clarify how they handle situations where the head word is not a pronoun. While the action is implicit, it is clear that the authors need to address this issue, and the comment provides a specific area for clarification. However, the comment does not offer concrete guidance on how to resolve this issue, such as suggesting alternative methods or approaches. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed instructions on how to implement the suggested change.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the prediction is a pronoun\" and \"the head of noun phrases,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how an antecedent is identified when the prediction is a pronoun and how to handle situations where the head word is not a pronoun. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the method proposed by the authors for identifying antecedents, specifically when the prediction is a pronoun. It highlights a potential issue with the method of matching the head of noun phrases, questioning how to handle situations where the head word is not a pronoun. While the comment identifies a gap in the proposed method, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The authors would need to clarify or provide additional information to address this concern effectively. Therefore, the comment is somewhat verifiable, as it raises a valid concern but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the method proposed by the authors for identifying antecedents, particularly when the prediction is a pronoun. It highlights a potential issue with the method of matching the head of noun phrases, questioning how to handle situations where the head word is not a pronoun. This feedback is clear and actionable, as it prompts the authors to clarify their method and consider alternative approaches to address this limitation. However, the comment could be more helpful if it provided suggestions on how to handle these situations or offered alternative methods for identifying antecedents. Overall, the comment is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment explicitly suggests including more baselines, it does not provide specific guidance on which baselines to include or how to implement them. The action is somewhat explicit but lacks concrete details on execution, making it somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The comment also recommends including more baselines based on related work to strengthen the paper. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the comparison of models and the discussion of baselines. The comment is specific in detailing what needs to be addressed regarding the comparison and the inclusion of additional baselines. Therefore, the comment is weakly grounded but specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that the MST baseline is an appropriate comparison. The suggestion to include more baselines is logical but not fully substantiated with evidence or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper by questioning the comparison of the proposed models to models that only consider different senses but not sememes. It suggests that the MST baseline might be an example of such a model and notes that this aspect is not sufficiently described. The reviewer also recommends including more baselines based on related work to strengthen the paper. This feedback is clear and actionable, as it provides a specific suggestion for improvement by comparing the proposed models to a relevant baseline. However, the comment could be more helpful if it provided additional guidance on how to implement the suggested comparison or which baselines to include. Overall, the comment is mostly helpful as it directs the authors to a specific area for enhancement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the selection of frame similarity factors and attributes similarity factors is unclear. However, it does not provide any explicit guidance or suggestions on how the authors should clarify this aspect. The comment lacks specific instructions or examples of what the authors should do to address the issue, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the selection of frame similarity factors and attributes similarity factors, which are specific elements of the paper. However, it does not specify which part of the paper discusses these factors, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the selection of these factors, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the selection of frame similarity factors and attributes similarity factors, but it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The comment identifies a specific area of confusion regarding the selection of frame similarity factors and attributes similarity factors, which is a crucial aspect of the paper's methodology. However, it lacks depth and does not provide any suggestions or guidance on how the authors might clarify or improve this aspect. Without actionable feedback or specific recommendations, the comment does not offer the authors a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it highlights an issue but does not provide sufficient guidance for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\\'s length but should be stronger. It points out that the setting is limited to an extremely low-resource regime and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks, which was not demonstrated. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these weaknesses or suggestions for specific changes. The action is implicit and somewhat vague, as the authors can infer that they need to expand the experiments to include more diverse settings and tasks, but the comment lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main weaknesses of the paper, specifically the experiments. It points out that the setting is limited to an extremely low-resource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method has potential for use in more NLP tasks. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the limitations of the experiments and suggesting potential improvements, but without explicit references to sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are weak due to the limited setting to an extremely low-resource regime and that sentence classification is an easier task. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks, which was not demonstrated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claims. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies the main weaknesses of the paper, specifically the experiments, which are understandable given the paper\\'s length but should be stronger. It points out that the setting is limited to an extremely low-resource regime and that sentence classification is an easier task, suggesting that the proposed augmentation method has potential for use in more NLP tasks, which was not demonstrated. While the comment highlights areas for improvement, it lacks specific suggestions or guidance on how to address these weaknesses or expand the experiments to include more diverse settings and tasks. The feedback is somewhat helpful as it provides a direction for potential enhancements, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether treating concept map extraction as a separate task is necessary. It provides a rationale by comparing it to generic summarization systems that build knowledge graphs and generate summaries. However, it does not explicitly instruct the authors to make any changes or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors can infer that they might need to reconsider the treatment of concept map extraction, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also mentions the challenge of distinguishing concept maps with a growing number of nodes. However, the comment does not specify which part of the paper this discussion pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its critique of the concept map extraction process, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also discusses the challenge of distinguishing concept maps with a growing number of nodes. While the comment provides some reasoning and context, it lacks specific examples or references to support the claim about the difficulty of distinguishing concept maps. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about treating concept map extraction as a separate task, comparing it to generic summarization systems that build knowledge graphs. It also points out the challenge of distinguishing concept maps with a growing number of nodes, suggesting that general summaries should be more readable. While the comment identifies an interesting point for consideration, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is somewhat helpful as it prompts the authors to reflect on the necessity of treating concept map extraction separately, but it does not provide actionable steps or detailed advice. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue in the text, noting that lines 102-106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to correct the misleading statement or what changes should be made. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 102-106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, noting that the phrase \"such distribution\" cannot refer to the discussion above. This provides clear guidance on what needs to be addressed in the text. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that lines 102-106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the text, noting that lines 102-106 are misleading because the phrase \"such distribution\" cannot refer to the discussion above. This feedback is clear and actionable, as it points out a potential confusion in the text that the authors should address. By correcting this issue, the authors can improve the clarity and accuracy of their draft. However, the comment could be more helpful if it provided suggestions on how to rephrase the text to avoid confusion. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the choice of datasets and the duration of the study period. It asks whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. While the comment implies that the authors should provide more context or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to clarify the dataset choice and the nature of style shifts. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, it does not specify which part of the paper this discussion is related to, such as a particular section or table. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its questions about the dataset and style shifts, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or explanation, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. This feedback highlights an important aspect that the authors should consider when discussing their results or methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point challenges the claim that there is no corresponding set of tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not explicitly instruct the authors to include these references or to address the claim in their draft. While the action is implicit, it is concrete as it points out a specific issue and provides a basis for further investigation. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment challenges a claim about the absence of corresponding tools for the reinforcement learning setting. It provides a counterpoint by referencing specific references, including some from the submitted paper, which suggests that the claim is false. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or conclusion section, but this is not explicitly mentioned. The comment is specific in identifying the issue of the absence of tools and providing references to support the claim, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point challenges a claim by providing references to support the assertion that there are indeed corresponding tools for the reinforcement learning setting. This is a strong form of evidence, as it directly addresses the claim with specific examples and references. The reviewer's response is fully verifiable, as it provides clear reasoning and evidence to support the claim, making it a 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment challenges a claim made in the paper, specifically questioning the assertion that there is no corresponding set of tools for the reinforcement learning setting. By providing references to support the claim that such tools do exist, the comment offers a clear and actionable response. This feedback is valuable as it prompts the authors to reconsider their initial claim and potentially update their paper with relevant references. However, the comment could be more helpful if it explained why the references are relevant or how they might impact the paper's conclusions. Overall, the comment is mostly helpful as it provides a clear direction for the authors to address the claim, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not provide explicit guidance on how the authors should address this gap or suggest specific ways to incorporate these references into their work. The action is implicit and vague, as the authors are left to infer that they should include these references but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or discussion. The authors can infer that it relates to the literature review or related work section, but this inference is not explicit. The comment is specific in detailing the missing link to similar work, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a reference to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, the comment does not provide specific examples or references to these works, making it difficult for the authors to understand the exact nature of the missing link. Without detailed examples or references, the claim is not fully verifiable, as it lacks the necessary evidence to support the assertion. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a gap in the paper's literature review by pointing out the absence of references to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These references are relevant because they have a similar structure to the CRF and the ability to perform exact inference. By highlighting this omission, the comment provides a clear and actionable suggestion for the authors to include these references in their work. This feedback is valuable as it helps the authors to strengthen their paper by providing a more comprehensive literature review. However, the comment could be more helpful if it offered specific guidance on how to integrate these references or what aspects of the literature to focus on. Overall, the comment is mostly helpful, as it directs the authors to an important area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 is written in a concise manner due to space limitations and could benefit from a slower development to make it easier to read. While the comment implies that the authors should expand on the content to improve readability, it does not provide specific guidance on what aspects need to be expanded or how to achieve this. The action is implicit and somewhat vague, as the authors know they need to expand the section but lack detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 4,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is \"tersely written\" and could benefit from a slower development for easier readability. This level of detail allows the authors to understand what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 4 is written in a concise manner due to space limitations, which could be improved for easier readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or improvements needed. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Section 4, noting that it is written in a concise manner due to space limitations. It suggests that the section could benefit from a slower development to make it easier to read. While the comment highlights a potential area for improvement, it lacks specific suggestions or guidance on how the authors might expand or elaborate on the content to achieve this. The feedback is somewhat helpful as it points out a problem but does not provide detailed actionable advice, leaving the authors with a general direction to consider but without a clear path forward. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete actions for the authors to take, making the comment highly actionable. The authors know exactly what needs to be done to address the feedback, which is to include a specific table and provide an explanation. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, and that the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths and explaining how the dataset is balanced across categories. While the comment identifies a potential issue with the paper, it lacks specific examples or references to support the claim that the distribution is crucial for assessment. The suggestion to include a table and explain the dataset's balance is a logical response but lacks detailed justification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing a more detailed analysis of the distribution of video lengths within the benchmark dataset. It suggests including a table to show this distribution and explains why it is important for assessing reasoning ability and robustness. The comment is clear and actionable, offering specific guidance on how the authors can enhance their draft. By addressing this feedback, the authors can improve the comprehensiveness and clarity of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should take a cautious approach regarding their contribution until the promised dataset is made publicly available. However, it does not provide explicit guidance on how the authors should proceed or what actions they should take to address this issue. The comment lacks concrete details or suggestions on how to handle the situation, leaving the authors uncertain about how to implement the advice. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the dataset not being publicly available, which is a specific concern. However, it does not specify which part of the paper discusses the dataset or how it is relevant to the contribution. The authors can infer that it relates to the dataset section or discussion, but this inference is not explicit. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset promised in the paper is not yet publicly available, suggesting a cautious approach until the dataset is openly accessible. However, the comment lacks specific evidence, examples, or references to support this claim. Without additional context or details, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights a critical issue regarding the availability of the dataset promised in the paper. It suggests that the authors should take a cautious approach until the dataset is openly accessible, which is a valid concern for the reproducibility and impact of the research. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure the dataset's availability. While it identifies a potential problem, it does not provide actionable advice or detailed recommendations, making it somewhat helpful. The authors are left with a general understanding of the issue but without clear steps to address it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing [A]. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific example of what needs to be included, making it highly actionable. The authors know exactly what action to take and how to implement it, ensuring a clear path for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work on modular networks for VQA\" and references [A], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of related work on modular architectures for VQA in the introduction. This provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction seems to imply that no one does modular architectures for VQA, but it does not mention related work on modular networks for VQA. This claim is based on the observation that the introduction lacks a specific reference to related work, which could be inferred as a gap in the literature. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the relevance of the claim and the need to include the mentioned related work, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper\\'s discussion of related work, noting that it does not mention related work on modular networks for VQA. This is a crucial point as it highlights a potential oversight that could impact the comprehensiveness of the literature review. By pointing out the need to include this specific reference, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it suggested how to integrate this reference or discussed the significance of modular architectures in VQA. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. While the comment identifies a gap in the presentation of the results, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include these cases in the tables, but the comment lacks concrete instructions on how to implement this change. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ablation experiment\" and the \"two tables,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the performance without reinforcement learning dropped lower than without dependency tree, and the tables do not list the cases where dependency tree and RL are not used. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance without reinforcement learning dropped lower than without dependency tree, and the tables do not list the cases where dependency tree and RL are not used. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without dependency tree. It also points out that the two tables do not list the cases where dependency tree and RL are not used. This feedback is somewhat helpful as it highlights a gap in the presentation of results, which could be addressed by including these cases in the tables. However, the comment lacks detailed guidance on how to present this information or suggestions for how to improve the clarity of the ablation experiment. While it provides a starting point for the authors to consider, it does not fully address the needs for improving the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the notation and the split between \"static\" and temporal features, suggesting that more information is needed to understand what \"S\" and \"Xt\" represent. However, the comment does not provide explicit guidance on how the authors should address this issue or what additional information should be included. The action is implicit and somewhat vague, as the authors can infer that more explanation is needed but are not given concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the notation and the split between \"static\" and temporal features, which are specific elements of the paper. It explicitly mentions \"notation\" and \"split,\" allowing the authors to accurately identify the parts of the paper being discussed. However, it does not specify what aspects of the notation or split are confusing or require more information, leaving the authors to infer that more details about \"S\" and \"Xt\" are needed. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the notation and the split between \"static\" and temporal features are confusing, suggesting that more information is needed to understand what \"S\" and \"Xt\" represent. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or references leaves the claim somewhat verifiable, as it requires the authors to infer the nature of the confusion and the necessary clarification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation and the split between \"static\" and temporal features, noting that this is confusing and requires more information than is provided in the paper. While it highlights a potential area of confusion, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might clarify these aspects. Without actionable advice or detailed feedback, the authors may find it challenging to address the issue effectively. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide enough detail to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper deals with many graph notions and could be improved with more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, the comment does not provide explicit instructions on how to address these issues or what specific details should be added. The authors are left with a general understanding of what needs improvement but without concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed instructions on how to achieve them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions \"many graph notions\" and suggests that the writing is generally good but could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, it does not specify which sections or parts of the paper are being addressed, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s complexity due to the introduction of many graph notions. It acknowledges that the writing is generally good but suggests that more details could be provided, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. This feedback is somewhat helpful as it points out specific areas where the paper could be improved, but it lacks depth and does not offer detailed guidance on how to enhance the clarity and detail of these sections. The authors are left with a general understanding of what needs improvement but without specific actionable steps to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should introduce the specific aspects of the model that are relevant to the example model, such as the limitations in infinite subdivisions for \\u03b3^1 and \\u03b3^m, and the boundedness of certain parameters. This feedback provides a clear and explicit action for the authors to take, as it specifies what information should be included to clarify the model\\'s limitations. The comment also offers concrete guidance on what aspects to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, namely introducing the specific aspects of the model that are relevant to the example model, such as the limitations in infinite subdivisions and the boundedness of certain parameters. This provides a clear direction for the authors to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should introduce specific aspects of the model that are relevant to the example model, such as limitations in infinite subdivisions and bounded parameters. While the comment provides a logical suggestion for improving the clarity of the model description, it lacks specific examples or references to support the claim. The authors would need to infer the exact details of what needs to be included, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the clarity of the model description in the paper. It specifically recommends introducing the aspects of the specific model that are relevant to the example model, such as limitations in infinite subdivisions and bounded parameters. This feedback is valuable as it guides the authors on how to enhance the transparency and comprehensiveness of their model presentation, which is crucial for readers to fully understand the methodology and its implications. However, the comment could be more helpful if it included specific examples or references to illustrate these aspects, which would further enhance its utility. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer suggests that this condition may lead to unreasonably large learning rates when working with large-scale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors might address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the scalability of the learning rate condition. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the required condition on the learning rate, noting that it is not scalable and questioning the practicality of having a step size that grows with the sample size. However, it does not specify which part of the paper this condition is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the scalability of the learning rate condition, providing a clear rationale for why it is not realistic. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer provides a logical argument, explaining why this condition might lead to unreasonably large learning rates when working with large-scale datasets. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. While the reasoning is sound, the absence of detailed evidence or examples makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer explains that this condition could lead to unreasonably large learning rates when working with large-scale datasets, which is a valid concern. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their approach. While it highlights a potential weakness, it does not provide concrete steps or alternatives for the authors to consider, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer explains that this condition could lead to unreasonably large learning rates when working with large-scale datasets. While the comment highlights a potential problem, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the scalability of the learning rate condition. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic to have a step size that grows with the sample size in practice. However, it does not specify which part of the paper this condition is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the scalability of the learning rate condition, providing a clear rationale for why it is not realistic. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer provides a logical argument, explaining why this condition might lead to unreasonably large learning rates when working with large-scale datasets. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. While the reasoning is sound, the absence of detailed evidence or examples makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer explains that this condition could lead to unreasonably large"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should use a more convincing setting by sampling unlabeled data from millions of reviews, as done in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. This is an explicit suggestion that provides a concrete action for the authors to take, which is to replicate the approach used in the referenced work. The comment also explains why this is important, noting that the current dataset is perfectly balanced, which is impractical in real-world applications. This level of detail and specificity makes the comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of unlabeled data from the Amazon review dataset, specifically mentioning the Blitzer version. It points out that the dataset is perfectly balanced, which is impractical in real-world applications, and suggests using a more convincing setting as in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. This provides a clear reference to the specific dataset and a concrete example of a more practical approach. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. Despite this, the comment is specific in detailing the issue and suggesting a solution. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the unlabeled data from the Amazon review dataset is perfectly balanced, which is impractical in real-world applications. It suggests using a more convincing setting as in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification. The comment provides a specific reference to a previous work, which supports the claim by offering a practical approach to address the issue. However, the comment could be strengthened by providing more detailed reasoning or examples of how the current dataset's balance affects real-world applications. Despite this, the overall claim is well-supported, making it mostly verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the use of unlabeled data in the Amazon review dataset, noting that it is perfectly balanced, which may not reflect real-world scenarios. It suggests a more convincing setting by referencing a previous work, 'Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification,' which provides a practical approach to address this issue. This feedback is clear and actionable, offering a concrete suggestion for improvement that could enhance the relevance and applicability of the study. However, the comment could be more helpful if it provided additional context or guidance on how to implement the suggested approach. Overall, the comment is mostly helpful, as it directs the authors toward a potential improvement in their methodology.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they could take to improve their sampling method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) on line 130. It also compares this issue to sampling from the leverage score, as discussed in [3]. This provides full grounding, as the authors can accurately identify the part of the paper being addressed, specifically Equation (10) and the discussion on sampling. The comment is also specific because it clearly specifies the problem with sampling from the DPP and references a similar issue with sampling from the leverage score. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. The reviewer provides a logical comparison between the two sampling methods, suggesting that the DPP sampling might be more challenging than sampling from the leverage score. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim that sampling from the DPP is more difficult. While the comparison is relevant, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with sampling from the DPP when eigenfunctions are inaccessible, referencing a similar problem with sampling from the leverage score. This provides a clear and actionable insight into a potential weakness in the paper's methodology. By drawing a comparison to a related issue, the comment offers a direction for the authors to explore and potentially address. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue or improve the sampling method. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the generalization of observations to few-shot learners beyond Prototypical Networks is not evaluated, which could limit the scope of the submission\\'s contributions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider evaluating the generalization to other few-shot learners, but it does not specify which methods or approaches to use or how to conduct this evaluation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the generalization of observations to few-shot learners beyond Prototypical Networks, which is a specific aspect of the paper. It is fully grounded as it explicitly mentions \"few-shot learners\" and \"Prototypical Networks,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights the need to evaluate the generalization of observations, which is a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the generalization of observations to few-shot learners beyond Prototypical Networks is not evaluated, which could limit the scope of the submission\\'s contributions. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by evaluating the generalization of observations to few-shot learners beyond Prototypical Networks. This feedback is clear and actionable, as it points out a potential limitation in the scope of the submission\\'s contributions. By suggesting that the authors should consider evaluating the generalization to other few-shot learners, the comment provides a concrete direction for improvement. However, it could be more helpful if it offered specific examples or methods for evaluating generalization. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the handling of different modalities in Equation 3, noting that the equation directly removes the modal subset of all instances. It explicitly asks the authors to address this issue, providing a clear and direct action for them to take. The comment specifies the problem and suggests a potential area for improvement, making it highly actionable. The authors know exactly what needs to be done to address the concern, which is to deal with the problem mentioned above. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Equation 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning how the equation deals with the problem of different modalities of different instances having varying contributions. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about Equation 3, questioning how it deals with instances where different modalities have varying contributions. The comment suggests that the equation directly removes the modal subset of all instances, implying a potential issue with the handling of different modalities. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the exact issue and provide additional context to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Equation 3, noting that it directly removes the modal subset of all instances, which could lead to a problem with different modalities having varying contributions. The comment raises a valid concern about the potential impact of this approach on the analysis and suggests that the authors should address this issue. However, the comment lacks detailed guidance or suggestions on how to deal with this problem, such as proposing alternative methods or approaches to handle the varying contributions of different modalities. While it highlights an important area for improvement, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the proposed objective equation, Eq. 2, which requires optimization over both the parameters of the transformation \\u03a6 and the shared model \\u03b8_S. It highlights that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al. 2019), has not been discussed clearly. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need to be clarified. The action is implicit and somewhat vague, as the authors can infer that they need to discuss the impact on the number of parameters, but the comment lacks concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 2\" and \"line 128,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al. 2019), has not been discussed clearly. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed objective equation, Eq. 2, requires optimization over both the parameters of the transformation \\u03a6 and the shared model \\u03b8_S. It also notes that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al. 2019), has not been discussed clearly. While the comment identifies a gap in the discussion, it does not provide specific examples or detailed reasoning to support why this is a significant issue or how it affects the paper. The mention of prior work is a step towards verification, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed objective equation, Eq. 2, which requires optimization over both the parameters of the transformation \\u03a6 and the shared model \\u03b8_S. It highlights that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al. 2019), has not been discussed clearly. This feedback is clear and actionable, as it points out a gap in the discussion that the authors need to address. By identifying this omission, the comment provides a concrete direction for the authors to improve their draft, making it mostly helpful. However, it could be more helpful if it offered suggestions on how to discuss the impact on the number of parameters or provided examples of how this could be addressed. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two separate issues. First, it questions whether Eq. 4 stands, implying that the authors should clarify or address this concern. Second, it points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, specifically mentioning the marginal improvement on OfficeHome. However, the comment does not provide explicit guidance on how to address these issues or what actions the authors should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq. 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue regarding the improvement of the designed solutions, particularly on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71, indicating a marginal improvement. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions the validity of Eq. 4, suggesting that it implies a specific outcome for u^l in Eq. 3. This is a factual observation that does not require verification. The second part discusses the improvement of the designed solutions in Table 5, noting that the improvement is marginal on some datasets, such as OfficeHome. This part is somewhat verifiable as it provides a specific example of a marginal improvement, but it lacks detailed reasoning or references to support the claim about the significance of the improvement. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two separate issues. First, it questions the validity of Eq. 4, suggesting that it implies a specific outcome for u^l in Eq. 3. This raises a potential inconsistency that the authors should address. Second, it points out that the improvement of the designed solutions in Table 5 is not significant on some datasets, particularly mentioning the marginal improvement on OfficeHome. This feedback is somewhat helpful as it identifies areas where the authors might need to clarify or provide more detailed explanations. However, it lacks specific suggestions or guidance on how to address these issues, such as recommending additional analyses or comparisons. Therefore, the comment is rated as somewhat helpful, as it provides some insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that utilizing a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their work. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the use of a volumetric representation in the deformation field, referencing VolumeDeform [1] as an example. However, it does not specify which part of the paper this critique pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or related work section, but this inference is not explicit. The comment is specific in pointing out that the idea of using a volumetric representation is not novel, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of a volumetric representation in the deformation field is not novel, referencing VolumeDeform [1] as an example. However, the comment does not provide specific details or analysis to support why this idea is not novel or how it compares to VolumeDeform. The reference to VolumeDeform is a starting point, but without further elaboration or comparison, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment points out that the use of a volumetric representation in the deformation field is not a novel idea, referencing VolumeDeform [1] as an example. This feedback is somewhat helpful as it identifies a potential area where the authors might need to clarify or expand upon their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors could address this issue or improve their draft. Without actionable advice or detailed feedback, the comment provides limited value to the authors. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides an explicit suggestion to consider averaging over subword representations, referencing a specific source (Hewitt and Manning, 2019) for further information. This feedback is concrete, as it directly instructs the authors to explore an alternative method for embedding the first subword token. The authors know exactly what action to take and how to implement it, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L.490,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed suggestion to consider averaging over subword representations, referencing a specific source (Hewitt and Manning, 2019) for further information. This provides clear guidance on how to address the issue, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that averaging over subword representations is a common practice, referencing a specific source (Hewitt and Manning, 2019) for further information. This provides a logical basis for the claim, as it references a well-known practice in the field. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a reasonable basis for the claim but lacks comprehensive justification.', 'verifiability_label': '4', 'helpfulness_rationale': 'The comment provides a specific suggestion for improving the paper by recommending the averaging of subword representations, referencing a specific source (Hewitt and Manning, 2019) for further information. This feedback is actionable and provides a clear direction for the authors to enhance their work by adopting a common practice in the field. However, the comment could be more helpful if it included additional context or guidance on why this approach is beneficial or how it might impact the results. Despite this, the feedback is mostly helpful as it offers a concrete step for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit suggestion for the authors to conduct calibration curves to demonstrate the agreement between predicted scores and actual risk. It also recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. These suggestions are concrete and provide specific steps for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the model\\'s discriminant ability and suggests that the model\\'s AUC may not fully demonstrate its consistency with the clinical scoring system. It encourages related studies to conduct calibration curves to show the agreement and suggests proving the feasibility of the generated scoring system. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or figure. While the authors can infer that it relates to the model evaluation or results section, the lack of explicit grounding makes it difficult to pinpoint the exact area needing attention. The comment is specific in detailing what needs to be addressed, such as the need for calibration curves and feasibility proofs. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the model\\'s AUC may not fully demonstrate its consistency with the clinical scoring system, and it encourages the conduct of calibration curves to show the agreement. The comment also suggests proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. While the comment provides a logical argument for the need to conduct calibration curves and prove the feasibility of the scoring system, it lacks specific references or examples to fully substantiate the claim. The suggestion to discuss the difference between traditional and proposed methods is a general recommendation that does not provide detailed guidance. Therefore, the comment is somewhat verifiable, as it offers a reasonable basis for the claim but could be strengthened with more detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for the authors to conduct calibration curves to demonstrate the agreement between predicted scores and actual risk, which is crucial for the clinical scoring system. It also recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. These suggestions are specific and provide a clear direction for the authors to improve their draft, making the comment highly helpful. By offering detailed guidance on how to enhance the paper's content and methodology, the comment effectively supports the authors in refining their work. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the experimental setup and the comparison with baselines. It suggests that the experiments are not strong or fair, questioning the use of position kernels as baselines and recommending the use of default settings. Additionally, it points out missing baselines related to Bayesian optimization with discrete and categorical variables and suggests comparing the proposed approach with these baselines. The comment also mentions the need to discuss the limitations and societal impacts of the proposed approach. While the comment provides a clear direction for improvement, it does not specify exactly how to address these issues or which experiments to conduct. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several specific issues with the paper, including the experimental setup, the use of position kernels as baselines, the absence of certain baselines, and the need to discuss limitations and societal impacts. However, it does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the use of default settings and the inclusion of missing baselines. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the experimental setup and the use of position kernels as baselines, suggesting that the experiments are not strong or fair. It questions why the default settings of the baselines are not used and mentions the absence of certain baselines related to Bayesian optimization with discrete and categorical variables. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The suggestion to compare the proposed approach with these missing baselines is a logical step but remains somewhat vague without detailed guidance. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper. It questions the strength and fairness of the experiments, suggesting that the use of position kernels as baselines may not be justified and recommending the use of default settings from the literature. Additionally, it points out missing baselines related to Bayesian optimization with discrete and categorical variables and suggests comparing the proposed approach with these baselines. The comment also raises concerns about the paper\\'s discussion of limitations and societal impacts, indicating that these aspects are not adequately addressed. While the comment provides clear and actionable feedback, it could be more helpful if it offered specific suggestions or examples for addressing these issues. Overall, the comment is mostly helpful as it guides the authors in improving their draft by highlighting areas that need further attention and clarification.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests that the presentation of bits should be clarified as representation bits in Section 4.3. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action to clarify the presentation is somewhat vague, as it does not specify how to rephrase or restructure the content. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. Additionally, it suggests clarifying the presentation of \"bits\" as \"representation bits.\" This provides clear guidance on what needs to be addressed in the paper, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a question about the performance of sparsity patterns and suggests that there is a lack of insight into why they perform similarly. It also questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a lack of insight into why all sparsity patterns perform similarly, questioning whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also points out a specific issue with the terminology, suggesting that 'presentation bits' should be clarified as 'representation bits' in Section 4.3. While the comment highlights an important area for clarification and improvement, it lacks depth and does not provide specific guidance on how to address these issues. The feedback is somewhat helpful as it points out areas that need further exploration but does not offer detailed suggestions for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made, making it difficult for the authors to identify the exact section that needs attention. While the authors can infer that it pertains to Section 6, the comment lacks specificity in detailing what specific aspects of the perspective or contributions should be compared. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment does not provide any specific examples, references, or reasoning to support why such a comparison would be beneficial or how it could enhance the manuscript. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the comprehensiveness of the related work and suggesting a specific way to enhance the manuscript. However, the comment lacks depth and does not provide detailed guidance on how to conduct this comparison or what specific aspects should be considered. To be more helpful, the comment could include examples of prior efforts or suggest specific comparisons that would be beneficial. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests examining the performance with different numbers of scenarios, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but this inference is not as clear as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the model\\'s performance. Without this context, the claim remains unverifiable, as the authors may not understand the basis of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. This is a constructive suggestion that could help the authors better understand the impact of the number of scenarios on the model\\'s performance. However, the comment does not provide specific guidance on how to conduct these experiments or what aspects to focus on, which limits its helpfulness. While it offers a direction for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the ability of the model to predict quality labels, even if it is trained on high-quality data. It questions whether disturbances in the training data could affect the model\\'s ability to generate correct quality labels. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to investigate or mitigate potential disturbances. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the ability of the model to predict quality labels, even when trained on high-quality data. It questions whether disturbances in the training data could affect the model\\'s performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the model's performance or evaluation, but without explicit references, it remains unclear. The comment is specific in detailing the concern about disturbances affecting the model\\'s ability to generate correct quality labels, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the ability of the model to predict quality labels, even when trained on high-quality data. It questions whether disturbances in the training data could affect the model\\'s performance. However, the comment does not provide specific examples or evidence of disturbances or how they might impact the model. The reasoning is based on a logical assumption but lacks detailed justification or references to support the claim. As a result, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a valid concern about the ability of the model to predict quality labels, even when trained on high-quality data. It questions whether disturbances in the training data could affect the model's performance, which is a critical aspect to consider for the model's reliability. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or investigate potential disturbances. While it identifies an important area for consideration, the feedback is somewhat helpful as it prompts the authors to think about the robustness of their model's predictions but does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explicitly instruct the authors to incorporate these references or discuss the implications of these extensions. While the comment provides valuable information, it lacks actionable guidance on how the authors should utilize this information to improve their draft. Therefore, the comment is somewhat actionable, as it provides some insight but does not offer clear instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment discusses the bounded noise assumption and mentions several efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing the issues with the bounded noise assumption and suggesting alternative approaches, but it lacks explicit references to the paper\\'s sections or figures. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. This provides a clear and detailed justification for the claim, making it fully verifiable. The references to external works support the claim by offering examples of alternative approaches and theories, allowing the authors to understand the context and potential improvements. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and provides references to recent works that have extended these noise conditions. This feedback is valuable as it directs the authors to relevant literature that could enhance their understanding of the topic. However, the comment does not offer specific guidance on how the authors might incorporate these references or insights into their draft, such as discussing the implications of these extensions or how they might improve the paper. While it provides a starting point for further exploration, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights severe writing issues in the paper, including grammatical errors, misuse of mathematical symbols, and unclear sentences. However, it does not provide specific examples or guidance on how to address these issues. The authors are left without clear instructions on where to focus their efforts or how to correct the identified problems. As a result, the comment lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which sections or parts of the paper contain these issues, making it difficult for the authors to identify the exact areas needing improvement. Without specific references or examples, the comment lacks grounding, as the authors cannot confidently determine which parts of the paper are being addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper contains severe writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, the comment does not provide specific examples or detailed explanations of these issues, making it difficult for the authors to understand and address the problems. Without concrete evidence or references, the claim remains unverifiable, as it lacks the necessary support to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies severe writing issues in the paper, including grammatical errors, misuse of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues, leaving the authors without actionable feedback. While the comment highlights important areas for improvement, it lacks depth and specificity, making it barely helpful. The authors are left with a general understanding of the problem but without clear steps to correct it. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate this information into their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the related work and possibly integrate it into their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it highlights the similarity between the model\\'s motivation and goals to a prior VAE paper. However, it does not specify which part of the paper this observation pertains to, making it weakly grounded. The comment is specific in identifying the potential for exploring energy models and the similarity to a prior VAE paper, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and it suggests that the model\\'s motivation aligns with a prior VAE paper. However, the comment does not provide specific examples or references to support the claim about the exploration of energy models or the comparison with GANs and VAEs. The mention of a prior VAE paper provides some context, but without detailed examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable, as it requires more detailed support to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model align with a prior VAE paper, suggesting that the authors should consider this related work. However, the comment lacks specific guidance or actionable advice on how the authors might integrate this information into their draft or further explore the energy models. While it identifies an area for potential improvement, the feedback is somewhat helpful as it provides a direction for the authors to consider but does not offer detailed suggestions or examples for implementation. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate this information into their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the related work and possibly integrate it into their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not specify which part of the paper this observation pertains to, making it weakly grounded. The comment is specific in identifying the potential for exploring energy models and the similarity to a prior VAE paper, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and it suggests that the model\\'s motivation aligns with a prior VAE paper. However, the comment does not provide specific examples or references to support the claim about the exploration of energy models or the comparison with GANs and VAEs. The mention of a prior VAE paper provides some context, but without detailed examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable, as it requires more detailed support to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should conduct such experiments, but it lacks concrete details or steps on how to implement them. As a result, the authors are left with a vague understanding of what needs to be done to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the need for experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, it does not specify which part of the paper this issue is related to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the issue, as it clearly outlines what needs to be addressed regarding the experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. This is a relevant point that could impact the validity and applicability of the research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or data collection methods. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative terminology or providing a rationale for why the term \"certificate\" is being used in this context. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors clarify the terminology and ensure that it is understood in the intended context. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing alternative terminology or providing a detailed explanation of the term \"certificate\" in the context of the paper. While it highlights an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors conduct additional experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet. It also provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. The explicit mention of references and the suggestion to explore deeper networks and other network structures provides clear guidance on what the authors should do to strengthen their paper. The comment is highly actionable as it offers concrete steps and references for the authors to follow, ensuring they know exactly how to improve their draft.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet. It also provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental section or methodology. The authors can infer that it relates to the experimental setup or results, but the comment does not specify the exact part of the paper being addressed. The suggestion is specific, as it clearly outlines what additional experiments should be conducted and provides references for inspiration. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet, are needed to strengthen the paper. It provides references to specific works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. This provides a clear and specific suggestion for additional experiments, making the claim mostly verifiable. However, the comment could be strengthened by explaining why these specific references are relevant or how they would enhance the paper. Overall, the feedback is mostly verifiable due to the provision of references and the suggestion for additional experiments, but it could be more robust with further explanation.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment suggests conducting additional experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet, to further strengthen the paper. It provides specific references to relevant works, including MoBiNet, Dynamic Channel Pruning, and Learning Dynamic Routing, which could serve as a basis for these experiments. This feedback is highly helpful as it offers clear and actionable guidance for the authors to enhance their experimental setup and results, providing a concrete path for improvement. By following this suggestion, the authors can significantly strengthen their paper with additional empirical evidence and comparisons. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. While the comment implies that the authors should consider this reformulation, it does not explicitly instruct them to make this change or explain how it would affect the motivation of Algorithm 1. The action is implicit and somewhat vague, as the authors need to infer the need for this reformulation and understand its implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq.(1)\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the prox-linear subproblem can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation of Algorithm 1 unclear. The reviewer provides a logical reasoning by suggesting a reformulation that could affect the motivation of the algorithm. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to explore the suggested reformulation to fully understand its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the motivation of Algorithm 1 by suggesting that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, which would make the motivation unclear. This feedback is clear and actionable, as it points out a specific area where the authors might need to clarify or reframe their approach. By suggesting a potential reformulation, the comment provides a concrete direction for the authors to improve the clarity and motivation of their work. However, it could be more helpful if it included additional guidance on how to address this issue or examples of how the reformulation could be implemented. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to a critical area for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that including multiple local prompts is intuitive, but it raises a concern about the differences in features and their positions across different categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the intuition behind including multiple local prompts and acknowledges that it is intuitive. However, it does not specify which part of the paper this concern relates to, such as a particular section or discussion. The authors may have to infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue with the intuition behind the prompts, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that including multiple local prompts is intuitive but raises a concern about the differences in features and their positions across different categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that including multiple local prompts is intuitive but raises a concern about the differences in features and their positions across different categories. While it identifies a potential issue, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The authors are left without guidance on how to address the concern or what aspects of the paper might need further clarification or explanation. Therefore, the comment is barely helpful, as it points out a potential weakness but does not offer constructive feedback or actionable steps for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding the results in Table 6 and the ablation studies of MCT without adaptive metrics. The first question asks why the results in Table 6 do not align with Table 1 (MCT-pair), which implies that the authors should provide an explanation for this discrepancy. The second question requests ablation studies of MCT without adaptive metrics, suggesting that the authors should conduct these studies to further analyze the impact of adaptive metrics on MCT. While the questions provide some guidance, they do not explicitly instruct the authors on how to address these issues or what specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 6\" and \"Table 1 (MCT-pair)\", allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by asking why the results of Table 6 do not align with Table 1 and requesting ablation studies of MCT without the adaptive metrics. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions regarding the alignment of results in Table 6 with Table 1 (MCT-pair) and the need for ablation studies of MCT without adaptive metrics. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. They are straightforward requests for clarification or additional analysis, which do not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions regarding the results in Table 6 and the ablation studies of MCT without adaptive metrics. By pointing out these areas for improvement, the comment provides clear and actionable feedback that can help the authors enhance their draft. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues or what specific aspects to focus on. Overall, the comment is mostly helpful as it identifies areas for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights similarities between the current analysis and prior works, suggesting that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. However, the comment does not offer explicit guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a detailed critique of the analysis, comparing it to prior works and suggesting that the results are not surprising due to similarities with existing studies. It references specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in detailing the similarities and comparisons to prior works, providing a clear basis for the critique. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that similar analyses are present in prior works and that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. This provides a logical basis for the claim, as it references existing literature and studies that have explored similar topics. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a strong foundation but lacks some specific details for full verification. The score 4 aligns with this assessment.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the analysis presented in the paper, noting that similar analyses are already present in prior works. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. This feedback is somewhat helpful as it highlights a potential gap in the originality of the research and suggests that the results may not be particularly surprising. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the novelty of their work. As it stands, the comment provides a starting point for reflection but lacks detailed guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the 10 sub-tasks are simplistic for bAbi and that the authors should provide more discussions. While the comment implies that the authors should address this issue by adding more discussions, it does not specify what kind of discussions are needed or how they should be structured. The action is implicit and somewhat vague, as the authors know they need to provide more discussions but are not given clear guidance on what those discussions should entail. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the simplicity of the 10 sub-tasks in the bAbi task and suggests that more discussions are needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the simplicity of the sub-tasks and the need for more discussions, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the 10 sub-tasks are simplistic for the bAbi task and suggests that the authors should provide more discussions. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the simplicity of the 10 sub-tasks in the bAbi task and suggests that more discussions are needed. While it points out a specific area for improvement, the comment lacks depth and does not provide detailed guidance on what kind of discussions would be beneficial or how they could be structured. This limits the usefulness of the feedback for the authors, as it does not offer actionable steps or specific suggestions for enhancing their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues. First, it asks for clarification on the term \"sqeuence of episodes,\" which suggests that the authors should provide a definition or explanation. This is an explicit action that the authors can take to address the confusion. Second, the comment points out the absence of related work, suggesting that the paper's novelty may be questioned due to its lack of reference to relevant literature. This is an implicit suggestion that the authors should include a discussion of related work to strengthen their argument for novelty. While the first part is explicit, the second part is implicit and lacks specific guidance on how to include related work. Overall, the comment is mostly actionable, as it provides clear guidance on one aspect but lacks detailed instructions for the other.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"sqeuence of episodes\" and suggests the inclusion of related work, which is crucial for establishing the novelty of the paper. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two issues: the definition of \"sqeuence of episodes\" and the absence of related work. The first part of the comment is a request for clarification, which does not require verification. The second part suggests that the paper\\'s novelty may be questioned due to the lack of reference to related work. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises two important points. First, it questions the definition of 'sqeuence of episodes,' suggesting that the authors clarify this term. This is a clear and actionable suggestion that helps the authors improve the clarity of their paper. Second, the comment points out the absence of related work, noting that the paper's novelty may be questioned due to this omission. This feedback is valuable as it prompts the authors to consider including relevant literature to strengthen their argument for novelty. However, the comment could be more helpful if it provided specific examples of related work or guidance on how to integrate it into the paper. Overall, the comment is mostly helpful, as it identifies areas for improvement and provides some direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the characterization of the study as an \"ablation\" study, stating that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might reframe their study or what specific aspects need to be addressed to align with the concept of an ablation study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the characterization of a study about different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this critique pertains to, such as a specific section or table where the study is described. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique, as it clearly identifies the issue with the characterization of the study, but it lacks grounding, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study about different subdomain sizes is not an \"ablation\" study because it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. Without further explanation or references, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides a claim but lacks sufficient justification or evidence to fully support it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the characterization of a study about different subdomain sizes as an 'ablation' study, suggesting that it does not involve removing a component of the method. This feedback is somewhat helpful as it identifies a potential misinterpretation of the study's methodology. However, it lacks depth and does not provide specific guidance on how the authors might address this issue or improve their characterization. Without actionable advice or suggestions, the comment provides some insight but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should make these additional comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, it does not specify which part of the paper this evaluation is in or where these comparisons should be made. The authors can infer that it relates to the evaluation section, but the lack of explicit mention of specific sections or figures makes it weakly grounded. The comment is specific in suggesting additional comparisons to strengthen the evaluation, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons would be beneficial or how they would enhance the evaluation. The lack of detailed justification or references makes it difficult for the authors to understand the full context and significance of the suggestion. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential improvement in the evaluation section by suggesting that the base DA methods should be compared with and without the architectural competitors, such as AutoDial and AdaBN. This feedback is clear and actionable, as it provides a specific direction for enhancing the evaluation by including direct comparisons with relevant competitors. By following this suggestion, the authors can strengthen their analysis and provide a more comprehensive understanding of the performance of their proposed TransferNorm architecture. However, the comment could be more helpful if it included specific guidance on how to conduct these comparisons or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on how the attention module is attached to the ResNet-20 architecture during the search process. It specifically inquires about the number of attention modules used and their placement, whether after each block or stage. This feedback provides a clear and direct action for the authors to take, which is to clarify these details in their draft. The request is explicit and concrete, giving the authors a specific task to address. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"ResNet-20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding how the attention module is attached to the backbone architecture during the search process. The comment questions the number of attention modules used and their placement, providing a clear direction for the authors to address. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the implementation of the attention module in the ResNet-20 architecture. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the implementation of the attention module in the ResNet-20 architecture. It questions the number of attention modules used and their placement, whether after each block or stage. This feedback is clear and actionable, as it provides a direct request for clarification that could significantly improve the clarity and understanding of the paper. By addressing this issue, the authors can enhance the transparency and comprehensibility of their methodology. However, the comment could be more helpful if it suggested how to clarify these details or provided examples of how other studies have addressed similar issues. Overall, the comment is mostly helpful, as it guides the authors toward a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. While it identifies a specific issue with the clarity of the proof, it does not provide explicit guidance on how the authors should address this problem. The comment lacks concrete suggestions or actions for the authors to take, such as recommending ways to improve the clarity of the proof or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the theorem is buried at the end of the appendix and its proof is not clear enough. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is buried at the end of the appendix and whose proof is not clear enough. This feedback is somewhat helpful as it points out a potential weakness in the paper\\'s presentation and suggests that the authors should clarify or improve the clarity of the proof. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative ways to present the proof or suggesting additional clarifications. As a result, the comment is somewhat helpful, as it highlights a critical area for improvement but does not fully support the authors in making the necessary changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis on BRP-NAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to expand their analysis to include more NAS approaches, but the comment lacks concrete suggestions on which specific approaches to include or how to conduct the additional comparisons. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis on BRP-NAS, specifically mentioning that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which sections or figures are affected. The comment is specific in pointing out the lack of comparison with other NAS approaches, which is a clear area for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis on BRP-NAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This claim is somewhat verifiable as it identifies a specific limitation in the analysis, but it lacks detailed examples or references to other NAS approaches that could have been included. The comment suggests that the authors should expand their analysis, but it does not provide specific guidance on which approaches to include or how to conduct the additional comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This feedback is clear and actionable, as it directs the authors to expand their analysis to include a broader range of NAS approaches. By providing a specific area for enhancement, the comment offers valuable guidance that can help the authors improve the depth and comprehensiveness of their analysis. However, the comment could be more helpful if it suggested specific NAS approaches to include or how to conduct the additional comparisons. Overall, the comment is mostly helpful, as it effectively points out a limitation and provides a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to expand the method\\'s applicability. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, it does not specify which part of the paper discusses the method\\'s applicability or how it is currently limited to digit or text images. The authors might infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in its critique of the method\\'s applicability, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the method might not be applicable to natural images. Without specific examples, comparisons, or references to similar work, the claim lacks verifiability. The authors are left without guidance on how to address this concern or what aspects of the method might need to be reconsidered. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the applicability of the proposed method to natural images, specifically mentioning CIFAR10 as an example. This is a relevant point as CIFAR10 has broader applications in the real world compared to digit or text images. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or expand the method's applicability. Without actionable advice or detailed feedback, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential limitation but does not offer constructive feedback or suggestions for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. It implies that the authors should explore this possibility or acknowledge that it is an open problem. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to include a specific reference or discussion on this topic. The action is implicit but concrete, as the authors know what needs to be done to address the suggestion. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FFNs\" and references a specific issue discussed in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it suggests exploring existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment provides a clear direction for improvement, suggesting that the authors should either find a solution or acknowledge the problem as open. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment provides a logical reasoning by questioning the possibility of finding an approximation or suggesting that the problem might be an open one. However, it lacks specific references or examples of existing work that could be explored, which would make the claim more verifiable. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional details to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even if it's an approximation. This feedback is valuable as it encourages the authors to explore alternative approaches or acknowledge the limitations of their current methodology. By suggesting a potential solution or highlighting an open problem, the comment provides actionable guidance that could enhance the paper's comprehensiveness and clarity. However, the comment could be more helpful if it included specific references or examples of relevant work. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with more detailed suggestions.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies questionable design choices, specifically mentioning the use of perplexity as a measure of semantic information retention after fine-tuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not provide explicit guidance on how to control these factors or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should address the control of domain drift, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses \"some questionable design choices,\" specifically mentioning the use of perplexity as a measure of semantic information retention after fine-tuning. It questions how factors like domain drift are controlled, implying that the authors should address this issue. However, the comment does not specify which part of the paper these design choices are discussed in, making it weakly grounded. The comment is specific in identifying the issue of controlling domain drift, but without explicit grounding, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of perplexity as a measure of semantic information retention after fine-tuning, questioning how factors like domain drift are controlled. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that perplexity is an appropriate measure or that domain drift is not adequately controlled. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the use of perplexity as a measure of semantic information retention after fine-tuning, questioning how factors like domain drift are controlled. This feedback is somewhat helpful as it points out a specific area where the authors might need to clarify or justify their methodology. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address the issue or improve the analysis. The authors are left with a general understanding of the problem but without actionable steps to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the work, noting that it only uses binary features and questioning the applicability of the method to real and categorical features. While the comment identifies an area for improvement, it does not provide explicit guidance or suggestions on how the authors should address this limitation. The action is implicit, as the authors need to infer that they should consider the applicability of their method to real and categorical features. However, the comment lacks concrete details on how to implement this change, making it vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of binary features in the work and questions the applicability of the method to real and categorical features. However, it does not specify which part of the paper discusses the use of binary features or how the authors should address the applicability to real and categorical features. This makes it difficult for the authors to identify the exact section that needs revision. The comment is weakly grounded because it does not provide specific guidance on where to find this information, and it is not specific about what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the applicability of the method to real and categorical features, given that the work only uses binary features. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the work, noting that the method only uses binary features and questioning its applicability to real and categorical features. This feedback is somewhat helpful as it points out an area where the authors might need to expand their method to be more generalizable. However, the comment lacks specific suggestions or guidance on how the authors could address this limitation, such as recommending the inclusion of real or categorical features. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. While the comment identifies a lack of novelty, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the algorithm for constructing coresets, stating that it is not novel as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not specify which part of the paper this critique pertains to, such as a specific section or subsection. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the lack of novelty in the algorithm, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This claim is somewhat verifiable as it provides a logical reasoning that the algorithm is an extension rather than a novel contribution. However, the comment lacks specific references or examples to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the algorithm for constructing coresets, noting that it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This feedback is somewhat helpful as it points out a potential weakness in the originality of the work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their contribution. Without actionable advice or further elaboration, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. There is no guidance on how the authors might address this lack of novelty or improve the originality of their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the algorithm for constructing coresets, stating that it is not novel as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. However, it does not specify which part of the paper this critique pertains to, such as a specific section or subsection. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the lack of novelty in the algorithm, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the algorithm for constructing coresets is not novel, as it is an extension of existing frameworks for classical k-means and (k,z) clusterings to the kernelized setting. This claim is somewhat verifiable as it provides a logical reasoning that the algorithm is an extension rather than a novel contribution. However, the comment lacks specific references or examples to support the claim, making it difficult for the authors to fully understand and address the issue. Without detailed evidence or references, the authors may find it challenging to respond effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the algorithm for constructing coresets, noting"}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative approach they should consider. The comment lacks concrete details or actions for the authors to take, making it difficult for them to understand how to improve their draft. As a result, the action is implicit and vague, aligning with a score of 2.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the rationale behind the decision, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle if all reports were included. This feedback prompts the authors to reconsider their methodology or data selection, encouraging them to explore alternative approaches or justifications for their choice. However, the comment does not provide specific suggestions or guidance on how to address this issue or what alternative strategies might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should generate more instances with constraints and variables to address the concern about the ability of LLMs to model problems with large instance sizes. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to generate these instances or what specific steps to follow. The action is somewhat vague, as it lacks detailed guidance on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should generate more instances with constraints and variables, particularly since few instances in the paper have more than 7 variables. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or table where these instances are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to address the concern about LLMs\\' ability to model problems with large instance sizes, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should generate more instances with constraints and variables, particularly since few instances in the paper have more than 7 variables. This claim is based on the observation that the current dataset is limited in terms of the number of variables, which could affect the ability of LLMs to model problems with large instance sizes. However, the comment lacks specific examples or references to support the claim that more variables would improve the model\\'s performance. While the suggestion is logical, it would be strengthened with additional evidence or references to make it fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the dataset, specifically the number of variables in the instances, which could affect the ability of LLMs to model problems with large instance sizes. It suggests that generating more instances with constraints and variables could address this concern. While the comment highlights an important issue, it lacks specific guidance on how to generate these instances or what additional variables might be relevant. The feedback is somewhat helpful as it points out a potential area for improvement but could be more actionable with detailed suggestions or examples.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should generate more instances with constraints and variables, particularly since few instances in the paper have more than 7 variables. This feedback is explicit in its suggestion, but it lacks concrete guidance on how to generate these instances or what specific steps to take. The action is somewhat vague, as it provides a general direction but does not offer detailed instructions on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should generate more instances with constraints and variables, particularly since few instances in the paper have more than 7 variables. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or table where these instances are discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to address the concern about LLMs\\' ability to model problems with large instance sizes, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should generate more instances with constraints and variables, particularly since few instances in the paper have more than 7 variables. This claim is based on the observation that the current dataset is limited in terms of the number of variables, which could affect the ability of LLMs to model problems with large instance sizes. However, the comment lacks specific examples or references to support the claim that more variables would improve the model\\'s performance. While the suggestion is logical, it would be strengthened with additional evidence or references to make it fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the dataset, specifically the number of variables in the instances, which could affect the ability of LLMs to model problems with large instance sizes. It suggests that generating more instances with constraints and variables could address this concern. While the comment highlights an important issue, it lacks specific guidance on how to generate these instances or what additional variables might be relevant. The feedback is somewhat helpful as it points out a potential area for improvement but could be more actionable with detailed suggestions or examples.\", 'helpfulness_label': '"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the impact of the base node, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion or complexity in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or improve their understanding of the topic. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it highlights a potential area for clarification but does not offer actionable insights or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space into the latent space. This implies that the authors should reconsider the direction of the arrow to align with the intended purpose of influencing n^(i). However, the comment does not provide explicit instructions on how to make this change or why it is necessary. The action is implicit and somewhat vague, as the authors need to infer the need for a change and how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and suggests that it should be from the latent space to n^(i) instead of the current direction. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space into the latent space. The reviewer implies that the main purpose is to influence n^(i), but does not provide specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to substantiate the suggestion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a specific question about the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space into the latent space. This feedback is somewhat helpful as it points out a potential inconsistency or confusion in the figure's representation. However, it lacks depth and does not provide guidance on why this change might be necessary or how it could impact the overall understanding of the figure. To be more helpful, the comment could include reasoning or suggestions on how this change could improve the clarity of the figure or the overall presentation of the results. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the use of abbreviations in the paper, particularly the abbreviation \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. While the comment points out the lack of definition for abbreviations, it does not provide explicit instructions on how the authors should address this issue. The authors are left to infer that they need to define all abbreviations used in the paper, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that many abbreviations lack definition and provides a specific example of \"AR\" standing for domain adaptation tasks and algorithms. This level of detail and specificity makes it clear what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definition and provides a specific example of \"AR\" in Table 5 standing for domain adaptation tasks and algorithms. This provides a clear and specific example of the issue, making the claim somewhat verifiable. However, the comment could be strengthened by explaining why this lack of definition is problematic or suggesting how it could be addressed. The addition of more context or examples would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations in the paper, noting that many abbreviations lack definition and causing confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it directs the authors to address the lack of definition for abbreviations, particularly in the context of domain adaptation. However, the comment could be more helpful if it suggested ways to improve the definition of abbreviations or provided examples of how to clarify them. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a specific example to guide the authors.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the performance comparison in Table 1, specifically noting that the VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This implies that the comparison is unfair. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for fair comparison. The action is implicit and somewhat vague, as the authors need to infer that they should adjust the comparison or provide a more detailed explanation of the sample weights used. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that the VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair due to differences in sample weights used by VINS compared to other baselines. The reviewer provides a specific example of how VINS sets different sample weights, while most baselines use a uniform weight of 1. This claim is somewhat verifiable as it highlights a specific issue with the comparison, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide more context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the performance comparison in Table 1, noting that the VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This highlights a potential unfairness in the comparison. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the fairness of the comparison. While it points out a problem, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors are left with a clear area for improvement but without specific steps to take, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative approaches or optimizations. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not specify which part of the paper discusses the reply buffer or the time complexity, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the reply buffer and its impact on time complexity, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning.\" However, the comment does not provide detailed reasoning or evidence to support why this is a concern or how the referenced paper relates to the issue. The lack of specific examples or detailed explanation makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. This is a relevant observation that could impact the efficiency and scalability of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the algorithm's efficiency. Without actionable advice or further elaboration, the comment is somewhat helpful, as it points out a potential problem but does not offer a clear path for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative approaches or optimizations to address this issue. Without specific guidance or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not specify which part of the paper discusses the reply buffer or the time complexity, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue with the reply buffer and its impact on time complexity, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, 'PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning.' However, the comment does not provide detailed reasoning or evidence to support why this is a concern or how the referenced paper relates to the issue. The lack of specific examples or detailed explanation makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. This is a relevant observation that could impact the efficiency and scalability of the proposed method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the algorithm's efficiency. Without actionable advice or further elaboration, the comment is somewhat helpful, as it points out a potential problem"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that a brief conclusion of the article and a summary of the paper\\'s contributions need to be provided. This is a clear and direct action for the authors to take, as it specifies exactly what needs to be added to improve the draft. The comment is explicit and provides concrete guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that a brief conclusion of the article and a summary of the paper\\'s contributions need to be provided. However, it does not specify which part of the paper these should be included in, making it weakly grounded. The comment is specific in its request for a conclusion and summary, but without explicit references to sections, it is challenging for the authors to pinpoint where these additions should be made. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a brief conclusion and summary of the paper\\'s contributions are needed. However, it does not provide any reasoning, examples, or references to support why these additions are necessary or how they would improve the paper. Without specific evidence or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that a brief conclusion and a summary of the paper\\'s contributions need to be provided. This feedback is clear and actionable, as it directs the authors to include these elements in their draft to enhance its completeness and clarity. However, the comment could be more helpful if it provided examples of how a conclusion and summary could be structured or what specific points should be included. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their paper. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include a comparison with a method designed to defend against multiple attacks, which provides some guidance on what the authors could do to improve their paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This claim is somewhat verifiable as it provides a logical suggestion for improvement, but it lacks specific examples or references to existing methods that could be used for comparison. The comment implies that such a comparison would be beneficial, but without detailed guidance or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This is a constructive suggestion that could enhance the paper's relevance and impact by providing a more comprehensive comparison. The comment also acknowledges the paper's interest in defending against increasing malicious perturbations, which adds value to the feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this comparison. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the plan-based method requiring manual design based on the ground truth, which is unrealistic in real-world scenarios. It also notes that the learned plan methods are not comparable to methods with pre-defined plans based on Table 2. The comment implies that the proposed method may be difficult to generalize to new datasets without the ground truth summary. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the generalizability of their method. The action is implicit and somewhat vague, as the authors are left to infer the need for a more robust evaluation or generalization strategy. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the plan-based method, specifically mentioning the need for manual design based on the ground truth, which is unrealistic in real-world scenarios. It also compares the learned plan methods to those with pre-defined plans based on Table 2, indicating potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. However, the comment does not specify which part of the paper discusses the plan-based method or the learned plan methods, making it weakly grounded. The authors can infer that it relates to the methodology section, but the lack of explicit references or specific sections makes it challenging to pinpoint. The comment is specific in detailing the issue with the plan-based method and its generalizability, but the lack of grounding makes it difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plan-based method requires manual design based on the ground truth, which is unrealistic in real-world scenarios. It also suggests that the learned plan methods are not comparable to methods with pre-defined plans based on Table 2, indicating potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. While the comment provides a logical argument about the limitations of the plan-based method, it lacks specific examples or references to support the claim about the learned plan methods being comparable. The mention of Table 2 provides some context, but the claim remains somewhat verifiable due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant limitation of the plan-based method, noting that it requires manual design based on the ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to methods with pre-defined plans, suggesting potential difficulties in generalizing the proposed method to new datasets without the ground truth summary. This feedback is clear and actionable, as it highlights a critical weakness in the methodology and provides a specific area for improvement. By addressing this issue, the authors can enhance the practical applicability and generalizability of their method. However, the comment could be more helpful if it offered suggestions on how to overcome these limitations or alternative approaches to consider. Overall, the comment is mostly helpful, as it effectively guides the authors towards improving their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding a first sentence to introduce the content of Section 3.2. This is a clear and direct action for the authors to take, as it specifies what needs to be done to improve the clarity of the section. The suggestion is concrete, as it provides a specific step for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly suggests adding a first sentence to introduce the content of the section, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a first sentence to introduce Section 3.2, which is a clear and direct suggestion. However, it does not provide any reasoning or justification for why this addition is necessary or how it would improve the section. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment is clear and actionable, suggesting that the authors add a first sentence to introduce Section 3.2. This is a straightforward and specific piece of feedback that can help the authors improve the clarity and organization of their paper. By providing a direct action, the comment is mostly helpful, as it guides the authors in making a specific improvement to their draft. However, it could be more helpful if it explained why adding a first sentence is important or how it would enhance the section. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps to take to clarify the statement. As a result, the authors are left without a clear understanding of what action to take or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the claim or justify why this statement is problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the meaning of 'initial rationale selector is perfect' in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback is somewhat helpful as it prompts the authors to clarify the statement, which could be important for understanding the context and purpose of the initial rationale selector. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the statement. Therefore, it is rated as somewhat helpful, as it identifies a potential area for clarification but does not fully support the authors in making improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment provides a clear and explicit suggestion for improving the clarity of the text. It instructs the authors to update the statement about uncertainty to clarify that it is defined based on the posterior distribution, which is a more accurate representation of epistemic model uncertainty. The comment also provides a specific example of how this clarification could be made, by mentioning the prior distribution and the posterior distribution. This level of detail and specificity gives the authors a clear understanding of what needs to be done to improve the draft. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the part of the paper being addressed, which is the definition of uncertainty. It also specifies what needs to be clarified, namely, the representation of epistemic model uncertainty in the prior distribution and the update to the posterior distribution upon observing data. This provides clear guidance on how to improve the clarity of the text. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests a clarification regarding the definition of uncertainty, specifically noting that it is based on the posterior distribution. The reviewer provides a detailed explanation of how this uncertainty is represented in the epistemic model, using the prior distribution and the posterior distribution upon observing data. This explanation is clear and provides a logical basis for the claim, making it fully verifiable. The reviewer's suggestion is well-supported by logical reasoning and specific examples, allowing the authors to understand and address the issue effectively. Therefore, the comment is rated as 5: Fully Verifiable.\", 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the clarity of the text regarding the definition of uncertainty. It specifies that the uncertainty should be defined based on the posterior distribution, and it offers a detailed explanation of how this uncertainty is represented in the epistemic model. By suggesting this clarification, the comment helps the authors to better understand and present their work, making it highly helpful. The feedback is specific and provides a concrete way for the authors to enhance the clarity and accuracy of their draft, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it questions whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, and second, it asks about the number of questions created for the zero-shot intent classifier and the accuracy of the system. While the comment explicitly mentions these points, it does not provide specific guidance on how the authors should address these issues. The authors are left to infer that they need to clarify these aspects in their draft, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, and it asks about the number of questions created for the zero-shot intent classifier and the accuracy of the system. This provides clear guidance on what the authors need to clarify or address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions seeking clarification about the experimental setup and results. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions that are relevant to the paper\\'s methodology and results. First, it asks whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, which is an important aspect of the evaluation process. Second, it inquires about the number of questions created for the zero-shot intent classifier and the accuracy of the system, which are critical metrics for assessing the performance of the proposed method. While the comment identifies areas for clarification, it does not provide detailed guidance or suggestions on how the authors might address these issues or improve their draft. The feedback is somewhat helpful as it prompts the authors to clarify specific aspects of their work, but it lacks depth and actionable advice, leaving the authors with a general sense of what needs to be addressed without detailed steps on how to do so.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a lack of meaningful baselines in the paper, noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare their work with a chain-of-thought prompting approach. This feedback is clear and provides a concrete action for the authors to take, which is to include more meaningful baselines in their comparisons. The suggestion is specific and actionable, giving the authors a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of meaningful baselines and suggests a comparison with a chain-of-thought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors could compare their work with a chain-of-thought prompting approach. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with a chain-of-thought prompting approach provides some direction but does not fully explain why this comparison would be meaningful or how it would enhance the paper. Therefore, the comment is somewhat verifiable, as it provides a suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of meaningful baselines. It points out that while the authors mention various model criticism techniques in Section 2, they limit their comparisons to simple naive baselines. The comment suggests that the authors could compare their work with a chain-of-thought prompting approach, which could provide a more robust evaluation. This feedback is clear and actionable, offering a specific direction for improvement that would enhance the paper\\'s rigor and comprehensiveness. However, the comment could be more helpful if it provided additional context or examples of how the chain-of-thought prompting approach could be integrated. Overall, the comment is mostly helpful, as it effectively guides the authors towards a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important experimental details and the lack of explanations or interpretations in the Appendix, specifically mentioning the PCA experiments in Figures 3, 7, and 8. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text or appendices. However, the lack of concrete guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and experiments (PCA), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the absence of explanations or interpretations in the Appendix, which is crucial for understanding the experimental details. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. The comment provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This level of detail and specificity supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper by pointing out the absence of important experimental details and the lack of explanations or interpretations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8, which are not explained, providing concrete examples of what needs to be addressed. This feedback is clear and actionable, as it directs the authors to include more detailed explanations and interpretations in their draft. However, the comment could be more helpful if it offered suggestions on how to improve the explanations or provided additional context for the authors to consider. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue. It lacks actionable advice, such as suggesting alternative notations or recommending a consistent use of \"K.\" As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This provides some grounding as it refers to specific lines in the paper (L166 and L176), allowing the authors to identify the parts of the paper being addressed. However, the comment lacks specificity as it does not explain why this ambiguity is problematic or suggest how the authors might resolve it. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the notation \"K\" is abused in the paper, being used ambiguously to represent both a known kernel function and the number of layers. This is a factual observation that does not require verification, as it is based on the reviewer\\'s understanding of the text. The comment does not express an opinion, make a subjective claim, or suggest changes that would require justification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This is a clear and actionable observation that highlights a potential source of confusion in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending alternative notations or suggesting ways to clarify the usage of \"K.\" While it points out a problem, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\\' admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\\' statement about the potential impact of cognitive mechanisms on self-organization and suggests that it would be surprising if behavioral economists ignored these aspects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific points need clarification. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' admission that the problem is reductionist and does not allow for bargaining and negotiation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition in light of the problem\\'s limitations and suggests the need for more citation to compare with \"previously appreciated\" work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\\' admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\\' statement about the potential impact of cognitive mechanisms on self-organization and suggests that it would be surprising if behavioral economists ignored these aspects. However, the comment lacks specific examples or references to support the claim that behavioral economists would ignore these aspects, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the relevance of connections to human cognition in the context of the problem being studied. It points out the authors' admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation, which are commonly used by humans. The comment questions the authors' statement about the potential impact of cognitive mechanisms on self-organization and suggests that it would be surprising if behavioral economists ignored these aspects. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or provide more context. While it identifies a potential area for improvement, it does not offer actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and that word choice is flamboyant in multiple places. However, it does not provide explicit guidance on how to address this issue or suggest specific changes to make the language more appropriate. The authors are left to infer that they should tone down the language, but the comment lacks concrete details on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"conclusion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording, noting that it is overly exaggerated and that word choice is flamboyant in multiple places. This provides clear guidance on what needs to be addressed in the conclusion. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and that word choice is flamboyant in multiple places. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and make appropriate changes. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the language used in the conclusion, noting that it is overly exaggerated and that word choice is flamboyant in multiple places. This feedback is somewhat helpful as it highlights a potential issue with the writing style that could impact the clarity and professionalism of the paper. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending more precise or concise language. Without actionable advice, the authors may find it challenging to effectively improve their draft based on this feedback. Therefore, the comment is rated as somewhat helpful, as it points out a problem but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of comparison to simple feature acquisition baselines, such as expected utility, which is a significant weakness of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific baselines to include. The comment also mentions writing style and other issues, but these are not elaborated upon. As a result, the authors are left without clear instructions on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact sections that need improvement. The comment also mentions writing style and other issues, but these are not elaborated upon, leaving the authors without specific guidance on how to address them. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison to simple feature acquisition baselines like expected utility, which is a significant weakness. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines like expected utility. This feedback is valuable as it highlights an important area for improvement that could enhance the paper\\'s credibility and impact. However, the comment does not provide specific suggestions or guidance on how the authors might conduct these comparisons or which baselines would be most appropriate. While it points out a critical issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the introduction of multi-granularity and multi-scale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their work. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the introduction of multi-granularity and multi-scale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment does not specify which part of the paper discusses these approaches or where the critique is most relevant. The authors may have to infer that it pertains to the introduction or related sections, but this inference is not explicit. The comment is specific in detailing the critique but lacks grounding, as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the introduction of multi-granularity and multi-scale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains unverifiable, as it does not provide sufficient justification for the authors to address the critique effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the introduction of multi-granularity and multi-scale approaches in the context of convolutional networks, suggesting that merely applying this approach to MLMs is not innovative. It also mentions that some algorithms used in the article from object detection enhance information on the input side, while many MLMs can already perform object detection tasks independently. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their work. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these additional experiments. The action is implicit and somewhat vague, as the authors need to infer the need for more experiments and the specific tasks or domains to explore. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this is not explicitly mentioned. The comment is specific in detailing the concerns and suggestions for further experimentation, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments do not adequately address these issues. The authors are left to infer the nature of the concerns and the need for additional experiments, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It highlights a specific area of concern regarding the training of similar nodes or graphs with features that converge excessively, potentially discarding their unique features. Additionally, it questions the effectiveness of selecting positive samples without introducing perturbation noise, which could lead to lower generalization performance. The comment suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the feedback identifies critical areas for improvement, it lacks specific guidance on how to design or conduct these additional experiments. The authors are left with a clear direction for further investigation but without detailed instructions on implementation. Therefore, the comment is somewhat helpful, as it provides valuable insights but could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this discussion should be included in, nor does it provide specific details on what aspects of the discussion are lacking. The authors may have an idea of where this discussion could fit, but the comment lacks grounding and specificity. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of a question and an expression of desire for more discussion on the power of different architectures. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects of the discussion should be expanded or how to enhance the paper. Therefore, the comment is barely helpful, as it provides a starting point but does not fully support the authors in improving their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their methods across different splits of train-val-test rather than just different initialization seeds to obtain robust results. This feedback is explicit and provides a clear action for the authors to take, which is to conduct additional evaluations across different splits. The comment also offers concrete guidance on how to improve the robustness of the results, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the methods across different splits of train-val-test rather than just different initialization seeds to obtain robust results. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or results section, but this inference is not explicit. The comment is specific in its suggestion to evaluate across different splits, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that evaluating the methods across different splits of train-val-test would provide more robust results than just different initialization seeds. This claim is somewhat verifiable as it provides a logical reasoning for why different splits are more beneficial for obtaining robust results. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that evaluating the methods across different splits of train-val-test would provide more robust results than just different initialization seeds. This feedback is clear and actionable, as it provides a specific recommendation for improving the robustness of the results. By conducting evaluations across different splits, the authors can ensure that their findings are not dependent on a single split and are more generalizable. This suggestion is valuable as it offers a straightforward way to enhance the reliability and validity of the study's results. However, the comment could be more helpful if it provided additional context or examples of how different splits can impact the results. Overall, the comment is mostly helpful, as it guides the authors towards a significant improvement in their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that Figure 2 is ambiguous due to unclear explanations of symbols and raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process. While the comment identifies specific issues with the figure, it does not provide explicit guidance on how to address these ambiguities or clarify the symbols. The authors are left to infer that they need to improve the clarity of the figure and possibly investigate the issue of information redundancy. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that some symbols are not explained clearly and raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 2 is ambiguous due to unclear explanations of symbols and raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references leaves the claim somewhat verifiable, as the authors would need to infer the nature of the ambiguity and the potential redundancy themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Figure 2, noting that some symbols are not explained clearly. It also raises a question about potential information redundancy and interference in the multi-sphere icosahedral discretization process. This feedback is somewhat helpful as it points out a specific area for improvement in the paper's presentation and raises a relevant question that could impact the understanding of the methodology. However, the comment could be more helpful if it provided suggestions on how to clarify the symbols or address the potential redundancy issue. Overall, the comment offers some guidance but lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper\\'s results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment suggests that this limitation could restrict the applicability of the results. However, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve the scope of their results. The action is implicit and vague, as the authors are left to infer that they should consider including a broader range of kernels or discuss the implications of this limitation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific limitation in the paper regarding the assumption of the spectrum of a kernel being sub-gaussian. It points out that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. This provides a clear indication of the part of the paper being addressed, making the comment fully grounded. However, the comment lacks specificity as it does not detail how the authors might address this limitation or suggest alternative approaches. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the paper\\'s results are limited because the authors assume a sub-gaussian spectrum for kernels, which is reasonable for popular Gaussian kernels but not for other popular kernels like Matern kernels. The reviewer provides a logical reasoning for this claim, explaining that the assumption of a sub-gaussian spectrum is valid for Gaussian kernels but not for Matern kernels, which decay polynomially. This reasoning is clear and provides a solid basis for the claim. However, the comment could be strengthened by providing specific examples or references to support the claim about the limitations of the results. Therefore, the comment is mostly verifiable, as it provides a strong logical basis but lacks detailed examples or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper\\'s results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment highlights that this limitation could restrict the applicability of the results. While it points out a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the scope of their results. The feedback is somewhat helpful as it raises an important consideration but lacks depth and actionable advice, leaving the authors with a general insight into a potential limitation without clear steps to address it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance. It suggests that the authors should focus more on the pretraining method in the main paper. While the comment explicitly states the action needed (focusing more on the pretraining method), it does not provide specific guidance on how to implement this suggestion, such as which aspects of the pretraining method should be emphasized or how to structure the discussion. The action is concrete but somewhat vague, as it lacks detailed instructions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the lack of detailed discussion on unsupervised pretraining in the main paper and suggesting that it is more important than other modules presented in the paper. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4. However, it lacks specific evidence or detailed reasoning to support this claim, such as comparisons with other methods or detailed analysis of the impact of unsupervised pretraining. The suggestion to focus more on the pretraining method in the main paper is based on a comparison with the ablation study in Table 5, but this comparison is not fully elaborated. Without additional context or detailed justification, the claim remains somewhat verifiable, as it provides a logical basis but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the main paper regarding the lack of detailed discussion on unsupervised pretraining, despite its significant impact on performance gain. It suggests that the authors should focus more on the pretraining method in the main paper, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific suggestions on how to structure the discussion or what aspects of the pretraining method should be emphasized. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should test their method on more datasets to gain a better understanding of its performance. While the action is explicit, it is somewhat vague as it does not specify which additional datasets should be used or how many datasets are needed for a comprehensive evaluation. The authors are given a clear direction to improve their work, but the lack of specific guidance on the number or types of datasets limits the level of detail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not specify which part of the paper discusses the method or the datasets used, making it weakly grounded. The comment is specific in its suggestion to test on more datasets, but without grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method should be tested on more datasets to gain a better understanding of its performance. However, it does not provide any specific reasoning, examples, or references to support why more datasets are necessary or how they would improve the evaluation. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the method should be tested on more datasets to gain a better understanding of its performance. While this is a logical and constructive suggestion, it lacks specificity and does not provide guidance on which additional datasets should be considered or how many datasets are needed for a comprehensive evaluation. The comment identifies a potential area for improvement but does not offer actionable advice or detailed feedback, making it somewhat helpful. The authors are given a direction to improve their work, but the lack of specific guidance limits the comment\\'s effectiveness. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the domain of the inputs, noting that they appear to be in the same sphere but not mentioned in the paper. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify the domain of the inputs in their paper. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the domain of the inputs, specifically noting that they appear to be in the same sphere and are not mentioned in the paper. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact location where this information should be included. While the comment is specific in questioning the domain of the inputs, it lacks grounding as it does not provide explicit references to the paper\\'s sections or figures. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the domain of the inputs, noting that they appear to be in the same sphere and are not mentioned in the paper. This feedback is somewhat helpful as it directs the authors to clarify an important aspect of their work that may have been overlooked. However, the comment lacks depth and does not provide guidance on how to address this issue or what specific information should be included to clarify the domain. To be more helpful, the comment could suggest ways to incorporate this information or provide examples of how similar studies have addressed this issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a specific example, mentioning \"Z\\u0027\" and suggesting that taking it to be the empty set would imply independence between x and y given W, which contradicts Eq. (7). This feedback is explicit in pointing out the inconsistency and provides a clear action for the authors to address the conflict. However, it does not specify how to resolve the conflict or what changes are needed. The action is concrete but could be more detailed, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (7)\" and \"Lemma 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, suggesting a specific example involving \"Z\\u0027\" and its implications. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, as illustrated by a specific example involving \"Z\\u0027.\" The reviewer provides a clear explanation of the issue, making the claim mostly verifiable. However, the comment could be strengthened by providing additional examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific inconsistency in the paper, pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It provides a clear example involving \"Z\\u0027\" to illustrate the issue, suggesting that taking \"Z\\u0027\" to be the empty set would imply independence between x and y given W, which contradicts Eq. (7). This feedback is clear and actionable, as it directs the authors to address the inconsistency and potentially revise their definitions or equations. However, the comment could be more helpful if it suggested how to resolve the conflict or provided additional guidance on the implications of this inconsistency. Overall, the comment is mostly helpful, as it provides a significant insight into a potential error in the paper, but could be further enhanced with more detailed suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the distinction between the two normalization methods. Without actionable suggestions or explicit directions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the difference between Online Normalization and Batch Normalization, particularly their bias and unbiased nature. It raises a question about why Online Normalization is unbiased and Batch Normalization is biased, which is a clear and specific point. However, the comment does not explicitly mention which part of the paper discusses these normalization methods, making it weakly grounded. Despite this, the comment is specific in detailing the issue, so it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. It suggests that the authors clarify why Online Normalization is unbiased and Batch Normalization is biased. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. It points out a potential confusion regarding why Online Normalization is unbiased and Batch Normalization is biased. While the comment identifies a specific area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the distinction between the two normalization methods. Without actionable feedback or additional context, the comment is somewhat helpful, as it prompts the authors to consider revising their explanation. However, it lacks depth and specificity, which limits its usefulness. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. While the comment highlights an area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this concept. The action is implicit, as the authors need to infer that they should address the clarity of the concept, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. However, it does not specify which part of the paper this concept is discussed in, making it weakly grounded. The comment is specific in its inquiry about the definition of local interactions, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks any justification or examples to help the authors understand the issue or how to address it. As a result, the claim is not verifiable, as it does not provide the necessary information for the authors to improve their draft. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the clarity of the concept of local interactions, specifically whether it refers to interactions within a time window or within the same modality. While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might clarify this concept or improve its presentation. The comment lacks actionable feedback, leaving the authors without a clear path to address the issue. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this discrepancy. The authors are left to infer that they need to investigate and possibly revise their results or methodology, but the lack of specific actions or directions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the paper\\'s claim of better results in the Molecule generation experiment, noting that adding the proposed constrained method actually results in lower validity and diversity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of better results in the Molecule generation experiment is contradicted by the observation that adding the proposed constrained method actually results in lower validity and diversity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the paper's claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. This feedback is somewhat helpful as it points out a potential issue that the authors need to address. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might resolve this discrepancy or improve their results. To be more helpful, the comment could include suggestions for further analysis or explanations to clarify the observed results. Therefore, the comment is rated as somewhat helpful, as it highlights an important area for improvement but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to include this description or specify how much detail is required. The action is implicit and somewhat vague, as the authors can infer the need for more information but lack concrete guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not specify which part of the paper this description should be included in, nor does it provide any details on what aspects of the Starcraft environment need more description. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not contain any claims, opinions, or suggestions that require verification. It is a request for additional information, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While this feedback highlights an area where additional information could be beneficial, it lacks specificity and does not provide detailed guidance on what aspects of the environment need more description or how this could enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors combine existing techniques without innovation and suggests using more recent and effective domain adaptation methods to improve performance. While the comment implies that the authors should consider alternative domain adaptation methods, it does not explicitly instruct them to do so or provide specific examples of these methods. The action is implicit and somewhat vague, as the authors need to infer that they should explore and implement more advanced domain adaptation techniques. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the combination of existing techniques to create a framework without innovation, specifically mentioning the use of adversarial attack or correction methods and domain adaptation methods. It also points out that the adopted domain adaptation method is an old and simple method proposed eight years ago. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or method description. This makes it difficult for the authors to pinpoint the exact area needing improvement. While the comment is specific in detailing the issue with the domain adaptation method, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors combine existing techniques without innovation and suggests using more recent and effective domain adaptation methods to improve performance. The claim is supported by logical reasoning, as it points out the lack of innovation in combining existing techniques and questions the choice of an old and simple domain adaptation method. However, the comment lacks specific references or examples of alternative domain adaptation methods that could be used, which would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but could be more robust with additional supporting evidence.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's approach, noting that the authors combine existing techniques without innovation. It points out that the adversarial attack or correction method and the domain adaptation method used are proposed by prior work and that the adopted domain adaptation method is outdated. The comment suggests that the authors should consider using more recent and effective domain adaptation methods to improve the performance of their framework. This feedback is clear and actionable, as it provides a specific area for improvement and offers a rationale for why the current approach may not be optimal. However, the comment could be more helpful if it suggested specific alternative domain adaptation methods or provided a detailed analysis of why the current methods are not effective. Overall, the comment is mostly helpful as it directs the authors to a potential area for enhancement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include more game environments. While it implies that additional experiments are necessary, it does not provide specific guidance on which additional environments to include or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not specify which part of the paper discusses the experiments or which game environment is being used. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct more experiments, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not provide any specific reasoning, examples, or references to support why more experiments are necessary or how they would improve the study. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental design, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary to provide a broader perspective or validation of the findings. While the comment highlights an important area for improvement, it lacks specific guidance on which additional game environments should be considered or how to conduct these experiments. The feedback is somewhat helpful as it points out a potential weakness in the study, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include more game environments. While it implies that additional experiments are necessary, it does not provide specific guidance on which additional environments to include or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not specify which part of the paper discusses the experiments or which game environment is being used. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct more experiments, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not provide any specific reasoning, examples, or references to support why more experiments are necessary or how they would improve the study. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental design, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary to provide a broader perspective or validation of the findings. While the comment highlights an important area for improvement, it lacks specific guidance on which additional game environments should be considered or how to conduct these experiments. The feedback is somewhat helpful as it points out a potential weakness in the study, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. While it implies that additional experiments are necessary, it does not provide specific guidance on which additional game environments to include or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the experiments are only conducted on one game environment and recommends the need for more"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and the accuracy levels. However, the comment does not explicitly instruct the authors to address this issue or suggest how to improve the implementation. While the information is detailed, the lack of a direct action or guidance on how to resolve the problem makes the comment somewhat actionable. The authors know that the issue exists but may not be entirely clear on how to proceed with improvements.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the authors have implemented ImageNet for the first time, but it does not specify which part of the paper this claim is made in. The authors can infer that it relates to the implementation section, but this inference is not explicit. The comment provides specific details about the slowness and low accuracy of the implementation, mentioning the time taken to test an ImageNet picture using AlexNet and ResNet-18 and the accuracy levels. However, without explicit grounding, the comment is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' claim of implementing ImageNet for the first time is inaccurate, as it is slow and has low accuracy. The reviewer provides specific examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and the accuracy levels, which support the claim. This provides a clear and detailed justification for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and the accuracy levels. This feedback is clear and actionable, as it highlights a significant problem that the authors need to address. However, the comment could be more helpful if it suggested potential solutions or improvements to address the issue. Overall, the comment is mostly helpful as it provides valuable insights into a critical aspect of the work, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the classification error of the proposed network and suggests that it may not be universally as good as the standard softmax network. It questions the authors\\' claim of better detecting out-of-distribution samples without compromising classification accuracy. The reviewer explicitly requests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provide theoretical justifications for their claims. This feedback is explicit and provides concrete actions for the authors to take, such as reporting classification accuracy and offering theoretical justifications. The request for reporting classification accuracy is clear, and the suggestion for theoretical justifications adds depth to the feedback. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the classification network proposed by the authors and questions the universality of its classification error compared to the standard softmax network. It raises concerns about the potential loss of classification accuracy when building a new model for better detecting out-of-distribution samples. The reviewer suggests reporting the classification accuracy on ImageNet data and requests theoretical justifications for the issue. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the proposed classification network and its performance. The authors can infer that it relates to the methodology or results section, but the comment lacks explicit grounding. However, it is specific in detailing what needs to be addressed, such as reporting classification accuracy and providing theoretical justifications. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed network compared to the standard softmax network. It questions the universality of the proposed network\\'s classification error and suggests that building a new model for better detecting out-of-distribution samples might compromise its classification accuracy. The reviewer requests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provide theoretical justifications for their claims. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the universality of the classification error. The request for reporting classification accuracy and theoretical justifications provides some guidance, but the initial claim remains somewhat verifiable due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the universality of the proposed classification network's performance compared to the standard softmax network. It questions the authors' claim of better detecting out-of-distribution samples without compromising classification accuracy. The reviewer suggests reporting the classification accuracy of the proposed classifier on ImageNet data and requests theoretical justifications for their claims. This feedback is clear and actionable, providing the authors with specific steps to take to address the concern and improve the robustness of their claims. By suggesting both empirical evidence (classification accuracy) and theoretical justifications, the comment offers a comprehensive approach to enhancing the paper's credibility and depth. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the experimental comparison, suggesting that the proposed method was pre-trained before fine-tuning, which may not be the case for the compared methods. It questions whether the compared methods were initialized with the same or similar pre-trained model, and if not, it points out that the proposed method without SSL performs inferior to most of the compared methods. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should ensure a fair comparison by using similar pre-trained models for all methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the experimental comparison, questioning whether the compared methods were initialized with the same or similar pre-trained model as the proposed method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental comparison is unfair due to differences in pre-training between the proposed method and the compared methods. The reviewer provides a specific example from Table 1, where the proposed method without SSL performs inferior to most compared methods. This provides a logical reasoning for the claim, as it highlights a potential issue with the experimental setup. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a clear direction for improvement but lacks comprehensive justification.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experimental comparison, specifically noting that the proposed method was pre-trained before fine-tuning, while the compared methods may not have been initialized with the same or similar pre-trained model. This observation is important because it questions the fairness of the comparison, as the proposed method may have an advantage due to its pre-training. The comment provides a specific example from Table 1, where the proposed method without SSL performs inferior to most compared methods, highlighting a critical area for improvement. While the comment does not offer explicit suggestions on how to address this issue, it effectively points out a potential weakness in the experimental setup, which is valuable feedback for the authors to consider. Therefore, the comment is mostly helpful, as it provides clear insights into a significant aspect of the experimental design that needs attention.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from describing possible alternate formulations for Confidence Diversity (CD). It does not explicitly request additional experiments but rather points out a lack of clarity regarding what additional information CD captures beyond Predictive Uncertainty. The reviewer also questions why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" While the comment implies that the authors should address these issues, it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113\" and \"line 115,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as describing alternate formulations for Confidence Diversity (CD) and questioning the use of entropy as a measure of \"amount of spreading of teacher predictions.\" The comment provides clear guidance on what additional information is needed to clarify the paper, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the clarity of the paper regarding Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It suggests that the paper should describe alternate formulations for CD and questions the use of entropy as a measure of \"amount of spreading of teacher predictions.\" However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires the authors to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper by suggesting that the authors describe possible alternate formulations for Confidence Diversity (CD). This feedback is actionable and provides a clear direction for enhancing the clarity and depth of the paper. It also raises a question about the use of entropy as a measure of 'amount of spreading of teacher predictions over the probability simplex among different (training) samples,' which could be addressed in the paper. However, the comment could be more helpful if it provided additional context or examples to support the suggestion. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. It suggests that this makes the human baseline considerably weaker than the model baseline, apart from other factors mentioned in Section 4.1. Additionally, the comment points out a potential misrepresentation in the abstract regarding the human baseline\\'s performance. However, the comment does not provide specific guidance on how the authors should address this issue or improve the presentation of the human baseline. The feedback is explicit in identifying the problem but lacks concrete suggestions on how to resolve it, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. It also points out a potential misrepresentation in the abstract regarding the human baseline\\'s performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the human baseline and the potential misrepresentation in the abstract, but without explicit grounding, the authors may struggle to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the human baseline is considerably weaker than the model baseline due to the human only following a little more than 1 hour of speech recordings compared to the full 15 hours. The comment also points out a potential misrepresentation in the abstract regarding the human baseline\\'s performance. However, the comment lacks specific evidence or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The mention of \"misleading\" in the abstract provides some context, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the human baseline, noting that the human only follows a little more than 1 hour of speech recordings compared to the full 15 hours. This discrepancy makes the human baseline considerably weaker than the model baseline. Additionally, the comment points out a potential misrepresentation in the abstract regarding the human baseline's performance. While the comment highlights a critical issue, it lacks detailed guidance on how the authors might address this discrepancy or improve the presentation of the human baseline. The feedback is somewhat helpful as it points out a significant weakness, but it could be more actionable with specific suggestions or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the related work section, noting that it discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they should include these methods as baselines, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the related work section, specifically mentioning the discussion of methods for training NMT models beyond MLE, such as RL methods. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the issue of none of these methods being used as baselines, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the related work section discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This claim is somewhat verifiable as it identifies a gap in the literature review, but it lacks specific examples or references to support the claim. The authors would need to provide more detailed information or examples to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the related work section, noting that it discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This feedback is somewhat helpful as it points out a potential weakness in the paper's literature review. However, it lacks specific suggestions or guidance on how the authors might address this gap, such as recommending which RL methods to include as baselines or how to integrate them into the study. Without actionable advice, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors should investigate the resilience of the metric to the choice of random projection. While the comment explicitly states the need for further analysis, it does not provide specific guidance on how to conduct this investigation or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the results, namely the variability in results with the chosen random projection matrix. It suggests that the authors should investigate the resilience of the metric to the choice of random projection, which is a clear and specific direction. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. Despite this, the comment is specific in its suggestion, so the overall classification aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. While the comment implies that the authors should investigate the resilience of the metric to the choice of random projection, it does not provide specific examples or detailed reasoning to support this claim. The suggestion is somewhat vague and lacks concrete evidence or references to substantiate the concern. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a valid concern about the variability in results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors should investigate the resilience of the metric to the choice of random projection, which is a critical aspect to consider for the robustness of the results. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how to address this concern. The feedback is somewhat helpful as it points out an area for improvement but lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and the comparative methods, rather than just being used in the ablation study. While the comment implies that the authors should consider using FGT for performance evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the use of FGT for performance evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limited use of FGT for performance evaluation, suggesting that it should be used to evaluate both the proposed method and comparative methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the evaluation. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation of the proposed method, specifically regarding the use of FGT. It suggests that FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This feedback is somewhat helpful as it points out a limitation in the current evaluation process and offers a suggestion for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to implement this suggestion. Overall, the comment provides a direction for improvement but lacks depth, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or expand the scope of their work. The comment lacks actionable guidance, leaving the authors without a clear direction for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the focus of the work, specifically mentioning that it is narrow in terms of the task (climate change QA) and the language (Arabic). However, it does not specify which part of the paper discusses this focus, making it weakly grounded. The comment is specific in identifying the narrow scope of the work, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the work is focused on a narrow task (climate change QA) in a specific language (Arabic), which may limit its broader impact. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it affects the broader impact of their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the work, noting that it is focused on a narrow task (climate change QA) in a specific language (Arabic). This observation is relevant as it highlights a potential scope for improvement in terms of broader applicability. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or expand the scope of their work. Without specific recommendations or examples, the authors may find it challenging to effectively respond to this feedback. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not provide detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. While the comment implies that the authors should reconsider their approach to distinguishing these distances, it does not provide explicit guidance on how to address this issue or what alternative approach to take. The action is implicit and somewhat vague, as the authors need to infer that they should simplify their approach but are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these distances are discussed. Without explicit references, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide details on why distinguishing between these distances is unnecessary or how the authors might simplify their approach. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion or how it could be substantiated. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that there may be no need to distinguish between the two types of representation distances, $d_{SM}$ and $d_{DM}$, as they are calculated in the same way. While this observation could potentially simplify the approach, the comment lacks specific guidance or suggestions on how the authors might address this issue or what alternative approach to take. Without actionable advice or detailed feedback, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for simplification but does not provide enough detail to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB) and suggests that the authors should clarify the criteria behind this selection. It also implies that other tasks or datasets might provide different insights, which could be valuable information for the authors to consider. However, the comment does not explicitly instruct the authors to provide this clarification or explore other tasks or datasets. The action is implicit and somewhat vague, as the authors need to infer that they should address the generalizability concern and explore additional benchmarks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB), which is a specific part of the paper. This provides full grounding, as the authors can accurately identify the section being addressed. The comment also specifies the issue by questioning the generalizability of the evaluation and suggesting that the authors clarify the criteria behind the selection and explore other tasks or datasets for different insights. This level of detail makes the comment specific, as it clearly outlines what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and explore other tasks or datasets for different insights. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about generalizability. The suggestion to explore other tasks or datasets is a logical extension of the concern, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and explore other tasks or datasets for different insights. This feedback is constructive as it prompts the authors to consider the broader implications of their evaluation choices and encourages them to expand their analysis. However, the comment could be more helpful if it provided specific suggestions or examples of alternative tasks or datasets that could be considered. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a lack of detail in the experimental description, suggesting that providing more clarity would greatly benefit the reader's understanding and judgment of the results. It also directs the authors to the 'Questions' section for further details. While the comment explicitly states the need for increased clarity and provides a reference to additional information, it does not offer specific guidance on what aspects of the experimental description need more detail or how to improve them. The action is implicit but concrete, as the authors know what needs to be done but may need to infer the exact details. Therefore, this comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment highlights a lack of detail in the experimental description, suggesting that providing more clarity would benefit the reader's understanding and judgment of the results. However, it does not specify which part of the manuscript lacks detail, making it weakly grounded. The comment is specific in its suggestion to increase clarity and provides a reference to the 'Questions' section for further details, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the experimental description lacks detail, making it difficult for the reader to judge the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to sections or aspects of the experimental description that are lacking detail, making it difficult for the authors to address the issue effectively. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the manuscript, noting that the experimental description lacks detail, which makes it difficult for the reader to judge the results. It provides a clear and actionable suggestion to increase clarity in the experimental description, which would significantly benefit the manuscript. However, the comment could be more helpful if it offered specific examples or guidance on what aspects of the experimental description need more detail. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper is not self-contained and requires the supplementary material to understand certain parts of the main paper. It also emphasizes the importance of reproducibility and requests the authors to release their source code. While the comment explicitly states the need for the supplementary material and the release of source code, it does not provide specific guidance on how to improve the self-containment of the paper or how to structure the supplementary material. The request for source code release is clear, but the comment lacks detailed instructions on how to achieve this. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights that the paper is not self-contained and requires the supplementary material to understand certain parts of the main paper. It also requests the release of the source code to allow for reproducibility. However, the comment does not specify which parts of the paper are not self-contained or what specific sections require additional information. This lack of specificity makes it difficult for the authors to pinpoint the exact areas needing improvement. The request for source code release is clear, but without specific guidance on how to improve self-containment, the comment is weakly grounded and not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not self-contained and requires the supplementary material to understand large parts of the main paper. It also requests the release of the source code to allow for reproducibility. However, the comment does not provide specific examples or detailed reasoning to support why the paper is not self-contained or why the supplementary material is necessary. The request for source code release is a clear suggestion but lacks detailed justification. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's self-containment, noting that the main paper is not comprehensive enough to be understood without the supplementary material. This highlights a critical aspect that the authors need to address to ensure their work is accessible and reproducible. Additionally, the comment requests the release of the source code, which is a clear and actionable suggestion for improving the reproducibility of the results. While the comment provides valuable feedback on the need for self-containment and reproducibility, it could be more helpful if it offered specific suggestions on how to enhance the main paper's self-containment or how to structure the supplementary material. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear request for additional resources.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly instruct the authors to include this rationale. The comment is explicit in its suggestion but vague on how to implement it, as it does not specify the exact details or context of the comparison. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks concrete guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly mention which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not specify the exact section or part of the paper being addressed. The comment is specific in its suggestion to provide a rationale for the choice of algorithms, but it is not fully grounded due to the lack of explicit reference to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not provide specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not specify the exact reasons or context. While the comment identifies a potential area for improvement, it lacks depth and specificity, leaving the authors with a general suggestion rather than actionable guidance. The feedback is somewhat helpful as it points out a potential gap in the paper's explanation, but it could be more beneficial with additional details or examples. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of a discussion about the Set Transformer (https://arxiv.org/abs/1810.00825) and other related works that use summary tokens. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this omission. The comment suggests that the authors should include a discussion of these related works, but it does not specify which aspects of the discussion should be included or how to integrate this information into the paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of a discussion about the Set Transformer (https://arxiv.org/abs/1810.00825) and other related works that use summary tokens. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need for a discussion on related works, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide specific examples or references to these works, nor does it explain why this omission is problematic or how it affects the paper\\'s contribution. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the absence of a discussion about the Set Transformer and other related works that use summary tokens. This is a valuable observation as it highlights a potential gap in the paper\\'s analysis and context. However, the comment does not provide specific suggestions or guidance on how the authors might address this omission, such as recommending which related works to include or how to integrate this discussion into the paper. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but does not fully support the authors in implementing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue regarding the methodology, specifically questioning the details of how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific details need to be included. The comment lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the methodology or experimental setup, the lack of explicit grounding makes it challenging to address the comment effectively. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the methodology of the paper, specifically asking for details on how the network is trained to fit the residual instead of directly learning the input-output mapping. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the input-output mapping. This feedback is somewhat helpful as it highlights a potential gap in the paper's methodology that the authors should address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve this aspect of their work. Without additional context or detailed advice, the authors may find it challenging to fully address the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification about the experiment setup in Section 3.3, specifically regarding data augmentation methods, learning rate, and other relevant details. While the comment identifies a specific area that needs clarification, it does not provide explicit instructions on how to address this issue. The authors are left to infer that they need to provide more detailed information about the experimental setup, but the comment lacks concrete guidance on what specific details should be included. Therefore, the comment is somewhat actionable, as it highlights a need for clarification but does not provide explicit instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests clarification on the experiment setup, including data augmentation methods, learning rate, and other relevant details. The comment provides a clear reference to the section and specifies what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the experiment setup in Section 3.3, specifically asking for clarification on data augmentation methods, learning rate, and other details. The comment provides a reference to a specific paper, \"BadNets: Evaluating Backdooring Attacks on Deep Neural Networks,\" which suggests that the authors should include more detailed information about their experimental setup. However, the comment does not provide specific examples or detailed reasoning to support why this information is necessary or how it would improve the paper. While the reference to \"BadNets\" provides some context, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific question about the experiment setup in Section 3.3, asking for clarification on details such as data augmentation methods, learning rate, and other relevant aspects. While the comment identifies a gap in the paper's transparency, it does not provide detailed guidance or suggestions on how to improve the clarity or completeness of the experimental setup. The authors are left to infer that they need to provide more detailed information, but the comment lacks actionable advice or specific examples. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully guide the authors in making the necessary changes.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the closeness of the numbers when comparing the proposed method with baselines and suggests that the authors might have performed a statistical significance test. However, the comment does not explicitly instruct the authors to conduct a statistical significance test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform a statistical significance test but are not given specific instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, it does not specify which part of the paper this comparison is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to perform a statistical significance test, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that a statistical significance test is necessary. Without further elaboration or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. This feedback is somewhat helpful as it points out a potential issue that could affect the interpretation of the results. However, the comment lacks specificity and does not provide guidance on how the authors might conduct a statistical significance test or what specific results might be affected. To be more helpful, the comment could include suggestions on how to perform the test or what specific results might be affected by the closeness of the numbers. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks detailed guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the choice of testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signed ranked test, to compare samples generated from the same input. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to make this change. The action is somewhat implicit, as the authors can infer that they should explore the use of a paired test setting, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the choice of testing and suggests using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where the testing is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting a change in the testing approach, but without grounding, it is difficult for the authors to know where to make these changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the choice of testing might be incorrect and proposes using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. However, the comment does not provide specific reasoning or evidence to support why the current choice of testing is incorrect or why the proposed test setting is more appropriate. The suggestion lacks detailed justification or examples, making it difficult for the authors to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the choice of testing and suggests using a paired test setting, such as the Wilcoxon signed ranked test, for comparison. This feedback is somewhat helpful as it points out a specific area for improvement in the methodology section of the paper. However, the comment lacks depth and does not provide detailed guidance on why the current choice of testing might be incorrect or how the proposed test setting would address this issue. To be more helpful, the comment could include a rationale for why the current choice is problematic and how the proposed test setting would enhance the analysis. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While the comment implies that these actions should be taken, it does not specify which sections or parts of the paper need particular attention or how the authors should structure this information. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. However, it does not specify which sections or parts of the paper need these improvements, making it difficult for the authors to identify the exact areas that require attention. The lack of specific guidance on where to make these changes makes the comment weakly grounded. Additionally, the comment lacks specificity in terms of what exactly needs to be addressed in terms of background knowledge or related literature. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. However, the comment does not provide specific examples or detailed reasoning to support why these changes are necessary or how they would enhance the paper. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and moving the description of related literature forward. While this feedback identifies areas for improvement, it lacks specificity and does not provide detailed guidance on how to enhance the organization or what specific aspects of the background knowledge or related literature should be emphasized. Without actionable suggestions or examples, the authors may find it challenging to effectively address the feedback. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While the comment identifies a gap in the comparison, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they should include these models in their comparison, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the related work section. Without explicit references to specific sections or elements, the authors may find it challenging to pinpoint where the comparison is lacking. Additionally, the comment lacks specificity regarding what aspects of these models should be compared or how they should be integrated into the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is valuable as it highlights an area where the authors could enhance the comprehensiveness of their work by including these models in their comparison. However, the comment lacks specific guidance on how to integrate these models or what aspects of their performance should be evaluated. While it provides a clear direction for improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds, specifically mentioning the difference between sqrt(beta) and beta^{1/3}. It also notes that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback. However, the comment does not provide explicit guidance on how the authors should address this gap or improve their results. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a gap between the lower and upper bounds, specifically mentioning the difference between sqrt(beta) and beta^{1/3}. It also notes that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific in detailing the issue with the bounds and the potential improvement with the independence number, it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a gap between the lower and upper bounds, specifically mentioning the difference between sqrt(beta) and beta^{1/3}. It also suggests that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific gap in the paper's analysis, comparing the lower and upper bounds of a certain expression. It highlights that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback. However, the comment lacks detailed guidance on how the authors should address this issue or improve their results. While it points out a potential area for enhancement, it does not provide actionable steps or suggestions for the authors to take. As a result, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in improving their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not provide explicit guidance on how to incorporate these results or what specific tasks to include. The action is implicit and somewhat vague, as the authors can infer the need for additional results but lack detailed instructions on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include results in other modalities and discusses the relevance of OOD performance for language tasks, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not provide specific examples or references to support the claim that OOD performance is more relevant for language tasks. The comment lacks detailed reasoning or evidence to fully substantiate the suggestion, making it somewhat verifiable. The authors would need to infer the relevance of OOD performance in language tasks, which adds to the ambiguity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests expanding the results section to include experiments in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. This feedback is somewhat helpful as it provides a direction for the authors to consider additional experiments that could enhance the comprehensiveness of their results. However, the comment lacks specific guidance on which language-related tasks to include or how to measure OOD performance, which limits its usefulness. The authors would need to infer these details on their own, making the comment somewhat helpful but incomplete. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the recent related work CoCoOp [1] should be compared in the experiments. It provides a clear and direct action for the authors to take, which is to include CoCoOp in their experiments. This feedback is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"the recent related work CoCoOp [1] is not compared in the experiments,\" which provides full grounding as it clearly identifies the specific part of the paper being addressed\u2014the experiments. It also specifies what needs to be addressed by suggesting that the authors should compare their work with CoCoOp, a recent related work. This level of detail and specificity allows the authors to accurately understand the feedback and make the necessary adjustments. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the recent related work CoCoOp [1] should be compared in the experiments. The reviewer provides a specific reference to CoCoOp, which is a CVPR\\'22 work that is the extended version of CoOp. This provides a clear and specific basis for the claim, making it fully verifiable. The reviewer supports the claim by referencing a specific work and its relevance to the current study, which is a strong piece of evidence. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by noting that the recent related work CoCoOp [1] is not compared in the experiments, despite being a CVPR\\'22 work that is the extended version of CoOp. The reviewer suggests that it is necessary to include CoCoOp in the experiments to provide a comprehensive comparison. This feedback is clear and actionable, as it directs the authors to a specific area where their work can be improved by adding a relevant comparison. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate CoCoOp into the experiments. Overall, the comment is mostly helpful as it highlights a significant omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the author has only conducted experiments on two typical games and questions the performance of ReBeL on more complex problems, particularly those with larger depths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting additional experiments or methods to evaluate ReBeL on more complex problems. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically questioning the limited scope of the experiments conducted on two typical games and the potential performance of ReBeL on more complex problems with larger depths. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in detailing the issue with the limited scope of experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the scope of the experiments conducted, specifically mentioning that the author only tested ReBeL on two typical games and raises concerns about its performance on more complex problems with larger depths. However, the comment lacks specific examples or references to support the claim that the experiments are insufficient or that the performance on complex problems is a significant issue. Without detailed reasoning or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the experimental scope of the paper, specifically questioning the limited number of games tested and the implications for evaluating ReBeL's performance on more complex problems with larger depths. This feedback highlights an important area for improvement, as it suggests that the authors should consider expanding their experiments to include a broader range of complex games. However, the comment lacks specific guidance or suggestions on how to address this issue, such as recommending additional games or methodologies to explore. While it points out a critical area for enhancement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a missing aspect in the paper, specifically the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a discussion on the theoretical guarantee, but the comment lacks concrete details on what specific aspects should be covered or how to structure this discussion. Therefore, the comment is somewhat actionable, as it highlights a necessary addition but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific area of the paper that lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the missing theoretical guarantee, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a factual statement that does not require verification, as it is a matter of fact that the paper does not include such a discussion. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a valuable observation that highlights a potential weakness in the paper\\'s theoretical foundation. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the theoretical guarantee should be discussed. While it points out an important omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but does not fully support the authors in implementing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of quantitative measures to evaluate the generated VCEs, noting that the evaluation is primarily based on visual inspection. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to introduce quantitative measures or suggest specific metrics to use. The action is implicit, as the authors can infer that they need to incorporate quantitative evaluation methods, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a general issue with the evaluation of the generated VCEs, noting that it is primarily based on visual inspection. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure where the evaluation is discussed. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in pointing out the need for quantitative measures, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of the generated VCEs is primarily based on visual inspection, lacking quantitative measures. This claim is somewhat verifiable as it highlights a potential issue with the evaluation process. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the evaluation process, specifically noting the lack of quantitative measures to assess the generated VCEs. It highlights that the evaluation is primarily based on visual inspection, which may not provide a comprehensive understanding of the results. This feedback is clear and actionable, as it directs the authors to consider incorporating quantitative measures to enhance the evaluation process. However, the comment could be more helpful if it suggested specific quantitative measures or metrics that could be used. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the generated videos, noting significant artifacts and a below-average action recognition performance compared to the state-of-the-art on the UCF dataset. It also mentions the use of more complex architectures in the state-of-the-art methods. However, the comment does not provide specific guidance or suggestions on how to address these issues or improve the performance. The authors are left without clear actions to take, such as identifying the root cause of the artifacts or proposing ways to enhance the action recognition performance. As a result, the comment lacks actionable content, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of significant artifacts in the generated videos and the below-average action recognition performance compared to the state-of-the-art on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the problem areas, such as the artifacts and the performance gap, but lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the state-of-the-art on the UCF dataset. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment highlights a significant issue with the generated videos, noting that they have significant artifacts and that only some of the beach videos are convincing. It also points out that the action recognition performance is below the state-of-the-art on the UCF dataset, which uses more complex architectures. However, the comment lacks specific suggestions or guidance on how to address these issues or improve the performance. While it identifies a critical area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a significant problem but does not offer detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to clarify the connection between the term and the referenced work. As a result, the authors are left without a clear understanding of what action to take in response to this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it relates to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the work need further explanation. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it highlights a potential issue but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the experiments, noting that they are limited to MNIST and a single real-world dataset. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might expand their experiments to address this limitation or what specific datasets they should consider. Without actionable suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation of the experiments, noting that they are limited to MNIST and a single real-world dataset. However, it does not specify which part of the paper discusses the experiments or where this limitation is most apparent. The authors might infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in identifying the limitation of the dataset used in the experiments, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to MNIST and a single real-world dataset, suggesting that the authors should consider expanding their experiments to include more datasets. However, the comment does not provide any specific reasoning or evidence to support why this limitation is problematic or how it might impact the validity or generalizability of the results. Without additional context or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides a claim but lacks sufficient justification or evidence to fully support it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the experiments, noting that they are limited to MNIST and a single real-world dataset. This feedback is somewhat helpful as it points out a potential area for improvement, suggesting that the authors should consider expanding their experiments to include more datasets. However, the comment lacks specific guidance on which additional datasets might be relevant or how the authors could address this limitation. To be more helpful, the comment could provide suggestions on how to select or include other datasets or what specific aspects of the experiments could be expanded. Overall, the feedback is somewhat helpful as it highlights a potential area for improvement but does not offer detailed guidance for the authors to implement it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be helpful. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is explicit and provides a clear action for the authors to take, which is to quantify and clarify the claim. The suggestion is concrete, as it specifies what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests quantifying and clarifying a claim about ReLUs not working well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides full grounding as it explicitly mentions the AlexNet paper, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, quantifying and clarifying the claim about ReLUs. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be beneficial. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This provides a logical basis for the claim, as it references a well-known paper and its practices. However, the comment could be strengthened by including specific references or data to further substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a clear rationale but lacks detailed evidence or references to fully support the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that quantifying and clarifying the claim \"ReLU does not work very well in very deep or in convolutional networks\" would be beneficial. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and used convolution (with pooling rather than ReLUs for the convolutional layers). This feedback is clear and actionable, as it directs the authors to provide more detailed evidence or analysis to support their claim. By doing so, the authors can strengthen their argument and improve the clarity of their draft. Therefore, the comment is highly helpful, as it offers a specific and actionable suggestion for enhancing the paper\\'s quality and comprehensiveness.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more explanations regarding the consistency between training and inference, which is addressed multiple times in the paper. While the comment implies that more detailed explanations are needed, it does not explicitly instruct the authors to do so or provide specific guidance on what aspects should be elaborated upon. The action is implicit and somewhat vague, as the authors can infer that more explanations are needed but may not know exactly what to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (95-97 and 308-310) where the authors discuss the consistency between training and inference. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, which is providing more explanations on the consistency between training and inference. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should provide more explanations on the consistency between training and inference, particularly regarding the smoothness of neural models. However, the comment does not provide specific examples or references to support why this is necessary or how it could be improved. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion and how to address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more explanations on the consistency between training and inference, particularly regarding the smoothness of neural models. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that could be clarified. However, the comment could be more helpful if it provided examples or suggestions on how to enhance the explanations. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' claim of achieving superior performance with fewer parameters, specifically questioning whether the improvements are due to the smaller word embedding and LSTM sizes or if the baseline model was tested with standard parameter settings. The reviewer suggests that the authors should provide evidence of improvements when using larger word embedding and LSTM parameters. While the comment implies that the authors should conduct additional experiments to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and how to conduct them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding their model\\'s performance and parameter count, particularly the use of smaller word embedding and LSTM sizes. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in questioning the validity of the claim and suggesting a need for additional evidence, such as improvements when using larger word embedding and LSTM parameters. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the authors\\' claim of achieving superior performance with fewer parameters, specifically questioning whether the improvements are due to the smaller word embedding and LSTM sizes or if the baseline model was tested with standard parameter settings. The reviewer suggests that the authors should provide evidence of improvements when using larger word embedding and LSTM parameters. While the comment identifies a potential issue with the claim, it lacks specific examples or references to support the suggestion. The authors are left to infer the need for additional experiments, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the authors' claim of achieving superior performance with significantly fewer parameters, particularly questioning the role of smaller word embedding and LSTM sizes. It suggests that the authors should provide evidence of improvements when using larger word embedding and LSTM parameters. This feedback is clear and actionable, as it prompts the authors to conduct additional experiments to substantiate their claims. However, the comment could be more helpful if it provided specific guidance on how to design and execute these experiments or suggested alternative ways to demonstrate the model's efficiency. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear direction for further investigation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue with the hyperparameters, it does not provide explicit guidance on how to address this problem or suggest specific actions to take. The authors are left to infer that they need to consider the availability of the environment or a good OPE method for finetuning, but the comment lacks concrete steps or suggestions on how to implement this. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or how they are introduced. The authors can infer that it relates to the methodology or experimental setup, but the comment lacks explicit grounding. It is specific in identifying the need for finetuning and the potential dependencies, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of extra hyperparameters k and \u03b7 requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the introduction of extra hyperparameters k and \u03b7, which require finetuning. It highlights the dependency on the availability of the environment or a good OPE method for this finetuning. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. While it points out a potential weakness, it does not provide actionable steps or detailed feedback that could help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It identifies specific errors in the text, such as correcting the letter \"f\" to \"g\" in line 108 and removing the extra period in line 115. Additionally, it raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question implies that the authors should provide more details or evidence to support their claim of convergence. The feedback is clear and actionable, giving the authors specific steps to address the identified errors and a question to consider regarding their baseline method. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper (line 108 and line 115), allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as correcting the letter \"f\" to \"g\" and removing the extra period, providing clear guidance on what needs to be revised. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured convergence of the networks. This question adds specificity to the feedback, as it prompts the authors to provide additional details or evidence regarding their baseline method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of three parts: a correction of a typographical error, a suggestion to remove an extra period, and a question about the convergence of the baseline MCL with deep learning. The first two parts are factual statements that do not require verification. The third part is a question seeking clarification, which does not contain a claim that needs verification. Therefore, the overall comment is comprised of factual statements and a question, making it \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by identifying two typographical errors in the manuscript: the correction of a letter \"f\" to \"g\" in line 108 and the removal of an extra period in line 115. These corrections are clear and would improve the clarity and professionalism of the paper. Additionally, the comment raises a question about the baseline MCL with deep learning, asking how the authors ensured that each network converged to reasonable results. This question prompts the authors to provide more detailed information or evidence regarding the convergence of their baseline method, which is a valuable point for improvement. Overall, the comment is mostly helpful as it offers clear corrections and a thought-provoking question that can guide the authors in enhancing their draft. However, it could be more helpful if it provided additional guidance or suggestions on how to address the question about convergence. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the reliance of FedPCL on the selection of pre-trained models, which limits its applications. It also notes that the model accuracy is sensitive to these models. However, the comment does not provide specific guidance or suggestions on how the authors might address this limitation or improve the applicability of their framework. While it acknowledges the authors\\' efforts to develop a lightweight federated learning framework and integrate pre-trained models, it lacks actionable advice on how to enhance the framework or expand its applicability. As a result, the authors are left without clear direction on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the reliance of FedPCL on the selection of pre-trained models, which limits its applications. It also mentions the sensitivity of model accuracy to these models, as illustrated in Table 4. The comment highlights the authors\\' efforts to develop a lightweight federated learning framework and integrate pre-trained models for federated aggregation. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or table. While the authors can infer that it relates to the discussion of pre-trained models and their impact on performance, the comment lacks explicit grounding. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the performance of FedPCL is heavily reliant on the selection of pre-trained models, limiting its applications to more widespread areas. It also notes that the model accuracy is sensitive to the pre-trained models, as shown in Table 4. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The mention of the authors\\' efforts to develop a lightweight federated learning framework and integrate pre-trained models is a positive aspect, but it does not substantiate the initial claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges the reliance of FedPCL on the selection of pre-trained models, which limits its applicability. It also notes that the model accuracy is sensitive to these models, as illustrated in Table 4. The comment highlights the authors' efforts to develop a lightweight federated learning framework to reduce computation and communication costs and integrate pre-trained models for federated aggregation. However, the comment lacks specific suggestions or actionable advice on how the authors might address the limitations or expand the applicability of their framework. While it provides some insight into the challenges faced, it does not offer detailed guidance on how to improve the draft, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to include the tentative attention maps in the qualitative figures, in addition to the retrieved and final attentions. While the comment implies that the authors should consider including these maps, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to include the tentative attention maps, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including tentative attention maps in the qualitative figures, which is a specific request for additional content. However, it does not specify which figures or sections of the paper should include these maps, making it weakly grounded. The comment is specific in its request for additional content, but without explicit references to sections, it is challenging for the authors to pinpoint where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to include tentative attention maps in the qualitative figures, but it does not provide any justification or reasoning for why this would be beneficial or necessary. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include tentative attention maps in the qualitative figures, in addition to the retrieved and final attentions. This feedback is specific and actionable, as it provides a clear direction for enhancing the qualitative figures to better illustrate the attention mechanisms used in the study. By including tentative attention maps, the authors could offer a more comprehensive understanding of the attention process, which could be valuable for readers and reviewers. However, the comment could be more helpful if it provided examples of how these maps could be incorporated or discussed in the figures. Overall, the comment is mostly helpful as it identifies a specific area for improvement and offers a clear suggestion, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address the issue or what specific changes need to be made. The comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that either the reviewer does not understand the figure or that the labels are incorrect. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a statement that either the reviewer does not understand Figure 5 or that the labels are incorrect. It does not contain any claims, opinions, or suggestions that require verification. The comment is purely descriptive and factual, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 5, either stating that the reviewer does not understand it or that the labels are incorrect. This feedback is clear and actionable, as it highlights a potential area of confusion or error that the authors need to address. However, the comment does not provide any suggestions or guidance on how to resolve the issue or improve the figure. While it points out a critical area for attention, it lacks depth and specificity, making it somewhat helpful. The authors are given a starting point for improvement but need additional guidance to fully address the feedback. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their work. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper this critique pertains to, such as a specific section or equation. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the derivation\\'s reliance on classical learning theory-based bounds, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. This feedback highlights a potential limitation in the authors\\' approach and suggests that incorporating Bayesian considerations could improve the validity of their bounds. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their work. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of weight decay, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their results. The comment lacks concrete suggestions or actions for the authors to take, making it unactionable. The authors are left without a clear understanding of how to address the identified problem, leaving them without a path forward for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with weight decay and the observation that cosine similarities for large weight decay strengths are not reported. However, it lacks explicit references to specific sections or figures, which could help the authors pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the application of weight decay to all layers might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, the comment lacks specific evidence, examples, or references to support this claim. The reviewer mentions that cosine similarities for large weight decay strengths are not reported, but this observation does not provide a logical or empirical basis for the claim. Without additional justification or references, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. The comment points out that cosine similarities for such large weight decay strengths are not reported, and the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is somewhat helpful as it highlights a specific area where the authors might need to investigate further or provide additional analysis. However, the comment lacks detailed guidance on how the authors should address this issue or what specific steps they should take to improve their results. While it provides a starting point for the authors to consider, it does not fully support them in making actionable improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential issue with the application of weight decay, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their results. The comment lacks concrete suggestions or actions for the authors to take, making it unactionable. The authors are left without a clear understanding of how to address the identified problem, leaving them without a path forward for improvement.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential issue with weight decay and the observation that cosine similarities for large weight decay strengths are not reported. However, it lacks explicit references to specific sections or figures, which could help the authors pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the application of weight decay to all layers might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, the comment lacks specific evidence, examples, or references to support this claim. The reviewer mentions that cosine similarities for large weight decay strengths are not reported, but this observation does not provide a logical or empirical basis for the claim. Without additional justification or references, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the application of weight decay"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. It suggests that this issue must be fixed for publication. The reviewer acknowledges that they did not have time to review the supplementary material due to the constraints of the review process, but emphasizes the importance of addressing this issue. The comment provides a clear and direct action for the authors to take, which is to ensure that the title, abstract, introduction, and discussion accurately reflect the unsupervised nature of the random forests results. This guidance is explicit and concrete, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of explanation regarding the unsupervised nature of the random forests results. The comment further emphasizes the importance of addressing this issue for publication and provides a rationale for why it is a serious omission. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the title, abstract, introduction, and discussion do not explain that the results are for unsupervised random forests, which is a serious omission. The reviewer provides a rationale for why this is important, stating that casual readers might remember the wrong conclusions if this information is not included. The comment also mentions that the reviewer did not have time to review the supplementary material due to the constraints of the review process, which adds context to the concern. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the omission and its potential impact on readers. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the title, abstract, introduction, and discussion sections of the paper, specifically noting that they do not explain that the results are for unsupervised random forests. This is a critical omission that could lead to misinterpretation by readers. The reviewer emphasizes the importance of addressing this issue for publication, as it could affect the credibility of the results. While the comment highlights a clear area for improvement, it does not provide specific guidance on how to correct this issue or suggest ways to enhance the explanation. The feedback is somewhat helpful as it points out a critical oversight but lacks detailed suggestions for improvement, leaving the authors with a general understanding of what needs to be addressed but without actionable steps.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. While the comment implies that additional evidence or analysis should be provided, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to include more supporting evidence, but it lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. The authors can infer that it relates to the dataset description or experimental results, but this inference is not explicit. The comment is specific in its request for more evidence and analysis, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, the comment does not provide specific examples, references, or detailed reasoning to justify why this is necessary or how it would enhance the paper. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by including additional supporting evidence or analysis. However, the comment could be more helpful if it offered suggestions on how to gather or present this evidence, such as which specific aspects to focus on or what types of analysis would be beneficial. Overall, the comment is mostly helpful as it guides the authors towards improving their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\\'s performance, suggesting that the fine-tuning without early-stopping may lead to high variances. It implies that proper ablation studies are needed to verify the distillation effect. While the comment identifies a potential issue and suggests a course of action, it does not explicitly instruct the authors to conduct specific ablation studies or provide detailed guidance on how to perform them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the potential regularization effects influencing the improvements observed in the teacher\\'s performance. It explicitly mentions the case where the student distills knowledge to the teacher, which is a clear reference to a specific part of the paper. The comment also specifies the issue by questioning the validity of the distillation claim due to the lack of early-stopping and the potential for high variances in fine-tuning on GLUE without validation. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\\'s performance, suggesting that the fine-tuning without early-stopping may lead to high variances. The reviewer provides a logical reasoning by pointing out that the fine-tuning on GLUE without validation early-stopping usually has very high variances. However, the comment lacks specific examples or references to support the claim that the improvements are solely due to regularization effects rather than distillation. This makes the claim somewhat verifiable, as it provides a logical basis but requires further evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the interpretation of the results, suggesting that the improvements in the teacher\\'s performance could be due to regularization effects rather than distillation. It points out that the fine-tuning is performed for 10 epochs without early-stopping, which could lead to high variances. The comment implies that proper ablation studies are needed to verify the distillation effect. While the comment highlights a critical area for further investigation, it does not provide specific guidance or suggestions on how to conduct these ablation studies or what aspects to focus on. This limits the comment\\'s helpfulness, as it offers a valuable insight but lacks detailed actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions. The first question asks about the utility of node importance in the 1-shot scenario, which is a specific and concrete action for the authors to address. The second question points out the absence of the 1-shot setting in the experiments, suggesting that the authors should include this setting in their experiments. Both questions provide clear and concrete actions for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises two specific questions about the paper. The first question addresses the utility of node importance in the 1-shot scenario, which is a direct and concrete issue that the authors can address by providing clarification or evidence. The second question points out the absence of the 1-shot setting in the experiments, which is also a specific issue that the authors can address by including this setting. The comment is fully grounded as it explicitly mentions the sections or aspects being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions that seek clarification or explanation. The first question asks about the utility of node importance in the 1-shot scenario, which is a request for further explanation rather than a claim. The second question questions the absence of the 1-shot setting in the experiments, suggesting that related works like RALE include this setting. This is also a request for clarification rather than a claim. Therefore, the comment does not contain claims that require verification, aligning with a \"No\" label.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions that are relevant to the paper\\'s methodology and experimental design. The first question seeks clarification on how node importance is utilized in the 1-shot scenario, which is a critical aspect of the paper\\'s approach. The second question points out the absence of the 1-shot setting in the experiments, noting that related works like RALE include this setting. This feedback is actionable as it prompts the authors to address these gaps in their paper, providing clear directions for improvement. However, the comment could be more helpful if it offered suggestions on how to incorporate these elements or if it provided additional context or references to support the questions. Overall, the comment is mostly helpful, as it identifies areas for improvement and provides a basis for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the formula, specifically mentioning the $\\ell_{BCE}$ formula. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the formula $\\ell_{BCE}$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing more details about the formula. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more details about the formula, specifically $\\ell_{BCE}$. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improvement by recommending that the authors provide more details about the formula, specifically $\\ell_{BCE}$. This feedback is specific and directly addresses a potential weakness in the paper, offering a concrete step for the authors to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional guidance on what specific details should be included or how this could impact the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors toward a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more discussions on why large language models (LLMs) struggle with fine-grained hard constraints and how to address these issues. While the comment implies that additional discussions are needed, it does not specify which sections of the paper should include these discussions or how they should be structured. The action is implicit and somewhat vague, as the authors need to infer that they should add more detailed explanations and potential solutions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there should be more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to address the issue of LLMs struggling with fine-grained hard constraints, but it lacks grounding as it does not reference specific sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussions about why large language models (LLMs) struggle with fine-grained hard constraints and how to address these problems. However, the comment does not provide any specific examples, references, or reasoning to support why these discussions are necessary or how they would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more discussions on why large language models (LLMs) struggle with fine-grained hard constraints and how to address these problems. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by offering additional context and potential solutions. However, the comment lacks depth and does not provide specific examples or suggestions on how to address the issue, leaving the authors with a general direction but no detailed guidance. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of self-supervised learning on 360 video data with spatial audio. It implies that the authors should provide more insights into why this approach is valuable. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that more explanation is required but are not given concrete steps on how to address this. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and questions the necessity of self-supervised learning on 360 video data with spatial audio. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing attention. The comment is specific in questioning the need for self-supervised learning on this type of data, but without grounding, it is weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of self-supervised learning on 360 video data with spatial audio, suggesting that more insights are needed. However, the comment does not provide specific examples, references, or detailed reasoning to support why this approach is valuable or necessary. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of explanation regarding the necessity of self-supervised learning on 360 video data with spatial audio. It questions why this approach is valuable and suggests that more insights are needed. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of insights are required. While it identifies a gap in the paper, it lacks actionable feedback, making it somewhat helpful. The authors are given a direction to consider but are not provided with detailed steps or examples to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while the paper covers the SimCLR case, it lacks an analysis of the projection head, which is considered an important aspect of the approach (as evidenced by SimCLR-v2 and other recent papers). However, the comment does not provide explicit guidance on how the authors should address this omission. It suggests that the authors should include an analysis of the projection head, but it does not specify how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion of the projection head, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of analysis on the projection head, a component that is considered important based on recent papers like SimCLR-v2. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an analysis of the projection head, which is considered an important aspect of the SimCLR approach. However, the comment does not provide specific references or examples of recent papers that emphasize the importance of the projection head, nor does it explain why this omission is significant. Without detailed justification or examples, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper\\'s analysis by pointing out that while the SimCLR case is covered, there is no analysis of the projection head, which is considered an important aspect of the approach (as evidenced by SimCLR-v2 and other recent papers). This feedback is clear and actionable, as it directs the authors to include an analysis of the projection head, which could significantly enhance the paper\\'s comprehensiveness and relevance. However, the comment could be more helpful if it provided additional context or suggestions on how to approach the analysis of the projection head. Overall, the comment is mostly helpful as it highlights a critical omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies several approximations introduced by the authors and points out the need to expand the discussion on possible vulnerabilities, such as the assumption of attacks being in the feasible set only in lines 107-110. While the comment implies that the authors should address these vulnerabilities to reassure readers, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on vulnerabilities. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the approximations introduced in the paper, specifically mentioning points i, ii, and iii. It also highlights the need to expand the discussion on possible vulnerabilities, such as the assumption of attacks being in the feasible set only in lines 107-110. While the comment does not explicitly mention the specific sections or lines where these approximations are discussed, the authors can infer that it pertains to the relevant parts of the paper. The comment is specific in detailing what needs to be addressed regarding the approximations and vulnerabilities, providing clear guidance on how to improve the paper. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the approximations introduced in the paper leave loose ends and that the possible vulnerabilities need to be expanded to reassure readers. The comment provides a logical reasoning by acknowledging the necessity of approximations to derive clean results but suggesting that the authors should expand their discussion on vulnerabilities to address potential concerns. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact vulnerabilities being discussed, which could be challenging without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approximations introduced in the paper, noting that they leave loose ends and potentially introduce vulnerabilities. It acknowledges the necessity of approximations to derive clean results but suggests that the authors should expand their discussion on possible vulnerabilities to address readers\\' concerns. This feedback is clear and actionable, as it provides a specific area for improvement and guidance on how to enhance the paper\\'s clarity and robustness. However, the comment could be more helpful if it offered suggestions on how to expand the discussion on vulnerabilities or provided examples of how to address them. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies several approximations in the paper and points out the need to expand the discussion on possible vulnerabilities, such as the assumption of attacks being in the feasible set only in lines 107-110. While the comment implies that the authors should address these vulnerabilities to reassure readers, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on vulnerabilities. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the approximations introduced in the paper and points out the need to expand the discussion on possible vulnerabilities, such as the assumption of attacks being in the feasible set only in lines 107-110. While the comment does not explicitly mention the specific sections or lines where these approximations are discussed, the authors can infer that it pertains to the relevant parts of the paper. The comment is specific in detailing what needs to be addressed regarding the approximations and vulnerabilities, providing clear guidance on how to improve the paper. Therefore, this comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the approximations introduced in the paper leave loose ends and that the possible vulnerabilities, such as the assumption of attacks being in the feasible set only in lines 107-110, need to be expanded to reassure readers. The comment acknowledges the necessity of approximations to derive clean results but suggests that the authors should provide a more comprehensive discussion on vulnerabilities. While the comment provides a logical reasoning for the need to expand the discussion, it lacks specific examples or references to support the claim. This makes the comment somewhat verifiable, as the authors would need to infer the exact vulnerabilities being discussed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approximations introduced in the paper, noting that they leave loose ends and potentially introduce vulnerabilities. It acknowledges the necessity of approximations"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It suggests that the comparison is unfair because it requires two representation models learned for each dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their experimental setup. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the extra complexity and cost of their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method does not have an advantage without prior information and that the comparison is unfair due to the extra complexity and cost involved. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method does not have an advantage over the SOTA without prior information, and that the comparison is unfair because it requires two representation models learned for each dataset. The reviewer provides a logical reasoning by explaining that the proposed method's advantage is only observed when using prior knowledge, which adds complexity and cost. However, the comment lacks specific examples or references to support the claim about the unfairness of the comparison. While the reasoning is sound, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It highlights that the comparison is unfair because it requires two representation models learned for each dataset, which adds complexity and cost. This feedback is clear and actionable, as it points out a specific weakness in the experimental setup that the authors should consider. By addressing this issue, the authors can improve the fairness and robustness of their comparison. However, the comment could be more helpful if it provided suggestions on how to mitigate the complexity or cost, such as proposing alternative methods or datasets. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the proposed model, stating that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or suggestions for potential solutions. Without any actionable advice or direction, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the proposed model, stating that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, it does not specify which part of the paper discusses this limitation or provides details on how the authors might address it. The authors can infer that it relates to the methodology or results sections, but the lack of explicit grounding makes it difficult to pinpoint the exact location. The comment is specific in identifying the issue but lacks grounding, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific limitation of the proposed model, noting that it can only be used with a small number of dimensions due to the curse of dimensionality imposed by the core tensor C. This feedback is somewhat helpful as it highlights an important consideration for the authors to address in their work. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might overcome this limitation or explore alternative approaches. To be more helpful, the comment could include potential solutions or references to related work that might address this issue. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for the authors but does not fully support their efforts to improve the draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It highlights that Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a general-purpose neural network model. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their model. The action is implicit and vague, as the authors are left to infer that they need to investigate and possibly modify their approach to address the negative transfer. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It highlights that Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a general-purpose neural network model. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not explicit. The comment is specific in detailing the contradiction between the model\\'s performance and its claimed general-purpose nature. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It highlights that Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a general-purpose neural network model. The comment provides a specific example of poor performance on downstream tasks, which supports the claim. However, it lacks detailed reasoning or references to substantiate the claim further. The authors are left to infer the significance of this observation, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It highlights that Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a general-purpose neural network model. This feedback is somewhat helpful as it identifies a specific issue with the model's general-purpose nature and provides a concrete example of poor performance on downstream tasks. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or improve the model's general-purpose capabilities. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses dissatisfaction with the theoretical contribution, stating that it is weak and unpractical. It also mentions that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their theoretical contribution. There is no guidance on how to strengthen the theoretical aspect or what specific elements need to be addressed. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical contribution, specifically mentioning that it is weak and unpractical, and lacks mathematical novelty. However, it does not specify which part of the paper this theoretical contribution is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment provides some level of specificity in terms of the issues identified, it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical contribution is weak and unpractical, and that the proof lacks mathematical novelty. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses dissatisfaction with the theoretical contribution, stating that it is weak and unpractical, and lacks mathematical novelty. While it identifies a specific area for improvement, the comment lacks actionable feedback or suggestions on how to strengthen the theoretical contribution. It does not provide any guidance on what aspects of the theoretical framework could be improved or how the authors might address these issues. As a result, the comment is not helpful, as it does not offer the authors a clear path to enhance their draft. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to make this clarification. The action is implicit and somewhat vague, as the authors need to infer the exact action to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L240\" and \"L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification regarding the meaning of \"is sufficient\" and the authors\\' intention to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how to address this issue. The comment lacks depth and actionable advice, leaving the authors with a vague understanding of what needs to be improved. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant difference between the proposed method and a previous work, [10], in terms of computation time and search space. It suggests that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the performance of their method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific comparison between the proposed method and a previous work, [10], regarding computation time and search space. It highlights that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. However, the comment does not specify which part of the paper this comparison is made in, making it weakly grounded. The authors can infer that it relates to the comparison section or the results, but this is not explicitly stated. The comment is specific in detailing the issue of information loss in the output, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method achieves faster computation by reducing the search space to ancestral graphs, resulting in a less informative output compared to the richer search space of DAGs. The claim is somewhat verifiable as it provides a logical reasoning for the observed difference in computation time and output information. However, the comment lacks specific references or examples to support the claim fully, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights a significant difference between the proposed method and a previous work, [10], in terms of computation time and search space. It points out that the proposed method achieves faster computation by reducing the search space to ancestral graphs, which results in a less informative output compared to the richer search space of DAGs. This observation is insightful and provides a clear comparison that the authors might consider in their work. However, the comment lacks specific suggestions or guidance on how the authors could address this issue or improve the performance of their method. While it identifies a potential weakness, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the VAD description, suggesting that the current approach of discarding TF bins with a magnitude less than epsilon is not consistent with the definition of a VAD. The reviewer points out that a VAD is typically defined over time and not frequency, and that it should be used to detect the presence of speech rather than just energy. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it. The authors are left to infer that they need to revise their VAD description to align with the correct definition, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, which is that the VAD is not being used to detect the presence of speech but rather discarding TF bins with zero magnitude, which could lead to division by zero. The comment provides a clear rationale for why this approach is not consistent with the definition of a VAD. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the VAD description, specifically questioning the approach of discarding TF bins with a magnitude less than epsilon. The reviewer suggests that this approach is not consistent with the definition of a VAD, which is typically used to detect the presence of speech and is defined over time, not frequency. The comment provides a logical reasoning based on the standard definition of a VAD, making the claim somewhat verifiable. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the VAD description, pointing out that the current approach of discarding TF bins with a magnitude less than epsilon is not consistent with the definition of a VAD. The reviewer clarifies that a VAD is typically used to detect the presence of speech and is defined over time, not frequency. This feedback is clear and actionable, as it provides the authors with a specific area to revise and align their approach with the standard definition of a VAD. However, the comment could be more helpful if it offered suggestions on how to modify the VAD description to better align with the definition. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment explicitly requests additional metrics, it does not provide specific guidance on how to calculate or present these metrics. The action is clear but lacks detailed instructions on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the training of the student and refinement networks simultaneously and questions the fairness of the comparison with the teacher network. It suggests providing KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses the training of these networks or the comparison with the teacher network, making it weakly grounded. The comment is specific in its request for KID/FID metrics, but without grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. However, the comment does not provide any specific reasoning or evidence to support why the comparison might be unfair or how the KID/FID metrics would resolve this issue. The request for metrics is a logical suggestion but lacks detailed justification or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment identifies a potential issue with the comparison, it lacks specific guidance on how to calculate or present these metrics, which could be beneficial for the authors. The feedback is somewhat helpful as it points out a potential area for improvement but could be more actionable with detailed instructions or examples.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the paper could be improved by conducting a more detailed analysis of how specific models behave differently when using ReGuide. It explicitly mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides a clear and direct action for the authors to take, as it specifies what additional analysis should be conducted and how it should be presented. The feedback is explicit and concrete, offering a clear path for improvement. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Model-Specific Insights,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a detailed analysis of how specific models behave differently when using ReGuide, including presenting differences in false positive rates (FPR) between models with and without ReGuide. This provides clear guidance on what additional analysis should be conducted to enhance the paper's conclusions. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that the paper could be improved by conducting a more detailed analysis of how specific models behave differently when using ReGuide. It provides a specific example of presenting differences in false positive rates (FPR) between models with and without ReGuide. This suggestion is based on a logical reasoning that additional analysis could add nuance to the conclusions. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the additional analysis required, which limits the level of detail and support provided. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper by suggesting that a deeper investigation into how specific models behave differently when using ReGuide could enhance the conclusions. It provides a specific example, mentioning the differences in false positive rates (FPR) between models with and without ReGuide, which could be presented for a better comparison. This feedback is clear and actionable, offering a concrete direction for the authors to improve their analysis and presentation. However, the comment could be more helpful if it provided additional guidance on how to conduct this analysis or what specific models should be considered. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to clarify the motivation. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it pertains to the evaluation or discussion of the DCI framework, but without explicit references, it remains unclear. The comment is specific in detailing the need for clarification on the motivation for considering explicitness(E) and size(S) as extra evaluations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific examples or references to support the claim that the DCI framework already considers these factors. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the traditional DCI framework, suggesting that it may already consider explicitness(E) and size(S) as evaluation factors. It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their evaluation framework. While it identifies a potential issue, it does not offer actionable steps or detailed feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider whether the types of interventions included in the paper are practical and safe for querying in the real world. While the comment implies that the authors should evaluate the practicality and safety of their interventions, it does not provide specific guidance on how to conduct this evaluation or what aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the types of interventions included in the paper, suggesting that they are reasonable computationally but questioning their practicality and safety for querying in the real world. However, it does not specify which part of the paper discusses these interventions, making it weakly grounded. The comment is specific in its suggestion to consider the practicality and safety of the interventions, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the types of interventions included in the paper are reasonable computationally but questions their practicality and safety for querying in the real world. However, the comment does not provide specific examples or reasoning to support why these interventions might be impractical or unsafe. Without additional context or evidence, the claim lacks sufficient justification, making it difficult for the authors to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks detailed support or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the practicality and safety of the interventions discussed in the paper. It suggests that while the interventions may be computationally reasonable, they should also be evaluated for their practicality and safety in real-world querying scenarios. This feedback is somewhat helpful as it points out an important aspect that the authors should consider, but it lacks specific guidance or examples on how to assess the practicality and safety of the interventions. The comment could be more helpful with additional details or suggestions on how to evaluate these aspects, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the manual disentangling process, specifically questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods for disentangling. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the manual disentangling process, particularly questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not specify which part of the paper discusses the manual disentangling process, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not precise. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or why learning disentangling would be more interesting. The suggestion is based on a subjective opinion rather than a verifiable claim, as it does not provide detailed justification or examples. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The comment highlights an interesting point but does not offer actionable advice or detailed recommendations, leaving the authors with a general direction to explore. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the connection between the theoretical analysis and the proposed method, questioning how the proposed method enhances the generalization for distant nodes. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The feedback is vague and lacks concrete steps or examples, making it difficult for the authors to know exactly what changes or clarifications are needed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the theoretical analysis and the proposed method, specifically questioning the connection between the theoretical analysis and the method. It highlights the adoption of the self-attention mechanism from the transformer and its application to the graph, and raises a concern about how the proposed method enhances generalization for distant nodes. However, the comment does not specify which part of the paper this analysis is found in, making it weakly grounded. The authors can infer that it relates to the theoretical analysis and the proposed method, but without explicit references, it remains challenging to pinpoint the exact sections. The comment is specific in detailing the issue with the connection between theory and method, as well as the enhancement of generalization for distant nodes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the connection between the theoretical analysis and the proposed method, questioning how the proposed method enhances the generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the connection is weak or how the proposed method improves generalization. This makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances the generalization for distant nodes. This feedback is somewhat helpful as it identifies a potential gap in the paper's argumentation and highlights an area that requires further clarification or substantiation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the connection between theory and practice. To be more helpful, the comment could include specific examples, references, or suggestions for enhancing the theoretical analysis or demonstrating the method's effectiveness. Therefore, the comment is rated as somewhat helpful, as it points out a critical area for improvement but lacks detailed guidance.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the connection between the theoretical analysis and the proposed method, questioning how the proposed method enhances the generalization for distant nodes. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the connection between theory and practice. The feedback lacks actionable steps or concrete examples, making it difficult for the authors to know exactly what changes or clarifications are needed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the theoretical analysis and the proposed method, specifically questioning the connection between the theoretical analysis and the method. It highlights the adoption of the self-attention mechanism from the transformer and its application to the graph, and raises a concern about how the proposed method enhances generalization for distant nodes. However, the comment does not specify which part of the paper this analysis is found in, making it weakly grounded. The authors can infer that it relates to the theoretical analysis and the proposed method, but without explicit references, it remains challenging to pinpoint the exact sections. The comment is specific in detailing the issue with the connection between theory and method, as well as the enhancement of generalization for distant nodes. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the connection between the theoretical analysis and the proposed method, questioning how the proposed method enhances the generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the connection is weak or how the proposed method improves generalization. This makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances the generalization for distant nodes. This feedback is somewhat helpful as it identifies a potential gap in the paper's argumentation and highlights an area that requires further clarification or substantiation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, implying that it is a collection of tricks to improve defense evaluation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve their work. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the technical contribution of the work, suggesting that the proposed pipeline is incremental and not novel. However, it does not specify which part of the paper this critique pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs improvement. Additionally, the comment lacks specificity in detailing what aspects of the pipeline are considered incremental or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, suggesting it is a collection of tricks to improve defense evaluation. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the technical contribution of the work, suggesting that the proposed pipeline is incremental and not novel. It implies that the work is a collection of tricks to improve defense evaluation. However, the comment lacks specific details or examples to support this critique, making it difficult for the authors to understand the basis of the claim or address it effectively. Without actionable feedback or suggestions for improvement, the comment does not provide the authors with a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it identifies a potential issue but does not offer actionable guidance.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the reason why the eta_ri term is non-central chi-squared distribution, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable advice or suggestions for clarification or explanation, leaving the authors without a clear path to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment is specific in questioning the distribution, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the distribution of the eta_ri term, specifically why it is non-central chi-squared. While it identifies a potential area of confusion or lack of explanation, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The feedback lacks depth and actionable advice, making it difficult for the authors to effectively use this comment to enhance their work. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment questions the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify the distribution. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment is specific in questioning the distribution, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The comment raises a question about the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. Without actionable advice or context, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, consistent with a score of 2.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment questions the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or clarify the distribution. Without actionable advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the distribution of the eta_ri term, specifically why it is non-central chi-squared. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment"}
{"generated_text": "{'actionability_rationale': 'The review point provides specific feedback on the vagueness of the comment at line 15, suggesting that the authors should refer to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. It also critiques the analogy of reinforcement learning and the agent analogy, suggesting that it is out of place and recommending that the authors focus on generalization capabilities, which are better illustrated by the examples provided later in the paper. While the comment provides clear guidance on what to include and where to find relevant information, it does not explicitly instruct the authors to make these changes themselves. The feedback is concrete and specific, but the action is inferred, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L15,\" \"L16,\" \"L17,\" and \"L18,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the comment, such as the vagueness of the reference to RNNs and the out-of-place nature of the reinforcement learning/agent analogy. The comment further provides specific suggestions for improvement, such as referring to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point provides specific references to the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to support the claim that certain RNNs work well for certain natural language reasoning tasks. It also critiques the out-of-place nature of the reinforcement learning/agent analogy and suggests that generalization capabilities are better illustrated by examples later in the paper. This provides clear reasoning and specific references, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or further justification for the critique of the reinforcement learning/agent analogy. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback on the draft. It identifies a vague comment at line 15 and suggests referencing the literature on natural language inference and the leaderboard at https://nlp.stanford.edu/projects/snli/ to provide a more concrete example of RNNs working well for certain natural language reasoning tasks. Additionally, it critiques the out-of-place nature of the reinforcement learning/agent analogy and recommends focusing on generalization capabilities, which are better illustrated by the examples provided later in the paper. This feedback is clear and actionable, offering the authors a path to improve the clarity and relevance of their draft. However, it could be more helpful if it provided specific suggestions on how to integrate the suggested references or examples into the paper. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks. It suggests that comparing the inference speed between the proposed network and prior work would be more interesting. While the comment identifies a gap in the analysis, it does not explicitly instruct the authors to include this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a speed analysis and compare it with prior work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of speed analysis in the experiments, specifically mentioning the comparison of GFLOPs between different segmentation networks. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting that comparing the inference speed between the proposed network and prior work would be more interesting, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments lack a speed analysis, specifically mentioning the comparison of GFLOPs between different segmentation networks. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a significant issue or how it affects the overall evaluation of the proposed network. Without additional context or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the analysis by pointing out the lack of speed analysis in the experiments. It suggests that comparing the inference speed between the proposed network and prior work would be more interesting than just comparing GFLOPs. This feedback is clear and actionable, as it provides a specific direction for improvement that could enhance the paper\\'s contribution and relevance. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects of the inference speed analysis would be most informative. Overall, the comment is mostly helpful as it directs the authors to a valuable area for enhancement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is not well-positioned in the literature and highlights that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. The reviewer suggests that the authors should conduct a thorough literature review to identify additional works that utilize this property. While the comment implies that the authors should perform a literature review, it does not explicitly instruct them to do so or provide specific guidance on how to conduct this review. The action is implicit and somewhat vague, as the authors need to infer the need for a literature review and how to carry it out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed method\\'s positioning in the literature, specifically pointing out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the well-known nature of the key idea and providing examples of previous works, but without explicit grounding, it is challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and highlights that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. This provides a clear and specific reference to existing literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed method's positioning in the literature, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides specific examples of previous works, such as the original denoising score matching objective and 'score-interpolation,' which use this property. This feedback is valuable as it directs the authors to a potential area of overlap or prior work that they may need to address in their literature review. However, the comment could be more helpful if it suggested how the authors might integrate this information into their paper or provided additional context on why this is a significant issue. Overall, the comment is mostly helpful as it highlights a potential gap in the literature review and provides specific examples, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that if the authors have the resources, they should conduct a comparison between the \"small learning rate for attention parameters\" benchmark and the proposed approach. While the comment implies that this comparison would be of interest, it does not explicitly instruct the authors to perform the comparison or provide guidance on how to execute it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the comparison and understand how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach if they have the resources. However, it does not specify which part of the paper this benchmark is discussed in, making it weakly grounded. The comment is specific in its suggestion to compare the benchmark with the proposed approach, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach if they have the resources. However, the comment does not provide any reasoning, evidence, or justification for why this comparison would be beneficial or how it would contribute to the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific action for the authors to consider, which is to compare the \"small learning rate for attention parameters\" benchmark with the proposed approach if they have the resources. This feedback is somewhat helpful as it provides a clear direction for potential future work that could enhance the paper\\'s impact. However, it lacks depth and does not offer guidance on how to conduct the comparison or what specific aspects should be evaluated. The authors are left with a suggestion but without detailed instructions on how to implement it, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the paper\\'s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what experiments might be necessary. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations or conduct additional experiments. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the approach taken to resolve a debate that was previously left open and suggests that the distribution might have changed. The comment further asks whether experiments have been conducted to disentangle changes in distribution from the removal of information, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the approach is flawed or incomplete. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the paper's approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. This feedback is somewhat helpful as it identifies a potential issue with the paper's methodology and encourages the authors to consider alternative explanations or additional experiments. However, the comment lacks specific suggestions or guidance on how to address these concerns, such as recommending specific experiments or analyses to conduct. While it prompts the authors to think critically about their approach, it could be more helpful with additional details or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it suggests an area of interest, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might investigate or address this curiosity, nor is there any suggestion for how to incorporate this information into their draft. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses curiosity about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental section or results, but this inference is not explicit. The comment is specific in its curiosity about the performance of a particular method, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric. However, it does not contain any claims, opinions, or suggestions that require verification. It is a purely factual statement of interest, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses curiosity about the performance of a specific method (LST) combined with an adaptive metric. While it identifies an area of interest, it does not provide any actionable feedback or suggestions for the authors to improve their draft. The comment lacks depth and does not offer any guidance on how the authors might explore or address this curiosity. As a result, it is not helpful to the authors in terms of improving their work. Therefore, the comment is rated as 1, indicating it is not helpful at all.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. It suggests that the plots should be much clearer, which is a direct and explicit action for the authors to take. The comment provides concrete guidance on what needs to be improved, such as increasing the size of the plots, improving color differentiation, and clarifying axis labels. This level of detail and specificity makes the feedback highly actionable, as it gives the authors a clear path to follow for enhancing the clarity of their experimental results presentation.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"plots,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. The reviewer supports this claim by providing specific examples of these issues, such as the difficulty in distinguishing between pink and red colors. This level of detail and specificity makes the claim mostly verifiable, as it provides clear reasoning and examples to substantiate the critique. However, the comment could be strengthened by including references to best practices or examples of effective plot design, which would fully verify the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies specific issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. It highlights that these issues make the plots difficult to read and understand, which is crucial for presenting experimental results. By pointing out these problems, the comment provides clear and actionable feedback that can help the authors improve the clarity and effectiveness of their data presentation. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending larger plot sizes or clearer label differentiation. Overall, the feedback is mostly helpful as it directs the authors' attention to critical areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the performance gains are not very high, with the difference between the baseline and the best approach being less than 1% for most metrics. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their results or what specific aspects of their approach could be enhanced. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance gains of the different metrics, comparing the baseline (without caption and without warmup) to the best approach (with caption and warmup). However, it does not specify which metrics are being discussed or which part of the paper this comparison is made in, making it weakly grounded. The comment is specific in pointing out that the performance gains are not very high, but it lacks detailed guidance on how to address this issue or improve the results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance gains are not very high, with the difference between the baseline and the best approach being less than 1% for most metrics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or data, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific issue with the performance gains of the proposed approach, noting that the difference between the baseline and the best approach is less than 1% for most metrics. This feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The comment could be more helpful if it included specific recommendations or examples of how to enhance the performance or improve the results. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the Unary model. It suggests that using a better Unary baseline might still result in a performance boost. However, the comment does not provide explicit guidance or suggestions on how the authors should address this question or what specific actions they should take to investigate this further. The action is implicit and vague, as the authors are left to infer that they should explore the performance of a better Unary baseline. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Tab 1,2,3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue by questioning the performance boost due to additional parameters in LinearTop and NLTop compared to the performance of the Unary model. The comment also references a specific paper ([14]) for context, providing additional specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the performance of the Unary model. It references a specific paper ([14]) for context, suggesting that using a better Unary baseline might still result in a performance boost. However, the comment lacks detailed reasoning or evidence to support the claim that the additional parameters are the sole reason for the performance boost. The reference to [14] provides some context but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a starting point for the authors to explore but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the performance boost due to additional parameters in the LinearTop and NLTop models compared to the performance of the Unary model. It references a specific paper ([14]) for context, suggesting that using a better Unary baseline might still result in a performance boost. This feedback is somewhat helpful as it prompts the authors to consider the impact of additional parameters and the potential need for a better baseline. However, the comment lacks detailed guidance or suggestions on how to address this issue or what specific steps to take to investigate the performance boost. While it identifies an area for improvement, it could be more helpful with additional context or actionable advice. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. While the comment implies that the authors should expand their discussion to include comparisons, it does not provide explicit instructions on how to achieve this or what specific aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the discussion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Related Work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. This provides clear guidance on what the authors need to address in their discussion of related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. However, the comment does not provide specific examples or references to support the claim that a more detailed discussion is necessary. Without additional context or evidence, the authors may find it challenging to understand the extent of the improvement needed. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from a more detailed discussion of related work, not just by describing the related works but also by discussing the differences to the presented work. This feedback is somewhat helpful as it identifies a specific area for improvement in the paper, namely the need for a more nuanced and detailed discussion of related work. However, the comment lacks specificity and does not provide detailed guidance on how to achieve this improvement or what specific aspects should be emphasized. To be more helpful, the comment could include examples of how the discussion could be expanded or what specific differences should be highlighted. Therefore, the comment is somewhat helpful, as it points out a potential area for enhancement but lacks depth and actionable suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that this would be beneficial, it does not explicitly instruct the authors to conduct these additional experiments or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests expanding the experiments to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the introduction. The authors might infer that it relates to the experimental setup, but this inference is not explicit. The comment is specific in its suggestion to explore additional architectures and tasks, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. However, the comment does not provide any reasoning, examples, or references to support why this would be beneficial or how it could improve the paper. Without specific evidence or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the experiments in the paper should be expanded to include other architectures and classification tasks beyond neural networks and image classification. This feedback is somewhat helpful as it identifies a potential area for improvement in the scope of the experiments. However, it lacks specificity and does not provide guidance on which specific architectures or tasks should be explored. Additionally, it does not offer suggestions on how to conduct these additional experiments or what benefits they might bring to the paper. While it points out a potential limitation, the comment could be more actionable with more detailed guidance. Therefore, it is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the output from the algorithm depends on the order in which the data are processed. It explicitly suggests that this aspect should be clarified. However, the comment does not provide specific guidance on how to clarify this point, such as by recommending a particular way to present this information or by suggesting additional examples. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the algorithm\\'s output depending on the order in which the data are processed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem, but without grounding, the authors may struggle to pinpoint the exact section that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the algorithm's output depending on the order in which the data are processed. It suggests that this aspect should be clarified, which is a valuable observation. However, the comment lacks specific guidance or suggestions on how to address this issue or clarify the output's dependence on data order. While it points out a potential weakness, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the algorithm\\'s output depending on the order in which the data are processed. It explicitly suggests that this aspect should be clarified, providing a clear and direct action for the authors to take. However, the comment does not offer specific guidance on how to clarify this point, such as by recommending a particular way to present this information or by suggesting additional examples. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a potential issue with the algorithm\\'s output depending on the order in which the data are processed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem, but without grounding, the authors may struggle to pinpoint the exact section that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the output from the algorithm depends on the order in which the data are processed. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the algorithm's output depending on the order in which the data are processed. It suggests that this aspect should be clarified, which is a valuable observation. However, the comment lacks specific guidance or suggestions on how to address this issue or clarify the output's dependence on data order. While it points out a potential weakness, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out a potential issue with the algorithm\\'s output depending on the order in which the data are processed. It explicitly suggests that this aspect should be clarified, providing a clear and direct action for the authors to take. However, the comment does not provide specific guidance on how to clarify this point, such as by recommending a particular way to present this information or by suggesting additional examples. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a potential issue with the algorithm\\'s output depending on the order in which the data are processed. However, it does not specify which part of the paper this issue is"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. However, it does not provide explicit guidance on how the authors should address this issue. While it suggests that the sampling process should be evaluated more carefully, it does not specify which benchmarks or aspects of the sampling process need further investigation. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for more careful experimental evaluation of sampling, particularly on the proposed benchmarks. However, it lacks detailed guidance on how to conduct this evaluation or which benchmarks should be considered. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the sampling process used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide specific evidence or examples to support this claim. The comment mentions that this process is not evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. However, without further elaboration or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the sampling process used to obtain different initializations x_0, which is crucial for the convergence to the optimum. It points out that this process is not evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is somewhat helpful as it highlights a gap in the experimental evaluation that needs attention. However, the comment lacks specific guidance on how the authors should address this issue or what additional experiments should be conducted. To be more helpful, the comment could provide suggestions on how to conduct a more thorough evaluation or which benchmarks should be considered. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks depth and actionable advice.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. However, it does not provide explicit guidance on how the authors should address this issue. While it suggests that the sampling process should be evaluated more carefully, it lacks specific instructions or examples of what aspects of the sampling process need further investigation or improvement. The comment lacks actionable details, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the importance of sampling in obtaining different initializations x_0 and its impact on convergence to the optimum. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for more careful experimental evaluation of sampling, particularly on the proposed benchmarks. However, it lacks detailed guidance on how to conduct this evaluation or which benchmarks should be considered. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the sampling process used to obtain different initializations x_0 is important for convergence to the optimum, but it does not provide specific evidence or examples to support this claim. The comment mentions that this process is not evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. However, without further elaboration or references, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the sampling process used to obtain different initializations x_0, which is crucial for the convergence to the optimum. It points out that this process is not evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is somewhat helpful as it highlights a gap in the experimental evaluation that needs attention. However, the comment lacks specific guidance on how the authors should address this issue or what additional experiments should be conducted to improve the evaluation. To be more helpful, the comment could provide suggestions on"}
{"generated_text": "{'actionability_rationale': \"The review point raises questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for comparing computational cost with only [9]. It suggests that there is no further discussion of this aspect in the paper, leaving the authors with a vague understanding of what needs to be addressed. While the comment identifies areas for clarification, it does not provide explicit guidance on how to improve the draft or what specific aspects should be discussed further. The action is implicit and somewhat vague, making the comment barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for comparing computational cost with only [9]. It also questions whether the computational cost is a significant contribution to the paper and whether it is a big issue in a practical scenario. However, the comment does not specify which part of the paper these comparisons are discussed in, making it weakly grounded. The authors can infer that the questions relate to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing the issues with the comparison and the need for further discussion, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for comparing computational cost with only [9]. It questions whether the computational cost is a significant contribution to the paper and whether it is a big issue in a practical scenario. However, the comment does not provide any specific evidence, reasoning, or references to support these questions or claims. Without additional context or justification, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions about the logic behind the comparison of the proposed method with [9] and [16] and the rationale for comparing computational cost with only [9]. It also questions whether the computational cost is a significant contribution to the paper and whether it is a big issue in a practical scenario. While the comment identifies areas for clarification and suggests that there may be gaps in the discussion, it does not provide specific guidance or suggestions on how the authors might address these issues or improve their draft. The feedback is somewhat helpful as it prompts the authors to consider and potentially expand their discussion, but it lacks depth and actionable advice, leaving the authors with a general sense of what needs to be addressed without clear direction. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider using tabular data as a modality, which is another popular form of multi-modal data. While the comment implies that this could be an interesting direction, it does not explicitly instruct the authors to include this aspect in their work. The suggestion is vague and lacks concrete guidance on how to implement this idea, making it somewhat actionable. The authors can infer that they might want to explore this direction, but the comment does not provide specific steps or examples on how to do so. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the use of tabular data as a modality, which is another popular form of multi-modal data. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area where this suggestion should be applied. Additionally, the comment is specific in suggesting that the model could work well with tabular data, but it does not provide detailed guidance on how to implement this idea or what aspects of the model would need to be adjusted. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that tabular data is another popular form of multi-modal data and that it would be interesting to explore how the model works with tabular data. However, it does not provide any specific reasoning, examples, or references to support why this is a relevant or interesting direction. The claim lacks depth and does not offer a clear rationale for why the authors should consider this aspect. As a result, the comment is considered unverifiable, as it does not provide sufficient evidence or justification for the authors to understand the significance of the suggestion.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors consider using tabular data as a modality, which is another popular form of multi-modal data. While the comment identifies an interesting direction for exploration, it does not provide specific guidance or suggestions on how to implement this idea. The authors are left with a general suggestion but without actionable steps or examples to follow. This makes the comment somewhat helpful, as it offers a potential area for expansion but lacks depth and specificity in its feedback. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While the action is explicit, it lacks concrete guidance on what specific details should be included or how they should be presented. The authors are aware of the need for more information on attention, but the comment does not provide detailed instructions on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it identifies a need for additional information but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not specify which part of the paper this information should be added to, making it weakly grounded. The comment is specific in its suggestion to include more details on attention, but without grounding, the authors may struggle to identify the exact sections where this information should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details on using attention should be included, possibly as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that more details on using attention should be included, possibly as an extra appendix. While this feedback acknowledges the need for additional information, it lacks specificity and does not provide guidance on what specific details should be included or how they might enhance the paper. Without actionable suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning that the model can work well for various image noise types. While the comment implies that the authors should provide results for other types of noise, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their results to include other types of noise. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper\" and \"images corrupted using Gaussian noise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model's ability to handle various image noise types. This provides clear guidance on what aspect of the paper needs further clarification or expansion. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model\\'s ability to handle various image noise types. This is a logical inquiry seeking clarification on the authors\\' rationale. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest why this is a concern. As a result, the comment is considered unverifiable, as it lacks the necessary justification or evidence to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the limited scope of the results presented in the paper, specifically questioning why only results on images corrupted with Gaussian noise are shown, given the claim that the model can handle various image noise types. This feedback prompts the authors to consider expanding their experimental setup to include other types of noise, which could enhance the robustness and generalizability of their findings. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as which types of noise to include or how to structure the additional experiments. While it identifies a potential weakness, the lack of detailed advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the empirical version of the objective (3) might be more appropriate to include in the supplementary materials. While it implies that the authors should consider moving this content to the supplementary materials, it does not explicitly instruct them to do so or provide a rationale for why this would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should move the content to the supplementary materials. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"objective (3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests moving the empirical version of the objective to the supplementary materials, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the empirical version of the objective (3) might be more appropriate to include in the supplementary materials. However, the comment does not provide any reasoning, examples, or references to support why this is the case. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the empirical version of the objective (3) might be more appropriate to include in the supplementary materials. While this provides a potential area for improvement, it lacks specific guidance or reasoning to support why this is the case. The comment does not offer detailed feedback or suggestions on how to improve the presentation or organization of the objective, leaving the authors with limited actionable information. As a result, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the claim made in lines 180-182, stating that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, without necessarily implying that it minimizes the expected convex surrogate. The comment provides a clear and explicit action for the authors to take, which is to clarify or correct the claim in question. The feedback is concrete, as it specifies the exact part of the paper to address and the nature of the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 180--182,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, without necessarily implying that it minimizes the expected convex surrogate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, without necessarily implying that it minimizes the expected convex surrogate. This claim is somewhat verifiable as it provides a logical reasoning based on the information presented in the paper. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the paper to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the claim made in lines 180-182, noting that Corollar 10 only shows that uncertainty sampling moves in descent directions of the expected 0-1 loss, without necessarily implying that it minimizes the expected convex surrogate. This feedback is clear and actionable, as it directs the authors to clarify or correct the claim in question. By pointing out this potential misunderstanding, the comment provides valuable guidance for improving the clarity and accuracy of the paper. However, it could be more helpful if it offered suggestions on how to address the issue or provided additional context. Overall, the comment is mostly helpful, as it effectively highlights a critical point for the authors to consider.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add missing details about the division of the dataset into training and test sets, including the numbers involved and the method used for division (e.g., random or other considerations). This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what information needs to be added to improve their draft, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"division to train and test sets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, such as the numbers and the method used for division. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the draft lacks detail, namely the division of the dataset into training and test sets. It points out that the numbers and the method used for division are missing, which is crucial information for understanding the experimental setup. By suggesting that these details should be added, the comment provides clear and actionable feedback that can help the authors improve the clarity and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how other studies have handled similar details. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the model\\'s testing on other tasks in the bAbI dataset, given that it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to other tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model\\'s testing on other tasks in the bAbI dataset, specifically mentioning Task 1 of bAbI. This provides some grounding as it allows the authors to identify the part of the paper being addressed, which is the testing methodology or results. However, the comment does not specify what needs to be addressed or improved in terms of testing on other tasks. It lacks specificity regarding the details of the testing or the potential issues that might arise from only testing on a single supporting fact dataset. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the model\\'s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. However, it does not provide any evidence, reasoning, or references to support the claim that only Task 1 was tested or that testing on other tasks is necessary. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model\\'s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer any insights or recommendations for expanding the testing or exploring other tasks, leaving the authors with a general idea but no actionable steps to take. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the dataset used in the experiments is small and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it labels this as a minor issue and does not provide specific guidance on how to address this concern. The authors are left with a general suggestion but without concrete steps or examples on how to implement it. The action is implicit and somewhat vague, as it does not offer detailed instructions on how to improve the dataset or what specific results should be included. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the small dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it does not specify which part of the paper discusses the dataset or the experiments, making it weakly grounded. The comment is specific in suggesting a potential improvement to the dataset, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the small size of the dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it labels this as a minor issue and does not provide specific reasoning or evidence to support why this is a concern or how it affects the overall quality of the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges the small size of the dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's experimental setup. However, the comment is vague and lacks specific guidance on how to address this issue or what results should be included. The authors are left with a general suggestion but without detailed instructions on how to implement it. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the first claimed contribution of the paper, suggesting that it lacks empirical justification. However, it does not provide explicit guidance on how the authors should address this issue or what kind of empirical evidence would be necessary. The comment implies that the authors should provide empirical evidence to support their claim, but it does not specify how to do so or what kind of evidence would be most effective. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the first claimed contribution of the paper, which is that the proposed algorithm does not take as many points or does not require apriori knowledge about dimensions of subspaces. However, it does not specify which part of the paper this contribution is made in, making it weakly grounded. The comment suggests that empirical justification is needed for this claim, but it does not provide specific guidance on what kind of empirical evidence would be necessary. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point critiques the first claimed contribution of the paper, suggesting that it lacks empirical justification. However, the comment does not provide specific examples or references to support the claim that the proposed algorithm does not take as many points or does not require apriori knowledge about dimensions of subspaces. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the first claimed contribution of the paper, noting that it lacks empirical justification for its claim that the proposed algorithm does not take as many points or does not require apriori knowledge about dimensions of subspaces. While the comment identifies a potential weakness in the paper's claims, it does not provide specific suggestions or guidance on how the authors might address this issue or what kind of empirical evidence would be necessary to support their claims. This lack of actionable feedback limits the usefulness of the comment, making it barely helpful. Therefore, the comment aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. It explicitly recommends that the paper needs to provide a sufficient discussion on the comparison with RMED. This feedback is clear and direct, giving the authors a specific action to take: to include a detailed comparison with RMED in their paper. The comment provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the proposed S1DB-ED algorithm, suggesting that it is too similar to RMED (Komiyama et al. 2015). It recommends that the paper needs to give a sufficient discussion on the comparison with RMED. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the discussion or comparison section where the novelty of the S1DB-ED algorithm is presented. The authors can infer that it relates to the sections where the proposed algorithm is discussed, but the comment does not provide exact references. The feedback is specific in suggesting a need for a detailed comparison with RMED, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed S1DB-ED algorithm is too similar to RMED (Komiyama et al. 2015), suggesting that the novelty of this part is limited. The reviewer recommends that the paper needs to give a sufficient discussion on the comparison with RMED. While the comment identifies a potential issue with the novelty of the proposed algorithm, it lacks specific examples or detailed reasoning to substantiate the claim. The reference to RMED provides some context, but the comment does not explain why the similarity is problematic or how it affects the novelty of the work. Therefore, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the proposed S1DB-ED algorithm, noting that it is too similar to RMED (Komiyama et al. 2015). It suggests that the paper needs to provide a sufficient discussion on the comparison with RMED to address this concern. This feedback is clear and actionable, as it directs the authors to include a detailed comparison with RMED to enhance the novelty and differentiation of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this comparison. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. This is an explicit action that provides clear guidance on what the authors need to do to improve their draft. Additionally, the comment mentions a minor point about the low jailbreaking percentage for certain LLMs, which further clarifies what needs to be addressed. The feedback is concrete and actionable, giving the authors a clear path to follow for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be included, which is a comparison of the approach in GCG to other LLMs, and mentions a minor point about the low jailbreaking percentage for certain LLMs. This provides clear guidance on what the authors need to address, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. It also mentions a minor point about the low jailbreaking percentage for certain LLMs. While the suggestion to include a comparison is logical and could be beneficial, the comment lacks specific examples or references to support the claim about the low jailbreaking percentage. This makes the claim somewhat verifiable, as it provides a general suggestion but lacks detailed evidence or justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides two pieces of feedback. First, it suggests that the authors should include a comparison of their approach in GCG, which allows for the transfer of adversarial prompts to other LLMs. This is a clear and actionable suggestion that could enhance the paper\\'s scope and impact. Second, it points out a minor issue with the low jailbreaking percentage for certain LLMs, which is a specific area for improvement. While the comment is mostly helpful, it could be more comprehensive by providing additional context or suggestions for addressing the low jailbreaking percentage. Overall, the feedback is clear and provides valuable guidance for the authors to improve their draft, making it mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not provide explicit guidance or suggestions on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should explore the capabilities of the framework in different contexts. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate this inquiry. The comment lacks specific examples or references to external works that might address this concern, making it difficult for the authors to understand the basis of the question. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the inquiry.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. This is a relevant and insightful inquiry that prompts the authors to consider the scope and applicability of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or explore these areas. While it identifies an important aspect for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the dataset creation is optional and mentions that the Kialo dataset is well-studied and cleaner than the dataset created in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the created dataset can be additional data to learn from, but it does not offer guidance on how the authors might use this information or whether it should be included in the paper. As a result, the authors are left without a clear understanding of what actions to take based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the creation of the dataset and compares it to the Kialo dataset, which is well-studied in the community. However, it does not specify which part of the paper this discussion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its observation about the Kialo dataset being cleaner and suggesting that the created dataset can be additional data to learn from. However, it lacks detailed guidance on how the authors might use this information or whether it should be included in the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point compares the dataset created in the paper to the Kialo dataset, suggesting that the latter is more suitable for the authors\\' needs. However, the comment does not provide specific reasoning or evidence to support why the Kialo dataset is more appropriate or cleaner. The mention of \"no automatic processes exist to construct it\" implies that the Kialo dataset is more reliable, but this is not substantiated with detailed justification or examples. As a result, the claim is somewhat verifiable, as it provides a general comparison but lacks detailed evidence or reasoning to fully support the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the creation of the dataset is optional and suggests that the Kialo dataset, which is well-studied in the community, provides exactly what the authors need. It highlights that the Kialo dataset is cleaner than the dataset created in the paper, as no automatic processes are required to construct it. However, the comment does not provide specific guidance or suggestions on how the authors might use the created dataset or whether it should be included in the paper. While it identifies a potential alternative, it lacks actionable advice or detailed feedback that could help the authors improve their draft. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully support the authors in enhancing their work.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges that the creation of the dataset is optional and suggests that the Kialo dataset, which is well-studied in the community, provides exactly what the authors need. It highlights that the Kialo dataset is cleaner than the dataset created in the paper, as no automatic processes exist to construct it. However, the comment does not provide any explicit or implicit actions for the authors to take, such as suggesting that they should use the Kialo dataset instead or discuss the creation of their own dataset. Without specific guidance or suggestions, the authors are left without a clear understanding of how to address this feedback. Therefore, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the creation of the dataset and compares it to the Kialo dataset, which is well-studied in the community. However, it does not specify which part of the paper this discussion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact part of the paper being addressed, resulting in weak grounding. The comment is specific in its observation about the Kialo dataset being cleaner and suggesting that the created dataset can be additional data to learn from. However, it lacks detailed guidance on how the authors might use this information or whether it should be included in the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point compares the dataset created in the paper to the Kialo dataset, suggesting that the latter is more suitable for the authors' needs. However, the comment lacks specific reasoning or evidence to support why the Kialo dataset is more appropriate or cleaner. The mention of 'no automatic processes exist to construct it' implies that the Kialo dataset is more reliable, but this is not substantiated with detailed justification or examples. As a result, the claim is somewhat verifiable, as it provides a general"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. The comment explicitly requests that the authors address these weaknesses, providing a clear and direct action for improvement. It also includes specific suggestions on what needs to be added or changed, making the feedback highly actionable. The authors are given a clear path to follow in order to enhance their draft, ensuring that they know exactly what steps to take to improve it.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the number of tasks in the experiments and suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, such as the number of tasks and the presentation of results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited number of tasks in the experiments and suggests that the authors should include several tasks and present sequential results in terms of tasks learned rather than epochs. However, the comment does not provide specific examples or references to support the claim that the number of tasks is insufficient or that sequential results are necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the limited number of tasks in the experiments. It suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By addressing this comment, the authors can enhance the comprehensiveness and robustness of their experimental results. However, the comment could be more helpful if it included additional suggestions or examples of how to present the sequential results. Overall, the feedback is mostly helpful as it guides the authors towards a significant improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer and asks why numerosity does not appear in earlier layers. While the comment raises a valid concern about the rationale behind the analysis, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the motivation for their analysis or provide additional context. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in questioning the rationale behind the analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the motivation for analyzing only the last convolutional layer and why numerosity does not appear in earlier layers. This feedback is somewhat helpful as it prompts the authors to clarify their rationale for this specific choice, which could be important for understanding the methodology and results. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or improve the analysis. To be more helpful, the comment could include additional questions or suggestions for further exploration or justification. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about setting the parameter S, but it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or action for the authors to take, such as recommending a specific method or approach to determine the parameter S. Without any actionable advice or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about setting the parameter S, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper this comment pertains to, making it weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of setting the parameter S, leaving the authors without clear direction. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about setting the parameter S, but it does not provide any specific reasoning, examples, or references to support why this is a problem or how it affects the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a concern about setting the parameter S, which is a critical aspect of the paper. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their approach. Without actionable advice or detailed feedback, the authors are left without a clear understanding of what steps to take to enhance their draft. As a result, the comment is not helpful, as it lacks the depth and specificity needed to guide the authors in improving their work. Therefore, it aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim in the introduction that shape constraints do not require tuning a free parameter. It points out that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing, can be considered a hyperparameter that needs to be chosen or tuned. While the comment identifies a potential issue with the claim, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or rephrase the claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"introduction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim that \"these shape constraints do not require tuning a free parameter,\" noting that the choice of employing specific constraints can be considered a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what needs to be addressed in the introduction. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction\\'s statement about shape constraints not requiring tuning a free parameter is technically true but suggests that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing, can be considered a hyperparameter that needs to be chosen or tuned. This claim is somewhat verifiable as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion that these constraints are indeed hyperparameters. The comment could be strengthened by providing more detailed examples or references to substantiate the claim, making it more robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the claim in the introduction that shape constraints do not require tuning a free parameter. It points out that the choice of employing specific constraints, such as convex or concave, and increasing/decreasing, can be considered a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it prompts the authors to reconsider their claim and potentially revise it to accurately reflect the nature of the constraints. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of how to rephrase the claim. Overall, the comment is mostly helpful as it directs the authors' attention to an important aspect of their work that requires clarification.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their dataset and model coverage to include other biases and state-of-the-art generative models. However, the comment lacks concrete details on how to implement these changes, such as suggesting specific datasets or models to include. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on other important biases and state-of-the-art generative models like GPT. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that the comment pertains to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what is missing, such as other biases and state-of-the-art models, but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also mentions the absence of assessments on state-of-the-art generative models like GPT. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the significance of these omissions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on state-of-the-art generative models like GPT. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered suggestions on how to expand the dataset or model coverage or provided examples of other biases and datasets that could be included. Overall, the comment is mostly helpful as it directs the authors' attention to important areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. However, it does not provide explicit guidance on how to address these issues or suggest specific changes to make the figure more understandable. The authors are left to infer that they need to clarify the workflow, improve the captions, and possibly rework the representation of communication modes, but the comment lacks concrete steps or examples. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issues with the figure, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow, captions, and the representation of communication modes. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that the workflow, captions, and representation of communication modes are unclear. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity of their figure, which is crucial for effectively communicating their workflow and findings. However, the comment could be more helpful if it provided suggestions on how to enhance the figure, such as recommending specific changes to the layout or labeling. Overall, the comment is mostly helpful as it highlights a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\\'s performance under different scenarios. It also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. This feedback is explicit and concrete, giving the authors a clear direction on what to include in their paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\\'s performance under different scenarios. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section where this analysis should be incorporated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\\'s performance under different scenarios. This feedback is logical and provides a clear rationale for why error analysis is important, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim that error analysis is essential for model performance evaluation. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offers guidance on how to provide detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their paper by addressing a critical aspect of model evaluation. However, the comment could be more helpful if it included specific examples or references to similar studies that have effectively used error analysis. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' claim that their work is NLP-specific, suggesting that it lacks specificity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what specific aspects of their approach should be clarified. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' claim that their work is NLP-specific, suggesting that it lacks specificity. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the claim but lacks grounding, as it does not provide a clear reference to the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' claim that their work is NLP-specific by questioning the lack of specificity in their approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors\\' claim that their work is NLP-specific, suggesting that it lacks specificity. However, the comment does not provide any specific feedback or suggestions on how the authors might address this issue or improve the clarity of their approach. Without actionable guidance or detailed feedback, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential issue but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that at least one NCE-based method should be included for comparison. It references a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This provides a clear and explicit action for the authors to take, as they are directed to include a comparison with an NCE-based method. The comment also offers a specific reference to guide the authors in making this addition. Therefore, the comment is highly actionable, as it provides a direct and concrete action for the authors to implement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This provides a clear and specific reference for the authors to follow, making the comment fully grounded. The suggestion is also specific, as it directs the authors to include a comparison with an NCE-based method, which is a concrete action. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including at least one NCE-based method for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This provides a clear and specific reference to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the inclusion of such a method would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that at least one NCE-based method should be included for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This feedback is clear and actionable, as it provides a specific recommendation for the authors to include a comparison with an NCE-based method. By referencing a relevant work, the comment offers a concrete direction for the authors to enhance their draft. However, it could be more helpful if it provided additional context or guidance on how to integrate this comparison effectively. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests two specific improvements to the experiment section: conducting a significance test on human evaluation results and comparing the proposed method with the most recent LLM. These suggestions are explicit and provide clear guidance on what actions the authors should take to enhance their draft. The comment is concrete, as it specifies the types of tests and comparisons that would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically recommending the inclusion of a significance test on human evaluation results and comparing the proposed method with the most recent LLM. However, it does not specify which part of the experiment section this feedback pertains to, making it weakly grounded. The comment is specific in its suggestions for improvement, providing clear guidance on what actions the authors should take to enhance their draft. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by conducting a significance test on human evaluation results and comparing the proposed method with the most recent LLM. While the comment provides a logical suggestion for enhancing the experimental analysis, it lacks specific examples or references to support the claim that these additions would be beneficial. The reasoning is based on common practices in the field, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experiment section, suggesting that conducting a significance test on human evaluation results would enhance the analysis. Additionally, it recommends comparing the proposed method with the most recent LLM, which is a relevant and constructive suggestion for improving the draft. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the significance test or which specific LLMs should be compared. Overall, the feedback is mostly helpful as it offers clear directions for enhancing the experimental section, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for comparison. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of dataset size on their results and potentially adjust their comparison accordingly. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the fairness of the comparison and suggesting that the superior performance may be due to the dataset size rather than the method itself. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods is unfair due to the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. While the comment provides a logical reasoning for the potential unfairness of the comparison, it lacks specific examples or references to support the claim. The authors are left to infer that the scale of the dataset is a significant factor, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. This feedback is somewhat helpful as it identifies a potential issue with the comparison and provides a logical reasoning for the concern. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparison. To be more helpful, the comment could include suggestions for alternative methods or datasets to ensure a fair comparison. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an unclear aspect regarding the generalizability of the biases discussed in the paper. It mentions specific examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1), but questions the extent to which these situations are generalizable. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or clarify the generalizability of the biases. The action is implicit and vague, as the authors are left to infer that they need to provide more context or evidence regarding the generalizability of these biases. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"Theorem 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the paper, which is the unclear generalizability of the biases discussed in these sections. The comment provides a clear direction for the authors to address, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the biases discussed in the paper, specifically mentioning examples of biases in target statistics (section 3.2) and prediction shift of gradient values (Theorem 1). However, the comment does not provide specific evidence, examples, or references to support the claim that these situations are not generalizable. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding the generalizability of the biases discussed in the paper. It highlights that while the paper presents examples of biases in target statistics and prediction shift of gradient values, it does not provide clarity on the extent to which these situations are generalizable. This feedback is somewhat helpful as it points out a potential gap in the paper's analysis and encourages the authors to clarify the generalizability of the biases. However, the comment could be more helpful if it suggested ways to address this issue or provided additional context to support the claim. Overall, the comment provides some guidance but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows the previous work, Luciddreamer. It explicitly requests the authors to clarify if there is any additional novel effort in this part. This feedback provides a clear and direct action for the authors to take, which is to address the novelty of their contribution in this section. The comment is explicit and concrete, guiding the authors on what specific information they need to provide to substantiate their claim of novelty. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the section on 3D Gaussians generation is novel or follows previous work, Luciddreamer. The comment clearly specifies what needs to be addressed, namely, the novelty of the contribution in this section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions whether the section on 3D Gaussians generation in Section 3.1 is novel or simply follows previous work, specifically Luciddreamer. The comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique, making it difficult to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the section on 3D Gaussians generation, specifically in relation to the previous work, Luciddreamer. It prompts the authors to clarify whether there are any additional novel contributions or improvements in this part of the paper. This feedback is somewhat helpful as it identifies a potential area for clarification or expansion, but it lacks specific guidance or suggestions on how to address the issue. The authors are left with a general direction to explore, but without detailed advice, the comment does not fully support their efforts to improve the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the first paragraph of the Introduction, stating that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. While the comment identifies a specific issue with the introduction, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should revise the introduction to better align with the paper\\'s focus on drift detection. However, the comment lacks concrete details on how to restructure the introduction, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the introduction, which is that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first paragraph of the Introduction is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. While the claim is based on the reviewer\\'s observation, it lacks specific examples or references to support the assertion that the introduction is not aligned with the paper\\'s focus. The comment could be strengthened by providing more detailed reasoning or evidence to substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the first paragraph of the Introduction, noting that it is entirely devoted to a general introduction of DNNs without mentioning drift, which is the core focus of the paper. The reviewer suggests that this entire paragraph provides little valuable information to readers. This feedback is clear and actionable, as it directs the authors to revise the introduction to better align with the paper's focus on drift detection. However, the comment could be more helpful if it provided suggestions on how to integrate the DNN introduction with the drift focus or offered examples of how to make the introduction more relevant. Despite this, the comment is mostly helpful as it provides a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors present a simplified version of theorem 2 for the general audience, similar to theorem 1. While the comment implies that the current presentation of definition 2 and theorem 2 is difficult to understand, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should simplify theorem 2. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition 2 and theorem 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding these sections for the general audience. The comment provides a clear direction for improvement by suggesting a simplified version of theorem 2. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the presentation of definition 2 and theorem 2 is difficult for the general audience to understand, similar to theorem 1. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the presentation of theorem 2, suggesting that it might be difficult for the general audience to understand, similar to theorem 1. This feedback is somewhat helpful as it points out a potential accessibility issue that the authors should consider. However, the comment lacks specific suggestions or guidance on how to simplify theorem 2 or make it more accessible. Without actionable advice, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to explore how the performance of the experiments changes when using a larger image resolution than the current 224*224. While the comment implies that the authors should consider conducting experiments with different image resolutions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore different resolutions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the performance of experiments with larger image resolutions, specifically mentioning the current resolution of 224*224. However, it does not specify which part of the paper this suggestion pertains to, such as a particular experiment or section. The authors can infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in suggesting a potential area for exploration, but it lacks grounding as it does not pinpoint a specific section or experiment. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests exploring the performance of experiments with larger image resolutions, specifically mentioning the current resolution of 224*224. However, it does not provide any reasoning, evidence, or references to support why this exploration would be interesting or beneficial. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting exploration by suggesting that the authors consider conducting experiments with larger image resolutions than the current 224*224. This feedback provides a potential direction for further investigation, which could enhance the depth and relevance of the study. However, the comment lacks specific guidance on how to implement this suggestion or what larger resolutions to consider. While it offers a valuable idea, the feedback could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not explicitly instruct the authors to include this information or provide guidance on where or how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should make this mention but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim is not verifiable, as it lacks the necessary support to be understood or acted upon by the authors. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on why this information is important or how it could be incorporated into the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion or how to implement it effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests conducting additional experiments on larger datasets, noting that compute might be an issue. It also mentions a concern about maintaining probabilities at large batch sizes but acknowledges that this aspect is not critical. The comment provides a clear suggestion for further experimentation and acknowledges the authors\\' efforts in addressing concerns. However, it lacks specific guidance on how to conduct these experiments or what aspects to focus on, making the action somewhat vague. The authors know that additional experiments are suggested but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests additional experiments on larger datasets, noting that compute might be an issue. It also mentions a concern about maintaining probabilities at large batch sizes but acknowledges that this aspect is not critical. The comment is fully grounded as it explicitly mentions \"larger data sets\" and \"large batch size,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what additional experiments could be beneficial and acknowledges the authors\\' efforts in addressing concerns. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests additional experiments on larger datasets, noting that compute might be an issue. It also mentions a concern about maintaining probabilities at large batch sizes but acknowledges that this aspect is not critical. The comment provides a logical reasoning for the suggestion, as larger datasets could provide more comprehensive results, but it lacks specific examples or references to support the claim. The authors are left to infer the importance of these experiments, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests conducting additional experiments on larger datasets, noting that compute might be an issue. It also acknowledges the authors' efforts in addressing concerns but raises a potential issue regarding maintaining probabilities at large batch sizes. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct these experiments or what aspects to focus on. The authors are left to infer the importance of these additional experiments, making the feedback somewhat helpful. However, the comment does provide a clear direction for future work, which could be beneficial if expanded upon. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While the comment implies that additional explanation is needed, it does not explicitly instruct the authors to include this explanation or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should add more explanation but are not given concrete steps on how to implement this suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not specify which part of the paper this explanation should be included in, making it difficult for the authors to identify the exact section that needs additional explanation. The comment is specific in its suggestion to include more explanation of the bounds, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional explanation is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the paper could benefit from more explanation of the meaning of the bounds, possibly in the appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the bounds need clarification or how the explanation could be structured. The comment is somewhat helpful as it points out a potential weakness, but it does not offer actionable advice or examples to help the authors address this issue effectively. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but incomplete in its feedback.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation. It also mentions that some datasets are large, which could limit the applicability of certain algorithms. The reviewer acknowledges the authors\\' detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. However, the comment does not explicitly instruct the authors to take any specific action, such as adding more datasets or explaining the limitations of the current dataset selection. While the feedback provides valuable insights, it lacks explicit guidance on how the authors should address the issue, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the adequacy of the datasets used for evaluation, specifically mentioning the number of datasets for each task. It highlights concerns about the potential insufficiency of the datasets, particularly if some are too large for certain algorithms. The reviewer acknowledges the authors\\' detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. However, the comment does not specify which part of the paper this feedback pertains to, such as the experimental section or the dataset description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in detailing the concern about dataset size and the need for more rigorous evaluation, but without explicit grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be enough for a rigorous evaluation, especially if some datasets are too large. The reviewer acknowledges the authors\\' detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. This feedback is mostly verifiable as it provides some justification for the concern about dataset size and acknowledges the authors\\' efforts to address the issue. However, it could be strengthened with more specific examples or references to support the claim about the insufficiency of the datasets. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large for certain algorithms. The reviewer acknowledges the authors' detailed reply, which includes the provision of a repository and online platform for reproducing the experiments, clarification on the novelty of the datasets, and explanations for the number and choice of datasets. This feedback is mostly helpful as it identifies a potential weakness in the evaluation process and provides the authors with valuable insights and context. However, it could be more helpful if it offered suggestions on how to address the issue, such as recommending additional datasets or methods to enhance the evaluation. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that while there is good performance on ImageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This observation implies that the authors should consider including results with larger models to provide a more comprehensive evaluation. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include larger models in their evaluation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of ResNet models on the ImageNet classification task, specifically mentioning ResNet50/34/18. However, it does not specify which part of the paper this information is presented in, making it weakly grounded. The comment is specific in pointing out the absence of results with larger models like ResNet101/152, which is a clear issue that needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is good performance on ImageNet classification with ResNet50/34/18, but no results are provided for larger models like ResNet101/152. This claim is somewhat verifiable as it highlights a potential gap in the evaluation, but it lacks specific examples or references to support the claim about the good performance of the smaller models. The authors would need to infer the extent of the performance gap and the relevance of larger models, which makes the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential gap in the evaluation by noting that while there is good performance on ImageNet classification with ResNet50/34/18, there are no results with larger models like ResNet101/152. This observation is important as it suggests that the authors should consider including results with larger models to provide a more comprehensive evaluation of their models' performance. However, the comment does not provide specific guidance on how to include these results or what aspects of the larger models' performance should be evaluated. While it highlights a potential area for improvement, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is somewhat helpful, as it points out a significant gap in the evaluation but lacks depth in its guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the method addresses sparse reward problems and whether it supports this claim through the experiments. It also asks if the proposed method requires sub-task-specific rewards, which would be similar to providing dense rewards. Additionally, it inquires about the ability of other methods (Qmix) to solve sparse-reward tasks when given the sum of low-level rewards as the global reward. While the comment raises valid questions, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback is vague and lacks actionable steps, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the method\\'s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. However, the comment does not specify which part of the paper these questions relate to, such as the experimental results or the method description. This lack of grounding makes it difficult for the authors to identify the exact sections needing attention. The comment is specific in its questions, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method\\'s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples, references, or detailed explanations, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions about the method's ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. While the comment identifies areas for improvement and raises valid concerns, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their draft. The feedback is somewhat helpful as it prompts the authors to consider additional aspects of their method, but it could be more actionable with more detailed advice or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not provide specific guidance or suggestions on how to address these issues. The authors are left without clear instructions on what changes to make or how to improve their draft. The lack of actionable details makes it difficult for the authors to know how to proceed, leaving the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"confusing mistakes in the proof of the main results\" and \"lacks a detailed discussion and comparison with previous work.\" However, it does not specify which part of the paper these issues are found in, making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, the comment lacks specificity regarding the nature of the confusing mistakes or the aspects of the discussion and comparison that are lacking. This makes the comment weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that there are \"confusing mistakes\" in the proof of the main results and that the paper lacks a detailed discussion and comparison with previous work. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two main issues: confusing mistakes in the proof of the main results and a lack of detailed discussion and comparison with previous work. However, it does not provide specific examples or detailed guidance on how to address these issues, leaving the authors without actionable feedback. While the comment highlights areas for improvement, it lacks depth and specificity, making it somewhat helpful. The authors are aware of the need to improve, but the feedback does not offer concrete steps or suggestions for making those improvements. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the unclear motivation for using an adversarial network in the model and the unfair comparison of experimental results due to the proposed model\\'s larger size. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns. The lack of actionable suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the motivation for using an adversarial network and the fairness of the experimental results comparison. It explicitly mentions the need for clarification regarding the use of the adversarial network and the unfairness of the comparison due to the proposed model\\'s larger size. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of motivation and fairness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two concerns: the motivation for using an adversarial network and the fairness of the experimental results comparison. The first claim is that the motivation is unclear, which is a subjective observation that requires the authors to provide more context or explanation. The second claim about the unfairness of the comparison is based on the size of the proposed model compared to others, which is a factual observation. However, the comment lacks specific examples or references to support the claim of unfairness, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper: the unclear motivation for using an adversarial network and the unfairness of the experimental results comparison. It points out that the comparison is biased due to the proposed model's larger size compared to others. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation. While it highlights important areas for improvement, the feedback is somewhat helpful as it provides a starting point for the authors to consider but does not offer detailed steps or examples for addressing these concerns. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two issues: the unclear motivation for using an adversarial network in the model and the unfairness of the experimental results comparison due to the proposed model\\'s larger size. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their motivation. The lack of actionable advice or detailed feedback makes it difficult for the authors to know how to proceed with their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the motivation for using an adversarial network in the model and the fairness of the experimental results comparison. It explicitly mentions the need for clarification regarding the use of the adversarial network and the unfairness of the comparison due to the proposed model\\'s larger size. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of motivation and fairness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two concerns: the motivation for using an adversarial network in the model and the fairness of the experimental results comparison. The first claim is subjective and lacks specific reasoning or examples to support the assertion that the motivation is unclear. The second claim about the unfairness of the comparison is based on the size of the proposed model compared to others, which is a factual observation. However, the comment does not provide detailed examples or references to substantiate the claim of unfairness, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the paper: the unclear motivation for using an adversarial network and the unfairness of the experimental results comparison. It points out that the comparison is biased due to the proposed model's larger size compared to others. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation. While it highlights important areas for improvement, the feedback is somewhat helpful as it provides a starting point for the authors to consider but does not offer detailed steps or examples for addressing these concerns. Therefore, the comment aligns with a score of 3.\", '"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue regarding the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or direction on what kind of adversarial loss should be used or how it should be implemented. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue is related to, such as a particular section, figure, or table. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity in terms of what needs to be addressed or how the issue could be resolved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is no adversarial loss to guarantee the perturbed data being similar to the authentic data. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the lack of an adversarial loss to ensure that the perturbed data remains similar to authentic data. This is a critical point that could significantly impact the effectiveness of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what kind of adversarial loss could be used. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details or actionable steps, such as recommending specific methods for tuning or suggesting ways to mitigate the variability in hyperparameters. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not specify which part of the paper discusses these hyperparameters or how they are tuned, making it weakly grounded. The comment is specific in identifying the issue of hyperparameter tuning and the potential variability in optimal hyperparameters, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the need to tune multiple hyperparameters and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, the comment lacks specific examples or detailed reasoning to support the claim about the variability in optimal hyperparameters. While it highlights a potential issue, it does not provide sufficient evidence or context to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks the depth needed for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical issue related to the tuning of multiple hyperparameters, such as step size, N, and delta t, which are essential for the optimization process. It raises a concern about the potential variability in optimal hyperparameters due to the sample-by-sample optimization, which is a valid point that could impact the robustness and generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing methods to mitigate the variability or suggesting ways to optimize the hyperparameters. While it highlights an important area for improvement, the feedback is somewhat helpful as it provides a direction for the authors to consider but does not offer detailed actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited number of methods used for performance comparison and the lack of consistency in the proposed method\\'s performance. It suggests that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. However, the comment does not explicitly instruct the authors to take any specific actions, such as suggesting which methods to include for comparison or how to analyze the inferior results. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance comparison and the consistency of the proposed method\\'s performance compared to other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. This provides clear guidance on what needs to be addressed, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than other methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s performance evaluation, noting that the comparison is limited to a few methods and that the proposed method is not consistently better than other methods. It suggests that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. This feedback is clear and actionable, as it directs the authors to address a critical weakness in their work by offering a specific suggestion for improvement. However, the comment could be more helpful if it provided additional guidance on how to conduct the analysis or which specific aspects of the results need further exploration. Overall, the comment is mostly helpful as it highlights a significant area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to compare the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. While the comment implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section where this comparison should be made. Additionally, the comment lacks specificity regarding what aspects of the support should be compared or how the comparison should be conducted. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests comparing the support of the solution obtained by the proposed scheme with that obtained by baseline methods, such as using a Jaccard index. However, the comment does not provide any reasoning, evidence, or references to support why this comparison would be interesting or beneficial. Without such justification, the claim remains unverifiable, as the authors may not understand the rationale behind the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests a potential comparison between the support of the solution obtained by the proposed scheme and that obtained by baseline methods, such as using a Jaccard index. This suggestion is somewhat helpful as it provides a direction for further analysis that could enhance the paper\\'s depth and comprehensiveness. However, the comment lacks specificity and does not offer detailed guidance on how to conduct this comparison or what aspects should be considered. To be more helpful, the comment could include more detailed suggestions or examples of how to implement the comparison. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It raises a question about whether the current work is merely an extension or introduces novel contributions. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and vague, as the authors are left to infer that they need to demonstrate originality or differentiate their work from the previous study. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not specify which part of the paper these similarities are found in, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in questioning the originality of the work, but it lacks grounding as it does not point to specific sections or elements of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the article\\'s reasoning and writing logic bear similarities to a previous study, raising questions about the originality of the work. However, the comment does not provide specific examples or detailed comparisons to substantiate this claim. Without concrete evidence or references, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension or introduces novel contributions. This feedback is somewhat helpful as it highlights a potential issue that the authors should address. However, it lacks specific guidance or suggestions on how to differentiate the work or demonstrate originality. The comment could be more helpful with additional details or examples to help the authors understand how to address the concern. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension or introduces novel contributions. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern. The action is implicit and vague, as the authors are left to infer that they need to demonstrate originality or differentiate their work from the previous study. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. However, it does not specify which part of the paper these similarities are found in, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in questioning the originality of the work, but it lacks grounding as it does not point to specific sections or elements of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the article's reasoning and writing logic bear similarities to a previous study, raising questions about the originality of the work. However, the comment does not provide specific examples or detailed comparisons to substantiate this claim. Without concrete evidence or references, the authors may find it challenging to address the concern effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully support the assertion.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension or introduces novel contributions. This feedback is somewhat helpful as it highlights a potential issue that the authors should address. However, it lacks specific guidance or suggestions on how to differentiate the work or demonstrate originality. The comment could be more helpful with additional details or examples to help the authors understand how to address the concern. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the originality of the article, noting similarities in reasoning and writing logic to a previous study. It questions whether the current work is merely an extension or introduces novel contributions. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the very-long-term forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. While the comment implies that the authors should conduct additional experiments and adjust their baseline models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the very-long-term forecasting task being of limited practical significance and suggests improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments and adjust the baseline models, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the very-long-term forecasting task is of limited practical significance and suggests improving the discussion by conducting experiments on more datasets and training the baseline models with the \"correct\" forecast horizon. However, the comment does not provide specific examples or references to support the claim about the practical significance of the task. The suggestion to conduct additional experiments is a logical step, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the practical significance of the very-long-term forecasting task and suggests that the discussion could be improved by conducting experiments on more datasets and training the baseline models with the 'correct' forecast horizon. This feedback is somewhat helpful as it points out a specific area for improvement in the paper's discussion section. However, it could be more helpful if it provided additional guidance on how to conduct these experiments or what specific datasets and forecast horizons should be considered. Overall, the comment offers a direction for enhancing the paper's discussion, but it lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions, and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to perform these analyses or provide specific guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the need for these analyses and how to carry them out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the results section or discussion, but this inference is not explicit. The comment is specific in detailing what additional analyses could be conducted to enhance the paper, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors. However, the comment does not provide specific examples or references to support the claim that these approaches are indeed superior. The suggestion is vague and lacks detailed reasoning or evidence, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and why deterministic MLP predictors outperform more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is valuable as it points out a potential area for deeper investigation that could enhance the paper\\'s contribution and understanding of the results. However, the comment lacks specific guidance on how to conduct these analyses or what aspects to focus on, which limits its usefulness. While it identifies a meaningful direction for improvement, the lack of detailed suggestions makes it somewhat helpful, as it provides a general direction but not a comprehensive roadmap for the authors to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of analysis of the security (privacy protection) of the proposed framework. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting specific aspects of security to consider or methods for analysis. Without concrete instructions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific area of concern regarding the security (privacy protection) of the proposed framework. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors can infer that it relates to the security or privacy aspects of the framework, the comment lacks full grounding. It is specific in identifying the issue of security analysis but does not provide detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not analyze the security (privacy protection) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of analysis of the security (privacy protection) of the proposed framework. This is a critical area that the authors should address to ensure the robustness and credibility of their work. However, the comment does not provide any specific guidance or suggestions on how to conduct this analysis or what aspects of security should be considered. While it highlights an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the multi-scale statement, suggesting that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the multi-scale statement or provide a more accurate explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the multi-scale statement, specifically pointing out that the slow and fast RNN operate on the logical time scale rather than the physical time scale. This provides a clear and specific critique of the statement, allowing the authors to identify the part of the paper being discussed. The comment also specifies the issue with the multi-scale statement, namely the reduction in gradient path by the slow RNN. This level of detail makes the comment fully grounded and specific, as it clearly identifies the part of the paper being addressed and what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the multi-scale statement is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer provides a logical explanation by clarifying that the stacks are sequentialized in the graph, which supports the claim. However, the comment lacks specific references or examples to further substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the explanation to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the multi-scale statement, pointing out that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. This feedback is somewhat helpful as it identifies a specific area of confusion or misinterpretation in the paper. However, it lacks depth and does not provide actionable suggestions on how the authors might address this issue or clarify the multi-scale statement. The comment could be more helpful with additional guidance or examples to help the authors improve their draft. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the multi-scale statement, pointing out that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the multi-scale statement or provide a more accurate explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the multi-scale statement, specifically pointing out that the slow and fast RNN operate on the logical time scale, not the physical time scale. This provides a clear and specific critique of the statement, allowing the authors to identify the part of the paper being discussed. The comment also specifies the issue with the multi-scale statement, namely the reduction in gradient path by the slow RNN. This level of detail makes the comment fully grounded and specific, as it clearly identifies the part of the paper being addressed and what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the multi-scale statement is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer provides a logical explanation by clarifying that the stacks are sequentialized in the graph, which supports the claim. However, the comment lacks specific references or examples to further substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the explanation to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the multi-scale statement, pointing out that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and raw-level features, while the former framework (Line 167-174, Sec. 4) does not seem limited to raw-level selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment implies that the authors should consider representation learning in their feature selection, it does not provide explicit guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their feature selection. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the proposed invariant learning module focuses on mask selection and raw-level features, while the former framework does not seem limited to raw-level selection. Additionally, it mentions a discussion about representation learning in the appendix, suggesting that the feature selection could be improved by considering representation learning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed invariant learning module focuses on mask selection and raw-level features, while the former framework does not seem limited to raw-level selection. It also mentions a discussion about representation learning in the appendix, suggesting that the feature selection could be improved by considering representation learning. While the comment provides some context and suggests an area for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of representation learning in the appendix provides some context, but it does not offer a comprehensive explanation or justification for the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires more detailed evidence or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and raw-level features, while the former framework does not seem limited to raw-level selection. It also mentions a discussion about representation learning in the appendix, suggesting that the feature selection could be further improved by considering representation learning. While the comment highlights a gap in the current framework and provides a direction for improvement, it lacks specific suggestions or guidance on how to implement this improvement. The authors are left with a general understanding of what needs to be addressed but without detailed steps or examples. Therefore, the comment is somewhat helpful, as it points out an area for enhancement but does not fully support the authors in making the necessary changes.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of ensuring that the paraphrases generated for the training data are significantly different from the original sentences. It explains that this is crucial because the model relies on the quality of these paraphrases, and if the difference is not large enough, the final training data quality will be low, leading to a small number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide specific guidance on how to address it, such as suggesting methods to ensure significant differences or how to measure this difference. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of generating paraphrases for the training data, specifically mentioning the need for these paraphrases to be significantly different from the original sentences. This provides some grounding as it refers to a specific aspect of the paper, but it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the importance of the paraphrases and their impact on the model\\'s reliance on quality data. However, it lacks detailed guidance on how to address the issue, such as suggesting methods to ensure significant differences. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of paraphrases used for training data, noting that the difference between paraphrases and original sentences is crucial. It explains that if the difference is not significant, the quality of the final training data will be low, leading to a small number of pairs being added to the new training data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the impact of paraphrase quality on the model\\'s reliance on quality data. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue regarding the generation of paraphrases for the training data, emphasizing the importance of ensuring that the paraphrases are significantly different from the original sentences. This is crucial because the model relies on the quality of these paraphrases, and if they are not sufficiently distinct, the final training data quality will be compromised. The comment highlights the potential impact of this issue on the model's performance and the subsequent discarding process. However, it lacks specific suggestions or guidance on how to address this problem, such as methods to ensure significant differences or how to measure this difference. While it points out a significant area for improvement, the feedback could be more actionable with detailed advice. Therefore, the comment is somewhat helpful, as it provides insight into a critical aspect but lacks comprehensive guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should further verify the effectiveness and universality of the Flipped-QA framework to non-LLM-based models like HiTeA and InternVideo. While the comment implies that the authors should expand their analysis to include these models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the Flipped-QA framework should be further verified for its effectiveness and universality to non-LLM-based models like HiTeA and InternVideo. However, it does not specify which part of the paper discusses the Flipped-QA framework or how it is currently applied to LLM-based models. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its suggestion to expand the analysis to non-LLM-based models, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the Flipped-QA framework should be further verified for its effectiveness and universality to non-LLM-based models like HiTeA and InternVideo. The reviewer provides a logical reasoning by stating that the framework is a general approach for various generative VideoQA models, but the authors have only applied it to LLM-based models. This implies that the framework's applicability and effectiveness should be tested on other models as well. However, the comment lacks specific examples or references to support the claim that HiTeA and InternVideo are suitable models for this framework. While the suggestion is reasonable, it could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the suggestion but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's scope, suggesting that the Flipped-QA framework should be further verified for its effectiveness and universality to non-LLM-based models like HiTeA and InternVideo. This feedback is valuable as it encourages the authors to expand their analysis and consider a broader range of models, which could enhance the applicability and impact of their work. However, the comment could be more helpful if it provided specific suggestions on how to conduct this verification or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their approach. The reviewer is willing to improve their score if the authors can address these concerns. While the comment implies an action, it does not provide explicit guidance on how to address the lack of novelty or theoretical contribution. The authors are left to infer that they need to provide more detailed explanations or evidence of novelty, but the comment lacks concrete steps or examples. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical novelty of the proposed method, noting that it primarily builds upon existing methods such as Clopper-Pearson intervals and Gaussian elimination. It suggests that the authors should address this concern by providing a more detailed explanation or addressing the novelty of their approach. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction or methodology sections, making it weakly grounded. The comment is specific in identifying the lack of theoretical novelty and suggesting a potential area for improvement, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks significant theoretical novelty, primarily because it builds upon existing methods such as Clopper-Pearson intervals and Gaussian elimination. The reviewer provides references to specific works by Clopper and Pearson, as well as Golub and Van Loan, which support the claim. This provides a clear and detailed basis for the claim, making it fully verifiable. The references to external works and the specific methods mentioned offer a robust foundation for the critique, allowing the authors to understand the basis of the concern and how to address it. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that it primarily builds upon existing methods such as Clopper-Pearson intervals and Gaussian elimination, lacking significant theoretical novelty. The reviewer is willing to improve their score if the authors can address this concern. While the comment highlights a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a critical area for improvement but lacks detailed actionable advice, leaving the authors to infer the necessary steps themselves. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the text input is concatenated by the four text elements of an object. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this question or what steps they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether the text input is concatenated by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context being addressed. Without specific grounding, the authors cannot confidently determine where to find this information or how to address the question. The comment is specific in its inquiry but lacks grounding, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question seeking clarification about the concatenation of text input with four text elements of an object. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether the text input is concatenated by the four text elements of an object. While it identifies a potential area for clarification, it does not provide any context, reasoning, or suggestions on why this is important or how it might impact the paper. Without additional guidance or explanation, the authors are left without actionable feedback on how to address this issue. Therefore, the comment is barely helpful, as it lacks depth and specificity, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, which implies that the authors should clarify why the presented topic is important or relevant. However, the comment does not specify what aspects of the motivation should be improved or how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer explanation of the importance of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper could improve by providing a better motivation for the \"Why\" aspect, implying that the authors should clarify why the presented topic is important or relevant. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to improve the motivation, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could improve by providing better motivation for the \"Why\" aspect, implying that the authors should clarify why the presented topic is important or relevant. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the paper could improve by providing better motivation for the \"Why\" aspect, implying that the authors should clarify why the presented topic is important or relevant. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to enhance the motivation or what aspects of the \"Why\" should be addressed. This limits the usefulness of the feedback for the authors, as it does not offer actionable steps or examples to improve the draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the action is explicit, it is somewhat vague because it does not specify which aspects of the C2D method should be tested or how the experiments should be designed. The authors are aware of the need for additional experiments but may need to infer the details of what is expected. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments on a particular dataset, which provides some guidance on what could be improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper. Without detailed justification or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is somewhat helpful as it identifies a specific area where the authors could enhance the robustness and applicability of their findings. However, the comment lacks detailed guidance on how to design these experiments or what specific results should be expected. To be more helpful, the comment could include suggestions on how to structure the experiments or what metrics to use to evaluate the C2D method. Overall, the feedback provides a direction for improvement but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details or examples of what specific visualizations or comparisons are needed, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the need for more visualization, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The comment identifies a specific area for improvement, namely the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any guidance or suggestions on how the authors might address this issue, such as recommending specific types of visualizations or comparisons that could be included. Without actionable advice, the comment is vague and does not offer the authors a clear path to improve their draft. Therefore, it is barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the importance of the results and questions the novelty of the findings. It references a previous work, [15], which claims that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer notes that this makes the decentralized algorithm with occasional noise expected to escape saddle points in polynomial time. Additionally, the comment points out that the iteration complexity in Theorem 3 is no longer dimension-free due to a $d$ dependency instead of $log d$. While the comment highlights potential issues, it does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their results. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to respond. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the concerns about the importance of the results, referencing a previous work, [15], and pointing out the change in iteration complexity from dimension-free to $d$ dependency. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the importance of the results and the novelty of the findings. It references a previous work, [15], which claims that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer notes that this makes the decentralized algorithm with occasional noise expected to escape saddle points in polynomial time. However, the comment does not provide specific examples or detailed reasoning to support the claim that the results are not surprising or that the iteration complexity is no longer dimension-free. The lack of detailed evidence or references makes it difficult for the authors to fully understand and address the concerns raised. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises concerns about the importance and novelty of the results presented in the paper. It references a previous work, [15], which claims that perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer notes that this makes the decentralized algorithm with occasional noise expected to escape saddle points in polynomial time. Additionally, the comment points out that the iteration complexity in Theorem 3 is no longer dimension-free due to a $d$ dependency instead of $log d$. While the comment identifies potential issues with the novelty and importance of the results, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback provides some insight into the perceived lack of novelty but does not offer actionable steps for the authors to enhance their work. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices and emphasizes the importance of addressing this issue. It suggests that the authors should consider this aspect and potentially revisit the rating if the issue is resolved. While the comment highlights a critical area for improvement, it does not provide explicit guidance on how to address the sensitivity or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the sensitivity of their results and potentially adjust their rating if the issue is resolved. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sensitivity of the empirical results to hyperparameter choices, which is a critical aspect of the study. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the importance of addressing this issue, as it could potentially affect the validity of the results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a valid concern in any study. However, the comment does not provide specific examples or detailed reasoning to support why this issue is particularly critical or how it could affect the study\\'s validity. The mention of \"conceivably\" suggests that the reviewer is speculating on the potential impact, which makes the claim somewhat verifiable. The authors would need to provide more detailed evidence or examples to fully address this concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, which is a common issue in machine learning studies. It highlights the potential impact of incorrect hyperparameter choices on the validity of the results, emphasizing the importance of addressing this aspect. The comment is specific in its suggestion that the authors should consider the sensitivity of their results and potentially revisit their rating if the issue is resolved. This feedback is actionable and provides a clear direction for the authors to improve their study, making it mostly helpful. However, it could be more helpful if it offered specific guidance on how to assess and address the sensitivity of the results. Overall, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to clarify the novelty and contribution of their proposed method by addressing the similarity to existing attack methods on a surrogate model. While the comment implies that the authors should provide a more detailed explanation of the novelty, it does not explicitly instruct them to do so or provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors can infer the need for clarification but may not know exactly how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of existing attack methods on a surrogate model and suggests that the novelty and contribution of the proposed method should be clarified. However, it does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity in detailing what aspects of the novelty or contribution should be clarified. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work utilizes existing attack methods on a surrogate model and suggests that the novelty and contribution of the proposed method should be clarified. However, the comment does not provide specific examples or references to existing work that the authors should compare their method against. This lack of detailed evidence or examples makes it difficult for the authors to understand the basis of the claim and how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty and contribution of the proposed method, noting that it utilizes existing attack methods on a surrogate model. It suggests that the authors need to clarify the novelty and contribution of their work by addressing the similarity to existing methods. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how the authors might demonstrate the novelty of their approach. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed advice on how to address it, leaving the authors with a general direction to explore. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the experiment, specifically the reliance on pseudo feature importance due to the absence of true feature importance. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The reviewer provides a specific suggestion to strengthen the experiment by considering the difference between the tested method and the pseudo feature importance. However, the comment does not explicitly instruct the authors to implement these suggestions or provide detailed guidance on how to do so. While the action is implicit, it is concrete and provides clear direction for improvement. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"one experiment\" and \"Prop 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the reliance on pseudo feature importance and the need for a stronger experiment. The comment provides clear guidance on how to strengthen the experiment by addressing the difference between the tested method and the pseudo feature importance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment is difficult to trust because the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer provides a logical reasoning by mentioning the reliance on Prop 3.2 and the need for a large enough perturbation value to ensure the correctness of the pseudo feature importance. However, the comment lacks specific examples or references to support the claim about the difficulty in trusting the experiment. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experiment, noting that the use of pseudo feature importance due to the absence of true feature importance makes it difficult to trust the results. It suggests that the experiment could be strengthened by addressing the correctness of the pseudo feature importance and the difference between the tested method and the pseudo feature importance. The comment provides clear and actionable feedback, offering a specific direction for improvement by suggesting ways to strengthen the experiment. This level of detail and guidance is valuable for the authors, making the comment highly helpful. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that non-convexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue or what specific properties of function Z are relevant. The comment lacks actionable details, leaving the authors uncertain about how to incorporate this feedback into their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ln. 182--184,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion about the potential non-convexity issue and its relation to the convergence of SGD. The comment specifies that the function Z should have certain good properties to mitigate this issue, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that non-convexity may not be an issue for the SGD to converge if the function Z has certain good properties. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide examples or references to substantiate why these properties would make non-convexity less of an issue. Without additional context or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the non-convexity of the function Z, suggesting that it may not be a concern for the SGD to converge. However, it lacks specificity and does not provide any guidance on how the authors might address this issue or what specific properties of function Z are relevant. Without actionable advice or detailed suggestions, the comment does not offer the authors a clear path to improve their draft. As a result, it is rated as barely helpful, as it provides some insight but does not fully support the authors in enhancing their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue regarding the experimental settings, specifically noting that the results are not reproducible due to missing code. It explicitly instructs the authors to provide the code, which is a clear and direct action. This feedback is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of experimental settings and result reproducibility, specifically mentioning that the results are not reproducible due to missing code. However, it does not specify which part of the paper discusses the experimental settings or results, making it weakly grounded. The comment is specific in identifying the need for code to ensure reproducibility, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly and that result reproducibility is critical using the provided information. However, it does not provide specific examples or detailed reasoning to support why the experimental settings are not mentioned properly or how the lack of code impacts reproducibility. The comment lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental settings, specifically noting that the results are not reproducible due to missing code. This feedback is clear and actionable, as it directly points out a significant weakness in the paper that needs to be addressed. By highlighting the need for code to ensure reproducibility, the comment provides a clear direction for improvement. However, it could be more helpful if it offered suggestions on how to provide the code or where to include it in the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the claim that the experimental results across various language pairs and domains prove the effectiveness of the proposed prompts. It specifically questions the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their claim. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 6 and Table 7,' allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it critiques the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in these tables supports the effectiveness of the proposed prompts. The comment provides a clear direction for the authors to consider, namely, whether the slight improvement is sufficient to substantiate the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 supports the effectiveness of the proposed prompts. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this critique. Without additional context or justification, the claim remains unverifiable, as the authors may not fully understand the basis of the critique. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the claim that the experimental results across various language pairs and domains prove the effectiveness of the proposed prompts. It specifically questions the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7, suggesting that this improvement may not be sufficient to support the claim. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their claim. While it identifies a potential weakness, it lacks actionable feedback, making it somewhat helpful. The authors are left with a clear area for improvement but without detailed guidance on how to enhance their draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment critiques the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 supports the effectiveness of the proposed prompts. However, it does not provide any explicit or implicit actions for the authors to take to address this critique. Without actionable steps or suggestions, the authors are left without a clear path forward. The comment lacks specificity and does not offer guidance on how to strengthen the claim or improve the experimental results. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Table 6 and Table 7,' allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it critiques the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in these tables supports the effectiveness of the proposed prompts. The comment provides a clear direction for the authors to consider, namely, whether the slight improvement is sufficient to substantiate the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 supports the effectiveness of the proposed prompts. However, the comment lacks supporting evidence, reasoning, or examples to substantiate this critique. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the claim remains unverifiable, as it does not provide sufficient information for the authors to address the issue effectively. This aligns with a score of 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the claim that the slight improvement observed in ChatGPT compared to ChatGPT+DSP in Tables 6 and 7 supports the effectiveness of the proposed prompts. It questions the sufficiency of this improvement to substantiate the claim, suggesting that the authors need to provide a stronger justification. However, the comment does not offer specific suggestions or guidance on how the authors might strengthen their claim or address the critique. Without actionable feedback or detailed advice, the comment provides some insight but lacks practical value for the authors. Therefore, it is somewhat helpful, aligning"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the analysis of the Cycle FC align feature is insufficient and implies that there could be various designs of this feature. It provides a specific suggestion by mentioning experiments or analysis with different sampling intervals and sample sizes. However, the comment does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to improve the analysis. While the action is implied, it lacks concrete details on how to implement the suggested changes, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis of the Cycle FC align feature, suggesting that the analysis is insufficient and could be improved by considering different designs, such as experiments with varying sampling intervals and sample sizes. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in suggesting areas for improvement, such as considering different sampling intervals and sample sizes, which provides clear guidance on what the authors need to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the analysis of the Cycle FC align feature is insufficient and implies that there could be various designs of this feature. However, it does not provide specific examples or references to support the claim that the analysis is insufficient or that there are multiple designs. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the analysis of the Cycle FC align feature, suggesting that the analysis could be more comprehensive by considering different designs and experimental conditions, such as varying sampling intervals and sample sizes. This feedback is somewhat helpful as it points out a specific aspect of the analysis that could be expanded upon, providing a direction for the authors to enhance their work. However, the comment could be more helpful if it included specific suggestions or examples of how to conduct these experiments or analyses. Overall, the feedback is somewhat helpful as it highlights an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point is explicit in its request for clarification regarding the feature extractor used for the dimensionality of each region, which is specified as 512. This is a clear and direct action for the authors to take, as it prompts them to provide the specific feature extractor used in their work. The comment is concrete, as it specifies exactly what information is needed to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of the feature extractor used for the dimensionality of each region. This provides clear guidance on what information is missing and how it should be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the feature extractor used for a specific dimensionality. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual question seeking additional information, which is a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment is clear and actionable, as it explicitly requests clarification on the feature extractor used for the dimensionality of each region, which is specified as 512. This feedback is valuable because it prompts the authors to provide additional details that could enhance the transparency and reproducibility of their work. By addressing this question, the authors can improve the clarity and completeness of their methodology section, making the paper more accessible to readers. However, the comment could be more helpful if it suggested specific feature extractors that might be relevant or provided examples of similar studies that have used similar approaches. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not explicitly instruct them to do so or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors need to infer that they should provide a more detailed explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its suggestion to provide a clearer explanation, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the motivation for applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the motivation for applying CMD in federated learning, suggesting that it could benefit from a more explicit demonstration or explanation. While the comment highlights a specific area for improvement, it lacks depth and does not provide detailed guidance or suggestions on how to address this issue. The authors are left with a general understanding of what needs clarification but are not given actionable steps to take. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain, suggesting that comparisons to UNets are necessary. The reviewer implies that the authors should include comparisons to UNets to clarify the performance boost. While the comment explicitly states that comparisons to UNets are necessary, it does not provide specific guidance on how to conduct these comparisons or what aspects to focus on. The action is implicit but concrete, as the authors know what needs to be done to address the concern. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"complex UNet part after the fractional transform,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain and suggests that comparisons to UNets are necessary to clarify the performance boost. The comment provides a clear rationale for why such comparisons are important, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the complexity of the CoNO model, specifically the use of a UNet part after the fractional transform. It questions the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain and suggests that comparisons to UNets are necessary to clarify the performance boost. The comment provides a logical reasoning by comparing the UNet operation to pointwise multiplication as done in FNOs, which is a common practice in the field. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to conduct further research or experimentation to fully address the concern, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the CoNO model, specifically questioning the contribution of the fractional transform versus the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are necessary to clarify the performance boost. This feedback is clear and actionable, as it provides a specific area for the authors to address to improve the clarity and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to conduct these comparisons or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the contribution of the paper may be marginal because the methods used are well-designed and demonstrated. It questions the necessity of adding another stream for low-resolution data, implying that this might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not provide explicit guidance or suggestions on how the authors could address this concern or improve their contribution. The action is implicit and vague, as the authors are left to infer that they might need to reconsider the contribution or provide a stronger argument for its significance. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment suggests that the contribution of the paper may be marginal because the methods used are well-designed and demonstrated, and adding another stream for low-resolution data might not be a significant contribution for a top-tier venue like ICLR. However, it does not specify which part of the paper this assessment is based on, nor does it provide detailed feedback on what aspects of the contribution are marginal or how they could be improved. The lack of grounding and specificity makes it difficult for the authors to identify the exact parts of the paper that need attention or improvement. Therefore, this comment is not grounded and not specific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the contribution of the paper is marginal because the methods used are well-designed and demonstrated, and adding another stream for low-resolution data might not be a significant contribution for a top-tier venue like ICLR. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate why the addition of another stream would not be a significant contribution. Without additional context or justification, the claim remains unverifiable, as it does not provide the authors with a clear understanding of how to address the concern or improve their contribution. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the contribution of the paper may be marginal because the methods used are well-designed and demonstrated, and adding another stream for low-resolution data might not be a significant contribution for a top-tier venue like ICLR. While the comment identifies a potential issue with the contribution, it lacks specificity and actionable guidance. It does not provide the authors with insights on how to strengthen their contribution or address the concern about the marginality of the contribution. The feedback is vague and does not offer detailed suggestions for improvement, making it barely helpful. Therefore, the comment aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not include any explicit or implicit actions for the authors to take. The comment mentions that the reviewer did not carefully read additional experiments described in the Appendix due to time constraints, but this does not provide any guidance or suggestions for improvement. As a result, the authors are left without any actionable steps to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not specify which parts of the paper are being addressed or what specific issues are being discussed. The mention of \"additional experiments described in the Appendix\" provides some context, but it does not allow the authors to pinpoint the exact sections or elements being discussed. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not contain any claims, opinions, or suggestions that require verification. It is a statement of appreciation and does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not offer any specific feedback or suggestions for improvement, nor does it highlight any particular areas that need attention or clarification. The comment lacks actionable guidance or insights that could help the authors enhance their draft. As a result, the feedback is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the active learning method used in step 2, specifically whether it aligns with traditional active learning that selects informative samples for labeling. While the comment highlights a potential issue with the description, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify or correct the description of the active learning method. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"step 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether the \"active learning pipeline\" method is the same as traditional active learning that selects informative samples for labeling. This provides clear guidance on what aspect of the description needs clarification or correction. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the active learning method used in step 2, specifically whether it aligns with traditional active learning that selects informative samples for labeling. The comment does not contain any subjective claims or opinions, making it a factual statement. It does not require verification as it is a question seeking clarification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the active learning method used in step 2, specifically whether it aligns with traditional active learning that selects informative samples for labeling. This feedback is valuable as it prompts the authors to clarify their methodology, ensuring that the readers understand the approach accurately. However, the comment could be more helpful if it provided additional context or suggestions on how to address the potential misinterpretation. Overall, the comment is somewhat helpful as it identifies an area for clarification but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It questions whether the same procedure is used as was used for baselines, noting that most baselines do not use this dataset. The reviewer suggests that this could provide an unfair advantage to the proposed method if it is used in all experiments. While the comment highlights a potential issue, it does not explicitly instruct the authors to clarify this point or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the experimental methodology. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'experimental methodology' and references the use of the 300W-LP dataset in the training process. It also specifies the issue by questioning whether the same procedure is used as was used for baselines and whether this could provide an unfair advantage to the proposed method. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be clarified. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It questions whether the same procedure is used as was used for baselines, noting that most baselines do not use this dataset in their training. The reviewer suggests that this could provide an unfair advantage to the proposed method if it is used in all experiments. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that most baselines do not use the 300W-LP dataset. This makes the claim somewhat verifiable, as the authors would need to investigate further to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the clarity of the experimental methodology, specifically regarding the use of the 300W-LP dataset. It points out a discrepancy in the paper's claims, questioning whether the same procedure is used as was used for baselines, noting that most baselines do not use this dataset. This observation is important as it could affect the fairness and comparability of the results. The comment provides a clear and actionable suggestion for the authors to clarify whether the 300W-LP dataset is used in all experiments or just some, which could significantly impact the interpretation of the results. By addressing this issue, the authors can enhance the transparency and validity of their experimental setup. Therefore, the comment is rated as highly helpful, as it identifies a critical area for improvement and provides clear guidance on how to address it.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some aspects of the algorithm may not be novel, specifically mentioning computation offloading and gradient augmentation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address these concerns or what specific changes they should make to their draft. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of how to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, it does not specify which part of the paper discusses these techniques or where they are applied, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of these techniques are not novel or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some aspects of the algorithm, such as computation offloading and gradient augmentation, may not be novel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of some techniques used in the algorithm, specifically mentioning computation offloading and gradient augmentation. However, it lacks specificity and does not provide any further details or suggestions on how the authors might address this concern. Without actionable feedback or guidance, the comment does not offer the authors a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides an understanding of the integral in Equation (1) as a bag observation model or spatial aggregation process. It highlights a potential issue with the authors\\' assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their formulation. The action is implicit and vague, as the authors are left to infer that they need to consider alternative aggregation methods. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation (1), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the formulation, suggesting that the observations might be aggregated by another procedure, such as simple summation or population weighted average. The comment provides a clear explanation of the potential discrepancy between the authors\\' assumption and the actual aggregation methods used in the data. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the integral in Equation (1) corresponds to a bag observation model or spatial aggregation process, referencing specific works. It then points out a potential issue with the authors\\' assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. The comment provides a logical reasoning based on the referenced works and the potential discrepancy in the aggregation method. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a detailed explanation of the integral in Equation (1), relating it to bag observation models or spatial aggregation processes. It highlights a potential issue with the authors' assumption that the observations are obtained by averaging over the corresponding support $v$, suggesting that the data might be aggregated by another procedure, such as simple summation or population weighted average. This feedback is valuable as it offers a deeper understanding of the mathematical formulation and encourages the authors to consider alternative aggregation methods. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or if it included examples of how these alternative methods might be applied. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks comprehensive guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\\' method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their analyses. The action is implicit and vague, as the authors are left to infer that they need to conduct more comprehensive analyses or provide a clearer explanation of their method\\'s performance. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\\' method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this inference is not explicit. The comment is specific in detailing the issue with the comprehensiveness of the analyses and the question regarding the performance improvement claim. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the authors\\' method underperforms the baseline in some instances. It questions the extent to which the performance improvement can be attributed to the authors\\' claim of moving code-switched pretraining from the word level to the sense level. However, the comment lacks specific examples or detailed reasoning to support the claim that the analyses are not comprehensive enough. The authors are left to infer that more detailed analyses are needed, but the comment does not provide explicit guidance or evidence to substantiate this claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's experimental analysis, noting that the majority of the experiments focus on presenting results rather than comprehensively analyzing the method itself and the experimental outcomes. It highlights a potential limitation in the paper's claims, questioning the extent to which the performance improvement brought by the pretraining method can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. This feedback is somewhat helpful as it points out a critical area for improvement in the paper's analysis and raises a valid concern about the authors' claims. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or enhance their analysis. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment does not explicitly instruct the authors to include these takeaways or provide detailed guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include more practical implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and suggests that the paper lacks practical implications, which is understandable given the novelty of the work. It also mentions a specific observation regarding querying a cluster proportionally to the square root of its size as a main take-away point. However, the comment does not specify which part of the paper discusses the theoretical results or where this observation is made, making it weakly grounded. The comment is specific in identifying the lack of practical implications and the potential take-away point, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the paper could benefit from more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment does not provide specific examples or references to support the claim that this observation is novel or unique to the paper. The reasoning is based on the reviewer\\'s perspective as an applied researcher, which adds some context but lacks detailed evidence or references. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but could be strengthened with more detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the paper could benefit from more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment lacks depth and does not provide specific guidance on how the authors might enhance the practical implications or present these takeaways. While it identifies a potential area for improvement, it does not offer actionable suggestions or detailed feedback, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is somewhat helpful, as it points out a potential weakness but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information they provide beyond T/I/O. While the comment implies that the authors should provide more context or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of introducing separators and asks for clarification on the additional information they provide beyond T/I/O. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information beyond T/I/O. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or what specific issues might arise. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, questioning the purpose and additional information provided by the introduction of \"separators\" in section 4. This feedback is clear and actionable, as it prompts the authors to clarify the role and significance of these elements in their work. By addressing this question, the authors can enhance the clarity and coherence of their paper, making the comment highly helpful. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or what additional information should be included. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific observation about the synthesized results for UCF-101, noting inconsistencies in motion, color, and object presence over time. It suggests that using videos with a longer duration, such as by running the LSTM over many time steps, could address these issues. While the comment implies that the authors should consider this approach, it does not explicitly instruct them to do so. The suggestion is concrete in terms of what could be done to improve the results, but the action is not directly stated. Therefore, the comment is somewhat actionable, as it provides a clear direction for improvement but lacks explicit guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"short video sequences\" and references the UCF-101 dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the synthesized results, noting inconsistencies in motion, color, and object presence over time. The suggestion to use videos with a longer duration by running the LSTM over many time steps provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the synthesized results for UCF-101 exhibit inconsistencies in motion, color, and object presence over time. It suggests that using videos with a longer duration could address these issues by running the LSTM over many time steps. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the inconsistencies. The suggestion is mostly verifiable as it offers a plausible solution but could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the synthesized results for the UCF-101 dataset, noting inconsistencies in motion, color, and object presence over time. It suggests that using videos with a longer duration, such as by running the LSTM over many time steps, could potentially address these issues. This feedback is clear and actionable, providing the authors with a concrete direction for improvement. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement this suggestion. Overall, the comment is mostly helpful as it offers a valuable insight and actionable advice, but it could be further enhanced with more detailed suggestions.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the method might affect insurance costs. The comment lacks both explicit and implicit actions, leaving the authors without any direction on how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of the method on insurance costs for men and women, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about insurance costs, but without grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the impact of the method on insurance costs for men and women. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest or concern, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the method might affect insurance costs. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it provides a starting point for the authors but does not offer comprehensive guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper\\'s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their categorization. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the paper\\'s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the discrepancy and providing an example, such as the BERT paper being available on arXiv from October. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper categorizes papers based on their publication years, but many papers are available on arXiv much earlier. This claim is somewhat verifiable as it provides a specific example, the BERT paper being available on arXiv from October, which supports the assertion. However, the comment lacks detailed reasoning or references to explain why this discrepancy is problematic or how it affects the paper\\'s analysis. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some support but requires further elaboration to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. It provides a specific example, mentioning the BERT paper being available on arXiv from October. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their categorization. While it highlights a potential problem, it lacks actionable feedback, making it somewhat helpful. The authors are aware of the issue but are left without clear steps to take to resolve it. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta. This raises a valid concern but does not provide explicit guidance on how the authors should address this issue. The second part of the comment asks for clarification on the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide a specific value of u to demonstrate the difference. While the second part is somewhat actionable, the first part lacks explicit guidance, making the overall comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the use of rejection sampling with an arbitrary parameter beta instead of importance sampling, and the differentiation between QRS and RS in Algorithm 1. The first part of the comment is fully grounded as it explicitly mentions the use of rejection sampling and the parameter beta, allowing the authors to accurately identify the part of the paper being addressed. The second part is also fully grounded, as it refers to Algorithm 1 and the specific elements QRS and RS. The comment is specific in detailing what needs to be addressed in each part, providing clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta. This raises a logical question but lacks specific reasoning or evidence to support the claim that importance sampling would be more appropriate. The second part of the comment points out a potential confusion in Algorithm 1 regarding the differentiation between QRS and RS, suggesting that the authors should provide a specific value of u to clarify the difference. While this part is somewhat verifiable, it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the overall comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two points for the authors to consider. First, it questions why the authors did not use importance sampling instead of rejection sampling with an arbitrary parameter beta, suggesting that importance sampling might be a more appropriate choice. This raises a valid concern about the methodology and could prompt the authors to reconsider their approach. Second, the comment points out a potential confusion in Algorithm 1 regarding the differentiation between QRS and RS, asking the authors to clarify this by providing a specific value of u. This feedback is somewhat helpful as it identifies areas for improvement and suggests specific actions for the authors to take, but it could be more helpful with additional guidance or examples. Overall, the comment provides some actionable insights but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" in line 285, specifically asking if \"chunk\" is still considered sequential information. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the meaning of \"non-sequential information\" and \"chunks\" in their draft. However, the comment lacks concrete details on how to resolve the confusion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"non-sequential information such as chunks,\" questioning whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific phrase in the text, \"non-sequential information such as chunks.\" It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the phrase \"non-sequential information such as chunks\" in line 285, asking whether \"chunk\" is still considered sequential information. This feedback is clear and actionable, as it prompts the authors to clarify the meaning of this phrase, which could potentially improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address the confusion. Overall, the comment is somewhat helpful as it identifies a potential area of ambiguity but lacks depth in its guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the current paper are similar to those in the previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the technical novelty of their work. The action is implicit and vague, as the authors are left to infer that they need to differentiate their work from the previous papers, but the comment does not offer concrete steps on how to achieve this. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the limited technical novelty of the paper by comparing it to previous works by Xing and Tsang (2022a, b). It suggests that the idea, co-attention mechanism, and architecture of the current paper are similar to those in the previous works. However, the comment does not specify which part of the paper these comparisons are based on, making it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity in detailing what aspects of the paper need to be improved to address the issue of limited technical novelty. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks technical novelty by comparing it to previous works by Xing and Tsang (2022a, b). However, the comment does not provide specific examples or detailed reasoning to support the claim that the idea, co-attention mechanism, and architecture are similar to those in the previous works. Without additional context or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's technical novelty by comparing it to previous works by Xing and Tsang (2022a, b). It highlights that the idea, co-attention mechanism, and architecture of the current paper are quite similar to those in the previous works. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks specific suggestions or guidance on how the authors might differentiate their work or enhance its novelty. The comment could be more helpful if it provided actionable advice or examples of how to address the issue of limited technical novelty. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the problem addressed in the paper is specific to binding affinity prediction or applies to other downstream tasks. While the comment implies that the authors should clarify this distinction, it does not provide explicit guidance on how to address this issue or what specific actions should be taken. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed explanation of the problem\\'s scope. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the problem addressed in the paper to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors may have to infer that it relates to the methodology or results sections where the problem is discussed. While the comment is specific in its inquiry about the scope of the problem, it lacks grounding as it does not explicitly mention a section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification about the applicability of the problem addressed in the paper to other downstream tasks or if it is specific to binding affinity prediction. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the problem addressed in the paper to other downstream tasks or if it is specific to binding affinity prediction. While this question is relevant and could prompt the authors to clarify their work's scope, the comment lacks actionable feedback or suggestions on how to address this issue. It does not provide guidance on how to improve the draft or what specific aspects should be considered when discussing the problem\\'s applicability. As a result, the comment is barely helpful, as it identifies a potential area for clarification but does not offer actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison in terms of computation cost or running time, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to consider. Without any actionable advice or suggestions, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in asking about the comparison of computation cost or running time, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the comparison in terms of computation cost or running time. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison in terms of computation cost or running time, which is a relevant aspect for the authors to consider. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison they should focus on. Without actionable advice or detailed feedback, the comment is somewhat helpful as it prompts the authors to consider a potential area for improvement but does not fully support their efforts to enhance the draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the necessity of having a column header as a separate type. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify or simplify the division of tables. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3\" and \"line 247-252,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of having a column header as a separate type in the tables, providing a clear direction for the authors to consider revising their approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the division of tables into three types, specifically questioning the necessity of having a column header as a separate type. However, it does not provide any supporting evidence, reasoning, or examples to justify this concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 3 regarding the division of tables into three types, questioning the necessity of having a column header as a separate type. While it raises a valid point, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this concern. It does not offer alternative approaches or improvements that could enhance the clarity or organization of the tables. As a result, the feedback is somewhat helpful, as it highlights a potential area for improvement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the task described in the paper is more akin to Argument Mining than Summarization and recommends that the paper clarify the differences between the task and Argument Mining/Discussion Summarization. While the comment implies that the authors should address this clarification, it does not provide explicit instructions on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the differences, but they are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the task described in the paper is more akin to Argument Mining than Summarization and recommends further clarification of the differences against Argument Mining/Discussion Summarization. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or discussion. This makes it difficult for the authors to identify the exact area that needs clarification. Additionally, the comment is specific in its suggestion to clarify the differences, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the task described in the paper is more akin to Argument Mining than Summarization and recommends further clarification of the differences against Argument Mining/Discussion Summarization. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the task is closer to Argument Mining or why clarification is necessary. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential misalignment between the task described in the paper and the field of Summarization, suggesting that it might be more akin to Argument Mining. It provides a clear and actionable suggestion for the authors to clarify the differences between their task and Argument Mining/Discussion Summarization. This feedback is valuable as it guides the authors in refining their understanding and presentation of their work, helping them to better position their contribution within the existing literature. However, the comment could be more helpful if it offered specific examples or references to support the claim or suggested ways to address the differences. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded for maximum benefit.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the definition of the sparsity of the residual term and suggests that it includes many zero elements. It also requests evidence to support the sparsity assumption across various noisy cases. Additionally, the comment implies that it is necessary to demonstrate the advantages of the proposed method compared to existing methods. While the comment does not explicitly instruct the authors to provide specific evidence or comparisons, the actions are clear and can be inferred from the feedback. The authors know what needs to be addressed and how to improve their draft by providing the requested evidence and comparisons. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the clarity of the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption across various noisy cases. It also suggests that it is necessary to show the advantages of the proposed method compared to existing methods. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the definition of sparsity or the assumptions of the proposed method. The comment is specific in detailing what needs to be addressed, such as providing evidence for the sparsity assumption and demonstrating the advantages of the proposed method. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption across various noisy cases. It also suggests that it is necessary to show the advantages of the proposed method compared to existing methods. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the definition is unclear. The request for evidence and comparison with existing methods provides some direction but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding the definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests providing evidence to support the sparsity assumption across various noisy cases. Additionally, the comment implies that it is necessary to demonstrate the advantages of the proposed method compared to existing methods. While the comment highlights a potential area of improvement, it lacks detailed guidance on how to address these issues or specific examples of what evidence or comparisons might be needed. The feedback is somewhat helpful as it points out a specific area for clarification but could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific issue with the clarity of the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption across various noisy cases. It also suggests that it is necessary to demonstrate the advantages of the proposed method compared to existing methods. While the comment does not explicitly instruct the authors to provide specific evidence or comparisons, the actions are clear and can be inferred from the feedback. The authors know what needs to be addressed and how to improve their draft by providing the requested evidence and comparisons. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the clarity of the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption across various noisy cases. It also suggests that it is necessary to show the advantages of the proposed method compared to existing methods. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the definition of sparsity or the assumptions of the proposed method. The comment is specific in detailing what needs to be addressed, such as providing evidence for the sparsity assumption and demonstrating the advantages of the proposed method. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption across various noisy cases. It also suggests that it is necessary to show the advantages of the proposed method compared to existing methods. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the definition is unclear. The request for evidence and comparison with existing methods provides some direction but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViT-tiny or small. Additionally, the reviewer asks if there is a foreseeable challenge to experiment on language tasks. While the comment provides specific suggestions for improvement, it does not explicitly instruct the authors to make these changes or address the questions. The actions are implicit and somewhat vague, as the authors need to infer the need for these changes and how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViT-tiny or small. It also raises a question about the possibility of experimenting on language tasks. However, the comment does not specify which part of the paper discusses the models and datasets, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed regarding the models and datasets, as well as the potential for language task experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViT-tiny or small. The reviewer also asks if there is a foreseeable challenge to experiment on language tasks. While the comment provides a logical basis for the suggestions, it lacks specific references or examples to fully substantiate the claims. The reasoning is somewhat supported by the suggestion to include more challenging datasets, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets like CIFAR100 and ResNet 34 or 50, as well as ViT-tiny or small. Additionally, the reviewer raises a question about the possibility of experimenting on language tasks. While the comment provides specific suggestions for improvement, it does not fully address the potential challenges or provide detailed guidance on how to implement these changes. The feedback is somewhat helpful as it highlights areas for enhancement but lacks depth and actionable steps, leaving the authors with a general sense of what needs to be improved.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of comparison against baselines in the paper, specifically mentioning the absence of baselines in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or codesearch tasks. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include baseline comparisons to enhance the comprehensiveness of their study, but the comment lacks concrete details on which specific baselines to consider or how to implement them. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of baseline comparisons, noting that many papers have developed architecture-agnostic similarity comparison or codesearch tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison against baselines, which is a widely understood binary analysis application. It references other papers that have developed architecture-agnostic similarity comparison or codesearch tasks, providing a logical basis for the claim. However, the comment could be strengthened by providing specific examples or references to these papers, which would enhance its verifiability. Overall, the comment is mostly verifiable as it offers a reasonable basis for the claim but lacks detailed references or examples to fully substantiate it. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of baseline comparisons in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or codesearch tasks. This feedback is valuable as it directs the authors' attention to an important aspect that could enhance the comprehensiveness and relevance of their study. However, the comment could be more helpful if it provided specific suggestions on which baselines to consider or how to incorporate them into the study. Overall, the comment is mostly helpful as it offers a clear direction for improvement but lacks detailed guidance, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses dissatisfaction with the contribution of the paper, stating that it is not enough. It acknowledges the importance of addressing the overfitting problem with limited data and proposes differentiable augmentation as a solution. However, the comment lacks specificity and does not provide any actionable guidance on how the authors might enhance their contribution or what specific aspects need improvement. The feedback is vague and does not offer concrete suggestions for addressing the perceived limitations, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses dissatisfaction with the contribution of the paper, stating that it is not enough. It acknowledges the importance of addressing the overfitting problem with limited data and proposes differentiable augmentation as a solution. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs improvement. Additionally, the comment lacks specificity in detailing what aspects of the contribution are insufficient or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution of the paper is not enough, suggesting that the paper addresses the overfitting problem with limited data and proposes differentiable augmentation as a solution. However, the comment lacks specific evidence, examples, or references to support the claim that the contribution is insufficient. Without detailed reasoning or references to comparable work, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses dissatisfaction with the contribution of the paper, stating that it is not enough. It acknowledges the importance of addressing the overfitting problem with limited data and proposes differentiable augmentation as a solution. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance their contribution or address the perceived limitations. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer actionable advice for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they mention that normalizing the input makes the results from Theorem 1 inapplicable. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this problem or what changes they should make to their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the contradiction or the applicability of Theorem 1. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the proof relies on a special case where a contradiction arises as matrix norms approach infinity, and that this is acknowledged in Section 3. The comment is specific in detailing what needs to be addressed, providing clear guidance on the issue with the proof technique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. This claim is somewhat verifiable as it provides a specific observation about the proof technique and references a section where this issue is acknowledged. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the proof to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also acknowledges that this is mentioned in Section 3, where the authors mention that normalizing the input makes the results from Theorem 1 inapplicable. This feedback is somewhat helpful as it highlights a potential weakness in the proof and provides a reference to where the issue is discussed. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or provide additional context to better understand the implications. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also states that allowing \"t\" to be arbitrary does not add value. This feedback is explicit and provides a clear action for the authors to take, which is to make the suggested change for clarity. The comment is concrete, as it specifies what needs to be done and why it is beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"histogram intersection kernel,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests replacing \"t\" with the size of T for clarity and explains that allowing \"t\" to be arbitrary does not add value. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It claims that allowing \"t\" to be arbitrary does not add value. However, the comment lacks specific reasoning or examples to support why this change would improve clarity or why allowing \"t\" to be arbitrary is unnecessary. Without detailed justification or references, the claim is difficult for the authors to understand and address. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by replacing \"t\" with the size of T. It also critiques the practice of allowing \"t\" to be arbitrary, stating that it does not add value. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and precision of their work. By addressing this suggestion, the authors can improve the comprehensibility of their draft, making the comment mostly helpful. However, it could be more helpful if it provided additional context or examples to further support the claim. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the possibility of assuming a general Gaussian distribution instead of an isotropic Gaussian in the proposed algorithm. It also asks about the difference between the two. While the comment highlights an area for consideration, it does not provide explicit guidance or suggestions on how the authors should address this question or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of assuming a general Gaussian distribution and compare it to the isotropic Gaussian. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. The comment is specific in its inquiry about the difference between the two distributions, but without clear grounding, it is challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the assumption of a general Gaussian distribution versus an isotropic Gaussian in the proposed algorithm. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the algorithm could be affected by this assumption. The comment lacks actionable feedback or detailed insights that could help the authors improve their draft. As a result, it is barely helpful, as it does not offer meaningful direction for the authors to enhance their work.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this issue or improve the section. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the intent of Section 5.2, but it does not specify which part of the paper this section is located in. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in questioning the intent of the section, but without clear grounding, it is challenging for the authors to understand the context or what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the intent of Section 5.2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, which is a valid inquiry that could help the authors clarify their objectives and structure their discussion. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the section. It lacks actionable feedback or specific advice, leaving the authors without a clear path forward. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable guidance.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It highlights that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not provide specific guidance on how the authors should address this issue or improve their approach. The feedback lacks actionable details, such as suggesting alternative methods or strategies for enhancing the accuracy of the surrogate model. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed approach, suggesting that it is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM. It highlights the need for careful selection of basis functions, meshes, and stiffness matrix assembly, and mentions that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method description. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed approach is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It also suggests that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. The comment provides some logical reasoning by comparing the proposed approach to specialized numerical solvers and operator learning methods. However, it lacks specific examples or references to support the claim about the accuracy of operator learning methods compared to specialized numerical solvers. This makes the claim somewhat verifiable, as it provides a general idea but could benefit from more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the proposed approach, suggesting that it is essentially learning a surrogate model for solving linear/linearized systems of equations in FEM, which still requires careful selection of basis functions, meshes, and stiffness matrix assembly. It highlights that current operator learning methods are not yet as accurate as specialized numerical solvers but are more universal. While the comment points out a relevant issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve their approach. The feedback is somewhat helpful as it provides a direction for potential improvement but does not offer detailed actionable advice, leaving the authors with a general understanding of what needs to be addressed but without clear steps to take. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the paper\\'s focus on single-token cloze queries or multi-token ones, noting that this is not clearly explained until the conclusion. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between single-token and multi-token queries in the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"single-token cloze queries\" and \"multi-token ones,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of clarity until the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about the paper\\'s focus on single-token cloze queries or multi-token ones, noting that this is not clearly explained until the conclusion. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim of confusion. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the distinction between single-token cloze queries and multi-token ones. It notes that this clarification is not clearly explained until the conclusion, which could be confusing for readers. While the comment highlights an important issue, it does not provide specific suggestions or guidance on how the authors might clarify this distinction in their draft. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction on how to address the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address the reproducibility issue or what steps they should take to ensure their results are reproducible. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft in this regard. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the results section. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding the reproducibility issue, as it does not provide details on what aspects of the results are difficult to reproduce or how the code could be made more accessible. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. However, it does not provide any supporting evidence, reasoning, or examples to justify why the results are difficult to reproduce or why the code's availability is crucial. Without additional context or explanation, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the reproducibility of the results, specifically asking if the code will be publicly available. While it identifies a potential issue, it lacks depth and does not provide any suggestions or guidance on how the authors might address this concern or improve the reproducibility of their results. Without actionable feedback or specific recommendations, the comment does not offer meaningful assistance to the authors in enhancing their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the technical contribution or differentiate their work from existing methods. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the similarity between $kNN-ECD$ and $kNN-MT$, suggesting that the technical contribution of the paper is limited. However, it does not specify which part of the paper discusses these methods or how they are compared, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in terms of what aspects of the methods or contributions need to be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the technical contribution of the paper is limited because the proposed method, $kNN-ECD$, is very similar to another method, $kNN-MT$. This feedback identifies a potential issue with the novelty of the work, which is important for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might enhance the technical contribution or differentiate their work from existing methods. Without actionable advice or detailed feedback, the authors are left with a general understanding of the problem but without clear steps to improve their draft. Therefore, the comment is somewhat helpful, as it highlights a significant area for improvement but does not provide enough detail to be fully actionable.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding the number of parameters used in each approach in Section B.3. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting that they clarify this point or provide specific details. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the number of parameters used in each approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the number of parameters used in each approach, specifically in Section B.3. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual statement seeking additional information, which does not fit the criteria for a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the lack of clarity regarding the number of parameters used in each approach, particularly in Section B.3. This feedback is valuable as it highlights a potential issue that could affect the understanding of the paper by readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of the presentation. While it points out a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the statistical significance of the evaluation results reported in Table 1, which are based on only three trials for each case. It suggests that reporting deviations is not justified due to the lack of statistical significance. The reviewer provides a clear explanation of why the reported deviations are not meaningful and questions the validity of statements comparing the performance to the next best baseline. However, the comment does not provide specific guidance on how the authors should address this issue, such as suggesting additional trials or statistical analysis. While the action is implied, it lacks concrete details on how to implement the suggested changes, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation results, noting that the reported deviations are not statistically significant due to the limited number of trials. The comment further explains why statements comparing performance to the next best baseline are not meaningful, providing a clear rationale for the critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation results reported in Table 1 are based on only three trials for each case, which is statistically not significant. The reviewer suggests that reporting deviations is not justified due to the lack of statistical significance, questioning the validity of statements comparing performance to the next best baseline. While the comment provides a logical reasoning for the claim, it lacks specific references or examples to fully substantiate the argument. The suggestion to report deviations is not fully supported by evidence or detailed reasoning, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the evaluation results reported in Table 1, noting that the results are based on only three trials for each case, which is statistically not significant. The reviewer points out that reporting deviations is not justified due to the lack of statistical significance, questioning the validity of statements comparing the performance to the next best baseline. This feedback is clear and actionable, as it highlights a critical flaw in the evaluation process and provides a specific suggestion for improvement. By addressing this issue, the authors can enhance the credibility and robustness of their results. However, the comment could be more helpful if it offered suggestions on how to conduct a more statistically sound evaluation or provided alternative methods for reporting results. Overall, the comment is mostly helpful, as it effectively guides the authors towards improving their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include detailed experimental results to address the concern. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. It suggests that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, while the comment specifies the need for detailed experimental results, it does not provide specific guidance on what aspects of the results should be detailed or how they should be presented. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment lacks specific examples or detailed reasoning to support the claim that the scaling law is not applicable in the context of dense retrieval models. The reference to Ni et al. provides some context, but the comment does not explain why the scaling law should not apply or how the experimental results should be detailed. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks sufficient detail to fully support the argument.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. While the comment identifies a potential weakness in the paper's findings, it lacks specific guidance on how to present or interpret these results. The feedback is somewhat helpful as it points out an area for improvement but does not offer detailed suggestions or examples to help the authors address the concern effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might investigate this issue or what steps they should consider. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the Greek language, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a request for information, expressing interest in understanding whether other multilingual pretraining setups also struggle with Greek. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. While it identifies a potential area of concern, it does not provide any specific guidance or suggestions for the authors to address this issue. The comment lacks actionable feedback or detailed insights that could help the authors improve their work. As a result, it is barely helpful, as it provides a general direction for further exploration but does not offer concrete steps or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. While the comment implies that the current setup might be limiting, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should consider extending the model to multiple vehicles, but it lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable, as it prompts the authors to consider a potential extension but does not provide specific steps or suggestions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not specify which part of the paper this question pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about scalability, but without clear grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scalability of the approach, specifically asking if it is easy to extend the model to multiple trucks and drones. However, it does not provide any supporting evidence, reasoning, or examples to justify why this might be a concern or how it could be addressed. The comment lacks specific details or references that would help the authors understand the implications of this question or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the need for an extension to multiple vehicles.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent question about the scalability of the approach, specifically asking if it is feasible to extend the model to multiple trucks and drones. This feedback is valuable as it challenges the authors to consider the practical implications of their work and suggests a direction for potential future research. However, the comment does not provide specific guidance or suggestions on how to address this issue, such as potential methodologies or frameworks that could be used for scalability. While it prompts the authors to think about broader applicability, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with Equation 8, suggesting that subtracting s from the dynamic information may lead to the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a way to mitigate the loss of dynamic information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation 8, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with Equation 8, specifically noting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in the equation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that subtracting s from the dynamic information in Equation 8 may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a logical explanation or references to substantiate the assertion that subtracting s would lead to the loss of dynamic information. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This feedback is somewhat helpful as it points out a specific area where the authors might need to reconsider their approach. However, the comment lacks depth and does not provide actionable suggestions or guidance on how to address this issue. The authors are left to infer that they need to find a way to mitigate the loss of dynamic information, but the comment does not offer concrete steps or alternatives. Therefore, the comment is somewhat helpful, as it highlights a potential problem but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a potential issue with Equation 8, suggesting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to find a way to mitigate the loss of dynamic information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Equation 8, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with Equation 8, specifically noting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This provides clear guidance on what needs to be addressed in the equation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that subtracting s from the dynamic information in Equation 8 may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the assertion remains vague and difficult for the authors to address effectively. The lack of detailed explanation or references makes it challenging for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with Equation 8, specifically noting that subtracting s from the dynamic information may result in the loss of some dynamic information, making it difficult for the LSTM module to capture the complete dynamic changes. This feedback is somewhat helpful as it points out a specific area where the authors might need to reconsider their approach. However, the comment lacks depth and does not provide actionable suggestions or guidance on how to address this issue. The authors are left to infer that they need to find a way to mitigate the loss of dynamic information, but the comment does not offer concrete"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not provide any explicit or implicit actions for the authors to take. The questions are open-ended and do not offer guidance on how the authors should address these issues in their draft. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. However, it does not specify which part of the paper these questions relate to, such as a particular section, figure, or experiment. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its questions about the impact of MC samples and network structure, but without clear grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions asking about the impact of the number of MC samples on performance and the influence of network structure on this aspect. These questions are factual inquiries seeking clarification and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions about the impact of the number of MC samples on performance and the influence of network structure on this aspect. While these questions are relevant and could help the authors explore important factors affecting their results, they do not provide specific guidance or suggestions on how to address these issues in the draft. The feedback lacks actionable advice or detailed insights that would enable the authors to improve their work. As a result, the comment is somewhat helpful, as it identifies areas for further exploration but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a mixed usage of notations for $\\\\hat{Y}$ and $Y$ in Section 2. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to clarify the notations, reorganize the section, or provide a consistent notation throughout the paper. Without specific instructions or examples, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notations of $\\\\hat{Y}$ and $Y$ being used in a mixed way in Section 2. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notations, allowing the authors to understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issue and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the notations of $\\\\hat{Y}$ and $Y$ being used in a mixed way in Section 2. This is a clear and actionable feedback that highlights a potential source of confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a consistent notation or providing a clearer explanation. While it points out a problem, it lacks depth and specificity, making it somewhat helpful. The authors are given a direction to improve, but the feedback could be more comprehensive with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not provide better results compared to previous theoretical results. However, the comment does not offer any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue or improve their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, stating that it does not provide better results compared to previous theoretical results. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the metric perspective analysis, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not provide better results compared to previous theoretical results. However, the comment lacks specific examples or detailed reasoning to support the claim that the metric perspective analysis is not better. The reference to Bartlett et al. (2017) provides some context, but it does not substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks detailed evidence or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, suggesting that it does not provide better results compared to previous theoretical results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their work. While it points out a potential weakness, it does not offer actionable feedback or detailed advice on how to enhance the paper. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential confusion in notation, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they should clarify the notation or provide a consistent explanation for the use of \"r\" in different contexts. However, the lack of specific instructions or suggestions makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is somewhat actionable, as it highlights a potential issue but lacks concrete guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation used in the paper, noting that the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems is confusing. This provides full grounding as it explicitly mentions the specific part of the paper being addressed, allowing the authors to accurately identify the issue. The comment is also specific because it clearly specifies the confusion caused by the inconsistent use of \"r.\" Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems is confusing. This is a subjective observation that lacks specific examples or references to support the claim. The comment does not provide detailed reasoning or evidence to substantiate why this notation is confusing, making it difficult for the authors to understand and address the issue. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with notation, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This observation highlights a potential source of confusion for readers, which is an important point for the authors to address. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this issue or improve the notation. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful. The authors are aware of the issue but may need to seek additional guidance to effectively address it. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment does not explicitly instruct the authors to remove or modify these claims, nor does it provide specific guidance on how to demonstrate the benefits. The action is implicit and somewhat vague, as the authors can infer the need for demonstration but lack concrete steps on how to achieve it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. However, the comment does not specify which part of the paper these claims are made in, making it weakly grounded. The comment is specific in its critique of the claims and suggests a direction for improvement, but without explicit grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. While the comment provides a logical argument questioning the desirability of sparsity, it lacks specific examples or references to support the claim. The suggestion to demonstrate the benefits or provide evidence of cost savings is a reasonable request, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence of practical cost savings. This feedback is mostly helpful as it identifies a potential weakness in the paper's claims and offers a clear direction for improvement. However, the comment could be more helpful if it provided specific suggestions on how to demonstrate the benefits or evidence of cost savings. Overall, the comment is mostly helpful, as it guides the authors towards a more robust argumentation and evidence presentation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate that the geometry of the space is meaningful, such as whether certain operations on the vectors result in semantically coherent outcomes. While the comment implies that the authors should conduct such an analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence of the meaningfulness of the space. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaningfulness of the vector space resulting from the morphfitting process, specifically asking if the geometry of the space is meaningful. It suggests that the authors should provide evidence or analysis to demonstrate the meaningfulness of the space, such as whether certain operations on the vectors result in semantically coherent outcomes. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in its request for evidence or analysis to support the meaningfulness of the space. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate the meaningfulness of the space, such as whether certain operations on the vectors result in semantically coherent outcomes. However, the comment does not provide specific examples or references to support the claim that the geometry of the space is meaningful. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient support or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a critical question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate that the geometry of the space is meaningful, such as whether certain operations on the vectors result in semantically coherent outcomes. This feedback is valuable as it prompts the authors to consider the interpretability and utility of their results, which is essential for understanding the implications of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this analysis. Overall, the comment is mostly helpful as it directs the authors to an important area for further exploration and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. While the comment implies that the authors should explore these areas, it does not provide explicit guidance on how to identify or measure these improvements. The action is somewhat implicit and lacks concrete details on how to execute the suggested exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in suggesting areas for improvement, such as accuracy and modeling sequential relationships, but without explicit references to sections or figures, the authors may struggle to pinpoint where these suggestions apply. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these specific properties might be more relevant or why they should be prioritized over FLOPs or inference time. Without additional context or references, the claim lacks verifiability, making it difficult for the authors to understand and address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. This feedback is somewhat helpful as it provides a direction for the authors to explore alternative areas for improvement beyond FLOPs and inference time. However, the comment lacks specificity and does not offer detailed guidance on how to measure or evaluate these properties. To be more helpful, the comment could include examples of specific properties to consider or methods for assessing them. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for the authors but could be more comprehensive.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. While the comment implies that the authors should explore these areas, it does not provide explicit guidance on how to identify or measure these improvements. The action is somewhat implicit and lacks concrete details on how to execute the suggested exploration. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in suggesting areas for improvement, such as accuracy and modeling sequential relationships, but without explicit references to sections or figures, the authors may struggle to pinpoint where these suggestions apply. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. However, the comment lacks specific reasoning or evidence to support why these properties might be more relevant or why they should be prioritized over FLOPs or inference time. Without additional context or references, the suggestion remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that if the authors did not find improvement in FLOPs or inference time, they should look for improvements in accuracy or specific properties, such as the ease of modeling sequential relationships with a recurrent model. This feedback provides a direction for the authors to explore alternative areas for improvement beyond FLOPs and inference time. However, the comment lacks specificity and does not offer detailed guidance on how to measure or evaluate these properties. To be more helpful, the comment could include examples of specific properties"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that it is unclear how the authors arrived at the different components of the \"scoring function\" and the threshold values/ranges. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting specific steps to clarify or provide additional details. Without actionable guidance, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the clarity of the \"scoring function\" and the threshold values/ranges, but it does not specify which part of the paper this information is located in. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in detailing what is unclear, namely, the derivation of the components of the scoring function and the threshold values/ranges. However, without explicit grounding, the comment is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the clarity of the \"scoring function\" and the threshold values/ranges, but it does not provide any specific examples, references, or detailed reasoning to support the claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The comment identifies a specific area of confusion regarding the derivation of the components of the 'scoring function' and the threshold values/ranges. It highlights a gap in the paper's clarity, which is important for readers to understand the methodology and results. However, the comment does not provide any suggestions or guidance on how the authors might clarify these aspects, such as recommending specific sections to revisit or additional explanations. While it points out a potential weakness, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It also points out that the authors do not employ one-hot encoding for this dataset, which could negatively impact performance. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include more datasets with categorical features or employ one-hot encoding, but the comment lacks concrete steps or suggestions on how to implement these changes. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'Model Comparison' section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features and that the authors do not employ one-hot encoding for this dataset. This provides clear guidance on what needs to be addressed to improve the paper's contribution. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the dataset selection is inadequate for a paper that emphasizes a 'thorough' comparison of models on a 'wide range' of datasets. The reviewer supports this claim by noting that only one dataset has categorical features, which are generally more challenging for deep learning models, and that the authors do not employ one-hot encoding for this dataset. This lack of encoding could negatively impact performance for some models. The comment provides specific examples and reasoning to justify the claim, making it mostly verifiable. However, it could be strengthened by providing more detailed examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It points out that the authors do not employ one-hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it highlights a potential weakness in the paper's methodology and suggests a specific area for improvement. By addressing this issue, the authors can enhance the robustness and generalizability of their results. However, the comment could be more helpful if it provided additional guidance on how to incorporate one-hot encoding or other strategies to handle categorical features. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to a critical aspect of their work that needs attention.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses dissatisfaction with the choice of two IoT datasets, suggesting that they are unpopular and not well-suited for benchmarking. It implies that the authors should have considered better options, such as wearable health or mobile activity recognition data, or datasets from the UCI repository. However, the comment does not provide explicit guidance on how to make these changes or which specific datasets to consider. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their dataset choices, but they are left without concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of IoT datasets, noting that they are unpopular and not well-suited for benchmarking. The reviewer suggests alternative datasets, such as wearable health or mobile activity recognition data, or sets from the UCI repository, providing clear guidance on what the authors should consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the choice of two IoT datasets is \"unpopular\" and \"weird,\" suggesting that the datasets are not well-suited for benchmarking. The reviewer provides reasoning by noting that the FlatCam Face dataset is relatively recent but not substantially followed, and the Head-pose detection dataset was published in 2004 and is no longer widely used. This provides some logical reasoning for the claim, but it lacks specific examples or references to support the assertion that these datasets are not suitable for benchmarking. The suggestion to consider better options, such as wearable health or mobile activity recognition data, adds some context but does not fully substantiate the initial claim. Therefore, the comment is somewhat verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of datasets in Section 4, specifically the two IoT datasets mentioned. It points out that these datasets are not widely used and suggests that the authors should have considered better options for benchmarking, such as wearable health or mobile activity recognition data. This feedback is somewhat helpful as it highlights a specific area for improvement in the paper, namely the choice of datasets for benchmarking. However, the comment could be more helpful if it provided specific examples or guidance on how to select better datasets or what criteria to consider when choosing datasets for benchmarking. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the regret bound for the proposed mini-batch method, stating that it is claimed to be in the appendix but not found in the supplementary material. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as whether they should clarify the location of the regret bound or provide it in the main text. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"regret bound for the mini-batch estimator,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of the regret bound in the supplementary material, despite the authors\\' claim that it is there. The comment provides a clear reference to a specific external work, \"Zalan Borsos, Andreas Krause, and Kfir Y Levy. Online Variance Reduction for Stochastic Optimization,\" which helps the authors understand the context of the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' claim about the regret bound for the mini-batch method being in the appendix is not supported by the supplementary material. The reviewer provides a specific reference, \"Zalan Borsos, Andreas Krause, and Kfir Y Levy. Online Variance Reduction for Stochastic Optimization,\" which could be used to verify the claim. However, the comment does not explicitly mention where in the supplementary material the regret bound is supposed to be found, which could make it more challenging for the authors to address the issue. Despite this, the reference to an external work provides some level of verification. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, noting that the authors claim the regret bound for the mini-batch method is in the appendix but the reviewer did not find it in the supplementary material. This is a clear and actionable feedback that highlights a potential oversight or error in the paper's organization. By pointing out this discrepancy, the comment provides the authors with a specific area to address, which could be the inclusion of the regret bound in the main text or clarification of its location. However, the comment could be more helpful if it suggested how the authors might resolve this issue or provided additional context on why this is a concern. Overall, the comment is mostly helpful as it directs the authors' attention to a critical oversight, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific weakness of the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed method or what specific changes should be made. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this comparison or where the authors should focus their efforts to address this weakness. The authors can infer that it relates to the comparison section or results, but the comment lacks explicit grounding. The specificity is limited because it does not provide detailed guidance on how to improve the performance or what specific aspects need to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as the main weakness of the method. However, the comment does not provide any supporting evidence, such as specific results or comparisons, to substantiate this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a valuable observation that highlights an area where the authors need to improve their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance their method. Without actionable feedback or detailed advice, the authors are left with a general understanding of the problem but no clear path to improvement. Therefore, the comment is somewhat helpful, as it points out a weakness but does not offer comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point presents a critique of the evaluation method used to assess the quality of \\u003c\\\\overline{\\\\Pi}\\\\u003e. It suggests that evaluating the performance in the worst MDP would be more appropriate than the current summation method, as it could reveal a more balanced assessment of the policies. However, the comment does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should change the evaluation method and understand the rationale behind it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"intuitive goal\" and the \"worst MDP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current evaluation method, suggesting that evaluating the performance in the worst MDP would be more appropriate. The comment provides a clear rationale for this suggestion, explaining why the summation method might be misleading and why the \\u003c\\\\min\\\\u003e operator would be more suitable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a critique of the evaluation method used to assess the quality of \\u003c\\\\overline{\\\\Pi}\\\\u003e. It suggests that evaluating the performance in the worst MDP would be more appropriate than the current summation method, as it could reveal a more balanced assessment of the policies. The comment provides a clear rationale for this suggestion, explaining why the summation method might be misleading and why the \\u003c\\\\min\\\\u003e operator would be more suitable. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the implications of this critique and consider the suggested change, which limits the level of verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a detailed critique of the evaluation method used to assess the quality of the set of policies, \\u003c\\\\overline{\\\\Pi}\\\\u003e. It suggests that evaluating the performance in the worst MDP would be more appropriate than the current summation method, as it could reveal a more balanced assessment of the policies. The comment offers a clear rationale for this suggestion, explaining why the summation method might be misleading and why the \\u003c\\\\min\\\\u003e operator would be more suitable. This feedback is highly actionable and provides the authors with a specific and detailed suggestion for improvement, allowing them to enhance the clarity and effectiveness of their evaluation method. Therefore, the comment is rated as highly helpful.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. While the comment implies that a more detailed analysis is needed, it does not explicitly instruct the authors to provide this information. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the extraction process, but the comment does not specify how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for clarification on how the parts of sentences and documents are extracted and whether the rules of extraction affect the experiment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on the extraction of parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. This feedback is somewhat helpful as it prompts the authors to clarify a potentially important aspect of their methodology. However, it lacks depth and does not provide specific guidance on how to address the issue or what aspects of the extraction process should be detailed. The authors are left with a general suggestion for improvement but without actionable steps to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the content in lines 107-114 is speculative or overly opinionated and suggests that it should be stated as a remark, an aside in the Discussion section, or removed. This provides a clear and direct action for the authors to take, specifying the exact changes needed to address the issue. The feedback is explicit and concrete, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107-114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the content, suggesting that it should be stated as a remark, an aside in the Discussion section, or removed. This provides clear guidance on how to address the concern, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the content in lines 107-114 is speculative or overly opinionated and suggests it should be stated as a remark, an aside in the Discussion section, or removed. However, the comment does not provide specific examples or reasoning to support why this content is speculative or opinionated, nor does it offer a detailed explanation of why it should be removed or rephrased. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the content in lines 107-114, noting that it seems speculative or overly opinionated. It provides actionable advice by suggesting that this content should be stated as a remark, an aside in the Discussion section, or removed. This feedback is clear and provides a direct way for the authors to improve their draft by addressing the speculative nature of the content. However, the comment could be more helpful if it offered additional guidance on how to rephrase or restructure the content to make it more appropriate for the Discussion section. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a clear solution, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether they should explain their choice, provide alternative distributions, or clarify the rationale behind their selection. Without specific suggestions or actions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, it does not specify which part of the paper discusses these distributions or provides context for the question. The authors might infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in its inquiry about the motivation behind the choice of distributions, but it lacks grounding as it does not point to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these distributions are unclear or inappropriate. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It questions the motivation behind this selection, which is a crucial aspect of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or specific recommendations, the comment is not helpful in guiding the authors towards enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on how the quantitative results are obtained, specifically questioning what data is used for training, validating, and testing. This request provides a clear and direct action for the authors to take, which is to provide more detailed information about the data used in their experiments. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"quantitative results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the data used for training, validating, and testing. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of how quantitative results are obtained, specifically asking for more detailed information about the data used for training, validating, and testing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the quantitative results are unclear. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity of the quantitative results in the paper. It questions the lack of detail on what data is used for training, validating, and testing, which is crucial information for understanding the methodology and reproducibility of the results. By pointing out this gap, the comment provides a clear and actionable suggestion for the authors to enhance the transparency and comprehensiveness of their work. However, it could be more helpful if it offered specific examples or guidance on how to improve the clarity of the data description. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly requests the authors to explain how the SE framework can help improve their work, similar to the previous comment. It suggests that the authors should provide a detailed explanation of why and how their framework is beneficial, rather than just showing what has been achieved. This feedback is clear and direct, providing a concrete action for the authors to take. The comment also includes a reference to a previous work, \"Neural architecture search with gBdt,\" which could serve as a model for the authors to follow. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SE framework\" and references a specific work, \"Neural architecture search with gBdt,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for a detailed explanation of how the SE framework can help improve the work, similar to the previous comment. The authors are given a clear direction on what needs to be addressed, making this comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the authors\\' explanation of how the SE framework can help improve their work, similar to the previous comment. It suggests that the authors should provide a detailed explanation of why and how their framework is beneficial, rather than just showing what has been achieved. The comment references a previous work, \"Neural architecture search with gBdt,\" which could serve as a model for the authors to follow. However, the comment does not provide specific examples or detailed reasoning to support the claim that the authors' explanation is insufficient. While the reference to \"Neural architecture search with gBdt\" offers some context, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies a specific area for improvement in the paper, namely the lack of explanation of how the SE framework can help improve the work. It provides a clear and actionable suggestion for the authors to explain the benefits and mechanisms of their framework, which is a valuable piece of feedback. However, the comment could be more helpful if it offered specific examples or detailed guidance on how to enhance the explanation. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or what steps they should consider to improve the generalizability of their approach. As a result, the authors are left without a clear understanding of what changes or additions are needed to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the approach are limited to two views or how the generalizability to more views could be improved. Without clear grounding and specific guidance, the authors cannot effectively address the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views without too much difficulty. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitation of the approach to two views, suggesting that the system should be able to generalize to more views without significant difficulty. This feedback is somewhat helpful as it points out a potential area for improvement in the generalizability of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or enhance the generalizability of their system. To be more helpful, the comment could provide examples of how other systems have successfully generalized to multiple views or offer suggestions on how to adapt the current approach to accommodate more views. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but does not fully guide the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It suggests that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. However, the comment does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative metrics or methods to address this limitation. Without specific guidance or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. However, the comment does not specify which part of the paper discusses these metrics or where they are used, making it weakly grounded. The comment is specific in identifying the limitations of the metrics, but without explicit references to the paper, the authors may struggle to pinpoint the exact sections needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning, specifically loss after switch and recovery time after switch, may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. This claim is somewhat verifiable as it provides a logical reasoning for the limitation, suggesting that the metrics might not be suitable in certain contexts. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to further explore the implications of this limitation to fully address the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the metrics of loss after switch and recovery time after switch. It points out that these metrics may not be applicable in settings where task boundaries are not known or where there are no hard task boundaries to be identified. This feedback is somewhat helpful as it highlights an important consideration for the authors to address when evaluating their results. However, the comment could be more helpful if it provided suggestions on alternative metrics or methods that could be used in such settings. Overall, the comment provides a useful insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific guidance on what aspects of the experimental setup need improvement or how to address these questions. The comment lacks explicit instructions or concrete details on how to enhance the experimental setup, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not specify which part of the paper these ablation experiments are discussed in, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestion that the experiments deserve better setup, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, the comment does not provide specific examples or reasoning to support why the current setup is inadequate or what improvements are needed. Without detailed justification or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific details or examples of what these questions are or how the experimental setup could be improved. This lack of specificity and actionable guidance makes it difficult for the authors to understand and address the feedback effectively. As a result, the comment is barely helpful, as it identifies a potential area for improvement but does not offer concrete suggestions or examples to guide the authors in making the necessary enhancements.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the error analysis on the movie dataset is missing, and it suggests that other researchers need to know which cases the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis on the movie dataset. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of an error analysis on the movie dataset to provide information on cases where the model fails. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a factual statement rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the draft could be improved, namely the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis for other researchers to understand the model\\'s performance and potential limitations. By pointing out this omission, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and utility of their work. However, it could be more helpful if it offered suggestions on how to conduct or present the error analysis. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out the absence of a separate part or subsection dedicated to introducing the inference strategy, specifically how to use multiple prompts in the test stage. This provides a clear and direct action for the authors to take, which is to include such a section or subsection in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a separate part or subsection dedicated to introducing the inference strategy, particularly how to use multiple prompts in the test stage. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach method lacks a separate part or subsection dedicated to introducing the inference strategy, specifically how to use multiple prompts in the test stage. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the absence of a separate part or subsection dedicated to introducing the inference strategy, particularly how to use multiple prompts in the test stage. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending the inclusion of such a section or subsection. By addressing this feedback, the authors can enhance the clarity and completeness of their approach, making the comment mostly helpful. However, it could be more helpful if it offered additional guidance on how to structure this section or what specific details should be included. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods. It suggests that more explanations could be provided. While the comment implies that the authors should offer additional explanations, it does not explicitly instruct them to do so or provide specific guidance on what aspects to explain. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like f-CLSWGAN and f-VAEGAN-D2. It suggests that more explanations could be given. However, the comment does not specify which part of the paper this issue is related to, such as the results section or the ablation experiments. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the explanations are needed or how they should be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like f-CLSWGAN and f-VAEGAN-D2. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the results are indeed lower than expected. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the low results obtained using only ML in the ablation experiments, comparing them to some simple early methods like f-CLSWGAN and f-VAEGAN-D2. It suggests that more explanations could be given, implying that the authors should provide additional context or analysis to address this issue. While the comment identifies a potential weakness in the results, it lacks specific guidance or suggestions on how to improve the explanations or address the low results. The feedback is somewhat helpful as it points out an area for improvement but does not offer detailed advice or actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be done, namely, to provide a detailed plan for addressing the limitations, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the limitations section of the paper, which is a specific part of the paper. It provides a clear suggestion for improvement by asking the authors to provide a more detailed plan on how they plan to address these limitations in their future work. This makes the comment fully grounded, as the authors can accurately identify the part of the paper being addressed, and it is specific in its request for a detailed plan. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not provide any specific examples or reasoning to support why this is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is clear and actionable, as it directs the authors to enhance their future work by offering a comprehensive strategy for addressing the identified limitations. However, the comment could be more helpful if it provided specific examples or guidance on what aspects of the limitations should be addressed or how to structure the plan. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar methods have been proposed for multi-task learning and suggests that they have not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"Similar methods have already been proposed for multi-task learning,\" but it does not specify which part of the paper this observation pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what specific aspects of the paper need to be addressed or how the authors should incorporate the mentioned methods. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that similar methods have been proposed for multi-task learning but are not discussed in the paper. However, it does not provide any specific examples or references to these methods, nor does it explain why their inclusion would be beneficial or relevant to the paper. Without detailed evidence or reasoning, the claim remains unverifiable, as the authors are left without a clear understanding of the basis for the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that similar methods have been proposed for multi-task learning but are not discussed in the paper. This observation highlights a potential gap in the literature review or discussion section, suggesting that the authors may need to include these methods to provide a comprehensive overview of the field. However, the comment does not provide specific guidance on which methods to include or how they should be integrated into the paper. While it identifies an area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion to conduct a comparison or provide details on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the methodology section or results. The authors may infer that it pertains to the comparison section, but this inference is not explicit. The comment is specific in questioning the computation cost, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their methodology to reduce computation cost. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take, such as suggesting a comparison or providing guidance on how to address this issue. Without actionable guidance, the authors are left uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the methodology or results sections. The authors may infer that it pertains to the comparison section, but this inference is not explicit. The comment is specific in questioning the computation cost, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their methodology to reduce computation cost. Without actionable feedback, the authors are left uncertain about what steps to take to enhance their draft. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take, such as suggesting a comparison or providing guidance on how to address this issue. Without actionable guidance, the authors are left uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the methodology or results sections. The authors may infer that it pertains to the comparison section, but this inference is not explicit. The comment is specific in questioning the computation cost,"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the comment provides a potential solution, it lacks explicit instructions on how the authors should implement this solution or address the confusing writing. The action is implicit and somewhat vague, as the authors need to infer the steps to take to resolve the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues (1) and (2) related to the use of a generic external knowledge base, as shown in Figure 3. This provides full grounding, as the authors can accurately identify the parts of the paper being addressed. The comment also specifies what needs to be addressed, namely the potential confusion in the writing, which is a clear and specific issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that issues 1) and 2) can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. However, it also notes that the writing is confusing, making it unclear whether this is indeed the case. While the suggestion is logical and supported by the reference to Figure 3, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the confusion. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues (1) and (2) that can be resolved by using a generic external knowledge base, as demonstrated in Figure 3. This provides a clear and actionable suggestion for improvement, offering a potential solution to the issues mentioned. However, the comment also notes that the writing is confusing, which is a separate issue that needs to be addressed. While the suggestion is helpful, the comment could be more comprehensive by providing specific examples or guidance on how to clarify the writing. Overall, the feedback is mostly helpful as it directs the authors to a potential solution for the issues identified, but it could be more detailed for full effectiveness. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the analysis in the paper is somewhat weak in light of theoretical work on sampling and particle-based optimization methods. It specifically mentions the lack of information regarding the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization in time and space. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more detailed analysis or references to support their claims, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not offer specific guidance on how to implement those improvements.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical work on sampling and particle-based optimization methods, specifically mentioning the lack of information regarding the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization in time and space. However, it does not explicitly mention which part of the paper this analysis is in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, providing clear guidance on the theoretical aspects that require further development. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the analysis is weak in light of theoretical work on sampling and particle-based optimization methods. It specifically mentions the lack of information regarding the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization in time and space. However, the comment does not provide specific references or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. Without additional context or examples, the authors may find it challenging to address the issues effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's analysis by pointing out that the theoretical work on sampling and particle-based optimization methods is not adequately addressed. It specifically mentions the lack of information regarding the existence and smoothness of the solution of SDE (2a)-(2d) and the guarantees of the discretization in time and space. This feedback is clear and actionable, as it highlights specific areas where the authors need to provide more detailed analysis or references to support their claims. By addressing these points, the authors can significantly improve the rigor and depth of their work. However, the comment could be more helpful if it provided additional guidance or suggestions on how to strengthen these aspects. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to critical areas for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting they provide the missing hyperparameters or clarify their implementation in the paper. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the model, noting that it has many components with unspecified hyperparameters. However, it does not specify which parts of the paper discuss these components or provide details on the hyperparameters. The authors can infer that the issue relates to the model description or implementation, but the comment lacks explicit grounding, making it weakly grounded. The comment is specific in identifying the need for more detailed information on hyperparameters, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model has many components with unspecified hyperparameters, which could be a challenge for someone trying to replicate the model. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the model, noting that it has many components with unspecified hyperparameters. This is a relevant observation that could impact the reproducibility and replicability of the model. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue, such as providing the missing hyperparameters or clarifying their implementation in the paper. Without actionable feedback, the comment provides some insight but does not fully support the authors in improving their draft. Therefore, it is rated as somewhat helpful, as it highlights a potential area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but the proposed method worked well. It also recommends showing failure cases and analyzing the limitations. While the comment provides specific suggestions on what to include, it does not explicitly instruct the authors to make these changes or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results and failure cases to provide a more comprehensive analysis of the proposed method. However, it does not specify which sections of the paper these should be included in, making it weakly grounded. The comment is specific in its suggestions, as it provides clear guidance on what additional information should be included to enhance the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results and failure cases to provide a more comprehensive analysis of the proposed method. However, it does not provide any specific examples, references, or reasoning to support why these additions would be beneficial or how they would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the rationale behind the suggestion, leaving the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that including qualitative results, possibly with zoomed-in views, for cases where previous methods failed but the proposed method worked well, would be beneficial. It also recommends showing failure cases and analyzing the limitations of the proposed method. This feedback is specific and actionable, providing clear guidance on how the authors can enhance their paper by demonstrating the effectiveness of their method in different scenarios. However, the comment could be more helpful if it included examples or detailed suggestions on how to present these results or analyses. Overall, the comment is mostly helpful as it offers valuable insights for improving the draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific steps they should follow to evaluate the interpretability tax. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the lack of evaluation of the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this evaluation should be included in, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but the comment lacks explicit grounding. The specificity is clear as it identifies a specific area for improvement, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks evaluation, namely the magnitude of the interpretability tax associated with the method. This is a valuable observation as it highlights a potential weakness in the paper's analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the interpretability tax should be evaluated. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While the comment explicitly states the need for training losses, it does not provide specific guidance on how to obtain or analyze these losses. The action is implicit, as the authors need to infer that they should include training losses in their analysis, but it is concrete because the direction is clear. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for training losses, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it might impact the results. Without such context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While it identifies a potential issue, it lacks specificity and does not provide guidance on how to address the concern or what aspects of the training process might be unstable. The request for training losses is a logical step to take, but without further elaboration, the comment remains somewhat helpful. The authors are given a direction to investigate, but the feedback could be more comprehensive and actionable. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment critiques the paper\\'s claim about the strength of the proposed BC loss, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their claims. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the paper\\'s claim about the strength of the proposed BC loss, specifically mentioning the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability. However, it does not specify which part of the paper these elements are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment provides some specificity by identifying the issues, it lacks full grounding as the authors cannot confidently determine the exact parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper overstates the strength of the proposed BC loss by suggesting that geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are essentially the same concept from different viewpoints. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks explicit references to the parts of the paper where these elements are discussed, making it difficult for the authors to address the critique effectively. Without detailed evidence or examples, the claim remains unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the paper's claim about the strength of the proposed BC loss, suggesting that the geometric interpretability, theorem 1, high/low entropy representations, and hard-negative mining ability are essentially the same concept from different viewpoints. This feedback is somewhat helpful as it identifies a potential overstatement in the paper's claims. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their claims. Without actionable advice or detailed feedback, the comment provides some insight but does not fully support the authors in enhancing their draft. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the relevance of the proposed method to the authors\\' motivations, specifically regarding the use of automatic scores and human evaluation scores. It suggests that the proposed framework, FFAEVAL, and similar systems like Chatbot Arena may not be suitable for evaluating a single dialogue system, such as providing a fluency score. However, the comment does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to reconsider the relevance of their method to their motivations and the evaluation systems used. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the relevance of the proposed method to the authors\\' motivations, specifically mentioning the use of automatic scores and human evaluation scores. It also questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. However, the comment does not specify which part of the paper discusses these aspects, making it weakly grounded. The authors can infer that it relates to the abstract section, but this inference is not explicit. The comment is specific in detailing the concerns about the relevance of the proposed method to the authors\\' motivations and the evaluation systems used. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the relevance of the proposed method to the authors\\' motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. However, the comment lacks specific examples or references to support the claim that these systems are not suitable for evaluating a single dialogue system. While the reviewer provides a logical argument based on the current state of evaluation systems, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the relevance of the proposed method to the authors' motivations, specifically regarding the use of automatic scores and human evaluation scores. It questions the applicability of the proposed framework, FFAEVAL, and similar systems like Chatbot Arena for evaluating a single dialogue system, such as providing a fluency score. The comment provides a logical argument based on the current state of evaluation systems, suggesting that these arena-based evaluation systems may not solve the problems of current score-based evaluation systems. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies a potential issue, it does not offer actionable steps or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks. While the comment highlights a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue or what alternative approaches they might consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the implications of using focal loss in regression tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks. However, the comment does not specify which part of the paper discusses the use of focal loss or the regression tasks, making it weakly grounded. The comment is specific in identifying the issue with the use of focal loss in regression tasks and the potential impact on accuracy. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks, which could lead to inaccurate results. However, the comment lacks specific examples or references to support the claim that focal loss is not suitable for regression tasks. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the use of focal loss in regression tasks and points out a potential issue with its application. It suggests that the authors may not have considered the difference between classification and regression tasks, which could lead to inaccurate results. While the comment identifies a potential area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or explore alternative approaches. The feedback is somewhat helpful as it highlights a potential weakness in the paper, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects of scalability they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. Without explicit references or detailed context, the authors may find it challenging to determine exactly where this issue is addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors should investigate this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. This is an important consideration for the authors to address, as it impacts the practical applicability and efficiency of their method. However, the comment does not provide any guidance or suggestions on how the authors might investigate or address this issue. It lacks actionable advice or specific directions for improvement, leaving the authors without a clear path forward. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to explore this possibility. As a result, the authors are left without a clear understanding of what actions to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper would benefit from this consideration or how it could be addressed. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. While it identifies a potential area for further exploration, it does not provide any specific guidance or suggestions on how the authors might investigate this question or what improvements might be expected. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to address the issue. Therefore, the comment is barely helpful, as it provides a starting point for consideration but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the paper does not provide information about the type of GPUs used and the inference time during testing. This feedback is clear and direct, instructing the authors to include this information in their draft. The action is explicit and concrete, as it specifies exactly what needs to be added to the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the absence of information about the type of GPUs used and the inference time during testing. However, it does not specify which part of the paper this information is missing, making it weakly grounded. The comment is specific in identifying the missing details, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not provide information about the type of GPUs used and the inference time during testing. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of information about the type of GPUs used and the inference time during testing. This is a critical piece of information that could impact the reproducibility and reliability of the results. By pointing out this omission, the comment provides clear and actionable feedback that would help the authors improve their draft. However, the comment could be more helpful if it suggested how to include this information or provided examples of how other papers have addressed similar issues. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image, rather than connecting with the Images Masked by Second Masks. This provides a clear and direct action for the authors to take, which is to correct the connections in the figure. The comment is explicit and concrete, as it specifies exactly what needs to be changed and how to implement the correction. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the connections in the figure, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, not the Images Masked by Second Masks. This provides clear guidance on what needs to be revised in the figure. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the connections in Figure 2 should be between the Second Inpainted Images and the Inpainted Image, not the Images Masked by Second Masks. This is a factual observation that does not require any supporting evidence or reasoning. It is a straightforward correction of a visual representation in the figure, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the connections in Figure 2, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, not the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific correction to make in their figure. By addressing this detail, the authors can improve the clarity and accuracy of their visual representation, enhancing the overall quality of their draft. However, the comment could be more helpful if it included additional guidance on why this correction is important or how it might impact the interpretation of the results. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should explore the potential impact of the method on their findings. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in its inquiry about the potential impact of the method on findings, but without grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that such a method might affect the findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). While the comment identifies a potential area for exploration, it lacks specific guidance or suggestions on how the authors might address this concern or what implications it might have for their results. The feedback is somewhat helpful as it prompts the authors to consider the impact of their choice of optimization method, but it does not provide actionable steps or detailed insights to enhance the draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). While the comment identifies a potential area for exploration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of the method on their findings. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in its inquiry about the potential impact of the method on findings, but without grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a question about the use of adaptive gradient methods instead of SGD and whether this method, which rescales gradient components, might affect the findings. It specifically inquires about the potential amplification of updates for weights associated with hard features (e.g., x2). However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that such a method might affect the findings. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.\","}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting additional experiments, updating the compared methods, or expanding the types of teacher architectures. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The mention of \"Tab.\" suggests that the issue might be related to a table, but it is not explicitly mentioned, leaving the authors without full grounding. The comment is specific in detailing the issues but lacks grounding, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are insufficient due to limited types of teacher architectures and outdated compared methods. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two specific issues with the experiments: the limited types of teacher architectures and the outdated nature of the compared methods. This feedback is somewhat helpful as it points out areas where the paper could be improved, but it lacks depth and does not provide actionable suggestions on how to address these issues. The authors are given a direction to consider expanding the types of teacher architectures or updating the compared methods, but without further guidance, the feedback remains incomplete. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not explicitly instruct the authors to conduct this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the comparison and understand how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or experiment. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in suggesting a comparison between different design approaches, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a comparison between sequential design and combinational design, implying that the proposed method performs better in pure combinational logic without registers. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or detailed explanation, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a comparison between sequential design and combinational design, implying that the proposed method may perform better in pure combinational logic without registers. This is a constructive suggestion that could help the authors explore the limitations and strengths of their method. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects to focus on. While it offers a potential direction for improvement, the feedback could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practicality of the paper\\'s approach, which is to use known causal relationships between features. It highlights that prior knowledge is not always available and might be inaccurate for specific subpopulations, leading most researchers to focus on mining causal relationships from data automatically. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of their work. The action is implicit and vague, as the authors are left to infer that they need to consider the limitations of prior knowledge and explore alternative approaches. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a concern about the practicality of using known causal relationships between features, as it acknowledges that prior knowledge is not always available and might be inaccurate for specific subpopulations. However, it does not specify which part of the paper discusses this approach or where the authors might need to address this concern. The authors can infer that it relates to the methodology or discussion sections, but the comment lacks explicit grounding. The specificity is limited because it does not provide detailed guidance on what aspects of the paper need to be revised or improved to address the concern about practicality. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about the practicality of using known causal relationships between features, noting that prior knowledge is not always available and might be inaccurate for specific subpopulations. The reviewer suggests that most researchers focus on mining causal relationships from data automatically. While the comment highlights a potential limitation, it does not provide specific examples or references to support the claim that prior knowledge is inaccurate or unavailable. The reasoning is based on general observations about the field, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's approach, which is the reliance on known causal relationships between features. It points out that prior knowledge is not always available and might be inaccurate for specific subpopulations, which is a common challenge in many fields. The reviewer suggests that most researchers focus on mining causal relationships from data automatically, implying that the proposed approach might be impractical. While the comment highlights an important consideration, it lacks specific suggestions or guidance on how the authors might address this issue or improve the practicality of their work. The feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly points out the absence of comparative experiments with non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2 in Section 4.3. It suggests that including these comparisons would provide a broader context and highlight the unique advantages or potential shortcomings of the proposed method. This feedback is clear and direct, giving the authors a specific action to take: conduct and report comparative experiments with these non-linear blocks. The comment provides concrete guidance on how to improve the draft, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Section 4.3,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparative experiments with non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback provides a clear direction for the authors to enhance their work by including these comparisons, which would help showcase the unique advantages or potential shortcomings of the proposed method. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks comparative experiments with non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, which could provide a broader context for the proposed method. However, the comment does not provide specific examples or references to support the claim, nor does it explain why these comparisons are necessary or how they would enhance the paper. Without detailed reasoning or evidence, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper could be improved by highlighting the lack of comparative experiments with non-linear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper's comprehensiveness and depth by including these comparisons. By addressing this feedback, the authors can better demonstrate the unique advantages or potential shortcomings of their proposed method in a broader context. However, the comment could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
