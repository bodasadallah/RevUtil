{"generated_text": "{'actionability_rationale': 'The review comment suggests that the dataset used in the study is artificially created and may contain noise, such as misinformation or out-of-context images. It implies that the authors should conduct more analysis on the quality of the dataset and the amount of noise it might have. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the dataset used in the study, specifically mentioning that it is artificially created and may contain noise, such as misinformation or out-of-context images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. However, the comment does not specify which part of the paper discusses the dataset or the analysis, making it weakly grounded. The authors can infer that it relates to the dataset section, but this inference is not explicit. The comment is specific in detailing the issue with the dataset quality and the need for further analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset used in the study is artificially created and may contain noise, such as misinformation or out-of-context images. The reviewer suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. However, the comment lacks specific examples or references to support the claim about the dataset\\'s noise, making it difficult for the authors to fully understand and address the issue. The suggestion for more analysis is logical, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the dataset used in the study, noting that it is artificially created and may contain noise, such as misinformation or out-of-context images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. This feedback is somewhat helpful as it points out a critical aspect of the dataset that could impact the study's validity and suggests a direction for further investigation. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or examples of how to assess dataset quality. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the dataset used in the study is artificially created and may contain noise, such as misinformation or out-of-context images. It implies that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the dataset used in the study, specifically mentioning that it is artificially created and may contain noise, such as misinformation or out-of-context images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. However, the comment does not specify which part of the paper discusses the dataset or the analysis, making it weakly grounded. The authors can infer that it relates to the dataset section, but this inference is not explicit. The comment is specific in detailing the issue with the dataset quality and the need for further analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset used in the study is artificially created and may contain noise, such as misinformation or out-of-context images. It suggests that the authors should conduct more analysis on the quality of the dataset and the amount of noise it potentially has. However, the comment lacks specific examples or references to support the claim about the dataset\\'s noise, making it difficult for the authors to fully understand and address the issue. The suggestion for more analysis is logical, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the dataset used in the study, noting that it is artificially created and may contain noise, such as misinformation or"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation is correct, implying that the current method is flawed. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify or revise the description of HIERENC. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"HIERENC,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the description of HIERENC, noting that using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. This provides clear guidance on what needs to be addressed in the description of HIERENC. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that using the average of all instantiations of context filled by every possible entity in the vocabulary is a poor approach because it introduces noise. The reviewer provides a logical reasoning by questioning the validity of averaging multiple instantiations, which could lead to noise. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact issue and potential solutions from the reviewer\\'s reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the description of HIERENC, noting that the current approach of using the average of all instantiations of context filled by every possible entity in the vocabulary is unclear and potentially introduces noise. The reviewer suggests that only one instantiation is correct, implying that the current method is flawed. This feedback is clear and actionable, as it provides a specific area for improvement and highlights a potential weakness in the methodology. However, the comment could be more helpful if it offered suggestions on how to clarify the description or address the noise issue. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While the comment implies that the authors should explain their rationale for this selection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the selection of 10 answers from all correct answers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind this selection and its potential impact on the underestimation of performances. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. It does not contain any subjective opinions, claims, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the selection of 10 answers from all correct answers and its potential impact on the underestimation of performances. While it identifies a specific area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. This is a direct request for additional information, providing the authors with a clear action to take. The comment is explicit and concrete, as it specifies exactly what information is needed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for clarification on the splits used for obtaining the ATIS numbers. The comment provides a direct request for additional information, which is clear and specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the splits used for obtaining the ATIS numbers in Table 4. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area in the paper that requires clarification, namely Table 4. It asks for more information about the splits used for obtaining the ATIS numbers, which is a direct and actionable request for additional details. However, the comment lacks depth and does not provide suggestions on how to improve the clarity or presentation of the information. While it prompts the authors to address a specific issue, it does not offer comprehensive guidance or insights that could enhance the draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should correct the wording 'on par or better' to address a perceived cognitive bias among NLP researchers. While the comment implies that the authors should make this correction, it does not provide explicit guidance on how to rephrase the results or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact changes to make. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the line number (l.791), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential cognitive bias among NLP researchers and suggesting a correction to the wording. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that there is a general cognitive bias among NLP researchers to map instances where they perform worse to 'on par' and all the rest to 'better'. While the reviewer provides a rationale for this claim, it lacks specific examples or references to support the assertion. The comment suggests that the authors should correct this bias, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the phrasing of the experimental results, suggesting that the authors might be using a cognitive bias to label their results as 'on par' or 'better' when they perform worse. This observation is insightful and could help the authors improve the clarity and accuracy of their reporting. However, the comment lacks specific guidance on how to address this issue or suggestions for alternative phrasing. While it points out a potential problem, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of novelty in the paper\\'s contribution, noting that adversarial attacks by perturbing text have been done on many NLP and image-text models. It suggests that the only new effort is applying similar ideas to video-text models. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the novelty of their work or what specific aspects they should focus on to differentiate their contribution. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the lack of novelty in the paper\\'s contribution, specifically mentioning adversarial attacks by perturbing text on NLP and image-text models. It highlights that the only new effort is applying similar ideas to video-text models. However, the comment does not specify which part of the paper discusses the novelty or lack thereof, making it weakly grounded. The comment is specific in identifying the issue of lack of novelty and suggesting that the paper lacks originality in its approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty due to the similarity of adversarial attacks by perturbing text on NLP and image-text models, which have been previously explored. The comment provides a logical reasoning by referencing the related work section of the paper, which presumably summarizes these prior efforts. However, the comment lacks specific examples or references to the exact works that have been done, making it somewhat verifiable. The authors would need to refer to the related work section to fully understand the claim, which adds a layer of complexity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the paper's contribution, specifically noting that adversarial attacks by perturbing text have been previously explored in NLP and image-text models. It highlights that the only new effort is applying similar ideas to video-text models. This feedback is somewhat helpful as it points out a potential weakness in the paper's originality. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might enhance the novelty of their work or differentiate it from existing research. Without actionable advice or detailed feedback, the comment provides limited value to the authors in terms of improving their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how an antecedent is identified when the prediction is a pronoun, and it highlights a potential issue with the proposed method of matching the head of noun phrases. The comment implies that the authors should clarify how they handle situations where the head word is not a pronoun. While the action is implicit, it is clear that the authors need to address this issue, and the comment provides a specific area for clarification. However, the comment does not offer concrete guidance on how to implement this clarification, such as suggesting specific examples or methods to handle the situation. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a specific question about how an antecedent is identified when the prediction is a pronoun, and it highlights a potential issue with the proposed method of matching the head of noun phrases. It explicitly mentions the method and the specific scenario where the head word is not a pronoun, providing full grounding. The comment is also specific as it clearly identifies the issue and suggests a potential area for clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the method proposed by the authors for identifying antecedents, specifically when the prediction is a pronoun. It highlights a potential issue with the method of matching the head of noun phrases, questioning how to handle situations where the head word is not a pronoun. While the comment identifies a specific area for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide additional context or evidence to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it provides a clear question but requires more detailed support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the method proposed by the authors for identifying antecedents, particularly when the prediction is a pronoun. It highlights a potential issue with the method of matching the head of noun phrases, questioning how to handle situations where the head word is not a pronoun. This feedback is clear and actionable, as it prompts the authors to clarify their method and consider alternative approaches to address the identified issue. However, the comment could be more helpful if it provided suggestions on how to handle these situations or offered alternative methods for identification. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear direction for addressing the issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN. It also questions how the stable points in probabilistic metric space are obtained, implying that this information is crucial for readers to understand and replicate the results. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to include more detailed discussions, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for more detailed explanations on the convergence process and the derivation of stable points. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that discussions are needed on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors need to include discussions on the convergence of the proposed joint learning process for RNN and CopyRNN, specifically regarding how stable points in probabilistic metric space are obtained. This feedback is somewhat helpful as it identifies a gap in the paper's explanation, which could be crucial for readers to understand and replicate the results. However, the comment lacks specific guidance on how to address this issue or what aspects of the convergence process should be discussed. To be more helpful, the comment could provide examples or references to similar works that address this topic, offering a clearer path for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of the reasoning chains in addressing implicit offensive texts. However, it does not provide explicit guidance or suggestions on how the authors should address these issues or improve their approach. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about what steps to take to enhance their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two main points: the absence of information regarding societal biases in the knowledge bases and the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not specify which part of the paper these concerns relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its critique of the lack of information on societal biases and the example provided in Fig., but it lacks full grounding as it does not explicitly mention the sections or figures being discussed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the societal biases in the knowledge bases used and questions the effectiveness of reasoning chains in addressing implicit offensive texts. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The mention of Fig. suggests that the example is related to the effectiveness of reasoning chains, but without further details, the claim remains vague. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises two concerns: first, it questions whether the knowledge bases used are free from societal biases, and second, it expresses skepticism about the effectiveness of reasoning chains in addressing implicit offensive texts, using Fig. as an example. While the comment identifies potential issues, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is somewhat helpful as it points out areas for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a detailed set of questions that the authors should address to improve their draft. It explicitly instructs the authors to describe the traits of the experts, justify the need for expert annotation, and provide context on whether the experts were linguistic or domain experts. The comment also asks about the differences between expert and non-expert annotation and whether it introduced linguistic challenges. These questions are clear and specific, guiding the authors on what information to include and how to address the points raised. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions for the authors to consider, such as describing the traits of the experts, justifying the need for expert annotation, and addressing differences between expert and non-expert annotation. The comment also raises questions about linguistic challenges introduced by expert annotation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the traits of the experts and the necessity of expert annotation, suggesting that the authors should provide more context. However, it does not provide specific evidence or references to support the claim that expert annotation is necessary or that it introduces linguistic challenges. The comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a detailed set of questions that the authors should address to improve their draft. It prompts the authors to describe the traits of the experts and justify why annotation must be carried out by experts, even if it has commercial value. The comment also asks about the expertise of the annotators and whether their annotation introduces linguistic challenges. This feedback is clear and actionable, offering specific areas for the authors to consider and improve upon. However, it could be more helpful if it provided suggestions on how to address these points or examples of how to justify the need for expert annotation. Overall, the comment is mostly helpful as it guides the authors in enhancing their draft with detailed feedback.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While the comment implies that the authors should provide such examples, it does not explicitly instruct them to do so or specify which components or models should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples of the system in action. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including examples of the system applied to actual texts, which implies that it addresses the methodology or results section of the paper. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in its suggestion to include examples of the system on actual texts, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include examples of the system applied to actual texts, rather than focusing solely on other components or models. While this feedback provides a clear direction for improvement, it lacks specificity and does not offer detailed guidance on how to incorporate these examples or what specific texts should be used. The comment is somewhat helpful as it identifies an area for enhancement but does not fully support the authors in implementing the suggestion. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the use of the Challenge Set. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the use of the Challenge Set, which is a specific aspect of the paper. The authors can infer that it relates to the methodology or evaluation section, but the comment does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the use of the Challenge Set, specifically whether it is used to augment the training material and, if so, what data split was used. This feedback is somewhat helpful as it prompts the authors to clarify a potentially confusing aspect of their methodology. However, it lacks depth and does not provide specific guidance on how to address the issue or improve the clarity of the paper. The authors are left with a general suggestion to clarify the use of the Challenge Set, but without additional details or examples, the feedback remains somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach to all parts of speech. It suggests that the authors should provide a better understanding of the gap between the performance of TWSI and the oracle GAP for PPDBClus, and why the performance is not uniform across parts of speech. While the comment implies that the authors should address these issues, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations and analysis. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, such as the performance on nouns and the claim about the generalizability of the clustering approach. It also specifies the issue by pointing out the contradiction between the claim and the observed performance gap. The comment is specific in detailing what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises concerns about the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach to all parts of speech. It points out that the oracle GAP for PPDBClus is higher than most clustering approaches, which contradicts the claim that the clustering approach is generalizable. The comment provides a logical reasoning based on the observed performance gap, suggesting that the authors should provide a better understanding of this gap. However, it lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific concern regarding the performance of the clustering approach, particularly on nouns, and questions the generalizability of the approach to all parts of speech. It points out a contradiction between the claim of generalizability and the observed performance gap. This feedback is clear and actionable, as it directs the authors to address the performance issue and provide a better understanding of the gap. However, the comment could be more helpful if it suggested specific ways to investigate and resolve the issue, such as proposing additional experiments or analyses. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to follow.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to provide examples of spurious structures to clarify why the new model is better than MH. This is a clear and direct action, giving the authors a specific task to perform. The comment also specifies what needs to be addressed, making it highly actionable. The authors know exactly what information is needed to improve their draft, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion, which is its abstract nature and the lack of clarity on why the new model is better than MH. The request for examples of spurious structures provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the discussion in section 5.2 is abstract and lacks clarity on why the new model is better than MH. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks evidence or references to substantiate the assertion that the discussion is abstract or unclear. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the discussion in section 5.2, noting that it is abstract and lacks clarity on why the new model is better than MH. It provides a clear and actionable suggestion by asking the authors to provide examples of spurious structures. This feedback is helpful as it directs the authors to a specific area for improvement, giving them a clear path to enhance the clarity and understanding of their work. However, the comment could be more helpful if it offered additional guidance or examples of how to address the issue. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with more detailed suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probabilistic connection in the paper is not formal enough and recommends either formalizing this connection or adjusting the language to clarify it. While the action is explicit, it does not provide specific guidance on how to formalize the connection or what aspects of the language should be adjusted. The authors know they need to address the issue but may need additional information to fully implement the suggested changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of the probabilistic connection being drawn in the paper, suggesting that it is not formal enough. However, it does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in its suggestion to either formalize the connection or adjust the language to clarify it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the probabilistic connection is not formal enough, suggesting that it should be either formalized or the language adjusted to clarify it. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed reasoning or evidence makes the claim borderline verifiable, as it requires the authors to infer the nature of the problem and how to resolve it. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the probabilistic connection in the paper, noting that it is not formal enough to be considered more than motivational. It provides a clear suggestion for improvement by either formalizing the connection or adjusting the language to clarify it. This feedback is actionable and provides the authors with a clear direction for enhancing the clarity and rigor of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to formalize the connection. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem. While the comment implies that the authors should include such evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. However, it does not specify which part of the paper this claim is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for empirical evidence, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. However, the comment does not provide any specific evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support their claim about the algorithm\\'s performance in the Column Subset Selection problem. This feedback is specific and actionable, as it directs the authors to include additional data or results that would strengthen their claims. However, the comment could be more helpful if it provided examples of what kind of evidence would be most effective or how to structure this evidence within the paper. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. While the comment implies that the authors should provide more context or explanation about the datasets and the style shifts, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information to clarify the dataset choice and the nature of style shifts. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, it does not specify which part of the paper this discussion is related to, such as a particular section or table. The authors can infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in its questions about the dataset and style shifts, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of datasets and the duration of the study period, specifically asking whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. However, the comment does not provide any supporting evidence, reasoning, or references to justify these questions. Without additional context or examples, the authors may find it challenging to address the concerns effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of datasets and the duration of the study period, specifically questioning whether 4 years is sufficient to study style shifts and what kind of style shifts occur during this time. This feedback highlights an important aspect that the authors should consider when evaluating their dataset and methodology. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative datasets or methods to study style shifts. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might clarify or improve the confusing parts, leaving the authors without a clear direction for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not specify which parts of the paper are confusing or what aspects need clarification. This makes it difficult for the authors to pinpoint the exact sections that require attention. The comment is weakly grounded because it does not provide specific references or details about the confusing parts, and it is not specific in terms of what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the paper is confusing. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion may arise, as listed in point 3. However, it does not provide any details or examples of these confusing parts, nor does it offer suggestions or guidance on how the authors might address these issues. Without actionable feedback or specific examples, the comment lacks the depth and clarity needed to be helpful for the authors. As a result, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': \"The review point acknowledges that the results are based on standard techniques but notes that they are not obvious a priori and require a fair degree of technical competency. While it highlights a potential issue with the results, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the clarity of their work. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the results section, indicating that the results are based on 'standard' techniques but are not obvious a priori and require a fair degree of technical competency. However, it does not specify which part of the paper this observation pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the results are unclear or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point claims that the results are based on 'standard' techniques but are not obvious a priori, requiring a fair degree of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the results are based on 'standard' techniques but notes that they are not obvious a priori and require a fair degree of technical competency. This observation highlights a potential issue with the clarity and accessibility of the results, suggesting that the techniques may be more complex than initially apparent. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of their work. While it identifies a potential area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges that the results are based on 'standard' techniques but notes that they are not obvious a priori and require a fair degree of technical competency. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue or improve the clarity of their work. The comment lacks actionable details, leaving the authors uncertain about what steps to take to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment addresses the results section, noting that the results are based on 'standard' techniques but are not obvious a priori and require a fair degree of technical competency. However, it does not specify which part of the paper this observation pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the results are unclear or how they could be improved. Without clear grounding or detailed feedback, the authors are left uncertain about how to address the issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point acknowledges that the results are based on 'standard' techniques but notes that they are not obvious a priori and require a fair degree of technical competency. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the results are based on 'standard' techniques but notes that they are not obvious a priori and require a fair degree of technical competency. This observation highlights a potential issue with the clarity and accessibility of the results, suggesting that the techniques may be more complex than initially apparent. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the clarity of their work. While it identifies a potential area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a weakness but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges that the results"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the amount of data used to train the text disambiguation model compared to the end-to-end system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what steps they should take to improve their conclusion. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed analysis or justification for their conclusions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the amount of data used to train the text disambiguation model compared to the end-to-end system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the experimental results or discussion sections, but this is not explicitly mentioned. The comment is specific in detailing the issue with the conclusion, but without full grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the amount of data used to train the text disambiguation model compared to the end-to-end system. It questions the conclusion that the direct model is the better of the two systems, given the small difference in performance. However, the comment does not provide specific evidence or reasoning to support this claim, such as detailed comparisons or statistical analysis. The lack of supporting details or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the conclusion that the direct model is the better of the two systems, given the small difference in performance and the amount of data used for training. It raises a valid concern about the reliability of the conclusion based on the limited data used for training the text disambiguation model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights an important point, the feedback could be more helpful if it provided actionable advice or examples of how to strengthen the conclusion. Therefore, the comment is somewhat helpful, as it prompts the authors to consider the robustness of their conclusions but does not fully guide them in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies two specific issues: the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation. It explicitly states that the paper does not provide evidence or justification for GaRare's advantages over GaLore based on theoretical analysis. Additionally, it suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. These actions are clear and concrete, providing the authors with specific steps to take to improve their draft. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'GaRare' and 'GaLore,' allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of motivation for using GaRare and the need for a more detailed algorithmic presentation, particularly regarding the process of recovering updated parameters from projected gradients. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks motivation for using GaRare and does not provide evidence or justification for its advantages over GaLore. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion for a more detailed algorithmic presentation is somewhat vague, as it does not specify what aspects of the algorithm should be clarified. Therefore, the comment is somewhat verifiable, as it provides some guidance but requires more detailed justification or examples to be fully actionable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas for improvement in the paper. It points out that the paper lacks motivation for using GaRare and does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. Additionally, it suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. This feedback is clear and actionable, as it provides the authors with specific areas to address and improve upon. By addressing these points, the authors can enhance the clarity and impact of their work. Therefore, the comment is highly helpful, as it offers detailed guidance for improving the draft.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not provide explicit guidance on how the authors should address this gap or suggest specific ways to incorporate these references into their work. The action is implicit and somewhat vague, as the authors need to infer that they should include these references to strengthen their work's connection to existing literature. Therefore, the comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure to the CRF and the ability to perform exact inference. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or discussion. The authors can infer that it relates to the literature review or related work section, but this inference is not explicit. The comment is specific in detailing the missing link to similar work, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper lacks a connection to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, which have a similar structure and the ability to perform exact inference. However, the comment does not provide specific examples or references to these works, nor does it explain why this connection is important or how it could be addressed. Without detailed justification or references, the claim is difficult for the authors to verify and act upon. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a gap in the paper's literature review by pointing out the absence of references to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These references are relevant because they have a similar structure to the CRF and the ability to perform exact inference, which could be valuable for the authors to consider. However, the comment lacks specific guidance on how the authors should incorporate these references or what aspects of the work these references could enhance. While it highlights an important area for improvement, the feedback could be more actionable by providing concrete suggestions or examples. Therefore, the comment is somewhat helpful, as it directs the authors to a potential area of enhancement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" The reviewer requests more clarification on this similarity. While the comment implies that the authors should provide additional details or context to address this similarity, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this similarity is found in, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its request for more clarification on the similarity, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the method part of the paper is similar to the related work cited, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comparison or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the method part of the paper is similar to the related work cited, specifically 'Generating Adversarial Disturbances for Controller Verification.' It requests more clarification on this similarity. While the comment identifies a potential overlap, it does not provide specific details or suggestions on how the authors might address this similarity or clarify their contribution. This feedback is somewhat helpful as it prompts the authors to provide additional context or differentiation, but it lacks depth and actionable guidance, leaving the authors with a general direction to follow. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: (1) whether the proposed method is fairly compared with other methods, and (2) whether the proposed technique promotes existing Class incremental semantic segmentation methods. While the questions imply that the authors should address these concerns, they do not provide explicit guidance on how to do so. The authors are left to infer that they need to justify the fairness of their comparison and demonstrate the novelty of their technique in the context of existing methods. However, the comment lacks concrete suggestions or detailed instructions on how to address these issues, making the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises two questions regarding the proposed method. The first question asks whether the method is fairly compared with other methods, and the second question inquires about the promotion of existing Class incremental semantic segmentation methods. However, the comment does not specify which part of the paper these questions relate to, such as specific sections or figures. This lack of grounding makes it difficult for the authors to identify the exact areas needing attention. The comment is specific in its questions, but without clear grounding, it is challenging for the authors to address the issues effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of two questions regarding the fairness of comparison and the promotion of existing methods. It does not contain any claims or opinions that require verification. The questions are factual in nature and seek clarification or information, making them normal statements. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions regarding the proposed method. The first question asks whether the method is fairly compared with other methods, which is a valid concern for the authors to address. The second question inquires about the promotion of existing Class incremental semantic segmentation methods, which could be relevant to the broader impact of the work. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how the authors might address these questions. The feedback is somewhat helpful as it prompts the authors to consider these aspects, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 is written in a concise manner due to space limitations and could benefit from a slower development to make it easier to read. While the comment implies that the authors should expand the section to improve readability, it does not provide specific guidance on what aspects should be expanded or how much additional content is needed. The action is implicit and somewhat vague, as the authors know they need to expand the section but lack detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 4,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by noting that the section is \"tersely written\" and could benefit from a slower development for easier readability. This level of detail allows the authors to understand what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 4 is written in a concise manner due to space limitations, which could be improved for easier readability. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact issues or improvements needed. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Section 4, noting that it is written in a concise manner due to space limitations. It suggests that the section could benefit from a slower development to make it easier to read. While the comment highlights a potential area for improvement, it lacks specific guidance on what aspects of the section should be expanded or how to achieve a slower development. The feedback is somewhat helpful as it points out a problem but does not provide detailed suggestions for improvement, leaving the authors with a general direction to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete actions for the authors to take, making the comment highly actionable. The authors know exactly what needs to be done to address the feedback, which is to include a specific table and provide an explanation. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the previous question, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of a table showing the distribution of video lengths across the dataset and an explanation of how the authors ensured a balanced representation of different video lengths across the 11 categories. This provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the distribution of videos of different lengths within the benchmark is crucial for assessing reasoning ability and robustness, and that the paper does not provide relevant explanations. The reviewer suggests including a table showing the distribution of video lengths and explaining how the dataset is balanced across categories. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the distribution is crucial or that the paper lacks relevant explanations. The suggestion to include a table and explain the dataset's balance is a logical response but requires further justification or evidence to be fully verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved, namely the distribution of video lengths within the benchmark dataset. It highlights the importance of this distribution for assessing reasoning ability and robustness, which is a valid concern. The comment provides a clear and actionable suggestion by recommending the inclusion of a table showing the distribution of video lengths and an explanation of how the dataset is balanced across categories. This feedback is detailed and constructive, offering the authors a straightforward way to enhance the clarity and robustness of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should take a cautious approach regarding their contribution until the promised dataset is made publicly available. However, it does not provide explicit guidance on how the authors should proceed or what actions they should take to address this issue. The comment lacks concrete details or suggestions on how to handle the situation, leaving the authors uncertain about how to implement the advice. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the dataset not being publicly available, which is a concern regarding the contribution. However, it does not specify which part of the paper discusses the dataset or how it is relevant to the contribution. The authors can infer that it relates to the dataset section or the contribution section, but this inference is not explicit. The comment is specific in identifying the issue of dataset availability, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset promised in the paper has not been made publicly available, suggesting a cautious approach until the dataset is openly accessible. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the paper, noting that the promised dataset has not been made publicly available. This is an important point that the authors should address, as it affects the reproducibility and impact of their work. However, the comment lacks specific guidance or suggestions on how the authors might proceed or what actions they could take to address this issue. While it identifies a critical concern, it does not provide actionable advice or detailed feedback, making it somewhat helpful. The authors are left with a clear understanding of the problem but without clear steps to resolve it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the novelty of the proposed method is limited due to its similarity to existing attentional modules. It specifically mentions that the group attention design is related to ResNeSt but is not discussed in the paper. The reviewer suggests that the authors should discuss the relationship between their work and ResNeSt, as this could provide a clearer understanding of the novelty. However, the comment does not explicitly instruct the authors to discuss this relationship or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for discussion but lack detailed instructions on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, suggesting that it is too similar to other attentional modules proposed in previous works. It mentions specific references [1, 2, 3] and notes that the group attention design is related to ResNeSt [4], but this is not explicitly mentioned in the paper. The comment is somewhat specific in identifying the issue of similarity to existing works, but it lacks full grounding as it does not specify which part of the paper discusses these related works or the group attention design. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to other attentional modules proposed in previous works. It provides references to specific works [1, 2, 3] and mentions that the group attention design is related to ResNeSt [4]. However, the comment lacks detailed reasoning or specific examples to explain why the proposed method is too similar to existing works or how it relates to ResNeSt. While the references provide some support, the lack of detailed justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the novelty of the proposed method, noting that it is too similar to other attentional modules proposed in previous works. It specifically mentions references [1, 2, 3] and suggests that the group attention design is related to ResNeSt [4], but this relationship is not discussed in the paper. The comment provides a clear direction for improvement by suggesting that the authors should discuss the relationship between their work and ResNeSt, which could enhance the paper's novelty and differentiation. However, the comment could be more helpful if it offered specific suggestions on how to discuss this relationship or what aspects of ResNeSt should be highlighted. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement but lacks detailed guidance on execution.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the authors' claim of achieving state-of-the-art results on challenging scene text recognition tasks, particularly regarding the claim that the performance is due to the first step. It suggests conducting comparisons with existing detection methods to validate the claim. However, the comment does not explicitly instruct the authors to perform these comparisons or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the need for comparisons and how to execute them. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the claim of achieving state-of-the-art results on scene text recognition tasks, specifically questioning the validity of this claim. It suggests that the performance is largely due to the first step and recommends conducting comparisons with existing detection methods. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the results section or the conclusion, but this is not explicit. The comment is specific in detailing the issue with the claim and suggesting a way to address it, but without full grounding, it aligns with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the claim of achieving state-of-the-art results on scene text recognition tasks, suggesting that the performance is largely due to the first step. It implies that comparisons with existing detection methods should be conducted to validate the claim. However, the comment lacks specific examples or references to support the claim that the performance is solely due to the first step, making it difficult for the authors to understand and address the critique effectively. The suggestion to conduct comparisons is a logical step but is not fully supported by the comment, which limits its verifiability. Therefore, the comment is considered borderline verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the authors' claim of achieving state-of-the-art results on scene text recognition tasks, particularly questioning the validity of the claim. It suggests that the performance is largely due to the first step and recommends conducting comparisons with existing detection methods to validate the claim. While the comment identifies a potential issue with the claim, it lacks specific guidance on how to conduct these comparisons or what aspects should be compared. The feedback is somewhat helpful as it points out a potential weakness in the paper's claims, but it could be more actionable with detailed suggestions or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the implicit call to the Witness oracle is confusing. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to clarify the concept, provide an alternative explanation, or offer specific steps to improve the clarity of the text. Without actionable advice or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the paper, namely the confusion caused by the implicit call to the Witness oracle. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact location. The comment is specific in its critique of the confusion caused by the implicit call, but it lacks grounding as it does not provide a clear reference to the section or part of the paper where this issue occurs. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the implicit call to the Witness oracle is confusing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the implicit call to the Witness oracle is confusing. However, it does not provide any suggestions or guidance on how the authors might clarify this concept or improve the clarity of the text. Without actionable advice or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it highlights a potential issue but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the proposed method\\'s inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their method to handle headpose. The action is implicit and vague, as the authors are left to infer that they need to explore ways to incorporate headpose conditioning into their NeRF model. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method\\'s inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not specify which part of the paper discusses the headpose issue or the proposed method, making it weakly grounded. The comment is specific in detailing the problem and referencing a previous work, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the proposed method\\'s inability to handle headpose, which is deferred to future work. It questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. However, the comment does not provide specific reasoning or evidence to support why this is a significant issue or why it should be addressed. The reference to Gafni et al. provides a starting point, but the comment lacks detailed analysis or justification for the claim. Therefore, the claim is somewhat verifiable, as it provides a reference but lacks comprehensive reasoning or evidence to fully substantiate the point.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific limitation of the proposed method, namely its inability to handle headpose, which is deferred to future work. It also questions why it is not possible to condition the headpose parameters in the NeRF beyond the facial expression, referencing a previous work (Gafni et al. ICCV 2021) that can control both facial expression and headpose. This feedback is somewhat helpful as it highlights a potential area for improvement and provides a reference for the authors to consider. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this limitation or incorporate headpose conditioning into their NeRF model. Overall, the comment provides some insight but lacks depth and actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the structural optimization is a main component and has been emphasized several times, but it notes that the optimization algorithm is directly from previous works, which can be confusing and reduces the contribution. While the comment identifies a potential issue with the originality of the optimization algorithm, it does not provide explicit guidance on how the authors should address this concern. The suggestion to clarify or differentiate the contribution is implicit and somewhat vague, as it does not specify the exact steps the authors should take to enhance the originality of their work. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the structural optimization component, which is mentioned several times in the paper, indicating full grounding. However, it does not specify which part of the paper this component is discussed in, making it difficult for the authors to pinpoint the exact section. The comment is specific in pointing out that the optimization algorithm is directly from previous works, which reduces the contribution. This makes the comment weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the structural optimization is a main component emphasized several times, but it is confusing because the optimization algorithm is directly from previous works. The reviewer suggests that this reduces the contribution. However, the comment lacks specific examples or references to the previous works, making it difficult for the authors to understand the exact nature of the confusion or how to address it. Without detailed evidence or examples, the claim is not fully verifiable, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the structural optimization component, noting that it is emphasized several times but seems to be directly from previous works, which can be confusing and reduce the contribution. This feedback is somewhat helpful as it points out a specific area where the paper might lack originality or clarity. However, the comment could be more helpful if it provided suggestions on how the authors could differentiate their work or enhance the contribution in this area. Overall, the comment provides a direction for improvement but lacks detailed guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the pipeline style method, which includes two models, does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models in the experiments are not well introduced. While the comment identifies specific issues, it does not provide explicit guidance on how to address these problems or improve the results. The authors are left to infer that they need to enhance the performance of their models or provide a more detailed explanation of the baseline models. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the performance of a pipeline style method with two models, noting that it does not yield better average results for both XVNLI and MaRVL. It also mentions that the baseline models in the experiments are not well introduced. However, the comment does not specify which part of the paper discusses these models or the experiments, making it weakly grounded. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing the issues with the results and the lack of introduction for baseline models, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pipeline style method with two models does not yield better average results for both XVNLI and MaRVL, and that the baseline models in the experiments are not well introduced. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the pipeline style method, noting that it does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models in the experiments are not well introduced, which is a critical aspect for readers to understand the context and performance of the models. However, the comment lacks actionable suggestions or guidance on how to improve the method or introduce the baseline models more effectively. While it highlights important areas for improvement, the feedback is somewhat helpful as it provides a direction for the authors to consider but does not offer detailed steps or examples to follow. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' methodology for reproducing a well-known result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not explicitly instruct the authors to do so or suggest specific alternative methods. The action is implicit and somewhat vague, as the authors can infer that they need to improve their methodology but are not given concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the authors\\' methodology for reproducing a well-known result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. However, the comment does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not explicit. The comment is specific in its critique of the methodology and the need for improvement, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point challenges the authors\\' methodology for reproducing a well-known result, left political bias in ChatGPT and LLMs in general, using a \"coarse\" methodology. It questions the need for this observation to be made again using this methodology, referencing the common knowledge that language models reproduce the biases of the corpora on which they are trained. However, the comment lacks specific examples or references to support the claim that the methodology is \"coarse\" or that the observation needs to be made again. This makes the claim somewhat verifiable, as it provides a general critique but lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the authors' methodology for reproducing a well-known result, left political bias in ChatGPT and LLMs in general, using a 'coarse' methodology. It questions the need for this observation to be made again using this methodology, implying that the authors should consider alternative approaches or provide a more detailed analysis. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might improve their approach. The feedback is somewhat helpful as it points out a potential limitation but does not offer actionable advice for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention related work on modular networks for VQA, specifically referencing [A]. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific example of what needs to be included, making it highly actionable. The authors know exactly what action to take and how to implement it, ensuring a clear path for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work on modular networks for VQA\" and references [A], allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of related work on modular architectures for VQA in the introduction. This provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction seems to imply that no one does modular architectures for VQA, but it does not mention related work on modular networks for VQA. This claim is based on the observation that the introduction lacks a specific reference to related work, which could be inferred as a gap in the literature. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the relevance of the claim and the need to include the mentioned related work, which adds to the complexity of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper\\'s discussion of related work, noting that it does not mention related work on modular networks for VQA. This is a crucial point as it highlights a potential oversight that could impact the comprehensiveness of the literature review. By pointing out the omission of a relevant area, the comment provides clear and actionable feedback, encouraging the authors to include this information to strengthen their paper. However, the comment could be more helpful if it suggested specific references or examples of related work that should be included. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors primarily focus on SSC and suggests that they should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. While the comment implies that the authors should include these comparisons to provide a more comprehensive analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons to enhance their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or subsection. The authors can infer that it relates to the discussion or comparison of methods, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting that the authors should include these comparisons to provide a more comprehensive analysis, but the lack of grounding makes it challenging for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. However, the comment does not provide specific examples or references to support the claim that these methods are computationally efficient or come with similar guarantees. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's focus, suggesting that the authors should contrast their method with other subsequent methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park, which are computationally efficient and come with similar guarantees. This feedback is somewhat helpful as it points out an area where the authors could enhance the comprehensiveness of their work by including these comparisons. However, the comment lacks specific guidance on how to incorporate these comparisons or what aspects to focus on when contrasting the methods. To be more helpful, the comment could provide more detailed suggestions or examples of how these comparisons could be made. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly states that the term 'semantic' segmentation is not low-level because the categories are specified for each pixel. It suggests that the statements about semantic segmentation being a low-level cue should be removed from the paper. This feedback is clear and direct, providing the authors with a specific action to take: removing those statements. The comment is explicit and concrete, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the terminology used in the paper, specifically regarding the term \"semantic\" segmentation. It points out that the categories are specified for each pixel, which implies that the term \"low-level\" is not accurate. This feedback is fully grounded as it explicitly mentions the issue with the terminology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the removal of statements about semantic segmentation being a low-level cue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the term 'semantic' segmentation is not low-level because the categories are specified for each pixel. This claim is somewhat verifiable as it provides a logical reasoning for why the term 'low-level' is not accurate, but it lacks specific examples or references to support the claim fully. The authors would need to infer the exact context or examples of the statements about semantic segmentation being a low-level cue to fully understand the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the terminology used in the paper, specifically regarding the term 'semantic' segmentation. It points out that the categories are specified for each pixel, which implies that the term 'low-level' is not accurate. This feedback is clear and actionable, as it provides a direct suggestion to remove statements about semantic segmentation being a low-level cue from the paper. By addressing this issue, the authors can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional context or guidance on why this distinction is important. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional explanation.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point questions the validity of the claim that the proposed modules improve accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. While the comment implies that the authors should consider using different datasets for their ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments with different datasets. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, referencing a table. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This level of specificity is clear, as it directs the authors to consider alternative datasets for their ablation study. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. The comment implies that the current dataset may not be sufficient to demonstrate the effectiveness of the proposed modules. However, it does not provide specific evidence or reasoning to support why the current dataset is insufficient or why the suggested datasets would be more appropriate. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. This feedback is somewhat helpful as it prompts the authors to consider alternative datasets for their ablation study, which could strengthen the evaluation of their proposed modules. However, the comment lacks specific guidance on how to conduct this evaluation or what aspects of the proposed modules should be further explored with these datasets. To be more helpful, the comment could provide more detailed suggestions or examples of how to use these datasets to improve the analysis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. While the comment implies that the authors should consider using different datasets for their ablation study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments with different datasets. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in its critique, suggesting alternative datasets for evaluation, but lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the validity of a claim regarding the improvement of proposed modules in terms of accuracy and completeness, suggesting that using another dataset, such as the training set of Tanks & Temples or ETH3D, could provide a more robust evaluation. The comment implies that the current dataset may not be sufficient to demonstrate the effectiveness of the proposed modules. However, it does not provide specific evidence or reasoning to support why the current dataset is insufficient or why the suggested datasets would be more appropriate. The lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It also points out that previous work has considered multiple vulnerabilities simultaneously. The reviewer suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment highlights potential issues and suggests areas for clarification, it does not provide explicit guidance on how the authors should address these concerns or improve the methodology. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously. The comment also raises concerns about the interpretability of the results. However, it does not specify which part of the paper this methodology is discussed in, making it weakly grounded. The comment is specific in detailing the issues with the methodology and the comparison to previous work, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously. The reviewer suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case and questions the interpretability of the results. While the comment provides a logical basis for questioning the methodology, it lacks specific references or examples to fully substantiate the claim. The suggestion to clarify the intended use case is a reasonable point, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises several concerns about the methodology used for vulnerability discovery, specifically questioning the ecological validity of considering a single vulnerability at a time. It compares this approach to previous work that has considered multiple vulnerabilities simultaneously and suggests that the authors clarify whether identifying one vulnerability at a time is an intended use case. Additionally, the comment questions the interpretability of the results and suggests that the improvements are marginal. While the comment identifies potential issues and areas for improvement, it lacks specific suggestions or guidance on how the authors might address these concerns or enhance the methodology. The feedback is somewhat helpful as it points out areas that need clarification but does not provide detailed actionable advice, leaving the authors with a general sense of what needs to be improved.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific area of concern regarding the relationship between degree bias and the community structure, noting that the explanations are not intuitive enough. It suggests that the authors provide more explanations on how to achieve a small degree of bias from a clear community structure. However, the comment does not explicitly instruct the authors to do so or provide concrete guidance on how to improve the explanations. The action is implicit and somewhat vague, as the authors can infer that more detailed explanations are needed but may not know exactly how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the relationship between degree bias and the community structure, as demonstrated by Theorems 1 and 2. It highlights that the relationship is not intuitive enough and suggests that more explanations are needed to clarify this aspect. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the sections where Theorems 1 and 2 are presented, but this inference is not direct. The comment is specific in detailing the issue with the relationship between degree bias and community structure, but it lacks explicit grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the relationship between degree bias and the community structure is not intuitive enough, despite the proofs provided in Theorems 1 and 2. However, the comment does not provide specific examples or detailed reasoning to support this claim. The lack of detailed evidence or examples makes it difficult for the authors to understand the exact nature of the issue and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the relationship between degree bias and the community structure, noting that the explanations are not intuitive enough. It highlights the need for more detailed explanations on how to achieve a small degree of bias from a clear community structure, referencing Theorems 1 and 2 as relevant to the discussion. However, the comment lacks specific suggestions or guidance on how to improve the explanations or what additional information should be included. While it points out a critical area for improvement, the feedback could be more actionable and comprehensive to be considered highly helpful. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific area of concern regarding the relationship between degree bias and the community structure, noting that the explanations are not intuitive enough. It suggests that the authors provide more explanations on how to achieve a small degree of bias from a clear community structure. However, the comment does not explicitly instruct the authors to do so or provide concrete guidance on how to improve the explanations. The action is implicit and somewhat vague, as the authors can infer that more detailed explanations are needed but may not know exactly how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the relationship between degree bias and the community structure, as demonstrated by Theorems 1 and 2. It highlights that the relationship is not intuitive enough and suggests that more explanations are needed to clarify this aspect. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the sections where Theorems 1 and 2 are presented, but this inference is not direct. The comment is specific in detailing the issue with the relationship between degree bias and community structure, but it lacks explicit grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the relationship between degree bias and the community structure is not intuitive enough, despite the proofs provided in Theorems 1 and 2. However, the comment lacks specific examples or detailed reasoning to support this claim. The mention of Theorems 1 and 2 provides some context, but without further elaboration, the authors may struggle to understand the exact nature of the issue. The lack of detailed evidence or examples makes it difficult for the authors to grasp the point and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. While the comment implies that more details are needed, it does not explicitly instruct the authors to provide these details or specify how to do so. The action is implicit and somewhat vague, as the authors can infer that more details are needed but may not know exactly what to include. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment mentions \"many graph notions\" and suggests that the writing is generally good but could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, it does not specify which sections or parts of the paper are affected by these issues, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, such as providing a clearer definition of the resistance distance and more explanations for Algorithm 1. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper deals with many graph notions and could benefit from more details, such as a clearer definition of the resistance distance and more explanations for Algorithm 1. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a general suggestion but lacks the necessary support to fully substantiate the need for additional details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's clarity, specifically noting that it deals with many graph notions and could benefit from more details. It suggests that the writing is generally good but could be improved with additional explanations, such as a clearer definition of the resistance distance and more detailed explanations for Algorithm 1. While the comment highlights areas for improvement, it lacks specific guidance or suggestions on how to enhance the clarity and detail of the paper. The feedback is somewhat helpful as it points out areas that need attention but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the originality of their work. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the originality of the paper, stating that the main idea of variable splitting is not new and that the algorithm is also not new. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity in detailing what aspects of the originality are limited or how the authors might address this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific reasoning or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the originality of the paper by pointing out that the main idea of variable splitting is not new and that the algorithm is also not new. This feedback is clear and identifies a significant issue with the paper\\'s contribution. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. While it highlights a critical area for improvement, the comment could be more helpful with additional context or actionable advice. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the evaluation of shape model invariance, specifically noting that evaluation on transformations of training images may not fully prove the point. It explicitly asks for quantitative results on testing images, providing a clear and direct action for the authors to take. This feedback is explicit and concrete, as it specifies what additional information is needed to strengthen the evaluation. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"shape model invariance study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the evaluation on transformations of training images and requests quantitative results on testing images. This provides clear guidance on what needs to be addressed in the study. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of shape model invariance, specifically questioning whether evaluation on transformations of training images fully proves the point. It requests quantitative results on testing images to strengthen the evaluation. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the current evaluation is insufficient. The request for quantitative results provides some direction, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the evaluation of shape model invariance. It points out that the current evaluation on transformations of training images may not fully prove the point and suggests the need for quantitative results on testing images. This feedback is clear and actionable, as it directs the authors to consider additional quantitative evaluations to strengthen their study. However, the comment could be more helpful if it provided specific suggestions on how to conduct these evaluations or what metrics to use. Overall, the comment is mostly helpful as it highlights a critical aspect for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. The comment implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it would provide a better understanding of the state-of-the-art. While the comment explicitly states that the paper should be discussed, it does not provide detailed guidance on how to integrate this paper into the draft or what specific aspects should be compared. The action is implicit but concrete, as the authors know what to do but may need some additional direction on how to implement it. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications,\" by Ghoshdastidar and Dukkipati, as a related work that was possibly missed. It implies that this paper deals with hypergraph data and tensors, and it suggests that discussing and comparing it would provide a better understanding of the state-of-the-art. However, the comment does not specify which part of the paper this related work should be discussed in, making it weakly grounded. The comment is specific in suggesting a related work to consider, but without explicit mention of the paper\\'s relevance to specific sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that a specific paper, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, is a related work that was possibly missed by the authors. The comment suggests that this paper deals with hypergraph data and tensors, and it should be discussed and compared against to provide a better understanding of the state-of-the-art. However, the comment does not provide specific details or examples of how this paper relates to the current work or what aspects should be compared. This lack of detailed justification or examples makes the claim somewhat verifiable, as the authors would need to independently verify the relevance and potential impact of the suggested paper. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential oversight in the literature review, suggesting that the authors may have missed a related work by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment implies that discussing and comparing this paper would provide a better understanding of the state-of-the-art in the field. While the comment highlights an important omission, it does not provide specific guidance on how the authors should integrate this paper into their draft or what aspects of the paper should be compared. The feedback is somewhat helpful as it points out a potential gap in the literature review but lacks detailed suggestions for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises concerns about the scalability of the optimal transport method and questions the authors' claim that it takes seconds to compute on a 36-core machine. It explicitly requests the authors to demonstrate the scalability on normal machines with a couple of cores. Additionally, the comment asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. This feedback is explicit and provides concrete actions for the authors to take, such as demonstrating scalability and explaining the computation of optimal transport. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the scalability of the optimal transport method and questions the authors\\' claim about the computation time. It explicitly mentions the \"Approach\" section, allowing the authors to identify the part of the paper being discussed. However, it does not specify which part of the approach is being questioned or what aspects need to be addressed regarding scalability and computation. While the comment is grounded in the \"Approach\" section, it lacks specificity in detailing the exact issues or improvements needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the scalability of the optimal transport method and questions the authors' claim that it takes seconds to compute on a 36-core machine. It also asks for clarification on how the optimal transport distance is computed, given that the Sinkhorn method provides a doubly stochastic matrix. While the comment identifies potential issues with scalability and computation, it lacks specific examples or references to support these claims. The reasoning is somewhat logical, but the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important questions about the scalability of the optimal transport method and the computation time, which are critical aspects for the authors to address. It points out that while the authors claim the method takes seconds to compute on a 36-core machine, it's not clear how it scales on normal machines with fewer cores. Additionally, the comment questions the process of computing the optimal transport distance from the doubly stochastic matrix provided by the Sinkhorn method. This feedback is clear and actionable, as it prompts the authors to demonstrate the scalability of their method and clarify the computation of optimal transport. However, the comment could be more helpful if it provided suggestions on how to address these issues or offered alternative approaches for computation. Overall, the comment is mostly helpful, as it guides the authors in improving their draft by identifying specific areas for clarification and improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in following the experimental procedures and evaluations in the paper, indicating that the authors may need to clarify or simplify these sections. However, the comment does not provide specific guidance on how to improve the clarity or structure of the experimental section. The authors are left with a general understanding of what needs to be addressed but without concrete steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the experimental procedures and evaluations in the paper, indicating that the authors may need to clarify or simplify these sections. However, it does not specify which part of the paper is causing the confusion, making it weakly grounded. The comment is specific in its feedback, as it clearly identifies the issue of difficulty in following the experimental procedures and evaluations. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is \"extremely hard to follow,\" but it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed explanations or references, the authors may find it challenging to understand the basis of the difficulty and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the paper, noting that it was \"extremely hard to follow\" and that the authors read it multiple times without fully understanding the experimental procedures and evaluations. This feedback is clear and actionable, as it identifies a specific area where the paper needs improvement in terms of clarity and organization. However, the comment could be more helpful if it provided suggestions on how to improve the clarity, such as recommending the use of diagrams, step-by-step explanations, or additional examples. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement but lacks detailed guidance on how to address the issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should introduce the specific aspects of the model that are relevant to the example model. It provides concrete guidance by specifying what should be clarified, such as the setting with finite subdivisions for \\gamma^1 and \\gamma^m, and the boundedness of certain parameters. This feedback is explicit and provides clear instructions on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l132,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as introducing the specific aspects of the model that are relevant to the example model. The comment specifies that the authors should clarify the setting with finite subdivisions for \\gamma^1 and \\gamma^m and the boundedness of certain parameters. This level of detail provides clear direction for improvement, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should clarify certain aspects of the model, such as the setting with finite subdivisions for \\gamma^1 and \\gamma^m, and the boundedness of certain parameters. While the comment provides specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the significance of these clarifications, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors should clarify certain aspects of the model, such as the setting with finite subdivisions for \\gamma^1 and \\gamma^m, and the boundedness of certain parameters. This guidance is clear and directly addresses potential areas of confusion or misinterpretation in the paper. By following this advice, the authors can improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it included examples or further explanation of why these clarifications are important. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it is not realistic to have a step size that grows with the sample size in practice. The reviewer suggests that this condition may lead to unreasonably large learning rates when working with large-scale datasets. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors might address this concern or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the scalability of the learning rate condition. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the required condition on the learning rate, noting that it is not scalable and may lead to unreasonably large learning rates when working with large-scale datasets. However, it does not specify which part of the paper discusses this condition, making it weakly grounded. The comment is specific in identifying the issue with the scalability of the learning rate condition and its potential impact on large-scale datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required condition on the learning rate, which scales with the number of samples, is not scalable and unrealistic. The reviewer provides a logical reasoning by stating that in practice, step sizes do not grow with the sample size, which could lead to unreasonably large learning rates when dealing with large-scale datasets. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the scalability of the required condition on the learning rate, noting that it is not realistic in practice. The reviewer points out that step sizes typically do not grow with the sample size, which could lead to unreasonably large learning rates when working with large-scale datasets. This feedback is clear and actionable, as it highlights a potential limitation of the current approach and suggests that the authors need to reconsider the scalability of the learning rate condition. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative approaches to consider. Overall, the comment is mostly helpful as it directs the authors' attention to a critical aspect that needs improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they could take to improve their sampling method. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) on line 130. It also compares this issue to sampling from the leverage score in [3]. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically Equation (10) and the reference to [3]. The comment is specific because it clearly details the problem with sampling from the DPP and compares it to a similar issue with the leverage score. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. The reviewer suggests that sampling from the DPP might be more challenging than sampling from the leverage score, but the comment lacks specific examples or detailed reasoning to support this claim. While the reviewer provides a reference to [3], the justification for the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. This feedback is somewhat helpful as it identifies a potential challenge in the sampling process, which could be relevant for the authors to address. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might overcome this issue or improve their sampling method. Without additional context or specific recommendations, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, as it points out a potential area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve their sampling method or what steps they could take to overcome this challenge. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) on line 130. It also compares this issue to sampling from the leverage score in [3]. This provides full grounding as the authors can accurately identify the part of the paper being addressed, specifically Equation (10) and the reference to [3]. The comment is specific because it clearly details the problem with sampling from the DPP and compares it to a similar issue with the leverage score. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. The reviewer suggests that sampling from the DPP might be more challenging than sampling from the leverage score, but the comment lacks specific examples or detailed reasoning to support this claim. While the reviewer provides a reference to [3], the justification for the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific concern about the difficulty of sampling from the DPP when eigenfunctions are inaccessible, referencing a similar issue with sampling from the leverage score in [3]. This feedback is somewhat helpful as it identifies a potential challenge in the sampling process, which could be relevant for the authors to address. However"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit feedback on the abstract, stating that it does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. While the comment identifies specific areas for improvement, it does not provide detailed guidance on how to address these issues or what specific changes should be made. The authors are aware of what needs to be improved but may need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"abstract,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the abstract lacks description of how the idea was evaluated and what the outcome was. Additionally, it mentions minor language issues, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract lacks description of how the idea was evaluated and what the outcome was, and mentions minor language issues. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed evidence or references leaves the claim somewhat verifiable, as it requires the authors to infer the nature of the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it provides a good explanation of the proposed idea but lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include more information about the evaluation process and outcomes. Additionally, the comment mentions minor language issues, which could be addressed to improve the clarity and effectiveness of the abstract. While the comment highlights a specific area for improvement, it does not provide detailed guidance on how to enhance the abstract further. Therefore, the comment is mostly helpful, as it provides valuable insights but could be more comprehensive with additional suggestions. This aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses skepticism about the experimental results and questions the lack of experiments on the POMDP problem with non-convex value functions, specifically mentioning examples like surveillance in museums with thresholded rewards and privacy preserving data collection. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific experiments should be conducted. The action is implicit and vague, as the authors are left to infer that they need to conduct additional experiments, but without detailed instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental results\" and the \"experiments section,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of experiments on the POMDP problem with non-convex value functions, particularly in the context of the examples provided. The reviewer questions why there are no experiments on these settings, even in a simulated context, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the experimental results of the paper, specifically regarding the POMDP problem with non-convex value functions. The reviewer points out that the paper uses examples of surveillance in museums with thresholded rewards and privacy preserving data collection to motivate the case for their solution, but questions why there are no experiments on these settings. This raises a logical inconsistency in the paper\\'s experimental design. However, the comment lacks specific examples or references to support the claim that the experiments are not useful, making it somewhat verifiable. The authors would need to provide more detailed reasoning or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the experimental results of the paper, specifically regarding the POMDP problem with non-convex value functions. It questions the lack of experiments on the examples mentioned, such as surveillance in museums with thresholded rewards and privacy preserving data collection, despite these being used to motivate the solution. The reviewer suggests that the experiments section would be more useful if there were experiments on these settings, even in a simulated context. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by providing additional experimental evidence. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or what specific results should be expected. Overall, the comment is mostly helpful as it identifies a significant gap in the paper's experimental validation, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit feedback on the authors\\' workload and suggests that the contribution of the article is incremental. It also points out that the article combines GraphRAG and GraphCare, and mentions that many key baselines were not cited. Additionally, it highlights that the paper focuses on RAG for EHR and should introduce essential RAG algorithms such as MedRetriever and commonly used GraphRAG algorithms like KGRAG. While the comment provides specific suggestions for improvement, it does not offer detailed guidance on how to implement these suggestions. The authors are aware of what needs to be addressed but may require additional information to fully understand how to apply the feedback. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' code and the article, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed feedback on the perceived incremental nature of the contribution, the combination of GraphRAG and GraphCare, and the absence of key baselines. It further suggests that the paper should introduce essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the contribution of the article is incremental and consists of a combination of GraphRAG and GraphCare. It also points out the absence of key baselines and suggests that the paper should introduce essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. While the comment provides some reasoning by mentioning the combination of existing methods and the absence of key baselines, it lacks specific references or detailed explanations to fully substantiate the claim. The suggestion to introduce specific algorithms is a logical deduction but could be strengthened with more detailed justification or examples. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional evidence or examples to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by pointing out the incremental nature of the contribution and suggesting that the paper is essentially a combination of existing methods, specifically GraphRAG and GraphCare. It also highlights the absence of key baselines and recommends the introduction of essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This feedback is actionable and provides clear guidance on how the authors can improve their paper by expanding the discussion and introducing relevant literature. However, the comment could be more helpful if it offered specific suggestions on how to integrate these algorithms or provided examples of how they could enhance the paper. Overall, the comment is mostly helpful as it identifies areas for improvement and offers a direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This action is clear and direct, providing a specific and concrete step for the authors to take to address the issue of understanding whether the performance improvement is solely due to the network design or the nature of ImageNet. The comment also highlights the importance of this analysis, giving the authors a clear direction on what to include in their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This provides clear guidance on which part of the paper should be addressed, making it easy for the authors to identify the specific section. The comment also specifies what needs to be addressed, namely understanding whether the performance improvement is solely due to the network design or the nature of ImageNet. This level of detail ensures that the authors know exactly what is expected in terms of analysis and presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. The rationale provided explains the importance of this analysis in understanding whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet. The comment highlights the potential unfair advantage of algorithms that skip layers or channels, which is a relevant consideration for the authors to address. However, the comment could be strengthened by providing specific examples or references to support the claim about the potential unfair advantage. Overall, the comment is mostly verifiable as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. This is important for understanding whether the performance improvement is solely due to the network design to exploit spatial redundancies or whether it is influenced by the nature of ImageNet. The comment also highlights the potential unfair advantage of algorithms that skip layers or channels, which is a relevant consideration for the authors to address. By suggesting this specific analysis, the comment offers a clear direction for the authors to improve their draft, making it mostly helpful. However, it could be more helpful if it provided additional guidance on how to interpret the results or what specific insights the graph should reveal. Overall, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the evaluation of the time-aware model, suggesting that the effectiveness of the proposed methods might be questionable when the training and evaluation time-steps are different. It implies that the authors should consider evaluating their methods under different time-step scenarios to better understand their performance. However, the comment does not explicitly instruct the authors to conduct such evaluations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the need for additional evaluations and how to conduct them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the effectiveness of the proposed methods when the training and evaluation time-steps are the same, suggesting that the authors should consider different scenarios where the time-steps are different. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 5 shows similar performance between the baseline model and the time-aware model when trained and evaluated with the same time-step, which raises questions about the effectiveness of the proposed methods. The reviewer suggests that the proposed methods might make more sense under different scenarios where the training and evaluation time-steps are different. However, the comment lacks specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to conduct additional evaluations or provide further analysis to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the evaluation of the time-aware model, noting that similar performance is observed when trained and evaluated with the same time-step. It questions the effectiveness of the proposed methods under these conditions and suggests that the authors should consider evaluating their methods under different time-step scenarios. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation methodology. By addressing this concern, the authors can gain a better understanding of their model's performance and potentially enhance its applicability. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these additional evaluations. Overall, the comment is mostly helpful, as it offers valuable insights and suggestions for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the clarity of how disentanglement is guaranteed in the paper. It notes that the \"Broader Impacts and Limitations\" section mentions a limitation regarding obtaining fully disentangled latent vectors but does not provide details on how this is realized or guaranteed. The comment explicitly suggests that the authors should clarify this aspect, indicating a clear action for the authors to take. However, it does not provide specific guidance on how to address this issue, such as which sections or methods should be revised. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not specify which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the realization and guarantee of disentanglement, but without full grounding, it is challenging for the authors to pinpoint the exact sections to revise. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation regarding obtaining fully disentangled latent vectors. However, the comment does not provide specific examples or detailed reasoning to support the claim that the disentanglement is not clear. The reference to the \"Broader Impacts and Limitations\" section provides some context, but it does not offer sufficient evidence or explanation to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the 'Broader Impacts and Limitations' section mentions a limitation regarding obtaining fully disentangled latent vectors, it does not provide details on how this is realized or guaranteed. This feedback is clear and actionable, as it directs the authors to clarify this aspect, which is crucial for understanding the methodology and results. However, the comment could be more helpful if it suggested specific ways to address the issue, such as which sections or methods should be revised to provide more clarity. Overall, the comment is mostly helpful as it highlights a significant area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that to compare the obtained complexity for the proposed method with previous results in a strongly-convex concave case, the authors should use standard regularization tricks. While the comment implies that the authors should incorporate these tricks, it does not explicitly instruct them to do so or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should use regularization tricks and how to apply them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using standard regularization tricks to compare the obtained complexity of the proposed method with previous results in a strongly-convex concave case. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result. The authors might infer that it relates to the comparison or analysis section, but this inference is not explicit. The comment is specific in its suggestion to use regularization tricks, but it lacks grounding as it does not specify the exact part of the paper where this comparison is made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use standard regularization tricks to compare the obtained complexity of their proposed method with previous results in a strongly-convex concave case. However, the comment does not provide any specific examples or references to support the claim that regularization tricks are necessary or how they would improve the comparison. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should use standard regularization tricks to compare the obtained complexity of their proposed method with previous results in a strongly-convex concave case. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which regularization tricks to use or how they might enhance the comparison. The feedback is somewhat helpful as it points out a potential enhancement, but it does not offer actionable steps or examples, leaving the authors with limited guidance on how to implement the suggestion. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss how to handle different types of inputs, such as bio-medical signals or speech, and present their solutions in the paper. It also mentions that the citation seems disordered. While the comment implies that the authors should address the issue of input handling and improve the citation order, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address these issues. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two distinct issues: the handling of different types of inputs and the order of citations. However, it does not specify which part of the paper these issues are related to, making it weakly grounded. The comment is specific in suggesting that the authors discuss how to deal with different types of inputs and present their solutions, and it also notes that the citation order seems disordered. However, without explicit references to sections or figures, the authors may struggle to pinpoint the exact parts of the paper that need attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss how to handle different types of inputs, such as bio-medical signals or speech, and provides a suggestion for improvement. However, it does not provide specific examples or detailed reasoning to support why this is important or how it could be addressed. The comment also mentions that the citation seems disordered, but without further explanation or examples, it remains vague. Therefore, the comment is somewhat verifiable, as it provides a suggestion but lacks detailed justification or evidence to fully support the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, suggesting that the authors should discuss how to handle different types of inputs, such as bio-medical signals or speech. This is a valuable suggestion as it highlights a potential weakness in the paper's methodology or applicability. Additionally, the comment notes that the citation seems disordered, which could be an issue for the paper's clarity and credibility. While the comment provides clear guidance on what the authors should address, it could be more helpful if it offered specific examples or suggestions on how to improve the handling of different inputs or the citation order. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Wh-types\" or not transformable. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the generalization or what steps to take to mitigate the problem. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to question answering, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Wh-types\" or not transformable. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The authors can infer that it relates to the question answering process, but without explicit references, it remains challenging to pinpoint the exact section. The comment is specific in detailing the potential issue with generalization, providing a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the question answering process requires template mapping to transform questions into masked statements, which might lead to poor generalization to questions that are not \"Wh-types\" or not transformable. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific reasoning or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically the need for template mapping to transform questions into masked statements. It suggests that this might lead to poor generalization to questions that are not \"Wh-types\" or not transformable. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this issue or improve the generalization of their approach. Without actionable steps or detailed feedback, the authors are left with a general understanding of the problem but without clear directions on how to resolve it. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a significant issue with the ICL-HAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to discuss or acknowledge it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the impact of the ICL-HAR on accuracy scores, specifically mentioning the drop from 70.4 to 55.6 on TRIP. However, it does not specify which part of the paper discusses the ICL-HAR or the accuracy scores, making it weakly grounded. The comment is specific in detailing the issue with the ICL-HAR's impact on accuracy, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the ICL-HAR improves consistency and verifiability but negatively impacts accuracy scores, specifically mentioning a drop from 70.4 to 55.6 on TRIP. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the ICL-HAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It specifically mentions a drop in accuracy scores from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. While the comment highlights a critical point, it does not provide specific guidance on how to discuss or acknowledge this issue, leaving the authors with a general direction but no actionable steps. Therefore, the comment is somewhat helpful, as it points out a significant concern but lacks depth and specificity in its feedback.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to \"cite the source appropriately\" regarding the rock-paper-scissors example, which is inspired by a previous work. This provides a clear and direct action for the authors to take, ensuring they give proper credit to the original source. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to cite the source appropriately. This provides clear guidance on what needs to be done to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by previous work and suggests citing the source appropriately. However, the comment does not provide any specific references or examples of previous work that the example is inspired by, nor does it explain why this is important to cite. Without additional context or evidence, the claim is difficult for the authors to verify and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or references to support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the use of the rock-paper-scissors example, noting that it is inspired by previous work. It provides a clear and actionable suggestion for the authors to cite the source appropriately. This feedback is helpful as it guides the authors to ensure proper attribution and acknowledges the influence of prior work, which is an important aspect of academic integrity. However, the comment could be more helpful if it provided specific examples of previous work or detailed guidance on how to cite the source. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that needs attention.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to compare the performance of the model not only on synthetic data but also on real-world datasets with different losses. This provides a clear and direct action for the authors to take, which is to demonstrate the importance of the three projection errors by showing performance on both synthetic and real-world data. The comment is explicit and concrete, giving the authors a clear path to follow for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"comparing the performance of the model only pre-trained on synthetic data,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the comparison is unfair and recommending that the authors demonstrate the importance of the three projection errors by providing performance on both synthetic and real-world datasets with different losses. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparing the performance of the model only pre-trained on synthetic data is unfair and suggests that demonstrating the importance of the three projection errors is more appropriate. However, the comment does not provide specific examples or references to support why this comparison is unfair or how the three projection errors are important. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of the model\\'s performance, specifically noting that comparing it only on synthetic data is unfair. It suggests that demonstrating the importance of the three projection errors would be more appropriate by showing performance on both synthetic and real-world datasets with different losses. This feedback is clear and actionable, providing the authors with a specific direction for improvement. By suggesting a more comprehensive evaluation, the comment helps the authors enhance the robustness and relevance of their findings. However, it could be more helpful if it offered additional guidance on how to effectively demonstrate the importance of the three projection errors. Overall, the comment is mostly helpful, as it directs the authors towards a meaningful enhancement of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit suggestion for the authors to conduct calibration curves to demonstrate the agreement between predicted scores and actual risk. It also recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. These suggestions are concrete and provide specific steps for the authors to take, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"model AUC,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the model discriminant ability may be hard to show its consistency between predicted scores and actual risk, and it highlights the importance of calibration curves to demonstrate this agreement. The comment further suggests proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the model\\'s AUC may not consistently reflect the actual risk, which could be a concern for clinical scoring systems. It recommends conducting calibration curves to demonstrate the agreement between predicted scores and actual risk, and it suggests proving the feasibility of the generated scoring system. While the comment provides a logical argument for the importance of calibration curves, it lacks specific examples or references to support the claim about the consistency of the AUC. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for the authors to conduct calibration curves to demonstrate the agreement between predicted scores and actual risk, which is crucial for the clinical scoring system. It also recommends proving the feasibility of the generated scoring system and discussing the difference between the traditional method and the proposed method. These suggestions are specific and provide the authors with a clear path for improving their draft, making the comment highly helpful. However, the comment could be more helpful if it included examples or references to similar studies that have successfully demonstrated these aspects. Overall, the feedback is mostly helpful, as it offers valuable guidance for enhancing the paper's content and impact.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests that the presentation of bits should be clarified as representation bits in Section 4.3. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues. The action to clarify the presentation is somewhat vague, as it does not specify how to rephrase or restructure the content. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Section 4.3,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. Additionally, it suggests clarifying the presentation of bits as representation bits. This provides clear guidance on what needs to be addressed in the section, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the lack of insight into why all sparsity patterns perform similarly and whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests clarifying the presentation of bits as representation bits in Section 4.3. While the comment raises valid questions about the analysis and presentation, it lacks specific examples or references to support the claim about the generalizability of the observation to GNNs. The suggestion to clarify the presentation is clear, but the overall justification for the claim is somewhat vague, making the comment mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also points out a specific issue with the presentation of bits in Section 4.3, suggesting that they should be clarified as representation bits. While the comment highlights important areas for improvement, it lacks detailed guidance on how to address these issues or what specific changes should be made. The feedback is somewhat helpful as it provides a direction for the authors to consider, but it could be more comprehensive and actionable to be fully beneficial. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests clarifying the presentation of bits as representation bits in Section 4.3. While the comment points out specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The suggestion to clarify the presentation is somewhat vague, as it does not specify how to rephrase or restructure the content. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Section 4.3,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of insight into why all sparsity patterns perform similarly and questions whether this is unique to the sparsity detection problem or a general characteristic of GNNs. Additionally, it suggests clarifying the presentation of bits as representation bits. This provides clear guidance on what needs to be addressed in the section, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the lack of insight into why all sparsity patterns perform similarly and whether this is unique to the sparsity detection problem or a general characteristic of GNNs. It also suggests clarifying the presentation of bits as representation bits in Section 4.3. While the comment raises valid questions about the analysis and presentation, it lacks specific examples or references to support the claim about the generalizability of the observation to GNNs. The suggestion to clarify the presentation is clear, but the overall justification for the claim is somewhat vague, making the comment mostly verifiable. Therefore, the comment aligns with a score of 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. It also recommends including a discussion on the advantages and disadvantages of different methods for transforming high-dimensional data to a low-dimensional latent space. While the comment explicitly states these actions, it does not provide specific guidance on how to conduct these comparisons or discuss the advantages and disadvantages. The authors are left with a clear direction but without detailed instructions on how to implement these suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for experimental comparisons with methods like CaCE and raw gradients, as well as a discussion on the advantages and disadvantages of different methods for transforming high-dimensional data to a low-dimensional latent space. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. It also recommends including a discussion on the advantages and disadvantages of different methods for transforming high-dimensional data to a low-dimensional latent space. While the comment provides a logical basis for the claim, it lacks specific examples or references to support the comparison with CaCE or raw gradients. The suggestion for a discussion on the advantages and disadvantages of different methods is a general recommendation that could be improved with more detailed examples or references. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by suggesting that the authors should provide experimental comparisons with other methods, such as CaCE or raw gradients, to support their argument for using Shapely value explanations. This feedback is clear and actionable, as it provides a direct way for the authors to strengthen their argument and demonstrate the superiority of their approach. Additionally, the comment recommends including a discussion on the advantages and disadvantages of different methods for transforming high-dimensional data to a low-dimensional latent space, which could further enhance the paper's comprehensiveness and utility. By addressing these points, the authors can significantly improve the depth and rigor of their work. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the manuscript to the contributions of prior efforts. While it implies that such a comparison would be beneficial, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison in their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from a comparison of the perspective taken in the manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made, making it difficult for the authors to identify the exact section that needs attention. While the authors can infer that it pertains to Section 6, the comment lacks specificity in detailing what specific aspects of the perspective or contributions should be compared. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that Section 6 could benefit from a comparison of the perspective taken in the manuscript to the contributions of prior efforts. However, it does not provide any specific examples, references, or reasoning to support why such a comparison would be beneficial or how it could enhance the manuscript. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that Section 6 could benefit from a comparison of the perspective taken in the manuscript to the contributions of prior efforts. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct this comparison or what specific aspects should be considered. The feedback is somewhat helpful as it points out a potential enhancement, but it does not offer actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance of the model is closely related to the number of scenarios used for training and proposes examining the performance with different numbers of scenarios. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests examining the performance with different numbers of scenarios, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of the model is closely related to the number of scenarios used for training. While this is a logical claim, it lacks specific evidence or examples to support the assertion that varying the number of scenarios would significantly impact performance. The comment does not provide detailed reasoning or references to substantiate the claim, making it somewhat verifiable. The authors would need to conduct additional experiments or provide more detailed analysis to fully understand the impact of the number of scenarios on performance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the performance of the model is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, which is a specific and actionable suggestion. This feedback provides a clear direction for the authors to explore, potentially leading to a better understanding of the model\\'s performance and its limitations. However, the comment could be more helpful if it included specific recommendations on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve or expand upon their experimental setup or results. As a result, the comment lacks actionable information, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"experiments\" and \"CATER,\" but it does not specify which part of the paper these experiments are discussed in or how they relate to the main claims or findings. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in describing the comprehensive nature of the experiments, including architectural mismatches and cross-domain imitation, but it does not provide detailed guidance on what aspects of the experiments need improvement or clarification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point describes the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment consists solely of factual statements about the experiments, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment highlights the comprehensive nature of the experiments conducted by the authors to validate the efficacy of CATER in various settings, including architectural mismatches and cross-domain imitation. This feedback provides insight into the thoroughness of the experimental validation, which is valuable information for the authors. However, the comment lacks specific suggestions or guidance on how the authors might improve or expand upon their experimental setup or results. While it offers some insight into the strengths of the study, it does not provide actionable feedback that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a positive aspect but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Appendix A.2 does not illustrate the state space representation of the environment clearly. This provides a clear and direct action for the authors to take, which is to improve the clarity of the representation in Appendix A.2. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in illustrating the state space representation of the environment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. By pointing out this lack of clarity, the comment provides a clear and actionable feedback for the authors to improve the presentation of this information. However, it does not offer suggestions on how to enhance the clarity or provide examples of how to improve the representation. While it highlights a critical area for improvement, the feedback could be more helpful if it included specific guidance or examples. Therefore, the comment is somewhat helpful, as it directs the authors to a specific area needing attention but lacks depth in its suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the authors\\' approach, stating that it is only applicable to small or medium-scale problems and will be overwhelmed by truly large problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve their approach for larger-scale problems. The comment lacks actionable guidance, leaving the authors without a clear direction for enhancing their work. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a limitation of the authors\\' approach, stating that it is only applicable to small or medium-scale problems and will be overwhelmed by truly large problems. However, it does not specify which part of the paper this limitation is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in identifying the issue of scalability, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable to small or medium-scale problems and will be overwhelmed by truly large problems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this assertion, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation of the authors\\' approach, stating that it is only applicable to small or medium-scale problems and will be overwhelmed by truly large problems. This feedback is somewhat helpful as it points out a potential issue that the authors need to consider when scaling their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or improve their approach for larger-scale problems. Without actionable advice or examples, the feedback is incomplete, leaving the authors with a general understanding of the problem but no clear path forward. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explicitly instruct the authors to incorporate these references or discuss the implications of these extensions. While the comment provides valuable information, it lacks actionable guidance on how the authors should utilize this information to improve their draft. Therefore, the comment is somewhat actionable, as it provides some insight but does not offer clear instructions for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment discusses the bounded noise assumption and mentions several efforts to extend these noise conditions, referencing specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing the efforts to extend noise conditions and provides references to relevant works, which helps the authors understand the context and potential improvements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounded noise assumption is somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. However, the comment does not explain why the bounded noise assumption is restrictive or how the referenced works extend these conditions. While the references provide some support, the lack of detailed reasoning or specific examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights the bounded noise assumption as somewhat restrictive in stochastic optimization literature and mentions several efforts to extend these noise conditions. It provides references to specific works by A. Khaled and P. Richt\\u00e1rik and R. Gower, O. Sebbouh, and N. Loizou. This feedback is valuable as it directs the authors to relevant literature that could inform their work. However, the comment does not offer specific guidance on how to incorporate these references or how they might impact the authors\\' research. While it provides a starting point for further exploration, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the motivation for using characteristic function regularization. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might clarify their motivation or what specific aspects need to be addressed. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity in the motivation for using characteristic function regularization, but it does not specify which part of the paper this issue is addressed in. The authors cannot confidently determine which section or part of the paper the comment refers to, making it weakly grounded. The comment is specific in identifying the issue of unclear motivation, but without grounding, it is difficult for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation for using characteristic function regularization is not clear. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, namely the lack of clarity in the motivation for using characteristic function regularization. This feedback is valuable as it points out a potential weakness in the paper that the authors should address. However, the comment does not provide any suggestions or guidance on how the authors might clarify their motivation or improve the explanation. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, which are standard in contextual linear bandits. The reviewer notes that the combination of these techniques is not surprising and suggests that the contribution may be incremental. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the paper\\'s combination of existing techniques, specifically mentioning the adaptation to an unknown level of corruption (Lykouris et al., 2018), varying variances treated with a weighted version of OFUL (Zhou et al., 2021), and variable decision sets (standard in contextual linear bandits). This provides full grounding as the authors can accurately identify the parts of the paper being discussed. The comment also specifies that the combination of these techniques is not surprising, suggesting that the contribution may be incremental. However, it does not provide specific guidance on how the authors might enhance their contribution or differentiate their work from existing techniques. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s results are a combination of existing techniques, which is not surprising and may suggest that the contribution is incremental. However, the comment does not provide specific examples or references to support the claim that these techniques are indeed standard or widely known. Without detailed justification or evidence, the claim remains somewhat verifiable, as it lacks the depth and specificity needed for the authors to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper by noting that the results appear to be a combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. The reviewer suggests that the combination of these techniques is not surprising and may indicate that the contribution is incremental. While the comment points out a potential issue, it lacks actionable feedback or suggestions for how the authors might address this concern or enhance their contribution. Without specific guidance or recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more details about the aggregation operation after \"Integration\" in the main paper. It also suggests acknowledging the structure of other architectures if they are referenced. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The comment provides concrete guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of clarification regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It specifies the need for more details in the main paper and the acknowledgment of other architectures\\' structure. This provides full grounding as it explicitly mentions the part of the paper being addressed and is specific in detailing what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification and recommends providing more details in the main paper. It also advises acknowledging the structure of other architectures if referenced. While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that these clarifications are necessary. The suggestion is somewhat verifiable as it points out a potential issue but does not provide detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for clarification regarding the aggregation operation after \"Integration\" in the context of multiscale modeling. It provides a clear and actionable suggestion by recommending that the authors provide more details in the main paper and acknowledge the structure of other architectures if referenced. This feedback is valuable as it guides the authors in enhancing the clarity and completeness of their work, making it mostly helpful. However, it could be more helpful if it included specific examples or references to illustrate the need for clarification. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate this information into their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the related work and possibly integrate it into their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the use of energy models for image generation is less explored compared to GANs and VAEs, and it highlights the similarity between the model\\'s motivation and goals to a prior VAE paper. However, it does not specify which part of the paper this observation pertains to, such as the introduction or related work section. The authors can infer that it relates to the motivation and goals of the model, but the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in identifying the similarity to a prior VAE paper, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and it suggests that the model\\'s motivation aligns with a prior VAE paper. However, the comment does not provide specific examples or references to support the claim about the exploration of energy models or the comparison with GANs and VAEs. The mention of a prior VAE paper provides some context, but without detailed examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable, as it requires more detailed support to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model align with a prior VAE paper, suggesting that the authors should consider this related work. However, the comment lacks specific guidance or actionable suggestions on how the authors might incorporate this information into their draft or improve their approach. While it identifies an area for further exploration, it does not provide detailed feedback or constructive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate this information into their draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the related work and possibly integrate it into their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the potential for exploring energy models for image generation, noting that it is less explored compared to GANs and VAEs. It also suggests that the motivation and goals of the model align with a prior VAE paper, as detailed in the related work section. However, the comment does not specify which part of the paper this observation pertains to, such as the introduction or related work section. The authors can infer that it relates to the motivation and goals of the model, but the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in identifying the similarity to a prior VAE paper, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the use of energy models for image generation is less explored compared to GANs and VAEs, and it suggests that the model's motivation aligns with a prior VAE paper. However, the comment does not provide specific examples or references to support the claim about the exploration of energy models or the comparison with GANs and VAEs. The mention of a prior VAE paper provides some context, but without detailed examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable, as it requires more detailed"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should evaluate their method on a different benchmark, such as Atari, to assess its generalizability to other domains and its performance with discrete action spaces and high-dimensional observations. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable. The reviewer specifies the benchmark and the aspects to consider, giving the authors a clear path forward in improving their draft. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the evaluation of the method, specifically mentioning that it is evaluated only on tasks from the Meta World domain, which is a robotic manipulation domain. The reviewer suggests that the authors should run experiments on a different benchmark, such as Atari, to assess the method\\'s generalizability to other domains and its performance with discrete action spaces and high-dimensional observations. This feedback is fully grounded as it explicitly mentions the Meta World domain and suggests a specific benchmark (Atari) for further evaluation. It is also specific because it provides a clear direction for the authors to improve their draft by suggesting a different benchmark and detailing the aspects to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation of the method is limited to a single domain, making it difficult to judge its generalizability. The reviewer suggests running experiments on a different benchmark, such as Atari, to address this limitation. The claim is supported by logical reasoning, as it points out the need for broader evaluation to assess the method\\'s applicability across different domains. However, the comment could be strengthened by providing specific examples or references to similar studies that have successfully generalized across domains. Overall, the claim is mostly verifiable due to the logical reasoning provided, but it could be further strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the evaluation of the method, noting that it is only tested on tasks from the Meta World domain, which is a robotic manipulation domain. This limits the ability to judge the method\\'s generalizability to other domains. The reviewer provides a clear and actionable suggestion by recommending that the authors run experiments on a different benchmark, such as Atari, which is commonly used in the literature. This benchmark would allow for evaluation with discrete action spaces and high-dimensional observations, providing a more comprehensive assessment of the method\\'s capabilities. The feedback is detailed and constructive, offering a specific direction for improvement that could significantly enhance the paper\\'s impact and rigor. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis of what the model does, which could be very interesting. However, it does not provide specific guidance on what aspects of the model should be analyzed or how this analysis should be conducted. The action is implicit and somewhat vague, as the authors need to infer the details of the analysis required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that while the method is presented nicely and the experiments are good, there is a lack of analysis on what the model does. However, it does not specify which part of the paper this analysis should be included in, nor does it provide guidance on what aspects of the model should be analyzed. This makes it difficult for the authors to identify the exact sections that need revision. The comment is weakly grounded because it does not specify the part of the paper being addressed, and it is not specific about what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that while the method is presented nicely and the experiments are good, there is a lack of analysis on what the model does. However, the comment does not provide specific examples or reasoning to support why this analysis is missing or how it could be included. Without detailed justification or references, the claim lacks verifiability. Therefore, the comment is considered borderline verifiable, as it provides some insight but requires more detailed support to be fully convincing.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges that the method is presented well and the experiments are good, but it suggests that there is a lack of analysis on what the model does. This feedback is somewhat helpful as it identifies a potential area for improvement, specifically the need for a deeper analysis of the model's functionality. However, the comment lacks specificity and does not provide guidance on how to conduct this analysis or what aspects should be focused on. Without detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, as it points out a potential area for enhancement but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on the task setup, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. This provides a clear and direct action for the authors to take, which is to clarify these aspects in their draft. The comment is explicit and concrete, giving the authors a specific direction on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the task setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified, namely, which notes in the EHR are used as input and how far away the outcomes are from the last note date. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the clarity of the task setup, specifically asking about the use of notes in the EHR and the distance between the last note date and outcomes. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this clarity is important or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires clarification, namely the task setup. It points out that the authors need to clarify which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the clarity of their draft. By addressing this issue, the authors can enhance the comprehensibility of their work for readers. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how to clarify it. Overall, the comment is mostly helpful, as it guides the authors toward improving the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the reason why their proposed algorithm DMLCBO does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO, which use the double momentum technique. It also requests a discussion on the theoretical technique differences between DMLCBO and these previous works. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed discussion on the convergence rate and theoretical differences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and references specific previous works, SUSTAIN and MRBO, which use the double momentum technique. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely, the reason why DMLCBO does not achieve the same convergence rate as the referenced works and the theoretical technique differences between DMLCBO and these previous works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm DMLCBO does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO, which use the double momentum technique. The reviewer provides references to these previous works and suggests that the authors discuss the reason for this discrepancy and the theoretical technique differences. However, the comment lacks specific details or analysis to support the claim that DMLCBO does not achieve the same convergence rate. The references to previous works provide some context, but the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by pointing out that the proposed algorithm DMLCBO does not achieve the same convergence rate as previous works, such as SUSTAIN and MRBO, which use the double momentum technique. It suggests that the authors discuss the reason for this discrepancy and the theoretical technique differences between DMLCBO and these previous works. This feedback is clear and actionable, as it provides a specific area for the authors to address and improve their draft. By addressing this issue, the authors can enhance the theoretical foundation of their work and potentially strengthen its contribution to the field. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the scalability aspect, but it lacks concrete steps or recommendations on how to mitigate the potential scalability problem. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the modulator, which is a specific element of the paper, providing a clear reference to the part of the paper being discussed. It also raises a concern about scalability and the potential need for tedious hyperparameter tuning for diverse training data. This provides a specific issue for the authors to address, making the comment fully grounded. However, it does not specify how the authors should address the scalability issue or suggest potential solutions. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a concern about the scalability of the modulator, suggesting that it might require tedious hyperparameter tuning for diverse training data. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the modulator, noting that it is heuristically designed and suggesting that there might be scalability concerns. It raises a concern about the need for tedious hyperparameter tuning for diverse training data, which is a valid point that could impact the practicality and generalizability of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative approaches or strategies for improving scalability. While it highlights an important area for consideration, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should conduct such experiments, but it lacks concrete details or steps on how to implement them. As a result, the authors are left with a vague understanding of what needs to be done, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the application of imitation learning, specifically the need for labeled data and the potential difficulties in obtaining it. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the lack of experiments on the difficulty of obtaining labeled data and the impact of data size on performance. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there are no experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the lack of experiments on the difficulty of obtaining labeled data and how performance changes with the size of the labeled data when applying imitation learning. This is a relevant and important point that could impact the validity and applicability of the research. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing experiments or methodologies to investigate these aspects. While it highlights a critical area for improvement, the feedback is somewhat helpful as it points out a gap in the paper but does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment points out that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific NLP tasks to explore. The comment implies that the authors should expand their analysis to other tasks, but it lacks concrete details or actionable steps on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses the paper's focus on contrastive learning in code search tasks and suggests that it does not thoroughly explore the implications of the proposed method for other NLP tasks. However, it does not specify which part of the paper discusses the method's generalizability or where the authors should expand their analysis. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in its critique of the paper's generalizability, but without clear references or examples, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper does not thoroughly explore the implications of its proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's exploration of the proposed method's generalizability to other NLP tasks. It suggests that the paper could benefit from a more comprehensive analysis to enhance the generalizability of the results. However, the comment lacks specific guidance or suggestions on how the authors might expand their analysis or which other NLP tasks could be explored. While it points out an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative terminology or providing a rationale for why \"certificate\" is appropriate in the context of the paper. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 267,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"certificate,\" suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, suggesting that it might be misinterpreted due to its strong meaning in complexity theory. This is a valuable observation that could help the authors clarify the terminology and ensure that it is understood in the intended context. However, the comment lacks specific guidance or suggestions on how to address this issue, such as proposing alternative terminology or providing a detailed explanation of the term \"certificate\" in the context of the paper. While it highlights an important point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct additional experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet. It provides specific references to existing works, including [1] MoBiNet, [2] Dynamic Channel Pruning, and [3] Learning Dynamic Routing, which the authors can use as a basis for their experiments. This feedback is explicit and provides concrete guidance on what experiments to perform and which references to use, making it highly actionable. The authors know exactly how to apply the suggested changes to strengthen their paper, aligning with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet, to strengthen the paper. It provides references to existing works, including [1] MoBiNet, [2] Dynamic Channel Pruning, and [3] Learning Dynamic Routing, which the authors can use as a basis for their experiments. This feedback is fully grounded as it explicitly mentions specific references and experiments that the authors can perform to enhance their work. The comment is also specific, as it clearly outlines what additional experiments are needed and provides examples of relevant works. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet, are needed to strengthen the paper. It provides references to existing works, including [1] MoBiNet, [2] Dynamic Channel Pruning, and [3] Learning Dynamic Routing, which the authors can use as a basis for their experiments. This provides a clear and specific suggestion for additional experiments, making the claim mostly verifiable. However, the comment could be strengthened by explaining why these specific references are relevant or how they would enhance the paper. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct additional experiments on deeper networks, such as ResNet-50, and other network structures, like MobileNet, to further strengthen their paper. It provides specific references to existing works, including [1] MoBiNet, [2] Dynamic Channel Pruning, and [3] Learning Dynamic Routing, which the authors can use as a basis for their experiments. This feedback is clear and actionable, offering the authors a concrete path to improve their work by expanding their experimental setup. By following this suggestion, the authors can demonstrate the generalizability of their approach across different network architectures, which is a significant contribution to the field. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. While it acknowledges the thoroughness of the analysis, it does not provide explicit guidance on how the authors should address this limitation. The comment lacks specific suggestions or actions for the authors to take, such as recommending the inclusion of more recent or larger models, or discussing the implications of using only two models. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the evaluation of the results and analysis, noting that only two relatively old and small models are evaluated. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the limitation of the evaluation, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the results and analysis are detailed and comprehensive, but only two relatively old and small models are evaluated. This claim is somewhat verifiable as it highlights a potential limitation in the evaluation process. However, the comment lacks specific examples or references to support the claim that the models are \"old\" or \"small,\" making it difficult for the authors to fully understand and address the issue. Additionally, the comment does not provide suggestions on how to improve the evaluation or what specific models should be considered. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the evaluation of the results and analysis, noting that only two relatively old and small models are evaluated. While it points out a specific area for improvement, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this limitation. Without additional context or specific recommendations, the authors may find it challenging to effectively improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not offer detailed guidance or actionable steps for the authors to take.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS when certain conditions are met. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or incorporate it into their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific claim about the relationship between KD (Knowledge Distillation) and LS (Label Smoothing), suggesting that KD can be viewed as a special form of LS under certain conditions. However, it does not specify which part of the paper this observation is relevant to, making it weakly grounded. The comment is specific in detailing the conditions under which KD and LS are equivalent, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a rationale for this claim by explaining that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS become equivalent. This explanation offers a logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the equivalence of KD and LS under these conditions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides a nuanced perspective on the relationship between these two techniques, which could be valuable for the authors to consider. However, the comment lacks depth and does not offer actionable advice or suggestions on how the authors might incorporate this insight into their work. It does not provide specific guidance on how to address this observation or its implications for the paper's content or analysis. As a result, the comment is somewhat helpful, as it offers a potential area for exploration but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or incorporate it into their work. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. However, it does not specify which part of the paper this observation is relevant to, making it weakly grounded. The comment is specific in detailing the conditions under which KD and LS are equivalent, but without explicit references to the paper, the authors may struggle to identify the exact context. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. The reviewer provides a rationale for this claim by explaining that when the teacher network is uniformly distributed and the temperature is set at 1, KD and LS become equivalent. This explanation offers a logical reasoning for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the equivalence of KD and LS under these conditions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment acknowledges that KD (Knowledge Distillation) and LS (Label Smoothing) are not identical but suggests that KD can be viewed as a special form of LS under specific conditions. This observation provides a nuanced perspective on the relationship between these two techniques, which could be"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include more recent works on dynamic-pruning methods and provide results on large-scale datasets like ImageNet. While the comment implies that the authors should update their work to include these recent works and results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should update their paper with more recent works and larger datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.3. 2021,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper should include more recent works on dynamic-pruning methods and provide results on large-scale datasets like ImageNet. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should include more recent works on dynamic-pruning methods and provide results on large-scale datasets like ImageNet. However, it does not provide specific examples of recent works or detailed reasoning as to why these additions are necessary. The claim is somewhat verifiable as it highlights a potential area for improvement but lacks the depth and specificity needed for a fully verifiable comment. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by noting that the discussion of competing dynamic-pruning methods is outdated. It suggests that the authors should include more recent works in their analysis. Additionally, the comment points out that only results on small-scale datasets are provided, recommending the inclusion of results on large-scale datasets like ImageNet to further validate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides specific suggestions for improving the paper's comprehensiveness and relevance. However, it could be more helpful if it offered additional guidance on how to integrate these recent works or how to structure the discussion to effectively address the suggested improvements. Overall, the comment is mostly helpful, as it directs the authors toward meaningful enhancements to their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It asks why this particular dimension of difficulty is interesting, implying that the authors should provide a rationale or explanation for this decision. However, the comment does not explicitly instruct the authors to include such an explanation or suggest how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for their choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"images used in this paper sample,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds and why this particular dimension of difficulty is interesting. The comment provides a clear direction for the authors to address, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that the authors should provide a rationale for why this particular dimension of difficulty is interesting. However, the comment does not provide any specific reasoning or evidence to support the claim that this choice is not well motivated. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a logical question but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a valid concern about the motivation behind the choice of using randomly sampled CIFAR images as backgrounds to make the task harder. It questions why this particular dimension of difficulty is interesting, implying that the authors should provide a rationale or explanation for their decision. This feedback is somewhat helpful as it prompts the authors to consider and articulate the significance of their choice, which could enhance the clarity and impact of their work. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to justify the choice. Overall, the comment provides a direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the text inside the figure and the labels are too small to read without zooming, and it suggests that they should be roughly the same size as the manuscript text. This provides a clear and direct action for the authors to take, which is to ensure that the text in the figure is legible without zooming. The comment is explicit and concrete, giving the authors a specific task to address, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the text inside the figure and the labels,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the text is too small to read without zooming, and suggests that it should be roughly the same size as the manuscript text. This provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text inside the figure and the labels are too small to read without zooming, suggesting that they should be roughly the same size as the manuscript text. This is a subjective observation that requires the authors to make a judgment about the legibility of the text. However, the comment does not provide any supporting evidence, such as examples of the text or references to similar issues in other figures, which would help the authors understand the extent of the problem. Without additional context or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of the text inside the figure and labels, noting that they are too small to be legible without zooming. It provides a clear and actionable suggestion by recommending that the text should be roughly the same size as the manuscript text. This feedback is valuable as it helps the authors improve the accessibility and clarity of their figures, which is an important aspect of effective communication in scientific writing. However, the comment could be more helpful if it included specific recommendations on how to achieve this size or if it discussed the potential impact of this issue on the overall presentation of the results. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. This provides a clear and direct action for the authors to take, which is to revise the introduction. The comment is explicit and concrete, as it specifies the exact part of the paper that needs attention and what action should be taken. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the motivation is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction is unclear or what aspects need to be revised. This lack of specificity makes it difficult for the authors to identify the exact areas that need attention. The comment is weakly grounded because it does not provide explicit references to specific sections, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the motivation is not clear, suggesting that the introduction should be revised to make the paper easier to follow. However, the comment does not provide any specific examples, reasoning, or references to support why the motivation is unclear or how it could be improved. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity in the motivation presented in the introduction. It provides a clear and actionable suggestion for improvement, recommending that the introduction be revised to make the paper easier to follow. This feedback is valuable as it directs the authors to a specific area that needs attention and offers a concrete step for improvement. However, the comment could be more helpful if it provided additional guidance on how to revise the introduction or what aspects of the motivation should be clarified. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement and offers a clear direction for the authors.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the intuition behind including multiple local prompts, noting that the features and their positions differ across categories. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. This makes it difficult for the authors to identify the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the paper need to be addressed or improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the intuition that including multiple local prompts is beneficial but points out that the features and their positions differ across categories. While it identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this difference or improve their approach. The comment provides a starting point for the authors to consider, but it does not offer actionable advice or detailed feedback that could lead to significant improvements in the draft. Therefore, it is rated as somewhat helpful, as it highlights a potential area for improvement but does not fully support the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the alignment of relabeled reward data with human annotator judgments, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what steps should be taken to improve the validation process. Without specific suggestions or directions, the authors are left without a clear understanding of how to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the alignment of relabeled reward data with human annotator judgments, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue with the validation of the alignment, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments is insufficiently validated. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the validation of the alignment between relabeled reward data and human annotator judgments. However, it lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve the validation process. Without actionable feedback or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not provide the authors with a clear path forward.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper only conducts experiments on a limited number of molecules and provides in-distribution testing for these samples. It suggests that the value of the method might be limited if it requires training for each molecule individually. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their experiments or consider alternative approaches. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically mentioning the limited number of molecules and the in-distribution testing provided. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the limitation of the experiments, suggesting that the value of the method might be limited if it requires individual training for each molecule. This provides clear guidance on what needs to be addressed, making the comment specific. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s value would be limited if it requires individual training for each molecule, suggesting that the experiments are conducted on a limited number of molecules and only provide in-distribution testing. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the assertion. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it requires the authors to infer the implications of the claim themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper's experimental setup, specifically noting that the experiments are conducted on a limited number of molecules and only provide in-distribution testing. It suggests that the value of the method might be limited if it requires individual training for each molecule. This feedback is somewhat helpful as it points out a potential weakness in the experimental design that could impact the generalizability of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this limitation, such as expanding the number of molecules tested or exploring out-of-distribution testing. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the symbols used in the paper are complicated and take a long time to understand. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to simplify the symbols or improve their clarity, nor are there suggestions for alternative approaches. As a result, the authors are left without any actionable steps to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that symbols are complicated and take a long time to understand, but it does not specify which part of the paper these symbols are used in or provide any context about their complexity. This makes it difficult for the authors to identify the exact sections that need revision. Additionally, the comment lacks specificity regarding what aspects of the symbols are complicated or how they could be simplified. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that symbols are complicated and take a long time to understand, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the complexity of symbols used in the paper, noting that they take a long time to understand. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might simplify or clarify these symbols. Without actionable feedback or detailed advice, the comment does not offer the authors a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests comparing the results of a model that cannot capture periodic relationships with those of an explicitly compositional model. However, the comment does not provide explicit guidance or instructions on how the authors should conduct this comparison or what specific aspects they should focus on. The action is implicit and somewhat vague, as the authors need to infer that they should perform a specific comparison and analyze the results. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests comparing a model that cannot capture periodic relationships with an explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, such as a specific experiment or section. The authors might infer that it relates to the experimental results or discussion, but this inference is not explicit. The comment is specific in its question about the comparison of models, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests comparing a model that cannot capture periodic relationships with an explicitly compositional model. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this concern. Without additional context or justification, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the extent to which the results are influenced by the ability to capture periodicity rather than compositionality more generally. It suggests comparing a model that cannot capture periodic relationships with an explicitly compositional model, which is a relevant and insightful point. However, the comment lacks specificity and does not provide detailed guidance on how the authors should conduct this comparison or what specific aspects they should focus on. While it identifies an important area for exploration, the feedback could be more helpful with additional details or suggestions. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a critical aspect of their work but does not fully guide them in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses dissatisfaction with the paper\\'s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes that there are issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide specific guidance or suggestions on how to improve these aspects. The authors are left without clear instructions on what changes to make or how to enhance the writing and presentation. As a result, the comment lacks actionable details, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses dissatisfaction with the paper\\'s writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which sections or parts of the paper are affected, making it difficult for the authors to identify the exact areas needing improvement. The lack of specific guidance or examples leaves the authors without clear direction on how to address these issues. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is not well-written and possibly hurriedly written, making it difficult to read. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without detailed feedback or evidence, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses dissatisfaction with the paper's writing quality, suggesting that it may have been written in a hurry and is difficult to read. It also notes issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how to improve the writing or presentation. Without detailed guidance or examples, the authors are left without a clear understanding of what aspects need improvement and how to address them. As a result, the comment is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide specific guidance on what aspects of the introduction need to be expanded or how to make it more detailed. The action is implicit, as the authors can infer that they need to provide more information about orthogonality, but it lacks concrete details on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction or Part 2 is being addressed, making it weakly grounded. The comment is specific in its suggestion to provide more detail on orthogonality, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the introduction to orthogonality in Part 2 could be more detailed. While it identifies a specific area for improvement, it lacks specificity and does not provide any guidance on what aspects of the introduction need to be expanded or how to make it more detailed. Without actionable feedback or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and actionable suggestions.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights similarities between the current analysis and prior works, suggesting that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. However, the comment does not offer explicit guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback lacks actionable steps or concrete advice, leaving the authors without a clear path forward. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a detailed critique of the analysis, comparing it to prior works and suggesting that the results are not surprising due to similarities with existing studies. It references specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. However, the comment does not explicitly mention which part of the paper this critique pertains to, making it weakly grounded. The authors can infer that it relates to the analysis or results section, but this inference is not direct. The comment is specific in detailing the similarities and comparisons to prior works, providing a clear basis for the critique. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that similar analyses are present in prior works and that the results are not particularly surprising. It provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. This provides a logical basis for the claim, as it references existing literature and studies that have explored similar topics. However, the comment could be strengthened by providing more detailed references or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a strong foundation but lacks some specific details for full verification. The score 4 aligns with this assessment.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty and originality of the analysis presented in the paper. It points out that similar analyses are already present in prior works, suggesting that the results may not be particularly surprising. The comment provides specific examples, such as the robustness of CIFAR-10 models on various distributions, which have been studied in RobustBench and other works. This feedback is somewhat helpful as it highlights a potential weakness in the originality of the research, prompting the authors to consider whether their work adds significant value or presents new insights. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or enhance the originality of their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead in determining the optimal trade-off between model size and accuracy. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or suggestions for alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), which are specific elements of the paper. However, it does not specify which part of the paper discusses these parameters or how they are used in the study. The authors can infer that this comment relates to the experimental section or methodology, but the lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in identifying the potential issue of computational overhead, but it does not provide detailed guidance on how to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor) may introduce significant computational overhead in determining the optimal trade-off between model size and accuracy. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead in determining the optimal trade-off between model size and accuracy. This is a relevant observation that could impact the efficiency and effectiveness of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the computational overhead. While it highlights an important consideration, the feedback is somewhat helpful as it points out a potential weakness but does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the characterization of the study as an \"ablation\" study, stating that it does not involve removing a component of the method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might reframe their study or what specific aspects need to be addressed to align with the concept of an ablation study. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the characterization of a study about different subdomain sizes as an \"ablation\" study, suggesting that it does not involve removing a component of the method. However, it does not specify which part of the paper this critique pertains to, such as a specific section or table where the study is described. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique, as it clearly identifies the issue with the characterization of the study, but it lacks grounding, making it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the study about different subdomain sizes is not an \"ablation\" study because it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. Without further explanation or references, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it provides a claim but lacks sufficient justification or evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the characterization of a study about different subdomain sizes as an 'ablation' study, suggesting that it does not involve removing a component of the method. This feedback is somewhat helpful as it identifies a potential misinterpretation of the study's methodology. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or improve their characterization. Without actionable advice or suggestions, the feedback is limited in its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include these specific competitors. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, it does not specify which part of the paper this evaluation is currently addressing, making it weakly grounded. The comment is specific in suggesting that the evaluation should include these competitors, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, the comment does not provide specific reasoning or evidence to support why these particular competitors are relevant or why their inclusion would strengthen the evaluation. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential improvement in the evaluation section by suggesting that the base DA methods should be compared with and without the architectural competitors, such as AutoDial and AdaBN. This feedback is somewhat helpful as it provides a specific direction for enhancing the evaluation, which could strengthen the paper's argument and provide a more comprehensive comparison. However, the comment could be more helpful if it included specific details on how to incorporate these comparisons or why they are important. Overall, the comment offers a clear suggestion for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include these specific competitors. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, it does not specify which part of the paper this evaluation is currently addressing, making it weakly grounded. The comment is specific in suggesting that the evaluation should include these competitors, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. However, the comment does not provide specific reasoning or evidence to support why these particular competitors are relevant or why their inclusion would strengthen the evaluation. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. This feedback is somewhat helpful as it provides a specific direction for enhancing the evaluation, which could strengthen the paper's argument and provide a more comprehensive comparison. However, the comment could be more helpful if it included specific details on how to incorporate these comparisons or why they are important. Overall, the comment offers a clear suggestion for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment suggests that the evaluation could be strengthened by comparing the base DA methods with and without the architectural competitors, such as AutoDial and AdaBN. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their evaluation to include these specific competitors. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a weakness in the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the evaluation or what specific steps they should consider. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern about the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. However, it does not specify which part of the paper this evaluation is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in pointing out the issue with the baselines, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation is weak because the baselines used in the paper are not designed for fair classification. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation, specifically noting that the baselines used in the paper are not designed for fair classification. This feedback is valuable as it highlights a potential weakness in the methodology that could impact the validity of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the evaluation. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the setting in the first three paragraphs of section 2 needs to be clarified. It suggests that the authors may be implying a greater generality than what is actually presented, which could be confusing. This feedback provides a clear and direct action for the authors to take, which is to clarify the setting. The comment is explicit and concrete, guiding the authors on exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the first three paragraphs, which is the need for clearer explanation of the setting. The comment highlights a potential issue with the authors\\' claim of doing something in greater generality than what is presented, which provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the first three paragraphs of section 2 need to be clarified because the authors imply a greater generality than what is actually presented, which muddles the exposition. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2. It points out that the authors may be implying a greater generality than what is actually presented, which could confuse the reader. This feedback is clear and actionable, as it directs the authors to clarify the setting to improve the clarity and coherence of their exposition. However, the comment could be more helpful if it provided specific suggestions on how to clarify the setting or examples of what could be done to address the issue. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the convincing nature of the experiments, specifically questioning the choice of the old baseline like R3D and C3D. It suggests that the authors should consider using more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment implies that the authors should explore these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the proposed method\\'s compatibility with 3D CNNs and its advantages over existing approaches. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments section, specifically questioning the choice of old baselines like R3D and C3D. It suggests that the authors should consider more recent and computationally efficient approaches like X3D and SlowFast. The comment also asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment does not explicitly mention a specific section, it is clear that it pertains to the experiments section, allowing the authors to infer the relevant part of the paper. However, the comment lacks specificity in detailing what aspects of the experiments are not convincing or how the proposed method compares to the mentioned approaches. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of old baselines like R3D and C3D for the experiments, suggesting that more recent and computationally efficient approaches like X3D and SlowFast have been proposed. The reviewer asks whether the proposed method works on these 3D CNNs and what its advantages are compared to these approaches. While the comment raises a valid concern about the relevance and effectiveness of the chosen baselines, it lacks specific examples or references to support the claim that these newer approaches are more suitable. The suggestion to compare the proposed method with these 3D CNNs provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the choice of old baselines like R3D and C3D for the experiments, suggesting that more recent and computationally efficient approaches like X3D and SlowFast have been proposed. It questions whether the proposed method also works on these 3D CNNs and what its advantages are compared to these approaches. This feedback is somewhat helpful as it identifies a potential weakness in the experimental setup and prompts the authors to consider more recent and efficient baselines. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue or what aspects of the proposed method might offer advantages over the mentioned approaches. Overall, the comment provides a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on how the attention module is attached to the ResNet-20 architecture and how many attention modules are used. It also inquires about their placement, whether after each block or stage. This feedback provides a clear and direct action for the authors to take, which is to clarify these aspects in their draft. The request is specific and actionable, as it outlines what information needs to be added or clarified to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"attention module\" and the \"ResNet-20 architecture,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding how the attention module is attached to the backbone architecture and where it is placed. The comment provides a clear direction for the authors to improve the clarity of their description, making this comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the implementation of the attention module in the ResNet-20 architecture. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the implementation of the attention module in the ResNet-20 architecture. It questions the number and placement of attention modules, which is crucial for understanding the methodology and reproducibility of the work. By asking for clarification on these aspects, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how to clarify the information. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises two points. First, it questions the precision of the bitrate range used for BD-rate comparison, suggesting that the authors clarify this aspect. Second, it recommends a related work for discussion or comparison, specifically mentioning Guo Lu's paper on content adaptive algorithm in learned video compression. While the comment provides explicit actions for the authors to take, such as clarifying the bitrate range and incorporating a specific related work, it does not offer detailed guidance on how to implement these actions. The authors are aware of what needs to be done but may require additional information to fully execute the suggestions. Therefore, the comment is mostly actionable.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment addresses two specific issues: the precision of the bitrate range used for BD-rate comparison and the suggestion to include a related work on content adaptive algorithm in learned video compression. It provides a clear and specific reference to Guo Lu's work, which the authors should consider for discussion or comparison. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises two issues: the precision of the bitrate range used for BD-rate comparison and the suggestion to include a related work on content adaptive algorithm in learned video compression. The first part of the comment questions the precision of the bitrate range, which is a factual observation that requires clarification. The second part suggests a specific related work for discussion or comparison, which is a suggestion rather than a claim. Therefore, the comment consists of a mix of factual statements and suggestions, making it mostly verifiable. The authors would need to clarify the precision of the bitrate range and consider incorporating the suggested related work to fully address the feedback.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises two points for the authors to consider. First, it questions the precision of the bitrate range used for BD-rate comparison, suggesting that the authors clarify this aspect. This feedback is specific and actionable, prompting the authors to ensure that their comparison is based on a clear and consistent bitrate range. Second, the comment recommends a related work on content adaptive algorithm in learned video compression, which could be discussed or compared to the proposed method. This suggestion provides a valuable direction for the authors to enhance the context and relevance of their work. Overall, the comment is mostly helpful as it identifies specific areas for improvement and offers constructive guidance, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should distinguish between the all-or-nothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While the comment implies that the authors should make this distinction, it does not provide explicit guidance on how to achieve this or what specific changes should be made. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should distinguish between the all-or-nothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide specific guidance on how to achieve this distinction. The authors may have an idea of where this distinction could be relevant, but the comment lacks explicit grounding and specificity. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should distinguish between the all-or-nothing or cutoff phenomenon and usual statistical bounds familiar to the machine learning and NeurIPS community. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this distinction is necessary or how it would impact the paper. Without additional context or explanation, the claim remains unverifiable, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should distinguish between the all-or-nothing or cutoff phenomenon and usual statistical bounds that are familiar to the machine learning and NeurIPS community. While this is a valid point, the comment lacks specificity and does not provide detailed guidance on how the authors should make this distinction or why it is important. Without additional context or examples, the authors may find it challenging to understand the significance of this distinction and how it could improve their work. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the theoretical result, which only provides utility guarantees under the assumption that features and noise are Gaussian. It suggests that this is a strong requirement on the data and compares it to previous algorithms that do not require this assumption. Additionally, the comment recommends that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the action is explicit, it is somewhat vague as it does not provide specific guidance on how to address the limitation or how to compare the rates. The authors know they need to consider the Gaussian assumption and compare their results to existing literature, but the comment lacks detailed instructions on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical result in the paper, specifically mentioning that it provides utility guarantees only when features and noise are Gaussian. This is a strong requirement on the data, and the reviewer suggests comparing the rates achieved by the procedure to existing rates in the literature. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the theoretical results section. The comment is specific in detailing the issue with the Gaussian assumption and the need for comparison to existing rates. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical result in the paper provides utility guarantees only when features and noise are Gaussian, which is a strong requirement on the data. The reviewer compares this to previous algorithms that do not require this assumption, suggesting that the authors should compare their rates to existing rates in the literature. The claim is somewhat verifiable as it provides a logical reasoning for the need to compare rates and highlights a potential limitation of the theoretical result. However, it lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the theoretical result, which provides utility guarantees only under the assumption that features and noise are Gaussian. This is a strong requirement on the data, and the reviewer points out that previous algorithms do not require this assumption. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. This feedback is clear and actionable, as it highlights a critical area for improvement and provides a specific direction for the authors to enhance their draft. By addressing this limitation and comparing their results to existing literature, the authors can strengthen their paper. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. While the comment implies that such a comparison would be useful, it does not explicitly instruct the authors to perform this comparison or provide guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, it does not specify which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in its suggestion to compare with the original approach and the type of data to use, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. However, the comment does not provide any specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial for the authors to compare their proposed extension with the original approach from Schiratti et al. (2015), particularly on simulated data. This feedback is somewhat helpful as it identifies a potential area for improvement by highlighting the need for a comparison with a relevant existing work. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. To be more helpful, the comment could include suggestions on how to structure the comparison or what specific aspects of the original approach should be examined. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method. It mentions specific works ([1, 2, 3]) that focus on similar questions, implying that these comparisons should be included. While the comment explicitly states the action needed, it does not provide detailed guidance on which specific aspects of the proposed method should be compared or how to structure these additional experiments. The suggestion is concrete in terms of what needs to be added, but the lack of detailed instructions makes it somewhat vague. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks full specificity in execution.\", 'actionability_label': '4', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'experimental section' of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue, which is the lack of additional experimental comparisons to demonstrate the effectiveness of the proposed method. The comment references specific works ([1, 2, 3]) that focus on similar questions, providing a clear direction for the authors to expand their experimental comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that the authors should include additional experimental comparisons to demonstrate the effectiveness of their proposed method, referencing specific works ([1, 2, 3]) that focus on similar questions. This provides a clear rationale for the claim, as it highlights the need for more comprehensive experimental validation. However, the comment could be strengthened by providing more detailed reasoning or examples of how these additional comparisons would enhance the paper's impact. Despite this, the general logic and references make the claim mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the experimental section of the paper, suggesting that the authors should include additional comparisons with other relevant works. It provides a clear rationale by mentioning specific references ([1, 2, 3]) that focus on similar questions, indicating that these comparisons would enhance the paper's effectiveness. This feedback is actionable and provides a clear direction for the authors to improve their draft by expanding their experimental validation. However, the comment could be more helpful if it offered suggestions on how to structure these additional comparisons or what specific aspects of the proposed method should be compared. Overall, the comment is mostly helpful as it guides the authors towards a significant enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis on BRP-NAS is somewhat barebones, as it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to expand their analysis to include more NAS approaches, but the comment lacks concrete suggestions on which specific approaches to include or how to conduct the additional comparisons. Therefore, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the analysis on BRP-NAS, specifically mentioning that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This provides some grounding as it allows the authors to identify the part of the paper being discussed, but it does not specify which sections or figures are affected. The comment is specific in pointing out the lack of comparison with other NAS approaches, which is a clear area for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the analysis on BRP-NAS is \"somewhat barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This claim is somewhat verifiable as it identifies a specific limitation in the analysis, but it lacks detailed examples or references to other NAS approaches that could have been included. The comment suggests that the authors should expand their analysis, but it does not provide specific guidance on which approaches to include or how to conduct the additional comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some justification but lacks comprehensive support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the analysis of BRP-NAS, noting that it only compares against three basic alternatives and ignores other NAS approaches like super-net/one-shot methods. This feedback is clear and actionable, as it directs the authors to expand their analysis to include a broader range of NAS approaches. By providing a specific area for enhancement, the comment offers valuable guidance that can help the authors improve the depth and comprehensiveness of their analysis. However, the comment could be more helpful if it suggested specific NAS approaches to include or how to conduct the additional comparisons. Overall, the comment is mostly helpful, as it effectively points out a limitation and provides a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that more information is needed on the translation and filtering methodology used to create the Arabic climate change QA dataset. This feedback provides a clear and direct action for the authors to take, which is to include additional details about the process. The comment specifies what needs to be addressed, making it explicit and concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of details regarding the filtering process used to create the Arabic climate change QA dataset. It specifies that more information on the translation and filtering methodology is needed to assess the dataset quality. However, it does not explicitly mention which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, which is the lack of information on the filtering process. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the details around the filtering process used to create the Arabic climate change QA dataset are lacking, and more information on the translation and filtering methodology is needed to assess the dataset quality. This claim is somewhat verifiable as it identifies a specific area where the paper lacks detail, but it does not provide specific examples or references to support the claim. The authors would need to infer the exact nature of the missing information, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it provides a specific area for the authors to address, which could significantly improve the transparency and credibility of their work. However, the comment could be more helpful if it suggested how the authors might obtain or present this additional information. Overall, the comment is mostly helpful, as it guides the authors toward a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment results can be enriched by including more attacks with varying strengths and exploring how different thresholds affect detection performance. While the comment implies that these additions would be beneficial, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but lack detailed instructions on how to conduct them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiment results can be enriched by including more attacks with varying strengths and exploring how different thresholds affect detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental results section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, namely the inclusion of more attacks and the exploration of different thresholds. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results can be enriched by including more attacks with varying strengths and exploring how different thresholds affect detection performance. However, the comment does not provide specific examples or references to support the claim that these additions would be beneficial. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two specific areas where the paper could be improved: the inclusion of more attacks with varying strengths and the exploration of how different thresholds affect detection performance. This feedback is clear and actionable, as it provides the authors with specific directions on how to enhance their experimental results. By suggesting these additions, the comment offers a concrete path for the authors to improve the depth and robustness of their analysis. However, the comment could be more helpful if it provided examples of how these enhancements could be implemented or if it discussed the potential impact of these changes on the paper's conclusions. Overall, the comment is mostly helpful as it guides the authors in making meaningful improvements to their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to know the extent of the performance difference resulting from using different image sizes and different variations of ResNets. While the comment implies that the authors should investigate and report this difference, it does not provide explicit instructions on how to conduct this analysis or what specific metrics or methods should be used. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L170,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is understanding the performance difference resulting from using different image sizes and ResNet variations. This provides clear guidance on what the authors should investigate and report. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for more information, specifically asking for clarification on the performance difference resulting from using different image sizes and ResNet variations. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment is somewhat helpful as it identifies a specific area where the authors could provide more information, namely the performance difference resulting from using different image sizes and ResNet variations. However, it lacks depth and does not offer suggestions on how to conduct this analysis or what specific metrics or methods should be used. While it prompts the authors to consider a potential area for improvement, it does not provide detailed guidance or actionable steps, leaving the authors with a general direction but no concrete path forward. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not provide specific guidance on what aspects of the algorithm should be detailed or how the description should be structured. The action is implicit, as the authors need to infer that they should provide a detailed description of the algorithm, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or subsection. Without explicit references to the paper, the authors may find it challenging to determine where to make these improvements. Additionally, the comment lacks specificity regarding what aspects of the algorithm should be detailed or how the description should be structured. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to enhance understanding of the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the algorithm should be presented and described in detail, which would help in understanding the proposed method. While this feedback highlights an area for improvement, it lacks specificity and does not provide actionable guidance on how to enhance the description or what aspects of the algorithm should be detailed. Without additional details or examples, the authors may find it challenging to implement this suggestion effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. It implies that the authors should explore this possibility or acknowledge that it is an open problem. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to include a specific reference or discussion on this topic. The action is implicit but concrete, as the authors know what needs to be done to address the suggestion. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FFNs\" and references a specific issue discussed in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it suggests exploring existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment provides a clear direction for improvement by suggesting that the authors either explore this possibility or acknowledge it as an open problem. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even though a linear decomposition cannot be obtained. The comment implies that there might be alternative methods or approximations that could be explored. However, it does not provide specific references or examples of such work, making it somewhat verifiable. The authors would need to conduct additional research to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the omission of FFNs due to the inability to obtain a linear decomposition. It suggests that the authors consider existing work that might offer a way to compute the contribution of FFNs, even if it is an approximation. This feedback is valuable as it encourages the authors to explore alternative approaches or acknowledge the limitations of their current methodology. By suggesting a potential solution or highlighting an open problem, the comment provides actionable guidance that could enhance the paper\\'s comprehensiveness and clarity. However, it could be more helpful if it included specific references or examples of relevant work. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with more detailed suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: (1) How does the number of images impact the model performance, and (2) whether more training images make the performance worse or better. It also suggests that BYOL should be explained in the abstract for its first appearance. While the questions provide some guidance, they are not explicit about how the authors should address these issues. The suggestion to explain BYOL in the abstract is somewhat vague, as it does not specify how the authors should explain it. Therefore, the comment is somewhat actionable, as it provides some direction but lacks concrete details on how to implement the suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the impact of the number of images on model performance and the explanation of BYOL in the abstract. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questions, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions and a suggestion for clarification. It does not contain any subjective opinions, judgments, or claims that require verification. The questions are factual and seek clarification, while the suggestion for clarification is a request for additional information. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions and provides a suggestion for clarification. The first question asks about the impact of the number of images on model performance, which is a relevant inquiry for understanding the model\\'s behavior. The second question seeks an explanation of BYOL in the abstract, which is important for readers who may not be familiar with the concept. While the comment identifies areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues or enhance their draft. The feedback is somewhat helpful as it points out areas that need clarification but does not provide detailed advice on how to improve them.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should provide stronger arguments or intuitions to explain why the method works, particularly regarding the L_pixel component. While the comment implies that the authors should include more detailed explanations, it does not explicitly instruct them to do so or provide specific guidance on how to structure these explanations. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed reasoning. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the 'L_pixel' component, which is a specific part of the paper, providing full grounding. It also specifies the issue by asking for stronger arguments or intuitions to explain why these particular losses are 'bound to help.' This level of detail allows the authors to accurately identify the part of the paper being addressed and understand what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point questions the clarity of the explanation regarding why the method works, specifically regarding the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the current explanation is unclear. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the nature of the issue and how to address it. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of improvement regarding the clarity of the explanation for why the method works, particularly focusing on the L_pixel component. It suggests that providing stronger arguments or intuitions would be beneficial. This feedback is clear and actionable, as it directs the authors to enhance their explanation by offering more detailed reasoning or intuition. However, the comment could be more helpful if it provided specific examples or guidance on how to strengthen the arguments or intuitions. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for enhancement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors might address this concern, such as suggesting additional data collection or analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to justify the sufficiency of their dataset or consider expanding it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the dataset size being insufficient to capture a wide range of user traits and personalities across different content topics. It questions the sufficiency of 44k dialogues in comparison to the vast amount of tokens typically used in LLM training. The comment is fully grounded as it explicitly mentions the dataset size and the comparison to trillions of tokens, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the dataset size and the need for a larger dataset to cover varied domains. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer provides a logical reasoning by comparing the dataset size to the scale of LLM training data, suggesting that the dataset needs to be massive to cover varied domains. However, the comment lacks specific references or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to conduct further analysis or provide additional context to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the sufficiency of the dataset size (44k dialogues) in capturing a wide range of user traits and personalities across different content topics. It questions whether this dataset is adequate to cover the combinations of personalities and topics, given that LLMs are typically trained on trillions of tokens. The reviewer suggests that the dataset needs to be massive to cover varied domains, which is a valid point. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as expanding the dataset or exploring alternative methods to capture diverse user traits. While it identifies a potential weakness, the feedback could be more helpful with actionable advice. Therefore, the comment is somewhat helpful, as it provides insight but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the justification of using binary classification as a baseline metric, particularly regarding its ability to assess models\\' understanding of fine-grained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their baseline metrics. The action is implicit and vague, as the authors are left to infer that they need to reconsider their choice of baseline metrics or provide a more detailed justification. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models\\' understanding of fine-grained errors like technique errors. However, it does not specify which part of the paper discusses the baseline metrics or the TAL task, making it weakly grounded. The comment is specific in its critique of the binary classification's limitations, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models\\' understanding of fine-grained errors like technique errors. The reviewer acknowledges the importance of the TAL task but expresses uncertainty about the effectiveness of binary classification in evaluating this aspect. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the concern. The reasoning is logical but lacks detailed evidence, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the use of binary classification as a baseline metric, specifically questioning its ability to assess models' understanding of fine-grained errors like technique errors. While the reviewer acknowledges the importance of the TAL task, they express uncertainty about the effectiveness of binary classification in evaluating this aspect. This feedback is somewhat helpful as it identifies a potential limitation in the methodology and encourages the authors to consider alternative metrics or approaches. However, the comment could be more helpful if it provided suggestions on how to address this concern or offered alternative metrics that might better capture the desired evaluation. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, to understand when SynTextBench should be used over other metrics. While the comment implies that the authors should conduct this comparison, it does not provide explicit instructions on how to perform the comparison or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SynTextBench metric\" and references \"other metrics proposed in the literature,\" such as MMLU and Big Bench. This allows the authors to accurately identify the part of the paper being addressed, which is the comparison of SynTextBench to other metrics. The comment is also specific because it clearly specifies what needs to be addressed, namely understanding the conditions under which SynTextBench should be used over other metrics. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there has been a large amount of work on LLM evaluation and that some metrics do not satisfy the proposed desiderata. It suggests comparing the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench, to understand when SynTextBench should be used over other metrics. The comment provides a logical reasoning for the comparison, suggesting that it would be beneficial to include this comparison to clarify the conditions under which SynTextBench should be used. However, the comment lacks specific references or examples of the metrics being compared, which could strengthen the justification. Therefore, the claim is mostly verifiable, as it provides a clear rationale but could be improved with more detailed references or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the authors compare the SynTextBench metric to other metrics proposed in the literature, such as MMLU and Big Bench. This comparison could help clarify when SynTextBench should be used over other metrics. The comment is specific and provides a clear direction for the authors to enhance their work by offering a comparative analysis. However, it could be more helpful if it included specific guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it provides actionable feedback that can significantly improve the draft, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not provide explicit guidance on how the authors should address this issue or what alternative approach they should consider. The comment implies that the authors should reconsider their decision, but it lacks concrete suggestions or steps on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the decision to consider only segments with one label, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind considering only ECG segments with one label assigned, suggesting that the associated reports might be easier to handle if all reports were included. This feedback prompts the authors to reconsider their methodology and potentially expand their analysis to include more complex cases. However, the comment does not provide specific guidance or suggestions on how to address this issue or what alternative approaches might be more appropriate. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two specific areas where the paper could be improved: the discussion of scalability bounds and the lack of clarity regarding memory requirements and computational complexity. While the comment identifies these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their discussion on scalability and provide more detailed analysis of memory requirements and computational complexity. However, the lack of specific suggestions or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Scalability Bounds\" and \"memory requirements or computational complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the lack of discussion on the upper limits of scalability and the absence of a clear discussion on memory requirements and computational complexity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the upper limits of FedDES\\'s scalability and lacks a clear discussion of memory requirements or computational complexity. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two specific areas where the paper could be improved: the discussion of scalability bounds and the lack of clarity regarding memory requirements and computational complexity. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors enhance the completeness and depth of their analysis. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to improve the discussion. Overall, the feedback is mostly helpful as it directs the authors' attention to important areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects need clarification. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs clarification. The comment is specific in its inquiry about the impact of the base node, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the inquiry. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the relationship between the base node and the ordering, key nodes for attention, and model performance. While it identifies a potential area of confusion or complexity in the paper, it does not provide any guidance or suggestions on how the authors might address this issue or improve their understanding of the topic. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it highlights a potential area for clarification but does not offer actionable insights or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space into the latent space. This implies that the authors should reconsider the direction of the arrow to align with the intended purpose of influencing n^(i). However, the comment does not provide explicit instructions on how to make this change or why it is necessary. The action is implicit and somewhat vague, as the authors need to infer the need for a change and how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the direction of the arrow in the figure and suggests that it should be from the latent space to n^(i) instead of the current direction. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space into the latent space. The reviewer implies that the main purpose is to influence n^(i), but does not provide specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to substantiate the suggestion, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a suggestion but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a specific question about the direction of the arrow in Figure 2, suggesting that it should be from the latent space to n^(i) instead of from a Gaussian space into the latent space. This feedback is somewhat helpful as it points out a potential inconsistency or confusion in the figure's representation. However, it lacks depth and does not provide guidance on why this change might be necessary or how it could impact the overall understanding of the figure. To be more helpful, the comment could include reasoning or suggestions on how this change could improve the clarity of the figure or the overall presentation of the results. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the use of abbreviations in the paper, particularly the abbreviation \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. While the comment points out the lack of definition for abbreviations, it does not provide explicit instructions on how the authors should address this issue. The authors are left to infer that they need to define all abbreviations used in the paper, but the comment lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it highlights a specific area for improvement but does not provide detailed instructions on how to execute the action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of definition for abbreviations, particularly the abbreviation \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definition and causes confusion, specifically mentioning \"AR\" in Table 5 as an example. However, the comment does not provide any additional context, reasoning, or examples to support why this is a significant issue or how it affects the clarity of the paper. Without further elaboration or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations in the paper, noting that many abbreviations lack definition and cause confusion. It provides a specific example by mentioning \"AR\" in Table 5, which stands for domain adaptation tasks and algorithms. This feedback is clear and actionable, as it highlights a concrete area where the authors can improve the clarity of their work by defining abbreviations. However, the comment could be more helpful if it suggested how the authors might define these abbreviations or provided examples of how to do so. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it does not provide explicit guidance or suggestions for the authors to follow. The comment implies that the authors should consider other technical aspects when using advantage, but it does not specify what these aspects might be or how they should be addressed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it does not explicitly mention a specific part of the paper, the authors can infer that it relates to the methodology or analysis section. The comment is specific in questioning the technical basis for using advantage, which provides some guidance on what needs to be addressed. However, the lack of explicit mention of a section or part of the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the technical considerations for using advantage instead of q value in the analysis. It acknowledges that using advantage is more common in practice but seeks clarification on other technical aspects that might influence this choice. The comment does not contain a claim or an opinion that requires verification. It is a question seeking further explanation or justification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the technical considerations for using advantage instead of q value in the analysis. While it acknowledges that using advantage is more common in practice, it seeks clarification on other factors that might influence this choice. This feedback is somewhat helpful as it prompts the authors to consider additional aspects of their methodology, potentially leading to a more robust analysis. However, the comment lacks specific guidance or suggestions on how to address this question, which limits its usefulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights an issue with the fairness of the performance comparison in Table 1, specifically noting that VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. This comment implies that the authors should consider adjusting the comparison to ensure fairness, but it does not explicitly instruct them to do so. The action is implicit, as the authors need to infer that they should address the fairness of the comparison. However, the comment provides a clear and specific issue to address, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the performance comparison, noting that VINS sets different sample weights while most compared baselines set all sample weights as 1. This provides clear guidance on what needs to be addressed in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair due to differences in sample weights used by VINS compared to other baselines. The reviewer provides a specific observation about the sample weights, which supports the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to investigate further to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the performance comparison in Table 1, noting that the comparison is unfair due to differences in sample weights used by VINS compared to other baselines. This feedback is clear and actionable, as it highlights a potential weakness in the evaluation methodology that the authors should address. By pointing out this discrepancy, the comment provides a concrete direction for improvement, making it mostly helpful. However, it could be more helpful if it suggested how the authors might adjust the comparison to ensure fairness. Overall, the comment is valuable in guiding the authors towards enhancing the rigor of their evaluation, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting alternative approaches or optimizations. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. However, it does not specify which part of the paper discusses the reply buffer or the time complexity, making it weakly grounded. The comment is specific in identifying the potential issue with the time complexity, but without explicit references to the paper, the authors may struggle to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper, \"PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning.\" However, the comment does not provide detailed reasoning or evidence to support why this is a concern or how it affects the paper. The reference to another paper is a step towards verification, but it lacks specific examples or detailed analysis to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks comprehensive justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the algorithm, specifically mentioning that it will be too high if the reply buffer is too large. This is a relevant observation that could impact the practicality and efficiency of the proposed method. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the algorithm's efficiency. Without actionable advice or detailed feedback, the authors are left with a general insight but no clear path for improvement. Therefore, the comment is somewhat helpful, as it points out a potential problem but does not provide enough detail to be fully beneficial.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. While the comment provides a clear direction for improvement, it does not specify which baselines should be included or how the authors should incorporate these perspectives. The action is explicit but lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting ways to improve the performance display, but without grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment does not provide specific references or examples of these baselines, making it difficult for the authors to understand the exact suggestions or how to implement them. The lack of detailed guidance or references limits the verifiability of the claim, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is somewhat helpful as it provides a clear direction for improvement by suggesting specific areas to explore and compare with existing work. However, the comment lacks detailed guidance on which baselines to include or how to incorporate these perspectives, which could limit its effectiveness. The authors would benefit from more specific suggestions or examples to fully utilize this feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to incorporate these perspectives. The action is implicit, as it requires the authors to infer the need for additional comparisons and the specific baselines to consider. While the comment suggests a direction for improvement, it lacks concrete details on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting ways to improve the performance display, but without grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific references or examples of these baselines, making it difficult for the authors to understand the exact suggestions or how to implement them. The lack of detailed guidance or references limits the verifiability of the claim, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is somewhat helpful as it provides a clear direction for improvement by suggesting specific areas to explore and compare with existing work. However, the comment lacks detailed guidance on which baselines to include or how to incorporate these perspectives, which could limit its effectiveness. The authors would benefit from more specific suggestions or examples to fully utilize this feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this comparison in their paper. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include a comparison with a method designed to defend against multiple attacks, which provides some guidance on what the authors could do to improve their paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This claim is somewhat verifiable as it provides a logical suggestion for improvement, but it lacks specific examples or references to existing methods that could be used for comparison. The comment implies that such a comparison would be beneficial, but without detailed guidance or examples, the authors may find it challenging to implement the suggestion effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should compare their framework with a method designed to defend against multiple attacks, such as the defense against multiple attacks. This is a constructive suggestion that could enhance the paper's relevance and impact by providing a more comprehensive comparison. The comment also acknowledges the paper's interesting study on defending against increasing malicious perturbations, which adds value to the feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this comparison. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to define the bounds for \\u03c7_i^l, which is crucial for understanding the time-warp function. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l111,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is defining the bounds for \\u03c7_i^l to improve understanding of the time-warp function. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification, asking the authors to define the bounds for \\u03c7_i^l. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, providing a specific request for the authors to define the bounds for \\u03c7_i^l. This is important for understanding the time-warp function, which is a critical aspect of the paper. By addressing this request, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional context or suggestions on how to define these bounds or why they are important. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the efficiency or whether there are alternative methods to consider. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the efficiency of pairwise matching, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to use in practical application systems. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the assertion, making it difficult to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern about the efficiency of pairwise matching, stating that it is very low and difficult to use in practical application systems. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the efficiency of their approach. Without actionable advice or detailed feedback, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not offer constructive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not provide specific guidance or suggestions on how to improve the allocation of Figure 1 or the editing of the main paper. The authors are left with a vague understanding of what needs to be addressed, making it difficult to know how to implement the suggested changes. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment does not specify which part of the main paper needs editing or provide details on what aspects should be improved. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need attention. Additionally, the comment does not provide any guidance on how to address these issues, leaving the authors without clear direction. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the critique.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive. It also implies that the authors could have edited the space of the main paper more wisely. However, the comment lacks specificity and does not provide actionable guidance on how to improve the allocation of Figure 1 or the editing of the main paper. Without detailed suggestions or examples, the authors are left with a vague understanding of what needs to be addressed, making the feedback somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the first sentence of the abstract needs to be rewritten, providing a clear and direct action for the authors to take. This feedback is specific and actionable, as it gives the authors a specific task to perform to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions the first sentence of the abstract, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the sentence needs to be rewritten. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for a specific action, namely to rewrite the first sentence of the abstract. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it directly instructs the authors to rewrite the first sentence of the abstract. This feedback provides a clear direction for improvement, which is valuable for the authors to enhance the clarity and effectiveness of their abstract. However, the comment does not offer additional guidance or suggestions on how to improve the sentence or what specific changes should be made. While it is clear and actionable, it could be more helpful if it included more detailed advice or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to implement this idea or whether it should be considered a significant contribution. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the idea of adding a method on top of other methods to improve transferability, but it does not specify which part of the paper this suggestion is intended for. The authors cannot confidently determine which section or aspect of the paper the comment refers to, making it weakly grounded. The comment is specific in suggesting that this approach is good but not significant, providing a clear direction for the authors to consider. However, without explicit grounding, the comment is not fully actionable. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method on top of other methods to improve transferability is a good idea but not a significant contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this approach is not significant. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that adding a method on top of other methods to improve transferability is a good idea. However, it does not provide any further explanation or guidance on why this approach is not considered a significant contribution. The comment lacks depth and actionable feedback, leaving the authors without specific insights or suggestions for improvement. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the challenges when analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should explain these challenges, particularly the differences between their approach and Zhang et al. While the comment implies that the authors should provide more explanation, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as the authors need to infer that they should clarify the challenges and differences. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the analysis of Adam under the (L0,L1)-smoothness condition. It questions the clarity of the challenges and suggests that the authors should explain these challenges, particularly in relation to Zhang et al. This provides a clear indication of the part of the paper being addressed, making the comment fully grounded. However, it lacks specificity regarding the exact challenges or differences that need to be explained. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the clarity of the challenges when analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should explain these challenges, particularly in comparison to Zhang et al. The comment implies that the analysis is straightforward and does not require additional explanation, which is a subjective claim. However, it lacks specific examples or references to support the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a lack of clarity regarding the challenges when analyzing Adam under the (L0,L1)-smoothness condition. It suggests that the authors should explain these challenges, particularly in comparison to Zhang et al. This feedback is somewhat helpful as it points out a specific area where the paper could be improved by providing more detailed explanations. However, the comment could be more helpful if it offered suggestions on how to address these challenges or provided examples of what aspects need clarification. Overall, the comment provides a direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point mentions that most person re-ID methods are based on pedestrian detectors and that there are end-to-end methods that combine detection and re-ID. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should incorporate this information into their work or whether it is relevant to their research. As a result, the comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the methods used in person re-ID, mentioning that most methods are based on pedestrian detectors and that there are also end-to-end methods that combine detection and re-ID. However, it does not specify which part of the paper this information is relevant to, nor does it provide any specific guidance on how the authors should address this point. The comment lacks both grounding and specificity, as the authors cannot confidently determine which part of the paper it pertains to, and it does not offer clear instructions on what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point makes a factual statement about the methods used in person re-ID, mentioning that most methods are based on pedestrian detectors and that there are also end-to-end methods that combine detection and re-ID. This statement is descriptive and does not express an opinion, judgment, or suggestion that requires verification. It is a factual observation that does not fit the criteria for a claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a factual observation about the methods used in person re-ID, noting that most methods are based on pedestrian detectors and that there are also end-to-end methods that combine detection and re-ID. However, it does not offer any specific guidance or suggestions on how this information might be relevant to the authors\\' work or how it could be incorporated into their research. Without actionable feedback or insights, the comment lacks the depth and specificity needed to be helpful. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests adding a first sentence to introduce the content of Section 3.2. This is a clear and direct action for the authors to take, as it specifies what needs to be done to improve the clarity of the section. The suggestion is concrete, as it provides a specific step for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the action needed, which is to add a first sentence to introduce the content of the section. This provides clear guidance on what needs to be done to improve the section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a first sentence to introduce Section 3.2, which is a straightforward request for clarification. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, suggesting that the authors add a first sentence to introduce Section 3.2. This is a specific and direct piece of feedback that can help the authors improve the clarity and organization of their paper. By providing a concrete suggestion, the comment empowers the authors to make a meaningful improvement to their draft. However, it could be more helpful if it offered additional guidance on what kind of introduction would be beneficial or how it could enhance the section. Overall, the comment is mostly helpful, as it directs the authors toward a specific improvement that can enhance the clarity of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps to take to clarify the statement. As a result, the authors are left without a clear understanding of what action to take or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"initial rationale selector is perfect\" and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"initial rationale selector is perfect\" in line 44, suggesting that if it were perfect, no additional work would be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to clarify the claim or justify why this statement is problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the meaning of 'initial rationale selector is perfect' in line 44, suggesting that if it were perfect, no additional work would be needed. This feedback is somewhat helpful as it prompts the authors to clarify the statement, which could be important for understanding the context and purpose of the rationale selector. However, the comment lacks depth and does not provide specific guidance on how to address the issue or improve the clarity of the statement. Therefore, it is rated as somewhat helpful, as it identifies a potential area for clarification but does not fully support the authors in making improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it questions whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, and second, it asks about the number of questions created for the zero-shot intent classifier and the accuracy of the system. While the comment explicitly mentions these points, it does not provide specific guidance on how the authors should address these issues. The authors are left to infer that they need to clarify these aspects in their draft, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors experimented with domain ontologies to avoid generating placeholders in the evaluated responses, and it asks about the number of questions created for the zero-shot intent classifier and the accuracy of the system. This provides clear guidance on what the authors need to clarify or address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual questions seeking clarification on specific aspects of the paper, such as whether the authors experimented with domain ontologies and the number of questions created for the zero-shot intent classifier. These questions do not express opinions, judgments, or suggestions that require verification. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions that are relevant to the paper\\'s methodology and evaluation. The first question asks about the use of domain ontologies to avoid generating placeholders in the evaluated responses, which is a critical aspect of the experimental setup. The second question seeks clarification on the number of questions created for the zero-shot intent classifier and the accuracy of the system. These questions provide clear and actionable feedback, prompting the authors to clarify and potentially expand on their experimental methodology and results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the comment is mostly helpful as it directs the authors to clarify important aspects of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks citations to set it in context with other Multi-Agent Reinforcement Learning (MARL) work, specifically mentioning recent papers on self-play and population-play related to exploration and coordination. It provides specific examples of relevant papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which gives the authors a clear and concrete action to take. By including these citations, the authors can effectively contextualize their work within the broader MARL literature. Therefore, the comment is highly actionable, as it provides explicit guidance on what needs to be added and how to implement it.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MARL work,\" \"self-play,\" and \"population-play,\" allowing the authors to accurately identify the parts of the paper that need to be addressed. It is also specific because it clearly specifies what is missing, which is citations to set the work in context with recent papers on exploration and coordination. The comment provides specific examples of relevant papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which further aids the authors in understanding what needs to be added. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks citations to set it in context with other Multi-Agent Reinforcement Learning (MARL) work, specifically mentioning recent papers on self-play and population-play related to exploration and coordination. The comment provides specific examples of relevant papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which supports the claim by offering concrete references. This level of detail and specificity makes the claim mostly verifiable, as it provides clear evidence for the authors to consider in their revisions. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of citations to set the paper in context with other Multi-Agent Reinforcement Learning (MARL) work, particularly in relation to self-play and population-play. It provides specific examples of relevant papers, such as \"https://arxiv.org/abs/1806.10071\" and \"https://arxiv.org/abs/1812.07019,\" which the authors can include to enhance the paper\\'s context and relevance. This feedback is clear and actionable, offering the authors a concrete way to improve their draft by incorporating additional citations. However, it could be more helpful if it suggested how these citations might be integrated into the paper or provided further guidance on the context in which these papers should be discussed. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. It explicitly requests clarification on this aspect. While the comment does not provide a direct action, it clearly identifies a specific area that needs further explanation. The authors are given a clear direction to address the question, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"abstention process,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the difference between the abstention process and a decision threshold used by the models, and it requests clarification on this aspect. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by the models. The comment does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the abstention process, asking how it differs from a decision threshold used by the models. This question is relevant and prompts the authors to clarify their approach, which could be beneficial for improving the clarity and understanding of their work. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the draft. While it identifies a potential area for clarification, it lacks depth and actionable feedback, making it somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out a lack of meaningful baselines in the paper, noting that the authors limit their comparisons to simple naive baselines. It suggests that the authors could compare their work with a chain-of-thought prompting approach. This feedback is clear and provides a concrete action for the authors to take, which is to include more meaningful baselines in their comparisons. The comment is explicit and provides a specific direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of meaningful baselines and suggests a comparison with a chain-of-thought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks meaningful baselines, despite mentioning various model criticism techniques in Section 2. The reviewer suggests that the authors could compare their work with a chain-of-thought prompting approach. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with a chain-of-thought prompting approach provides some direction but does not fully explain why this comparison would be meaningful or how it would enhance the paper. Therefore, the comment is somewhat verifiable, as it provides a suggestion but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of meaningful baselines. It points out that while the authors mention various model criticism techniques in Section 2, they limit their comparisons to simple naive baselines. The comment suggests that the authors could compare their work with a chain-of-thought prompting approach, which could provide a more robust evaluation. This feedback is clear and actionable, offering a specific direction for improvement that could enhance the paper\\'s rigor and comprehensiveness. However, the comment could be more helpful if it provided additional context or examples of how the chain-of-thought prompting approach could be integrated. Overall, the comment is mostly helpful as it directs the authors to a potential enhancement that could significantly improve the paper\\'s quality.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment does not explicitly instruct the authors to make a change, it does provide a clear question that prompts them to clarify their pretraining methodology and its implications for generalization. The action is implicit but concrete, as the authors can directly address the question by providing the necessary information. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the pretraining process and its implications for generalization, providing clear guidance on what needs to be clarified. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question asking about the pretraining process of the cardiac signal representation learning model, specifically whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. The comment does not contain any claims or opinions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the pretraining process of the cardiac signal representation learning model, specifically asking whether it is pretrained on the entire dataset or just the training set. It also inquires about the generalization of the model when it is not trained on associated labels. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their work. The feedback is somewhat helpful as it prompts the authors to consider the implications of their pretraining methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without any actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This lack of grounding makes it difficult for the authors to identify the specific sections that need attention. The comment is specific in its suggestion that some aspects might be hardware and software dependent, but without explicit references or examples, it remains weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that some observations and design decisions might be hardware and software dependent, implying that these aspects could be influenced by specific hardware or software configurations. However, the comment does not provide any specific examples, references, or guidance on how the authors might address this issue or what implications it might have for their work. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This lack of grounding makes it difficult for the authors to identify the specific sections that need attention. The comment is specific in its suggestion that some aspects might be hardware and software dependent, but without explicit references or examples, it remains weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any specific examples, references, or reasoning to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that some observations and design decisions might be hardware and software dependent, implying that these aspects could be influenced by specific hardware or software configurations. However, the comment does not provide any specific examples, references, or guidance on how the authors might address this issue or what implications it might have for their work. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that some observations and design decisions might be hardware and software dependent, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects need to be considered. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent, but it does not specify which parts of the paper these observations or decisions are related to. This lack of grounding makes it difficult for the authors to identify the specific sections that need attention. The comment is specific"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any explicit or implicit actions for the authors to take. The questions are open-ended, leaving the authors without guidance on how to address them. Without specific suggestions or directions, the authors are left to infer the necessary steps themselves, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not specify which part of the paper these questions pertain to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to identify the exact areas needing attention. The comment is specific in its questions about the accuracy of the ground truth and the significance of the differences, but without clear references to the paper, it remains weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point consists of two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. They are purely descriptive and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions regarding the accuracy of the ground truth and the significance of the differences observed in the results. However, it does not provide any guidance or suggestions on how the authors might address these concerns or improve their analysis. The questions are open-ended and lack actionable feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of important experimental details and the lack of explanations or interpretations in the Appendix, specifically mentioning the PCA experiments in Figures 3, 7, and 8. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should include more detailed explanations and interpretations in the main text or appendices. However, the lack of concrete guidance makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is somewhat actionable, as it points out specific areas for improvement but lacks detailed instructions on how to implement those changes.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific figures (Figures 3, 7, and 8) and experiments (PCA), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting the absence of explanations or interpretations in the Appendix, which is crucial for understanding the experimental details. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. The comment provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This level of detail and specificity supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more context or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper, specifically the lack of detailed experimental information and explanations in the main text, with most details relegated to the Appendix. It highlights specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it directs the authors to include more detailed explanations and interpretations in the main text to enhance the comprehensiveness and clarity of the paper. However, the comment could be more helpful if it provided suggestions on how to improve the explanations or offered examples of how to structure the information. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that no new evaluation metrics are proposed and that existing metrics are only linearly combined. It also suggests that there should be an in-depth exploration of the reasons behind the experimental results in the analysis section. While the comment identifies areas for improvement, it does not explicitly instruct the authors to propose new metrics or conduct a detailed analysis. The action is implicit and somewhat vague, as the authors can infer the need for new metrics and deeper analysis but may not know how to implement these suggestions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of new evaluation metrics and the linear combination of existing ones, specifically mentioning the experimental analysis section. However, it does not specify which part of the paper this issue is found in, making it weakly grounded. The comment is specific in identifying the need for an in-depth exploration of the reasons behind the experimental results, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that no new evaluation metrics are proposed and that existing metrics are only linearly combined. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to explore the reasons behind the experimental results is a general observation rather than a claim. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by noting the absence of new evaluation metrics and the linear combination of existing ones. It highlights the need for an in-depth exploration of the reasons behind the experimental results, suggesting that the authors should provide a more detailed analysis. While the comment points out a critical area for improvement, it lacks specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it directs the authors to consider additional aspects of their work but could be more comprehensive with more detailed advice. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. However, the comment does not provide any explicit or implicit guidance on how the authors should address this issue. It lacks actionable advice, such as suggesting alternative notations or recommending a consistent use of \"K.\" As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This provides some grounding as it refers to specific lines in the paper (L166 and L176), allowing the authors to identify the parts of the paper being addressed. However, the comment lacks specificity as it does not explain why this ambiguity is problematic or suggest how the authors might resolve it. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the notation \"K\" is abused in the paper, being used ambiguously to represent both a known kernel function and the number of layers. This is a factual observation that does not require verification, as it is based on the reviewer\\'s understanding of the text. The comment does not express an opinion, judgment, or suggestion that requires justification, making it a normal statement. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation \"K,\" noting that it is used ambiguously to represent both a known kernel function and the number of layers. This is a clear and actionable observation that highlights a potential source of confusion in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending alternative notations or suggesting ways to clarify the usage of \"K.\" While it points out a problem, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\\' admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\\' statement about the potential impact of cognitively basic adaptation mechanisms and the structure of the CPR on self-organization. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify their stance. The action is implicit and vague, as the authors are left to infer that they need to provide more context or evidence to support their claims. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors\\' admission that the problem is reductionist and does not allow for bargaining and negotiation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the relevance of connections to human cognition and provides a clear suggestion for more citation to support the authors\\' claims. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of connections to human cognition in the context of the problem being studied. It highlights the authors\\' admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation. The reviewer questions the authors\\' statement about the potential impact of cognitively basic adaptation mechanisms and the structure of the CPR on self-organization, suggesting that it would be surprising if behavioral economists ignored these aspects. However, the comment lacks specific examples or references to support the claim that these aspects are commonly ignored by behavioral economists. This makes the claim somewhat verifiable, as it provides a logical basis for questioning the authors\\' stance but requires more detailed evidence to fully substantiate the point.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the relevance of connections to human cognition in the context of the problem being studied. It points out the authors' admission that the problem is reductionist and does not allow for mechanisms like bargaining and negotiation, which are commonly used by humans. The comment questions the authors' statement about the potential impact of cognitively basic adaptation mechanisms and the structure of the CPR on self-organization, suggesting that it would be surprising if behavioral economists ignored these aspects. The reviewer also recommends providing more citations to support the authors' claims. This feedback is clear and actionable, as it prompts the authors to clarify their stance and provide additional evidence to support their argument. However, the comment could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for improving the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant. However, it does not provide specific guidance on how to address this issue or suggest alternative wording. The authors are left without clear instructions on how to improve the phrasing or tone of their writing. As a result, the comment is vague and lacks actionable details, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of exaggerated wording in the conclusion, specifically mentioning the phrase \"our pioneering contributions herald a new era in robotic adaptability.\" This provides some grounding as it refers to a specific part of the paper, but it does not specify which sections or sentences are overly exaggerated. The comment is specific in identifying the issue of flamboyant word choice, but without explicit references to sections, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is flamboyant. However, the comment does not provide specific examples or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed justification or references, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the wording in the conclusion, noting that it is overly exaggerated and suggests that the word choice is flamboyant. This feedback is somewhat helpful as it points out a potential issue with the writing style that could impact the clarity and professionalism of the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue, such as recommending alternative phrasing or tone. Without actionable advice, the authors may find it challenging to effectively improve their draft based on this feedback. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and direct action for the authors to take, specifying what experiments need to be conducted and how to compare the methods. The feedback is concrete and actionable, as it gives the authors a specific task to complete to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or result section. This makes it difficult for the authors to identify the exact part of the paper that needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison should be emphasized or how the results should be presented. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, the comment does not provide any specific reasoning or evidence to support why these comparisons are necessary or how they would improve the paper. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and provides a concrete step for the authors to take to enhance the comprehensiveness of their analysis. By suggesting a direct comparison with existing methods, the comment helps the authors improve the robustness and validity of their findings. However, it could be more helpful if it included additional guidance on how to structure the ablation experiments or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on how historical observations are combined with inputs known over all time, given differences in sequence lengths. It specifies that the text mentions separate embedding and addition with positional encoding but lacks details on how these embeddings are combined and fed into the CSCM. This feedback provides a clear and direct action for the authors to take, which is to provide additional clarification on the combination and feeding of embeddings. The comment is explicit and concrete, guiding the authors on exactly what information is needed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the text,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the clarification of how historical observations are combined with inputs known over all time, given differences in sequence lengths. The comment provides a clear direction for the authors to improve their draft by addressing this issue. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the combination of historical observations with inputs known over all time, given differences in sequence lengths. It highlights a gap in the text regarding the method of combining these elements and feeding them into the CSCM. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the need for clarification. Without additional context or justification, the authors may find it challenging to understand the significance of this issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the combination of historical observations with inputs known over all time, given differences in sequence lengths. It highlights a gap in the text by pointing out that the method of combining these elements and feeding them into the CSCM is not clearly explained. This feedback is clear and actionable, as it directs the authors to provide additional clarification on this aspect, which is crucial for understanding the methodology. However, the comment could be more helpful if it suggested specific ways to address the issue or provided examples of how this combination could be achieved. Overall, the comment is mostly helpful as it guides the authors towards improving their draft by addressing a critical gap in the explanation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$ is not discussed, and their values are not specified in the paper. This provides a clear and direct action for the authors to take, which is to include a discussion on the sensitivity of these parameters and specify their values. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the lack of discussion on the sensitivity of these parameters and the absence of specified values. This provides clear guidance on what the authors need to include in their paper to address this issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$ is not discussed, and their values are not specified in the paper. This is a factual statement that does not require verification or evidence, as it is based on the absence of information in the paper. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\\\lambda$. It points out that these values are not specified in the paper, which is a critical aspect for understanding the robustness and reproducibility of the results. By highlighting this omission, the comment provides clear and actionable feedback that can help the authors improve their draft. However, the comment could be more helpful if it suggested how the authors might address this issue, such as by discussing the sensitivity analysis or providing specific values. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to conduct these additional experiments. The action is implicit and somewhat vague, as the authors can infer the need for more experiments but lack detailed guidance on how to implement them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this is not explicitly mentioned. The comment is specific in detailing the concerns and suggestions for further experimentation, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the current experiments do not adequately address these issues. The authors are left with a general concern about the model\\'s generalization performance, but without concrete evidence or examples, it is difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises important concerns about the potential impact of similarity-aware positive sample selection on GNN-based encoder over-smoothing and the generalization performance of the model. It highlights a specific area of concern regarding the training of similar nodes or graphs with features that converge excessively, potentially discarding their unique features. Additionally, it questions the effectiveness of selecting positive samples without introducing perturbation noise, which could lead to lower generalization performance. The comment suggests that more experiments should be conducted on different downstream tasks and across different domains to address these concerns. While the feedback identifies critical areas for improvement, it lacks specific guidance on how to conduct these additional experiments or what specific results to expect. The authors are left with a clear direction for further investigation but without detailed instructions on how to implement the suggested experiments. Therefore, the comment is somewhat helpful, as it provides valuable insights but could be more actionable with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded. As a result, the authors are left without a clear understanding of what changes or additions are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. However, it does not specify which part of the paper this question or desire pertains to, such as a specific section, table, or figure. The authors may have an idea of where this discussion could be relevant, but the comment lacks explicit grounding. Additionally, the comment is specific in its request for more discussion on the power of different architectures, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question and an expression of desire for more discussion on the power of different architectures. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of fast SMP compared to standard SMP and expresses a desire for more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue. The comment does not offer guidance on what aspects of the power of different architectures should be discussed or how the authors might expand their analysis. As a result, the comment is barely helpful, as it provides a general direction but does not offer detailed or actionable advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to clarify these concepts or where in the paper they should be addressed. Without specific instructions or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the types of situations/social norms (e.g., physical/psychological safety) in the main paper. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in pointing out the lack of clarity but lacks grounding, as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the types of situations/social norms (e.g., physical/psychological safety) are not clear in the main paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion in the paper, noting that the types of situations/social norms (e.g., physical/psychological safety) are not clear. This feedback is valuable as it highlights a potential gap in the paper's clarity, which could impact the reader's understanding. However, the comment lacks actionable guidance or suggestions on how the authors might clarify these concepts or where in the paper they should address this issue. While it points out a critical area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include more baselines for comparison and test more domains. It also points out that the choices of weighting and learning density functions are not strongly motivated and requests stronger empirical results. While the comment implies that the authors should provide additional baselines and empirical results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more baselines and test more domains. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include more baselines for comparison and test more domains, and it mentions that the choices of weighting and learning density functions are not strongly motivated. However, it does not specify which part of the paper these suggestions relate to, such as the experimental section or the methodology. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting additional baselines and empirical results, but without grounding, it is challenging for the authors to know where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more baselines for comparison and test more domains, and it questions the motivation behind the choices of weighting and learning density functions. The reviewer requests stronger empirical results to support these choices. While the comment provides a logical basis for the suggestion, it lacks specific examples or references to external works that could substantiate the claim. The reasoning is somewhat vague, as it does not provide detailed evidence or detailed examples of what constitutes strong empirical results. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas for improvement in the paper, specifically suggesting that more baselines should be compared and more domains tested. It also points out that the choices of weighting and learning density functions are not strongly motivated and requests stronger empirical results. This feedback is clear and actionable, providing the authors with specific directions to enhance their work. By addressing these suggestions, the authors can significantly improve the robustness and comprehensiveness of their study. However, the comment could be more helpful if it offered additional guidance on how to select appropriate baselines or which domains to test. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the comparability of their results. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the results are not comparable to existing methods, implying that the proposed methods may lack significance. However, it does not specify which part of the paper discusses the results or the proposed methods, making it difficult for the authors to identify the exact sections that need attention. The comment lacks specificity in detailing what aspects of the results are not comparable or what specific methods are being referred to. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the results are not comparable to existing methods, suggesting that the proposed methods lack significance. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific references to existing methods or detailed explanations of why the results are not comparable, the authors are left without guidance on how to address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a potential issue with the comparability of the results to existing methods, suggesting that the proposed methods may lack significance. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the comparability of their results. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it identifies a potential problem but does not offer actionable insights for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It suggests that the contribution is mainly the transposition of DeCorr\\'s insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it does not provide explicit guidance on how the authors could enhance the novelty or address the lack of insights about unique challenges in recommender systems. The feedback lacks concrete suggestions or actions for the authors to take, making it difficult for them to understand how to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the paper, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights the contribution as the transposition of DeCorr\\'s insights into graph collaborative filtering, with different datasets and backbones. The comment also mentions modifications like different penalty coefficients for users and items. However, it does not specify which part of the paper this critique applies to, making it weakly grounded. The comment is specific in identifying the lack of novelty and the need for more insights into unique challenges in recommender systems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty, suggesting that it is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The reviewer supports this claim by noting that the contribution is mainly the transposition of DeCorr\\'s insights into graph collaborative filtering, with different datasets and backbones. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about the lack of novelty. While the reviewer provides a general direction for the authors to consider, the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of novelty in the paper, noting that it seems like a straightforward application of existing literature, specifically DeCorr, in a specific application domain. It highlights that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. While the comment acknowledges some modifications, such as different penalty coefficients for users and items, it lacks depth in providing specific suggestions or guidance on how the authors could enhance the novelty or address the lack of insights about unique challenges in recommender systems. The feedback is somewhat helpful as it points out a potential issue but does not offer actionable advice for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper\\'s results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment suggests that this limitation could restrict the applicability of the results. However, it does not provide explicit guidance or suggestions on how the authors might address this limitation or improve their results. The action is implicit and vague, as the authors are left to infer that they should consider broader kernel classes or discuss the implications of this limitation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific limitation in the paper regarding the assumption of a sub-gaussian spectrum for kernels, particularly mentioning the exclusion of Matern kernels due to their polynomial decay spectrum. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which section or part of the paper this limitation is discussed in. The comment is specific in detailing the issue with the assumption and the potential restriction of the results, but it lacks full grounding because it does not specify the exact section where this limitation is discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper\\'s results are limited because the authors assume a sub-gaussian spectrum for kernels, which is reasonable for popular Gaussian kernels but excludes other popular kernels like Matern kernels. This claim is somewhat verifiable as it provides a logical reasoning for the limitation, explaining why the assumption is reasonable for Gaussian kernels but not for Matern kernels. However, the comment lacks specific examples or references to Matern kernels to fully substantiate the claim. Additionally, it does not provide detailed reasoning or evidence for why the inclusion of Matern kernels would be beneficial or how it could expand the applicability of the results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's results, specifically the assumption that the spectrum of a kernel is sub-gaussian. It notes that this assumption is reasonable for popular Gaussian kernels but acknowledges that other popular kernels like Matern kernels are not included, as their spectrum decays polynomially. The comment suggests that this limitation could restrict the applicability of the results. While it points out a potential issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve their results. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with a general insight into a limitation without clear steps to address it. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\\'s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. While the comment raises an important consideration, it does not explicitly instruct the authors to address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore the implications of this choice and potentially adjust their methodology accordingly. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\\'s gender beforehand, particularly at inference time. It also points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not explicit. The comment is specific in detailing the issue with the choice of ELM and the need for accuracy calculation after using a gender detection model. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of ELM (male/female) and whether it requires knowing the speaker\\'s gender beforehand, particularly at inference time. It suggests that the accuracy should be calculated after using a gender detection model in the pipeline, which is a logical point. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the relevance of this point to their work and consider the implications of the suggested approach. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the choice of ELM (male/female) and whether it requires knowing the speaker's gender beforehand, particularly at inference time. It points out a potential drawback, suggesting that the accuracy should be calculated after using a gender detection model in the pipeline, especially in cases where vocal traits match the speaker's identity. This feedback is valuable as it highlights an important consideration that could impact the accuracy and applicability of the proposed method. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored the implications of this choice on the overall methodology. Overall, the comment is mostly helpful as it identifies a significant area for improvement and encourages the authors to consider the impact of their choices, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived lack of technical depth or what specific changes could be made to improve the paper. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the paper are lacking in terms of technical depth or substance. Without specific references or detailed feedback, the authors cannot effectively address the critique. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is incremental and lacks technical depth, as it only adds a new loss to [31]. However, it does not provide any specific details or examples of what aspects of the paper are lacking in terms of technical substance or how the addition of a new loss might be perceived as incremental. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the paper is incremental and lacks technical depth, as it only adds a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how the authors might improve the technical substance of their work or what specific changes could be made to address the perceived lack of depth. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, it does not specify which part of the paper this assessment is based on, nor does it provide any details on what aspects of the paper are lacking in terms of technical depth or substance. Without specific references or detailed feedback, the authors cannot effectively address the critique. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, as it only adds a new loss to [31]. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper is incremental and lacks technical depth, as it only adds a new loss to [31]. However, it does not provide any specific details or examples of what aspects of the paper are lacking in terms of technical substance or how the addition of a new loss might be perceived as incremental. Without actionable feedback or suggestions for improvement, the authors are left without a clear understanding of how to address the critique. Therefore, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the paper is incremental and lacks technical depth, as it only adds a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. There is no guidance on how the authors might improve the technical substance of their work or what specific changes could be made to address the perceived lack of depth. Without actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale':"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the applicability of the model to real-world diffusion processes and suggests that the authors provide empirical evidence to demonstrate the model\\'s ability to capture diffusion phenomena in real-world scenarios. While the comment implies that the authors should include empirical evidence, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide empirical evidence, but the comment lacks specific guidance on how to collect or present this evidence. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors provide empirical evidence to demonstrate the model\\'s ability to capture diffusion phenomena. However, it does not specify which part of the paper this concern relates to, such as a particular section or result. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to provide empirical evidence, but without grounding, it is challenging for the authors to know where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the model to real-world diffusion processes, suggesting that empirical evidence is needed to demonstrate the model\\'s ability to capture diffusion phenomena. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as the authors would need to infer the basis of the concern themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical concern regarding the applicability of the model to real-world diffusion processes, which is a significant aspect of the paper's relevance and impact. It suggests that the authors provide empirical evidence to demonstrate the model's ability to capture diffusion phenomena in real-world scenarios. This feedback is clear and actionable, as it guides the authors to include empirical evidence that would strengthen the paper's claims and enhance its practical relevance. However, the comment could be more helpful if it provided specific suggestions on how to collect or present this evidence. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a plot showing how different weights of the model move, specifically suggesting a plot of relative weight change after unlearning to identify which layers are most affected. This is a clear and direct action for the authors to take, providing them with a specific and concrete task to improve their draft. The feedback is actionable because it gives a clear direction on what needs to be included in the paper to enhance its clarity and understanding. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Since the method is applied on each layer,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting the authors provide a plot of how different weights of the model move, such as plotting the relative weight change after unlearning to identify which layers are most affected. This provides clear guidance on what additional information is needed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide a plot showing how different weights of the model move, specifically after unlearning. This is a request for additional analysis or visualization to better understand the impact of unlearning on different layers. The comment does not contain a claim or an opinion that requires verification. It is a request for clarification or additional information, which is a normal statement. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper. It suggests that the authors should provide a plot showing how different weights of the model move, specifically after unlearning. This feedback is valuable as it directs the authors to a specific area where additional analysis or visualization could enhance the understanding of the model\\'s behavior. By following this suggestion, the authors can better illustrate the impact of unlearning on different layers, which could improve the comprehensibility and effectiveness of their work. However, the comment could be more helpful if it included specific examples or guidance on how to create such a plot. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the paper, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it does not provide explicit guidance or suggestions on how the authors might address this concern. The feedback lacks actionable steps or concrete advice on how to enhance the novelty or improve the methodology. As a result, the authors are left without a clear understanding of what changes or additions are needed to address the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the paper, specifically mentioning the ENCODE part and the incremental contribution in the decomposition part. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part. However, the comment lacks specific examples or detailed reasoning to support the claim that the decomposition part is a significant contribution. The mention of [10] provides some context, but without further elaboration or evidence, the claim remains somewhat verifiable. The authors would need to conduct further research or analysis to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the novelty of the paper, noting that the ENCODE part is already proposed in a previous work and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment identifies a potential issue with the novelty of the paper, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable steps or detailed advice on how to improve the paper's originality. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the presentation is too equation-driven and the notation, particularly in chapter 3, is convoluted and hard to follow. It suggests that an illustrative figure would be beneficial to help clarify the key concepts in section 3. This feedback is clear and provides a direct action for the authors to take, which is to include an illustrative figure to improve the clarity of their presentation. The suggestion is concrete and actionable, as it specifies what needs to be done to enhance the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the presentation is too equation-driven and the notation is convoluted, making it clear what needs to be improved. Additionally, the comment suggests including an illustrative figure to help clarify the key concepts in section 3. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation is too equation-driven and the notation is convoluted, making it hard to follow. However, the comment does not provide specific examples or detailed reasoning to support these claims. The suggestion to include an illustrative figure is a helpful suggestion but lacks the necessary evidence or explanation to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks the depth needed for a fully verifiable claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation, noting that it is too equation-driven and the notation is convoluted, making it hard to follow. It provides a clear suggestion for improvement by recommending the inclusion of an illustrative figure to help clarify the key concepts in section 3. This feedback is actionable and provides a concrete way for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it offered additional guidance on how to create an effective figure or what specific concepts should be illustrated. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a clear suggestion, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the visual presentation of the data in Figure 3 could be enhanced for better readability and aesthetic appeal. While it implies that the authors should improve the visual presentation, it does not provide specific guidance on how to achieve this enhancement, such as suggesting changes to the font size, color, or layout. The action is implicit and somewhat vague, as the authors know they need to improve the visual presentation but are not given concrete steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, which need enhancement for better readability and aesthetic appeal. This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the visual presentation of data in Figure 3 could be enhanced for better readability and aesthetic appeal. However, it does not provide specific examples or detailed reasoning to support why the current presentation is insufficient. The comment lacks detailed justification or suggestions for improvement, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the presentation of data in Figure 3, noting that the visual presentation, particularly the subscripts, could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a specific area for the authors to focus on to improve the clarity and effectiveness of their visual data presentation. However, the comment could be more helpful if it offered suggestions or examples of how to enhance the visual presentation. Overall, the comment is mostly helpful as it directs the authors' attention to a specific area needing improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the distinction between the two normalization techniques. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the difference between Online Normalization and Batch Normalization, particularly focusing on their bias and unbiased nature. It raises a question about why Online Normalization is unbiased and Batch Normalization is biased, which is a clear and specific point. However, the comment does not explicitly mention which part of the paper discusses these normalization techniques, making it weakly grounded. Despite this, the comment is specific in detailing the issue, so it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. It suggests that the authors clarify why Online Normalization is unbiased and Batch Normalization is biased. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the question effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the difference between Online Normalization and Batch Normalization, specifically regarding their bias and unbiased nature. It points out a potential confusion regarding why Online Normalization is unbiased and Batch Normalization is biased. While the comment identifies a specific area of confusion, it does not provide any actionable feedback or suggestions for the authors to address this issue. Without additional guidance or insights, the authors may find it challenging to improve their draft based on this comment. Therefore, it is rated as somewhat helpful, as it highlights an area for clarification but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It claims that this violation of the 9-page paper limit is grounds for rejection. While the comment identifies a specific issue with the paper\\'s formatting, it does not provide any guidance or suggestions on how the authors might address this problem or improve the paper. The action is explicit in terms of identifying the issue, but it lacks concrete details on how to resolve it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of reduced whitespace in the paper, specifically mentioning that equations are crammed together and captions are too close to the figures. However, it does not specify which sections or parts of the paper are affected, making it weakly grounded. The comment is specific in detailing the issue with the formatting, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. This claim is supported by the observation that the paper exceeds the 9-page limit, which is a clear violation of the submission guidelines. The reviewer provides a logical reasoning by linking the reduction in whitespace to the violation of the page limit, making the claim mostly verifiable. However, the comment could be strengthened by providing specific examples or references to the sections or figures affected, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper's formatting, noting that the authors have reduced whitespace, resulting in equations being crammed together and captions being too close to the figures. This is a clear and actionable feedback that highlights a potential violation of the submission guidelines, which could lead to rejection. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the paper's formatting. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might enhance the technical details or formulations to better reflect the novelty of their work. Without specific suggestions or directions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. However, it does not specify which sections or parts of the paper are lacking in detail or clarity. The authors may infer that it pertains to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the issue of limited technical details and formulations, but it lacks grounding as it does not specify the exact parts of the paper that need improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical details and formulations, suggesting that the main novelty is reflected in the scheme or procedure. While it points out an area for improvement, it lacks specificity and actionable guidance. The authors are left without clear direction on how to enhance the technical details or formulations to better reflect the novelty of their work. The feedback is somewhat helpful as it highlights a potential issue, but it does not provide detailed suggestions or examples to help the authors address this concern. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper\\'s claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this discrepancy. The authors are left to infer that they need to investigate and possibly revise their results or methodology, but the lack of specific actions or directions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly details the issue with the paper\\'s claim of better results in the Molecule generation experiment, noting that adding the proposed constrained method actually results in lower validity and diversity. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of better results in the Molecule generation experiment is contradicted by the observation that adding the proposed constrained method actually results in lower validity and diversity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or data, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a discrepancy between the paper's claim of better results in the Molecule generation experiment (Table.3) and the observation that adding the proposed constrained method actually results in lower validity and diversity. This feedback is somewhat helpful as it points out a potential issue that the authors should investigate. However, it lacks specific guidance or suggestions on how the authors might address this discrepancy or improve their results. The comment could be more helpful if it provided actionable steps or insights into how the authors might resolve this issue or enhance their experimental methodology. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to include this description or specify how much detail is required. The action is implicit and somewhat vague, as the authors can infer the need for more information but lack concrete guidance on execution. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not specify which part of the paper this description should be included in, nor does it provide any details on what aspects of the Starcraft environment need more description. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. However, it does not provide any justification or reasoning for why this additional description is necessary or how it would improve the paper. Without specific evidence or reasoning, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors provide more description of the Starcraft environment, possibly in an appendix. While this feedback acknowledges the need for additional information, it lacks specificity and does not provide guidance on what aspects of the environment should be described or how this could enhance the paper. Without actionable suggestions or detailed explanations, the comment does not offer the authors a clear path to improve their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to effectively address it.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a discussion on the prompt dataset creation and its source in the paper. While the action is explicit, it does not provide specific guidance on how to structure this discussion or what aspects should be included. The authors are aware of what needs to be addressed but lack detailed instructions on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the prompt dataset creation and its source, specifically for the few-shot case. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the prompt dataset creation and its source, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for this discussion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a discussion on the prompt dataset creation and its source should be included, specifically for the few-shot case. However, the comment does not provide any reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should include a discussion on the prompt dataset creation and its source, specifically for the few-shot case. While this is a valid suggestion for improving the paper, it lacks specificity and does not provide detailed guidance on how to structure this discussion or what aspects should be included. The authors are aware of what needs to be addressed but may find it challenging to implement the suggestion without additional context or examples. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should include a discussion on the prompt dataset creation and its source, specifically for the few-shot case. While the action is explicit, it lacks concrete guidance on how to structure this discussion or what specific aspects should be included. The authors are aware of what needs to be addressed but may find it challenging to implement the suggestion without additional details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the prompt dataset creation and its source, specifically for the few-shot case. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the prompt dataset creation and its source, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location for this discussion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should discuss the prompt dataset creation and its source, specifically for the few-shot case. However, it does not provide any reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors should include a discussion on the prompt dataset creation and its source, specifically for the few-shot case. While this is a valid suggestion for improving the paper, it lacks specificity and does not provide detailed guidance on how to structure this discussion or what aspects should be included. The authors are aware of what needs to be addressed but may find it challenging to implement the suggestion without additional context or examples. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should include a discussion on the prompt dataset creation and its source, specifically for the few-shot case. While the action is explicit, it lacks concrete guidance on how to structure this discussion or what specific aspects should be included. The authors are aware of what needs to be addressed but may find it challenging to implement the suggestion without additional details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the prompt dataset creation and its source, specifically for the few-shot case. However, it"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in understanding the motivation of the paper and describes it as an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the motivation or address the perceived incremental nature of the work. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the motivation of the paper and describes it as an incremental engineering paper. However, it does not specify which part of the paper is being discussed or what aspects of the motivation are unclear. This lack of grounding makes it difficult for the authors to identify the specific sections or elements that need clarification. The comment is specific in its critique of the paper\\'s motivation and incremental nature, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the motivation of the paper is difficult to follow and describes it as an incremental engineering paper. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed evidence or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses difficulty in following the motivation of the paper and describes it as an incremental engineering paper. While it identifies a potential issue with the clarity of the motivation, it lacks specific details or suggestions on how the authors might improve the clarity or address the perceived incremental nature of the work. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the motivation need clarification or how to enhance the paper\\'s originality. Therefore, the comment is barely helpful, as it provides a general critique but does not offer actionable insights for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an ablation study on the weighting method of the cross-entropy loss, which would be beneficial to see. It also points out a specific scenario where the weighting method might have helped, referencing the underperformance of the method in the Atlantis game due to repetitive background sounds. While the comment implies that such an ablation would be valuable, it does not explicitly instruct the authors to conduct this study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an ablation study on the weighting method of the cross-entropy loss, referencing a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds. This provides some grounding as it relates to a specific part of the paper, but it does not explicitly mention which section or experiment this relates to, making it weakly grounded. The comment is specific in suggesting an ablation study and providing a rationale for its relevance, which helps the authors understand what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an ablation study on the weighting method of the cross-entropy loss, referencing a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The authors are expected to infer the relevance of the weighting method to the performance issue, which could be challenging without additional context. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests an ablation study on the weighting method of the cross-entropy loss, which could provide valuable insights into the performance of the method. It references a specific scenario where the method underperforms in the Atlantis game due to repetitive background sounds, indicating that the weighting method might have helped in this context. This feedback is clear and actionable, as it directs the authors to conduct a specific type of analysis that could enhance their understanding of the method's effectiveness. However, the comment could be more helpful if it provided additional guidance on how to structure the ablation study or what specific aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a critical weakness in the paper, which is the lack of novelty and incremental nature of the work. It highlights that the paper addresses a specific problem of column operations in designing semantic parsers for Text-to-SQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to enhance the novelty or incremental nature of the work, nor are there suggestions for alternative approaches or improvements. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It mentions the problem addressed, which is the design of semantic parsers for Text-to-SQL, and highlights the design of a new dataset as a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. This makes it difficult for the authors to pinpoint the exact area needing improvement. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature, based on the work addressing a particular problem of column operations in designing semantic parsers for Text-to-SQL. It mentions the design of a new dataset as a different train/test split of an existing dataset SQUALL and another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples or detailed reasoning to support the claim that these contributions are not novel or incremental. The lack of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It highlights that the paper addresses a particular problem of column operations in designing semantic parsers for Text-to-SQL and mentions the design of a new dataset, which is a different train/test split of an existing dataset SQUALL. Additionally, it mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide specific suggestions or guidance on how the authors might enhance the novelty or incremental nature of their work. Without actionable feedback or detailed advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a significant issue but lacks actionable insights or suggestions for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include more game environments. While it implies that additional experiments are necessary, it does not provide specific guidance on which additional environments to include or how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the feedback. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not specify which part of the paper discusses the experiments or which game environment is being used. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to conduct more experiments, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are only conducted on one game environment and recommends the need for more experiments. However, it does not provide any specific reasoning, examples, or references to support why more experiments are necessary or how they would improve the study. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental design, noting that the experiments are only conducted on one game environment. It suggests that more experiments are necessary to provide a broader perspective or validation of the findings. While the comment highlights an important area for improvement, it lacks specific guidance on which additional game environments should be considered or how to conduct these experiments. This limits the usefulness of the feedback, as it provides a general direction but does not offer detailed suggestions for implementation. Therefore, the comment is somewhat helpful, as it points out a critical area for expansion but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It suggests using solid examples to support this explanation. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what needs to be done to address the comment, which is to provide examples that demonstrate the importance of removing these assumptions. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"removing some of the assumptions like bounded variance and bounded gradients,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing examples to explain the importance of removing these assumptions. This level of detail provides clear guidance on how to improve the draft. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific examples or reasoning to support why these assumptions are significant or how their removal impacts the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement, suggesting that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. It provides a clear direction for the authors to enhance their draft by offering a specific action to take\u2014using solid examples to support their explanation. This feedback is actionable and provides a clear path for the authors to improve their work, making it mostly helpful. However, it could be more helpful if it included specific examples or guidance on how to construct these examples. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and the accuracy levels. However, the comment does not explicitly instruct the authors to address this issue or suggest how to improve the implementation. While the information is detailed, the lack of a direct action or guidance on how to resolve the problem makes the comment somewhat actionable. The authors know that the issue exists but may not be entirely clear on how to proceed with improvements.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that the authors have implemented ImageNet for the first time, but it does not specify which part of the paper this claim is made in. The authors can infer that it relates to the implementation section, but this inference is not explicit. The comment provides specific details about the slowness and low accuracy of the implementation, mentioning the time taken to test an ImageNet picture using AlexNet and ResNet-18 and the accuracy levels. However, without explicit grounding, the comment is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors\\' claim of implementing ImageNet for the first time is inaccurate, as it is slow and has low accuracy. The reviewer provides specific examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and the accuracy levels, which support the claim. This provides a clear and detailed justification for the claim, making it fully verifiable. Therefore, the comment is categorized as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': \"The review comment identifies a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete examples, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and the accuracy levels. This feedback is valuable as it highlights a critical area for improvement and provides detailed information that can guide the authors in addressing the issue. However, the comment could be more helpful if it suggested potential solutions or strategies for improving the implementation. Overall, the comment is mostly helpful as it provides actionable feedback but could be further enhanced with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It suggests that labeled data could provide effective information for consistency training, referencing two external works for further exploration. However, the comment does not explicitly instruct the authors to incorporate labeled data into their consistency training or discuss how this might impact their results. The action is implicit and somewhat vague, as the authors need to infer that they should consider using labeled data for consistency training. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of labeled data for consistency training in graph anomaly detection, referencing two external works. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its suggestion to consider using labeled data for consistency training, but without explicit references to the paper\\'s sections or figures, the authors may struggle to pinpoint where this suggestion fits. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, referencing two external works. However, the comment does not provide specific reasoning or evidence to support the claim that labeled data would be beneficial for consistency training. The references to external works are not detailed enough to substantiate the claim, leaving the authors without clear guidance on how to address the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises an interesting question about the potential benefits of using labeled data for consistency training in graph anomaly detection. It references two external works that might provide insights into this approach. However, the comment does not offer specific guidance or suggestions on how the authors could incorporate labeled data into their consistency training or what impact this might have on their results. While it prompts the authors to consider an alternative method, it lacks actionable advice or detailed feedback, making it somewhat helpful. The authors would benefit from more detailed guidance on how to implement this suggestion or what specific aspects to consider when using labeled data for consistency training. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the classification error of the proposed network and suggests that it might not be universally as good as the standard softmax network. It questions the authors\\' claim of better detecting out-of-distribution samples without compromising classification accuracy. The reviewer explicitly requests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provide theoretical justifications for their claims. This feedback is explicit and provides concrete actions for the authors to take, such as reporting classification accuracy and offering theoretical justifications. The comment is highly actionable as it gives clear and detailed guidance on what the authors need to do to address the concern and improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the classification network proposed by the authors and questions the universality of its classification error compared to the standard softmax network. It raises concerns about the potential loss of classification accuracy when building a new model for better detecting out-of-distribution samples. The reviewer suggests reporting the classification accuracy on ImageNet data and requests theoretical justifications for the issue. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the proposed classification network and its performance. The authors can infer that it relates to the methodology or results section, but the comment lacks explicit grounding. However, it is specific in detailing the issue and the requested actions, such as reporting classification accuracy and providing theoretical justifications. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the classification error of the proposed network compared to the standard softmax network. It questions the universality of the proposed network\\'s classification error and suggests that it might not be as good as the softmax network. The reviewer also points out the potential loss of classification accuracy when building a new model for better detecting out-of-distribution samples. The comment requests that the authors report the classification accuracy of the proposed classifier on ImageNet data and provide theoretical justifications for their claims. While the comment raises a valid concern, it lacks specific examples or references to support the claim about the classification error being universally better. The request for reporting classification accuracy and theoretical justifications provides some direction, but the initial claim remains somewhat verifiable due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the universality of the proposed classification network's performance compared to the standard softmax network. It questions the authors' claim of better detecting out-of-distribution samples without compromising classification accuracy. The reviewer suggests reporting the classification accuracy of the proposed classifier on ImageNet data and requests theoretical justifications for their claims. This feedback is clear and actionable, providing the authors with specific steps to take to address the concern and improve their draft. By reporting classification accuracy and offering theoretical justifications, the authors can strengthen their claims and provide a more robust evaluation of their proposed network. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and vague, as the authors are left to infer that they need to clarify or revise their argument. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the feasibility of the argument regarding recognition lists being recalled based on items. It provides a detailed explanation of the issue, particularly in the context of old vs new judgments, where new items comprise the list of all items available in memory. This level of detail allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies the issue with the argument and provides a rationale for why it might be challenging to implement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim fully. The authors might find it challenging to address the issue without additional context or evidence. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It points out that in the most common case of recognition, new items comprise the list of all items available in memory, which makes the exhaustive list challenging to implement and test with simulations. This feedback is somewhat helpful as it identifies a potential weakness in the argument and highlights a practical issue that the authors should consider. However, the comment could be more helpful if it provided suggestions on how to address this concern or offered alternative approaches to support the argument. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their argument. The action is implicit and lacks specificity, leaving the authors to infer that they need to clarify or revise their argument. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It provides a detailed explanation of the issue, highlighting the challenge of an exhaustive list and the difficulty in testing concrete predictions with simulations. This level of detail allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies the issue with the argument and provides a rationale for why it might be challenging to implement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It questions the practicality of an exhaustive list and the ability to test concrete predictions with simulations. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim fully. The authors might find it challenging to address the issue without additional context or evidence. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the feasibility of the argument regarding recognition lists being recalled based on items, particularly in the context of old vs new judgments. It points out that in the most common case of recognition, new items comprise"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper would benefit from describing possible alternate formulations for Confidence Diversity (CD). It does not explicitly request additional experiments but rather points out a lack of clarity regarding what additional information CD captures beyond Predictive Uncertainty. The comment also questions why entropy is not a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" While the comment implies that the authors should address these issues, it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper would benefit from describing possible alternate formulations for Confidence Diversity (CD), which is a specific aspect of the paper. It also questions the clarity of the current description of CD and why entropy might not be a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" This provides some level of grounding as it refers to a specific concept within the paper, but it does not specify which part of the paper this feedback pertains to, such as a particular section or paragraph. The comment is specific in its critique of the current description of CD and the comparison with entropy, but it lacks full grounding due to the lack of explicit reference to a specific part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from describing possible alternate formulations for Confidence Diversity (CD) and questions the clarity of the current description. It does not make a claim that requires verification, as it is a suggestion for improvement rather than an opinion or judgment. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from describing possible alternate formulations for Confidence Diversity (CD), which is a specific aspect of the paper. It does not request additional experiments but rather points out a lack of clarity regarding what additional information CD captures beyond Predictive Uncertainty. The comment also questions why entropy might not be a good measure of \"amount of spreading of teacher predictions over the probability simplex among different (training) samples.\" While the comment identifies areas for improvement and raises specific questions, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is somewhat helpful as it provides some insight into potential areas of improvement, but it could be more comprehensive and actionable to be fully beneficial. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a strong assumption regarding the termination states of instructions and notes that labeling a large number of data manually is expensive in the general case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption regarding the termination states of instructions, noting that it is strong and expensive to label a large number of data manually in the general case. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in pointing out the issue with the assumption, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption regarding the termination states of instructions is strong and expensive to label a large number of data manually in the general case. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption regarding the termination states of instructions, noting that it is strong and expensive to label a large number of data manually in the general case. This feedback highlights a critical area for improvement, as it points out a limitation that could impact the validity of the assumptions made in the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or refine their assumptions. While it provides a starting point for consideration, the feedback could be more helpful with additional details or actionable advice. Therefore, it is rated as somewhat helpful, as it offers some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the description of the contribution regarding ECE_sweep, specifically mentioning the need to choose the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that the paper should be upfront about this contribution. While the comment implies that the authors should clarify their contribution, it does not provide specific guidance on how to achieve this clarity. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity in the description of the contribution regarding ECE_sweep, specifically mentioning the need to choose the number of bins using data, which is essentially autotuning a hyperparameter. This provides some grounding as it refers to a specific aspect of the paper. However, the comment does not specify which part of the text is unclear or lacks clarity, making it weakly grounded. The comment is specific in detailing what needs to be addressed, which is the clarity of the contribution regarding ECE_sweep. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the nature of the contribution with respect to ECE_sweep is not clearly described, suggesting that it amounts to a way to choose the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer argues that this is not fundamentally different from other estimators. The comment provides a logical reasoning based on the nature of the contribution and the method used, which is somewhat verifiable. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of clarity in the description of the contribution regarding ECE_sweep, specifically mentioning the need to choose the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that the paper should be upfront about this contribution, which is a valuable insight. However, the comment could be more helpful if it provided specific suggestions on how to clarify the contribution or examples of how to present it more clearly. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. While the comment identifies a potential issue with the lack of baseline comparisons, it does not provide explicit guidance on how the authors should address this. The action is implicit, as the authors need to infer that they should include these methods as baselines, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the related work section, specifically mentioning the discussion of methods for training NMT models beyond MLE, such as RL methods. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in identifying the absence of these methods as baselines, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This claim is somewhat verifiable as it identifies a potential gap in the paper\\'s methodology. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential gap in the paper's methodology by noting that the related work discusses methods for training NMT models beyond MLE, such as RL methods, but none of these methods are used as baselines. This observation is important as it highlights a missing comparison that could strengthen the paper's evaluation. However, the comment does not provide specific suggestions on how the authors might include these methods as baselines or what benefits this might bring to the analysis. While it points out a potential weakness, the lack of actionable guidance limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding whether the authors are referring to a specific efficient proxy or a family of efficient proxies. It suggests that the term \"Efficient Proxy\" is not a recognized entity, implying that the authors may be referring to a general concept of efficient proxies. However, the comment does not provide explicit guidance on how the authors should clarify this ambiguity. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term \"Efficient Proxy\" or provide a more precise definition of what is meant by \"efficient proxies.\" Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the clarity of the term \"Efficient Proxy\" in the paper. It points out that the term is unclear, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. However, the comment does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in identifying the ambiguity of the term \"Efficient Proxy,\" but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the term \"Efficient Proxy,\" suggesting that it could refer to a specific efficient proxy or a family of efficient proxies. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The lack of detailed explanation or references makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of terminology in the paper, specifically regarding the term \"Efficient Proxy.\" It points out that the term is ambiguous, suggesting that it could refer to a particular efficient proxy or a family of efficient proxies. This feedback is clear and actionable, as it provides a specific area for the authors to clarify in their draft. However, the comment could be more helpful if it offered suggestions on how to resolve the ambiguity or provided examples of how to clarify the term. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the methods used in the paper, noting that the methods of Mirzasoleiman et al., 2020 and the Group-learning setting are stacked, and then a classical method, DBSCAN, is used for clustering. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or improve their methodology. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the methods used in the paper, mentioning the stacking of methods from Mirzasoleiman et al., 2020 and the Group-learning setting, and the subsequent use of a classical method, DBSCAN, for clustering. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in detailing the issue with the methods, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the methods of Mirzasoleiman et al., 2020 and the Group-learning setting are stacked, and then a classical method, DBSCAN, is used for clustering. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methods used in the paper, noting that the methods of Mirzasoleiman et al., 2020 and the Group-learning setting are stacked, and then a classical method, DBSCAN, is used for clustering. This feedback is somewhat helpful as it points out a potential issue with the methodology, but it lacks depth and does not provide guidance on how the authors might address this concern or improve their approach. Without additional context or suggestions for alternative methods or approaches, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a specific issue with the methods used in the paper, noting that the methods of Mirzasoleiman et al., 2020 and the Group-learning setting are stacked, and then a classical method, DBSCAN, is used for clustering. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or improve their methodology. Without specific suggestions or directions, the authors are left without a clear understanding of what changes are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the methods used in the paper, noting that the methods of Mirzasoleiman et al., 2020 and the Group-learning setting are stacked, and then a classical method, DBSCAN, is used for clustering. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in detailing the issue with the methods, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the methods of Mirzasoleiman et al., 2020 and the Group-learning setting are stacked, and then a classical method, DBSCAN, is used for clustering. However, the comment lacks supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the methods used in the paper, noting that the methods of Mirzasoleiman et al., 2020 and the Group-learning setting are stacked, and then a classical method, DBSCAN, is used for clustering. This feedback is somewhat helpful as it points out a potential issue with the methodology, but it lacks depth and does not provide guidance on how the"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the variability in results with the chosen random projection matrix and suggests that the authors consider the resilience of the metric to the choice of random projection. It implies that the authors should investigate the potential for pathological projection matrices to skew the MFTMA capacity and width scores. While the comment explicitly states the need for further exploration, it does not provide specific guidance on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the results, namely the variability in results with the chosen random projection matrix. It suggests that the authors consider the resilience of the metric to the choice of random projection, which is a relevant concern. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or the appendix, but this is not clearly specified. The comment is specific in detailing the concern about the potential for pathological projection matrices to skew the scores, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the variability in results with the chosen random projection matrix and suggests that the authors consider the resilience of the metric to the choice of random projection. The reviewer implies that there might be a risk of pathological projection matrices skewing the scores, which is a valid concern. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors would need to investigate further to address this concern fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the variability in results with the chosen random projection matrix and suggests that the authors consider the resilience of the metric to the choice of random projection. It points out the possibility of pathological projection matrices skewing the MFTMA capacity and width scores, which is an important aspect to address for the robustness of the results. However, the comment could be more helpful if it provided specific guidance on how to investigate this issue or suggested methods for testing the resilience of the metric. Overall, the comment is somewhat helpful as it identifies a potential weakness in the study but lacks detailed actionable advice, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and the comparative methods, rather than just being used in the ablation study. While the comment implies that the authors should consider using FGT for performance evaluation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the use of FGT for performance evaluation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FGT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limited use of FGT for performance evaluation, suggesting that it should be used to evaluate both the proposed method and comparative methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the evaluation of FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would improve the evaluation. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the evaluation of the proposed method, specifically regarding the use of FGT. It suggests that FGT should be used to evaluate the performance of the proposed method and comparative methods, rather than just in the ablation study. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the evaluation process. However, the comment could be more helpful if it included additional details or examples on how to implement this suggestion. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the model is simple, which can be both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the simplicity of the model or whether it should be considered a feature or a bug. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model's simplicity are problematic or how it could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a feature or a bug. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the model is simple, describing it as both a feature and a bug. While it identifies a potential issue with the model's simplicity, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the model. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not offer the level of detail or actionable steps needed for improvement.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take regarding this observation. There is no guidance on whether the simplicity should be addressed or how it could be improved. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a specific section, table, or figure. Without explicit references or detailed explanation, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment lacks specificity regarding what aspects of the model\\'s simplicity are problematic or how it could be improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a feature or a bug. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges that the model is simple, describing it as both a feature and a bug. While it identifies a potential issue with the model's simplicity, it does not provide any specific suggestions or guidance on how the authors might address this concern or improve the model. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not offer the level of detail or actionable steps needed for improvement.\", 'helpfulness_label': '2'}{'actionability_rationale': \"The review comment acknowledges that the model is simple, describing it as both a feature and a bug. However, it does not provide any explicit or implicit actions for the authors to take regarding this observation. There is no guidance on whether the simplicity should be addressed or how it could be improved. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that the model"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the originality of the paper, specifically regarding the use of the winner-take-all property, which has been widely used in previous works. It questions the novelty of the paper\\'s contribution in understanding this behavior, especially given the extremely simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the originality of their work. The action is implicit and vague, as the authors are left to infer that they need to demonstrate the novelty of their contribution or provide a more detailed explanation of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the originality of the paper, specifically questioning the novelty of using the winner-take-all property, which has been widely used in previous works. It references a specific section, \"Sec 5,\" suggesting that the authors should clarify how their work contributes to the understanding of this behavior with its simplified settings. However, the comment does not explicitly mention the specific part of the paper being addressed, making it weakly grounded. The comment is specific in detailing the issue of originality and the need for clarification, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the winner-take-all property has been widely used in previous works, questioning the originality of the paper. It references NN-based clustering algorithms as examples and notes that most findings have been reported elsewhere. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the paper\\'s contribution is not novel. The mention of previous works provides some context, but the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the originality of the paper, specifically regarding the use of the winner-take-all property, which has been widely used in previous works. It questions the novelty of the paper's contribution in understanding this behavior, especially given the extremely simplified settings and the fact that most findings have been reported elsewhere. While the comment identifies a potential issue with the originality of the work, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the originality of their contribution. The feedback is somewhat helpful as it points out a potential weakness, but it could be more actionable with additional insights or suggestions for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the originality of the paper, specifically regarding the use of the winner-take-all property, which has been widely used in previous works. It questions the novelty of the paper\\'s contribution in understanding this behavior, especially given the extremely simplified settings and the fact that most findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the originality of their work. The action is implicit and lacks specificity, leaving the authors to infer that they need to demonstrate the novelty of their contribution or provide a more detailed explanation of their work. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the originality of the paper, specifically questioning the novelty of using the winner-take-all property, which has been widely used in previous works. It references NN-based clustering algorithms as examples and notes that most findings have been reported elsewhere. However, the comment does not specify which part of the paper is being addressed, such as a particular section or figure, making it weakly grounded. The comment is specific in detailing the issue of originality and the need for clarification, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the winner-take-all property has been widely used in previous works, questioning the originality of the paper's contribution in understanding this behavior, especially given the extremely simplified settings and the fact that most findings have been reported elsewhere. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the paper's contribution is not novel. The mention of previous works provides some context, but the lack of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the originality of the paper, specifically regarding the use of the winner-take-all property, which has been widely used in previous works. It questions the novelty of"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to help motivate the method. It also recommends including a rough example of some run-times in the experiments, which would be useful for readers looking to apply the method. These suggestions are explicit and provide clear guidance on what the authors should include in their draft to enhance its motivation and applicability. The actions are concrete, as they specify exactly what information should be added and how it can be presented. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment suggests mentioning the negligible computational cost of CHR in the main paper and provides a suggestion for including a rough example of run-times in the experiments. However, it does not specify which part of the main paper this information should be included in, making it weakly grounded. The comment is specific in its suggestion to include computational cost and run-time examples, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that it may be beneficial to mention the negligible computational cost of CHR in the main paper and provides a suggestion for including a rough example of run-times in the experiments. This is a request for additional information rather than a claim, as it does not express an opinion or judgment about the paper. Therefore, it is classified as 'No'.\", 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper, which could help motivate the method. It also recommends including a rough example of some run-times in the experiments, which would be useful for readers looking to apply the method. These suggestions are clear and actionable, providing the authors with specific ways to enhance the motivation and applicability of their work. However, the comment could be more helpful if it included examples or detailed guidance on how to present this information effectively. Overall, the feedback is mostly helpful as it offers valuable insights for improving the draft, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should compare their code completion system with existing commercial applications like Copilot. It provides a specific example of a state-of-the-art code completion system and recommends testing on a smaller subset of the RepoEval dataset. This feedback is clear and direct, giving the authors a concrete action to take. The suggestion is specific and provides a clear path for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their code completion system with existing commercial applications, such as Copilot, and provides a specific example of a state-of-the-art code completion system. It also recommends testing on a smaller subset of the RepoEval dataset. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. While the authors can infer that it relates to the comparison section or experimental setup, the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting a comparison with a particular commercial application and testing on a subset of the dataset, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their code completion system with existing commercial applications like Copilot. This is a logical suggestion based on the current state of the field, as it provides a benchmark for evaluating the performance of the proposed system. However, the comment does not provide specific examples or references to support the claim that Copilot is a state-of-the-art code completion system or that it is essential to compare with it. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to conduct additional research to fully understand the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to include additional baselines in their code completion task evaluation. It specifically recommends comparing their system with existing commercial applications like Copilot, which is a state-of-the-art code completion system. The comment also suggests testing on a smaller subset of the RepoEval dataset, which could help in more detailed analysis. This feedback is specific and provides a concrete direction for improvement, making it highly helpful for the authors to enhance the comprehensiveness and relevance of their experimental evaluation. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment implies that the authors should provide more context or explore additional benchmarks, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as the authors need to infer that they should provide more information or consider alternative benchmarks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB), which is a specific part of the paper. This provides full grounding, as the authors can accurately identify the section being addressed. The comment is also specific because it questions the generalizability of the evaluation and suggests that the authors should clarify the criteria behind the selection and consider whether other tasks or datasets might yield different insights. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about generalizability. The suggestion to consider other tasks or datasets is a logical extension but is not fully substantiated with evidence or reasoning. Therefore, the comment is somewhat verifiable, as it provides a basis for questioning the evaluation but requires more detailed justification or examples to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the generalizability of the evaluation on a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should clarify the criteria behind this selection and consider whether other tasks or datasets might yield different insights. This feedback is constructive as it prompts the authors to reflect on the limitations of their evaluation and encourages them to explore broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of alternative tasks or datasets that could be considered. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the performance of the model and baselines on test samples from the observational (in) distribution. It suggests that the authors should demonstrate the performance of their model and baselines on test samples from the observational distribution. This feedback is explicit and provides a clear action for the authors to take, which is to include this performance evaluation in their draft. The suggestion is concrete, as it specifies what needs to be added to the paper to address the issue. Therefore, the comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment addresses the issue of the performance of the model and baselines on test samples from the observational (in) distribution, specifically questioning the reason for the better performance of shift=0 compared to shift~ N ( 0 , \u03c3 2 ) . It suggests that the authors should demonstrate this performance on test samples from the observational distribution. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific as it clearly outlines what the authors need to demonstrate to address the concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the performance of the model and baselines on test samples from the observational (in) distribution, specifically regarding the better performance of shift=0 compared to shift~ N ( 0 , \u03c3 2 ). It suggests that the authors should demonstrate this performance on test samples from the observational distribution. While the comment raises a valid concern about the performance of the model, it lacks specific examples or references to support the claim that shift=0 is much better than shift~ N ( 0 , \u03c3 2 ). The suggestion to show performance on test samples from the observational distribution is a logical step to address the concern, but the initial claim lacks detailed justification. Therefore, the comment is somewhat verifiable, as it provides a suggestion but lacks comprehensive evidence or references to fully support the claim.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the performance of the model and baselines on test samples from the observational (in) distribution, specifically regarding the better performance of shift=0 compared to shift~ N ( 0 , \u03c3 2 ). It suggests that the authors should demonstrate this performance on test samples from the observational distribution, which is a logical and constructive suggestion. This feedback provides a clear direction for the authors to improve their draft by including additional performance evaluations. However, the comment could be more helpful if it offered specific guidance on how to conduct these evaluations or what aspects to focus on. Overall, the comment is mostly helpful as it identifies a gap in the current analysis and offers a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly states that the description of experimental details is lacking and that it would benefit from increased clarity to allow the user to better judge the results. It also provides a reference to 'Questions' for further details, which implies that the authors should address these questions to improve the clarity of the experimental description. This feedback is clear and direct, providing the authors with a specific action to take. The comment is highly actionable as it gives explicit guidance on what needs to be improved and how to address it.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'experiment description,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of detail in the experimental description, which makes it difficult for the user to judge the results. The comment further provides a reference to 'Questions' for further details, which adds specificity to the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the description of experimental details is lacking, making it difficult for the user to judge the results. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks concrete evidence or references to substantiate the assertion that the experimental description is insufficient. As a result, the claim is not fully verifiable, as it requires additional information or examples to be convincing. Therefore, the comment is rated as 2: Borderline Verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the manuscript, noting that the description of experimental details is lacking, which makes it difficult for the user to judge the results. It provides a clear and actionable suggestion by recommending that the description of experimental details would significantly benefit from increased clarity. The comment also directs the authors to 'Questions' for further details, offering a path for improvement. However, it could be more helpful if it provided specific examples or suggestions on how to enhance the clarity of the experimental description. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should provide more explanation to clarify the \"expected\" result and that the main contribution of the paper, the CBR, should be discussed in more detail. It specifically asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or only the first term. This feedback is explicit and provides concrete guidance on what the authors need to address to improve their draft. The authors are given a clear direction on what additional information or discussion is required, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"expected\" and \"Eq 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, providing more explanation and discussion on the CBR, different optimization strategies, and their results. This includes asking about the impact of minimizing both inter and intra terms or only the first term. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should provide more explanation for the \"expected\" result and discusses the main contribution of the paper, the CBR. It asks for a discussion on different optimization strategies and their results, such as the impact of minimizing both inter and intra terms in Equation 3 or only the first term. While the comment provides a logical reasoning for the need for additional explanation, it lacks specific references or examples to fully substantiate the claim. The authors are left to infer the relevance of these questions to the paper\\'s contribution and methodology. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the need for more explanation regarding the 'expected' result. It suggests that the paper should provide a clearer discussion on the contributions, particularly focusing on the CBR and its optimization strategies. The comment raises a question about the impact of minimizing both inter and intra terms in Equation 3 or only the first term, which could lead to a more detailed analysis of the results. This feedback is clear and actionable, offering the authors a specific direction for enhancing the clarity and depth of their discussion. However, it could be more helpful if it provided additional guidance or examples on how to address these issues. Overall, the comment is mostly helpful, as it provides valuable insights for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. While the comment implies that this addition would be beneficial, it does not explicitly instruct the authors to include such a definition or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a definition and how to incorporate it into their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not specify which part of the paper this definition should be included in, nor does it provide specific guidance on what aspects of the definition should be included or how it should be presented. This makes it difficult for the authors to identify the exact section where the definition should be added and what specific details are needed. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests including a formal or intuitive definition of the treewidth, which is central to all the proofs in the paper. This feedback is somewhat helpful as it identifies a potential area for improvement by pointing out the importance of clarifying a key concept. However, it lacks specificity and does not provide detailed guidance on how to incorporate this definition or what aspects of the definition would be most beneficial. To be more helpful, the comment could specify which proofs are particularly affected by the lack of a definition or offer suggestions on how to present the definition in a clear and accessible manner. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the paper is not self-contained and requires the supplementary material to understand certain parts of the main paper. It also requests the release of the source code to facilitate reproducibility. While the comment explicitly states the need for the supplementary material and the release of source code, it does not provide specific guidance on how to improve the self-containment of the main paper or what aspects of the paper should be clarified. The request for source code release is clear, but the comment lacks detailed instructions on how to enhance the paper\\'s self-containment. Therefore, the comment is somewhat actionable, as it identifies specific areas for improvement but lacks detailed guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights that the paper is not self-contained and requires the supplementary material to understand certain parts of the main paper. It also requests the release of the source code to allow for reproducibility. However, the comment does not specify which parts of the paper are not self-contained or what specific sections require clarification. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, while the comment requests the release of source code, it does not provide specific guidance on how to improve the self-containment of the main paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not self-contained and requires the supplementary material to understand large parts of the main paper. It also requests the release of the source code to allow for reproducibility. However, the comment does not provide specific examples or detailed reasoning to support why the paper is not self-contained or how the supplementary material is necessary. The request for source code release is a clear suggestion but lacks detailed justification. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks specific evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's self-containment, noting that the main paper is not comprehensive enough to be understood without the supplementary material. This highlights a critical aspect that the authors need to address to ensure the paper's accessibility and reproducibility. Additionally, the comment requests the release of the source code, which is a clear and actionable suggestion for improving the paper's reproducibility. However, the comment could be more helpful if it provided specific suggestions on how to enhance the self-containment of the main paper or what aspects of the paper could be clarified. Overall, the comment is mostly helpful as it points out a critical issue and offers a clear request for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of the model\\'s design choice involving multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what specific experiments or analyses could be conducted to explore this issue. The action is implicit and vague, as the authors are left to infer that they should conduct additional experiments or analyses to determine the importance of the design choice. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific feature of the model, the use of multiple INs at different speeds in the dynamics predictor, which is a novel aspect of the model. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it questions the importance of this design choice and whether one IN would suffice, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is important or how it affects the model\\'s performance. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the importance of a specific design choice in the model, namely the use of multiple INs at different speeds in the dynamics predictor. It explicitly asks whether this added complexity is necessary and whether one IN would suffice. This feedback is somewhat helpful as it prompts the authors to consider the significance of their design choice and potentially conduct further analysis or experimentation to justify its necessity. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue or what additional experiments might be necessary. Therefore, the comment is rated as somewhat helpful, as it identifies a potential area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the experiments, suggesting that the opponent might not aim to maximize the multi-agent payoff proposed by the authors. However, it does not provide explicit guidance on how the authors should address this concern or what steps they should take to improve their experiments. The comment lacks concrete suggestions or actions for the authors to take, making it unactionable. The authors are left without a clear understanding of what changes or additions are needed to address the issue, resulting in a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, namely that the opponent might not aim to maximize the multi-agent payoff proposed by the authors. The reviewer provides a rationale for this observation, mentioning that the opponent maximizes classical SE and AE instead. This level of detail helps the authors understand what needs to be addressed in their experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the opponent\\'s performance can be outperformed due to the opponent\\'s lack of aim to maximize the multi-agent payoff proposed by the authors. The reviewer provides a rationale by mentioning that the opponent maximizes classical SE and AE instead. While the comment offers a logical explanation, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as the authors can infer the reasoning but may need to seek additional information to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the experiments, specifically noting that the opponent might not aim to maximize the multi-agent payoff proposed by the authors. It provides a rationale for this observation, mentioning that the opponent maximizes classical SE and AE instead. While the comment highlights a potential weakness in the experimental design, it lacks specific suggestions or guidance on how the authors might address this issue or improve their experiments. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly instruct the authors to include this rationale. The comment is explicit in its suggestion but vague on how to implement it, as it does not provide specific guidance on what aspects of the choice should be clarified. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed instructions on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not explicitly mention which part of the paper this discussion should be included in. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding as it does not specify the exact section. The comment is specific in its suggestion to clarify the choice of algorithms, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not provide specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm over alternatives like PPO. It implies that the choice is related to the attention model paper the current work builds upon, but it does not specify the exact reasons or considerations that led to this choice. While the comment identifies a potential area for improvement, it lacks depth and specificity, leaving the authors with a general suggestion rather than actionable guidance. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance-regularized problem. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this confusion or what steps they should take to clarify the statement. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance-regularized problem. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance-regularized problem. However, the comment lacks specific reasoning or evidence to support this claim, making it difficult for the authors to understand the basis of the confusion. Without additional context or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO due to providing a more conservative upper bound than the variance-regularized problem. This feedback is somewhat helpful as it points out a potential issue that could be clarified or addressed in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might resolve this confusion or improve the clarity of the theorem. To be more helpful, the comment could include additional context, examples, or references to support the claim or offer actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, as it provides some insight but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of morphological segmentation across domains and suggests that it may need to be conducted differently for different domains. It also questions whether morphological segmentation is invariant across arbitrary domains. While the comment implies that the authors should address these questions, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore these questions in more detail. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the use of morphological segmentation across domains and suggests that it may need to be conducted differently for different domains. It also questions whether morphological segmentation is invariant across arbitrary domains. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this is not explicit. The comment is specific in detailing the questions and concerns about morphological segmentation, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the use of morphological segmentation across domains and suggests that it may need to be conducted differently for different domains. It questions whether morphological segmentation is invariant across arbitrary domains, which is relevant to the task of domain adaptation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises important questions about the use of morphological segmentation across different domains, suggesting that it may need to be conducted differently for each domain. This is particularly relevant in the context of domain adaptation, where the assumption of invariance may not hold. The comment highlights a potential weakness in the paper's approach and provides a clear direction for improvement by questioning the current assumptions and suggesting a need for further exploration. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the feedback is mostly helpful as it identifies a critical area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the object detection-based attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area of clarification needed, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the object detection-based attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the object detection or attention mechanisms discussed in the paper. The authors can infer that it relates to sections where these concepts are introduced or discussed, but the comment does not provide explicit references. The specificity is clear as it specifies the need for clarification on the attention process and rescaling. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question seeking clarification on the object detection-based attention process and the rescaling based on the receptive field. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the object detection-based attention process, specifically whether it is performed on the image or a convolutional feature map. It also inquires about the rescaling done based on the receptive field to determine the correspondence between image regions and spatial locations in the feature map. While the comment identifies a specific area of clarification needed, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to clarify a potentially confusing aspect of their work, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out the absence of a discussion about the Set Transformer (https://arxiv.org/abs/1810.00825) and other related works that use summary tokens. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this omission. The comment suggests that the authors should include a discussion of these related works, but it does not specify which aspects of the discussion should be included or how to integrate this information into the paper. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights the absence of a discussion about the Set Transformer (https://arxiv.org/abs/1810.00825) and other related works that use summary tokens. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need for a discussion on related works, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be integrated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide specific examples or references to these works, nor does it explain why this omission is problematic or how it affects the paper\\'s contribution. Without detailed justification or examples, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that use summary tokens. This is a valuable observation as it highlights an area where the authors could enhance the context and relevance of their work. However, the comment lacks specificity and does not provide guidance on how the authors might integrate this discussion into their paper. While it points out a potential weakness, it does not offer actionable advice or suggestions for improvement, making it somewhat helpful. The authors are aware of the need for additional discussion but are left without clear direction on how to proceed. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. While the comment implies that the authors should address this gap in their theoretical analysis, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a detailed analysis of the theoretical support for Fourier features. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the theoretical section or the discussion on Fourier features, but this inference is not precise. The comment is specific in questioning the theoretical support for Fourier features, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors are left without guidance on how to address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it has not been analyzed, which is an important consideration for the theoretical underpinnings of the work. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional analysis might be necessary. While it identifies a potential gap in the theoretical analysis, it lacks actionable advice, making it somewhat helpful. The authors are prompted to consider a theoretical aspect of their work, but the feedback could be more comprehensive and actionable to be rated higher.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue regarding the methodology, specifically questioning the details of how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific steps they should take to clarify this aspect. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a specific concern about the methodology, questioning the details of how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs clarification. While the authors can infer that it relates to the methodology or experimental setup, the comment lacks full grounding. It is specific in detailing the issue, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the methodology, specifically questioning how the network is trained to fit the residual instead of directly learning the input-output mapping. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the methodology, questioning how the network is trained to fit the residual instead of directly learning the input-output mapping. This feedback is somewhat helpful as it highlights a potential gap in the paper's explanation, prompting the authors to clarify this aspect. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending additional details or references. As a result, while it points out an important area for improvement, it does not fully support the authors in enhancing their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for clarification about the experiment setup in Section 3.3, specifically regarding data augmentation methods, learning rate, and other relevant details. This request provides a clear and direct action for the authors to take, as it specifies what information needs to be included or clarified in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the experiment setup, including data augmentation methods and learning rate. This provides clear guidance on what aspects of the paper require clarification or elaboration. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the experiment setup in Section 3.3, specifically regarding data augmentation methods and learning rate. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area of the paper that requires clarification, namely the experiment setup in Section 3.3. It prompts the authors to provide details on data augmentation methods and learning rate, which are crucial for understanding the experimental methodology. However, the comment lacks depth and does not offer suggestions on how to improve the clarity or presentation of this information. While it points out a gap in the paper, it does not provide actionable guidance or specific examples for the authors to enhance their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks comprehensive feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the closeness of the numbers when comparing the proposed method with baselines and suggests that the authors might have performed a statistical significance test. However, the comment does not explicitly instruct the authors to conduct a statistical significance test or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform a statistical significance test but are not given specific instructions on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, it does not specify which part of the paper this comparison is made in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to perform a statistical significance test, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that a statistical significance test is necessary. Without further elaboration or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the closeness of numbers when comparing the proposed method with baselines, suggesting that the authors might have performed a statistical significance test. This feedback is somewhat helpful as it points out a potential issue that could affect the interpretation of the results. However, the comment lacks specificity and does not provide guidance on how the authors might conduct a statistical significance test or what specific results might indicate a need for such a test. To be more helpful, the comment could include suggestions on how to perform the test or what statistical measures to consider. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not fully guide the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NP-SPEC-HMM. While the comment identifies a specific area of inquiry, it does not provide explicit guidance or suggestions on how the authors should address this question or what additional information should be included in their paper. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of non-parametric emission distributions on inference tasks. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the impact of non-parametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NP-SPEC-HMM. While the comment does not explicitly mention a specific part of the paper, it is clear that it pertains to the discussion of HMMs and their inference tasks. The authors can infer that it relates to the sections where these topics are discussed, but the comment lacks explicit grounding. The specificity is clear as it directly addresses a gap in the paper\\'s explanation of how non-parametric emission distributions affect inference tasks. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference tasks in HMMs. It asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NP-SPEC-HMM. While the question is logical and relevant to the paper\\'s focus, it does not contain any claims or opinions that require verification. It is a factual inquiry seeking clarification, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the impact of non-parametric emission distributions on inference tasks in HMMs. It specifically asks which common inference tasks (filtering, smoothing, marginal observation likelihood) can be computed exactly or approximately with an NP-SPEC-HMM. This question highlights an area where the paper could provide more clarity or detail, which is valuable for the authors to address. However, the comment does not offer specific suggestions or guidance on how the authors might explore or address this issue, leaving the feedback somewhat helpful. The authors are given a direction for improvement but lack detailed instructions on how to implement it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback implies that the authors should conduct a more detailed analysis of the experimental results to understand and explain the performance issues. However, the comment does not explicitly instruct the authors to perform this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a deeper analysis but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the analysis, namely the lack of analysis of the underlying reasons for the poor performance of the scope prompting method on GPT-3.5-turbo. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This claim is somewhat verifiable as it highlights a specific issue with the analysis but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide more context or evidence to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the analysis of experimental results, noting that the authors only mention the poor performance of the scope prompting method on GPT-3.5-turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to conduct a more detailed analysis to understand and explain the performance issues. However, the comment could be more helpful if it provided suggestions on how to conduct this analysis or what specific aspects to focus on. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment suggests that the motivation in the introduction about low-rank factorization is unnecessary, given that the main result is about polytopes. It also requests that the implications of the result for low-rank matrix factorization be explicitly discussed. While the comment implies that the authors should remove the unnecessary motivation and discuss the implications, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address both the unnecessary motivation and the implications for low-rank matrix factorization. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the motivation section in the introduction, specifically mentioning the low-rank factorization and its relevance to the main result about polytopes. It suggests that the motivation is unnecessary and requests that the implications for low-rank matrix factorization be discussed explicitly. However, the comment does not specify which part of the introduction this relates to, making it weakly grounded. The feedback is specific in identifying the issue with the motivation and the need for discussion on implications, but without explicit references to sections, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the motivation in the introduction about low-rank factorization is unnecessary given that the main result is about polytopes. It also suggests that the implications of the result for low-rank matrix factorization should be discussed explicitly. The comment provides a logical reasoning by pointing out the relevance of the main result and the need for discussion on implications. However, it lacks specific examples or references to support the claim fully. The suggestion to discuss implications is clear, but the comment could be strengthened by providing more detailed reasoning or examples to fully justify the claim. Therefore, the comment is somewhat verifiable, as it provides a logical basis but requires additional support to be fully convincing.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the motivation section of the introduction, suggesting that the discussion on low-rank factorization is unnecessary given the main focus on polytopes. It provides a clear suggestion for improvement by recommending that the implications of the result for low-rank matrix factorization be discussed explicitly. This feedback is actionable and provides a specific direction for the authors to enhance their draft by addressing both the relevance of the motivation and the implications of their findings. However, the comment could be more helpful if it offered additional guidance on how to discuss these implications or provided examples of how to integrate them into the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific method used for solving the min-min problem, which is mentioned as an alternating direction method. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should clarify which specific method is being used, provide more details about the method, or explore alternative methods. Without any actionable steps or suggestions, the authors are left without a clear direction on how to address this issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"min-min problem\" and the \"alternating direction method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the method used to solve the min-min problem, providing clear guidance on what needs to be clarified or elaborated upon. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about the specific method used to solve the min-min problem, which is mentioned as an alternating direction method. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the specific method used to solve the min-min problem, which is mentioned as an alternating direction method. While it identifies a gap in the paper's description, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their draft. Therefore, it is rated as barely helpful, as it highlights a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this critique or improve the novelty of their work. Without actionable suggestions or explicit directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, it does not specify which part of the paper this critique pertains to, such as a specific section or methodology. The authors may have an idea of where this critique applies, but it is not explicitly mentioned, making the comment weakly grounded. The critique is specific in questioning the originality of the approach, but without explicit grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the approach is limited, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the novelty of the approach, specifically questioning the originality of interpreting deep neural network predictions using linear models for model interpretation. While it identifies a potential issue with the novelty of the work, it lacks specific suggestions or guidance on how the authors might address this critique or enhance the originality of their approach. Without actionable feedback or detailed suggestions, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but does not offer constructive guidance for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not provide explicit guidance on how to achieve this comprehensiveness or generalization. The authors are left to infer that they need to expand the scope of their experiments or consider more diverse baselines, but the comment lacks concrete details on how to implement these changes. As a result, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, it does not specify which parts of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to address the limitations of the model size and baselines, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. However, the comment does not provide specific examples or detailed reasoning to support why these limitations are problematic or how they could be addressed. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to improve their experiments accordingly. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive. This feedback is somewhat helpful as it identifies a specific area for improvement, namely the need for more extensive experimentation. However, the comment lacks detailed guidance on how to achieve this comprehensiveness or generalization, such as suggesting additional experiments or baselines to consider. Without specific actionable steps, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. While the comment implies that the authors should consider incorporating these approaches, it does not provide explicit instructions on how to implement them or why they would be beneficial. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take and the potential benefits of adding these approaches. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, it does not specify which part of the paper this table is in or provide any context about the table itself. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in suggesting the addition of a particular approach, but without grounding, it is challenging for the authors to understand the context or relevance of this suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, the comment does not provide any justification or reasoning for why these approaches should be included or how they would enhance the table. Without specific examples, references, or logical reasoning, the claim lacks verifiability. The authors are left without guidance on how to implement this suggestion or why it would be beneficial, making the comment barely verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. This feedback is somewhat helpful as it identifies a potential enhancement to the paper by suggesting a specific approach that could be included. However, the comment lacks detail on why this approach would be beneficial or how it could be integrated into the table. To be more helpful, the comment could provide additional context, such as how these approaches could improve the results or enhance the analysis. Therefore, the comment is somewhat helpful, as it points out an area for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks an ablation study to explain why the chosen prompt is effective, particularly mentioning the potential benefits of few-shot examples for CoT. While the comment implies that an ablation study should be conducted to justify the choice of prompt, it does not explicitly instruct the authors to perform this study or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the potential benefits of few-shot examples for CoT. However, it does not specify which part of the paper this critique pertains to, such as a particular section or subsection. The authors can infer that it relates to the methodology or discussion section, but this inference is not explicit. The comment is specific in detailing what is missing\u2014a lack of ablation study and the potential benefits of few-shot examples for CoT\u2014but it lacks full grounding as it does not pinpoint the exact section. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks an ablation study to explain the choice of prompt, specifically mentioning the potential benefits of few-shot examples for CoT. However, the comment does not provide any specific examples or detailed reasoning to support why an ablation study is necessary or how it would improve the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks depth, namely the absence of an ablation study to justify the choice of prompt. It suggests that including few-shot examples for CoT could potentially improve performance, providing a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered additional guidance on how to conduct the ablation study or what specific aspects to focus on. Overall, the feedback is mostly helpful as it highlights a significant gap in the paper and offers a clear suggestion for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to use the terms \"causal mechanisms\" and \"causality\" carefully, as they are different from temporal relationships. This feedback is clear and direct, providing a specific action for the authors to take. It does not leave any ambiguity about what needs to be done, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1\" and \"causal mechanisms,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of terms \"causal mechanisms\" and \"causality,\" noting that they are different from temporal relationships. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that \"causal mechanisms\" and \"causality\" are different from temporal relationships, suggesting that the authors should use these terms carefully. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by pointing out a potential confusion in terminology regarding \"causal mechanisms\" and \"causality\" on page 1. It instructs the authors to use these terms carefully, emphasizing the distinction between causality and temporal relationships. This feedback is valuable as it helps the authors clarify their terminology, which is crucial for maintaining the integrity and clarity of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to distinguish between these concepts. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the strength of the demonstration of capability, specifically regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their demonstration. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence from the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. The reviewer raises a valid concern about the evidence provided, which helps the authors understand what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the strength of the demonstration of capability regarding the claim that replacing procedure steps of XAIFOOLER with a random mechanism dropped its performance. While it identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their demonstration. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not offer constructive advice for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using low-rank approximation, as presented in \"On the Complexity of Learning with Kernels.\" While the comment implies that such a discussion would be beneficial, it does not explicitly instruct the authors to include this discussion or provide specific guidance on how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should add this discussion but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using low-rank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss the relationship with the referenced work, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using low-rank approximation, as presented in \"On the Complexity of Learning with Kernels.\" However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include a discussion on how the results relate to the lower bounds on kernel learning using low-rank approximation, as presented in \"On the Complexity of Learning with Kernels.\" This feedback is somewhat helpful as it identifies a potential area for improvement by pointing out a relevant reference that could enhance the paper\\'s discussion. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate this discussion or what aspects of the results should be highlighted. To be more helpful, the comment could specify which parts of the paper the discussion should address or how it would contribute to the overall understanding of the results. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider the assumptions underlying PCA and how well they are met. While the comment highlights potential issues, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the assumptions and their implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It also suggests that the authors should consider the assumptions underlying PCA and how well they are met. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the method and assumptions, it lacks grounding, as it does not clearly identify the part of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It provides a reference to a paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions underlying PCA. However, the comment lacks specific details or examples about how the assumptions are met or how they relate to the paper\\'s results. While the reference provides a starting point for further exploration, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the novelty of using PCA to reduce interaction count and questions the significance of the paper's results. It suggests that the authors should consider the assumptions underlying PCA and how well they are met. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address these concerns or enhance the significance of their results. The feedback is somewhat helpful as it points out a potential weakness in the paper's methodology, but it does not provide actionable steps for improvement, leaving the authors with limited direction on how to strengthen their draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the authors should consider the assumptions underlying PCA and how well they are met. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address these concerns or what specific steps they should take to improve their draft. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the assumptions and their implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It suggests that the authors should consider the assumptions underlying PCA and how well they are met. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or result. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its critique of the method and assumptions, it lacks grounding, as it does not clearly identify the part of the paper being discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the novelty of using PCA to reduce interaction count and questions the significance of the paper results. It provides a reference to a paper by Dombrowski et al. that discusses robust explanations for deep neural networks, which could be relevant to the assumptions underlying PCA. However, the comment lacks specific details or examples about how the assumptions are met or how they relate to the paper's results. While the reference provides a starting point for further exploration, the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the novelty of using PCA to reduce interaction count and questions the significance of the paper's results. It suggests that the authors should consider the assumptions underlying PCA and how"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the few-shot RC models considered in the paper are not state-of-the-art, and it suggests comparing the performance of these models to relation extraction/generation models in few-shot settings. While the comment implies that the authors should conduct such a comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform this comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of few-shot RC models in the paper and suggests comparing their performance to relation extraction/generation models in few-shot settings. However, it does not specify which part of the paper discusses these models, making it weakly grounded. The comment is specific in suggesting a comparison to state-of-the-art models, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the few-shot RC models considered in the paper are not state-of-the-art, suggesting a comparison to relation extraction/generation models in few-shot settings. However, the comment does not provide specific examples or references to support the claim that the models are not state-of-the-art. The suggestion to compare performance is a logical inference, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by noting that the few-shot RC models considered are not state-of-the-art. It suggests comparing the performance of these models to relation extraction/generation models in few-shot settings. This feedback is somewhat helpful as it points out an area for improvement and provides a specific direction for the authors to enhance their work. However, the comment could be more helpful if it included specific examples or references to state-of-the-art models or detailed suggestions on how to conduct the comparison. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. While the comment implies that the authors should include results, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to present results, but the comment lacks specific guidance on how to present them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the discussion of using sequential MCB vs a single MCT layers for the decision head. It is fully grounded as it explicitly mentions a specific part of the paper, allowing the authors to accurately identify the section being addressed. The comment is also specific because it requests additional information about what was observed in this discussion, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing results related to the discussion of using sequential MCB vs a single MCT layers for the decision head. This feedback is clear and actionable, as it directs the authors to include results that would enhance the discussion and provide more insight into the topic. However, the comment could be more helpful if it offered suggestions on how to present these results or what specific observations should be included. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment highlights a potential issue with the experimental setup, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify their experimental setup and consider the impact of the number of distribution sets. However, the comment lacks concrete details on how to implement these clarifications, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, it does not specify which part of the paper this question pertains to, such as a specific section or table where this choice is discussed. This makes it difficult for the authors to pinpoint the exact area needing clarification. While the comment is specific in its inquiry about the choice of distribution sets and their impact, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. However, the comment does not provide any supporting evidence, reasoning, or references to justify the need for clarification or the potential impact of the choice of distribution sets. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it relates to the overall quality of the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of 20 distribution sets and whether the number of distribution sets can be controlled for each class. It also inquires about the impact of selecting only a few distribution sets. While the comment identifies a potential area for clarification, it lacks depth and specificity. It does not provide suggestions on how the authors might address this issue or what aspects of the choice of distribution sets could be improved. The feedback is somewhat helpful as it prompts the authors to consider the impact of their experimental setup, but it does not offer actionable guidance or detailed suggestions for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should showcase their approach using transformer-based (masked) language models instead of the obsolete n-gram HMM and RNN models. This action is clear and concrete, as it provides a specific direction for the authors to improve their draft by aligning it with current NLP trends. The comment offers a clear and actionable suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of perplexity experiments with obsolete language models, specifically mentioning n-gram HMM and RNN. It suggests that the authors should showcase their approach using transformer-based (masked) language models to better align with current NLP trends. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the use of perplexity experiments. The comment is also specific because it clearly specifies the need to use transformer-based models to improve alignment with current trends. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the use of obsolete language models (n-gram HMM and RNN) for perplexity experiments is outdated and recommends using transformer-based (masked) language models to better align with current NLP trends. The claim is supported by logical reasoning, as it highlights the need for alignment with contemporary practices in the field. However, the comment could be strengthened by providing specific examples or references to recent literature that supports the use of transformer-based models for such experiments. This would make the claim more verifiable. Therefore, the comment is categorized as 4: Mostly Verifiable, as it provides a clear rationale but lacks detailed references or examples to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the use of obsolete language models for perplexity experiments. It suggests that the authors should showcase their approach using more contemporary transformer-based (masked) language models, which are more aligned with current NLP trends. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the relevance and impact of their work. By following this suggestion, the authors can improve the alignment of their research with current practices in the field, making the comment highly helpful. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to clarify the estimation of mu. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the estimation of mu, which is the proportion of missing observations. However, it does not explicitly mention which part of the paper discusses this topic, making it weakly grounded. The comment is specific in questioning the estimation of mu, but it lacks detailed guidance on how the authors might address this issue or clarify the estimation process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any supporting evidence, reasoning, or references to justify why this estimation might be unclear or problematic. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the estimation of mu, which is the proportion of missing observations. However, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the estimation process. The comment lacks actionable feedback or specific recommendations, leaving the authors without a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider providing high-probability bounds instead of only bounds in expectation. It implies that using ensemble methods, as demonstrated in the experiments, could be a way to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment explicitly states these actions, it does not provide detailed guidance on how to implement them, such as which specific ensemble methods to use or how to calculate error bars. The authors are given a clear direction but may need to further explore the suggested methods to fully implement the changes. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"high-probability bounds\" and \"ensemble methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting the use of ensemble methods to achieve high-probability bounds and adding measures of robustness like error bars or standard deviation to the experiments. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that only bounds in expectation are provided and questions whether high-probability bounds could be obtained. It proposes using ensemble methods, as demonstrated in the experiments, to achieve this. Additionally, it suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific references or detailed examples of how ensemble methods or robustness measures could be implemented. This makes the claim somewhat verifiable, as the authors would need to explore the suggestions further to fully understand and apply them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper, specifically the absence of high-probability bounds, which are often more informative than bounds in expectation. It suggests using ensemble methods, as demonstrated in the experiments, to achieve these bounds. Additionally, it recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with specific steps to improve their work. By addressing these suggestions, the authors can enhance the robustness and reliability of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the paper\\'s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. The reviewer\\'s excitement is followed by disappointment upon learning that diversity is not enforced. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their model to enforce diversity. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the paper\\'s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. However, it does not specify which part of the paper this concern relates to, such as the introduction, methodology, or results sections. The authors might infer that it pertains to the methodology or results, but this is not explicitly stated. The comment is specific in detailing the issue of diversity not being enforced, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s focus on diversity, which is mentioned in the title, but the model does not enforce diversity explicitly. The reviewer expresses excitement about the potential of the model to incorporate diversity but becomes disappointed upon learning that diversity is not enforced. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the model does not enforce diversity. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant concern with the paper's focus on diversity, as mentioned in the title, but the model does not enforce diversity explicitly. This feedback is clear and actionable, as it highlights a critical gap in the paper's methodology that needs to be addressed. By pointing out this inconsistency, the reviewer provides a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered suggestions on how to incorporate diversity into the model or provided examples of how this could be achieved. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This provides a clear and direct action for the authors to take, which is to include these experiments in their draft. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights the absence of certain experiments, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are supposed to be included in, making it weakly grounded. The comment is specific in identifying the missing experiments, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how their absence impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of these missing experiments. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks completeness by pointing out that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. This feedback is clear and actionable, as it directs the authors to include these experiments to enhance the comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these experiments effectively. Overall, the comment is mostly helpful as it highlights a critical gap in the paper, but it could be more comprehensive with further guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds, specifically mentioning the difference between sqrt(beta) and beta^{1/3}. It also notes that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback results. However, the comment does not provide explicit guidance or suggestions on how the authors should address this gap or improve their results. The feedback is vague and lacks concrete actions or recommendations, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a gap between the lower and upper bounds, specifically mentioning the difference between sqrt(beta) and beta^{1/3}. It also notes that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback results. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact sections that need attention. While the comment provides some specificity by mentioning the adaptive adversary and counterfactual feedback, it lacks full grounding as it does not explicitly reference specific sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a gap between the lower and upper bounds, specifically mentioning the difference between sqrt(beta) and beta^{1/3}. It also suggests that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback results. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or references makes the claim somewhat verifiable, as it provides a general observation but requires further elaboration for the authors to effectively address the feedback.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap between the lower and upper bounds, specifically mentioning the difference between sqrt(beta) and beta^{1/3}. It also notes that the existing bound with the independence number may be more suitable for some graphs, particularly in the context of the adaptive adversary and counterfactual feedback results. However, the comment lacks specific guidance or suggestions on how the authors should address this gap or improve their results. While it points out an area for potential improvement, it does not provide actionable steps or detailed feedback that would help the authors enhance their draft. As a result, the comment is somewhat helpful, as it highlights an issue but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what steps they should consider to resolve it. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 2\" and references the CUB and SOP datasets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results of the ablation studies, particularly why the complete loss function performed worse than those with some terms missing. This provides clear guidance on what aspect of the results needs further explanation or clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the results in Table 2, specifically regarding the ablation studies on the CUB and SOP datasets. It points out that the complete loss function performed worse than those with some terms missing, which seems contradictory. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential inconsistency but lacks actionable insights or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to conduct an experiment where the image is occluded, simulating irregularities in neural/behavioral data and allowing them to inspect the model\\'s long-range inference capacity. The reviewer provides a clear rationale for why this experiment is important and suggests that it should be included in the final version of the paper. The action is explicit, and the authors are given concrete guidance on what experiments to perform and why they are important. This level of detail and specificity makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Finally,\" and \"similarly to above,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the inclusion of an experiment where the image is occluded to simulate irregularities in neural/behavioral data and to inspect the model\\'s long-range inference capacity. The comment provides a clear rationale for why this experiment is important, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an experiment where the image is occluded to simulate irregularities in neural/behavioral data. The reviewer provides a rationale for why this experiment is important, explaining that it would allow the authors to inspect the model\\'s long-range inference capacity. The suggestion is logical and supported by the reasoning that such an experiment would provide valuable insights into the model\\'s performance. However, the comment lacks specific references or examples to further substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for an additional experiment that the authors could conduct. It explains the rationale behind the experiment, noting that it would simulate irregularities often present in neural/behavioral data and allow for the inspection of the model's long-range inference capacity. The reviewer also emphasizes that these experiments are relatively straightforward to implement and should be included in the final version of the paper unless the authors have a compelling reason not to. This feedback is specific and provides a clear direction for enhancing the paper's experimental validation, making it highly helpful for the authors to improve their draft. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a specific issue in the abstract, noting that the statement 'ensure that with a low-rank feature subspace, a small number of attacked samples, and other mild assumptions' is unclear. It suggests that the abstract should be more high-level and that technicalities are not necessary. While the comment points out a specific area of confusion, it does not provide explicit guidance on how to clarify the statement or what aspects of the abstract should be made more high-level. The action is implicit and somewhat vague, as the authors need to infer the specific changes needed to improve the clarity of the abstract. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which is its unclear nature due to the technicalities mentioned. The comment provides a clear direction for improvement by suggesting that the abstract should be more high-level and that technicalities are not necessary. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the statement in the abstract is unclear and suggests that the abstract should be more high-level. However, the comment does not provide specific examples or detailed reasoning to support why the statement is unclear or how it could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the assertion.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of a statement in the abstract, noting that it is unclear and suggesting that the abstract should be more high-level. This feedback is valuable as it points out a potential area of confusion for readers and provides a clear direction for improvement. By suggesting that technicalities are not necessary, the comment helps the authors focus on the essential aspects of their work, enhancing the overall clarity and accessibility of the abstract. However, the comment could be more helpful if it provided specific suggestions on how to simplify the abstract or clarify the technicalities. Overall, the comment is mostly helpful as it directs the authors to improve the clarity of their abstract, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be beneficial to include results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not provide explicit guidance on how to incorporate these results or what specific tasks to include. The action is implicit and somewhat vague, as the authors can infer the need for additional results but lack detailed instructions on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include results in other modalities and discusses the importance of OOD performance for language tasks, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not provide specific examples or references to support the claim that OOD performance is more relevant for language tasks. The comment lacks detailed reasoning or evidence to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the relevance of OOD performance in language tasks, which adds to the ambiguity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests expanding the results section to include results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. This feedback is somewhat helpful as it provides a direction for the authors to consider additional experiments or analyses that could enhance the comprehensiveness of their work. However, the comment lacks specific guidance on how to incorporate these results or which language-related tasks to include, leaving the authors with a general suggestion rather than a detailed plan for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests expanding the results section to include results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not provide explicit guidance on how to incorporate these results or which specific language-related tasks to include. The action is implicit and somewhat vague, as the authors can infer the need for additional results but lack detailed instructions on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the results section to include results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include results in other modalities and discusses the importance of OOD performance for language tasks, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests expanding the results section to include results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. However, it does not provide specific examples or references to support the claim that OOD performance is more relevant for language tasks. The comment lacks detailed reasoning or evidence to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the relevance of OOD performance in language tasks, which adds to the ambiguity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests expanding the results section to include results in other modalities, such as language-related tasks, and mentions that people care about out-of-distribution (OOD) performance for language tasks. This feedback is somewhat helpful as it provides a direction for the authors to consider additional experiments or analyses that could enhance the comprehensiveness of their work. However, the comment lacks specific guidance on how to incorporate these results or which language-related tasks to include, leaving the authors with a general suggestion rather than a detailed plan for improvement."}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the motivation of the work should be further justified, particularly in the context of few-shot learning. It points out that the paper defines and creates a few-shot situation for graph link prediction but does not consider how to effectively use \"few-shot\" or how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific steps to take. The action is implicit and somewhat vague, as the authors can infer that they need to justify the motivation and consider the effectiveness of the \"few-shot\" approach, but they may not know exactly how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"few-shot learning\" and \"graph link prediction,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues with the motivation, noting that the paper does not consider how to effectively use \"few-shot\" and how to guarantee the trained model can be generalized well to new tasks. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the motivation of the work should be further justified, particularly in the context of few-shot learning. It suggests that the paper does not consider how to effectively use \"few-shot\" and how to guarantee the trained model can be generalized well to new tasks with 0/few training steps. While the comment identifies a potential issue, it lacks specific examples or references to support the claim. The authors may find it challenging to understand the exact points of concern without additional context or evidence. Therefore, the comment is somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical area for improvement in the paper's motivation and methodology. It points out that while the paper defines a few-shot situation for graph link prediction, it does not adequately address how to effectively use 'few-shot' or how to guarantee the trained model's generalizability to new tasks with 0/few training steps. This feedback is valuable as it highlights a significant gap in the paper's approach and suggests that the authors need to provide a more robust justification for their methodology. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues, such as proposing additional experiments or analyses. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the use of Gaussian Process (GP) and mentions that dynamical modeling has been widely investigated in the GP community, referencing the Gaussian Process Dynamical Model in NIPS 2005. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their use of GP or address the critique. The comment lacks actionable advice, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of Gaussian Process (GP) and references the dynamical modeling approach, mentioning the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors may have an idea of where the critique applies, but it is not explicitly mentioned, making the comment weakly grounded. The critique is specific in that it points out the naive use of GP and references a specific paper, but it lacks detailed guidance on how to address the critique. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of Gaussian Process (GP) is naive and references the Gaussian Process Dynamical Model in NIPS 2005. However, the comment does not provide specific examples or detailed reasoning to support why the use of GP is naive or how it compares to other approaches. The reference to NIPS 2005 provides some context, but it does not substantiate the claim. Without additional explanation or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the use of Gaussian Process (GP) and mentions that dynamical modeling has been widely investigated in the GP community, referencing a specific paper. However, it does not provide any specific feedback or suggestions on how the authors might improve their use of GP or address the critique. The comment lacks actionable advice or detailed guidance, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment critiques the use of Gaussian Process (GP) and references the dynamical modeling approach, mentioning the Gaussian Process Dynamical Model in NIPS 2005. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting specific improvements or changes to their methodology. The comment lacks actionable guidance, leaving the authors without a clear direction for addressing the critique. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the use of Gaussian Process (GP) and references the dynamical modeling approach, mentioning the Gaussian Process Dynamical Model in NIPS 2005. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors may have an idea of where the critique applies, but it is not explicitly mentioned, making the comment weakly grounded. The critique is specific in that it points out the naive use of GP and references a specific paper, but it lacks detailed guidance on how to address the critique. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point critiques the use of Gaussian Process (GP) and references the dynamical modeling approach, mentioning the Gaussian Process Dynamical Model in NIPS 2005. However, it does not provide specific examples or detailed reasoning to support why the use of GP is naive or how it compares to other approaches. The reference to NIPS 2005 provides some context, but it does not substantiate the claim. Without additional explanation or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered borderline verifiable.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the use of Gaussian Process (GP) and references the dynamical modeling approach, mentioning the Gaussian Process Dynamical Model in NIPS 2005. However, it does not provide specific feedback or suggestions on how the authors might improve their use of GP or address the critique. The comment lacks actionable advice or detailed guidance, leaving the authors without a clear path forward. As a result, the comment is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also recommends that the online algorithm and robustness be highlighted as novel and interesting, and that the experimental results in the appendix be moved to the main paper. While the comment provides clear guidance on what needs improvement and where the focus should be, it does not specify how the authors should address the \"half-baked\" aspect or how to present the online algorithm and robustness more effectively. The action is explicit but somewhat vague, as it lacks detailed instructions on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the differential privacy application, suggesting that it is \"half-baked\" and recommending that the authors think through it more clearly. It also mentions the online algorithm and robustness as novel and interesting, and suggests moving the experimental results from the appendix to the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application or the online algorithm, making it weakly grounded. The feedback is specific in suggesting improvements and clarifications, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment lacks specific examples or detailed reasoning to support the claim that the application is \"half-baked.\" The suggestion to move the experimental results is a logical recommendation but does not provide a rationale for why this is necessary. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement, suggesting that the differential privacy application is 'half-baked' and recommending that the authors think through it more clearly. It also highlights the novelty and interest of the online algorithm and robustness, suggesting that the experimental results in the appendix should be moved to the main paper. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the clarity and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to improve the differential privacy application or how to present the online algorithm and robustness more effectively. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to areas needing improvement and provides a clear path forward.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation and questioning the appropriateness of using robotic manipulation in general. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the scope of their methodology or consider alternative approaches. The feedback is vague, as it does not specify what aspects of the methodology should be clarified or how to address the concern. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the specificity of the proposed methodology, questioning whether it is specific to bimanual manipulation or if robotic manipulation in general would be more appropriate. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. The authors may have to infer that it pertains to the methodology section or the introduction, but this inference is not explicit. The comment is specific in its critique of the methodology\\'s scope, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the specificity of the proposed methodology, suggesting that it may not be limited to bimanual manipulation. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the specificity of the proposed methodology, questioning whether it is limited to bimanual manipulation or if robotic manipulation in general would be more appropriate. This feedback is somewhat helpful as it identifies a potential limitation in the scope of the methodology, prompting the authors to clarify or expand their approach. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative approaches or providing examples of how the methodology could be applied in different contexts. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide METEOR results, which are mentioned in recent works. This is a clear and direct action for the authors to take, as it specifies what additional information should be included in their draft. The comment is explicit and provides concrete guidance on how to address the feedback, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"METEOR results,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of METEOR results, which are mentioned in recent works. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide METEOR results, which are mentioned in recent works. However, the comment does not provide any specific references or examples of these recent works, making it difficult for the authors to understand the basis of the suggestion. Without detailed references or examples, the claim is not fully verifiable, as it lacks the necessary evidence to support the need for METEOR results. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment is clear and actionable, instructing the authors to include METEOR results, which are mentioned in recent works. This feedback is specific and provides a direct suggestion for improvement, aligning with a score of 4. The comment helps the authors understand what additional information is needed to strengthen their work, making it mostly helpful. However, it could be more helpful if it provided further context or examples of how METEOR results are typically used or interpreted in the field. Overall, the comment is clear and actionable, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should spend more time discussing the potential benefits of using AutoML approaches, such as extracting hints that can be reused in the design of new network architectures. It implies that the authors should provide more detailed comments on the findings of the study, particularly regarding the most significant takeaways from the discovered architecture. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should include more detailed comments on the findings. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or result. This makes it difficult for the authors to identify the exact area that needs attention. The comment is specific in its suggestion to discuss the biggest takeaways from the found architecture, but without grounding, it is weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper, suggesting that the authors should spend more time discussing the benefits of using AutoML approaches, particularly in terms of extracting hints that can be reused in the design of new network architectures. This feedback is somewhat helpful as it points out a specific aspect that could enhance the paper's value and contribution. However, the comment lacks depth and does not provide specific guidance or examples on how the authors might address this issue. To be more helpful, the comment could include suggestions on what aspects of the findings are most relevant or how the authors might structure their discussion to effectively communicate these insights. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main part, particularly the introduction, could be more concise. It also recommends including empirical results. While the comment implies that the authors should make the introduction more concise and incorporate empirical results, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the conciseness and include empirical results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not specify which part of the main part or the introduction is being addressed, making it weakly grounded. The comment is specific in suggesting that the introduction should be more concise and include empirical results, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main part, particularly the introduction, could be more concise and includes empirical results. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would improve the paper. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part, particularly the introduction, could be more concise and includes empirical results. While the comment identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to achieve this. The authors are left with a general idea of what needs to be addressed but without actionable steps or examples. This makes the comment somewhat helpful, as it points out a potential issue but does not fully support the authors in addressing it. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the experiments were conducted only on two typical games and questions the performance of ReBeL on more complex problems, particularly those with larger depths. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting additional experiments or methods to evaluate ReBeL on more complex problems. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental setup, specifically questioning the limited scope of the experiments conducted on only two typical games. It highlights a concern about the performance of ReBeL on more complex problems, particularly those with larger depths, which could lead to significant input sizes for value and policy functions. However, the comment does not specify which part of the paper this critique pertains to, such as the experimental section or results. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, the comment lacks specificity regarding what aspects of the experiments should be expanded or improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the limited scope of the experiments conducted on only two typical games, questioning the performance of ReBeL on more complex problems, particularly those with larger depths. However, the comment lacks specific examples or references to support the claim that the experiments are insufficient. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the experimental setup, specifically questioning the scope of the experiments conducted on only two typical games. It highlights a concern about the performance of ReBeL on more complex problems, particularly those with larger depths, which could lead to significant input sizes for value and policy functions. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand their experiments to better evaluate ReBeL's performance on more complex problems. While it points out a potential weakness, the feedback is incomplete and does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the trivial improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not provide specific guidance or suggestions on how the authors might address these concerns or enhance the novelty of their work. The comment lacks actionable details, leaving the authors without a clear path to improve their draft. As a result, the feedback is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the improvements on different datasets and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, it does not specify which part of the paper these claims are based on, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not reference specific sections, tables, or figures, and it is not specific about what aspects of the paper's novelty or improvements are being questioned. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and questions the novelty of the paper, suggesting that adding topic entities is incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment critiques the paper's improvements on different datasets, suggesting that they are trivial and questioning the novelty of the work. It also points out that many previous works have focused on similar topics, implying that the addition of topic entities is incremental. However, the comment lacks specific suggestions or guidance on how the authors might address these concerns or enhance the novelty of their work. While it identifies a potential issue, it does not provide actionable feedback or constructive advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is rated as barely helpful, aligning with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a missing aspect in the paper, specifically the lack of discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include a discussion on the theoretical guarantee, but the comment lacks concrete details on what specific aspects should be covered or how to structure this discussion. Therefore, the comment is somewhat actionable, as it highlights a necessary addition but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific area of the paper that lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the missing theoretical guarantee, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact location where this discussion should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion on the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the significance of this omission or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks discussion, namely the theoretical guarantee about the approximation ratio of the hierarchical strategy to the global optimal of the original QUBO. This is a critical aspect that could impact the credibility and completeness of the paper's findings. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the theoretical guarantee should be discussed. While it highlights an important omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a significant gap but does not offer detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of quantitative measures to evaluate the generated VCEs, noting that the evaluation is primarily based on visual inspection. While the comment identifies a gap in the current evaluation process, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they should consider incorporating quantitative measures to enhance the evaluation, but the comment lacks concrete suggestions or examples of what these measures might be. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a general issue with the evaluation of the generated VCEs, noting that it is primarily based on visual inspection. However, it does not specify which part of the paper this issue is related to, such as a particular section or method description. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in pointing out the need for quantitative measures, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of the generated VCEs is primarily based on visual inspection, lacking a quantitative measure. This claim is somewhat verifiable as it highlights a potential issue with the evaluation process. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence limits the verifiability of the claim, aligning it with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the evaluation process, specifically noting the lack of quantitative measures to assess the generated VCEs. It highlights that the evaluation is primarily based on visual inspection, which may not provide a comprehensive or objective assessment. This feedback is clear and actionable, as it directs the authors to consider incorporating quantitative measures to enhance the evaluation process. However, the comment could be more helpful if it provided specific suggestions or examples of quantitative measures that could be used. Overall, the comment is mostly helpful as it points out a critical area for improvement and offers a direction for enhancement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. While the comment points out a potential issue with the performance claims, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their results. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their performance claims. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance improvements over baselines, noting that they are marginal and mostly within the error bar range. It also mentions that the authors claim the method performs better than the baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not specify which part of the paper this analysis is based on, such as a specific section or table where these results are presented. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the performance claims, but without clear grounding, it is weakly grounded. Therefore, the comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. The reviewer provides a logical reasoning by comparing the improvements to the error bars, which supports the claim. However, the comment lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is clear, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance claims, noting that the improvements over baselines are marginal and mostly within the error bar range. It suggests that the performance differences between methods are not very significant, which could be a concern for the authors. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their results. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are left to infer that they need to clarify or justify their performance claims, but without explicit guidance, the feedback remains incomplete. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. While it identifies a potential issue with the performance claims, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their results. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to clarify or justify their performance claims, but without specific guidance, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance improvements over baselines, noting that they are marginal and mostly within the error bar range. It suggests that the performance differences between methods are not very significant, which is a relevant observation. However, the comment does not specify which part of the paper this analysis is based on, such as a specific section or table where these results are presented. Without clear grounding, the authors may find it challenging to identify the exact part of the paper that needs revision. The comment is specific in its critique of the performance claims, but the lack of grounding makes it weakly grounded. Therefore, the comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. The reviewer provides a logical reasoning by comparing the improvements to the error bars, which supports the claim. However, the comment lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is clear, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance claims, noting that the improvements over baselines are marginal and mostly within the error bar range, suggesting that the performance differences between methods are not very significant. This observation is relevant and could prompt the authors to reconsider their performance claims or provide more detailed analysis. However, the comment lacks specific guidance or suggestions"}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the generated videos, noting significant artifacts and a below-average action recognition performance compared to the state-of-the-art on the UCF dataset. It also mentions the use of more complex architectures in the state-of-the-art methods. However, the comment does not provide specific guidance or suggestions on how to address these issues or improve the performance. The authors are left without clear actions to take, such as identifying the root cause of the artifacts or proposing ways to enhance the action recognition performance. As a result, the comment lacks actionable content, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of significant artifacts in the generated videos and the below-average action recognition performance compared to the state-of-the-art on the UCF dataset. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the problem areas, such as the artifacts and the performance gap, but lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the state-of-the-art on the UCF dataset. However, the comment does not provide any supporting evidence, examples, or references to substantiate these claims. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the generated videos, noting that they have significant artifacts and that only some of the beach videos are convincing. It also points out that the action recognition performance is below the state-of-the-art on the UCF dataset, which uses more complex architectures. However, the comment lacks actionable feedback or suggestions on how to address these issues or improve the performance. While it highlights a critical area for improvement, the lack of specific guidance or recommendations limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some insight into areas needing attention but does not fully support the authors in enhancing their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how to make the new proposed evaluation set more diverse and representative than the previous method, and it questions how to select representative images. While the comment identifies a specific area of improvement, it does not provide explicit guidance or suggestions on how to achieve this diversity or representativeness. The authors are left to infer that they need to find ways to enhance the diversity and representativeness of the evaluation set, but the comment lacks concrete steps or examples to follow. Therefore, the comment is somewhat actionable, as it points out a specific area for improvement but does not offer detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of making the new proposed evaluation set more diverse and representative than the previous method, but it does not specify which part of the paper this evaluation set is discussed in. The authors can infer that it relates to the evaluation section, but this inference is not explicit. The comment is specific in questioning how to select representative images, but it lacks grounding as it does not mention a specific section or part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the diversity and representativeness of the new proposed evaluation set compared to the previous method, but it does not provide any specific evidence, reasoning, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the proposed evaluation set, questioning its diversity and representativeness compared to the previous method. It highlights a lack of clarity on how to select representative images, which is a critical aspect of evaluating the proposed method. However, the comment does not provide any suggestions or guidance on how to address this issue, such as recommending specific criteria for diversity or representative selection. While it points out a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it directs the authors' attention to an important area for improvement but does not offer detailed guidance on how to achieve it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to include a background section on the RL framework, specifically mentioning the need to introduce elements such as the MDP, trajectories, and policy. This action is clear and direct, providing the authors with a specific task to improve their draft. Additionally, the comment suggests including a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This further guidance on what needs to be included makes the feedback highly actionable. The authors know exactly what changes are needed to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for a \"background section\" to introduce the RL framework and the \"methods section\" to clarify the modifications proposed. This provides clear guidance on where these additions should be made, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details what needs to be included in the background section, such as the MDP, trajectories, and policy, and suggests providing a brief overview of the original DPO algorithm to distinguish the proposed modifications. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a background section to introduce the RL framework and provide a brief overview of the original DPO algorithm. This is a logical suggestion to clarify the context and make the paper more accessible. However, the comment does not provide specific examples or references to support the need for these additions, making it somewhat verifiable. The authors would need to infer the importance of these suggestions based on the reviewer\\'s reasoning, which is somewhat vague. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by suggesting that the authors include a background section to introduce the RL framework, specifically mentioning elements like the MDP, trajectories, and policy. This is crucial for clarifying the context and making the paper more accessible to readers. Additionally, the comment recommends providing a brief overview of the original DPO algorithm, which would help distinguish the proposed modifications in the methods section. These suggestions are specific and would significantly enhance the clarity and comprehensiveness of the paper. However, the comment could be more helpful if it offered additional guidance on how to structure the background section or provided examples of how to present the information. Overall, the feedback is mostly helpful as it directs the authors to improve the clarity of their work, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method, specifically that it may encounter issues if users continuously add new languages due to limited model capacity. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or suggestions for potential solutions. Without actionable steps or suggestions, the authors are left without a clear understanding of what changes or improvements are needed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a potential limitation of the proposed method, specifically the limited model capacity when users continuously add new languages. However, it does not specify which part of the paper discusses the method or the model capacity, making it weakly grounded. The comment is specific in identifying the issue of limited capacity and its potential impact on the method, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method may encounter a limitation if users continuously add new languages due to limited model capacity. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically the limited model capacity when users continuously add new languages. This is a valid concern that the authors should consider, as it could impact the scalability and applicability of their method. However, the comment lacks actionable suggestions or guidance on how the authors might address this limitation or improve the method's scalability. Without specific recommendations or examples, the feedback is somewhat helpful as it points out an area for potential improvement but does not provide detailed guidance for the authors to enhance their draft. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to clarify the connection between the term and the referenced work. As a result, the authors are left without a clear understanding of what action to take in response to this comment. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it relates to the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this question or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim. While it identifies a potential area for clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the work need further explanation. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it highlights an area of potential concern but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a similarity between the proposed method and another approach, suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It questions why [10] cannot use these side information. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their method. The action is implicit and vague, as the authors are left to infer that they should explore the possibility of incorporating these features into their method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions a specific reference, [10], which suggests a comparison with another approach. However, it does not specify which part of the paper this comparison is relevant to, making it weakly grounded. The comment is specific in questioning why the method in [10] cannot use certain side information, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is similar in spirit to another approach, suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. However, the comment lacks specific reasoning or evidence to support why this is the case, such as detailed comparisons or examples. The claim is somewhat verifiable as it points out a potential similarity but does not provide enough detail to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment highlights a similarity between the proposed method and another approach, suggesting that the method in [10] could also be equipped with scoring causal predictions and interventional data. It questions why [10] cannot use these side information, implying that the authors should consider this aspect in their work. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their method. While it identifies a potential area for enhancement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the Atari game results, noting that they are limited to a single game and a single baseline. It suggests that this makes it difficult to interpret the results. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to expand the results, analyze them differently, or provide additional context. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 7.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the Atari game results are limited to a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the Atari game results, noting that they are limited to a single game and a single baseline, making it difficult to interpret. While it points out a specific area for improvement, the comment lacks actionable suggestions or guidance on how the authors might address this issue or expand their analysis. Without additional context or specific recommendations, the authors are left without a clear path to improve their draft. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not provide detailed feedback or actionable steps for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the evaluation needs experiments on distributed deployment and a larger model. This provides a clear and direct action for the authors to take, as it specifies what additional experiments are required to improve the evaluation. The comment is explicit and concrete, giving the authors a clear path forward in addressing the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in its suggestion to include additional experiments, but without grounding, the authors may struggle to identify the exact sections that need to be addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any reasoning, examples, or references to support why these experiments are necessary or how they would improve the evaluation. Without such justification, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the evaluation section, suggesting that experiments on distributed deployment and a larger model are needed. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work. By addressing these suggestions, the authors can strengthen their evaluation and potentially improve the robustness and generalizability of their findings. However, the comment could be more helpful if it included specific guidance on how to conduct these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the authors\\' claim of achieving superior performance with significantly fewer parameters. It suggests that the authors in [1] might have tested their model with standard parameter settings, implying that the current claim may not be fully substantiated. The reviewer asks for improvements when the proposed model uses larger word embeddings and LSTM parameters, which provides a clear and concrete action for the authors to take. This feedback is explicit and actionable, as it guides the authors on how to strengthen their claim by demonstrating improvements with larger parameter sizes. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding their model\\'s performance and parameter efficiency. It questions the validity of the claim by suggesting that the authors in [1] might have tested their model with standard parameter settings. The reviewer asks for improvements when the proposed model uses larger word embeddings and LSTM parameters, which provides a clear and specific direction for the authors to address. This feedback is fully grounded as it references a specific claim and suggests a concrete action for improvement. Therefore, the comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the authors\\' claim of achieving superior performance with significantly fewer parameters, questioning whether this is due to the use of smaller word embedding and LSTM sizes. The reviewer suggests that the authors in [1] might have tested their model with standard parameter settings, implying that the current claim may not be fully substantiated. The comment requests improvements when the proposed model uses larger word embeddings and LSTM parameters, which provides a clear and specific action for the authors to take. However, the comment lacks direct evidence or references to support the claim that the authors in [1] tested with standard parameter settings, making it somewhat verifiable. The authors would need to provide additional context or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the authors' claim of achieving superior performance with significantly fewer parameters, questioning whether this is due to the use of smaller word embedding and LSTM sizes. It suggests that the authors in [1] might have tested their model with standard parameter settings, implying that the current claim may not be fully substantiated. The reviewer provides a clear and actionable suggestion by asking for improvements when the proposed model uses larger word embeddings and LSTM parameters. This feedback is highly helpful as it directs the authors to conduct additional experiments to strengthen their claim, offering a clear path for improvement. Therefore, the comment is rated as highly helpful.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. While the comment identifies a potential issue with the hyperparameters, it does not provide explicit guidance on how to address this problem or suggest specific actions to take. The authors are left to infer that they need to find a way to finetune these parameters, but the comment lacks concrete details or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks specific guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or how they are introduced. The authors can infer that this issue is related to the experimental setup or methodology, but the comment lacks explicit grounding. It is specific in identifying the need for finetuning and the potential dependence on the environment or OPE methods, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependence of this process on the availability of the environment or a good OPE method, which is a relevant observation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. While it points out a potential area for improvement, it does not provide actionable steps or detailed feedback that could help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it provides a general direction but lacks depth and specificity.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. However, it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The comment identifies a potential problem but lacks actionable details, making it somewhat actionable. The authors are left to infer that they need to find a way to finetune these parameters, but the comment does not offer concrete steps or suggestions on how to do so. Therefore, the comment is rated as somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need to finetune the extra two hyperparameters introduced by k and \u03b7, which depends on the availability of the environment or a good OPE method. However, it does not specify which part of the paper discusses these hyperparameters or how they are introduced, making it weakly grounded. The comment is specific in identifying the need for finetuning and the potential dependence on the environment or OPE methods, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the introduction of two hyperparameters, k and \u03b7, requires finetuning, which depends on the availability of the environment or a good OPE method. However, the comment lacks supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the introduction of two hyperparameters, k and \u03b7, which require finetuning. It highlights the dependence of this process on the availability of the environment or a good OPE method, which is a relevant observation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their approach. While it points out a potential area for improvement, it does not provide actionable steps or detailed feedback that could help the"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. However, the comment does not provide specific guidance on how to reproduce these features or what aspects of the previous models need to be replicated. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization approach used in the LN models and compares it to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. However, the comment does not specify which part of the paper discusses the regularization or the LN models, making it weakly grounded. The suggestion to reproduce the main features of previous models is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the regularization approach applied to the LN models, noting that it differs from previous models. It suggests that the authors should try to reproduce the main features of previous models to make the comparison fair. However, the comment lacks specific examples or references to the previous models, such as Pillow et al., which would provide more context and substantiate the claim. Without detailed references or examples, the authors may find it challenging to understand the exact nature of the discrepancy and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. This feedback is somewhat helpful as it points out a potential inconsistency in the methodology and encourages the authors to ensure a fair comparison. However, the comment lacks specific guidance on how to reproduce the main features of the previous models, leaving the authors with a general direction but no detailed steps to follow. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but could be more comprehensive.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. However, the comment does not provide specific guidance on how to reproduce these features or what aspects of the previous models need to be replicated. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization approach applied to the LN models and compares it to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. However, the comment does not specify which part of the paper discusses the regularization or the LN models, making it weakly grounded. The suggestion to reproduce the main features of previous models is specific, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the regularization approach applied to the LN models, noting that it differs from previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main features of these previous models to make the comparison fair. However, the comment lacks specific examples or references to the previous models, which would provide more context and substantiate the claim. Without detailed references or examples, the authors may find it challenging to understand the exact nature of the discrepancy and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a discrepancy in the regularization approach applied to the LN models compared to previous models, such as those by Pillow et al. It suggests that the authors should try to reproduce the main"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous top-down and bottom-up pose estimation methods. While the action is explicit, it does not provide specific guidance on how to conduct the comparison or what aspects of inference time should be considered. The authors are aware of the need to include this comparison but may need to infer the details of how to implement it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous top-down and bottom-up pose estimation methods. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information could be included. The authors can infer that it relates to the methodology or results section, but the lack of explicit grounding makes it difficult to pinpoint. The comment is specific in its suggestion to include a study of inference time, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous top-down and bottom-up pose estimation methods. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. The suggestion is based on a general observation about the relevance of inference time in the field, but without detailed justification or examples, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous top-down and bottom-up pose estimation methods. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct the comparison or what aspects of inference time should be considered. The authors are aware of the need to include this comparison but may need to infer the details of how to implement it. Therefore, the comment is somewhat helpful, as it points out a relevant area for enhancement but does not provide detailed actionable feedback.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous top-down and bottom-up pose estimation methods. While the action is explicit, it does not provide specific guidance on how to conduct the comparison or what aspects of inference time should be considered. The authors are aware of the need to include this comparison but may need to infer the details of how to implement it. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous top-down and bottom-up pose estimation methods. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or table where this information could be included. The authors can infer that it relates to the methodology or results section, but the lack of explicit grounding makes it difficult to pinpoint. The comment is specific in its suggestion to include a study of inference time, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a study of inference time for their pose estimation method, which is direct and does not require detection or keypoint grouping. It implies that this comparison is valuable and should be made to previous top-down and bottom-up pose estimation methods. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. The suggestion is based on a general observation about the relevance of inference time in the field, but without detailed justification or examples, it remains somewhat verifiable. Therefore"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim regarding evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these limitations explicitly. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It also points out that Batch Normalization standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion of evolutional dropout, but this inference is not direct. The comment is specific in detailing the limitations of the claim and suggesting a discussion, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the limitations of evolutional dropout in addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation. The comment implies that these limitations should be discussed explicitly. However, the claim lacks specific examples or references to support the comparison between evolutional dropout and Batch Normalization, making it difficult for the authors to fully understand and address the critique. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific claim about evolutional dropout addressing internal covariate shift and points out its limitations, particularly in only increasing the variance of low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation, suggesting that these limitations should be discussed explicitly. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper's discussion of evolutional dropout. However, it could be more helpful if it provided specific suggestions on how to discuss these limitations or what aspects should be emphasized. Overall, the comment offers a clear direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a specific claim about evolutional dropout addressing internal covariate shift and points out its limitations, suggesting that it only increases the variance of low-variance units. It also contrasts this with Batch Normalization, which standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. While the comment highlights a potential area for improvement, it does not provide explicit guidance on how to address these limitations or what specific aspects should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should discuss these limitations explicitly. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific claim about evolutional dropout addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion of evolutional dropout, but this inference is not direct. The comment is specific in detailing the limitations of the claim and suggesting a discussion, but without explicit grounding, it is challenging for the authors to pinpoint the exact section needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a claim about the limitations of evolutional dropout in addressing internal covariate shift, suggesting that it only increases the variance of low-variance units. It contrasts this with Batch Normalization, which standardizes the variance and centers the activation, implying that these limitations should be discussed explicitly. However, the comment lacks specific examples or references to support the comparison between evolutional dropout and Batch Normalization, making it difficult for the authors to fully understand and address the critique. The claim is somewhat verifiable as it provides a logical comparison but lacks detailed evidence"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to include the tentative attention maps in the qualitative figures, in addition to the retrieved and final attention maps. While the comment implies that the authors should consider including these maps, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need to include the tentative attention maps, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including tentative attention maps in the qualitative figures, which is a specific suggestion for improvement. However, it does not specify which figures or sections of the paper should include these maps, making it weakly grounded. The authors can infer that the suggestion pertains to the qualitative figures, but without explicit references, it remains challenging to pinpoint the exact parts of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that it would be interesting to include tentative attention maps in the qualitative figures, but it does not provide any justification or reasoning for why this would be beneficial or necessary. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that it would be beneficial to include tentative attention maps in the qualitative figures, in addition to the retrieved and final attention maps. This feedback is specific and actionable, as it provides a clear direction for enhancing the qualitative figures to better illustrate the attention mechanisms used in the study. By including tentative attention maps, the authors could offer a more comprehensive understanding of the attention process. However, the comment could be more helpful if it provided additional context or examples of how these maps could be integrated into the figures. Overall, the comment is mostly helpful as it guides the authors towards a specific improvement that could enhance the clarity and depth of their presentation.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the author should add more description about the contribution of the paper. However, it does not provide specific guidance on what aspects of the contribution should be described or how to enhance the description. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details about the contribution without being given concrete steps to follow. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the author should add more description about the contribution of the paper, but it does not specify which part of the paper this contribution is discussed in or what aspects of the contribution need more description. This lack of specificity makes it difficult for the authors to identify the exact sections that need revision. The comment is not grounded because it does not provide any explicit references to specific parts of the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the author should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the author should provide more description about the contribution of the paper. While this feedback acknowledges the need for additional explanation, it lacks specificity and does not offer guidance on what aspects of the contribution should be described or how to enhance the description. Without detailed suggestions or examples, the authors may find it challenging to address the feedback effectively. Therefore, the comment is barely helpful, as it identifies a need for improvement but does not provide actionable guidance.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of supervised baselines in the experiments, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images. It further recommends including a supervised baseline to provide a comparison with self-supervised methods. While the comment implies that the authors should include a supervised baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a supervised baseline. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the absence of supervised baselines in the experiments, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images. It provides a rationale for including a supervised baseline, which is a concrete suggestion for improvement. However, the comment does not specify which part of the paper this issue is related to, such as the experimental section or specific results. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Despite this, the comment is specific in its suggestion to include a supervised baseline for comparison. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the absence of supervised baselines in the experiments is a significant oversight, given the scale of the datasets used (~100k images). It provides a logical reasoning by assuming that full annotation is available for such datasets in practice, even if it is not always the case. This reasoning is supported by common knowledge about the feasibility of full annotation for large datasets. However, the comment could be strengthened by providing specific examples or references to similar studies that have included supervised baselines for comparison. Overall, the claim is mostly verifiable due to the logical reasoning and common knowledge provided, but it could be further strengthened with additional evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a logical rationale for including such baselines, suggesting that it is reasonable to assume full annotation for a dataset of scale ~100k images in practice. The comment further emphasizes the importance of including a supervised baseline to provide a comprehensive comparison with self-supervised methods. This feedback is clear and actionable, as it guides the authors on how to improve their draft by adding a critical component to their experimental setup. However, the comment could be more helpful if it suggested specific ways to integrate the supervised baseline or discussed the potential impact of including it. Overall, the comment is mostly helpful, as it effectively directs the authors towards a meaningful enhancement of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a concern about the minimal performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It also references a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly instruct the authors to address these issues or suggest specific actions to improve their work. The mention of the reference provides a potential direction for improvement, but the lack of explicit guidance makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the performance differences between methods and suggests that the benchmarks are outdated and likely saturated. It also references a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which provides a potential solution. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results section or discussion, but this inference is not precise. The comment is specific in detailing the issue with the performance differences and suggesting a potential solution, making it specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the performance differences between methods are minimal and suggests that the benchmarks are outdated and likely saturated. The comment provides a logical reasoning by stating that the performance differences are less than 1 percentage point, which may be attributable to random variation. Additionally, it references a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which could provide a potential solution. However, the comment lacks specific examples or detailed references to support the claim about the outdated benchmarks, making it somewhat verifiable. The addition of the reference provides some support, but the lack of detailed evidence or examples makes the claim somewhat verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the performance differences between methods, noting that they are minimal across evaluations, often less than 1 percentage point. It also points out that the benchmarks used may be outdated and likely saturated, suggesting that the results may be influenced by random variation. The comment provides a potential solution by referencing a specific paper, [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673), which could offer a way to address these issues. However, the comment could be more helpful if it provided specific guidance on how to incorporate the suggested solution or if it offered additional insights into how to improve the evaluation methodology. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a potential direction for addressing the issue, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it asks why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with non-deterministic dynamics to assess its empirical efficacy. Second, it questions why BEAR is missing from the baselines. While the comment identifies areas for improvement and suggests additional evaluations, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer that they should consider evaluating the method on non-deterministic domains and include BEAR in the baselines. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions: first, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with non-deterministic dynamics to assess its empirical efficacy. Second, it asks why BEAR is missing from the baselines. While the comment does not explicitly mention specific parts of the paper, it is clear that it pertains to the discussion or results section where the method's performance is evaluated. The authors can infer that it relates to the experimental setup and results, but the comment does not specify which sections or figures are being addressed. Therefore, the comment is weakly grounded as it does not provide explicit references to specific parts of the paper, but it is specific in its questions about the method\\'s applicability and the inclusion of BEAR in the baselines. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: first, it questions why the method is beneficial on Hopper, which has deterministic dynamics, and whether it can be evaluated on domains with non-deterministic dynamics to assess its empirical efficacy. Second, it asks why BEAR is missing from the baselines. The comment does not provide any supporting evidence, reasoning, or references to justify these questions or claims. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two important questions that could help the authors improve their draft. First, it questions the relevance of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. This feedback encourages the authors to broaden their experimental setup and consider a more comprehensive evaluation. Second, it points out the absence of BEAR in the baselines, which could be a significant oversight that affects the comprehensiveness of the comparison. By addressing these points, the authors can enhance the robustness and relevance of their work. However, the comment could be more helpful if it provided specific suggestions on how to evaluate the method on non-deterministic domains or why BEAR should be included in the baselines. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a theoretical justification for why co-training and weight averaging improve results. While the comment implies that these techniques are important for performance, it does not explicitly instruct the authors to include this justification. The action is implicit and somewhat vague, as the authors need to infer that they should provide a theoretical explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a theoretical justification for why co-training and weight averaging improve results. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in its request for a theoretical justification, but without grounding, it is challenging for the authors to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a theoretical justification for why co-training and weight averaging improve results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed evidence or logical reasoning to substantiate the need for a theoretical justification. As a result, the claim is not verifiable, as it does not offer sufficient support or guidance for the authors to understand or address the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide a theoretical justification for why co-training and weight averaging improve results. This feedback is somewhat helpful as it identifies a gap in the paper's theoretical foundation, which could be addressed to enhance the paper\\'s comprehensiveness and credibility. However, the comment lacks specific guidance on how to develop this justification or what aspects of the theory should be emphasized. To be more helpful, the comment could include examples or references to similar works that have successfully justified the use of co-training and weight averaging. Overall, the feedback provides a direction for improvement but could be more detailed and actionable.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their work. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, it does not specify which part of the paper this critique pertains to, such as a specific section or equation. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. The comment is specific in its critique of the derivation\\'s reliance on classical learning theory-based bounds, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the authors\\' derivation, stating that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. This feedback highlights a potential limitation in the authors\\' approach and suggests that incorporating Bayesian considerations could improve the validity of the bounds. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate Bayesian considerations into their work. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more details about the proposed method, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. While the comment implies that these details should be included, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that more information is needed, but it lacks concrete guidance on how to present this information. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in its request for additional information about the method, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these details are necessary or how they would improve the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, suggesting that more details about the proposed method should be presented. It specifies that the authors should provide information on how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. This feedback is clear and actionable, as it directs the authors to enhance their explanation of the method, which could significantly improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided examples or specific suggestions on how to present this information. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential issue with the proposed method's ability to detect hallucinations in open-ended responses, such as the example of introducing a sports celebrity. It suggests that the sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. While the comment identifies a potential weakness, it does not provide explicit guidance on how the authors might address this issue or improve their method. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses a potential issue with the proposed method's ability to detect hallucinations in open-ended responses, specifically mentioning the example of introducing a sports celebrity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the challenge of identifying shared information for consistency checking in open-ended responses. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method might struggle to detect hallucinations in open-ended responses, such as the example of introducing a sports celebrity. The comment provides a specific example to illustrate the challenge, which helps to ground the claim. However, it lacks detailed reasoning or references to support why this might be a significant issue or how it could be addressed. The claim is somewhat verifiable as it provides a clear example but lacks comprehensive justification, making it a 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the proposed method, specifically its ability to detect hallucinations in open-ended responses. It provides a specific example, 'introduce a sports celebrity to me', to illustrate the challenge of identifying shared information for consistency checking. This feedback is somewhat helpful as it highlights a critical area for improvement, but it could be more helpful if it offered suggestions on how the authors might address this issue or enhance their method's capabilities. Overall, the comment provides a clear direction for the authors to consider, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors verify the conclusion about the label noise and model size on MNIST and CNN. This is an explicit action that provides a clear direction for the authors to take. It specifies what needs to be verified and which datasets and models to use, making the action concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of theoretical findings relating to real-world deep learning models, suggesting that the authors verify their conclusions on MNIST and CNN. However, it does not specify which part of the paper this relates to, making it weakly grounded. The comment is specific in suggesting a verification on MNIST and CNN, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the theoretical findings should be verified on real-world deep learning models, specifically mentioning MNIST and CNN. However, the comment does not provide any specific reasoning or evidence to support why these models are relevant or why the verification is necessary. The claim lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the relevance of theoretical findings to real-world deep learning models. It suggests that the authors verify their conclusions about label noise and model size on MNIST and CNN, which are common benchmarks in the field. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the applicability of their findings. However, the comment could be more helpful if it offered additional guidance on how to conduct the verification or what specific aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific requirement for the choice of p(y|Hf\\u2010(tn)) being Gaussian, as it is necessary for the application of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is made later in the ELBOs. While the comment identifies a necessary condition for the model, it does not provide explicit guidance on how the authors should address this issue or where in the paper this assumption is made. The action is implicit and somewhat vague, as the authors need to infer that they should ensure the Gaussian assumption is made and verify where this assumption is applied. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p(y|Hf\\u2010(tn))\" and \"ELBOs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the choice of p(y|Hf\\u2010(tn)) being Gaussian is necessary for the application of Kalman Filtering and Smoothing and CVI, and that this assumption is made later in the ELBOs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that p(y|Hf\\u2010(tn)) must be chosen Gaussian for the application of Kalman Filtering and Smoothing and CVI, and that this assumption is made later in the ELBOs. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical requirement for the choice of p(y|Hf\\u2010(tn)) being Gaussian, as it is necessary for the application of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is made later in the ELBOs, providing a clear and actionable suggestion for the authors to ensure this assumption is properly addressed in their work. However, the comment could be more helpful if it offered additional guidance on how to implement this requirement or where exactly in the paper this assumption is made. Overall, the comment is mostly helpful as it directs the authors to a specific area that needs attention, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of weight decay, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their results. The comment lacks concrete suggestions or actions for the authors to take, making it unactionable. The authors are left without a clear understanding of how to address the identified problem, leaving them without a path forward for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with weight decay and the observation that cosine similarities for large weight decay strengths are not reported. However, it lacks explicit references to specific sections or figures, which could help the authors pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the application of weight decay to all layers might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, the comment lacks specific evidence, examples, or references to support this claim. The reviewer mentions that cosine similarities for large weight decay strengths are not reported, but this observation does not provide a logical or empirical basis for the claim. Without further justification or evidence, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. The comment points out that cosine similarities for such large weight decay strengths are not reported, and the plots end at a weight decay strength where cosine similarities are still close to optimal. This feedback is somewhat helpful as it highlights a specific area where the authors might need to investigate further or provide additional analysis. However, the comment lacks detailed guidance on how the authors should address this issue or what specific steps they should take to improve their results. While it provides a starting point for the authors to consider, it does not fully support them in making actionable improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a potential issue with the application of weight decay, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve their results. The comment lacks concrete suggestions or actions for the authors to take, making it unactionable. The authors are left without a clear understanding of how to address the identified problem, leaving them without a path forward for improvement.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the application of weight decay in the model, suggesting that it might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential problem with weight decay and the observation that cosine similarities for large weight decay strengths are not reported. However, it lacks explicit references to specific sections or figures, which could help the authors pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the application of weight decay to all layers might lead to a large training loss and suboptimal cosine similarities for large weight decay parameters. However, the comment lacks specific evidence, examples, or references to support this claim. The reviewer mentions that cosine similarities for large weight decay strengths are not reported, but this observation does not provide a logical or empirical basis for the claim. Without further justification or evidence, the claim remains unverifiable, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the application of weight decay"}
{"generated_text": "{'actionability_rationale': 'The review point provides explicit and concrete actions for the authors to take. It suggests that qualitative experiments should be conducted to demonstrate the validity of the conditional independence model, specifically recommending the use of illustrative experimental results to show the superiority of minimizing HSICcond-i over minimizing HSIC_HOOD. Additionally, it suggests providing visualization results or schematic diagrams to enhance the understanding of the new test metric. These actions are clear and provide specific guidance on how the authors can improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lack of qualitative experiments\" and provides specific suggestions for improvement, such as providing illustrative experimental results and visualization results or schematic diagrams. This allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results and visualization to support the claim. However, the comment lacks specific examples or references to support the claim that the current approach is insufficient. While the suggestion for illustrative results is a logical step, the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides actionable suggestions for improvement, such as recommending the use of illustrative experimental results to show the superiority of minimizing HSICcond-i over minimizing HSIC_HOOD. Additionally, it highlights the need for a correctness test and comparative experiments with other metrics, suggesting the inclusion of visualization results or schematic diagrams to enhance understanding. These specific and detailed suggestions empower the authors to address key weaknesses and improve the comprehensiveness and impact of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a specific analysis that could be conducted to improve the paper, namely studying the impact of the cost of incentivization on performance. It provides a detailed example of what this analysis could involve, such as examining the reward incentives for each agent and the collective return for different values of \\alpha. While the comment does not explicitly instruct the authors to perform this analysis, it provides a clear and concrete suggestion on how to enhance the paper. The authors can infer the action needed to improve their draft by following the detailed guidance provided. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests a specific analysis that could be conducted to improve the paper, focusing on the impact of the cost of incentivization on performance. It provides a detailed example of what this analysis could involve, such as examining the reward incentives for each agent and the collective return for different values of \\alpha. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, providing clear guidance on how to enhance the paper. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a specific analysis that could be conducted to improve the paper, focusing on the impact of the cost of incentivization on performance. It provides a detailed example of what this analysis could involve, such as examining the reward incentives for each agent and the collective return for different values of \\alpha. The comment also offers a rationale for why this analysis might be beneficial, suggesting that it could help clarify the emergence of roles between \"winners\" and \"cooperators.\" However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the relevance of this suggestion based on the provided reasoning, which is somewhat limited. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests a specific analysis that could be conducted to enhance the paper, focusing on the impact of the cost of incentivization on performance. It provides a detailed example of what this analysis could involve, such as examining the reward incentives for each agent and the collective return for different values of \\alpha. This suggestion is clear and actionable, offering the authors a concrete direction for improving their draft. By addressing this suggestion, the authors could significantly enhance the depth and comprehensiveness of their analysis. However, the comment could be more helpful if it included specific references or examples to further support the proposed analysis. Overall, the comment is mostly helpful, as it provides valuable guidance for improving the paper.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the approach description in Section 3 is difficult to follow and should be revised. It also suggests that the additional page in the camera-ready version should be used to extend the approach description rather than adding more experiments. This provides clear and concrete guidance on what needs to be done to improve the draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the approach description is difficult to follow and suggests using the additional page in the camera-ready version to extend the approach description rather than adding more experiments. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach description is difficult to follow and suggests that the additional page in the camera-ready version should be used to extend the approach description rather than adding more experiments. However, the comment does not provide specific examples or detailed reasoning to support why the approach description is difficult to follow or how extending the description would improve it. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the approach description in Section 3, noting that it is difficult to follow. It provides a clear and actionable suggestion by recommending that the additional page in the camera-ready version be used to extend the approach description rather than adding more experiments. This feedback is valuable as it directs the authors to improve the clarity and depth of their approach description, which is crucial for readers to understand the methodology. However, the comment could be more helpful if it provided specific suggestions on how to revise the approach description or examples of what additional information could be included. Overall, the comment is mostly helpful as it offers clear guidance for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific issues with the experimental section: the lack of interpretive insights into why the proposed gyro-structures outperform existing methods, and the absence of comparison with other state-of-the-art methods that might not rely on gyro-structures. While the comment highlights these areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to provide more interpretive insights and compare their methods with a broader range of state-of-the-art techniques. However, the lack of concrete suggestions or examples makes the action implicit and vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issues with the related discussion, such as the lack of interpretive insights into why the proposed gyro-structures outperform existing methods and the absence of comparison with other state-of-the-art methods. Additionally, it highlights the need for comparison with simpler or more commonly used techniques in manifold-based learning. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related discussion lacks interpretive insights into why the proposed gyro-structures outperform existing methods. It also points out the absence of comparison with other state-of-the-art methods that might not rely on gyro-structures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifold-based learning. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claims. The authors are left to infer the need for more detailed explanations and comparisons, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas for improvement in the experimental section of the paper. It points out the lack of interpretive insights into why the proposed gyro-structures outperform existing methods, suggesting that more detailed explanations are needed. Additionally, it highlights the absence of comparison with other state-of-the-art methods that might not rely on gyro-structures, questioning the paper's claim of outperforming simpler or more commonly used techniques in manifold-based learning. This feedback is clear and actionable, providing the authors with specific areas to address and improve upon. By addressing these points, the authors can enhance the clarity and robustness of their experimental results. Therefore, the comment is rated as highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. While the comment implies that additional evidence or analysis should be provided, it does not explicitly instruct the authors to do so. The action is somewhat implicit, as the authors can infer that they need to include more supporting evidence, but it lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for additional evidence and analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these additions. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, the comment does not provide specific examples, references, or detailed reasoning to justify why this is necessary or how it would enhance the paper. Without additional context or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that more evidence or analysis is needed to support the training effectiveness property of the dataset and other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their paper by including additional supporting evidence or analysis. However, the comment could be more helpful if it offered suggestions on how to gather or present this evidence, such as which specific aspects to focus on or where to find relevant data. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\\'s performance, suggesting that the fine-tuning without early-stopping may lead to high variances. It implies that proper ablation studies are needed to verify the distillation effect. While the comment highlights a potential issue, it does not explicitly instruct the authors to conduct ablation studies or provide specific guidance on how to perform them. The action is implicit and somewhat vague, as the authors need to infer that they should conduct ablation studies to address the concern. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the potential regularization effects influencing the improvements observed in the teacher\\'s performance. It explicitly mentions the case where the student distills knowledge to the teacher, which is a clear reference to a specific part of the paper. The comment is specific in detailing the concern about the potential regularization effects and suggests the need for proper ablation studies to verify the distillation effect. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the potential regularization effects influencing the improvements observed in the teacher\\'s performance, suggesting that the fine-tuning without early-stopping may lead to high variances. The reviewer provides a logical reasoning by pointing out that the fine-tuning on GLUE without validation early-stopping usually has very high variances. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct further analysis or experiments to fully address the concern, which is why the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's claim that the improvements in the teacher's performance are due to distillation rather than regularization effects. It points out that the fine-tuning without early-stopping could lead to high variances, suggesting that proper ablation studies are needed to verify the distillation effect. This feedback is clear and actionable, as it directs the authors to conduct additional experiments to substantiate their claims. However, the comment could be more helpful if it provided specific guidance on how to design and execute these ablation studies. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides two specific actions for the authors to consider. The first action suggests adding performance metrics on word similarity and sentence translation tasks, as seen in the MUSE paper and others, to enhance the credibility of the framework\\'s robustness and effectiveness. The second action recommends including experiments with morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, which is a minor suggestion. Both actions are explicit and provide clear guidance on what the authors should include in their experiments to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides two clear actions for the authors to consider: adding performance on word similarity and sentence translation tasks, as in the MUSE paper, and including experiments with morphologically rich languages like Finnish and Hebrew, as well as low-resource languages. This provides detailed guidance on how to enhance the robustness and effectiveness of the framework. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding performance metrics on word similarity and sentence translation tasks, as well as experiments with morphologically rich and low-resource languages, to enhance the credibility of the framework. The reviewer provides specific examples of similar tasks and languages that could be included, which provides some level of justification for the claim. However, the comment could be strengthened by providing more detailed reasoning or references to support the importance of these additions. Therefore, the comment is mostly verifiable, as it offers a logical basis for the suggestions but lacks comprehensive evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment provides two specific and actionable suggestions for enhancing the credibility and robustness of the framework. First, it recommends adding performance metrics on word similarity and sentence translation tasks, similar to the MUSE paper and others, which would provide a more comprehensive evaluation of the framework's effectiveness. Second, it suggests including experiments with morphologically rich languages like Finnish and Hebrew, as well as low-resource languages, which could further validate the framework's applicability across diverse linguistic contexts. These suggestions are clear and provide the authors with concrete steps to improve their draft, making the comment highly helpful. Therefore, the comment aligns with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions. The first question asks about the utility of node importance in the 1-shot scenario, which implies that the authors should clarify or explain how this concept is applied in that context. The second question points out the absence of a 1-shot setting in the experiments, suggesting that the authors should include this setting or discuss why it is not included. While the questions provide some guidance, they are not explicit in their actions, and the authors may need to infer the necessary steps to address them. The feedback is somewhat actionable as it identifies specific areas for clarification or inclusion, but it lacks concrete details on how to implement these suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two specific questions about the paper. The first question addresses the utility of node importance in the 1-shot scenario, which is a direct reference to a particular aspect of the paper. The second question points out the absence of a 1-shot setting in the experiments, again referencing a specific part of the paper. This provides full grounding as the authors can accurately identify the parts being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of explaining the utility of node importance in the 1-shot scenario and the inclusion of the 1-shot setting in the experiments. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two questions that seek clarification on the utility of node importance in the 1-shot scenario and the absence of a 1-shot setting in the experiments. These questions are factual in nature and do not express opinions, judgments, or suggestions that require verification. Therefore, they are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions that are relevant to the paper\\'s methodology and experimental setup. The first question asks about the utility of node importance in the 1-shot scenario, which is a critical aspect of the paper\\'s approach. The second question points out the absence of a 1-shot setting in the experiments, noting that related works like RALE do include this setting. These questions provide valuable feedback for the authors to consider, as they highlight areas where the paper could be improved or clarified. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks depth and actionable guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more discussions on why large language models (LLMs) struggle with fine-grained hard constraints and how to address these issues. While the comment implies that additional discussions are needed, it does not specify which sections of the paper should include these discussions or how they should be structured. The action is implicit and somewhat vague, as the authors need to infer that they should add more detailed explanations and potential solutions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that there should be more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this discussion should be included in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to address the issue of LLMs struggling with fine-grained hard constraints, but it lacks grounding as it does not reference specific sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that there should be more discussions about why large language models (LLMs) struggle with fine-grained hard constraints and how to address these problems. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide more discussions on why large language models (LLMs) struggle with fine-grained hard constraints and how to address these problems. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by offering additional context and potential solutions. However, the comment lacks depth and does not provide specific suggestions or examples of how to address the issue, which limits its usefulness for the authors. Therefore, the comment is rated as somewhat helpful, as it points out a potential area for improvement but does not fully guide the authors in making those improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of self-supervised learning on 360 video data with spatial audio. It implies that the authors should provide more insights into why this approach is valuable. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on what kind of insights are needed. The action is implicit and somewhat vague, as the authors can infer that more explanation is required but are not given concrete steps on how to address this. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results and questions the necessity of self-supervised learning on 360 video data with spatial audio. However, it does not specify which part of the paper this critique pertains to, making it weakly grounded. The comment is specific in questioning the need for self-supervised learning on this type of data, but without grounding, the authors may struggle to identify the exact section where this issue is discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of self-supervised learning on 360 video data with spatial audio, suggesting that more insights are needed. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is valuable or why more insights are required. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand and address the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of explanation regarding the necessity of self-supervised learning on 360 video data with spatial audio. It questions why this approach is valuable and suggests that more insights are needed. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what kind of insights are required. While it identifies a gap in the paper, it lacks actionable feedback, making it somewhat helpful. The authors are given a direction to consider but are not provided with detailed steps or examples to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and direct action for the authors to take, as it provides a specific step to improve the robustness and reliability of their results. The comment is explicit and concrete, giving the authors a clear path forward in addressing the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this recommendation pertains to, such as a specific section or result section. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to average results over multiple runs, but without grounding, it is weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This is a logical and reasonable suggestion, as it aligns with common practices in statistical analysis to ensure the reliability of results. However, the comment does not provide specific examples or references to support the claim, which could make it more robust. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it provides a general suggestion but without extensive justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the robustness and reliability of the results by recommending that they be averaged over multiple runs to determine statistical significance. This feedback is specific and directly addresses a potential weakness in the current analysis, offering a straightforward way for the authors to enhance the quality and validity of their findings. By following this advice, the authors can strengthen their paper and provide a more robust basis for their conclusions. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or examples of how it has been successfully applied in similar studies. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the observations and conclusions are currently hidden in the experimental section and recommends that the paper highlight these observations and conclusions. This feedback is explicit and provides a clear action for the authors to take, which is to make these observations and conclusions more prominent in the paper. The suggestion is concrete, as it specifies what needs to be done to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the trade-offs between annotation effort and training performance. While it does not explicitly mention a specific section, the authors can infer that it pertains to the experimental section. The comment is specific in its suggestion to highlight the observations and conclusions, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them for better understanding of the trade-offs between annotation effort and training performance. While the comment provides a logical suggestion for improving the paper, it lacks specific examples or references to support the claim that the observations and conclusions are indeed hidden. This makes the claim somewhat verifiable, as the authors would need to infer the exact observations and conclusions being referred to. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations and conclusions would be beneficial for understanding the trade-offs between annotation effort and training performance. This feedback is clear and actionable, as it provides a specific recommendation for improving the clarity and accessibility of the paper\\'s findings. However, the comment could be more helpful if it offered additional guidance on how to effectively highlight these observations or provided examples of how this could be achieved. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It also questions whether it is possible to show a comparison of the performance on datasets where the decision space is beyond binary. While the comment highlights an issue and suggests a potential comparison, it does not explicitly instruct the authors to perform this comparison or provide detailed guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include such a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Remark 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether it is possible to show a comparison of the performance on datasets where the decision space is beyond binary. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the requirement for more data when the classifier space is beyond binary, referencing Remark 1. It then questions whether it is possible to show a comparison of the performance on datasets where the decision space is beyond binary, referencing Zhang et al. [44] as an example. While the comment provides a logical basis for the concern, it lacks specific details or examples to fully substantiate the claim. The reference to Zhang et al. [44] provides some context, but it does not offer a detailed comparison or analysis. Therefore, the claim is somewhat verifiable, as it provides a basis for the concern but requires more detailed support or evidence to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the requirement for more data when the classifier space is beyond binary, as mentioned in Remark 1. It questions whether it is possible to show a comparison of the performance on datasets where the decision space is beyond binary. This feedback is somewhat helpful as it identifies a potential limitation in the current approach and suggests a direction for further investigation. However, the comment lacks specific guidance or suggestions on how to conduct this comparison or what aspects should be considered. To be more helpful, the comment could provide more detailed advice or examples on how to address this issue. Therefore, the comment is rated as somewhat helpful, as it prompts the authors to consider an important aspect but does not fully guide them in implementing the suggested improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. While the questions are clear, they do not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to investigate these aspects and possibly provide additional analysis or discussion. However, the lack of specific instructions or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment lacks grounding as it does not mention specific sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address these issues. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point consists of two questions regarding the impact of the SR model\\'s capacity on the FID and the presence of unexpected artifacts due to the pipelining method. These are factual inquiries that do not express opinions, judgments, or suggestions. They are purely descriptive and seek clarification, making them normal statements. Therefore, the label \"No\" is appropriate.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions: (1) How the capacity of the SR model affects the FID, and (2) the presence of unexpected artifacts due to the proposed method being pipelining. While these questions are relevant and could lead to valuable insights, the comment lacks specific guidance or suggestions on how the authors might address these issues. It does not provide actionable steps or detailed feedback that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it identifies areas for exploration but does not fully support the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This provides a clear and direct action for the authors to take, as they are explicitly told what types of experiments are needed to improve the draft. The comment is specific in identifying the types of experiments that should be included, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments should be included in, making it weakly grounded. The comment is specific in identifying the types of experiments that are missing, but without grounding, the authors may struggle to pinpoint where these experiments should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide any specific examples or references to support the claim, nor does it explain why these experiments are necessary or how they would improve the paper. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is clear and actionable, as it directly informs the authors of specific areas where their work could be strengthened. By highlighting these missing components, the comment provides a clear direction for the authors to enhance the depth and robustness of their experimental evaluation. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or what specific results to expect from them. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It suggests that the comparison is unfair because it requires two representation models learned for each dataset. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their experimental setup. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the extra complexity and cost of their method. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison, noting that the proposed method does not have an advantage without prior information and that the comparison is unfair due to the extra complexity and cost involved. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the comparison of the proposed method is unfair because it requires two representation models learned for each dataset, which is not the case for the SOTA. The reviewer provides a logical reasoning for why the comparison is unfair, stating that the proposed method's advantage is only realized when using prior knowledge. This reasoning is clear and supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the experimental results, noting that the proposed method does not have an advantage over the SOTA without prior information. It highlights that the comparison is unfair because it requires two representation models learned for each dataset, which adds extra complexity and cost. This feedback is clear and actionable, as it points out a specific area where the authors need to improve their experimental setup to ensure fairness. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative ways to conduct the comparison. Overall, the comment is mostly helpful as it guides the authors towards a more robust evaluation of their method.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. While the comment implies that the authors should consider including collaborative games in their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their experiments to include collaborative games. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or experiment. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in suggesting the inclusion of collaborative games, but it lacks grounding as it does not mention specific sections or experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks collaborative games in its experiments and proposes that it would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment does not provide any specific reasoning or evidence to support why collaborative games are important or how they would enhance the paper. Without detailed justification or examples, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the paper by noting the absence of collaborative games in the experiments. It suggests that including collaborative games would be interesting and could provide valuable insights into how the evaluated methods behave in different settings. This feedback is clear and actionable, as it directs the authors to consider expanding their experimental scope to include collaborative games. However, the comment could be more helpful if it provided specific suggestions on how to incorporate collaborative games or examples of how this could enhance the paper. Overall, the comment is mostly helpful as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. This provides a clear and direct action for the authors to take, which is to include the experimental settings for these figures. The comment is explicit and concrete, giving the authors a straightforward task to improve the clarity and verifiability of their results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 1 to Figure 9,\" allowing the authors to accurately identify the parts of the paper being addressed. This provides full grounding. The comment also specifies the issue by noting that the experimental settings are missing, which makes the figures difficult to be convincing. This level of detail is specific, as it clearly outlines what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings for Figures 1 to 9 are missing, making them difficult to be convincing. However, the comment does not provide any specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the claim is considered borderline verifiable, as it lacks sufficient detail to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the experimental settings for Figures 1 to 9 are missing. This is a critical point as it affects the verifiability and credibility of the results presented in those figures. By pointing out this omission, the comment provides clear and actionable feedback that can help the authors improve the clarity and robustness of their experimental methodology. However, the comment could be more helpful if it suggested how the authors might address this issue, such as by providing a detailed explanation of the missing settings or recommending specific steps to include them. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential ambiguity in the rationale behind the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment does not provide explicit guidance on how the authors should address this ambiguity or clarify their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed clarification on the proposed method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the rationale behind the work and the suggestion of pathway protection based on sparsity in activation channels. It highlights an ambiguity regarding how the proposed method avoids impeding the learning of new task knowledge, which is a critical aspect of the work. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing the ambiguity and suggesting a need for clarification, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the rationale behind the work, specifically regarding the suggestion of pathway protection based on sparsity in activation channels. It questions whether this approach avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage this sparsity. The comment provides a logical reasoning by pointing out the potential ambiguity in the rationale and suggests that the authors clarify how their proposed method addresses this issue. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide more detailed explanations or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential ambiguity in the rationale of the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It highlights that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. The comment suggests that the authors clarify how their proposed method addresses this issue, providing a clear direction for improvement. However, it lacks specific suggestions or examples on how to clarify the rationale, which could enhance the usefulness of the feedback. Overall, the comment is mostly helpful as it points out a critical area for clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}{'actionability_rationale': 'The review comment identifies a potential ambiguity in the rationale of the work, specifically regarding how the proposed method avoids impeding the learning of new task knowledge. It suggests that some parameter isolation methods are tailored to leverage sparsity in activation channels, which could be relevant to the discussion. However, the comment does not provide explicit guidance on how the authors should address this ambiguity or clarify their approach. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detailed clarification on the proposed method. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the rationale behind the work and the suggestion of pathway protection based on sparsity in activation channels. It highlights an ambiguity regarding how the proposed method avoids impeding the learning of new task knowledge, which is a critical aspect of the work. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing the ambiguity and suggesting a need for clarification, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the rationale behind the work, specifically regarding the suggestion of pathway protection based on sparsity in activation channels. It questions whether this approach avoids impeding the learning of new task knowledge, given that some parameter isolation methods are tailored to leverage this sparsity. The comment provides a logical reasoning by pointing out the potential ambiguity in the rationale and suggests that the authors clarify how their proposed method addresses this issue. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide more detailed explanations or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the regularization term appears ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics and justify their choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization term, specifically mentioning that it seems ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to explore alternative statistics is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the regularization term appears ad-hoc and lacks theoretical support, suggesting that other statistics could be used to replace the mean and standard deviation. The reviewer provides a specific suggestion, such as using the median, which is not sensitive to outlier values. However, the comment lacks detailed reasoning or references to support why these statistics are more appropriate or why the current approach is insufficient. The suggestion is somewhat verifiable as it offers a specific alternative, but it requires further elaboration to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the regularization term, noting that it seems ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. This feedback is somewhat helpful as it points out a specific area for improvement and provides a suggestion for alternative approaches. However, the comment could be more helpful if it included specific examples or references to support the use of the median or other statistics. Overall, the comment offers a direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the regularization term appears ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative statistics and justify their choice. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization term, specifically mentioning that it seems ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to explore alternative statistics is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the regularization term appears ad-hoc and lacks theoretical support, suggesting that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. However, the comment lacks detailed reasoning or references to support why these statistics are more appropriate or why the current approach is insufficient. The suggestion to explore alternative statistics is specific, but the comment does not provide a comprehensive justification for the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the regularization term, noting that it seems ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used to replace the mean and standard deviation in the regularization. This feedback is somewhat helpful as it points out a specific area for improvement and provides a suggestion for alternative approaches. However, the comment could be more helpful if it included specific examples or references to support the use of the median or other statistics. Overall, the comment offers a direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment points out that the regularization term appears ad-hoc and lacks theoretical support. It suggests that"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear and concrete action by suggesting that integrating benchmark comparisons against state-of-the-art fairness algorithms would enhance the paper. The comment specifies what needs to be done and how to implement it, making the action highly actionable. The authors know exactly what changes to make to improve their draft, aligning with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of comparisons with existing fairness algorithms. The comment suggests integrating benchmark comparisons against state-of-the-art fairness algorithms to enhance the paper\\'s evidence and positioning within the FairML research landscape. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper lacks comparisons with existing fairness algorithms, which would enhance the paper\\'s evidence and positioning within the FairML research landscape. The claim is supported by logical reasoning, as it highlights the importance of benchmark comparisons in evaluating the performance of the proposed method. However, the comment could be strengthened by providing specific examples of existing fairness algorithms or references to relevant literature that could be used for comparison. This would make the claim more verifiable. Therefore, the comment is categorized as 4: Mostly Verifiable, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of comparisons with existing fairness algorithms in the experimental section. It provides a clear and actionable suggestion by recommending the integration of benchmark comparisons against state-of-the-art fairness algorithms. This feedback is highly helpful as it guides the authors on how to enhance the paper\\'s evidence and positioning within the existing FairML research landscape. By addressing this suggestion, the authors can significantly improve the quality and impact of their work. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential for negative transfer in supervised pretraining based on the prediction of homo-lumo gap, using Transformer-M on QM9. It highlights that Transformer-M performs poorly on most tasks other than homo, lumo, and gap, which contradicts the claim of the paper that it is a general-purpose neural network model. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their model. The action is implicit and vague, as the authors are left to infer that they need to investigate and possibly modify their approach to address the negative transfer. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the supervised pretraining of Transformer-M on QM9, highlighting that it performs poorly on most tasks other than homo, lumo, and gap. This is a clear and specific issue that the authors can address. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. Despite this, the comment is specific in detailing the problem with the model\\'s performance and its implications for the paper\\'s claims. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as demonstrated by Transformer-M\\'s performance on QM9. The reviewer provides a specific example of poor performance on most tasks other than homo, lumo, and gap, which contradicts the paper\\'s claim of Transformer-M being a general-purpose neural network model. This claim is somewhat verifiable as it provides a specific example of negative transfer, but it lacks detailed reasoning or references to support the general claim about negative transfer. The authors would need to further explore and substantiate the claim to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the supervised pretraining of Transformer-M on QM9, specifically noting that it performs poorly on most tasks other than homo, lumo, and gap. This observation challenges the claim that Transformer-M is a general-purpose neural network model. The comment provides a specific example of negative transfer, which is a valuable insight for the authors to consider. However, the feedback could be more helpful if it offered suggestions on how to address this issue or improve the model's generalizability. Overall, the comment is somewhat helpful as it highlights a critical area for improvement but lacks detailed guidance for the authors to implement the suggested changes.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a potential issue with the supervised pretraining of Transformer-M on QM9, noting that it performs poorly on most tasks other than homo, lumo, and gap. This observation challenges the claim that Transformer-M is a general-purpose neural network model. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their model. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to investigate and possibly modify their approach to address the negative transfer, but without specific guidance, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the supervised pretraining of Transformer-M on QM9, highlighting that it performs poorly on most tasks other than homo, lumo, and gap. This is a clear and specific issue that the authors can address. However, the comment does not explicitly mention which part of the paper discusses this issue, making it weakly grounded. Despite this, the comment is specific in detailing the problem with the model\\'s performance and its implications for the paper\\'s claims. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the prediction of homo-lumo gap may lead to negative transfer, as demonstrated by Transformer-M\\'s performance on QM9. The reviewer provides a specific example of poor performance on most tasks other than homo, lumo, and gap, which contradicts the paper\\'s claim of Transformer-M being a general-purpose neural network model. This claim is somewhat verifiable as it provides a specific example of negative transfer, but it lacks detailed reasoning or references to support the general claim about negative transfer. The authors would need to further explore and substantiate the claim to fully address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the term \"distributional generalization\" and suggests that it might be too strong to describe the empirical phenomenon presented. It questions whether the ideal of the total variation between the test and train distributions of the network\\'s outputs vanishing to zero is realistic, given the limited number of test functions on which the outputs match. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their terminology. The action is implicit and vague, as the authors are left to infer that they should reconsider the term used to describe the phenomenon. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the terminology used to describe the phenomenon of distributional generalization. It points out that the term might be too strong to capture the empirical phenomenon presented, questioning the validity of the claim that the total variation between the test and train distributions of the network\\'s outputs vanishes to zero. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The feedback is specific in identifying the concern with the terminology, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the term \"distributional generalization\" and questions its appropriateness in describing the empirical phenomenon presented. The reviewer points out that the term might be too strong, as it implies a vanishing total variation between the test and train distributions of the network\\'s outputs, which might not be the case based on the limited number of test functions. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the term 'distributional generalization' and questions its appropriateness in describing the empirical phenomenon presented. It points out that the term might be too strong, as it implies a vanishing total variation between the test and train distributions of the network's outputs, which might not be the case based on the limited number of test functions on which the outputs match. This feedback is somewhat helpful as it identifies a potential issue with the terminology used in the paper, prompting the authors to reconsider their choice of words. However, the comment could be more helpful if it provided suggestions on alternative terminology or ways to clarify the concept. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses dissatisfaction with the theoretical contribution, stating that it is weak and unpractical. It also mentions that the proof lacks mathematical novelty. However, the comment does not provide any explicit or implicit actions for the authors to take to improve their theoretical contribution. There is no guidance on how to strengthen the theoretical aspect or what specific elements need to be addressed. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical contribution, specifically mentioning that it is weak and unpractical, and lacks mathematical novelty. However, it does not specify which part of the paper this theoretical contribution is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment provides some level of specificity regarding the issues with the theoretical contribution, it lacks full grounding as it does not explicitly mention a section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical contribution is weak and unpractical, lacking mathematical novelty. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses dissatisfaction with the theoretical contribution, stating that it is weak and unpractical, and lacks mathematical novelty. However, it does not provide specific suggestions or guidance on how the authors might strengthen their theoretical contribution or address the identified issues. Without actionable feedback or detailed explanations, the comment does not offer the authors a clear path to improve their draft. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428. It suggests that the authors might want to clarify that the sum of the \"optimistic\" hoped for rewards is close to the expected actual rewards. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to make this clarification. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L240 and L428,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification regarding the meaning of \"is sufficient\" and the authors\\' intention to explain the sum of the \"optimistic\" hoped for rewards being close to the expected actual rewards. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"is sufficient\" in lines 240 and 428, suggesting that the authors might want to clarify their intention. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how to address this issue. The comment lacks depth and actionable advice, making it somewhat helpful. The authors are given a direction to clarify their statement, but without further elaboration, the feedback does not fully support their efforts to improve the draft. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical discussions could be improved by providing sample complexity-type results, such as the amount of training data points needed to ensure that the algorithm does not return NSF. While the comment implies that the authors should include these results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide sample complexity results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical discussions, specifically mentioning the current theorems and their relation to fair representation. It suggests that the theoretical discussions could be improved by providing sample complexity-type results, such as the amount of training data points needed to ensure that the algorithm does not return NSF. However, the comment does not specify which sections of the paper these theoretical discussions are found in, making it weakly grounded. The suggestion is specific, as it clearly outlines what needs to be addressed in terms of providing additional results. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the theoretical discussions could be improved by providing sample complexity-type results, such as the amount of training data points needed to ensure that the algorithm does not return NSF. The comment provides a logical reasoning by linking the theoretical discussions to the algorithm design and the well-known property of mutual information to $\\Delta_{DP}$. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact nature of the improvements needed, which limits the clarity and comprehensiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems follow directly from the algorithm design and the well-known property of mutual information to $\\Delta_{DP}$. It provides a constructive suggestion by asking for sample complexity-type results, such as the amount of training data points needed to ensure that the algorithm does not return NSF. This feedback is clear and actionable, offering a specific direction for the authors to enhance their theoretical discussions. However, it could be more helpful if it provided examples or references to similar studies that have addressed this issue. Overall, the comment is mostly helpful as it guides the authors in improving their draft by suggesting a specific area for additional analysis.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the description of the VAD (Voice Activity Detection) in the paper. It points out that the current approach, which discards TF bins with a magnitude less than epsilon, is not a typical VAD definition. The reviewer suggests that this approach is more akin to discarding TF bins with zero magnitude, which could lead to division by zero. The comment implies that the authors should reconsider their definition of VAD and provide a more accurate description. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors can infer the need for revision but lack detailed instructions on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current approach, which discards TF bins with a magnitude less than epsilon, questioning whether this is a typical VAD definition. The comment further explains that a VAD is supposed to look for the presence of speech and is usually defined over time, not frequency. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the description of the VAD (Voice Activity Detection) in the paper. It questions the approach of discarding TF bins with a magnitude less than epsilon, suggesting that this is not a typical VAD definition. The reviewer points out that a VAD is supposed to look for the presence of speech and is usually defined over time, not frequency. While the comment provides a logical argument against the current approach, it lacks specific references or examples to fully substantiate the claim. The reasoning is clear but could be strengthened with additional evidence or references to support the assertion that the current approach does not align with typical VAD definitions. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but could benefit from more detailed evidence or references.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the description of the VAD (Voice Activity Detection) in the paper. It points out that the current approach, which discards TF bins with a magnitude less than epsilon, is not a typical VAD definition. The reviewer suggests that this approach is more akin to discarding TF bins with zero magnitude, which could lead to division by zero. The comment provides a clear explanation of what is wrong with the current description and offers a suggestion for improvement by clarifying the VAD definition. However, the comment could be more helpful if it provided specific guidance on how to revise the description or suggested alternative approaches. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and offers a logical critique, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not provide specific guidance or suggestions on how the authors might improve the clarity or structure of their presentation. The comment lacks actionable details, such as recommending specific sections to clarify or suggesting ways to enhance the experimental design. As a result, the authors are left without a clear understanding of what changes are needed to improve the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, it does not specify which parts of the paper are unclear or lack intuition, nor does it provide specific suggestions for improvement. This makes it difficult for the authors to identify the exact areas that need attention. The comment lacks both grounding and specificity, as it does not provide enough detail to guide the authors in addressing the issues. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper is difficult to follow due to a lack of clear intuition and insufficient experiments. However, the comment does not provide specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address the issues effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is difficult to follow due to a lack of clear intuition and insufficient experiments. This feedback is valuable as it highlights a critical area for improvement, which can help the authors enhance the clarity and coherence of their work. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending ways to improve the intuition or structure of the presentation or suggesting additional experiments that could provide more context. While it points out a problem, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment explicitly requests additional metrics, it does not provide specific guidance on how to calculate or present these metrics. The action is clear but lacks detailed instructions on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the training of the student and refinement networks simultaneously and questions the fairness of the comparison with the teacher network. It suggests providing KID/FID metrics for the teacher network. However, the comment does not specify which part of the paper discusses the training of these networks or the comparison with the teacher network, making it weakly grounded. The comment is specific in its request for KID/FID metrics, but without grounding, the authors may struggle to identify the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. However, the comment does not provide any specific reasoning or evidence to support why the comparison might be unfair or how the KID/FID metrics would resolve this issue. The request for metrics is a logical suggestion but lacks detailed justification or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the fairness of the comparison between the student and refinement networks, which are trained simultaneously. It suggests providing KID/FID metrics for the teacher network to address this concern. While the comment identifies a potential issue with the comparison, it lacks specific guidance on how to calculate or present these metrics, which could be beneficial for the authors. The feedback is somewhat helpful as it points out a potential area for improvement but could be more actionable with detailed instructions or examples.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they might need to consider scaling the refined vector, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests that a scaling variable before the attention weight might be beneficial. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the scaling of the refined region vector in the paper. It points out that the attention weight is in [0, 1] and sums up to 1 for all image regions, suggesting that the refined vector would only scale the most important regions by a factor of two before global pooling. The comment then suggests that having a scaling variable before the attention weight might be beneficial. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this change. The authors are left with a question but without actionable steps to address it. Therefore, the comment is somewhat helpful, as it prompts the authors to consider a potential enhancement but does not fully guide them in making the necessary changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\\'s inability to accurately recover the formal goal predicate in the presence of ambiguities in human language. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they should consider to improve their work. As a result, the comment lacks actionable content, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the ALFRED benchmark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue of goal misspecification, explaining that failures often occur due to the LLM\\'s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark are often due to goal misspecification, where the LLM does not accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references to studies or methodologies that could substantiate the assertion about goal misspecification. Without additional evidence or examples, the claim remains somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue related to goal misspecification on the ALFRED benchmark, explaining that failures often occur due to the LLM\\'s inability to accurately recover the formal goal predicate, especially in the presence of ambiguities in human language. This feedback is somewhat helpful as it highlights a critical area for improvement in the paper. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their approach. The comment could be more helpful with additional context, examples, or specific recommendations for addressing the goal misspecification problem. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of Sampling-Gaussian to significantly improve frameworks similar to IGEV. While the comments provide suggestions for analysis and exploration, they do not explicitly instruct the authors on how to conduct these analyses or what specific aspects to focus on. The actions are implicit and somewhat vague, as the authors need to infer the steps to take to address these concerns. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two concerns: first, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. Second, it raises a concern about the difficulty of Sampling-Gaussian to significantly improve frameworks similar to IGEV. While the comment does not explicitly mention specific sections of the paper, it is clear that it relates to the comparison of the proposed method with IGEV and other SOTA methods. The authors can infer that it pertains to the results and discussion sections, but the lack of explicit references makes it weakly grounded. The comment is specific in detailing the issues and suggesting analyses to be conducted, making it specific despite the weak grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two concerns. First, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This part of the comment is somewhat verifiable as it provides a logical reasoning for the authors to investigate the distribution of disparities. However, it lacks specific examples or references to support the claim about the improvement being small. The second concern about the difficulty of Sampling-Gaussian to improve frameworks similar to IGEV is not substantiated with evidence or reasoning, making it difficult to evaluate. Therefore, the overall verifiability of the comment is 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises two concerns. First, it questions the improvement of the method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV to understand why the effect is not significantly improved. This provides a clear direction for the authors to investigate and potentially improve their method. Second, it raises a concern about the difficulty of Sampling-Gaussian to significantly improve frameworks similar to IGEV. This insight prompts the authors to consider the limitations of their approach and potentially explore alternative methods. While the comment does not provide detailed guidance on how to conduct these analyses, it offers valuable directions for improvement. Therefore, the comment is mostly helpful, as it identifies areas for further investigation and improvement, but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could benefit from a deeper investigation into how specific models behave differently when using ReGuide. It explicitly mentions the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides a clear and concrete action for the authors to take, as they are directed to focus on specific models and present relevant data. The comment also offers a specific area for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Model-Specific Insights,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular area for improvement by recommending a deeper investigation into how specific models behave differently when ReGuide is applied. The comment specifies the need to present differences in false positive rates (FPR) between models with and without ReGuide for a better comparison. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper could benefit from a deeper investigation into how specific models behave differently when using ReGuide. It provides a specific example of comparing false positive rates (FPR) between models with and without ReGuide. This suggestion is based on a logical reasoning that adding such specific insights could enhance the paper\\'s conclusions. However, the comment lacks detailed examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct additional research or analysis to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper by suggesting that a deeper investigation into how specific models behave differently when using ReGuide could enhance the conclusions. It provides a specific example of comparing false positive rates (FPR) between models with and without ReGuide, offering a clear direction for the authors to explore. This feedback is actionable and provides a concrete suggestion for the authors to consider, making it mostly helpful. However, it could be more helpful if it included additional guidance on how to conduct this investigation or what specific models to focus on. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests clarification on whether the Fourier modes are real or complex numbers. This is a clear and direct action for the authors to take, as it provides a specific area of ambiguity that needs to be addressed. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Fourier modes,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for clarification on whether the Fourier modes are real or complex numbers. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the nature of Fourier modes (real or complex), which is a factual inquiry rather than a claim or suggestion. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it provides a specific request for clarification regarding the nature of Fourier modes (real or complex). This feedback is valuable because it helps the authors ensure that their presentation of Fourier modes is accurate and consistent with the mathematical concepts they are using. By addressing this point, the authors can improve the clarity and rigor of their work. However, the comment could be more helpful if it included additional context or examples to further explain the importance of this clarification. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations $h$ and $g$ are introduced without explanation of their input and output domains, and that the same issue applies to $\\delta$, which has some brief description. While the comment identifies a specific issue with the lack of clarity in notation, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to clarify the input and output domains of these notations, but the comment lacks concrete suggestions on how to do so. Therefore, the comment is somewhat actionable, as it highlights a specific area for improvement but does not provide detailed instructions on how to implement the change.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the notations $h$ and $g', allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the lack of explanation for their input and output domains. Additionally, it mentions the issue with $\\delta$, providing further specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the introduction of notations $h$ and $g$ without explanation of their input and output domains, and mentions a similar issue with $\\delta$. However, the comment does not provide specific examples or references to support the claim that these notations are unclear or poorly defined. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notations $h$ and $g$ in the paper, noting that they are introduced without explanation of their input and output domains. This is a critical point as it affects the clarity and understanding of the paper. The comment also mentions a similar issue with $\\delta$, providing some context. However, the feedback lacks depth and does not offer suggestions or guidance on how the authors might address these issues, such as by providing definitions or examples. While it highlights an important area for improvement, the comment could be more helpful with additional details or actionable advice. Therefore, it is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus the pre-trained language models. It provides a clear and concrete suggestion for the authors to include results using the GCPG model without pre-trained initializations. This feedback is explicit and provides a direct action for the authors to take, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"results\" and \"task formulation,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the lack of ablation studies to clarify the contribution of the task formulation versus pre-trained language models. The comment is specific in suggesting that the paper should include results using the GCPG model without pre-trained initializations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks ablation studies, which would help clarify the contribution of the task formulation versus pre-trained language models. The comment suggests including results using the GCPG model without pre-trained initializations. While the suggestion is clear, it lacks specific examples or references to support the claim that ablation studies are necessary. The reasoning is logical, but the comment could be strengthened with more detailed justification or references to similar studies. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks comprehensive evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by pointing out the absence of ablation studies. It highlights the importance of understanding the contribution of the task formulation versus the pre-trained language models by suggesting that the paper should include results using the GCPG model without pre-trained initializations. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. By addressing this issue, the authors can better demonstrate the impact of their proposed method and enhance the comprehensiveness of their results. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting a specific change to the figure or providing examples of how the axes could be clarified. Without concrete instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding what the axes represent in the figure. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the difficulty in understanding the axes in Figure 1. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it directs the authors to a specific area that needs clarification. However, the comment could be more helpful if it provided suggestions on how to improve the figure, such as labeling the axes or providing a key. Overall, the comment is mostly helpful as it highlights a critical area for improvement but lacks detailed guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that direct runtime comparisons with existing methods are missing and emphasizes the importance of including them to demonstrate the efficiency of the proposed approach. It provides a clear and concrete action for the authors to take, which is to include these comparisons. The comment also explains why these comparisons are necessary, making the action explicit and actionable. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Direct runtime comparisons with existing methods,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the missing direct runtime comparisons and the need for these comparisons to demonstrate the efficiency of the proposed approach. This provides full grounding and specificity, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing, which is necessary to demonstrate the efficiency of the proposed approach. The reviewer provides a logical reasoning by explaining that the proposed approach is based on implicit differentiation, which usually requires additional computational costs. This reasoning supports the claim that direct runtime comparisons are essential for evaluating efficiency. However, the comment could be strengthened by providing specific examples or references to similar studies that have included such comparisons. Overall, the claim is mostly verifiable due to the logical reasoning provided, but it could be further strengthened with additional evidence or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. It explains that the proposed approach is based on implicit differentiation, which typically involves additional computational costs. By emphasizing the importance of including these comparisons to demonstrate the efficiency of the proposed approach, the comment provides clear and actionable feedback. This feedback is valuable as it guides the authors in understanding the necessity of including such comparisons to strengthen their work. However, the comment could be more helpful if it suggested specific methods or approaches for conducting these comparisons. Overall, the comment is mostly helpful as it highlights a significant area for improvement, but it could be further enhanced with more detailed guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed framework is a simple combination of meta-learning and federated learning, suggesting that it lacks technical contribution. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance the technical contribution or what specific aspects need to be improved. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed framework, specifically mentioning that it is a simple combination of meta-learning and federated learning. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in pointing out the lack of technical contribution, but without clear grounding, it is challenging for the authors to pinpoint the exact area needing improvement. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning, lacking any technical contribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed framework, noting that it is a simple combination of meta-learning and federated learning without any technical contribution. This feedback is somewhat helpful as it points out a specific area for improvement, namely the lack of originality or innovation in the framework. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might enhance the technical contribution or address this issue. Without actionable advice or examples, the authors may find it challenging to fully understand and improve upon this feedback. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that discussing case studies and error studies could enhance the paper\\'s effectiveness by providing concrete examples of the proposed components. It specifically mentions the Element-level Graph Pre-training and its focus on core elements, but it does not provide explicit guidance on how to conduct these studies or what specific aspects to include. The comment implies that the authors should include case studies to support their claims, but it lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing case studies and error studies to highlight the effectiveness of the proposed components, specifically mentioning the Element-level Graph Pre-training. It provides a specific example of a case study from \"Graph pre-training for AMR parsing and generation.\" This feedback is fully grounded as it explicitly mentions the Element-level Graph Pre-training and references a specific example, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it suggests a method for enhancing the paper\\'s effectiveness by including case studies and error studies. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that discussing case studies and error studies could enhance the paper\\'s effectiveness by providing concrete examples of the proposed components. It mentions a specific example from \"Graph pre-training for AMR parsing and generation,\" which supports the claim. However, the comment lacks detailed reasoning or specific examples of how case studies and error studies would improve the paper, making it somewhat verifiable. The addition of more detailed examples or explanations would strengthen the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that discussing case studies and error studies could enhance the paper's effectiveness by providing concrete examples of the proposed components. It specifically mentions the Element-level Graph Pre-training and its focus on core elements, but it lacks detailed guidance on how to conduct these studies or what specific aspects to include. While the comment identifies a potential area for improvement, it does not provide actionable steps or examples, making it somewhat helpful. The authors would benefit from more detailed feedback on how to implement these suggestions effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to clarify the motivation. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It also mentions the need to clarify the motivation for considering these factors as extra evaluations. However, the comment does not specify which part of the paper this discussion is related to, making it weakly grounded. The authors can infer that it relates to the evaluation or discussion of the DCI framework, but this inference is not explicit. The comment is specific in detailing the need for clarification on the motivation for considering explicitness(E) and size(S) as extra evaluations. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the traditional DCI framework and suggests that it may already consider explicitness(E) and size(S). It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific examples or references to support the claim that the DCI framework already considers these factors. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the traditional DCI framework, suggesting that it may already consider explicitness(E) and size(S) as evaluation factors. It provides a rationale for why these factors might be relevant, such as the need to evaluate disentanglement (D) using a fixed capacity of probing (f) and the importance of fixing the latent size. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the motivation for considering these factors as extra evaluations. While it identifies a potential area for improvement, the feedback is somewhat helpful as it provides some insight but does not offer actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the manual disentangling process, specifically questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative methods for disentangling. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the manual disentangling process, particularly questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment does not specify which part of the paper discusses the manual disentangling process, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup, but this inference is not precise. The comment is specific in detailing the issue with manual disentangling and suggesting an alternative approach, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. However, the comment lacks specific reasoning or evidence to support why this choice is problematic or why learning disentangling would be more interesting. The suggestion is based on a subjective opinion rather than a verifiable claim, as it does not provide detailed justification or examples. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the manual disentangling process, questioning the choice of the semantic segmentation network as the first module in the pipeline. It suggests that the paper would be more interesting if the disentangling were learned rather than manual. This feedback is somewhat helpful as it points out a potential area for improvement and encourages the authors to consider alternative approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address the issue or explore alternative methods. To be more helpful, the comment could include examples of alternative approaches or references to relevant literature. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the connection between the theoretical analysis and the proposed method, suggesting that the authors\\' approach seems to simply adopt the idea of the self-attention mechanism from the transformer and apply it to the graph. The reviewer questions how the proposed method enhances the generalization for distant nodes. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve their analysis. The action is implicit and vague, as the authors are left to infer that they need to strengthen the connection between the theoretical analysis and the proposed method. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the theoretical analysis and the proposed method, specifically mentioning the PAC-Bayesian bound for GNNs in the transductive setting. It questions the connection between the theoretical analysis and the proposed method, suggesting that the method seems to adopt the idea of the self-attention mechanism from the transformer and apply it to the graph. However, the comment does not specify which part of the paper this analysis is found in, making it weakly grounded. The comment is specific in questioning the connection between the theoretical analysis and the proposed method, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the connection between the theoretical analysis and the proposed method, suggesting that the proposed method seems to adopt the idea of the self-attention mechanism from the transformer and apply it to the graph without enhancing the generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The authors are left to infer the basis of the critique, making it difficult to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the connection between the theoretical analysis and the proposed method, specifically questioning the enhancement of generalization for distant nodes. It highlights a potential disconnect between the theoretical framework and the practical application of the proposed method. However, the comment lacks specific suggestions or guidance on how the authors might strengthen the connection or improve the analysis. While it identifies a potential issue, it does not provide actionable feedback or detailed insights that could help the authors address the concern effectively. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the connection between the theoretical analysis and the proposed method, suggesting that the proposed method seems to adopt the idea of the self-attention mechanism from the transformer and apply it to the graph without enhancing the generalization for distant nodes. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their analysis. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to strengthen the connection between the theoretical analysis and the proposed method, but without specific guidance, the feedback remains vague.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the theoretical analysis and the proposed method, specifically mentioning the PAC-Bayesian bound for GNNs in the transductive setting. It questions the connection between the theoretical analysis and the proposed method, suggesting that the method seems to adopt the idea of the self-attention mechanism from the transformer and apply it to the graph without enhancing the generalization for distant nodes. However, the comment does not specify which part of the paper this analysis is found in, making it weakly grounded. The comment is specific in questioning the connection between the theoretical analysis and the proposed method, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the connection between the theoretical analysis and the proposed method, suggesting that the proposed method seems to adopt the idea of the self-attention mechanism from the transformer and apply it to the graph without enhancing the generalization for distant nodes. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. The authors are left to infer the basis of the critique, making it difficult to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or justification to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some pieces in the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. It suggests that the authors should provide more clarity by checking the original paper. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the presentation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the presentation of existing methods. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation (12)\" and \"pieces using existing methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the presentation of these methods is vague and can only be understood after checking the original paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some pieces in the paper use existing methods, such as equation (12), and that the presentation of these methods is vague. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of existing methods in the paper, particularly referring to equation (12). It points out that the presentation is vague and suggests that the authors should provide more clarity by checking the original paper. While the comment highlights a potential area for improvement, it lacks depth and does not offer specific suggestions or guidance on how to enhance the clarity of the presentation. This limits its usefulness for the authors, as they may find it challenging to fully address the issue without additional context or direction. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the stability definition needs better justification, suggesting that the left side should be lower bounded. This provides a clear and direct action for the authors to take, which is to address the justification of the stability definition and ensure it is lower bounded. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"stability definition,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current definition, suggesting that the left side should be lower bounded. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the stability definition needs better justification, suggesting that the left side can be arbitrarily small under some construction of \\u03b4. The reviewer proposes a more reasonable treatment by making it lower bounded. However, the comment lacks specific examples or references to support the claim that the current definition is insufficiently justified. While the suggestion is logical, the absence of detailed evidence or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that it can be arbitrarily small under certain conditions. It suggests a more reasonable treatment by proposing that the definition should also be lower bounded. This feedback is clear and actionable, providing the authors with a specific area to address and improve in their draft. By offering a constructive suggestion for enhancing the justification of the stability definition, the comment is mostly helpful, as it guides the authors toward a more robust and comprehensive presentation of their work. However, it could be more helpful if it included additional context or examples to further support the suggestion. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit action for the authors to take. It suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. Additionally, it recommends that the paper aim for a more application-oriented venue if it does not address these issues. The comment is concrete, as it specifies the exact steps the authors need to take to improve their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"contrastive response tuning\" as part of the core methodology, allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what needs to be addressed, such as comparing the effectiveness against existing methods and addressing the issues mentioned above. The comment further suggests that the paper should aim for a more application-oriented venue if it does not address these issues. This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and address the issues mentioned above. It also recommends that the paper aim for a more application-oriented venue if it does not address these issues. However, the comment does not provide specific examples or references to support the claim that the paper should compare against existing methods or address the issues mentioned. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the basis of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for the authors to compare their methodology, specifically contrastive response tuning, against existing methods such as contrastive decoding. This comparison would help validate the effectiveness of their approach and provide a benchmark for future work. Additionally, the comment highlights the need to address the issues mentioned above and suggests that the paper should aim for a more application-oriented venue if it does not address these issues. This feedback is detailed and constructive, offering specific guidance on how the authors can improve their work. Therefore, the comment is highly helpful, as it empowers the authors to make significant improvements to their draft.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises several concerns about the algorithm\\'s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity of the computation and the efficiency of the algorithm are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes are needed. The actions are implicit and somewhat vague, as the authors can infer the need for improvement but lack detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses several issues related to the algorithm\\'s effectiveness, problem, and validation experiments. It points out that the algorithm requires access to the entire training dataset and suggests considering how it operates when the dataset is not fully perceptible. Additionally, it notes that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not analyzed. The comment also expects the authors to further elucidate the technical contribution. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the areas that need improvement, such as the algorithm\\'s effectiveness and the need for comprehensive validation experiments. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the algorithm\\'s effectiveness and problem, specifically noting that it requires access to the entire training dataset. It suggests that the authors should consider how the algorithm operates effectively when the training dataset is not fully perceptible. Additionally, it points out that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution. While the comment identifies several areas for improvement, it lacks specific examples or references to support the claims about the algorithm\\'s effectiveness and problem. The suggestion to consider the algorithm\\'s operation with incomplete datasets is a logical inference but lacks detailed guidance. Therefore, the comment is somewhat verifiable, as it provides some reasoning but requires more detailed support to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies several areas for improvement in the paper. It points out that the algorithm requires access to the entire training dataset, suggesting that the authors should consider how the algorithm operates effectively when the dataset is not fully perceptible. Additionally, it notes that the related validation experiments are not comprehensive and that the time complexity and efficiency of the algorithm are not clearly analyzed. The comment also expects the authors to further elucidate the technical contribution. While the feedback highlights important areas for improvement, it could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is somewhat helpful as it provides clear directions for enhancing the paper, but it could be more comprehensive with detailed guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the proposed method is not well-positioned in the literature and highlights that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. It provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. The reviewer suggests that the authors should conduct a thorough literature review to identify additional works that utilize this property. While the comment implies that the authors should perform a literature review, it does not provide specific guidance on how to conduct this review or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for a literature review and how to carry it out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and references specific examples of previous works, such as the original denoising score matching objective and \"score-interpolation.\" This provides clear guidance on which part of the paper is being addressed, allowing the authors to accurately identify the sections or aspects needing attention. The comment is also specific because it highlights the well-known nature of the key idea and suggests that the authors should conduct a thorough literature review to identify additional works that utilize this property. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known. The reviewer provides examples of previous works, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. This provides a clear and specific reference to existing literature, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed references or examples to further substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed method, noting that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is well-known and has been used in previous works. It provides specific examples, such as the original denoising score matching objective and \"score-interpolation,\" which use this property. This feedback is valuable as it highlights the need for the authors to conduct a thorough literature review to ensure their work is well-positioned and differentiated. The comment offers actionable advice by suggesting that the authors should review additional works that utilize this property, which could help them strengthen their contribution. However, the comment could be more helpful if it provided specific guidance on how to conduct this literature review or what aspects to focus on. Overall, the comment is mostly helpful as it provides clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment implies that the authors should provide a gradient comparison between KL and PCC to support their claim. While the action is implicit, it is concrete as it specifies the type of comparison needed. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing a gradient comparison between KL and PCC. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point challenges the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It suggests that the constraint strength of a loss function is defined by its gradient distribution and provides an example of how KL divergence and MSE loss have the same optimal solution but differ in their gradient distributions. The comment is mostly verifiable as it offers a logical explanation and an example to support its claim, but it could be strengthened by providing more detailed comparisons or references to existing literature. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper regarding the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to the KL divergence due to its invariance to scale and shift. It provides a logical argument that the constraint strength of a loss function is defined by its gradient distribution, using an example to illustrate the point. The comment suggests that the authors should provide a gradient comparison between KL and PCC to support their claim. This feedback is clear and actionable, offering a specific area for improvement that can enhance the paper\\'s rigor and clarity. However, it could be more helpful if it included additional guidance on how to conduct the gradient comparison or what specific aspects should be highlighted. Overall, the comment is mostly helpful, as it provides valuable insights and actionable suggestions for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the paper\\'s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what experiments might be necessary. The action is implicit and vague, as the authors are left to infer that they need to provide more evidence or conduct additional experiments to clarify the situation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L106,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the approach taken to resolve a debate that was previously left open and suggests that the distribution might have changed. The comment further asks whether experiments have been conducted to disentangle changes in distribution from the removal of information, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the paper\\'s approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the approach is flawed or incomplete. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the paper's approach to resolving a debate that was previously left open. It questions whether the distribution has changed and whether experiments have been conducted to disentangle changes in distribution from the removal of information. This feedback is somewhat helpful as it identifies a potential issue with the paper's methodology and encourages the authors to consider alternative explanations or additional experiments. However, the comment lacks specific suggestions or guidance on how to address these concerns, such as recommending specific experiments or analyses to conduct. While it prompts the authors to think critically about their approach, it could be more helpful with additional details or actionable advice. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should reproduce the results of the compared methods using the same settings as the proposed method, specifically mentioning the use of AdamW with cosine lr for training. This action is clear and concrete, as it provides a specific step for the authors to take to ensure a fair comparison. The comment also highlights the importance of using the same settings as the compared methods, which is a logical and actionable suggestion. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the comparison of methods, noting that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. It suggests that the direct comparison is unfair and recommends reproducing the results of the compared methods using the same settings as the proposed method. This feedback is fully grounded as it explicitly mentions the comparison of methods and the specific training settings, allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the issue with the comparison and provides a solution. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the direct comparison of methods is unfair because the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests reproducing the results of the compared methods using the same settings as the proposed method to ensure fairness. This claim is somewhat verifiable as it provides a logical reasoning for the unfairness of the comparison and suggests a solution to address it. However, it lacks specific examples or references to support the claim about the unfairness of the comparison, which could strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of methods in the paper. It points out that the proposed method uses AdamW with cosine lr for training, while the compared methods use adam with fixed lr. The reviewer suggests that this difference in training settings could make the comparison unfair. They recommend reproducing the results of the compared methods using the same settings as the proposed method to ensure a fair comparison. This feedback is clear and actionable, as it provides a specific suggestion for improving the fairness of the comparison. However, it could be more helpful if it included additional guidance on how to reproduce the results or what specific aspects of the results should be compared. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. It suggests that the plots should be much clearer, which is a direct and concrete action for the authors to take. The comment provides specific areas for improvement, such as increasing the size of the plots, improving color differentiation, and clarifying axis labels. This level of detail and specificity makes the action explicit and concrete, allowing the authors to know exactly what changes to make. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"plots,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are \"terrible\" due to their small size, poor color differentiation, unclear axis labels, and visually similar labels. The reviewer provides specific examples of these issues, such as the difficulty in distinguishing between pink and red colors. This level of detail and specificity supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing additional examples or references to similar issues in other publications, which would fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies specific issues with the plots, such as their small size, poor color differentiation, unclear axis labels, and visually similar labels. It highlights that these issues make the plots difficult to read and understand, which is crucial for presenting experimental results. By pointing out these problems, the comment provides clear and actionable feedback that can help the authors improve the clarity and effectiveness of their presentation. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending larger plot sizes or clearer label differentiation. Overall, the comment is mostly helpful as it directs the authors' attention to critical areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. It also provides specific guidance on what needs to be addressed, such as including standard deviations in the table. This feedback is clear and direct, giving the authors a concrete action to take. The comment is highly actionable as it provides explicit instructions on how to improve the draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the table, namely the absence of standard deviations, and suggests that the submission would be stronger if the experiments were more extensive. Additionally, it provides a clear direction for improvement by mentioning the need to include standard deviations in the table. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 does not show standard deviations and suggests that the submission would be stronger if the experiments were more extensive. However, the comment lacks specific examples or references to support the claim about the lack of standard deviations or the need for more extensive experiments. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also provides a clear suggestion for improvement by stating that the submission would be stronger if the experiments were more extensive. This feedback is actionable and provides the authors with a clear direction for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to incorporate standard deviations or suggested specific areas where more extensive experiments could be conducted. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit suggestions for improving the paper\\'s structure, specifically recommending a clearer organization of sections (introduction, method, experiments) and more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, the comment suggests improving the visualization of Figures 7 and 8. These actions are clear and concrete, giving the authors a specific plan for enhancing their draft. The feedback is actionable because it provides clear guidance on what needs to be improved and how to achieve it. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests improvements to the paper\\'s structure, specifically recommending a clearer organization of sections and more focus on the IEM in Figure 3. It also mentions the need to improve the visualization of Figures 7 and 8. While the comment does not explicitly mention specific sections or figures, it provides enough context for the authors to understand the areas needing attention. The suggestion to improve the structure and focus on the IEM is specific, allowing the authors to address the feedback effectively. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is difficult to follow and recommends improvements to the structure and visualization of certain figures. However, it does not provide specific examples or detailed reasoning to support why the structure is unclear or why Figure 3 is considered the main figure. The lack of detailed justification or evidence makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically noting that some sections are difficult to follow and require multiple readings. It provides actionable suggestions for improving the paper\\'s structure by recommending a clearer organization of sections (introduction, method, experiments) and more focus on the IEM in Figure 3, which the reviewer considers the main figure. Additionally, the comment suggests enhancing the visualization of Figures 7 and 8. These specific and detailed suggestions empower the authors to make meaningful improvements to their draft, making the feedback highly helpful. However, the comment could be more helpful if it provided additional context or examples to further guide the authors in implementing these suggestions. Overall, the feedback is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. While the comment implies that this would be an interesting addition, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should broaden their experimental scope. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the experiments to include other architectures and classification tasks beyond neural networks and image classification. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the introduction. The authors might infer that it relates to the experimental setup, but this inference is not explicit. The comment is specific in its suggestion to explore other architectures and tasks, but it lacks grounding as it does not point to a specific section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be expanded to include other architectures and classification tasks beyond neural networks and image classification. However, the comment does not provide any reasoning, evidence, or examples to support why this would be beneficial or how it could improve the paper. Without specific justification or references, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should expand their experiments to include other architectures and classification tasks beyond neural networks and image classification. This feedback is somewhat helpful as it provides a direction for potential future work that could enhance the scope and applicability of the study. However, the comment lacks specificity and does not offer guidance on how to conduct these additional experiments or what specific tasks or architectures should be explored. To be more helpful, the comment could include suggestions on which tasks or architectures might be particularly relevant or how to structure the additional experiments. Therefore, the comment is rated as somewhat helpful, as it points out an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment implies that the authors should provide a detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address this concern by providing a detailed explanation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. It requests the authors to explain why the absence of locality bias in transformers is not a concern. However, the comment does not specify which part of the paper this concern relates to, making it weakly grounded. The authors might infer that it pertains to the methodology or discussion section, but this is not explicitly stated. The comment is specific in detailing the concern about locality bias and its potential impact, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that transformers without locality bias are not suitable. The reasoning is based on a general observation about information propagation, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the use of transformer models without locality bias, suggesting that due to the limited speed of information propagation, neighborhood agents should naturally have more impact on each other compared to distant nodes. The reviewer requests the authors to explain why the absence of locality bias in transformers is not a concern. While the comment identifies a potential issue and prompts the authors to provide an explanation, it lacks specific suggestions or guidance on how to address this concern. The feedback is somewhat helpful as it highlights an area for improvement but could be more actionable with detailed advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need to clarify the impact of the mitigation strategies on the overall performance of the model. It suggests that there might be a trade-off between reducing a particular behavior and maintaining high performance, and questions whether these strategies significantly impair the model\\'s utility. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and clarify the impact of the mitigation strategies. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the impact of mitigation strategies on the overall performance of the model, specifically questioning whether these strategies significantly impair the model\\'s utility. However, it does not specify which part of the paper discusses these strategies or how they are implemented, making it weakly grounded. The comment is specific in its concern about the trade-off between reducing a particular behavior and maintaining high performance, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the overall performance of the model, suggesting that there might be a trade-off between reducing a particular behavior and maintaining high performance. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed evidence or references leaves the claim somewhat verifiable, as it requires the authors to infer the implications of the mitigation strategies on performance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the mitigation strategies proposed in the paper, specifically questioning their impact on the overall performance of the model. It highlights the trade-off between reducing a particular behavior and maintaining high performance, which is a critical consideration for the authors to address. The comment suggests that if these strategies significantly impair the model's utility, it might deter their adoption, providing a valuable insight for the authors to consider. However, the comment could be more helpful if it offered suggestions on how to assess and mitigate this trade-off or provided examples of similar strategies that have been successfully implemented. Overall, the comment is mostly helpful as it directs the authors' attention to a critical aspect of their work that needs further exploration and clarification.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the use of 6-fold cross-validation in the paper, questioning the necessity of this method compared to other papers that did not use cross-validation. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should justify the use of 6-fold cross-validation or consider alternative methods, but it does not offer concrete steps or examples for the authors to follow. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses the use of 6-fold cross-validation in the paper, specifically questioning the necessity of this method compared to other papers that did not use cross-validation. However, it does not specify which part of the paper discusses the cross-validation or the datasets used, making it weakly grounded. The comment is specific in questioning the reason for using 6-fold cross-validation and suggesting that it is unclear why it is required, but it lacks explicit references to the relevant sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the necessity of using 6-fold cross-validation in the paper, referencing other papers that did not use cross-validation. However, the comment lacks specific examples or detailed reasoning to support the claim that 6-fold cross-validation is unnecessary or that it provides no additional value compared to other methods. The absence of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the use of 6-fold cross-validation in the paper, questioning the necessity of this method compared to other papers that did not use cross-validation. This feedback highlights a potential weakness in the paper's methodology, prompting the authors to justify the use of 6-fold cross-validation or consider alternative methods. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks depth and actionable guidance.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the necessity of using 6-fold cross-validation in the paper, referencing other papers that did not use cross-validation. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or justify the use of 6-fold cross-validation. The comment implies that the authors should consider alternative methods or provide a rationale for their choice, but it lacks concrete steps or examples. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses the use of 6-fold cross-validation in the paper, questioning the necessity of this method compared to other papers that did not use cross-validation. However, it does not specify which part of the paper discusses the cross-validation or the datasets used, making it weakly grounded. The comment is specific in questioning the reason for using 6-fold cross-validation and suggesting that it is unclear why it is required, but it lacks explicit references to the relevant sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the necessity of using 6-fold cross-validation in the paper, referencing other papers that did not use cross-validation. However, the comment lacks specific examples or detailed reasoning to support the claim that 6-fold cross-validation is unnecessary or that it provides no additional value compared to other methods. The absence of detailed justification or references makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the use of 6-fold cross-validation in the paper, questioning the necessity of this method compared to other papers that did not use cross-validation. This feedback highlights a potential weakness in the paper's methodology, prompting the authors to justify the use of 6-fold cross-validation or consider alternative methods. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address this issue. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks depth and actionable guidance.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment questions the necessity of using 6-fold cross-validation in the paper, referencing other papers that did not use cross-validation. However, it does not provide explicit guidance or suggestions on how the authors"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the presence of combinatorial and heuristic aspects in the proposed framework, particularly in the Non-Ambiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment implies that the authors should provide more information on the impact of these components, it does not explicitly instruct them to do so. The action is somewhat implicit and vague, as the authors need to infer that they should clarify the impact of the heuristic components. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed framework for ReC, specifically mentioning the Non-Ambiguous Query Generation procedure. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it highlights the heuristic components and suggests clarifying their impact. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a highly effective engineering method for ReC, but it also notes the incorporation of combinatorial and heuristic aspects. The comment suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the need for clarification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the effectiveness of the proposed engineering method for ReC but points out the presence of combinatorial and heuristic aspects, particularly in the Non-Ambiguous Query Generation procedure. It suggests that the authors clarify the impact of these heuristic components. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The authors are left to infer the nature of the impact and how to clarify it, making the feedback somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the proposed method's ability to be trained without camera information, specifically questioning the feasibility of performing ray marching without knowing the viewpoint. The reviewer asks how the authors know where the ray comes from, implying a need for clarification or explanation. However, the comment does not provide explicit guidance on how the authors should address this issue or what additional information or analysis is needed. The action is implicit and somewhat vague, as the authors can infer that they need to provide more details or evidence to support their method's applicability without camera information, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Line 223' and references the 'so called \\\"knowledge of CAD model correspondences\\\"', allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the feasibility of the proposed method without camera information and asks how the authors know where the ray comes from, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a concern about the proposed method's ability to be trained without using camera information, specifically questioning the feasibility of performing ray marching without knowing the viewpoint. The reviewer asks how the authors know where the ray comes from, implying a need for clarification or evidence. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the method cannot be trained without camera information. This makes the claim somewhat verifiable, as the authors would need to provide additional information or evidence to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical concern about the proposed method's ability to be trained without using camera information, specifically questioning the feasibility of performing ray marching without knowing the viewpoint. The reviewer asks how the authors know where the ray comes from, implying a need for clarification or evidence. This feedback is valuable as it highlights a potential limitation of the method that the authors should address. However, the comment could be more helpful if it provided suggestions on how to overcome this limitation or offered alternative approaches. Overall, the comment is mostly helpful as it identifies a significant issue that the authors need to consider, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the method ODA, which is used to solve the MOIP problem, has learned to imitate the problem-solving method but does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the improvement in performance and computation speed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific method, ODA, and its application to solve the MOIP problem. It highlights a lack of clarity in explaining how the presented method improves the performance and computation speed compared to using ODA alone. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing what needs to be addressed, namely the lack of clarity in the improvement of performance and computation speed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method ODA, used to solve the MOIP problem, has learned to imitate the problem-solving method but does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the presentation of the method ODA, which is used to solve the MOIP problem. It points out that while the method has learned to imitate the problem-solving method, it does not clearly explain how the presented method improves the performance and computation speed compared to using ODA alone. This feedback is somewhat helpful as it highlights a gap in the explanation that the authors need to address. However, it lacks depth and does not provide specific suggestions or guidance on how to improve the clarity of the presentation. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests two actions for the authors to take: conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method, and conducting experiments on the full dataset instead of the low-resource regime. These actions are clear and specific, providing the authors with explicit guidance on how to improve their draft. The comment is highly actionable as it offers concrete steps for the authors to follow, ensuring they know exactly what changes to make to enhance their experimental evaluation.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lack of experimental results on more datasets\" and provides specific suggestions for improvement, such as conducting experiments on more datasets and evaluating the method on the full dataset instead of the low-resource regime. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of their proposed method. It also recommends evaluating the method on the full dataset rather than the low-resource regime. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more datasets would be beneficial or that the current evaluation is insufficient. The suggestion is somewhat verifiable as it offers a clear direction for improvement but requires additional justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of experimental results on more datasets. It provides a clear and actionable suggestion for the authors to conduct additional experiments on more datasets to provide a more comprehensive evaluation of their proposed method. Additionally, the comment recommends evaluating the method on the full dataset rather than the low-resource regime, which could further enhance the robustness of the evaluation. This feedback is clear and provides the authors with a specific direction for improving their draft, making it mostly helpful. However, it could be more helpful if it included examples of other datasets that could be used or further guidance on how to conduct these additional experiments. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about how the generic argument task and the random argument task support the authors\\' claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment identifies areas of concern, it does not provide explicit guidance or suggestions on how the authors might address these issues. The feedback lacks concrete steps or examples of what changes could be made to improve clarity and coherence. As a result, the authors are left without a clear understanding of how to enhance their draft based on this comment. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the clarity of the generic argument task and the random argument task, as well as the dataset transformation and experimental setup. However, it does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in pointing out the lack of clarity and the cumbersome nature of the dataset transformation and experimental setup, but it does not provide detailed guidance on how to improve these aspects. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generic argument task and the random argument task do not clearly support the authors\\' claims. It also states that the dataset transformation and experimental setup are cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to substantiate these claims, making it difficult for the authors to understand and address the issues effectively. The absence of supporting evidence or references leaves the claim somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a lack of clarity in the paper regarding how the generic argument task and the random argument task support the authors' claims. It also notes that the dataset transformation and experimental setup are cumbersome and unclear. While the comment highlights areas of concern, it does not provide specific suggestions or actionable steps for the authors to improve the clarity and coherence of their work. The feedback lacks depth and detail, making it somewhat helpful as it points out weaknesses but does not offer concrete guidance for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider using tabular data as a modality, which is another popular form of multi-modal data. While the comment implies that this could be an interesting direction, it does not explicitly instruct the authors to include this aspect in their work. The suggestion is vague and lacks concrete details on how to implement this idea, such as which specific aspects of the model should be adapted for tabular data. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests exploring the use of tabular data as a modality, which is another popular form of multi-modal data. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors might infer that it relates to the discussion of multi-modal data, but this inference is not explicit. The comment is specific in suggesting an interesting direction for the model, but it lacks grounding as it does not point to a specific part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that tabular data is another popular form of multi-modal data and that it would be interesting to explore how the model works for tabular data. However, it does not provide any specific reasoning, examples, or references to support why this is a relevant or interesting direction. The claim lacks depth and does not offer a clear rationale for why the authors should consider this aspect. As a result, the comment is considered unverifiable, as it does not provide sufficient evidence or justification for the authors to understand or address the suggestion.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors consider using tabular data as a modality, which is another popular form of multi-modal data. While the comment identifies an interesting direction for the model, it does not provide specific guidance or suggestions on how to incorporate tabular data or what aspects of the model might be adapted for this purpose. The feedback is somewhat helpful as it offers a potential area for exploration but lacks depth and actionable advice, leaving the authors with a general idea but no clear path forward. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a clear and explicit action for the authors to take: \"add more analysis about the multilingual alignment of entity representations\" and suggests that \"it would be better to have visualizations or case studies for different types of languages such as language family.\" Additionally, it raises a specific question about the alignment of entities from low-resourced languages with high-resourced ones. The comment is concrete, as it specifies what additional analysis and visualizations are needed, and it provides a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the analysis of entity representations, specifically the alignment of entity representations across different languages. It suggests adding more analysis on multilingual alignment and provides specific suggestions for visualizations or case studies to illustrate this alignment for different language families. Additionally, it raises a question about the alignment of entities from low-resourced languages with high-resourced ones. This feedback is fully grounded as it explicitly mentions the \"language-agnostic characters of entity representations\" and the specific areas needing improvement. It is also specific because it provides clear guidance on what additional analysis and visualizations are needed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper has weak analysis on the alignment of entity representations, particularly in the context of multilingual alignment. It suggests adding more analysis and provides specific suggestions for visualizations or case studies to illustrate this alignment for different language families. The comment also raises a question about the alignment of entities from low-resourced languages with high-resourced ones. While the comment provides a clear direction for improvement, it lacks specific references or detailed examples to fully substantiate the claim. The suggestion for visualizations or case studies is a logical extension of the critique, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of weakness in the paper, namely the analysis of the alignment of entity representations across different languages. It suggests that the authors should provide more analysis on multilingual alignment and recommends the inclusion of visualizations or case studies to illustrate this alignment for different language families. Additionally, it raises a question about the alignment of entities from low-resourced languages with high-resourced ones, which is a relevant consideration for the paper. The feedback is clear and actionable, providing the authors with specific steps to improve their analysis and presentation. However, it could be more helpful if it offered additional guidance or examples on how to implement these suggestions. Overall, the comment is mostly helpful, as it effectively directs the authors to enhance their draft by addressing a critical gap in the analysis.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly points out two issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This provides clear and direct actions for the authors to take, such as removing duplicates and ensuring that all publications include their respective venues and years. The feedback is explicit and concrete, giving the authors a clear path to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies specific issues with the references list, mentioning duplicates and missing publication venues and years. However, it does not specify which references are duplicates or which papers lack publication details, making it weakly grounded. The comment is specific in detailing the issues with the references, but without explicit references or sections, the authors may find it challenging to pinpoint the exact parts needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that the publication venues and/or years of many papers are missing. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without specific references or detailed explanations, the authors may find it difficult to understand the basis of the critique and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and/or years for many papers. This feedback is clear and actionable, providing the authors with a straightforward list of tasks to address. By correcting these issues, the authors can improve the accuracy and completeness of their reference list, which is crucial for academic integrity and credibility. However, the comment could be more helpful if it offered suggestions on how to avoid duplicates or provided tips on how to ensure publication details are included in future references. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the theoretical analysis in Theorem 1 is unclear and weak, and it specifically points out the lack of clarity regarding the error bound. It also suggests that the authors need to analyze and compare their theoretical results to other comparable methods. This feedback provides a clear and direct action for the authors to take, which is to clarify the theoretical analysis and compare it with other methods. The comment is explicit and concrete, offering a clear path for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, particularly the lack of clarity regarding the error bound and the need for comparison with other methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that it is unclear what the error bound means. It provides a clear and actionable suggestion for the authors to analyze and compare their theoretical results with other comparable methods. This feedback is valuable as it directs the authors to a specific area of improvement, offering a clear path for enhancing the clarity and robustness of their theoretical analysis. However, the comment could be more helpful if it provided additional guidance on how to analyze and compare the results or suggested specific methods for doing so. Overall, the comment is mostly helpful, as it effectively highlights a critical area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two issues: first, it questions why explicit methods perform better than implicit methods on locomotion tasks, and second, it points out that the pseudo-code of the proposed method is missing. The first part of the comment suggests that the authors should provide an explanation for the observed performance difference, but it does not offer specific guidance on how to address this issue. The second part of the comment is explicit in stating that the pseudo-code is missing, but it does not provide any suggestions on how to include it or why it is necessary. The authors are left with a clear action to provide an explanation for the performance difference and to include the missing pseudo-code, but the feedback lacks detailed guidance on how to execute these actions. Therefore, the comment is somewhat actionable, as it identifies specific areas for improvement but lacks detailed instructions on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two specific issues: first, it questions why explicit methods perform better than implicit methods on locomotion tasks, and second, it points out that the pseudo-code of the proposed method is missing. The first part of the comment is fully grounded as it references specific tasks and methods, allowing the authors to accurately identify the areas being addressed. The second part is also fully grounded, as it explicitly mentions the missing pseudo-code, which is a critical component for understanding and replicating the proposed method. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two issues: first, it questions why explicit methods perform better than implicit methods on locomotion tasks, and second, it points out that the pseudo-code of the proposed method is missing. The first part of the comment is a claim that requires justification, as it suggests a potential issue with the performance of the methods. The second part is a factual statement about the absence of pseudo-code, which is verifiable. However, the comment lacks specific reasoning or evidence to support the claim about the performance difference between explicit and implicit methods. Therefore, the comment is mostly verifiable, as it provides some support for the claim but could be strengthened with additional justification or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment raises two important points. First, it questions why explicit methods perform better than implicit methods on locomotion tasks, which is a critical aspect of the paper\\'s methodology and results. This question prompts the authors to provide a detailed explanation or analysis of this observation, which could enhance the paper\\'s understanding and impact. Second, the comment points out that the pseudo-code of the proposed method is missing, which is essential for replicating and verifying the results. This feedback is actionable and provides clear guidance for the authors to include the missing pseudo-code, ensuring transparency and reproducibility of their work. Overall, the comment is mostly helpful as it identifies specific areas for improvement and offers clear suggestions for enhancing the paper\\'s clarity and completeness. However, it could be more helpful if it provided additional context or guidance on how to address the performance comparison issue. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning that the model can work well for various image noise types. While the comment implies that the authors should provide results for other types of noise, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their results to include other types of noise. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper\" and \"images corrupted using Gaussian noise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model's ability to handle various image noise types. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model\\'s ability to handle various image noise types. This is a logical inquiry seeking clarification on the authors\\' rationale. However, it does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the reason for only showing results on images corrupted with Gaussian noise, despite mentioning the model\\'s ability to handle various image noise types. This feedback is somewhat helpful as it prompts the authors to clarify their experimental setup and potentially expand their results to include other types of noise. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as recommending additional types of noise to test or how to present the results. While it identifies a potential area for improvement, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. While the comment implies that this visualization would be beneficial, it does not explicitly instruct the authors to perform this task or provide guidance on how to create the visualization. The action is implicit and somewhat vague, as the authors need to infer that they should include a visualization and how to create it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. The authors can infer that it pertains to the motivation or discussion of the research, but this inference is not explicit. The comment is specific in its suggestion to visualize the effect, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. However, it does not provide any specific evidence, reasoning, or examples to support why this visualization would be beneficial or how it would enhance the paper. The claim lacks detailed justification or references to existing literature, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should visualize the effect of the gradual decline in performance of existing PU learning methods as the dimensionality of the data increases. This is a constructive suggestion that could enhance the paper by providing a clearer understanding of the research motivation. However, the comment lacks specific guidance on how to create the visualization or what aspects should be included. While it identifies a potential improvement, the feedback could be more actionable with additional details. Therefore, the comment is somewhat helpful, as it provides a direction for enhancement but lacks full comprehensiveness.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a convoluted description of results and suggests that the authors need to simplify their presentation. It also provides specific suggestions, such as referencing related work on speaker-listener communication from a teachability perspective and checking for useful communication. The comment includes links to external references, which can guide the authors in addressing the issue. However, while the suggestions are concrete, they do not explicitly instruct the authors to make these changes themselves. The authors are left with a clear direction but without direct instructions on how to implement the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the convoluted description of results, specifically mentioning the phrase \"less likely to produce less easier to teach and less structured languages when no listener gets reset.\" This provides some grounding as it refers to a specific part of the paper, but it does not explicitly mention which section or figure this description is found in. The comment is specific in suggesting that the authors simplify their presentation and provides references to related work. However, without explicit references to sections or figures, the comment is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the convoluted description of results, suggesting that it could be simplified. It provides specific examples and references to related work, such as [1] and [2], which can help the authors understand the context and potential improvements. The comment also questions the differences in figures and suggests checking for useful communication, which adds depth to the critique. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Overall, the comment is mostly verifiable due to the references and suggestions provided, but it lacks some specific details that would make it fully verifiable. Therefore, it aligns with a score of 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the convoluted description of results, providing a clear example of where the description is unnecessarily complex. It suggests simplifying the presentation and offers a related idea from the literature, referencing specific works for further exploration. The comment also questions the differences in figures and suggests checking for useful communication, which provides actionable feedback for the authors to improve their draft. However, the comment could be more helpful if it included specific suggestions on how to simplify the presentation or how to address the issues with the figures. Overall, the comment is mostly helpful as it directs the authors to areas for improvement and provides some guidance, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the approximation error should be more clearly defined by providing a mathematical characterization. While the comment implies that the authors should clarify the definition of the approximation error, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to provide a mathematical characterization, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the definition of the approximation error, which is somewhat vague and ambiguous. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment suggests providing a mathematical characterization to clarify the definition, but it does not specify what aspects of the mathematical characterization are needed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the definition of the approximation error is ambiguous and proposes providing a mathematical characterization to clarify it. However, the comment does not provide specific examples or references to support the claim that the definition is ambiguous. The suggestion to provide a mathematical characterization is logical, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the definition of the approximation error, noting that it is unclear unless the values are seen in the table. It suggests providing a mathematical characterization to clarify the definition. This feedback is clear and actionable, as it directs the authors to improve the clarity and precision of their definition. However, it could be more helpful if it provided specific examples or guidance on how to develop a mathematical characterization. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the proposed model: the slow dynamics due to the reassignment probability being 1/n, and the simplicity of the evolution model as it only changes edges associated with the 1 node changing cluster on average. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The feedback lacks concrete suggestions or steps for improvement, leaving the authors uncertain about how to enhance their model. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific aspects of the proposed model, such as the reassignment probability and the simplicity of the evolution model. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing the issues with the model, such as the slow dynamics and the simplicity of the evolution model. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model produces only 1 node changing cluster per time step on average because the reassignment probability is 1/n, which allows for very slow dynamics. It also notes that the evolution model is simplistic as it only changes edges associated with the 1 node changing cluster on average. While the comment provides a logical explanation for the slow dynamics and the simplicity of the model, it lacks specific references or examples to fully substantiate the claim. The reasoning is clear but could be strengthened with additional evidence or references. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific issues with the proposed model: the slow dynamics due to the reassignment probability being 1/n, and the simplicity of the evolution model as it only changes edges associated with the 1 node changing cluster on average. This feedback is clear and actionable, providing the authors with concrete areas to address and improve upon. By highlighting these weaknesses, the comment offers valuable guidance for enhancing the model's dynamics and complexity. However, it could be more helpful if it suggested potential solutions or ways to address these issues. Overall, the comment is mostly helpful, as it effectively directs the authors' attention to critical areas for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to add missing details about the division of the dataset into training and test sets, including the numbers involved and the method used for division (e.g., random or other considerations). This provides a clear and direct action for the authors to take, making the comment highly actionable. The authors know exactly what information needs to be added to improve their draft, ensuring a high level of actionability.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"division to train and test sets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be added, such as the numbers and the method used for division. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there are missing details about the division of the dataset into training and test sets, including the numbers and the method used for division. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the draft could be improved by highlighting the missing details about the division of the dataset into training and test sets. It specifies that the numbers and the method used for division should be included, providing clear guidance on what information is needed to enhance the transparency and reproducibility of the study. This feedback is actionable and helps the authors understand how to improve their draft, making it mostly helpful. However, it could be more helpful if it provided examples of how to present this information or suggested specific methods for division. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions that the long-text input could restrict the scalability of the framework. While the comment identifies an issue, it does not provide explicit guidance or suggestions on how the authors might address these concerns. The action is implicit and vague, as the authors are left to infer that they need to explore alternative approaches or methods to mitigate the need for human labor and optimize the textual format. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to long-text input. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the current approach and the potential scalability issue, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and the lack of an optimal textual format for policy learning. It also mentions the potential restriction of scalability due to long-text input. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of detailed evidence or justification makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant challenge in the current approach, which is the need for human labor in building text descriptions for each task. It also points out the lack of an optimal textual format for policy learning, which varies from task to task and model to model. Additionally, the comment raises a concern about the scalability of the framework due to the use of long-text input. While the comment highlights important issues, it lacks specific suggestions or actionable steps for the authors to address these challenges. The feedback is somewhat helpful as it provides insight into potential areas for improvement but does not offer detailed guidance or concrete solutions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what steps they could take to prove new theoretical results. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the claim that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, it does not specify which part of the paper this claim pertains to, such as the methodology, results, or discussion sections. Without explicit references to specific sections or elements, the authors may find it challenging to identify the exact areas needing attention. Additionally, the comment lacks specificity regarding what new theoretical results are expected or how the authors might prove them. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work does not prove any new theoretical results despite using a novel type of loss in a specific setting. However, the comment lacks specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it difficult to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out a potential issue with the paper's contribution, specifically that it does not prove any new theoretical results despite using a novel type of loss in a specific setting. This feedback is somewhat helpful as it identifies a gap in the paper's contribution, which could be important for the authors to address. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what new theoretical results could be explored. To be more helpful, the comment could include examples of theoretical results that could be developed or suggestions on how to prove new theoretical contributions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment implies that the authors should provide additional evidence, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more evidence. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. However, the comment does not specify which part of the paper this hypothesis relates to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact area needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point presents a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, suggesting that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment provides a logical reasoning for the hypothesis, it lacks specific examples or references to support the claim. The suggestion to provide more evidence is a request for additional information, which is not inherently verifiable. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the dataset, proposing that the trivial part consists of images with highly consistent object poses or typical poses in the center, while the impossible part might include ambiguous labels or atypical poses. The reviewer also questions whether the authors could provide more evidence to support or refute this hypothesis. While the comment identifies a potential area for exploration, it lacks specific guidance or suggestions on how the authors might gather or present this evidence. The feedback is somewhat helpful as it prompts the authors to consider a hypothesis and suggests a direction for further investigation, but it could be more actionable with more detailed guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the model\\'s testing on other tasks in the bAbI dataset, given that it was only tested on a single supporting fact dataset (Task 1). While the comment implies that the authors should consider testing the model on other tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to other tasks. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model\\'s testing on other tasks in the bAbI dataset, specifically mentioning Task 1 of bAbI. This provides some grounding as it allows the authors to identify the part of the paper being addressed, which is the testing methodology or results. However, the comment does not specify what needs to be addressed or improved in terms of testing on other tasks. It lacks specificity regarding the details of the testing or the potential issues that might arise from only testing on a single supporting fact dataset. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the model\\'s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. However, it does not provide any evidence, reasoning, or references to support the claim that only Task 1 was tested or that testing on other tasks is necessary. The comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model\\'s testing on other tasks in the bAbI dataset, specifically mentioning Task 1. While it identifies a potential area for improvement, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. It does not offer any insights into why testing on other tasks might be important or what benefits it could bring. As a result, the comment is somewhat helpful, as it points out a potential area for further exploration but does not provide actionable feedback for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3.2 is difficult to follow and recommends that the authors improve it by providing more illustrations and examples. While the action is explicit, the comment does not specify which parts of the section are particularly confusing or how the illustrations and examples should be incorporated. This lack of detail makes the action somewhat vague, as the authors know they need to improve the section but may not know exactly how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Sec. 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the section is difficult to follow and recommending the inclusion of more illustrations and examples. This provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that Section 3.2 is difficult to follow and recommends improvements by providing more illustrations and examples. However, the comment does not provide any specific examples or detailed reasoning to support why the section is unclear or how the suggested improvements would enhance understanding. This lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the nature of the issues and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with Section 3.2, noting that it is difficult to follow. It provides a clear suggestion for improvement by recommending the inclusion of more illustrations and examples to enhance understanding. This feedback is actionable and provides a concrete direction for the authors to improve the clarity of their work. However, the comment could be more helpful if it specified which parts of Section 3.2 are particularly confusing or suggested specific types of illustrations or examples that could be beneficial. Despite this, the feedback is mostly helpful as it guides the authors toward a clear and actionable improvement. Therefore, the comment aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. It points out that this calculation could be time-consuming, especially for problems with many objectives. The reviewer suggests that this might make LaMOO impractical for such problems. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze and possibly optimize the time complexity of the algorithm. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Time Complexity\" and \"LaMOO,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the time complexity of the proposed algorithm, particularly the calculation of the hypervolume in each step of LaMOO, and raises a concern about its practicality for problems with many objectives. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the time complexity of the proposed algorithm, specifically regarding the calculation of the hypervolume in each step of LaMOO. The reviewer questions whether this could make LaMOO impractical for problems with many objectives. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the calculation of the hypervolume is time-consuming or impractical. The reasoning is based on general observations about the complexity of the calculation, but without detailed evidence or analysis, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the time complexity of the proposed algorithm, specifically focusing on the calculation of the hypervolume in each step of LaMOO. It points out that this calculation could be time-consuming, especially for problems with many objectives, and questions whether LaMOO would become impractical for such problems. This feedback is valuable as it highlights a potential limitation of the algorithm that the authors should consider. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as proposing optimizations or alternative approaches to improve efficiency. Overall, the comment is mostly helpful as it identifies a significant area for improvement but lacks detailed guidance on how to resolve the issue.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the dataset used in the experiments is small and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it labels this as a minor issue and does not provide specific guidance on how to address this concern. The authors are left with a general suggestion but without concrete steps or examples on how to implement it. The action is implicit and somewhat vague, as it lacks detailed instructions on how to improve the dataset or what specific results should be included. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the small dataset used in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. However, it does not specify which part of the paper discusses the dataset or the experiments, making it weakly grounded. The comment is specific in suggesting a potential improvement, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset used in the experiments is small and proposes that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide specific evidence or reasoning to support the claim that the dataset size is a significant issue or that results on larger datasets would be more convincing. The suggestion is vague and lacks detailed justification, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the use of small datasets in the experiments and suggests that it would be more convincing to see results on medium or even large datasets, such as ImageNet. This feedback is somewhat helpful as it identifies a potential area for improvement in terms of dataset size and suggests a specific benchmark dataset to consider. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or what specific results should be included. The authors are left with a general direction but without comprehensive instructions on how to enhance the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several issues regarding the limitations of evolutionary methods and suggests that the title is too generic and vague. It also questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The feedback is somewhat actionable as it points out areas for improvement but lacks concrete suggestions on how to implement them. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of evolutionary methods and suggests that the title is too generic and vague. It also questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the limitations section or the title, but this is not explicit. The comment is specific in its critique of the title and the concept of \"brittle convergence properties,\" but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the limitations of evolutionary methods and suggests that the title is too generic and vague. It questions the meaning of \"brittle convergence properties\" and encourages the authors to be more precise and honest in their critique. However, the comment lacks specific examples or references to support the claim about the limitations of evolutionary methods or the meaning of \"brittle convergence properties.\" The suggestion to be more precise and honest is a general observation without detailed evidence or reasoning, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's discussion of evolutionary methods, suggesting that there are deeper aspects to consider regarding leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and vague, recommending that the authors be more precise and honest in their critique. The comment provides a clear direction for improvement by highlighting specific areas that need further exploration and clarification. However, it could be more helpful if it offered specific suggestions or examples of how to address these issues. Overall, the comment is mostly helpful as it guides the authors towards enhancing the depth and clarity of their work, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. While the comment does not explicitly instruct the authors to provide this information, it clearly indicates what needs to be addressed. The authors can infer that they should include details on these aspects in their paper. However, the comment lacks specific guidance on how to present this information, such as suggesting the inclusion of a detailed explanation or example. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the synthesis process and edge handling, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of questions seeking clarification on specific aspects of the paper, such as the synthesis of the focal stack and the handling of edges with depth discontinuities. These questions are not claims but rather requests for information or clarification. Therefore, they do not fit the criteria for a claim and are classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises important questions about the synthesis of the focal stack, the forward model of using a defocus map and an image to synthesize a defocused image, and the handling of edges where depth discontinuities occur. These are critical aspects that could significantly impact the understanding and evaluation of the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it lacks actionable feedback, making it somewhat helpful. The authors are given a direction to explore but without detailed instructions on how to proceed, limiting the comment\\'s usefulness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a comparison of their approach\\'s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other models. It also points out a minor issue with the low jailbreaking percentage for certain LLMs. While the suggestion to include a comparison is explicit, it does not provide detailed guidance on how to conduct this comparison or which specific LLMs to focus on. The comment also highlights a minor issue with the jailbreaking percentage, but it does not offer suggestions on how to address this issue. Therefore, the comment is mostly actionable, as it provides a clear direction for improvement but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the low jailbreaking percentage for certain LLMs, providing clear guidance on what needs to be addressed. Additionally, the suggestion to include a comparison of the approach\\'s transferability to other LLMs is specific and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a comparison of their approach\\'s transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other models. It also points out a minor issue with the low jailbreaking percentage for certain LLMs. While the suggestion to include a comparison is logical and could enhance the paper, the comment lacks specific examples or references to support the claim about the low jailbreaking percentage. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the issue with the jailbreaking percentage. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides two actionable suggestions. First, it suggests that the authors should include a comparison of their approach's transferability to other LLMs, specifically mentioning the ability to craft adversarial prompts and transfer them to other models. This feedback is clear and provides a specific direction for enhancing the paper's scope and impact. Second, it points out a minor issue with the low jailbreaking percentage for certain LLMs, which could be addressed by the authors. While the comment does not offer detailed guidance on how to improve the jailbreaking percentage, it highlights an area that needs attention. Overall, the comment is mostly helpful as it provides clear and actionable feedback that can significantly improve the draft. However, it could be more helpful with additional guidance on the jailbreaking issue. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it implies that the authors should provide a more detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the distinction between these concepts. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, which is the introduction of the importance of unsupervised feature selection from a diffusion perspective. It also raises a question about the difference between similarity and exit times in nature. However, it does not specify which part of the paper this discussion is in, making it weakly grounded. The comment is specific in its request for a detailed explanation of the difference between similarity and exit times, providing a clear direction for the authors to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the difference between similarity and exit times in the context of feature selection from a diffusion perspective. While it identifies a potential area of confusion, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their explanation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. While the comment implies that the authors should consider these limitations, it does not provide explicit guidance or suggestions on how to address them. The action is implicit and somewhat vague, as the authors need to infer that they should explore the capabilities of the framework in different contexts. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, such as a specific section or discussion. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. However, it does not provide any supporting evidence, reasoning, or references to substantiate this inquiry. The comment lacks specific examples or references to external works that might address this issue, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the unified framework, specifically whether it can handle general POMDP formulations, including continuous or infinite spaces. This is a relevant and insightful inquiry that prompts the authors to consider the scope and applicability of their framework. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or explore these areas. While it identifies an important aspect for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the dataset creation is optional and mentions that the Kialo dataset is well-studied and cleaner than the dataset created in the paper. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the created dataset can be additional data to learn from, but it does not offer guidance on how the authors might use this information or whether it should be included in the paper. As a result, the authors are left without a clear understanding of what actions to take based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the creation of the dataset, specifically mentioning the Kialo dataset and its cleanliness compared to the dataset created in the paper. However, it does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in pointing out the comparison between the Kialo dataset and the one created in the paper, suggesting that the latter can be additional data to learn from. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point compares the dataset created in the paper with the Kialo dataset, suggesting that the latter is cleaner and more suitable for the authors\\' needs. However, the comment does not provide specific evidence or reasoning to support why the Kialo dataset is more suitable or cleaner. The mention of \"no automatic processes exist to construct it\" provides some context but does not substantiate the claim. Without detailed justification or examples, the claim remains somewhat verifiable, as it lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the creation of the dataset is optional and highlights the availability of the Kialo dataset, which is well-studied and cleaner than the dataset created in the paper. It suggests that the created dataset can be additional data to learn from, which is a useful observation. However, the comment lacks actionable guidance or specific suggestions on how the authors might use this information to improve their work. While it provides some insight into the dataset creation process, it does not offer detailed feedback or constructive advice that could help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable suggestions.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges that the creation of the dataset is optional and mentions the Kialo dataset as a well-studied and cleaner alternative. However, it does not provide any explicit or implicit actions for the authors to take regarding the dataset creation. The comment suggests that the created dataset can be additional data to learn from, but it does not offer guidance on how the authors might use this information or whether it should be included in the paper. As a result, the authors are left without a clear understanding of what actions to take based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the creation of the dataset, mentioning the Kialo dataset as a well-studied and cleaner alternative. However, it does not specify which part of the paper discusses the dataset creation, making it weakly grounded. The comment is specific in pointing out the comparison between the Kialo dataset and the one created in the paper, suggesting that the latter can be additional data to learn from. However, without explicit references to sections or specific details, the authors may find it challenging to pinpoint the exact area needing improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point compares the dataset created in the paper with the Kialo dataset, suggesting that the latter is cleaner and more suitable for the authors\\' needs. However, the comment lacks specific evidence or reasoning to support why the Kialo dataset is more suitable or cleaner. The mention of \"no automatic processes exist to construct it\" provides some context but does not substantiate the claim. Without detailed justification or examples, the claim remains somewhat verifiable, as it lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the creation of the dataset is optional and highlights the Kialo dataset as a well-studied and cleaner alternative. It suggests that the created dataset can be additional data to learn from, which is a useful observation. However, the comment lacks actionable guidance or specific suggestions on"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. The comment explicitly requests that the authors address these weaknesses, providing a clear and direct action for improvement. It also includes specific suggestions on what needs to be added or changed, making the feedback highly actionable. The authors are given a clear path to follow in order to enhance their draft, ensuring that they know exactly what steps to take to improve it.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the number of tasks in the experiments and suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. The authors can infer that it relates to the experimental section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, such as the number of tasks and the presentation of results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the limited number of tasks in the experiments and suggests that the authors should include several tasks and present sequential results in terms of tasks learned rather than epochs. However, the comment does not provide specific examples or references to support the claim that the number of tasks is insufficient or that sequential results are necessary. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the limited number of tasks in the experiments. It suggests that the authors should include several tasks (at least 10) and present sequential results in terms of tasks learned rather than epochs. This feedback is clear and actionable, providing the authors with a concrete direction for improvement. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their experimental results. However, the comment could be more helpful if it included specific examples or references to support the claim that more tasks are necessary. Overall, the comment is mostly helpful as it guides the authors towards a significant enhancement of their draft, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about setting the parameter S, but it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or action for the authors to take, such as recommending a specific method or approach to determine the parameter S. Without any actionable advice or direction, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about setting the parameter S, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper this comment pertains to, making it weakly grounded. Additionally, the comment does not provide specific guidance on how to address the issue of setting the parameter S, leaving the authors without clear direction. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a concern about setting the parameter S, but it does not provide any specific reasoning, examples, or references to support why this is a problem or how it affects the paper. Without additional context or evidence, the authors may find it challenging to understand the significance of this issue and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue related to setting the parameter S, which is a critical aspect of the paper. However, it does not provide any suggestions or guidance on how the authors might address this problem or improve their approach. Without actionable advice or specific recommendations, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not offer meaningful feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics. While the comment implies that the authors should consider including a human evaluation, it does not explicitly instruct them to do so or provide guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should include a human evaluation and understand how to integrate it into their work. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics. However, it does not specify which part of the paper this evaluation should be included in or how it should be integrated. The authors can infer that it relates to the evaluation section, but the lack of specific guidance makes it difficult to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics. While the comment implies that automatic metrics can be misleading, it does not provide specific examples or references to support this claim. The reasoning is based on a general observation about the limitations of automatic metrics, but without detailed evidence or examples, the claim remains somewhat vague. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some justification but lacks detailed support.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic evaluation metrics. This is a valid point, as automatic metrics can be misleading and do not always align with human perception. However, the comment lacks specificity and does not provide guidance on how to conduct a human evaluation or what aspects should be considered. While it highlights an important area for improvement, the feedback is incomplete and does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention that the experimental setup borrowed from [2] is only semi-real, as multi-node seed cascades are artificially created by merging single-node seed cascades. This provides a clear and direct action for the authors to take, ensuring that they address this issue in their draft. The comment is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental setup borrowed from [2],\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the setup is only semi-real due to the artificial creation of multi-node seed cascades by merging single-node seed cascades. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This claim is somewhat verifiable as it provides a logical explanation for why the setup is not fully realistic. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This feedback is clear and actionable, as it provides a direct suggestion for the authors to clarify this point in their draft. By addressing this issue, the authors can enhance the transparency and credibility of their experimental methodology. However, the comment could be more helpful if it offered additional guidance on how to present this information or suggested ways to mitigate the limitations of the semi-real setup. Overall, the comment is mostly helpful as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on state-of-the-art generative models like GPT. While the comment highlights these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their dataset and model coverage to include other biases and state-of-the-art generative models. However, the comment lacks concrete details on how to implement these changes, such as suggesting specific datasets or models to include. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the datasets and models used in the paper, specifically mentioning the bias benchmarks that only assess gender, race, and religion. It also points out the absence of assessments on other important biases and state-of-the-art generative models like GPT. However, the comment does not specify which part of the paper discusses these limitations, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in detailing what is missing, such as other biases and state-of-the-art models, but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are not measured. It also mentions the absence of assessments on state-of-the-art generative models like GPT. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the significance of these omissions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two specific areas where the paper could be improved: the limited datasets and models, and the absence of assessments on state-of-the-art generative models like GPT. By pointing out these gaps, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered suggestions on how to expand the dataset or model coverage or provided examples of other biases and datasets that could be included. Overall, the comment is mostly helpful as it directs the authors' attention to important areas for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the sensitivity of the method to hyperparameters, specifically mentioning the need to perform a careful hyperparameter search to find a proper value for $\\alpha$. While the comment implies that the authors should conduct a thorough hyperparameter search, it does not provide explicit guidance on how to perform this search or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sensitivity of the method to hyperparameters, specifically mentioning the need to perform a careful hyperparameter search to find a proper value for $\\alpha$. However, it does not specify which part of the paper discusses the method or the hyperparameters, making it weakly grounded. The comment is specific in identifying the need for a careful hyperparameter search, but without explicit references to the paper, the authors may struggle to pinpoint the exact section that requires attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters, specifically mentioning the need to perform a careful hyperparameter search to find a proper value for \\u03b1. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method's sensitivity to hyperparameters, specifically mentioning the need for a careful hyperparameter search to find a proper value for \\u03b1. This feedback is somewhat helpful as it highlights a critical aspect that the authors should consider when applying the method to new problems. However, the comment lacks specific guidance on how to conduct this search or what criteria to use for determining the proper value of \\u03b1. To be more helpful, the comment could provide additional details or examples on how to approach this task. Therefore, the comment is rated as somewhat helpful, as it points out a potential area for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies specific issues with Figure 3, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. However, it does not provide explicit guidance on how to address these issues or suggest specific changes to make the figure more understandable. The authors are left to infer that they need to clarify the workflow, improve the captions, and possibly rework the representation of communication modes, but the comment lacks concrete steps or examples. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issues with the figure, noting that the workflow and captions are unclear and that the representation of communication modes is confusing. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow, captions, and the representation of communication modes. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that the workflow, captions, and representation of communication modes are unclear. This feedback is clear and actionable, as it directs the authors to focus on improving the clarity of their figure, which is crucial for effectively communicating their workflow and findings. However, the comment could be more helpful if it provided suggestions on how to enhance the figure, such as recommending specific changes to the layout or labeling. Overall, the comment is mostly helpful as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. While it identifies a specific area of confusion, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should clarify or address this issue, leaving the authors without a clear direction for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. This makes it difficult for the authors to pinpoint the exact area needing clarification. Additionally, the comment lacks specificity in detailing what aspect of the \"learned [MASK] embedding\" is unclear or how it is used in the SSL pre-training stage. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. However, it does not provide any supporting evidence, reasoning, or references to clarify what is unclear or how this term is used in the context of the paper. Without additional context or explanation, the comment lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the meaning of 'learned [MASK] embedding' in the SSL pre-training stage of the proposed method. While it identifies a specific area of confusion, it does not provide any additional context or suggestions for clarification. The comment lacks actionable feedback or guidance on how the authors might address this issue or improve the clarity of their explanation. As a result, the comment is not helpful, as it does not offer the authors a clear path to enhance their draft. Therefore, it aligns with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the reported results are partially derivative, as they extend to hyper-networks the results already presented in the literature for standard networks. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what steps they should consider to make their results more original. Without specific suggestions or directions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, as they extend to hyper-networks the results already presented in the literature for standard networks. However, it does not specify which part of the paper these results are reported in or which specific results are being discussed. This lack of grounding makes it difficult for the authors to identify the exact sections that need revision. The comment is specific in pointing out the issue of derivative results, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the reported results are partially derivative, as they extend to hyper-networks the results already presented in the literature for standard networks. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported results, suggesting that they may be partially derivative, as they extend to hyper-networks the results already presented in the literature for standard networks. This feedback is somewhat helpful as it points out a potential area for improvement, but it lacks specificity and does not provide detailed guidance on how the authors might address this concern. Without additional context or suggestions for how to differentiate the results or provide original contributions, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that Figure 3 is difficult to read, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the figure's readability, such as suggesting changes in font size, color contrast, or layout. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Figure 3,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the figure is \"very hard to read anything on the figure,\" which is a clear and specific description of the problem. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a factual observation about the difficulty of reading Figure 3, which is a claim that can be verified by the authors themselves. However, the comment does not provide any reasoning, examples, or references to support why the figure is hard to read or how it could be improved. Without additional context or evidence, the claim is difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides a claim but lacks sufficient justification or evidence to fully support it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is difficult to read. However, it does not provide any suggestions or guidance on how the authors might improve the figure's readability or what specific elements are causing the difficulty. Without actionable feedback or detailed advice, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it highlights a problem but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment consists of two parts. First, it points out that the GAT is trained with the whole model, which is a specific observation that the authors may need to address. Second, it suggests that the paper needs to be reviewed by an English native speaker and that some sentences need rewriting to improve clarity. While the first part is somewhat explicit, it lacks concrete guidance on how to address the issue of training the GAT with the whole model. The second part is more explicit, as it provides a clear action for the authors to take (reviewing by an English native speaker) and a specific suggestion for improving clarity (rewriting sentences). However, the comment could be more actionable if it provided examples of sentences that need rewriting or detailed guidance on how to improve clarity. Overall, the comment is mostly actionable, as it provides some direction but could be more specific in its suggestions.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses two separate issues: the training of the GAT with the whole model and the need for English language review and sentence rewriting for clarity. However, it does not specify which part of the paper discusses the training of the GAT with the whole model, making it weakly grounded. The comment is specific about the need for English language review and sentence rewriting, but it does not provide detailed guidance on which sentences need rewriting. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two parts. The first part claims that the GAT is trained with the whole model, which is a factual statement that does not require verification. The second part suggests that the paper needs to be reviewed by an English native speaker and that some sentences need rewriting for clarity. This part is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or detailed guidance on which sentences need rewriting. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the training of the GAT with the whole model and the need for English language review and sentence rewriting for clarity. While the comment points out these areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. For example, it does not specify which sentences need rewriting or provide examples of how to improve clarity. This makes the feedback somewhat helpful, as it highlights areas for improvement but does not fully guide the authors in making those improvements. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two separate comments. The first comment suggests replacing the expression `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which is a direct and explicit action. The second comment questions the choice of SGD learning rate, noting that it is unclear why the value of 0.1 was chosen. This part of the comment is implicit, as it does not provide specific guidance on how to justify the choice of the learning rate. However, it does highlight a potential area for clarification. Overall, the review point is mostly actionable, as it provides explicit guidance on one action and suggests an area for further explanation on another. Therefore, the comment aligns with a score of 4.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies the issues with the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda` and questions the justification behind the choice of SGD learning rate. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two separate comments. The first comment questions the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda`, suggesting that it lacks justification. The second comment questions the choice of SGD learning rate, noting that it is unclear why the value of 0.1 was chosen, unlike the default value of Adam. While the comments identify areas for improvement, they do not provide specific reasoning or evidence to support the claims. The lack of detailed justification or references makes the claims somewhat verifiable, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement in the paper. It suggests replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda`, which is a direct and explicit action that could enhance the clarity and flexibility of the model. Additionally, it questions the choice of SGD learning rate, noting that it is unclear why the value of 0.1 was chosen, unlike the default value of Adam. This feedback is valuable as it provides clear and actionable suggestions for improvement, helping the authors to refine their methodology and enhance the transparency of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to justify the choice of the learning rate. Overall, the comment is mostly helpful, as it effectively directs the authors to areas that need further clarification and improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\\'s performance under different scenarios. It also highlights the importance of error analysis in guiding subsequent improvements and expansions of the ERC research. This feedback is explicit and concrete, giving the authors a clear direction on what to include in their paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\\'s performance under different scenarios. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact section where this analysis should be incorporated. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provides a clear action by suggesting that they should provide detailed explanations of the model\\'s performance under different scenarios. However, the comment does not provide specific examples or references to support the claim that error analysis is essential or how it could aid in subsequent improvements. While the suggestion is logical and aligns with common practices in the field, the lack of detailed justification or evidence makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment highlights the importance of error analysis in evaluating model performance and identifying potential issues. It provides a clear and actionable suggestion for the authors to conduct error analysis and offers guidance on how to provide detailed explanations of the model\\'s performance under different scenarios. This feedback is valuable as it guides the authors on how to enhance their paper by addressing a critical aspect of model evaluation. However, the comment could be more helpful if it included specific examples or references to similar studies that effectively use error analysis. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should analyze the domain gap and discuss the gap between datasets. It also recommends adding discussions about the adaption of datasets and the value of the approach if it can fine-tune a pre-trained model on synthetic data. While the comment provides a clear direction for improvement, it does not specify exactly which datasets should be discussed or how the analysis should be structured. The action is explicit but somewhat vague, as it does not provide detailed guidance on execution. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the domain gap and discusses the gap between datasets, suggesting that some datasets may be closer, making the adaptation less of an issue. It also recommends that if the method can fine-tune a pre-trained model on synthetic data, the value of the approach would be higher. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what the authors should consider, such as analyzing the domain gap and the value of the approach. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests analyzing the domain gap and discusses the gap between datasets, recommending that some datasets may be closer, making the adaptation less of an issue. It also suggests that if the method can fine-tune a pre-trained model on synthetic data, the value of the approach would be higher. While the comment provides a logical reasoning for the suggestions, it lacks specific examples or references to support the claim about the datasets being closer or the value of the approach. This makes the claim somewhat verifiable, as it provides a basis for the suggestions but requires further elaboration for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests analyzing the domain gap and provides specific guidance on how to address it by discussing the gap between datasets. It acknowledges that some datasets may be closer, which could affect the adaptation process, and suggests that if the method can fine-tune a pre-trained model on synthetic data, the value of the approach would be higher. This feedback is clear and actionable, offering the authors a direction for improvement by highlighting areas that need further exploration and analysis. However, the comment could be more helpful if it provided specific examples or detailed suggestions on how to analyze the domain gap or discuss the datasets. Overall, the comment is mostly helpful as it provides valuable insights and actionable steps for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that at least one NCE-based method should be included for comparison. It references a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This provides a clear and explicit action for the authors to take, as they are directed to include a comparison with an NCE-based method. The comment also offers a specific reference to guide the authors in making this addition. Therefore, the comment is highly actionable, as it provides a direct and concrete action for the authors to implement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This provides a clear reference and context for the authors to follow. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or result, making it weakly grounded. The suggestion is specific in terms of what needs to be included for comparison, but without explicit grounding, the authors may struggle to pinpoint where to make this addition. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including at least one NCE-based method for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This provides a clear and specific reference to support the claim, making the comment mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples of how the inclusion of such a method would enhance the paper. Overall, the comment is mostly verifiable due to its reliance on a specific reference and the logical reasoning provided.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment suggests that the paper should include at least one NCE-based method for comparison, referencing a specific work, [1], which demonstrates the possibility of learning an energy-based model (EBM) on natural images with a strong noise distribution. This feedback is clear and actionable, as it provides a specific recommendation for the authors to enhance their comparison framework. By including this method, the authors can better contextualize their own work and demonstrate its relevance within the field. The comment is mostly helpful as it offers a clear direction for improvement, but it could be more helpful if it provided additional guidance on how to integrate the suggested method or what specific aspects of the comparison would be most beneficial. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests two specific improvements to the experiment section: conducting a significance test on human evaluation results and comparing the proposed method with the most recent LLM. These suggestions are explicit and provide clear guidance on what actions the authors should take to enhance their draft. The comment is concrete, as it specifies the types of tests and comparisons that would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically recommending the inclusion of a significance test on human evaluation results and comparing the proposed method with the most recent LLM. However, it does not specify which part of the experiment section this feedback pertains to, making it weakly grounded. The comment is specific in its suggestions for improvement, providing clear guidance on what actions the authors should take to enhance their draft. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by conducting a significance test on human evaluation results and comparing the proposed method with the most recent LLM. While the comment provides a logical suggestion for enhancing the experimental analysis, it lacks specific examples or references to support the claim that these additions would be beneficial. The reasoning is based on general knowledge about the importance of statistical significance and the relevance of recent LLMs, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experiment section, suggesting that conducting a significance test on human evaluation results would enhance the analysis. Additionally, it recommends comparing the proposed method with the most recent LLMs, which is a relevant and constructive suggestion for expanding the scope of the comparison. This feedback provides clear and actionable guidance, helping the authors to strengthen their experimental design and results. However, the comment could be more helpful if it included specific details on how to conduct the significance test or which LLMs should be compared. Overall, the comment is mostly helpful, as it offers valuable insights for improving the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the authors\\' claim that there is no research on joint error for UDA, suggesting that this problem has been studied in previous works, such as \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML 2019. The reviewer explicitly instructs the authors to discuss this work and illustrate the relationship between it and the proposed method, as well as why their method is better. This feedback provides a clear and concrete action for the authors to take, namely to include a discussion of the referenced work and its relationship to their own. The comment is explicit and provides detailed guidance on how to address the issue, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML 2019, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the authors\\' claim about the lack of research on joint error for UDA and suggests discussing this work to clarify the relationship between it and the proposed method. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' assertion about the lack of research on joint error for UDA is incorrect, as it contradicts previous work. The reviewer provides a specific reference, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML 2019, which directly challenges the authors\\' claim. This provides a clear and specific reference to support the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the authors\\' claim that there is no research focusing on the joint error for UDA. It points out that this problem has already been studied in previous works, such as \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML 2019. The reviewer suggests that the authors discuss this work and illustrate the relationship between it and their proposed method, as well as why their method is better. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing a potential oversight in their literature review. The comment is highly helpful as it offers a concrete suggestion for enhancing the paper\\'s comprehensiveness and accuracy. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative methods for comparison. The action is implicit and vague, as the authors are left to infer that they need to consider the impact of dataset size on their results and potentially adjust their comparison accordingly. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comparison with state-of-the-art (SOTA) methods, specifically mentioning the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. This provides some grounding as it refers to a specific aspect of the paper, but it does not explicitly mention which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the fairness of the comparison and suggesting that the superior performance may be due to the dataset size, rather than the method itself. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the comparison with state-of-the-art (SOTA) methods is unfair due to the use of a new, large-scale dataset (209M) compared to existing methods that use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. While the comment provides a logical reasoning for the potential unfairness of the comparison, it lacks specific examples or references to support the claim. The authors are left to infer the impact of dataset size on the results, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods, noting that the performance of the paper is based on a new, large-scale dataset (209M) while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method may be attributed to the scale of the dataset rather than the method itself. This feedback is somewhat helpful as it identifies a potential issue with the comparison and provides a rationale for why the results might be influenced by dataset size. However, the comment could be more helpful if it offered suggestions on how the authors might address this concern or provide a more nuanced comparison. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. This is an explicit suggestion that provides a clear action for the authors to take, which is to incorporate these models as the base encoder and compare their transfer parts. The comment also offers concrete guidance on what specific changes to make, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method description. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its suggestion to use pre-trained models and compare transfer parts, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. This claim is based on the observation that pre-trained models can overcome domain-shift problems in the NLP field. However, the comment lacks specific references or examples to support the claim that these models are indeed the best choice or that they would provide a significant advantage over n-gram features. The reasoning is logical but lacks detailed evidence or examples, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for improving the paper's methodology. It suggests using powerful pre-trained language models like BERT and XLNet as the base encoder for all methods, comparing the efficacy of the transfer parts instead of the simplest n-gram features. This feedback is specific and offers a concrete way to enhance the paper's approach, which could significantly impact the results and analysis. By following this advice, the authors can improve the robustness and relevance of their work. However, the comment could be more helpful if it included a discussion on why these models are particularly suitable or how they might improve the results. Overall, the comment is mostly helpful as it directs the authors towards a specific and beneficial improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the proposed method\\'s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain comes from specific modules or is simply due to more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. While the comment identifies a potential issue, it does not explicitly instruct the authors on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more thorough ablation study to clarify the contributions of each module. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of the proposed method and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters. However, it does not specify which part of the paper this concern relates to, such as the methodology section or the results section. The authors can infer that it pertains to the method description or the ablation study, but this inference is not explicit. The comment is specific in detailing the issue with the current ablation study, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the proposed method\\'s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, it lacks specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. The authors are left to infer that the study needs to be more comprehensive, but without explicit guidance or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the proposed method, specifically the complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters, highlighting a gap in the current ablation study. The comment suggests that the current version of the ablation study does not provide definitive answers to these questions, which is a valid concern. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their ablation study. While it points out a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies a concern about the complexity of the proposed method and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters, and notes that the current ablation study does not provide definitive answers to these questions. While the comment highlights a potential issue, it does not explicitly instruct the authors on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a more thorough ablation study to clarify the contributions of each module. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the complexity of the proposed method and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters, and notes that the current ablation study does not provide definitive answers to these questions. However, the comment does not specify which part of the paper this concern relates to, such as the methodology section or the results section. The authors can infer that it pertains to the method description or the ablation study, but this inference is not explicit. The comment is specific in detailing the issue with the current ablation study, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the proposed method\\'s complexity and the potential impact of additional parameters on performance. It questions whether the main performance gain originates from specific modules or is merely due to more parameters, noting that the current ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or detailed reasoning to support the claim that the current ablation study is insufficient. Without explicit guidance or evidence, the authors are left to infer that the study needs to be more comprehensive, but the lack of detailed support makes"}
{"generated_text": "{'actionability_rationale': \"The review point raises a question about the explanation provided in line 196-7 regarding why the two quantities are different and how they capture the difference in learning settings. While the reviewer acknowledges the need for more explanation, they also express a leaning toward acceptance, suggesting that the paper should be accepted despite the need for clarification. However, the comment does not provide explicit guidance on how the authors should address this issue or what additional explanation is required. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed explanation, but the comment does not specify how to do so. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'l 196-7,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly asks for an explanation of why the two quantities are different and how they capture the difference in learning settings. The comment provides a clear direction for the authors to address, making it fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point consists of a question seeking clarification on the explanation provided in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual inquiry seeking additional information, making it a normal statement. Therefore, it should be labeled as 'No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment raises a specific question about the explanation provided in the paper regarding the difference between two quantities and how they capture the difference in learning settings. While it identifies a gap in the explanation, it does not offer suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it points out a potential area for improvement but does not provide actionable advice.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to discuss the sensitivity of any fixed tuning parameters in the model, both in terms of strengths and weaknesses. This request provides a clear and direct action for the authors to take, as it specifies what aspect of the model they should address. The comment is explicit and concrete, giving the authors a clear path forward in improving their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"4.,\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the discussion of the sensitivity of any fixed tuning parameters in the model, including both strengths and weaknesses. This provides clear guidance on what the authors should focus on in their response. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for the authors to discuss the sensitivity of fixed tuning parameters in their model, both in terms of strengths and weaknesses. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is somewhat helpful as it identifies a specific area for improvement by asking the authors to discuss the sensitivity of any fixed tuning parameters in their model, both in terms of strengths and weaknesses. This feedback provides a clear direction for the authors to enhance their analysis and understanding of their model. However, the comment lacks depth and does not offer specific suggestions or examples of how to address this issue, which could make it more actionable. Therefore, the comment is somewhat helpful, as it points out an area for improvement but does not fully guide the authors in making the necessary changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests an interesting direction for the authors to explore, which is to investigate the proposed framework with different policy gradient approaches. However, it does not provide explicit instructions on how to conduct these experiments or what specific policy gradient approaches to consider. The request for \"experiment results\" is somewhat vague, as it does not specify which experiments are being referred to or what additional information is needed. The comment lacks concrete details on how to implement the suggested exploration, making it somewhat actionable. The authors can infer that they need to conduct additional experiments, but the lack of specific guidance on what to include in these experiments limits the actionability.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies (DDPO and IPPG). However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional information about the experimental setup, which could help the authors address the suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests exploring the proposed framework with different policy gradient approaches and asks about the number of random seeds used for learning the policies. However, it does not provide any reasoning, evidence, or references to support why this exploration is necessary or how it would impact the framework. The request for \"experiment results\" is vague and lacks specific guidance on what aspects of the experiments should be detailed. Without additional context or justification, the claim is difficult for the authors to understand and address, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting direction for the authors to explore, which is to investigate the proposed framework with different policy gradient approaches. This suggestion could potentially expand the scope of the study and provide additional insights into the framework\\'s performance. However, the comment lacks specificity regarding which policy gradient approaches to consider or how the exploration should be structured. Additionally, it does not provide guidance on how to conduct these experiments or what specific results should be expected. While the suggestion is intriguing, it does not offer detailed or actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper\\'s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. While the comment implies that the authors should expand their evaluation to include additional datasets and tasks, it does not provide explicit instructions or guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and specify which datasets and tasks to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper\\'s results and conclusions would be stronger if the analysis were applied to more datasets and more tasks. However, it does not specify which part of the paper this evaluation is based on, nor does it provide details on which datasets or tasks should be considered. This lack of specificity and grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper\\'s results and conclusions would be stronger if the analysis were applied to more datasets and tasks. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's evaluation, specifically noting that the analysis is conducted on only one dataset and one task. It suggests that the results and conclusions would be stronger if the analysis were applied to more datasets and tasks. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and generalizability of their findings. By expanding the evaluation to include additional datasets and tasks, the authors can strengthen their results and conclusions. However, the comment could be more helpful if it offered suggestions on how to select or prioritize additional datasets or tasks. Overall, the comment is mostly helpful as it guides the authors in improving their draft by suggesting a specific area for enhancement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not provide explicit guidance on how the authors should incorporate these suggestions into their work. The action is implicit and somewhat vague, as the authors are left to infer that they should explore these connections and present them in a different context. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to explore connections with kernel regression and smoothing, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the considerations in the paper should also be applicable to kernel (ridge) regression and could be presented in the \"language of kernel interpolation/smoothing.\" This feedback is somewhat helpful as it points out a potential connection that the authors might explore, which could expand the scope of their work. However, the comment lacks specific guidance on how to make this connection or what aspects of the paper should be rephrased or restructured to accommodate this suggestion. Without detailed instructions or examples, the authors may find it challenging to fully implement the feedback. Therefore, the comment is rated as somewhat helpful, as it provides a direction for potential improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example, mentioning Lines 55-64, where the authors discuss factors affecting the performance of chain-of-thought prompting. The comment implies that the authors should include references to existing studies that discuss these factors. While the action is explicit, it lacks concrete details on which specific references to include or how to integrate them into the paper. The authors know they need to add references but may need more guidance on how to do so effectively. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 55-64,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to add supportive references for claims that may be inspired from existing studies. The comment provides a clear example of the lines in question, making it easy for the authors to understand and address the feedback. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some claims may be inspired from existing studies and recommends adding supportive references. It provides a specific example, mentioning Lines 55-64, where the authors discuss factors affecting the performance of chain-of-thought prompting. The comment implies that the authors should include references to existing studies that discuss these factors. While the suggestion is logical and based on the authors\\' discussion, it lacks specific references or detailed reasoning to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the claim but requires additional evidence or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, suggesting that some claims may be inspired from existing studies. It provides a specific example, mentioning Lines 55-64, where the authors discuss factors affecting the performance of chain-of-thought prompting. The comment implies that the authors should include supportive references to substantiate these claims. While the feedback highlights an important aspect for the authors to consider, it lacks detailed guidance on which specific references to include or how to integrate them into the paper. The comment is somewhat helpful as it points out a potential gap in the paper but could be more comprehensive with additional suggestions or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks presented in the paper are somewhat standard and proposes the inclusion of unique tasks to showcase the diversity of the dataset. While the comment implies that the authors should consider adding more diverse tasks, it does not explicitly instruct them to do so. The suggestion is vague and lacks concrete details on how to implement these changes, such as which specific tasks to consider or how to structure them. As a result, the authors may find it challenging to know exactly how to address this feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the tasks presented in the paper are somewhat standard and proposes the inclusion of unique tasks to showcase the diversity of the dataset. However, it does not specify which part of the paper discusses the tasks or the dataset, making it weakly grounded. The comment is specific in suggesting the inclusion of unique tasks, such as Question Answering from images, which provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks presented in the paper are somewhat standard and proposes the inclusion of unique tasks to showcase the diversity of the dataset. However, the comment lacks specific examples or references to support the claim that the tasks are standard or to justify the suggestion of unique tasks. The reasoning is based on a general observation rather than detailed evidence or examples, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the tasks presented in the paper, noting that they are somewhat standard. It suggests that the authors could consider unique tasks to showcase the diversity of the dataset, such as interleaved image-text tasks like Question Answering from images. This feedback is somewhat helpful as it points out an area for improvement and provides a specific suggestion for enhancing the diversity of tasks. However, the comment could be more helpful if it offered more detailed guidance or examples of how to implement these unique tasks. Overall, the feedback is somewhat helpful, as it provides a direction for the authors to consider but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the relevance of the framework to problems involving non-convex losses and non-norm type defenses. It also inquires about the impact of the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints on the algorithm\\'s relevance. Additionally, it asks whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment raises important questions, it does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer what specific aspects of the framework should be clarified or expanded upon. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p.3, binary classification,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues regarding the relevance of the framework to non-convex losses and non-norm type defenses, as well as the impact of the non-vanishing duality gap and maximization over non-norm type constraints. Additionally, it questions the potential intuitions on the risk upperbound and the possibility of using the true mean to design a better defense. This level of detail provides clear guidance on what the authors need to address in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the relevance of the framework to problems involving non-convex losses and non-norm type defenses. It asks whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints make the algorithm irrelevant or whether it still provides intuitions on the risk upperbound. The comment also inquires about the possibility of using the true mean to design a better defense. While the questions are logical and could be relevant to the paper, they do not contain specific claims or references that would substantiate the questions. The authors would need to provide additional context or evidence to fully address these concerns. Therefore, the comment is considered borderline verifiable, as it lacks explicit evidence or references to support the questions.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises several questions about the relevance of the framework to problems involving non-convex losses and non-norm type defenses. It inquires about the impact of the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints on the algorithm's relevance. Additionally, it questions whether the algorithm provides intuitions on the risk upperbound and whether the true mean being known through an oracle can be used to design a better defense. While the comment identifies areas for clarification and potential improvements, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider the relevance of their framework and its potential applications, but it could be more actionable with detailed advice or examples.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This is an explicit suggestion that provides a clear direction for the authors to explore. However, the comment does not specify how to implement this action or what specific aspects of the sparsification process to focus on. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular action\u2014sparsifying the trained models and comparing their accuracy to the proposed model. This provides clear guidance on what needs to be done to improve the analysis or presentation in Figure 3. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. However, the comment does not provide any reasoning, evidence, or justification for why this action might be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an action for the authors to consider, which is to sparsify the trained models and compare their accuracy to the proposed model. This feedback is somewhat helpful as it provides a specific direction for the authors to explore, potentially leading to improvements in the analysis or presentation of their results. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or what specific aspects of sparsification to focus on. To be more helpful, the comment could include additional context or reasoning about why this action might be beneficial or how it could enhance the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks, the type of image features, and the fixed radius with different scales. While the comment identifies these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to provide more detailed explanations and examples to clarify these aspects. However, the lack of specific instructions or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lacks in detail about the techniques\" and provides specific examples of areas where the paper is unclear, such as the sparsification process, generating landmarks on the edge, deciding the number of landmarks, and the type of image features. It also questions the fixed radius with different scales and achieving shape invariance. This level of detail allows the authors to accurately identify the parts of the paper that need clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks detail about the techniques, making it difficult to reproduce the results. It provides specific examples of unclear aspects, such as the sparsification process, generating landmarks on the edge, and deciding the number of landmarks. However, the comment does not provide specific references, examples, or detailed reasoning to support these claims. While the examples are clear, the lack of detailed justification or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's lack of detail, making it difficult for readers to reproduce the results. It specifically points out the sparsification process, which is crucial for extracting landmark features, and questions other aspects such as generating landmarks on the edge, deciding the number of landmarks, and the type of image features. The comment also raises concerns about the fixed radius with different scales and achieving shape invariance. While the feedback highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and examples to clarify these aspects. Therefore, the comment is somewhat helpful, as it identifies weaknesses but could be more comprehensive in its guidance.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies several areas where the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks, the type of image features, and the fixed radius with different scales. However, the comment does not provide explicit guidance on how to address these issues or suggest specific steps for improvement. The authors are left to infer that they need to provide more detailed explanations and examples to clarify these aspects, but the lack of concrete instructions makes the comment somewhat vague. Therefore, the feedback is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lacks in detail about the techniques\" and provides specific examples of areas where the paper is unclear, such as the sparsification process, generating landmarks on the edge, deciding the number of landmarks, and the type of image features. It also questions the fixed radius with different scales and achieving shape invariance. This level of detail allows the authors to accurately identify the parts of the paper that need clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the paper lacks detail, making it difficult to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks, the type of image features, and the fixed radius with different scales. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the exact issues and how to address them. Without detailed justification or references, the claim is somewhat verifiable, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's lack of detail, making it difficult for readers to reproduce the results. It specifically points out the sparsification process, which is crucial for extracting landmark features, and questions other aspects"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the utility-based approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores could introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they might need to consider alternative approaches or metrics to mitigate these biases. However, the lack of specific suggestions or examples makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the utility-based approach used in FIITED for determining chunk significance, specifically mentioning the potential issue of basing eviction decisions purely on utility scores. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the potential issue of introducing biases, particularly regarding the treatment of recent chunks. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the utility-based approach used in FIITED for determining chunk significance. It suggests that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. While the comment identifies a potential issue, it lacks specific examples or references to support the claim of introducing biases. The reasoning is based on a logical deduction, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the utility-based approach used in FIITED for determining chunk significance. It points out that basing eviction decisions solely on utility scores might introduce biases, such as favoring recent chunks over valuable ones. This feedback is somewhat helpful as it highlights a specific area for improvement in the paper's methodology. However, the comment lacks depth and does not provide actionable suggestions or examples on how the authors might address this issue. To be more helpful, the comment could include specific recommendations or alternative approaches to mitigate the identified bias. Therefore, the comment is rated as somewhat helpful, as it provides a starting point for the authors but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a lack of clarity regarding how different parts of the framework contribute to the final result, particularly in the experimental section. It suggests that the authors should include quantitative experiments and comparisons between algorithms, as well as more detailed explanations of the presented ones. The comment provides specific actions, such as conducting quantitative experiments and comparisons, and offering detailed explanations, which are explicit and concrete. This guidance gives the authors clear direction on how to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the clarity of how different parts of the framework contribute to the final result, specifically mentioning the lack of quantitative experiments and comparisons between algorithms in the result section. While it does not explicitly mention a specific section, the authors can infer that it pertains to the experimental section. The comment is specific in detailing what is missing, such as quantitative experiments and detailed explanations of the algorithms. However, the lack of explicit section reference makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clarity regarding how different parts of the framework contribute to the final result, particularly in the experimental section. It suggests that the authors should include quantitative experiments and comparisons between algorithms to provide a more detailed understanding of the framework\\'s performance. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact areas needing improvement, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper regarding the clarity of how different parts of the framework contribute to the final result, particularly in the experimental section. It points out the lack of quantitative experiments and comparisons between algorithms, which is crucial for understanding the framework\\'s performance and contributions. The comment also suggests that more detailed explanations are needed for the presented algorithms. This feedback is clear and actionable, providing the authors with specific areas to address to improve the clarity and robustness of their work. However, it could be more helpful if it offered suggestions on how to conduct these experiments or provide detailed explanations. Overall, the comment is mostly helpful, as it guides the authors toward enhancing the clarity and rigor of their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to clarify their model\\'s capabilities. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. Without explicit references, the authors may find it challenging to identify the exact area being addressed. Additionally, the comment lacks specificity regarding what aspects of the model or data are unclear or need clarification. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the model\\'s ability to generate novel knowledge or testable hypotheses about neuron data. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is unverifiable, as it does not provide sufficient justification or evidence to support the assertion.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the model's ability to generate novel knowledge or testable hypotheses about neuron data. This is an important point that the authors should consider, as it questions the potential impact and utility of their work. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue. Without additional context or direction, the authors may find it challenging to fully understand and respond to the feedback. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors present a simplified version of theorem 2 for the general audience, similar to theorem 1. While the comment implies that the current presentation of definition 2 and theorem 2 is difficult to understand, it does not explicitly instruct the authors to make this change. The action is implicit and somewhat vague, as the authors need to infer that they should simplify theorem 2. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition 2 and theorem 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the difficulty in understanding these sections for the general audience. The comment provides a clear direction for improvement by suggesting a simplified version of theorem 2. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the presentation of theorem 2 is difficult for the general audience, similar to theorem 1. However, it does not provide any specific reasoning, examples, or references to support why this is the case. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the presentation of theorem 2, suggesting that it might be difficult for the general audience to understand, similar to theorem 1. This feedback is somewhat helpful as it points out a potential accessibility issue that the authors should consider. However, the comment lacks specific suggestions or guidance on how to simplify theorem 2 or make it more accessible. Without actionable advice, the authors may find it challenging to address the feedback effectively. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that it would be interesting to explore how the performance of the experiments changes when using a larger image resolution than the current 224*224. While the comment implies that the authors should consider conducting experiments with different image resolutions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore different resolutions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests exploring the performance of experiments with larger image resolutions, specifically mentioning the current resolution of 224*224. However, it does not specify which part of the paper this suggestion pertains to, such as a particular experiment or section. The authors can infer that it relates to the experimental setup or results, but this inference is not explicit. The comment is specific in suggesting a potential area for exploration, but it lacks grounding as it does not pinpoint a specific section or experiment. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests exploring the performance of experiments with larger image resolutions, specifically mentioning the current resolution of 224*224. However, it does not provide any reasoning, evidence, or references to support why this exploration would be interesting or beneficial. The comment lacks specific examples or detailed justification, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests an interesting exploration by suggesting that the authors consider conducting experiments with larger image resolutions than the current 224*224. This feedback provides a potential direction for further investigation, which could enhance the depth and relevance of the study. However, the comment lacks specific guidance on how to implement this suggestion or what larger resolutions to consider. While it offers a valuable idea, the lack of detailed instructions limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the KeyQN section, specifically asking what the \"keypoint mask averaged feature vector\" is and whether it is obtained by multiplying each feature map element-wise by H_psi. While the comment identifies a specific area of confusion, it does not provide explicit guidance on how the authors should address this issue or what additional information or clarification is needed. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the concept, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of the \"keypoint mask averaged feature vector\" and asks whether it is obtained by multiplying each feature map element-wise by H_psi. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific aspect of the paper, namely the definition of the \"keypoint mask averaged feature vector\" in the KeyQN section. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the KeyQN section, asking for clarification on the definition of the \"keypoint mask averaged feature vector.\" While it identifies a potential area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their draft. Therefore, it is rated as barely helpful, as it points out a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not explicitly instruct the authors to include this information or provide guidance on where or how to incorporate it. The action is implicit and somewhat vague, as the authors need to infer that they should make this mention but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L37,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. However, it does not provide any reasoning, evidence, or examples to support why this is necessary or how it would improve the paper. Without additional context or justification, the claim is not verifiable, as it lacks the necessary support to be understood or acted upon by the authors. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow a sampled policy for a certain period. While this is a valid suggestion, it lacks specificity and does not provide detailed guidance on why this information is important or how it could be incorporated into the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion or how to implement it effectively. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the paper\\'s approach to proving lower bounds for round complexity, suggesting that the results follow easily from a reduction to collaborative ranking. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the approach to proving lower bounds for round complexity in the context of batched ranking problems. It mentions the exploitation of an easy reduction from the problem of collaborative ranking, which implies that the authors are using a known result from collaborative ranking to derive their lower bound results. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the use of an easy reduction and the resulting corollary nature of the lower bound results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a major part of the work involved in proving results for batched ranking problems, and that the paper exploits an easy reduction from the problem of collaborative ranking. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed evidence or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s approach to proving lower bounds for round complexity in the context of batched ranking problems. It points out that the paper exploits an easy reduction from the problem of collaborative ranking, which may lead to a less challenging proof. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are given a direction to consider but are left without a clear path for improvement. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment highlights a concern about the paper\\'s approach to proving lower bounds for round complexity, suggesting that the results follow easily from a reduction to collaborative ranking. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their approach. The comment lacks actionable details, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the approach to proving lower bounds for round complexity in the context of batched ranking problems. It mentions the exploitation of an easy reduction from the problem of collaborative ranking, which implies that the authors are using a known result from collaborative ranking to derive their lower bound results. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the use of an easy reduction and the resulting corollary nature of the lower bound results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a major part of the work involved in proving results for batched ranking problems. It suggests that the paper exploits an easy reduction from the problem of collaborative ranking, which may lead to a less challenging proof. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper\\'s approach to proving lower bounds for round complexity in the context of batched ranking problems. It points out that the paper exploits an easy reduction from the problem of collaborative ranking, which may lead to a less challenging proof. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. While it highlights a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are given a direction to consider but are left without a clear path for improvement. Therefore, the comment aligns with a"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prompting technique used in the study is basic and fails to fully utilize the potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. While the comment implies that the authors should consider using more sophisticated prompting techniques, it does not provide specific guidance on how to implement this suggestion or what constitutes a \"carefully curated\" prompt. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve their prompting technique. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of a basic prompting technique in the study, suggesting that it fails to leverage the full potential of large language models (LLMs). It recommends using carefully curated prompts to achieve better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or how it could be improved. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its suggestion to use carefully curated prompts, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of large language models (LLMs). However, the comment does not provide specific examples or evidence to support this claim, such as comparisons with other studies or detailed explanations of how the current technique limits the potential of LLMs. Without such evidence, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the study, noting that the prompting technique used is basic and fails to fully leverage the potential of large language models (LLMs). It suggests that using carefully curated prompts could lead to better results in generating systematic reviews. While the comment highlights a potential area for improvement, it lacks specific guidance or examples on how to implement the suggested changes. The authors are left with a general idea of what could be improved but without detailed steps or examples to follow. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited novelty of the proposed video storyboarding approach, noting that it primarily relies on frame-wise SDSA, similar to ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of cross-attention. While the comment identifies a potential issue with the novelty of the approach, it does not provide explicit guidance on how the authors might address this concern or enhance the novelty of their work. The feedback lacks actionable steps or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the video storyboarding approach, specifically noting that it relies on frame-wise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of cross-attention. However, the comment does not specify which part of the paper discusses this approach or where the comparison with ConsiStory is made. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of limited novelty but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed video storyboarding approach lacks novelty, primarily because it relies on frame-wise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of cross-attention. The comment provides a logical reasoning by comparing the proposed method with an existing approach, but it lacks specific examples or references to substantiate the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires additional evidence or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the proposed video storyboarding approach, noting that it relies on frame-wise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of cross-attention. While the comment highlights a potential limitation, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their work or address this concern. The feedback lacks actionable steps or detailed insights, making it somewhat helpful. The authors are given a direction to consider, but the comment could be more comprehensive and actionable to be fully beneficial. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out that the proposed video storyboarding approach lacks novelty, as it relies on frame-wise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of cross-attention. While the comment identifies a potential issue with the novelty of the approach, it does not provide explicit guidance on how the authors might address this concern or enhance the novelty of their work. The feedback lacks actionable steps or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed video storyboarding approach, noting that it relies on frame-wise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of cross-attention. However, the comment does not specify which part of the paper discusses this approach or where the comparison with ConsiStory is made. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in identifying the issue of limited novelty but lacks grounding, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed video storyboarding approach lacks novelty, primarily because it relies on frame-wise SDSA, which is similar to the approach used in ConsiStory. The only notable difference is the use of CLIPseg and OTSU segmentation instead of cross-attention. While the comment provides a logical reasoning by comparing the proposed method with an existing approach, it lacks specific examples or references to substantiate the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires additional evidence or examples to be fully substantiated. Therefore, the comment is rated as 3: Somewhat"}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the zero-shot nature of the experiments and the potential limitations of transferability due to the difficulty of the source and target tasks. It also suggests that the authors clarify this in the paper to avoid misinterpretation. While the comment identifies areas that need clarification, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the zero-shot nature and the transferability limitations, but the comment does not offer concrete guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the zero-shot nature of the experiments and the potential limitations of transferability due to the difficulty of the source and target tasks. It suggests that the authors clarify this in the paper to avoid misinterpretation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about zero-shot and transferability limitations, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the zero-shot nature of the experiments and the potential limitations of transferability due to the difficulty of the source and target tasks. It provides a logical reasoning by suggesting that the policy transfer is possible due to the difficulty of the source task and the complexity of the target task. However, the comment lacks specific examples or references to support the claim about the difficulty of the tasks, making it somewhat verifiable. The authors would need to provide more detailed information or evidence to fully understand and address the concerns raised in the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important questions about the zero-shot nature of the experiments and the potential limitations of transferability due to the difficulty of the source and target tasks. It provides a logical reasoning by suggesting that the policy transfer is possible due to the difficulty of the source task and the complexity of the target task. The comment also highlights the need for the authors to clarify this in the paper to avoid misinterpretation. While the feedback identifies a critical area for improvement, it could be more helpful if it offered specific suggestions on how to address these issues or provide additional context. Overall, the comment is mostly helpful as it directs the authors' attention to a significant aspect of their work that needs clarification, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation. It also mentions that some datasets are large, which could limit the applicability of certain algorithms. The reviewer acknowledges the authors\\' response, which includes the provision of a repository and clarification on the datasets. However, the comment does not explicitly instruct the authors to take any specific action, such as adding more datasets or explaining the rationale behind the dataset selection. While the authors may infer that they need to address the dataset issue, the lack of explicit guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the adequacy of the datasets used for evaluation, specifically mentioning the number of datasets for each task. It raises a concern about the potential insufficiency of the datasets, particularly if some are too large for certain algorithms. The reviewer acknowledges the authors\\' response, which includes the provision of a repository and clarification on the datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The feedback is specific in identifying the concern about dataset size and the need for more rigorous evaluation, but it lacks explicit references to the paper\\'s sections. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be enough for a rigorous evaluation, especially if some datasets are too large. The reviewer acknowledges the authors\\' response, which includes the provision of a repository and clarification on the datasets, updating their assessment accordingly. However, the initial claim lacks specific examples or references to support the assertion about the insufficiency of the datasets. While the authors\\' response provides additional context, the original comment itself does not offer sufficient evidence or reasoning to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks detailed justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the adequacy of the datasets used for evaluation, suggesting that having 5, 6, and 4 datasets for the respective tasks may not be sufficient for a rigorous evaluation, especially if some datasets are too large. The reviewer acknowledges the authors' response, which includes the provision of a repository and clarification on the datasets, updating their assessment accordingly. While the comment identifies a potential issue with the dataset selection, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the evaluation. The feedback is somewhat helpful as it highlights an area for improvement but lacks depth and actionable advice, leaving the authors with a general direction to consider.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the method addresses sparse reward problems and whether it supports this claim through the experiments. It also asks if the proposed method requires sub-task-specific rewards, which would be similar to providing dense rewards. Additionally, it inquires about the ability of other methods (Qmix) to solve sparse-reward tasks when given the sum of low-level rewards as the global reward. While the comment raises valid questions, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback is vague and lacks actionable steps, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the method\\'s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. However, the comment does not specify which part of the paper these questions relate to, such as the experimental results or the method description. This lack of grounding makes it difficult for the authors to identify the exact sections needing attention. The comment is specific in its questions, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method\\'s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples, references, or detailed explanations, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions about the method's ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. While the comment identifies areas for improvement and raises valid concerns, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their draft. The feedback is somewhat helpful as it prompts the authors to consider additional aspects of their method, but it could be more actionable with more detailed advice or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment raises questions about the method's ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is vague and lacks actionable steps, making it barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the method\\'s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. However, the comment does not specify which part of the paper these questions relate to, such as the experimental results or the method description. This lack of grounding makes it difficult for the authors to identify the exact sections needing attention. The comment is specific in its questions, but without clear grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method\\'s ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. Without specific examples, references, or detailed explanations, the authors may find it challenging to understand and address the concerns raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions about the method's ability to address sparse reward problems and whether the experiments support this claim. It also questions the necessity of sub-task-specific rewards and whether other methods like Qmix can solve sparse-reward tasks with global rewards. While the comment identifies areas for improvement and raises valid concerns, it lacks specific suggestions or guidance on how the authors might address these issues or enhance their draft. The feedback is"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. While the comment does not explicitly instruct the authors to make a change, it does highlight a potential issue that needs to be addressed. The authors can infer that they should clarify this aspect in their paper to ensure a fair comparison. However, the comment lacks specific guidance on how to address this issue, such as suggesting a way to clarify the dataset usage or providing examples of how to do so. Therefore, the action is implicit and somewhat vague, making this comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the methodology or experimental setup. The authors can infer that it relates to the dataset usage or training process, but the comment does not specify the exact part of the paper where this information is discussed. Therefore, the comment is weakly grounded as it does not provide a direct reference to a specific section, but it is specific in its request for clarification. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. The comment does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the clarity of dataset usage in the paper. It specifically asks whether the AH36M dataset is used for training and, if so, whether other methods like HMR and SPIN have access to this data during training for a fair comparison. This feedback is valuable as it highlights a potential issue with the experimental setup that could affect the validity of the results. By addressing this question, the authors can ensure that their methodology is transparent and that their results are comparable to those of other methods. However, the comment could be more helpful if it provided suggestions on how to clarify this aspect or offered examples of how to address the issue. Overall, the comment is mostly helpful as it identifies a significant area for improvement but lacks detailed guidance on how to implement the suggested changes.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises two concerns: the unclear motivation for using an adversarial network in the model and the unfair comparison of experimental results due to the proposed model\\'s larger size. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns. The lack of actionable suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what changes to make. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the motivation for using an adversarial network and the fairness of the experimental results comparison. It explicitly mentions the need for clarification regarding the use of the adversarial network and the unfairness of the comparison due to the proposed model\\'s larger size. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of motivation and fairness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two concerns: the motivation for using an adversarial network and the fairness of the experimental results comparison. The first claim is that the motivation is unclear, which is a subjective observation that requires the authors to provide more context or explanation. The second claim about the unfairness of the comparison is based on the size of the proposed model compared to others, which is a factual observation. However, the comment lacks specific examples or references to support the claim of unfairness, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the unclear motivation for using an adversarial network and the unfairness of the experimental results comparison. It points out that the comparison is biased due to the proposed model\\'s larger size compared to others. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation. While it highlights important areas for improvement, the feedback is somewhat helpful as it provides a starting point for the authors to consider but does not offer detailed steps or examples for addressing these concerns. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment identifies two issues: the unclear motivation for using an adversarial network in the model and the unfairness of the experimental results comparison due to the proposed model\\'s larger size. However, it does not provide specific guidance or suggestions on how the authors might address these issues or improve the clarity of their motivation. The lack of actionable advice or detailed feedback makes it difficult for the authors to know how to proceed with their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the motivation for using an adversarial network in the model and the fairness of the experimental results comparison. It explicitly mentions the need for clarification regarding the use of the adversarial network and the unfairness of the comparison due to the proposed model\\'s larger size. This provides full grounding as the authors can accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of motivation and fairness. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two concerns: the motivation for using an adversarial network in the model and the fairness of the experimental results comparison. The first claim is subjective and lacks specific reasoning or examples to support the assertion that the motivation is unclear. The second claim about the unfairness of the comparison is based on the size of the proposed model compared to others, which is a factual observation. However, the comment does not provide specific examples or references to substantiate the claim of unfairness, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the unclear motivation for using an adversarial network and the unfairness of the experimental results comparison. It points out that the comparison is biased due to the proposed model\\'s larger size compared to others. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation. While it highlights important areas for improvement, the feedback is somewhat helpful as it provides a starting point for the authors to consider but does not offer detailed steps or examples for addressing these concerns. Therefore, the comment aligns with a score of 3"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details or actionable steps, such as recommending specific methods for tuning or suggesting ways to mitigate the variability in hyperparameters. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not specify which part of the paper discusses these hyperparameters or how they are tuned, making it weakly grounded. The comment is specific in identifying the issue of hyperparameter tuning and the potential variability in optimal hyperparameters, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the need to tune multiple hyperparameters and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, the comment lacks specific examples or detailed reasoning to support the claim about the variability in optimal hyperparameters. While it highlights a potential issue, it does not provide sufficient evidence or context to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks the depth needed for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical issue related to the tuning of multiple hyperparameters, such as step size, N, and delta t, which are essential for the optimization process. It highlights a potential problem with the variability in optimal hyperparameters due to the sample-by-sample optimization, which could impact the robustness and generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as proposing alternative methods for tuning or suggesting ways to mitigate the variability in hyperparameters. While it points out a significant area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending specific methods for tuning or suggesting ways to mitigate the variability in hyperparameters. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, it does not specify which part of the paper discusses these hyperparameters or how they are tuned, making it weakly grounded. The comment is specific in identifying the issue of hyperparameter tuning and the potential variability in optimal hyperparameters, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises a concern about the need to tune multiple hyperparameters, such as step size, N, and delta t, and questions the variability in optimal hyperparameters due to the sample-by-sample optimization. However, the comment lacks specific examples or detailed reasoning to support the claim about the variability in optimal hyperparameters. While it highlights a potential issue, it does not provide sufficient evidence or context to fully substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks the depth needed for full verification.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a critical issue related to the need to tune multiple hyperparameters, such as step size, N, and delta t, which are essential for the optimization process. It highlights a potential problem with the variability in optimal hyperparameters due to the sample-by-sample optimization, which could impact the robustness and generalizability of the results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the limited number of methods used for performance comparison and the lack of consistency in the proposed method\\'s performance. It suggests that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. However, the comment does not explicitly instruct the authors to take any specific actions, such as suggesting which methods to include for comparison or how to analyze the inferior results. The action is implicit and somewhat vague, as the authors can infer that they need to address the issue but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the performance comparison, specifically noting that the proposed method is not consistently better than other methods and suggesting that analysis should be provided for inferior results. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide analysis for the inferior results, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than other methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or reasoning, the claim remains vague and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the performance is only compared with a few methods and that the proposed method is not consistently better than other methods. It suggests that the authors should provide analysis for the inferior results, as they contradict the motivation of the study. This feedback is clear and actionable, as it directs the authors to address a critical weakness in their work by offering a specific suggestion for improvement. However, the comment could be more helpful if it provided additional guidance or examples on how to conduct the analysis or which methods to include for comparison. Overall, the comment is mostly helpful as it highlights a significant area for improvement and offers a clear direction for the authors to enhance their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). It suggests that this comparison is necessary to prove the superiority of the schema searched by the author\\'s method (ELF) over the schema in Mid Vision Feedback (MVF). While the comment identifies a specific area for improvement, it does not provide explicit instructions on how to conduct this comparison or what specific results should be included. The action is implicit and somewhat vague, as the authors can infer the need for additional experiments but may not know the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper\" and \"experimental demonstration,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of experimental demonstration of the contribution points, particularly the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically mentioning the absence of a comparison with the image classification result of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by stating that the absence of this comparison does not prove the superiority of the schema searched by the author\\'s method (ELF) over the schema in Mid Vision Feedback (MVF). However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact comparisons that should be made to address the issue, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental demonstration of the contribution points in the paper. It points out that while there is an experimental comparison between the author\\'s method (ELF) and a baseline without Mid Vision Feedback (MVF), there is no comparison with the image classification result of Mid Vision Feedback (MVF). This lack of comparison makes it difficult to determine the superiority of the schema searched by ELF over the schema in Mid Vision Feedback. The comment provides a clear and actionable suggestion for the authors to include this comparison, which would significantly enhance the paper\\'s experimental validation and contribution demonstration. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific results should be included. Overall, the feedback is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the notation \"D\" should be used differently to avoid confusion between its representation as dimensionality of points and dilation factor. This feedback is clear and provides a direct action for the authors to take, which is to change the notation. The suggestion is concrete and actionable, as it specifies what needs to be done to improve the clarity of the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using different notation for \"D\" to avoid confusion between its representation as dimensionality of points and dilation factor. However, it does not specify which part of the paper this issue is present in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion to use different notation, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using different notation for \"D\" to avoid confusion between its representation as dimensionality of points and dilation factor. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this change is necessary or how it would improve the clarity of the paper. Without such justification, the claim remains unverifiable, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper by pointing out that the notation \"D\" is used to represent both dimensionality of points and dilation factor. This feedback is clear and actionable, as it suggests using different notation to avoid ambiguity. By providing a specific suggestion for improvement, the comment helps the authors enhance the clarity and readability of their draft. However, it could be more helpful if it included examples of how to implement the suggested change or discussed the broader implications of this confusion. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for maximum benefit.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment raises a concern about the clarity of the concept of state and questions the equivalence of 'elements' to 'states' or 'actions' in the context of the paper. It explicitly requests more elaboration on this aspect. However, the comment does not provide specific guidance on how to clarify the concept or what additional details should be included. While the action is clear, the lack of concrete suggestions makes it somewhat vague. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'Line 186-line 187,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the concept of state and asking for more elaboration on the equivalence of 'elements' to 'states' or 'actions.' This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point raises a question about the clarity of the concept of state and its equivalence to 'elements' or 'actions' in the context of the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern, making the comment unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area of confusion regarding the concept of state in the paper, particularly in relation to the grid status and the application of actions. It raises a question about the equivalence of 'elements' to 'states' or 'actions,' suggesting that more elaboration is needed. This feedback is clear and actionable, as it directs the authors to clarify a potentially confusing aspect of their work. However, the comment could be more helpful if it provided suggestions on how to improve the clarity of the concept or offered examples of how to elaborate on it. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks depth in its guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide more detail on the innovation of the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify what aspects of the innovation should be detailed or how the authors should present this information. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context on the innovation, but they are not given clear guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the proposed FRM, which is a combination of channel attention and spatial attention. However, it does not specify which part of the paper this combination is discussed in, making it difficult for the authors to identify the exact section being referred to. The comment suggests that the innovation should be detailed, but it does not provide specific guidance on what aspects of the innovation need to be elaborated upon. This lack of grounding and specificity makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention, suggesting that the innovation should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed FRM, noting that it is a simple combination of channel and spatial attention mechanisms. It suggests that the innovation should be detailed, implying that the authors should provide more context or explanation about the novelty of their approach. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the innovation should be elaborated upon or how to present this information. While it highlights an area for improvement, it does not offer actionable advice or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a specific action to improve the redundancy between Section 3 and Section 4 by rearranging the content. It provides a concrete suggestion to move the first paragraph of Section 4 to Section 3 and the remainder of Section 4 before Section 3. This explicit guidance gives the authors a clear idea of how to address the redundancy issue, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting a rearrangement of content to reduce redundancy, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests a rearrangement of content to reduce redundancy between Section 3 and Section 4. It provides a specific suggestion by recommending the movement of certain content from one section to another. However, the comment lacks detailed reasoning or evidence to support why this rearrangement would be beneficial or how it would improve the paper. The suggestion is based on a subjective judgment of redundancy, which is not fully substantiated with logical reasoning or examples. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a redundancy issue between Section 3 and Section 4 and provides a specific suggestion for rearranging the content to address this redundancy. By suggesting the movement of certain content from one section to another, the comment offers a clear and actionable way for the authors to improve the organization and flow of their paper. This feedback is valuable as it helps the authors enhance the clarity and coherence of their manuscript, making the comment mostly helpful. However, it could be more helpful if it included additional suggestions or examples of how the rearrangement could be implemented. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. While the comment implies that these analyses are missing from the paper, it does not explicitly instruct the authors to perform these analyses or provide specific guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the need for these analyses and how to carry them out. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of certain approaches, such as simple greedy selection over more principled acquisition functions, and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what the authors should investigate, but without grounding, it is difficult for the authors to pinpoint the exact sections that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of certain approaches, such as simple greedy selection over more principled acquisition functions, and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. However, the comment does not provide specific examples or references to support the claim that these approaches are indeed superior. The suggestion lacks detailed reasoning or evidence to substantiate the need for these analyses, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should conduct theoretical analyses or extensive experiments to explore the reasons behind the superior performance of simple greedy selection approaches over more principled acquisition functions and deterministic MLP predictors over more robust probabilistic predictors like GPs, deep ensembles, or Bayesian neural networks. This feedback is valuable as it points out a potential area for deeper investigation that could enhance the novelty and understanding of the paper\\'s contributions. However, the comment lacks specific guidance on how to conduct these analyses or what aspects to focus on, which limits its usefulness. While it identifies a direction for improvement, it could be more helpful with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for a citation where the k-max problem was discussed elsewhere in the paper. This is a clear and direct request for the authors to provide additional references or information, which is actionable. The authors know exactly what action is required to address the comment, namely, to include a citation for the k-max problem. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"k-max problem,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests a citation for where the k-max problem was discussed elsewhere in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for a citation, which is a factual statement rather than a claim or opinion. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, asking the authors to provide a citation where the k-max problem was discussed elsewhere in the paper. This is a specific and direct request that helps the authors identify and address a potential oversight in their draft. By following this feedback, the authors can ensure that their work is more comprehensive and well-referenced. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate the cited information into the paper. Overall, the comment is mostly helpful as it guides the authors in improving their draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained later. It suggests that the exact contribution(s) need to be written more clearly in the Introduction. Additionally, it points out that the material supporting the main contributions seems to be in the appendix rather than the main sections, such as the deep-rag algorithm or discussion on high concurrency. While the comment highlights specific areas for improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to clarify the contributions in the Introduction and ensure that supporting material is appropriately integrated into the main sections. The action is implicit and somewhat vague, as it does not offer detailed guidance on implementation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of forward referencing in the paper, specifically mentioning the need for clearer explanation of contributions in the Introduction and the placement of supporting material in the appendix. However, it does not specify which sections or parts of the paper are affected by this issue, making it weakly grounded. The comment is specific in identifying the need for clearer explanation and the location of supporting material, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, where material is introduced without proper explanation and is explained later. It suggests that the exact contribution(s) need to be written more clearly in the Introduction and that the material supporting the main contributions is in the appendix, not the main sections. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issue. The lack of detailed evidence or references limits the verifiability of the claim, leaving it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with forward referencing in the paper, where material is introduced without proper explanation and is explained later. It suggests that the exact contribution(s) need to be written more clearly in the Introduction, which is a valuable piece of feedback for the authors to consider. Additionally, the comment points out that the material supporting the main contributions seems to be in the appendix rather than the main sections, such as the deep-rag algorithm or discussion on high concurrency. This observation is helpful as it directs the authors to ensure that their main contributions are clearly presented in the main sections of the paper. However, the comment could be more helpful if it provided specific suggestions on how to clarify the contributions or integrate the supporting material into the main sections. Overall, the comment is mostly helpful as it highlights areas for improvement and provides some guidance, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of analysis of the security (privacy protection) of the proposed framework. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks actionable details, such as suggesting specific aspects of security to consider or methods for analysis. Without concrete instructions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific area of concern regarding the security (privacy protection) of the proposed framework, but it does not specify which part of the paper this issue is discussed in. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in identifying the lack of analysis of security, but it lacks grounding as it does not pinpoint the exact section of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not analyze the security (privacy protection) of the proposed framework. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the analysis of the security (privacy protection) of the proposed framework. This is a critical aspect that should be addressed in any work involving sensitive data. However, the comment lacks specificity and does not provide any guidance on how the authors might analyze or address this issue. Without actionable suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it highlights a significant area for improvement but does not offer actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks but do not provide an explicit explanation or understanding of this concept in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by looking at PPP maps. While the comment implies that the authors should provide this explanation, it does not specify how to do so or what aspects of the explanation are needed. The action is implicit and somewhat vague, as the authors know they need to provide an explanation but may not know exactly how to structure it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the importance of reliable PPP metrics and the lack of explicit explanation in the article. It suggests that the authors should provide an explicit explanation of what type of understanding one can gain by looking at PPP maps. While the comment does not specify a particular section of the paper, it is clear that it pertains to the discussion or conclusion sections where the authors might address the importance of PPP metrics. The comment is specific in its request for an explanation, but it lacks full grounding as it does not explicitly mention a section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the lack of explicit explanation regarding the importance of reliable PPP metrics for understanding PPP effects in different tasks. It suggests that the authors should provide a more detailed explanation of what type of understanding one can gain by looking at PPP maps. While the comment identifies a gap in the article, it does not provide specific examples or references to support the claim. The reasoning is based on the authors\\' statement about the importance of PPP metrics, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the article by noting that while the authors mention the importance of reliable PPP metrics for understanding PPP effects in different tasks, this explanation is not explicitly provided in the article. It suggests that the authors should explicitly explain what type of understanding one can gain by looking at PPP maps. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of the concept, which could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to elaborate on this topic. Overall, the comment is mostly helpful as it highlights a specific area for improvement and provides a clear direction for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their baseline. The action is implicit and vague, as the authors are left to infer that they need to provide a stronger baseline or address the issue of rewardless actions. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This feedback is fully grounded as it explicitly mentions \"RBI\" and \"rewardless actions,\" allowing the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the training process and suggests that the authors should provide a stronger baseline to prove the usefulness of FP + RBI. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the training process for RBI, suggesting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. The reviewer questions whether this could be a significant factor contributing to the performance of FP + RBI over RBI alone. However, the comment lacks specific examples or detailed reasoning to support the claim that rewardless actions are being ignored. Without additional evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a logical basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a specific concern about the training process for RBI, noting that it only trains on rewarded actions and ignores rewardless actions that provide useful supervision. This observation suggests that this oversight could be a significant factor contributing to the performance of FP + RBI over RBI alone. The reviewer questions whether this is the case and suggests that the authors should provide a stronger baseline to prove the usefulness of FP. While the comment identifies a potential issue, it lacks detailed guidance or suggestions on how the authors might address this concern or improve their baseline. The feedback is somewhat helpful as it points out a potential weakness but does not offer comprehensive advice for improvement. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the multi-scale statement, suggesting that it is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the multi-scale statement or provide a more accurate explanation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the multi-scale statement, specifically pointing out that the slow and fast RNN operate on the logical time scale rather than the physical time scale. This provides a clear and specific critique of the statement, allowing the authors to identify the part of the paper being discussed. The comment also specifies the issue with the multi-scale statement, namely the reduction in gradient path by the slow RNN. This level of detail makes the comment fully grounded and specific, as it clearly identifies the part of the paper being addressed and what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the multi-scale statement is misleading because the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer provides a logical explanation by clarifying that the stacks are sequentialized in the graph, which supports the claim. However, the comment lacks specific references or examples to further substantiate the claim, making it somewhat verifiable. The authors would need to delve deeper into the explanation to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the multi-scale statement, pointing out that the slow and fast RNN operate on the logical time scale, not the physical time scale. The reviewer explains that the only benefit is a reduction in the gradient path by the slow RNN. This feedback is somewhat helpful as it identifies a potential issue with the multi-scale statement and provides a clear explanation of the problem. However, the comment could be more helpful if it suggested ways for the authors to address this issue or offered alternative explanations. Overall, the comment provides some insight but lacks depth and actionable guidance, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should clarify the distinction between the decision maker\\'s interest in the true objective function and the noise, which is typically assumed to be noise. The comment provides a clear action for the authors to take, which is to make this distinction more explicit in the formulation. This guidance is concrete and provides a direct path for the authors to improve their draft by addressing the specific issue of clarity. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the formulation in this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the formulation, which is the distinction between the decision maker\\'s interest in the true objective function and the noise, and suggests that this distinction should be made clearer. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the typical use of expected performance under observation noise for evaluation is misleading because the decision-maker is interested in the true objective function and the noise is assumed to be noise. The reviewer suggests that the formulation in the paper should clarify this distinction. While the comment provides a logical argument, it lacks specific examples or references to support the claim that the typical use is misleading. This makes the claim somewhat verifiable, as the authors would need to explore the literature or further reasoning to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formulation of the paper, noting that the decision maker\\'s interest is in the true objective function, not the noise, which is typically assumed to be noise. The reviewer suggests that this distinction should be made clearer in the formulation. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the clarity and accuracy of their work. By making this distinction more explicit, the authors can better align their formulation with the actual interests of the decision maker. Therefore, the comment is rated as highly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. While it acknowledges the possibility of oversmoothing as another phenomenon, it does not provide specific guidance or suggestions on how the authors might address this issue or incorporate it into their analysis. The comment lacks explicit or implicit actions for the authors to take, making it unactionable. The authors are left without a clear understanding of what steps to take to improve their work based on this feedback.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the potential causes of poor performance, but it lacks detailed guidance on how to address these issues or where in the paper they should be discussed. Therefore, the comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modeling ability of DGNs is attributed to oversquashing, vanishing/exploding gradients, and oversmoothing. While it acknowledges the possibility of oversmoothing as another phenomenon, it does not provide specific references or detailed reasoning to support the claim. The mention of oversmoothing is not elaborated upon, leaving the authors without a clear understanding of how this phenomenon might affect their work. Therefore, the claim is somewhat verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the long-range modeling ability of DGNs, attributing it to oversquashing, vanishing/exploding gradients, and oversmoothing. It acknowledges the possibility of oversmoothing as another phenomenon, which is a relevant consideration for very deep graph networks. However, the comment lacks specific guidance or actionable suggestions on how the authors might address these issues or incorporate them into their analysis. While it highlights an important area for improvement, the feedback is somewhat helpful as it provides a direction for further exploration but does not offer detailed steps or examples for the authors to follow. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment notes that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific guidance on how the authors should clarify this issue or what aspects need to be addressed. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to address the problem. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is weakly grounded because it does not provide explicit references to specific parts of the paper, and it is not specific enough to guide the authors on how to address the issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any guidance or suggestions on how the authors might clarify this issue or what aspects of the formulation are unclear. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. As a result, it is barely helpful, as it only points out a potential problem without offering a solution or direction for improvement.', 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any guidance or suggestions on how the authors might clarify this issue or what aspects of the formulation are unclear. The comment lacks explicit instructions or concrete details on how to address the problem, leaving the authors uncertain about how to improve their draft. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not specify which parts of the statement or introduction are unclear, making it difficult for the authors to pinpoint the exact sections that need revision. The comment lacks full grounding because it does not provide explicit references to specific parts of the paper, and it is not specific enough to guide the authors on how to address the issue. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review comment claims that the problem formulation is somewhat unclear in the statement and introduction examples, but it does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. As a result, the claim is unverifiable, as it lacks the necessary details to be actionable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any guidance or suggestions on how the authors might clarify this issue or what aspects of the formulation are unclear. Without actionable feedback or detailed advice, the comment lacks the depth and specificity needed to be helpful. The authors are left uncertain about how to address the problem, making the comment barely helpful.\", 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the statement and introduction examples. However, it does not provide any guidance or suggestions on how the authors might clarify this issue or what aspects of the formulation are unclear. Without actionable feedback or concrete advice, the authors are left uncertain about how to address the problem. The comment lacks explicit instructions or detailed suggestions, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the problem formulation, noting that it is somewhat unclear in the"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and direct action for the authors to take, which is to include these experiments to enhance the paper\\'s applicability and generalizability. The suggestion is concrete, as it specifies the types of models to consider, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this feedback pertains to, such as the experimental section or methodology. This makes it difficult for the authors to identify the exact section that needs attention. While the comment is specific in suggesting the need for additional experiments, it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is somewhat verifiable as it provides a logical suggestion for improving the paper\\'s applicability and generalizability. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the rationale behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It provides a clear and actionable suggestion by recommending that the authors conduct trials with models like OPT, BLOOM, or other alternatives. This feedback is valuable as it guides the authors on how to enhance the applicability and generalizability of their method. However, the comment could be more helpful if it included specific guidance on how to design and execute these experiments or what aspects to focus on. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or whether they should consider expanding the scope of their method to other types of generative models. Without any actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, it does not specify which part of the paper discusses this limitation or provides examples of generative models that can be fine-tuned. The authors may have an idea of where this discussion might be, but the comment lacks specificity in identifying the exact section or providing detailed guidance on what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the method only works for generative models that can be fine-tuned as an in/outpainting model. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of this assertion, making it difficult to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential limitation of the method, specifically that it only works for generative models that can be fine-tuned as an in/outpainting model. This observation is relevant and could prompt the authors to consider the applicability of their method to a broader range of generative models. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this limitation or expand the scope of their method. Without actionable feedback or additional insights, the comment is somewhat helpful, as it highlights an area for potential improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It also mentions that the process described in the first part does not align with the title\\'s expectations, which could be computationally demanding. However, the comment does not provide specific guidance or suggestions on how the authors might strengthen the connections or address the mismatch between the title and the content. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, it does not specify which sections or parts of the paper are being discussed, making it weakly grounded. The comment is specific in its critique, as it highlights a mismatch between the title\\'s expectations and the actual content, and mentions the computational demands of the process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions that the process described in the first part does not align with the title\\'s expectations and is computationally demanding, but lacks detailed evidence or references to substantiate these points. As a result, the claim is somewhat verifiable, as it provides some insight but requires further elaboration to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It also notes a mismatch between the title's expectations and the actual content, mentioning that the process described is computationally demanding. However, the comment lacks specific suggestions or guidance on how the authors might strengthen the connections or address the mismatch. While it identifies an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights a potential issue but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment expresses concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It also mentions a mismatch between the title\\'s expectations and the actual content, noting that the process described is computationally demanding. However, the comment does not provide specific guidance or suggestions on how the authors might strengthen the connections or address the mismatch. Without actionable advice or detailed feedback, the authors are left uncertain about how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It also mentions a mismatch between the title\\'s expectations and the actual content, noting that the process described is computationally demanding. However, the comment does not specify which sections or parts of the paper are being discussed, making it weakly grounded. The feedback is specific in its critique, as it highlights a potential issue with the connections and the computational demands, but lacks detailed guidance on how to address these concerns. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It also notes a mismatch between the title\\'s expectations and the actual content, mentioning that the process described is computationally demanding. However, the comment lacks specific examples or detailed reasoning to support these claims, making it somewhat verifiable. The authors would need to infer the exact issues from the comment, which limits its usefulness for the authors. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the connections between the curve finding and FGE parts of the paper, suggesting that the connections are weak. It also notes a mismatch between the title's expectations and the actual content, mentioning that the process described is computationally demanding. However, the comment lacks specific suggestions or guidance on how the authors might strengthen the connections or address the mismatch. While it identifies an area for improvement, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights a potential issue but does not fully"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using topological reasoning, generalized Voronoi graphs, semantic maps, or curiosity-driven exploration. It also mentions the long-term storage through pose graphs in SLAM, where loop closure is applied. While the comment implies that the authors should compare their method with these existing approaches, it does not provide explicit instructions on how to conduct this comparison or what specific aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the suggestion. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should discuss the proposed method in relation to existing methods for exploration, such as those using topological reasoning, generalized Voronoi graphs, semantic maps, or curiosity-driven exploration. It also mentions the long-term storage through pose graphs in SLAM, where loop closure is applied. However, the comment does not specify which part of the paper should include this discussion or where these methods are discussed. The authors can infer that it relates to the method section or the related work section, but this inference is not explicit. The comment is specific in detailing what needs to be addressed, but it lacks full grounding as it does not pinpoint the exact sections of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the general ideas of the proposed method are already present in other methods for exploration, such as reasoning topologically and long-term storage through pose graphs in SLAM. It provides examples of existing methods, such as those using generalized Voronoi graphs or semantic maps, and references the graph-based SLAM appendix section. This provides some support for the claim, as it offers specific examples and references to existing work. However, the comment could be strengthened by providing more detailed comparisons or examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but lacks comprehensive evidence or detailed examples.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the novelty of the proposed method, noting that some of its general ideas are already present in other methods for exploration. It provides specific examples, such as reasoning topologically and long-term storage through pose graphs in SLAM, which are discussed in the graph-based SLAM appendix section. The comment suggests that the paper should discuss the proposed method in relation to these existing approaches. This feedback is clear and actionable, as it directs the authors to consider and address the novelty of their work in the context of existing methods. However, the comment could be more helpful if it provided specific suggestions on how to highlight the differences or improvements of the proposed method. Overall, the comment is mostly helpful, as it provides a clear direction for the authors to enhance the discussion of their work's novelty.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests moving some details from the appendix back into the main text and moving some background information from Section 2 to the appendix. This provides explicit actions for the authors to take, such as identifying which details should be moved back and which background information should be moved to the appendix. The suggestion is concrete, as it outlines specific steps for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of moving experimental details, tasks, and other information to the appendix, which makes it difficult to interpret. It suggests moving some of these details back into the main text and moving some background information from Section 2 to the appendix. This provides a clear and specific suggestion for the authors to consider, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that moving experimental details, tasks, and other information to the appendix makes it difficult to interpret. It suggests moving some of these details back into the main text and moving some background information from Section 2 to the appendix. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim fully. The authors might find it challenging to understand the exact details that need to be moved back or why the background information should be moved to the appendix. Therefore, the comment is somewhat verifiable, as it provides a basis for the suggestion but requires more detailed justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper\\'s organization, noting that moving experimental details, tasks, and other information to the appendix makes it difficult to interpret. It provides a clear suggestion to move some of these details back into the main text and move some background information from Section 2 to the appendix. This feedback is actionable and provides a concrete way for the authors to improve the clarity and accessibility of their work. However, the comment could be more helpful if it specified which details should be moved back or why certain background information should be moved to the appendix. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that \"Memb is apparently the previous state-of-the-art,\" but there is no mention of any reference. This implies that the authors should include a reference to the state-of-the-art work, \"Memb,\" to provide context and support for their claim. However, the comment does not explicitly instruct the authors to include a reference or specify which reference to use. The action is implicit and somewhat vague, as the authors need to infer that they should add a reference but are not given specific guidance on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the mention of \"Memb\" as the previous state-of-the-art without providing a reference. However, it does not specify which part of the paper this issue pertains to, such as a section, table, or figure. The authors can infer that it relates to the discussion or conclusion section, but this inference is not explicit. The comment is specific in identifying the need for a reference but lacks grounding, as it does not specify the exact part of the paper where this issue is present. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"Memb is apparently the previous state-of-the-art,\" but it lacks supporting evidence or references to substantiate this claim. Without specific references or detailed reasoning, the authors may find it challenging to understand the basis of this assertion. The comment is considered unverifiable because it does not provide sufficient justification or evidence to support the claim, leaving the authors without a clear understanding of the basis for the statement. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that \"Memb is apparently the previous state-of-the-art,\" but there is no mention of any reference. This feedback highlights a gap in the paper's documentation, which is important for readers to understand the context and basis of the claim. However, the comment lacks actionable guidance on how the authors should address this issue, such as suggesting specific references to include or providing examples of similar works. While it points out a critical omission, it does not offer detailed advice or suggestions for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples. This feedback is explicit, as it directly instructs the authors to conduct a study on the impact of the ratio of unseen classes. The comment also provides a concrete example of what aspect to investigate, making it highly actionable. The authors know exactly what action to take and how to implement it, aligning with a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes, specifically how the performance varies with different ratios of unseen classes unlabeled examples. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. The authors can infer that it pertains to the experimental design or results, but this inference is not explicit. The comment is specific in its suggestion to study the impact of the ratio of unseen classes, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes on the performance of the model. However, it does not provide any specific reasoning, examples, or references to support why this is important or how it could be studied. The claim lacks detailed justification or evidence, making it difficult for the authors to understand the significance of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should study the impact of the ratio of unseen classes on the performance of their model. It provides a specific example of how the performance might vary with different ratios of unseen classes unlabeled examples, which is a relevant and actionable suggestion. This feedback encourages the authors to explore a potential area of improvement that could enhance the depth and applicability of their work. However, the comment could be more helpful if it included specific guidance on how to conduct this study or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a meaningful area for further investigation, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"For training we used an epsilon-greedy ...,\" suggesting that there might be epsilon-greedy exploration on top of the proposed strategy. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should take to clarify the meaning. As a result, the authors are left without a clear understanding of what action to take or how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"For training we used an epsilon-greedy ...,\" providing a clear indication of what needs to be clarified or addressed in this section. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilon-greedy ...,\" without providing any claim or suggestion for improvement. It does not contain any subjective opinions, judgments, or requests for changes that would require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of a phrase in the paper, specifically \"For training we used an epsilon-greedy ...,\" suggesting that there might be epsilon-greedy exploration on top of the proposed strategy. While the comment identifies a potential area of confusion, it does not provide any actionable feedback or suggestions for clarification or improvement. The authors are left without guidance on how to address this issue or what steps to take to enhance the clarity of their draft. Therefore, the comment is barely helpful, as it highlights a potential issue but lacks actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. It implies that the authors should consider whether this combination offers any novel contributions or if it is merely a direct combination of existing techniques. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or what specific aspects of the method could be improved to make it more novel. The action is implicit and vague, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment discusses the proposed method, suggesting it is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in identifying the combination of techniques and the replacement of the transformed distribution, but it lacks detailed guidance on how the authors might address the concern about the lack of novelty. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method is a direct combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to the novelty of their work. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed method, suggesting that it is a direct combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. The reviewer implies that this combination may lack novelty and encourages the authors to consider whether there are any new contributions. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. While it highlights an important aspect to consider, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. It implies that the authors should consider whether this combination offers any novel contributions or if it is merely a direct combination of existing techniques. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or what specific aspects of the method could be improved to make it more novel. The action is implicit and lacks concrete details, making it barely actionable. The authors are left uncertain about how to respond to the feedback.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment discusses the proposed method, suggesting it is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, it does not specify which part of the paper this observation is based on, making it weakly grounded. The comment is specific in identifying the combination of techniques and the replacement of the transformed distribution, but it lacks detailed guidance on how the authors might address the concern about the lack of novelty. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the proposed method is a direct combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to the novelty of their work. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the proposed method is a combination of GCN and normalizing flow, with the ultimate transformed distribution replaced by a Gaussian mixture distribution. It implies that the authors should consider whether this combination offers any novel contributions or if it is merely a direct combination of existing techniques. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or enhance the novelty of their work. While it highlights an important aspect to consider, the feedback does not provide actionable advice, making it somewhat helpful. Therefore, the comment aligns with a"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and raw-level features, while the former framework (Line 167-174, Sec. 4) does not seem limited to raw-level selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment highlights a specific area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of representation learning should be considered. The action is implicit and somewhat vague, as the authors can infer that they need to address the representation learning aspect, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 4.2\" and \"Line 167-174, Sec. 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the proposed invariant learning module focuses on mask selection and raw-level features, while the former framework does not seem limited to raw-level selection. Additionally, it mentions a discussion about representation learning in the appendix, suggesting that the feature selection in Section 4.2 could be improved by considering representation learning. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed invariant learning module focuses on mask selection and raw-level features, while the former framework does not seem limited to raw-level selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment identifies a potential issue with the focus of the proposed module, it lacks specific examples or detailed reasoning to fully substantiate the claim. The mention of representation learning in the appendix provides some context, but it does not offer a comprehensive explanation or justification for the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional details to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the proposed invariant learning module, specifically noting that it focuses on mask selection and raw-level features, while the former framework does not seem limited to raw-level selection. It also mentions a discussion about representation learning in the appendix. The reviewer suggests that the feature selection, presented in Section 4.2, could be further improved by considering representation learning. While the comment highlights a specific area for improvement, it lacks detailed guidance on how to address this issue or what specific aspects of representation learning should be considered. The feedback is somewhat helpful as it points out a potential gap in the paper's focus, but it could be more actionable with additional suggestions or examples. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors need to clarify or provide more information about the design of rewards, but it does not offer concrete steps or examples of what should be included. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific area where details are missing, mentioning the lack of understanding of how to design rewards. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in terms of what is missing (the design of rewards), it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some details are missing, specifically mentioning the lack of understanding of how to design rewards. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the draft is lacking detail, specifically mentioning the lack of understanding of how to design rewards. This feedback is somewhat helpful as it points out a gap in the paper that the authors need to address. However, it does not provide any suggestions or guidance on how to improve this aspect, such as recommending specific methods or references to consider. The comment lacks depth and actionable advice, leaving the authors with a general idea of what needs improvement but without clear steps to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the runtime of Prithvi WxC should be discussed as a potential limitation for ML-based emulators of climate model parametrizations, given its large parameter count. While the comment implies that the authors should address the runtime, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the runtime. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests discussing the runtime of Prithvi WxC as a potential limitation for ML-based emulators of climate model parametrizations, given its large parameter count. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need to discuss the runtime as a limitation, but without explicit references to sections or figures, the authors may struggle to pinpoint where this discussion should be placed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the runtime of Prithvi WxC should be discussed as a potential limitation for ML-based emulators of climate model parametrizations, given its large parameter count. This claim is somewhat verifiable as it provides a logical reasoning based on the computational cheapness of ML-based emulators, which is a common expectation for such models. However, the comment lacks specific examples or references to support the claim fully. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation of Prithvi WxC, specifically its runtime, which is crucial for ML-based emulators of climate model parametrizations. It suggests that the runtime should be discussed as a limitation, given the large parameter count of Prithvi WxC. This feedback is clear and actionable, as it directs the authors to address a significant aspect of their work that could impact its practical application. However, the comment could be more helpful if it provided specific guidance on how to discuss the runtime or suggested ways to mitigate this limitation. Overall, the comment is mostly helpful as it highlights an important area for improvement and offers a clear direction for the authors to follow.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the importance of ensuring that the paraphrases generated for the training data are significantly different from the original sentences. It explains that this is crucial because the model relies on the quality of these paraphrases, and if the difference is not large enough, the final training data quality will be low, leading to a small number of pairs being added to the new training data. While the comment identifies a potential issue, it does not provide specific guidance on how to address it, such as suggesting methods to ensure significant differences or how to measure this difference. The action is implicit and somewhat vague, as the authors can infer the need for improvement but lack concrete steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of generating paraphrases for the training data, specifically mentioning the need for these paraphrases to be significantly different from the original sentences. This provides some grounding as it refers to a specific aspect of the paper, but it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the importance of the paraphrases and their impact on the model\\'s reliance on quality data. However, it lacks detailed guidance on how to address the issue, such as suggesting methods to ensure significant differences. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of paraphrases used for training data, noting that the difference between paraphrases and original sentences is crucial. It explains that if the difference is not significant, the quality of the final training data will be low, leading to a small number of pairs being added to the new training data. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the impact of paraphrase quality on model performance. The reasoning is logical, but the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue in the paper regarding the generation of paraphrases for the training data. It highlights the importance of ensuring that the paraphrases are significantly different from the original sentences, as this directly impacts the quality of the final training data and the model's performance. The comment provides a clear explanation of why this is important and how it affects the subsequent steps in the process. However, it lacks specific suggestions or guidance on how to address this issue, such as proposing methods to ensure significant differences or how to measure this difference. While the comment points out a significant area for improvement, it could be more helpful with additional details or actionable advice. Therefore, it is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing could be improved, but it does not provide specific guidance on how to achieve this improvement. The authors are left without any explicit or implicit actions to take, such as suggestions for clearer explanations, rephrasing, or additional details. Without concrete steps or examples, the authors are unable to determine how to address the issue effectively. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the writing could be improved, but it does not specify which parts of the paper are difficult to understand or where the theoretical analysis is unclear. This lack of specificity makes it challenging for the authors to identify the exact areas that need improvement. Additionally, the comment does not provide any guidance on how to enhance the writing or what specific issues should be addressed. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the writing could be improved, but it does not provide any specific examples or reasoning to support this claim. The reviewer mentions that it took a lot of effort to understand the main idea and theoretical analysis, but this statement lacks detail and does not offer any constructive feedback or suggestions for improvement. As a result, the claim is not verifiable, as it does not provide enough information for the authors to address the issue effectively. Therefore, the comment is classified as \"1: Unverifiable.\"', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that the writing could be improved, noting that it took a significant effort to understand the main idea and theoretical analysis of the paper. However, it lacks specific suggestions or guidance on how to enhance the writing, such as clarifying complex concepts, improving sentence structure, or providing more detailed explanations. Without actionable feedback or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient guidance for the authors to address it effectively.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the fairness of the comparisons made between the domain-specific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zero-shot single-image 3D reconstruction models. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the fairness of their comparisons. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the comparison of the domain-specific model trained on Pix3D and the experiments conducted on Pix3D, particularly in relation to the fairness of comparisons to zero-shot single-image 3D reconstruction models. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. While the authors can infer that it relates to the comparison section, the lack of explicit grounding makes it difficult for them to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the comparisons between the domain-specific model trained on Pix3D and the experiments conducted on Pix3D are unfair, particularly when compared to zero-shot single-image 3D reconstruction models. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it lacks sufficient justification or evidence to fully support the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the fairness of the comparisons made between the domain-specific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zero-shot single-image 3D reconstruction models. While it identifies a potential issue with the methodology, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their comparisons. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment critiques the fairness of the comparisons made between the domain-specific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zero-shot single-image 3D reconstruction models. However, it does not provide any explicit or implicit actions for the authors to take to address this issue or improve the fairness of their comparisons. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the fairness of the comparisons made between the domain-specific model trained on Pix3D and the experiments conducted on Pix3D, particularly in relation to the comparison to zero-shot single-image 3D reconstruction models. However, it does not specify which part of the paper this critique pertains to, such as a specific section or experiment. While the authors can infer that it relates to the comparison section, the lack of explicit grounding makes it difficult for them to pinpoint the exact part of the paper being addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point critiques the fairness of the comparisons made between the domain-specific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zero-shot single-image 3D reconstruction models. However, the comment lacks specific examples or detailed reasoning to support the claim of unfairness. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the assertion.\", 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment critiques the fairness of the comparisons made between the domain-specific model trained on Pix3D and the experiments conducted on Pix3D, specifically mentioning the unfairness in comparing to zero-shot single-image 3D reconstruction models. While it identifies a potential issue with the methodology, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the fairness of their comparisons. Without actionable feedback or detailed advice, the authors"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. While the action is explicit, it is somewhat vague as it does not specify which aspects of the C2D method should be tested or how the experiments should be designed. The authors are given a clear direction to improve their work, but the comment lacks detailed guidance on execution, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to conduct additional experiments on a particular dataset to support the method, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. However, the comment does not provide any specific reasoning, examples, or references to justify why these experiments would be beneficial or how they would enhance the paper. Without detailed justification or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments on realistic noisy datasets like WebVision to provide more support for the C2D method. This feedback is somewhat helpful as it identifies a specific area where the authors could enhance the robustness and applicability of their findings. However, the comment lacks detailed guidance on how to design these experiments or what specific results should be expected, which limits its usefulness. The authors are given a direction for improvement but would benefit from more detailed suggestions or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the abstract visual reasoning tasks, noting that they are unintuitive and difficult to solve. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or improve their approach. The feedback lacks actionable steps or concrete advice, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment does not specify which part of the paper these tasks are discussed in, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the tasks are problematic or how they could be simplified. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. However, the comment lacks specific examples or evidence to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or references, the claim remains unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises concerns about the abstract visual reasoning tasks, noting their unintuitive nature and difficulty. It questions the complexity of the tasks, including the presence of multiple rows and factors changing between frames, and asks whether simpler tasks might be more appropriate. The comment also seeks clarification on whether the current formulation is the best approach. While it identifies potential issues, the feedback lacks specific suggestions or actionable steps for the authors to address these concerns. The comment provides a starting point for reflection but does not offer detailed guidance on how to improve the draft. Therefore, it is somewhat helpful, as it prompts the authors to consider alternative approaches but does not fully support them in making those changes.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details or examples of what specific visualizations or comparisons are needed, leaving the authors without a clear path forward. As a result, the action is implicit and vague, making it barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of essential visualization of intermediate processes and comparisons. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in identifying the need for more visualization, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement, noting the lack of essential visualization of intermediate processes and comparisons. However, it does not provide any guidance or suggestions on how the authors might address this issue, such as recommending specific types of visualizations or comparisons that could be included. Without actionable advice or examples, the comment is vague and does not offer the authors a clear path to improve their draft. Therefore, it is barely helpful, as it highlights a potential weakness but lacks actionable feedback.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the expected counterfactual, stating that it violates $\\mathcal{P}_2$ as defined in Definition 1. However, it does not provide any guidance or suggestions on how the authors should address this issue or what steps they should take to rectify it. The comment lacks explicit or implicit actions, leaving the authors without a clear understanding of what changes or improvements are needed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the expected counterfactual, stating that it violates $\\mathcal{P}_2$. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected counterfactual violates $\\mathcal{P}_2$ as stated in Definition 1. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the expected counterfactual, stating that it violates $\\mathcal{P}_2$ as defined in Definition 1. However, it does not provide any further explanation or guidance on how this violation affects the paper or what steps the authors should take to address it. The comment lacks depth and actionable suggestions, leaving the authors with a clear understanding of the issue but without a clear path forward for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the importance of the results and the iteration complexity, referencing a previous work [15] that claims perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer notes that the decentralized algorithm with occasional noise is expected to escape saddle points in polynomial time, given this prior work. Additionally, the comment points out that Theorem 3 shows a $d$ dependency instead of a $log d$ dependency, indicating a loss of dimension-free iteration complexity. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns or improve their results. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concerns about the importance of the results, the iteration complexity, and the loss of dimension-free iteration complexity in Theorem 3. The reviewer references a previous work [15] to provide context and highlights the specific issues with the iteration complexity. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the importance of the results and the iteration complexity, referencing a previous work [15] that claims perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer notes that the decentralized algorithm with occasional noise is expected to escape saddle points in polynomial time, given this prior work. However, the comment points out that Theorem 3 shows a $d$ dependency instead of a $log d$ dependency, indicating a loss of dimension-free iteration complexity. While the comment provides a logical reasoning based on previous work, it lacks specific examples or detailed references to substantiate the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the concern but could benefit from more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the importance of the results and the iteration complexity, referencing a previous work [15] that claims perturbed gradient descent can find second-order stationary points with almost-dimension-free polynomial iteration complexity. The reviewer notes that the decentralized algorithm with occasional noise is expected to escape saddle points in polynomial time, given this prior work. However, the comment points out that Theorem 3 shows a $d$ dependency instead of a $log d$ dependency, indicating a loss of dimension-free iteration complexity. While the comment identifies specific issues with the iteration complexity, it lacks actionable suggestions or guidance on how the authors might address these concerns or improve their results. The feedback is somewhat helpful as it highlights areas for improvement but does not provide detailed advice or constructive feedback that could lead to significant enhancements in the draft. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what steps they should consider. Without specific instructions or suggestions, the authors are left without a clear understanding of what action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether the grid search for learning rate is conducted on the validation set. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the validation set, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the methodology used in the grid search for learning rate, specifically whether it is conducted on the validation set. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about whether the grid search for learning rate is conducted on the validation set. While it identifies a potential issue or area for clarification, it does not provide any additional context, suggestions, or guidance on how the authors might address this concern. The comment lacks depth and specificity, leaving the authors without actionable feedback or insights into how to improve their work. Therefore, it is rated as barely helpful, as it provides a starting point for the authors but does not fully support their efforts to enhance their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the generalizability of the results to different groups, specifically marginalized groups. It prompts the authors to consider the diversity of the sample, including racial and economic diversity. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to improve the generalizability of their results. The action is implicit and somewhat vague, as the authors need to infer that they should explore the diversity of their sample and consider its implications for generalizability. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L393,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the generalizability of the results to different groups, particularly marginalized groups, and suggests considering racial and economic diversity in the sample. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the generalizability of the results to different groups, specifically marginalized groups, and asks about the diversity of the sample, including racial and economic diversity. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim or suggest why this is a concern. Without additional context or justification, the comment lacks verifiability, making it difficult for the authors to understand the basis of the question and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the generalizability of the results to different groups, particularly marginalized groups. It prompts the authors to consider the diversity of their sample, including racial and economic diversity, and its implications for the broader applicability of their findings. This feedback is valuable as it encourages the authors to reflect on the representativeness of their dataset and its potential limitations. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue, such as recommending additional analyses or data collection to enhance diversity. Overall, the comment is somewhat helpful as it identifies an important area for consideration but lacks detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the number of images in the VioT dataset, suggesting that it may be insufficient to validate the approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting additional data collection or analysis. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"3.1. VioT dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the number of images provided is small, which may affect the validity of the approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of images in the VioT dataset is small, which may affect the validity of the approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern, making the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a potential issue with the VioT dataset, noting that it consists of only 20 images in each of the four categories. This observation is relevant as it questions the sufficiency of the dataset for validating the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this concern, such as recommending additional data collection or analysis. While it highlights an important aspect to consider, the feedback is incomplete and does not provide actionable steps for improvement. Therefore, it is rated as somewhat helpful, as it provides some insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights several issues with the paper, including its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It suggests that more intuitive explanations are needed and that figure captions should include additional explanations and legends, such as explaining the colors in Fig. 2. However, the comment does not provide specific guidance on how to improve the explanations or what aspects of the derivations need more intuitive explanations. While the authors can infer that they need to enhance the clarity of their work, the lack of detailed instructions makes the comment somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment identifies several issues with the paper, including its difficulty in following the mathematical derivations and the lack of explanations in figure captions. It specifies that more intuitive explanations are needed and that figure captions should include additional explanations and legends, such as explaining the colors in Fig. 2. However, the comment does not explicitly mention which sections or figures are being referred to, making it weakly grounded. The authors can infer that the issues are related to the methodology and figures, but the lack of specific references makes it challenging to pinpoint the exact parts needing improvement. The comment is specific in detailing what needs to be addressed, such as providing intuitive explanations and figure captions, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper is hard to follow and suggests that more intuitive explanations on mathematical derivations are needed. It also points out the lack of explanations in figure captions, such as the colors in Fig. 2. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies several areas where the paper could be improved, specifically noting that the paper is hard to follow and suggesting the need for more intuitive explanations on mathematical derivations. It also points out the lack of explanations in figure captions, such as the colors in Fig. 2, and notes that figures did not contribute much to understanding. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to enhance the clarity and intuitiveness of the explanations. The authors are left with a general understanding of what needs to be improved but without detailed steps to implement these changes. Therefore, the comment is somewhat helpful, as it provides some insight but could be more comprehensive and actionable.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices and emphasizes the importance of addressing this issue. It suggests that the authors should consider this aspect and potentially revisit the rating if the issue is resolved. While the comment highlights a critical area for improvement, it does not provide explicit guidance on how to address the sensitivity or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the sensitivity of their results and potentially revise their rating. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the sensitivity of the empirical results to hyperparameter choices, which is a critical aspect of the paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the importance of addressing this issue, as it could potentially affect the validity of the results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a valid concern in any experimental work. However, the comment does not provide specific examples or detailed reasoning to support why this issue is particularly critical or how it could affect the results. The mention of \"conceivably\" suggests that the reviewer is speculating on the potential impact, which makes the claim somewhat verifiable. The authors would need to provide more detailed evidence or examples to fully address this concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, which is a common issue in experimental work. It highlights the potential impact of incorrect hyperparameter choices on the validity of the results, emphasizing the importance of addressing this issue. The comment is specific and actionable, as it prompts the authors to consider the sensitivity of their results and potentially revisit their rating if the issue is resolved. This feedback is valuable as it guides the authors in improving the robustness and reliability of their experimental findings. However, the comment could be more helpful if it provided specific suggestions or examples on how to address the sensitivity issue. Overall, the comment is mostly helpful, as it directs the authors to a critical area for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point critiques the motivation of the paper, specifically regarding the cross-encoder architecture. It clarifies that the architecture does not 'ignore cross-entity comparison' and 'attends to all candidates at once' to obtain final matching scores. However, the comment does not provide explicit guidance on how the authors should address this issue or improve their motivation. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to enhance their draft. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment critiques the motivation of the paper, specifically regarding the cross-encoder architecture. It clarifies that the architecture does not 'ignore cross-entity comparison' and 'attends to all candidates at once' to obtain final matching scores. However, the comment does not specify which part of the paper this critique is based on, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity in detailing what aspects of the motivation are unclear or need improvement. Therefore, the comment is not grounded and not specific, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point challenges the claim that the cross-encoder architecture 'ignores cross-entity comparison' and 'attends to all candidates at once' to obtain final matching scores. It provides a counterpoint by explaining that the architecture does not ignore cross-entity comparison and attends to all candidates simultaneously. However, the comment lacks specific examples or references to support the claim that the architecture is not as fine-grained as implied. This makes the claim somewhat verifiable, as it provides a logical argument but requires further evidence or examples to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the motivation of the paper, specifically regarding the cross-encoder architecture. It clarifies that the architecture does not 'ignore cross-entity comparison' and 'attends to all candidates at once' to obtain final matching scores, which is a significant point of clarification. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their motivation or clarify their claims. While it identifies a potential area for improvement, it does not offer actionable feedback or detailed insights, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the work uses an antiquated GNN model and method, which impacts the performance of the framework. It also mentions that the baseline algorithms/methods are antiquated. However, the comment does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the model or methods, nor are there suggestions for alternative approaches or references to more recent work. As a result, the authors are left without any actionable steps to address the issues raised. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment criticizes the use of an antiquated GNN model and method, as well as the antiquated baseline algorithms/methods. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to identify the exact sections that need revision. The comment lacks specificity in detailing what specific aspects of the model or methods are outdated or how they impact the performance. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work uses an antiquated GNN model and method, which impacts the performance of the framework. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples, comparisons, or references to more recent and effective models, the authors are left without a clear understanding of the basis for this critique. As a result, the claim is unverifiable, as it lacks the necessary justification to be actionable for the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of an antiquated GNN model and method, which is likely to impact the performance of the framework. It also points out that the baseline algorithms/methods are also antiquated. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address these issues. Without detailed feedback or recommendations for improvement, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, as it highlights a concern but does not offer actionable insights or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the experiment, specifically the reliance on pseudo feature importance due to the lack of true feature importance. It suggests that the experiment could be strengthened by addressing the difference between the tested method and the pseudo feature importance. The comment implies that the authors should consider using a different approach or providing more detailed analysis to strengthen the experiment. While the action is implicit, it is concrete as it provides a clear direction for improvement. The authors know exactly what needs to be done to strengthen the experiment, making this comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"one experiment\" and \"Prop 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the reliance on pseudo feature importance and the need for a stronger experiment. The comment provides clear guidance on how to strengthen the experiment by addressing the difference between the tested method and the pseudo feature importance. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiment is difficult to trust because the difference between the tested method and the pseudo feature importance is only the number of perturbations. The reviewer supports this claim by referencing \"Prop 3.2\" and the need for a large enough perturbation value to ensure the correctness of the pseudo feature importance. This provides some justification for the claim, but it could be strengthened by offering more detailed reasoning or examples. Therefore, the comment is somewhat verifiable, as it provides a logical basis for the claim but lacks full detail.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experiment, noting that the use of pseudo feature importance due to the lack of true feature importance makes it difficult to trust the results. It suggests that the experiment could be strengthened by addressing the difference between the tested method and the pseudo feature importance, such as by using a different approach or providing more detailed analysis. This feedback is clear and actionable, offering the authors a concrete way to improve the robustness and credibility of their experiment. However, the comment could be more helpful if it provided specific suggestions or examples of how to strengthen the experiment. Overall, the comment is mostly helpful, as it guides the authors toward a more effective approach to address the identified issue.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue regarding the experimental settings, specifically noting that the results are not reproducible due to missing code. It explicitly instructs the authors to provide the code, which is a clear and direct action. This feedback is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of experimental settings and result reproducibility, specifically mentioning that the results are not reproducible due to missing code. However, it does not specify which part of the paper discusses the experimental settings or results, making it weakly grounded. The comment is specific in identifying the need for code to ensure reproducibility, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly and that result reproducibility is critical using the provided information. However, it does not provide specific examples or detailed reasoning to support why the experimental settings are not mentioned properly or how the lack of code impacts reproducibility. The comment lacks detailed justification or references to substantiate the claim, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the experimental settings, specifically noting that the results are not reproducible due to missing code. This feedback is clear and actionable, as it directly points out a significant weakness in the paper that needs to be addressed. By highlighting the need for code to ensure reproducibility, the comment provides a clear direction for improvement. However, it could be more helpful if it offered suggestions on how to provide the code or where to include it in the paper. Overall, the comment is mostly helpful as it directs the authors to a critical area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback. It suggests that if the feedback is auto-generated, the authors might consider manually reviewing or generating different types of feedback to better reflect a real-life situation. While the comment implies an action, it does not explicitly instruct the authors to take this step. The suggestion is vague, as it does not provide specific guidance on how to generate different kinds of feedback or how to implement this change. Therefore, the comment is somewhat actionable, as it provides a direction but lacks concrete details on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is auto-generated, the authors might consider manually reviewing or generating different types of feedback to better reflect a real-life situation. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in suggesting a potential solution to address the lack of diversity in the feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of lexical and syntactic diversity in the teacher feedback, suggesting that if the feedback is auto-generated, the authors might consider manually reviewing or generating different types of feedback to better reflect a real-life situation. However, the comment does not provide specific examples or references to support the claim that the diversity is lacking. The suggestion to manually review or generate different feedback is a logical response to the concern, but without additional evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the lack of lexical and syntactic diversity in the teacher feedback, particularly if it is auto-generated. It suggests that the authors might consider manually reviewing or generating different types of feedback to better reflect a real-life situation. This feedback is somewhat helpful as it points out a specific area for improvement and provides a potential solution. However, it could be more helpful if it included specific examples or guidance on how to generate diverse feedback. Overall, the comment offers a direction for improvement but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the main text should clarify the presence of additional experiments in the supplement and ideally summarize their results. It also includes a question, which is an implicit request for more information. While the action is explicit in terms of clarifying the presence of additional experiments, the suggestion to summarize their results is vague, as it does not provide specific guidance on how to summarize the results. The authors can infer that they need to include more information about the supplementary experiments, but the comment lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main text should clarify the presence of additional experiments in the supplement and ideally summarize their results. However, it does not specify which part of the main text should be revised or where the additional experiments are located. This lack of explicit reference to specific sections or elements makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to clarify the presence of additional experiments and summarize their results, but it lacks grounding as it does not specify where these experiments are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a request for clarification and a question, which do not contain claims or opinions that require verification. They are factual statements seeking additional information or explanation. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the main text, suggesting that it should clarify the presence of additional experiments in the supplement and ideally summarize their results. This feedback is clear and actionable, as it provides a direct suggestion for improvement by making the main text more comprehensive. However, the comment could be more helpful if it offered specific guidance on how to summarize the results or what aspects of the additional experiments should be highlighted. Overall, the comment is mostly helpful as it directs the authors to an area that needs improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly suggests that the authors should compare their performance with two specific works: 'Multilingual unsupervised neural machine translation with denoising adapters' and 'MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer'. This is a clear and direct action for the authors to take, as it provides specific references to compare with. The comment also specifies that these works involve training adapters on top of a well-trained multilingual pretrained model, which gives the authors a clear idea of what to look for in these comparisons. Therefore, the comment is highly actionable, as it provides explicit and concrete guidance on how to improve the draft by including relevant comparisons.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment suggests comparing the performance with two specific works: 'Multilingual unsupervised neural machine translation with denoising adapters' and 'MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer'. However, it does not specify which part of the paper this recommendation pertains to, such as a section or a particular experiment. This makes it difficult for the authors to identify the exact area where this comparison should be included. Additionally, the comment lacks specificity in detailing what aspects of the performance should be compared or how the comparison should be conducted. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.\", 'grounding_specificity_label': '1', 'verifiability_rationale': \"The review point suggests comparing the performance of the current work with two specific works: 'Multilingual unsupervised neural machine translation with denoising adapters' and 'MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer'. However, the comment does not provide any reasoning or evidence to support why these particular works are relevant or why their inclusion would be beneficial. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for the authors to compare their performance with two specific works: 'Multilingual unsupervised neural machine translation with denoising adapters' and 'MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer'. This recommendation is highly helpful as it directs the authors to relevant literature that could enhance the comprehensiveness and impact of their study. By including these comparisons, the authors can better position their work within the existing literature and potentially identify areas for improvement or innovation. The comment is specific and provides a concrete step for the authors to take, making it highly helpful for improving the draft.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests that the authors consider extending their approach to more general settings. While the comment implies that the authors should explore broader applicability, it does not provide explicit guidance on how to achieve this extension or what specific aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the extent of the extension required. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. However, the comment does not specify which part of the paper discusses the current setting or how it could be extended. This makes it difficult for the authors to identify the exact sections that need revision. While the comment is specific in terms of the limitations it identifies, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point identifies specific limitations of the current setting, such as the need for knowledge of the model or access to a generative model, and the requirement for episodic problems with rewards given at the end of a task. It then suggests extending the approach to more general settings. While the comment provides a clear rationale for the need to extend the approach, it lacks specific examples or references to support the claim that these limitations are unique to the current setting. The suggestion to extend the approach is logical, but without detailed guidance or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific limitation of the current setting, noting that it requires knowledge of the model or access to a generative model, and that the problem should be episodic with a reward given at the end of a task. It then suggests extending the approach to more general settings. This feedback is somewhat helpful as it points out a potential area for improvement and encourages the authors to consider broader applicability. However, the comment could be more helpful if it provided specific suggestions or examples of how to extend the approach to more general settings. Overall, the comment offers a direction for improvement but lacks depth and detail, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point is explicit in its request for clarification regarding the feature extractor used for the dimensionality of each region, which is specified as 512. This is a clear and direct action for the authors to take, as it prompts them to provide the specific feature extractor used in their work. The comment is concrete, as it specifies exactly what information is needed to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the feature extractor used for the dimensionality of each region, which is specified as 512. This provides clear guidance on what information is missing or needs clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a factual statement seeking clarification about the feature extractor used for a specific dimensionality. It does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The comment is clear and actionable, seeking clarification on the feature extractor used for the dimensionality of each region, which is specified as 512. This is a specific and direct request for information that can help the authors provide more context or details about their methodology. By addressing this question, the authors can enhance the transparency and reproducibility of their work. However, the comment could be more helpful if it provided additional context or suggestions on why this information is important. Overall, the comment is mostly helpful as it guides the authors towards a specific area of improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer that they should add these details but are not given clear guidance on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper lacks these details or where they should be included. This makes it difficult for the authors to identify the exact sections that need revision. The comment is not grounded because it does not reference specific parts of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not provide any specific reasoning, examples, or references to support why these details are necessary or how they would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be beneficial for readers. While this is a reasonable suggestion, it lacks specificity and does not offer detailed guidance on how to include these details or where they should be placed in the paper. Without actionable advice or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks depth and clarity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies two specific areas for improvement: the lack of analysis of the effectiveness of each data augmentation method and the need to compare the approach to other paraphrasing methods like EDA or LLM-based paraphrasing. It also suggests references for further reading. While the comment provides explicit actions for the authors to take, it does not offer detailed guidance on how to conduct the analysis or compare methods. The authors are aware of what needs to be done but may require additional information to fully implement the suggestions. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"data augmentation method\" and \"paraphrasing methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be improved, such as the lack of analysis and the need to compare the approach to other paraphrasing methods like EDA or LLM-based paraphrasing. The comment further provides references for the authors to consider, making it specific and actionable. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of the effectiveness of each data augmentation method is insufficient and suggests comparing the approach to other paraphrasing methods like EDA or LLM-based paraphrasing. The comment provides references to support the claim, such as [1] Allen-Zhu et al., Physics of language models: Part 3.1, knowledge storage and extraction, and [2] Ovadia et al., Fine-tuning or retrieval? comparing knowledge injection in llms. This provides a solid foundation for the claim, making it mostly verifiable. However, the comment could be strengthened by elaborating on why these comparisons are necessary or how they would enhance the analysis. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the analysis of the paper, specifically the lack of analysis of the effectiveness of each data augmentation method. It suggests that comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, would clarify the unique advantages of the proposed method. The comment also provides references to relevant literature, which can guide the authors in expanding their analysis and understanding of the field. This feedback is clear and actionable, offering the authors a concrete direction for improvement. However, it could be more helpful if it included specific suggestions on how to conduct the analysis or compare methods. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for enhancing the draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an ablation study is necessary to understand the net effect of each component in the proposed model. It provides specific examples of what could be included in the ablation study, such as using a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This guidance is explicit and concrete, as it clearly outlines the actions the authors should take to address the issue. The authors know exactly what needs to be done to improve their draft, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the need for an ablation study to understand the net effect of each component in the proposed model, specifically mentioning \"learning with MMD.\" However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting an ablation study to evaluate the effect of each component, but without full grounding, it is challenging for the authors to pinpoint the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an ablation study is necessary to understand the net effect of each component in the proposed model, specifically mentioning \"learning with MMD.\" However, the comment does not provide specific examples or detailed reasoning to support why an ablation study is crucial or how it would benefit the understanding of the model. The suggestion is vague and lacks detailed justification, making it difficult for the authors to fully grasp the importance of the proposed action. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a critical area for improvement in the paper, specifically the lack of an ablation study to understand the net effect of each component in the proposed model. It provides a clear suggestion by suggesting specific ablation studies, such as using a typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. This feedback is actionable and offers a concrete path for the authors to enhance their work by providing a detailed analysis of the model components. However, the comment could be more helpful if it included additional guidance on how to conduct these ablation studies or what specific insights they might yield. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement and provides a clear direction for enhancing their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider this scenario, it does not provide explicit guidance or suggestions on how to address this question or what implications it might have for the paper. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this scenario in their analysis. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment poses a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may have to infer that it relates to the experimental results or discussion of negative samples. While the comment is specific in its question, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. It does not contain any claims, opinions, or suggestions that require verification. It is a factual question seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the performance of a model that assigns all negative samples to a distractor class. While it prompts the authors to consider a specific scenario, it does not provide any guidance or suggestions on how to address this question or what implications it might have for the paper. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it identifies a potential area for exploration but does not offer actionable insights or suggestions.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time. This provides a clear and direct action for the authors to take, which is to include such quantitative analysis to substantiate the claimed computational benefits. The comment is concrete, as it specifies what needs to be added to the paper to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"lack of quantitative analysis on computational gains,\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out the absence of specific measurements or comparisons to substantiate the claimed computational benefits. The comment is specific in detailing what needs to be addressed, namely the inclusion of quantitative analysis such as GPU hours, memory usage, or training time. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a quantitative analysis of computational gains, specifically mentioning the need for measurements like GPU hours, memory usage, or training time. This claim is supported by logical reasoning, as it highlights the importance of providing concrete evidence to substantiate the claimed computational benefits. However, the comment could be strengthened by providing specific examples or references to similar studies that have included such analyses. Therefore, the claim is mostly verifiable, as it provides a clear rationale but lacks detailed evidence or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing quantitative analysis of computational gains. It highlights the lack of measurements or comparisons, such as GPU hours, memory usage, or training time, which would substantiate the claimed efficiency improvements in the DQ V2 model. This feedback is clear and actionable, as it directs the authors to include such quantitative analysis to strengthen their claims. However, the comment could be more helpful if it suggested specific methods or tools for conducting this analysis. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing methods, implying that the method is less efficient for these scenes. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the time factor in their comparisons. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the comparison of methods, specifically mentioning COLMAP and scene-by-scene fine-tuning. However, it does not specify which part of the paper this comparison is discussed in, making it weakly grounded. The comment is specific in suggesting that the time taken for these processes should be considered when comparing methods, indicating what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing methods, suggesting that the method is less efficient for these scenes. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of methods, specifically mentioning the time taken for COLMAP and scene-by-scene fine-tuning. It suggests that this time factor should be considered when comparing methods, implying that the method may be less efficient for these scenes. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it points out a relevant aspect, the feedback is incomplete and does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the \"filter manifold network\" (FMN), including the lack of discussion or analysis, the need for experimentation with other architectures, and the scalability of adaptive convolutions with the number of filter parameters. The reviewer also questions the scalability of FMN with larger input and output channels. While the comment identifies specific areas for improvement, it does not provide explicit guidance or suggestions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer the necessary steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"filter manifold network\" (FMN), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and concerns about the FMN, including the lack of discussion, experimentation with other architectures, and scalability issues. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the discussion and analysis of the \"filter manifold network\" (FMN), suggesting that there is a lack of discussion or analysis. It also questions whether the authors have experimented with other architectures for FMN and whether the adaptive convolutions scale with the number of filter parameters. The comment provides specific areas for improvement, such as the need for more discussion or experimentation, but it lacks detailed reasoning or references to support these claims. The authors are left to infer the significance of these questions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's discussion and analysis of the 'filter manifold network' (FMN), which is a crucial component of the technique. It raises several questions about the lack of discussion, experimentation with other architectures, and the scalability of adaptive convolutions with the number of filter parameters. This feedback is valuable as it points out areas where the authors could enhance their analysis and provide more depth to their work. However, the comment could be more helpful if it offered suggestions or guidance on how to address these issues, such as recommending specific experiments or analyses to conduct. Overall, the comment is mostly helpful as it highlights important areas for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should investigate the individual contributions of noise and the exponential moving average to the proposed model. It implies that the authors should conduct experiments to determine the impact of each factor on the model\\'s performance. The comment provides a clear action for the authors to take, which is to perform specific experiments to assess the contributions of each factor. However, it does not specify how to design or execute these experiments, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed guidance on execution.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests that the authors should investigate the individual contributions of noise and the exponential moving average to their proposed model. It implies that the authors should conduct experiments to determine the impact of each factor on the model\\'s performance. However, the comment does not specify which part of the paper discusses these factors, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicitly mentioned. The comment is specific in suggesting a direction for further analysis, but without explicit grounding, it is challenging for the authors to pinpoint the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It implies that the authors should investigate the individual contributions of these factors to the model\\'s performance. However, the comment does not provide specific evidence, examples, or references to support the claim that these factors are beneficial or how they contribute to the model. Without detailed reasoning or references, the claim remains vague and difficult for the authors to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should investigate the individual contributions of noise and the exponential moving average to their proposed model. It implies that the authors should conduct experiments to determine the impact of each factor on the model\\'s performance. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their understanding of the model\\'s components. However, the comment could be more helpful if it included suggestions on how to design or interpret these experiments. Overall, the comment is mostly helpful as it guides the authors towards a meaningful area of exploration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent's behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what changes they should make to their draft. The feedback is vague and lacks actionable steps, leaving the authors uncertain about how to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\\'s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what needs to be addressed or improved in the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the reporting of results only after a significant amount of training, suggesting that the agent\\'s behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. However, the comment lacks specific evidence, examples, or references to support this claim. The reasoning is based on speculation rather than concrete evidence, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the reporting of results only after a significant amount of training, suggesting that the agent's behavior during learning might be more relevant. It speculates that early in training, the model parameters might be ineffective and the planning component might hinder performance. While the comment identifies an area for improvement, it lacks specific suggestions or actionable steps for the authors to address this issue. The feedback is somewhat helpful as it points out a potential weakness in the paper's presentation, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks the authors to clarify whether they consider documents as entire sentences in the context of the DocRED dataset. It also inquires about how the authors handle concepts with multiple entity mentions referring to the same entity. These questions provide clear and direct actions for the authors to take, such as adding this information to the manuscript. The comment is explicit and concrete, offering specific guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DocRED,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the authors consider documents as entire sentences and how they deal with concepts involving multiple entity mentions referring to the same entity. This provides clear guidance on what information is missing from the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification on specific aspects of the paper, such as whether documents are considered as entire sentences and how concepts with multiple entity mentions are handled. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the handling of documents in the context of the DocRED dataset, particularly regarding whether they are considered as entire sentences and how concepts with multiple entity mentions are addressed. This feedback is clear and actionable, as it prompts the authors to clarify these aspects in their manuscript. By addressing this question, the authors can provide more detailed information that could enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included suggestions on how to handle these issues or examples of how other studies have addressed similar concerns. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the marginal contribution of the work, suggesting that the methods used are well-designed and demonstrated. It also questions the need for adding another stream for low-resolution, implying that this might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve their contribution. The action is implicit and vague, as the authors are left to infer that they need to justify the significance of their work or consider alternative approaches. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment expresses a concern about the marginal contribution of the work, suggesting that the methods used are well-designed and demonstrated. It questions the need for adding another stream for low-resolution, implying that this might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or method, making it difficult for the authors to identify the exact area needing revision. Additionally, the comment lacks specificity in detailing what aspects of the contribution are marginal or how the addition of another stream might be significant. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is marginal because the methods used are well-designed and demonstrated, and adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. However, the comment lacks specific reasoning or evidence to support these claims, such as detailed comparisons with existing work or examples of how the methods are well-designed. Without additional context or justification, the authors may find it challenging to understand the basis of the critique, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment expresses a concern about the marginal contribution of the work, suggesting that the methods used are well-designed and demonstrated, and adding another stream for low-resolution might not be a significant contribution for a top-tier venue like ICLR. While the comment identifies a potential issue with the contribution, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the significance of their work. The feedback is somewhat helpful as it points out a potential weakness, but it does not provide actionable advice or detailed insights that could help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not include any explicit or implicit actions for the authors to take. The comment mentions that the reviewer did not read additional experiments in the Appendix due to time constraints, but this does not provide any guidance or suggestions for improvement. As a result, the authors are left without any actionable steps to address the feedback. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not specify which parts of the paper are being addressed or what specific issues are being discussed. The mention of \"additional experiments described in the Appendix\" provides some context, but it does not allow the authors to pinpoint the exact sections or elements being discussed. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not contain any claims, opinions, or suggestions that require verification. It is a statement of appreciation and does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses appreciation for the comprehensive Appendix, which provides additional detail about parts of the paper. However, it does not offer any specific feedback or suggestions for improvement, nor does it highlight any particular areas that need attention or clarification. The comment lacks actionable guidance or insights that could help the authors enhance their draft. As a result, the feedback is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. While the comment implies that the authors should expand their experimental scope to include these tasks, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer the need for additional experiments, but it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of results. This makes it difficult for the authors to identify the exact section where this improvement is needed. Additionally, the comment lacks specificity in detailing what specific challenges or tasks should be addressed to demonstrate scalability. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate the scalability of their method, LFF, by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is somewhat verifiable as it provides a logical reasoning for why such tasks are important to demonstrate scalability. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper's demonstration of the scalability of the proposed method, LFF. It suggests that the authors should expand their experimental scope to include more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and applicability of their method. By addressing this suggestion, the authors can strengthen their paper's claims and demonstrate the versatility of their approach. However, the comment could be more helpful if it included specific guidance on how to design and conduct these additional experiments. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point provides a list of references to other works in the field, including MISA, M2FNet, and MM-DFN. However, it does not offer any explicit or implicit actions for the authors to take regarding these references. There is no guidance on how the authors should incorporate these references into their paper or what specific aspects of their work should be compared or discussed with these references. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions specific references, such as MISA, M2FNet, and MM-DFN, which are relevant to the field of multimodal sentiment analysis. However, it does not specify which part of the paper these references are relevant to, making it difficult for the authors to identify the exact section that needs attention. The comment also critiques the paper by suggesting that MULT is considered the only deep learning-based baseline that considers cross-sensory interaction, but it is out of fashion since it was proposed in 2019. While the comment provides some context, it lacks specificity in terms of what aspects of the paper need improvement or clarification. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction, but MULT was proposed in 2019 and is considered out of fashion. However, the comment does not provide any specific evidence or reasoning to support this claim. It lacks detailed references or examples to substantiate the assertion that MULT is outdated or out of fashion. Without additional context or justification, the claim remains unverifiable, as it does not provide the authors with a clear understanding of why MULT is considered outdated or out of fashion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a list of references to other works in the field of multimodal sentiment analysis, including MISA, M2FNet, and MM-DFN. However, it does not offer any specific feedback or suggestions on how the authors might use these references to improve their paper. The comment also critiques the paper by suggesting that MULT is considered the only deep learning-based baseline that considers cross-sensory interaction, but it is out of fashion since it was proposed in 2019. While this observation may be relevant, it does not provide actionable guidance or suggestions for the authors to enhance their work. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that W1 and W2 are not defined in the paper, suggesting that they might denote the Encoder and the Decoder network. It also mentions that W and V are not defined in Eq. 3, which is similar to the issue with W1 and W2. However, the comment does not provide explicit instructions on how the authors should define these terms or where they should be defined. The action is implicit and somewhat vague, as the authors need to infer that they should define these terms in the appropriate sections. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides explicit references to page 3, line A4, and Eq. 3, allowing the authors to accurately identify the parts of the paper being addressed. This level of detail ensures full grounding. Additionally, the comment specifies what needs to be addressed, namely the need to define these terms, making it specific. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that W1 and W2 are not defined in the paper, and it suggests that they might denote the Encoder and the Decoder network. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies specific issues with the paper, namely the lack of definitions for W1 and W2, as well as W and V in Eq. 3. It provides clear and actionable feedback by suggesting that these terms might denote the Encoder and the Decoder network, which could help the authors clarify their notation. However, the comment could be more helpful if it offered suggestions on how to define these terms or where they should be defined in the paper. Overall, the comment is mostly helpful as it directs the authors to address a critical issue in their draft, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what changes they might consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore the impact of this process on performance and potentially adjust their methodology accordingly. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between generating negative chips and training the network might impact performance. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the process and its potential impact on performance, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the process of generating negative chips and their update during RPN training. It suggests that alternating between these two processes might impact performance and asks for clarification. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve performance. The feedback is somewhat helpful as it prompts the authors to consider the impact of their methodology on performance, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should evaluate their proposed approach on new patients and old patients separately, given that the patients are first-time visitors without historical reports. This is an explicit action that provides clear guidance on how the authors can improve their work. The suggestion is concrete, as it specifies the type of evaluation needed and the distinction between new and old patients. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests evaluating the proposed approach on new patients and old patients separately, given that the patients are first-time visitors without historical reports. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the evaluation or experimental setup, but this inference is not explicit. The comment is specific in its suggestion to evaluate the approach on new and old patients, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests evaluating the proposed approach on new patients and old patients separately, given that the patients are first-time visitors without historical reports. This is a logical suggestion that aligns with common practices in evaluating new methodologies. However, the comment does not provide specific examples or references to support the claim that evaluating on new and old patients is necessary. The reasoning is based on general knowledge of evaluation practices, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should evaluate their proposed approach on new patients and old patients separately, given that the patients are first-time visitors without historical reports. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation methodology. By distinguishing between new and old patients, the authors can gain a better understanding of the performance of their approach across different patient populations. This suggestion is valuable as it offers a concrete way to enhance the robustness and generalizability of the study. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper lacks in-depth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis of this training dynamics would strengthen the paper. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to approach it. The action is implicit and somewhat vague, as the authors need to infer that they should include an analysis but are not given detailed instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks in-depth analysis and questions why inverse scaling occurs over compute. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its request for an analysis explaining the training dynamics, which provides some guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks in-depth analysis and questions why inverse scaling occurs over compute. It implies that providing an analysis would strengthen the paper. However, the comment does not provide specific reasoning or evidence to support why this analysis is necessary or how it would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a lack of in-depth analysis in the paper, specifically questioning why inverse scaling occurs over compute. It suggests that providing an analysis of this training dynamics would significantly strengthen the paper. While the comment highlights an important area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what aspects should be included. The feedback is somewhat helpful as it points out a critical gap in the paper's analysis but could be more comprehensive with detailed advice or examples. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two questions that seek additional insights and performance evaluations. The first question asks for additional insights into modest performance gains on the Clothing1M dataset, while the second question inquires about the algorithm\\'s performance on other real-world datasets like WebVision, evaluated by DivideMix. These questions provide explicit actions for the authors to take, as they are asking for specific information or analysis that could enhance the paper. However, the questions are somewhat vague as they do not specify how the authors should incorporate this information into their draft or what specific details are needed. The authors know they need to provide additional insights or performance evaluations, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment consists of two questions, one about additional insights into modest performance gains on the Clothing1M dataset and the other about the algorithm\\'s performance on other real-world datasets like WebVision, evaluated by DivideMix. While the questions are specific in terms of what information is being sought, they do not provide explicit references to specific parts of the paper where these insights or evaluations should be addressed. The authors can infer that the questions relate to the results or discussion sections, but this inference is not as clear as it could be. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of two questions seeking additional insights and performance evaluations. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment consists of two questions that seek additional insights and performance evaluations. The first question asks for additional insights into modest performance gains on the Clothing1M dataset, which could help the authors provide a more comprehensive understanding of their results. The second question inquires about the algorithm\\'s performance on other real-world datasets like WebVision, evaluated by DivideMix, which could expand the scope of the paper\\'s evaluation. While the questions provide some guidance on what additional information could be included, they do not offer specific suggestions or detailed feedback on how to improve the draft. The comments are somewhat helpful as they identify areas for further exploration but lack depth and actionable advice, leaving the authors with a general direction to follow rather than a comprehensive plan for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper does not describe the hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This provides clear and concrete guidance on what the authors need to do to improve their draft, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of description of hyperparameters used by each defense and how they are derived. It also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. However, the comment does not specify which part of the paper this information should be included in, making it weakly grounded. The authors can infer that it relates to the methods or results sections, but this is not explicit. The comment is specific in detailing what needs to be addressed regarding the hyperparameters and evaluation methodology. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not describe the hyperparameters used by each defense nor how they are derived. It suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This claim is somewhat verifiable as it points out a specific gap in the paper\\'s methodology, but it lacks detailed examples or references to support the suggestion of a maximally charitable evaluation. The authors would need to infer how to address this issue, making the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper's methodology by pointing out that it does not describe the hyperparameters used by each defense nor how they are derived. This is a critical issue as it affects the reproducibility and robustness of the evaluation. The comment also suggests a maximally charitable evaluation by optimizing hyperparameters against the attack and demonstrating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. By addressing this issue, the authors can enhance the credibility and utility of their work. Therefore, the comment is highly helpful, as it offers detailed guidance on how to strengthen the paper's methodology and results.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment does not explicitly instruct the authors to include these takeaways or provide detailed guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include more practical implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and suggests that the paper lacks practical implications, which is understandable given the novelty of the work. It also mentions a specific observation regarding querying a cluster proportionally to the square root of its size as a main take-away point. However, the comment does not specify which part of the paper discusses the theoretical results or where this observation is made, making it weakly grounded. The comment is specific in identifying the lack of practical implications and the main take-away point, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that more take-away points for practitioners would be beneficial, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment lacks specific examples or references to support the claim that this observation is novel or unique to the paper. While the comment provides a logical reasoning for the suggestion, it is somewhat verifiable due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment lacks depth and does not provide specific guidance on how to present these takeaways or what additional points might be relevant. While it identifies a potential area for improvement, the feedback is somewhat helpful as it provides a starting point for the authors to consider but does not fully address their needs for improving the draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment does not explicitly instruct the authors to include these takeaways or provide detailed guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include more practical implications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the theoretical results and suggests that the paper lacks practical implications, which is understandable given the novelty of the work. It mentions a specific observation regarding querying a cluster proportionally to the square root of its size as a main take-away point. However, the comment does not specify which part of the paper discusses the theoretical results or where this observation is made, making it weakly grounded. The comment is specific in identifying the lack of practical implications and the main take-away point, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to the square root of its size is a main take-away point. However, the comment lacks specific examples or references to support the claim that this observation is novel or unique to the paper. While the comment provides a logical reasoning for the suggestion, it is somewhat verifiable due to the lack of detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the novelty of the work and the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more take-away points for practitioners, specifically mentioning the observation that querying a cluster proportionally to"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information they provide beyond T/I/O. While the comment implies that the authors should provide more context or explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide additional information. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the purpose of introducing separators and asks for clarification on the additional information they provide beyond T/I/O. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the introduction of separators in section 4 and asks for clarification on their purpose and additional information beyond T/I/O. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or what specific issues might arise. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, questioning the purpose and additional information provided by the introduction of \"separators\" in section 4. This feedback is clear and actionable, as it prompts the authors to clarify the role and significance of these elements in their work. By addressing this question, the authors can enhance the clarity and coherence of their paper, making the comment highly helpful. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or what additional information should be included. Overall, the feedback is mostly helpful, as it guides the authors toward a clearer presentation of their work.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it implies that the authors should explore alternative pooling methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate different pooling strategies. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the choice of mean pooling and suggests considering other pooling strategies. This provides clear guidance on what the authors need to address in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the choice of mean pooling and suggests considering other pooling strategies. It does not contain any subjective opinions, claims, or suggestions that require verification. Instead, it is a request for clarification or further explanation, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the choice of mean pooling and suggests considering other pooling strategies. While it identifies a potential area for improvement, it does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how they might be implemented. The comment lacks depth and actionable advice, leaving the authors with a general idea of what to consider but without concrete steps to take. Therefore, it is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly asks for clarification on whether the VQGAN is pre-trained or only trained on the 88,635 images from the Computer Vision Figures dataset. This request provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is explicit and concrete, as it specifies exactly what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"training details\" and specifically asks about the pre-training of the VQGAN and its training on the 88,635 images from the Computer Vision Figures dataset. This provides clear guidance on what part of the paper needs clarification. The comment is specific because it identifies the exact details that are missing, allowing the authors to address the issue directly. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on specific training details, specifically whether the VQGAN is pre-trained or trained on a particular dataset. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the training details of the VQGAN, asking whether it is pre-trained or only trained on a specific dataset. This feedback is clear and actionable, as it prompts the authors to provide additional information that could enhance the transparency and reproducibility of their work. By addressing this question, the authors can improve the clarity and completeness of their methodology section. However, the comment could be more helpful if it suggested how this information could be integrated into the paper or emphasized its importance. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. While the comment implies that these actions should be taken, it does not provide specific guidance on how to integrate these references or what aspects of the comparison should be emphasized. The authors can infer the need for these additions, but the lack of detailed instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. However, the comment does not specify which part of the paper these suggestions should be addressed in, making it weakly grounded. The comment is specific in its recommendations for including and comparing relevant works and discussing differences, but without explicit grounding, the authors may struggle to identify the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. While the comment provides a logical basis for the suggestions, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors are left to infer the relevance of these works and the potential benefits of including them, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides valuable feedback by suggesting that the work should include and compare to other relevant works, such as Li, 2017, and He, 2015, which are important in the context of task-oriented recommendation. It also recommends discussing how the current work differs from other chatbox research. This feedback is actionable and provides specific references for the authors to consider, which can significantly enhance the paper\\'s comprehensiveness and relevance. However, the comment could be more helpful if it offered additional guidance on how to integrate these references or what aspects of the comparison should be emphasized. Overall, the comment is mostly helpful as it directs the authors towards important areas for improvement and comparison, but it could be more comprehensive with further details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the generality of their methods. Without specific suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, as evidenced by the minor improvements in performance on the MSVD dataset (Table 3). This feedback is somewhat helpful as it highlights a potential limitation of the methods, which could guide the authors in revising or expanding their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the generality of their methods. Therefore, the comment is rated as somewhat helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the experimental strengths of the approach and suggests an alternative method that could be used to demonstrate the effectiveness of the proposed algorithm. It implies that the authors should consider running a descent procedure for 40 different networks from the training phase, but it does not explicitly instruct them to do so. The comment provides a logical reasoning for the alternative approach, suggesting that running vanilla Adam on the final network with 40 random initial points could be sufficient to reach the global minimum. However, it lacks specific guidance on how to implement this alternative method or why it would be more effective. The action is implicit and somewhat vague, as the authors can infer the need for an alternative approach but may not know how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental strengths of the approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could be sufficient to reach the global minimum. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its critique of the experimental approach, suggesting a more efficient method, but lacks grounding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental strengths of the approach, questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could be sufficient to reach the global minimum. While the comment provides a logical reasoning for the alternative approach, it lacks specific examples or references to support the claim that this alternative method would be more effective. The suggestion is based on a common-sense argument, but without detailed evidence or references, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the experimental strengths of the approach, specifically questioning the necessity of running a descent procedure for 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, which could be sufficient to reach the global minimum. This feedback provides a logical reasoning for the alternative approach, offering a potential simplification of the experimental setup. However, the comment lacks specific guidance on how to implement this alternative method or why it would be more effective. While it identifies a potential weakness, it could be more helpful with additional details or suggestions for improvement. Therefore, the comment is somewhat helpful, as it provides some insight but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the performance of FedSP in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, it does not provide explicit guidance on how the authors should address this issue or improve the performance of FedSP. The comment lacks concrete suggestions or actions for the authors to take, making it difficult for them to know how to respond. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance of FedSP in Tables 1 and 2, suggesting that it is not the best on some datasets. However, it does not specify which datasets are being referred to or provide details on what aspects of the performance are lacking. This makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. While the comment mentions specific tables, it lacks specificity in terms of what needs to be addressed, making it weakly grounded and not specific. Therefore, this comment aligns with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets, suggesting that the theme of the paper is mainly about FedSP. However, the comment does not provide any supporting evidence, such as specific examples or detailed analysis, to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the performance of FedSP in Tables 1 and 2 on some datasets, suggesting that the theme of the paper might be mainly about FedSP. However, the comment lacks specificity and does not provide any guidance on how the authors might address this issue or improve the performance of FedSP. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is rated as barely helpful, as it highlights a potential area for improvement but does not offer actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any explicit guidance or suggestions on how to explore the dataset further or what aspects should be emphasized. The action is implicit and vague, as the authors are left to infer that they should expand their discussion or analysis of the dataset but without specific direction on how to do so. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper where the dataset is mentioned. Without explicit references or detailed guidance, the authors may find it challenging to determine exactly where to focus their efforts. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could enhance the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific guidance or examples on how the authors might expand their discussion or analysis of the dataset. Without actionable advice or detailed suggestions, the comment lacks depth and does not offer the authors a clear path to improve their draft. As a result, the feedback is not helpful, as it does not provide the authors with meaningful insights or steps to enhance their work. Therefore, it aligns with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any explicit guidance or suggestions on how to explore the dataset further or what aspects should be emphasized. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to address the feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper where the dataset is mentioned. Without explicit references or detailed guidance, the authors may find it challenging to determine exactly where to focus their efforts. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific reasoning, examples, or references to support why this exploration is necessary or how it could enhance the paper. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any specific guidance or suggestions on how to expand the discussion or analysis of the dataset. Without actionable advice or detailed feedback, the authors are left without a clear understanding of how to improve their draft. The comment lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'}{'actionability_rationale': 'The review comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not provide any explicit guidance or suggestions on how to explore the dataset further or what aspects should be emphasized. The action is implicit and lacks concrete details, making it difficult for the authors to know exactly how to address the feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors could have explored the new proposed dataset, DRRI, more in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or section of the paper where the dataset is mentioned. Without explicit references or detailed guidance, the"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that realizing efficiency gains on GPU is a common challenge in pruning work, but it does not provide any specific guidance or suggestions for the authors to address this issue. It lacks explicit or implicit actions for the authors to take, such as recommending alternative approaches or providing examples of successful implementations. Without actionable advice or direction, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. However, it does not specify which part of the paper this observation pertains to, nor does it provide any specific suggestions or guidance on how the authors might address this issue. Without explicit references to sections or specific areas of the paper, the authors cannot confidently determine where to focus their efforts. Additionally, the comment lacks specificity in terms of what the authors should do to overcome this challenge. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges a common challenge in pruning work, specifically the difficulty of realizing efficiency gains on GPU. While it identifies a relevant issue, it lacks actionable feedback or suggestions for the authors to address this challenge. Without specific guidance or examples of how the authors might overcome this limitation, the comment provides minimal value to the authors in terms of improving their draft. Therefore, it is rated as barely helpful, as it highlights a concern but does not offer actionable insights or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the impact of the method on insurance costs for men and women. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of the method might affect insurance costs. The comment lacks both explicit and implicit actions, leaving the authors without any direction on how to improve their draft. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the impact of the method on insurance costs for men and women. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or details about the method or its application. Without clear grounding and specificity, the authors cannot effectively address the question. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking about the impact of the method on insurance costs for men and women. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the impact of the method on insurance costs for men and women. While it identifies a potential area of interest or concern, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of the method might affect insurance costs. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but does not offer substantial guidance for enhancing the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific reference, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which gives the authors a clear direction on how to address the issue. This level of specificity and directness makes the action explicit and concrete, allowing the authors to know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the difference between meta solvers and centralized RL, specifically mentioning that the meta solvers seem to be centralized controllers. It suggests that the authors clarify this distinction and provides a reference, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which helps ground the comment. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the meta solvers seem to be centralized controllers and suggests that the authors clarify the difference between the meta solvers and centralized RL, where agents share weights. The comment provides a reference, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016,\" which could help the authors understand the distinction. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to consult the reference to fully understand the context and implications of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confusion in the paper regarding the distinction between meta solvers and centralized RL, where agents share weights. It suggests that the authors clarify this distinction by referencing a specific work, \"Foester et al., Learning to communicate with deep multi-agent reinforcement learning, NIPS 2016.\" This feedback is clear and actionable, as it provides a specific direction for the authors to improve their draft by addressing a potential misunderstanding in the literature. However, the comment could be more helpful if it included additional context or suggestions on how to present this clarification effectively. Overall, the comment is mostly helpful as it guides the authors towards a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the paper\\'s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what changes they should make to their categorization. As a result, the comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the paper\\'s categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the discrepancy between arXiv and ACL Anthology publication dates, particularly mentioning the BERT paper as an example. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper categorizes papers based on their publication years, specifically mentioning the ACL Anthology, but notes that many papers are available on arXiv much earlier. The comment provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This provides some context and evidence for the claim, making it somewhat verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper's categorization of papers based on their publication years, noting that many papers are available on arXiv much earlier than the ACL Anthology. It provides a specific example, mentioning the BERT paper, which is available on arXiv from October. This feedback is somewhat helpful as it highlights a potential inconsistency in the paper's categorization, but it lacks depth and does not offer suggestions on how the authors might address this issue or improve their categorization. The comment could be more helpful if it provided additional context or guidance on how to resolve the discrepancy. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. The first part questions why the authors did not use Importance sampling instead of the proposed relaxation of rejection sampling. This part is somewhat actionable as it prompts the authors to clarify their choice. The second part of the comment asks for clarification on the difference between QRS and RS in Algorithm 1, suggesting that the authors should provide a specific value of u to demonstrate the difference. This part is explicit and concrete, providing a clear action for the authors to take. However, the first part lacks specificity and does not provide a direct action, making the overall comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the use of an arbitrary parameter beta instead of the true upper bound of the ratio p/q, and the difference between QRS and RS in Algorithm 1. The first part of the comment is fully grounded as it explicitly mentions the use of beta and the true upper bound, allowing the authors to accurately identify the part of the paper being addressed. The second part is also fully grounded, as it refers to Algorithm 1 and specifically mentions QRS and RS. The comment is specific in detailing what needs to be addressed in each part, providing clear guidance for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of two parts. The first part questions why the authors did not use Importance sampling instead of the proposed relaxation of rejection sampling, which is using an arbitrary parameter beta. This part is somewhat verifiable as it raises a logical question about the authors\\' choice, but it lacks specific reasoning or examples to support the claim. The second part of the comment questions the difference between QRS and RS in Algorithm 1 and asks for clarification. This part is also somewhat verifiable, as it seeks clarification on a specific aspect of the algorithm, but it does not provide detailed reasoning or examples to support the need for clarification. Overall, the comment is somewhat verifiable due to the lack of detailed justification or examples in both parts.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two points. First, it questions why the authors did not use Importance sampling instead of the proposed relaxation of rejection sampling, which uses an arbitrary parameter beta instead of the true upper bound of the ratio p/q. This part of the comment is somewhat helpful as it prompts the authors to clarify their choice and potentially improve their methodology. However, it lacks depth and does not provide specific suggestions for how to address this issue. The second part of the comment asks for clarification on the difference between QRS and RS in Algorithm 1, which is a specific request for additional information. While this part is clear and actionable, it does not address the initial question about the use of Importance sampling. Overall, the comment is somewhat helpful as it identifies areas for clarification but lacks comprehensive guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the experimental results. The action is implicit and vague, as the authors are left to infer that they need to provide more convincing evidence or address potential issues. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment does not specify which part of the paper these experiments are located in, making it difficult for the authors to identify the exact sections being referred to. While the authors can infer that it relates to the experimental results, the lack of explicit grounding makes it weakly grounded. The comment is specific in detailing the concern about the experimental results and the potential issues with the proposed method. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are not convincing or that the similarity to IRM is problematic. Without additional context or evidence, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the experimental results on the last two datasets, suggesting that they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the similarity to IRM is due to problems mentioned above, implying that the results may not be robust. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve the experimental results. While it identifies a potential issue, it does not provide actionable feedback or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not fully support the authors in addressing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference between detecting just the long one. While it implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clarification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of detecting both entities in the example and asks about the difference to \"just\" knowing the long one. This provides clear guidance on what needs to be addressed in the figure, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the necessity of detecting both entities in Figure 2 and asks about the difference to \"just\" knowing the long one. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of detecting both entities in Figure 2 and asks about the difference to \"just\" knowing the long one. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable feedback, leaving the authors with a general question that does not offer a clear path for improvement. Therefore, it is rated as barely helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" in line 285, specifically asking if \"chunk\" is still considered sequential information. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the meaning of \"non-sequential information\" and \"chunks\" in their draft. However, the comment lacks concrete details on how to resolve the confusion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the phrase \"non-sequential information such as chunks,\" questioning whether \"chunk\" is still considered sequential information. This provides clear guidance on what needs to be clarified or addressed in the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific phrase in the text, \"non-sequential information such as chunks.\" It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the phrase \"non-sequential information such as chunks\" in line 285, asking whether \"chunk\" is still considered sequential information. This feedback is clear and actionable, as it prompts the authors to clarify the meaning of this phrase, which could potentially improve the clarity and understanding of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to address the confusion. Overall, the comment is mostly helpful as it identifies a specific area for clarification, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. It points out that the upper bound in this case would be 0, which is not true. However, the comment does not provide any explicit or implicit actions for the authors to take. It simply highlights a potential issue without suggesting how the authors should address it. As a result, the authors are left without guidance on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the assumption of a separate node with 0 neighbors and explaining why the upper bound would be 0, which is not true. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about Theorem 1, specifically regarding the assumption of a separate node with 0 neighbors. It points out that the upper bound in this case would be 0, which is not true. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim or suggest how the authors might address the issue. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about Theorem 1, pointing out a potential issue with the assumption of a separate node with 0 neighbors. It highlights that the upper bound in this case would be 0, which is not true, and asks for an explanation. This feedback is somewhat helpful as it identifies a potential weakness in the theoretical foundation of the paper, prompting the authors to clarify or address this issue. However, the comment could be more helpful if it provided suggestions on how to resolve the issue or offered additional context. Overall, the comment provides some guidance but lacks depth, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a gap in the analysis regarding the handling of rumors generated by GPT and suggests that further analysis or solutions should be proposed. It questions why GPT-generated Rumor is closer to Natural Rumor in terms of detectability, despite being written by humans. However, the comment does not provide specific guidance or suggestions on how to address this issue or what kind of analysis should be conducted. The authors are left with a general understanding of what needs to be improved but without concrete steps to take. Therefore, the comment is somewhat actionable, as it identifies a gap but lacks detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the handling of rumors generated by GPT,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions why GPT-generated Rumor is closer to Natural Rumor in terms of detectability, despite being written by humans. The comment provides a clear direction for further analysis or solutions, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the difficulty of detecting rumors generated by GPT compared to natural rumors. It suggests that since artificial rumors are written by humans, they should be about the same difficulty as natural rumors, but the experimental results show otherwise. The comment questions the logic behind this discrepancy and implies that further analysis or solutions should be proposed. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to conduct additional analysis or provide more detailed reasoning to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the analysis regarding the handling of rumors generated by GPT, specifically questioning why GPT-generated Rumor is closer to Natural Rumor in terms of detectability. It points out that artificial rumors are written by humans and should be about the same difficulty as natural rumors, but the experimental results suggest otherwise. This feedback is somewhat helpful as it highlights an area for further exploration and analysis. However, it could be more helpful if it provided specific suggestions or guidance on how to address this issue or what kind of analysis should be conducted to better understand the results. Overall, the comment offers a clear direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the technical contribution is limited, specifically mentioning that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. While it identifies a potential issue with the technical contribution, it does not provide explicit guidance or suggestions on how the authors might address this limitation. The comment lacks concrete details or actionable steps for the authors to take, such as recommending specific changes or improvements to the content. As a result, the authors are left without a clear understanding of what actions to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a limitation in the technical contribution, specifically noting that the contents of Section 4 are not about a formal and principled solution but mostly about heuristics. This feedback is somewhat helpful as it points out a potential area for improvement in the paper's technical depth. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the technical contribution. Without actionable advice or detailed feedback, the authors may find it challenging to fully understand and implement the suggested improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. It implies that using various probability mass functions would add depth to the experimental setting. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore different probability mass functions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of the probability mass function in MixBoost, specifically mentioning that it is set to a quasi-uniform distribution with only one parameter. It suggests that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses regret that the probability mass function is not exploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. The reviewer implies that using various probability mass functions would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that the quasi-uniform distribution is not well-suited or that using different probability mass functions would be beneficial. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper by suggesting that the probability mass function, which is currently set to a quasi-uniform distribution, could be more effectively utilized. The reviewer points out that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the experimental design. However, the comment could be more helpful if it included examples or references to support the claim that different probability mass functions would be beneficial. Overall, the comment is mostly helpful as it directs the authors to a potential improvement area, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}{'actionability_rationale': \"The review comment suggests that the probability mass function, currently set to a quasi-uniform distribution with only one parameter, could be more effectively utilized by considering each learner class individually, even in the case of BDT of different depths. The reviewer implies that using various probability mass functions would add depth to the experimental setting. However, the comment does not explicitly instruct the authors to make these changes or provide specific guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore different probability mass functions. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of the probability mass function in MixBoost, specifically mentioning that it is set to a quasi-uniform distribution with only one parameter. It suggests that each learner class should be considered individually, even in the case of BDT of different depths, implying that using various probability mass functions would add depth to the experimental setting. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it provides a clear direction for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses regret that the probability mass function is practically unexploited and suggests that it should be considered individually for each learner class, even in the case of BDT of different depths. The reviewer implies that using various probability mass functions would add depth to the experimental setting. However, the comment lacks specific examples or references to support the claim that the quasi-uniform distribution is not well-suited or that using different probability mass functions would be beneficial. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this concern or what steps they should consider to ensure a fair comparison. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the results or discussion sections, but this inference is not explicit. The comment is specific in questioning the fairness of the comparison, but without grounding, it is challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison might be unfair. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fairness of comparing the accuracies of different models, specifically ChatGPT, which shows a high percentage of abstention. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern or improve the comparison. The comment lacks actionable advice or specific recommendations, leaving the authors without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it highlights a potential weakness but does not offer constructive feedback for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to discuss connections with a specific reference, [a], which is relevant to their topic. It provides a clear action by suggesting that the authors should address the connections with [a], which uses supervised learning in QBF solving. This guidance is concrete and provides a direct path for the authors to improve their draft by incorporating this reference and its connections. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific references, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed by suggesting a discussion of connections with a particular reference, [a], which uses supervised learning in QBF solving. This provides clear guidance on what the authors should include in their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references provided are relevant to the topic and suggests discussing connections with a specific reference, [a], which uses supervised learning in QBF solving. However, the comment does not provide detailed reasoning or evidence to support why these connections are important or how they relate to the authors\\' work. The lack of specific examples or detailed justification makes it difficult for the authors to understand the significance of the suggestion. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a missing reference that is relevant to the topic, specifically [a], which uses supervised learning in QBF solving. It suggests that the authors discuss the connections between their work and [a], which generalizes SMT. This feedback is clear and actionable, as it provides a specific reference for the authors to consider and suggests a potential area for further discussion or comparison. By addressing this suggestion, the authors can enhance the relevance and depth of their work. However, the comment could be more helpful if it provided additional context or guidance on how to integrate the suggested reference into the paper. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful improvement in their draft.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment implies that the authors should consider exploring alternative relationships and provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore and explain alternative relationships. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to explain this point is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. However, the comment does not provide specific examples or references to support the claim that other relationships might be more appropriate. The suggestion to explain this point is logical, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to explore alternative relationships or explain the current approach. The feedback is somewhat helpful as it points out a potential limitation but does not provide detailed advice on how to address it, leaving the authors with a general direction to consider.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment implies that the authors should consider exploring alternative relationships and provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore and explain alternative relationships. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion to explain this point is specific, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. However, the comment does not provide specific examples or references to support the claim that other relationships might be more appropriate. The suggestion to explain this point is logical, but without detailed reasoning or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the mono tonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss during training. It suggests that this relationship could be replaced by other relationships and recommends explaining this point. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to explore alternative relationships or explain the current approach. The feedback is somewhat helpful as it points out a potential limitation but does not provide detailed advice on how to address it, leaving the authors with a general direction to consider.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the mono tonic relationship between the degree of"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison in terms of computation cost or running time. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether the authors should include this comparison, how to conduct it, or what specific aspects to consider. Without any actionable advice or direction, the authors are left without a clear understanding of what is expected of them. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison in terms of computation cost or running time, but it does not specify which part of the paper this question pertains to. The authors may infer that it relates to the experimental results or methodology sections, but this inference is not explicit. The comment is specific in asking about the comparison of computation cost or running time, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point is a question asking for clarification about the comparison in terms of computation cost or running time. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison in terms of computation cost or running time, which is a relevant aspect for the authors to consider. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or what specific aspects of the comparison they should focus on. Without actionable advice or detailed feedback, the comment lacks depth and does not effectively assist the authors in improving their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the privacy-preserving nature of the approach compared to other federated learning approaches. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their approach. The action is implicit and vague, as the authors are left to infer that they need to provide more detailed explanations or evidence regarding privacy preservation. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the privacy-preserving nature of the approach compared to other federated learning approaches and questions whether privacy preservation is a concern in traffic signal control. However, it does not specify which part of the paper this discussion pertains to, making it weakly grounded. The comment is specific in its questions about privacy preservation and the applicability of federated learning in traffic signal control, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the privacy-preserving nature of the approach compared to other federated learning approaches and questions whether privacy preservation is a concern in traffic signal control. However, it does not provide any specific evidence, examples, or references to support these claims. The comment lacks detailed reasoning or references to substantiate the assertion that privacy preservation is a concern in traffic signal control, making it difficult for the authors to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the privacy-preserving nature of the approach compared to other federated learning approaches. It also questions whether privacy preservation is a concern in traffic signal control, suggesting that one traffic signal knowing the color of the next one could be a bad example. This feedback is somewhat helpful as it prompts the authors to consider and address potential privacy concerns in their application. However, the comment lacks specific guidance or suggestions on how to improve the privacy aspect of the approach or provide a more detailed explanation of why it is privacy-preserving. Therefore, the comment is rated as somewhat helpful, as it provides some insight but does not fully support the authors in enhancing their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly instructs the authors to start the section with the final paragraph, which is said to make the description of the neural network clearer. This provides a clear and direct action for the authors to take, making the comment highly actionable. The suggestion is concrete, as it specifies exactly what part of the section should be moved to the beginning. Therefore, this comment is rated as highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions '528,' allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting that the description of the neural network is hard to understand and suggests starting the section with the final paragraph for clarity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the description of the neural network is hard to understand, but it does not provide any specific examples or reasoning to support this claim. The comment suggests starting the section with the final paragraph to make it clearer, but without further explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence or justification to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the description of the neural network, noting that it is hard to understand. It provides a clear suggestion to start the section with the final paragraph, which is said to clarify the description. This feedback is actionable and provides a concrete step for the authors to improve the clarity of their draft. However, the comment could be more helpful if it offered additional guidance on how to make the description clearer or suggested specific changes to the text. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the possibility of training the model with attention-based enc-dec training instead of CTC loss. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. However, it does not specify which part of the paper discusses the model\\'s training or limitations, making it weakly grounded. The comment is specific in its suggestion to explore alternative training methods, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. However, it does not provide any supporting evidence, reasoning, or references to justify why this alternative might be beneficial or necessary. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance on why this alternative might be beneficial or how it could be implemented. The authors are left with a general suggestion but without actionable feedback or detailed reasoning, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. While it implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. However, it does not specify which part of the paper discusses the model\\'s training or limitations, making it weakly grounded. The comment is specific in its suggestion to explore alternative training methods, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. However, it does not provide any supporting evidence, reasoning, or references to justify why this alternative might be beneficial or necessary. The comment lacks specific examples or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. While it identifies a potential area for improvement, the comment lacks specificity and does not provide any guidance on why this alternative might be beneficial or how it could be implemented. The authors are left with a general suggestion but without actionable feedback or detailed reasoning, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training. While it implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this alternative. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model\\'s limitation to CTC loss and suggests the possibility of training it with attention-based enc-dec training"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the division of tables into three types in Section 3, specifically questioning the necessity of having a column header as a separate type. While the comment identifies a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The action is implicit, as the authors need to infer that they should clarify or simplify the division of tables. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3\" and \"line 247-252,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of having a column header as a separate type in the tables, providing a clear direction for the authors to consider revising their approach. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the division of tables into three types, specifically questioning the necessity of having a column header as a separate type. However, it does not provide any supporting evidence, reasoning, or examples to justify this concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in Section 3 regarding the division of tables into three types, questioning the necessity of having a column header as a separate type. While it raises a valid point, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might address this concern. It does not offer alternative approaches or improvements that could enhance the clarity or organization of the tables. As a result, the feedback is somewhat helpful, as it highlights a potential area for improvement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. However, the comment does not explicitly instruct the authors to include these methods or how to integrate them into their work. While the suggestion is clear in terms of what could be improved, it lacks concrete guidance on how to implement these changes. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the attack methods used in the paper, specifically mentioning that they are naive and suggesting the consideration of other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. However, the comment does not explicitly mention which part of the paper discusses the attack methods, making it weakly grounded. The authors can infer that it relates to the methodology section, but this inference is not direct. The comment is specific in suggesting alternative attack methods and providing references, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the attack methods used in the paper are naive and suggests considering other classical attack methods in NLP. It provides specific examples of papers to refer to for inspiration. However, the comment lacks detailed reasoning or evidence to support why the current attack methods are naive or why other methods should be considered. The suggestion to check specific papers provides a direction for improvement but does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it offers a suggestion but lacks comprehensive justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by noting that the attack methods used are naive. It suggests that the authors should consider other classical attack methods in NLP, providing specific examples of papers to refer to for inspiration. This feedback is clear and actionable, as it directs the authors to expand their methodology and potentially enhance the robustness of their findings. However, the comment could be more helpful if it offered additional guidance on how to integrate these methods or what specific aspects of the current methods are considered naive. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or mitigate the risk of unfairness. The action is implicit and vague, as the authors are left to infer that they need to consider these issues and potentially adjust their methodology or analysis. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the fairness of comparisons, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the potential issues with fairness and leakage, but without clear grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or references to support the claim about the potential leakage of information. While the reasoning is logical, the absence of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. This feedback is important as it points out a critical aspect that the authors should consider when evaluating their results. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or mitigate the risk of unfairness. While it identifies a potential problem, it does not provide actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or mitigate the risk of unfairness. The action is implicit and lacks concrete details, making it barely actionable. The authors are left to infer that they need to consider these issues but are not given clear steps to take. Therefore, this comment aligns with a score of 2.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the fairness of comparisons, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this is not explicit. The comment is specific in detailing the potential issues with fairness and leakage, but without clear grounding, it is challenging for the authors to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights the potential risk of leakage of additional information from the pretrained visual model and target dataset, which could skew results and lead to unfairness. However, the comment lacks specific examples or references to support the claim about the potential leakage of information. While the reasoning is logical, the absence of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a"}
{"generated_text": "{'actionability_rationale': 'The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what aspects of the paper could be revised in response. Without any actionable suggestions or directions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular observation about the dominance of function words over content words in a Japanese sentence, which is a clear issue for the authors to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any supporting evidence, reasoning, or context to explain why this observation is surprising or how it relates to the paper. Without any justification or references, the claim lacks verifiability, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, as depicted in Figure 1. However, it does not provide any context, explanation, or suggestions for why this observation is surprising or how it relates to the paper\\'s main points. Without additional information or guidance, the authors are left without a clear understanding of what aspects of the paper need improvement or clarification. Therefore, the comment is not helpful, as it lacks actionable feedback or insights that could aid the authors in enhancing their draft. This aligns with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using the minimal k-means objective over multiple seeds is more reasonable than the average of k-means objectives with multiple seeds. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. While the suggestion is explicit, it does not provide detailed guidance on how the authors should implement this change or what specific aspects of the current approach should be revised. The authors are left with a clear direction but without concrete steps on how to execute it, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests a minor change in the methodology, specifically recommending the use of the minimal k-means objective over multiple seeds as a more reasonable baseline instead of the average of k-means objectives. It provides references to support this claim, which is a valuable addition. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The suggestion is specific, as it clearly outlines what the authors should consider changing. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a minor change in methodology, recommending the use of the minimal k-means objective over multiple seeds as a more reasonable baseline instead of the average of k-means objectives. It provides references to support this claim, specifically mentioning Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. This provides a clear rationale for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a minor suggestion for improving the methodology by recommending the use of the minimal k-means objective over multiple seeds as a more reasonable baseline instead of the average of k-means objectives. It supports this suggestion with references to relevant literature, specifically Jin, Chi, et al. and Fr\u00e4nti, Pasi, and Sami Sieranoja. This feedback is actionable and provides a clear direction for the authors to consider in revising their methodology. However, the comment could be more helpful if it included specific guidance on how to implement this change or what aspects of the current approach might be improved. Overall, the comment is mostly helpful as it offers a constructive suggestion for improvement, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. While the comment implies that the authors should include this reference and discuss the relationship, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the reference and discuss the context. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the importance of including a reference to \"Lista,\" which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista\" to provide context. However, the comment does not specify which part of the paper should include this reference or discuss the context, making it weakly grounded. The authors can infer that it pertains to the introduction or related work section, but this is not explicitly mentioned. The comment is specific in its suggestion to include a reference and discuss the context, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is closely related to the idea of unrolling, as proposed in \"Lista,\" and suggests that the paper should discuss the similarities and differences between the proposed work and \"Lista.\" However, the comment does not provide specific examples or detailed reasoning to support why this reference is important or how it relates to the paper. The claim is somewhat verifiable as it highlights a potential gap in the paper\\'s context, but it lacks the depth and specificity needed for a fully verifiable comment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical reference, 'Lista,' which is closely related to the idea of unrolling. It suggests that the paper should discuss the similarities and differences between the proposed work and 'Lista' to provide context and situate the paper within the relevant literature. This feedback is valuable as it highlights a potential oversight in the paper's literature review and encourages the authors to clarify their position in the field. However, the comment could be more helpful if it provided specific suggestions on how to discuss these similarities and differences or examples of how to integrate the reference into the paper. Overall, the comment is mostly helpful as it directs the authors to an important aspect of their work that needs attention, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the clarity of the definition of the sparsity of the residual term and suggests that it includes many zero elements. It also requests evidence to support the sparsity assumption across various noisy cases. Additionally, the comment implies that it is necessary to demonstrate the advantages of the proposed method compared to existing methods. While the comment does not explicitly instruct the authors to provide specific evidence or comparisons, the actions are clear and can be inferred from the comment. The authors know what needs to be addressed and how to improve their draft by providing the requested evidence and comparisons. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the clarity of the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption across various noisy cases. It also suggests that it is necessary to show the advantages of the proposed method compared to existing methods. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where the sparsity assumption is discussed. The comment is specific in detailing what needs to be addressed, such as providing evidence for the sparsity assumption and demonstrating the advantages of the proposed method. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the definition of the sparsity of the residual term and requests evidence to support the sparsity assumption across various noisy cases. It also suggests that it is necessary to show the advantages of the proposed method compared to existing methods. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim that the definition is unclear. The request for evidence and comparison is a logical suggestion but does not provide explicit justification or examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully substantiated.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific concern about the clarity of the definition of the sparsity of the residual term in the paper. It questions whether the residual term includes many zero elements and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, the comment implies that it is necessary to demonstrate the advantages of the proposed method compared to existing methods. While the comment identifies a potential area of improvement, it lacks detailed guidance or specific suggestions on how to address these issues. The authors are left with a general understanding of what needs to be clarified but without actionable steps to take. Therefore, the comment is somewhat helpful, as it points out a specific area for improvement but does not fully guide the authors in making the necessary changes.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the term \"connectivity\" as misleading because it does not reflect the structural connections between the brain and body. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or what alternative terminology might be more appropriate. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the term \"connectivity\" as misleading, suggesting that it does not accurately reflect the structural connections between the brain and body. However, it does not specify which part of the paper this critique pertains to, such as a specific section, figure, or table. Without explicit references or detailed explanation, the authors may find it challenging to identify the exact area needing revision. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the term \"connectivity\" is misleading because it does not reflect the structural connections between the brain and body. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it difficult to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment critiques the term \"connectivity\" as misleading because it does not accurately reflect the structural connections between the brain and body. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the terminology. Without actionable feedback or specific recommendations, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. It suggests referring to \"Clarity, Quality, Novelty And Reproducibility\" for more information, but it does not provide specific guidance or examples of what needs to be addressed or improved. The action is implicit, as the authors can infer that they need to add more details, but it lacks concrete steps or examples on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights that the paper is not polished and lacks details in related work, experiments, and writing. However, it does not specify which sections or parts of the paper are missing details, making it difficult for the authors to identify the exact areas needing attention. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests a reference or guideline for improvement, but it does not provide specific guidance on what aspects need to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks details in related work, experiments, and writing, but it does not provide specific examples or evidence to support these claims. The mention of \"Clarity, Quality, Novelty And Reproducibility\" suggests a reference or guideline for improvement, but it does not offer detailed feedback or guidance on how to address these issues. Without specific examples or references, the claim remains vague and difficult for the authors to understand and act upon. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment highlights that the paper is not polished and lacks details in related work, experiments, and writing, suggesting that it is not ready for publication. While it identifies areas for improvement, the comment lacks specificity and does not provide actionable feedback or guidance on how to address these issues. Without detailed suggestions or examples, the authors may struggle to understand where to focus their efforts to improve the draft. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a detailed explanation of the steps involved in the process, identifying the importance of Step 3, which involves the use of an orthogonal matrix. It suggests that this aspect should be studied to validate the necessity of using an orthogonal matrix. However, the comment does not explicitly instruct the authors to include this study or provide specific guidance on how to conduct it. The action is implicit and somewhat vague, as the authors need to infer that they should include this study but are not given concrete steps on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific steps in the process, identifying Step 2 and Step 3 as critical components. It explains that Step 2 can be done regardless of the weight matrix being orthogonal, while Step 3 is vital when using an orthogonal matrix. However, the comment does not specify which part of the paper these steps are located in, making it weakly grounded. The comment is specific in detailing the importance of Step 3 and the need for further study, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of an orthogonal matrix is crucial for Step 3, as it is the only part that requires it. The reviewer provides a logical explanation by stating that the transpose of the matrix is easy to get and that Step 2 can be done regardless of the weight matrix being orthogonal. However, the comment lacks specific examples or references to support the claim that Step 3 is the only part requiring an orthogonal matrix. This makes the claim somewhat verifiable, as it provides a logical basis but requires additional evidence to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific aspect of the paper that requires further exploration and validation. It points out that while Step 2 can be done regardless of the weight matrix being orthogonal, Step 3 is the critical part that only orthogonal matrices can perform. The reviewer suggests that this aspect should be studied to validate the necessity of using orthogonal matrices. This feedback is clear and actionable, as it directs the authors to a specific area that needs further investigation. However, the comment could be more helpful if it provided additional guidance or examples on how to conduct this study. Overall, the comment is mostly helpful as it highlights a significant area for improvement and offers a clear direction for the authors to enhance their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also inquires about the possibility of experimenting on language tasks. While the comment explicitly states these actions, it does not provide concrete guidance on how to address these suggestions or what specific improvements would be beneficial. The authors are left with a general understanding of what needs to be done but lack detailed instructions on how to implement these changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also inquires about the possibility of experimenting on language tasks. However, the comment does not specify which part of the paper discusses the models and datasets, making it weakly grounded. The authors can infer that it relates to the methodology or experimental setup sections, but this is not explicitly mentioned. The comment is specific in detailing what needs to be addressed regarding the models and datasets, as well as the potential for language task experiments. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets like CIFAR100 and models like ResNet 34 or 50, as well as ViT-tiny or small. The reviewer also inquires about the possibility of experimenting on language tasks. While the comment provides a logical basis for the suggestions, it lacks specific references or detailed reasoning to fully substantiate the claims. The authors are left to infer the significance of these suggestions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the models and datasets used in the paper, suggesting that they are too toy-like and recommending the inclusion of more challenging datasets like CIFAR100 and models like ResNet 34 or 50, as well as ViT-tiny or small. The reviewer also raises a question about the possibility of experimenting on language tasks. While the comment provides some insight into potential improvements, it lacks specific guidance or suggestions on how to address these issues or what specific changes would be beneficial. The authors are left with a general understanding of what needs to be improved but without detailed instructions on how to implement these suggestions. Therefore, the comment is somewhat helpful, as it identifies areas for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of certain natural ablation studies, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is an explicit action for the authors to take, as it clearly indicates a specific area that requires attention. The comment also raises a minor question about the central argument against pretraining, which further guides the authors on what to consider. While the comment does not provide detailed instructions on how to conduct these studies or address the argument, the actions are clear and concrete. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment highlights the absence of certain natural ablation studies, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is a specific suggestion that provides clear guidance on what needs to be addressed. However, the comment does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. The authors can infer that it pertains to the experimental section or results, but this inference is not as clear as it could be. Despite this, the comment is specific in detailing what needs to be addressed, making it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some natural ablation studies are missing, specifically mentioning the need to include a baseline where scratchGAN is pretrained. This is a logical claim that can be supported by the reviewer\\'s understanding of the field or by providing examples of similar studies that have included such ablations. However, the comment does not provide specific references or detailed reasoning to fully substantiate the claim. The lack of explicit examples or detailed justification makes the claim somewhat verifiable, as the authors would need to infer the significance of the missing ablation studies on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by pointing out the absence of certain natural ablation studies, such as the need to include a baseline where scratchGAN is pretrained. This feedback is clear and actionable, as it directs the authors to conduct additional experiments that could strengthen their argument against pretraining. The comment also raises a minor question about the central argument against pretraining, which further encourages the authors to consider and address potential counterpoints. While the comment does not provide detailed guidance on how to conduct these studies or analyze the results, it offers a clear direction for improvement. Therefore, the comment is mostly helpful, as it provides valuable insights and actionable suggestions for enhancing the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a lack of comparison against baselines in the paper, specifically mentioning the absence of baselines in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or codesearch tasks. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include baseline comparisons to enhance the comprehensiveness of their study, but the comment lacks concrete details on which specific baselines to consider or how to implement them. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"functionality similarity comparison study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of baseline comparisons and provides context by mentioning that many papers have developed architecture-agnostic similarity comparison or codesearch tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison against baselines, which is a widely understood binary analysis application. The reviewer provides context by mentioning that many papers have developed architecture-agnostic similarity comparison or codesearch tasks, which are similar to the functionality similarity comparison study. This provides some logical reasoning and common knowledge to support the claim, making it somewhat verifiable. However, the comment could be strengthened by providing specific examples of relevant papers or detailed reasoning on why baseline comparisons are essential. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of baseline comparisons in the functionality similarity comparison study. It highlights that this is a widely understood binary analysis application and that many papers have developed architecture-agnostic similarity comparison or codesearch tasks, which are similar to the study's focus. This feedback is clear and actionable, as it directs the authors to include baseline comparisons to enhance the comprehensiveness and validity of their study. However, the comment could be more helpful if it provided specific suggestions on which baselines to consider or how to incorporate them into the study. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to mention in SI 6.5 that the preprocessing is identical to that in Mnih et al. [7], but the evaluation is slightly different due to the absence of human starts. This provides a clear and direct action for the authors to take, specifying exactly what needs to be included in the supplementary information. The comment is explicit and concrete, allowing the authors to know exactly how to address the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need to mention that the preprocessing is identical to that in Mnih et al. [7] but the evaluation is slightly different due to the absence of human starts. This provides clear guidance on what the authors should include in their supplementary information. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is slightly different from Mnih et al. [7] because no human starts are used. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanation or references to justify why the evaluation is different or how the absence of human starts affects the evaluation. Without additional context or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a claim but lacks sufficient justification or evidence to fully support it.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to include in their supplementary information. It highlights a discrepancy between the preprocessing method mentioned in Mnih et al. [7] and the evaluation process in the current work, noting that the evaluation is slightly different due to the absence of human starts. This feedback is clear and actionable, as it directs the authors to clarify this point in their supplementary information, ensuring transparency and accuracy in their methodology. However, the comment could be more helpful if it provided additional context or guidance on how to address this difference in evaluation. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not report any metrics demonstrating the efficiency of the proposed method compared to previous work. It explicitly states that the authors should report metrics to show the efficiency of their method. This feedback is clear and direct, providing a specific action for the authors to take. The comment does not leave any ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of reporting metrics that demonstrate the efficiency of the proposed method compared to previous work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for efficiency metrics, but without grounding, the authors may struggle to pinpoint where to make the necessary changes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not report any metrics demonstrating the efficiency of the proposed method compared to previous work. However, it does not provide any specific examples or references to support this claim, nor does it offer a logical explanation or reasoning for why such metrics are necessary. Without additional context or evidence, the claim remains unverifiable, as it lacks the necessary details to substantiate the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that it claims advantages over previous work in terms of efficiency but does not report any metrics to support this claim. This feedback is clear and actionable, as it directs the authors to include metrics that demonstrate the efficiency of their proposed method. However, the comment could be more helpful if it provided suggestions on which specific metrics to report or how to measure efficiency. Overall, the comment is mostly helpful as it highlights a critical gap in the paper and offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses that the contribution is not enough and highlights the importance of addressing overfitting with limited data using differentiable augmentation. However, it does not provide any explicit or implicit actions for the authors to take to improve their contribution. There is no guidance on how to enhance the contribution or what specific aspects need further development. As a result, the authors are left without any actionable steps to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the contribution being insufficient and highlights the importance of addressing overfitting with limited data using differentiable augmentation. However, it does not specify which part of the paper this critique pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the contribution are insufficient or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contribution is not enough, suggesting that the paper addresses an important issue but lacks depth. However, the comment does not provide any specific evidence, reasoning, or examples to support this claim. Without detailed justification or references to comparable work, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses a concern about the contribution being insufficient, specifically mentioning the importance of addressing overfitting with limited data using differentiable augmentation. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance their contribution. Without detailed guidance or examples, the authors are left without a clear path to improve their work. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer actionable advice for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly requests the authors to provide more details about the state-space, whether it is finite or continuous, and to specify the space in which theta lies. The reviewer also suggests that the actions should be clarified. This feedback is clear and direct, giving the authors a specific action to take: providing additional details about the state-space and the actions. The request for precision is also explicit, ensuring that the authors know exactly what information is needed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, providing more details about the state-space, whether it is finite or continuous, and the space in which theta lies. The reviewer also suggests that the actions should be clarified, giving the authors a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification and does not contain any subjective opinions, judgments, or suggestions that require verification. It is a factual request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is clear and actionable, as it explicitly requests the authors to provide more details about the state-space, whether it is finite or continuous, and to specify the space in which theta lies. The reviewer also suggests that the actions should be clarified, which is a direct and precise way to guide the authors in improving their draft. By addressing these specific areas, the comment offers valuable feedback that can help the authors enhance the clarity and precision of their work. However, it could be more helpful if it provided examples or suggestions on how to present this information more effectively. Overall, the comment is mostly helpful, as it directs the authors to a specific area needing improvement and provides a clear path forward.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also mentions that this is acknowledged by the authors in Section 3, where they discuss the need for normalization to make the results from Theorem 1 applicable. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to the proof. The action is implicit and somewhat vague, as the authors need to infer that they should consider revising the proof technique or providing additional context to address the contradiction. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Appendix A\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by noting that the proof relies on a special case where a contradiction arises as matrix norms approach infinity, and that this is acknowledged in Section 3. The comment is specific in detailing what needs to be addressed, providing clear guidance on the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. This claim is somewhat verifiable as it provides a specific observation about the proof technique and references a section where the authors acknowledge the issue. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the proof technique and the context provided in Section 3 to fully understand and address the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. It also acknowledges that this is discussed in Section 3, where the authors mention the need for normalization to make the results from Theorem 1 applicable. While the comment highlights a potential weakness in the proof, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the proof technique. The feedback is somewhat helpful as it points out a specific area for concern, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses a personal belief that LiDAR-based segmentation is the best choice for the downstream task and suggests that colorization-based pre-training primarily learns semantics. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their draft based on this feedback. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment discusses the choice of using object detection as the downstream task and suggests that LiDAR-based segmentation might be a better option. It also mentions that colorization-based pre-training primarily learns semantics, while object detection requires accurate locations and poses. However, the comment does not specify which part of the paper this critique pertains to, such as a specific section or experiment. The authors might infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its critique of the choice of downstream task and the limitations of colorization-based pre-training, but it lacks grounding as it does not point to a specific part of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a personal belief that LiDAR-based segmentation is the best choice for the downstream task and suggests that colorization-based pre-training primarily learns semantics. However, it lacks specific evidence, examples, or references to support this claim. The reasoning is based on the author\\'s opinion about the effectiveness of different methods, but without detailed justification or references, the claim remains unverifiable. The authors would need to provide more detailed reasoning or evidence to fully understand and address the critique. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a personal belief that LiDAR-based segmentation is the best choice for the downstream task, suggesting that colorization-based pre-training primarily learns semantics. However, it does not provide any specific feedback or suggestions on how the authors might improve their draft or address this critique. The comment lacks actionable guidance or detailed analysis, leaving the authors without a clear path to enhance their work. As a result, the comment is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a contradiction between the objective of Equation (12) and the theory proof provided. However, it does not provide explicit guidance on how the authors should address this contradiction or what changes they should make to resolve it. The comment lacks specific suggestions or detailed instructions on how to align the objective with the theory proof. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (12)\" and \"IPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a contradiction between the objective of Equation (12) and the theory proof. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a contradiction between the objective of Equation (12) and the theory proof provided. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting a contradiction between the objective of Equation (12) and the theory proof provided. This feedback is somewhat helpful as it highlights a potential weakness in the paper that the authors should address. However, the comment lacks depth and does not provide specific guidance or suggestions on how to resolve the contradiction or improve the theory proof. To be more helpful, the comment could include additional context, examples, or suggestions for addressing the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a contradiction between the objective of Equation (12) and the theory proof provided. However, it does not provide explicit guidance on how the authors should address this contradiction or what changes they should make to resolve it. The comment lacks actionable details, leaving the authors without a clear understanding of how to improve their draft. As a result, the feedback is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (12)\" and \"IPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a contradiction between the objective of Equation (12) and the theory proof provided. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is a contradiction between the objective of Equation (12) and the theory proof provided. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting a contradiction between the objective of Equation (12) and the theory proof provided. This feedback is somewhat helpful as it highlights a potential weakness in the paper that the authors should address. However, the comment lacks depth and does not provide specific guidance or suggestions on how to resolve the contradiction or improve the theory proof. To be more helpful, the comment could include additional context, examples, or suggestions for addressing the issue. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment identifies a contradiction between the objective of Equation (12) and the theory proof provided. However, it does not provide explicit guidance on how the authors should address this contradiction or what changes they should make to resolve it. The comment lacks specific suggestions or detailed instructions, leaving the authors without a clear understanding of how to improve their draft. As a result, the feedback is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Eq (12)\" and \"IPO,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a contradiction between the objective of"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder may not produce meaningful embeddings for such concepts, which could be a concern for the proposed method. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the adaptation capacity. The action is implicit and vague, as the authors are left to infer that they need to explore or address this concern, but without concrete steps or examples. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the adaptation capacity of the proposed visual memory to accommodate new concepts, specifically mentioning the assumption that the image encoder can produce meaningful embeddings for new concepts. It also raises a concern about the adaptation capacity for concepts where class labels correlate more with semantics rather than geometry, such as DINO representations. However, the comment does not specify which part of the paper discusses the adaptation capacity or the proposed visual memory, making it weakly grounded. The comment is specific in detailing the concern about the adaptation capacity for certain types of concepts, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It suggests that the image encoder may not produce meaningful embeddings for such concepts, which could be a concern for the proposed method. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it lacks detailed evidence or examples to substantiate the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the adaptation capacity of the proposed visual memory to accommodate new concepts, particularly those where class labels correlate more with semantics rather than geometry. It questions whether the image encoder can produce meaningful embeddings for such concepts, which could be a concern for the proposed method. While the comment identifies a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the adaptation capacity. The feedback is somewhat helpful as it points out a potential limitation, but it could be more actionable with additional insights or suggestions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the paper should include a comparison against the state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This is a clear and direct action for the authors to take, as it provides a specific and concrete suggestion for enhancing the paper. The comment does not leave any ambiguity about what needs to be done, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this suggestion pertains to, such as the experimental section or the discussion of related work. The authors might infer that it relates to the comparison section, but this is not explicitly mentioned. The comment is specific in its suggestion to include these loss functions, but the lack of grounding makes it difficult for the authors to pinpoint the exact section where this addition should be made. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This is a logical suggestion based on the field\\'s standards and practices, as these loss functions are commonly used in biometric verification. However, the comment does not provide specific references or examples of how these loss functions are typically used or why they are relevant to the paper\\'s focus. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the relevance and importance of these loss functions on their own. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the paper by recommending the inclusion of a comparison against state-of-the-art loss functions used in face/iris verification. It specifically mentions examples such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace, which are widely used in the field. This feedback is valuable as it directs the authors to a specific area where their work could be enhanced, offering a concrete way to strengthen the paper\\'s contribution and relevance. However, the comment could be more helpful if it provided additional context or reasoning on why these loss functions are particularly relevant or how their inclusion could impact the paper\\'s findings. Despite this, the comment is mostly helpful as it offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what the authors should do to address this question or improve the section. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the intent of Section 5.2, but it does not specify which part of the paper this section is located in. This makes it difficult for the authors to identify the exact section being addressed, resulting in weak grounding. The comment is specific in questioning the intent of the section, but without clear grounding, it is challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification about the intent of Section 5.2. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking additional information, which does not fit the criteria for a verifiable claim. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, which is a valid inquiry that could help the authors clarify the purpose and content of this section. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or improve the section. Without actionable feedback or specific advice, the comment lacks depth and does not effectively support the authors in enhancing their draft. Therefore, it is rated as barely helpful, as it identifies a potential area for improvement but does not offer actionable steps for the authors to take.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to clarify the threat model by defining the assumed threat model more explicitly. It provides concrete guidance on what needs to be included, such as specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. Additionally, it suggests including this information in a dedicated section, which further clarifies the action required. This level of detail and specificity makes the comment highly actionable, as it provides clear and concrete steps for the authors to take to improve their draft.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the threat model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as defining the assumed threat model more explicitly by specifying the attacker\\'s level of access, capabilities, and the defender\\'s available resources. Additionally, it suggests including this information in a dedicated section, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the threat model needs further clarification, specifically asking the authors to define the assumed threat model more explicitly. It provides a clear and specific suggestion for improvement, which is to include details such as the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This feedback is well-supported by logical reasoning, as it highlights the importance of clarity in the threat model for enhancing the paper\\'s comprehensibility. However, the comment could be strengthened by providing examples or references to similar works that effectively address the threat model, which would make it fully verifiable. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for further clarification of the threat model. It provides a clear and actionable suggestion by asking the authors to define the assumed threat model more explicitly, including details such as the attacker\\'s level of access, capabilities, and the defender\\'s available resources. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or references to similar works that effectively address the threat model. Overall, the comment is mostly helpful, as it offers clear guidance for improvement but could be expanded with more detailed suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the chat-gpt baseline is rudimentary and lacks testing for a few-shot approach. It suggests including discourse relation information in prompts, possibly using a Chain-of-Thought style, which could improve the results and enhance the paper\\'s evaluation. However, the comment does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should consider these suggestions but are not given specific steps to follow. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the chat-gpt baseline, suggesting that it is rudimentary and lacks testing for a few-shot approach. It also recommends including discourse relation information in prompts, possibly using a Chain-of-Thought style, which could improve the paper\\'s evaluation. However, the comment does not specify which part of the paper this feedback pertains to, such as a specific section or experiment. This makes it difficult for the authors to pinpoint the exact area needing attention. While the comment is specific in its suggestions, it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the chat-gpt baseline is rudimentary and lacks testing for a few-shot approach. It also suggests that including discourse relation information in prompts could yield good results, which would enhance the paper\\'s evaluation. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The suggestion to include discourse relation information is not substantiated with evidence or examples, leaving the authors without a clear path to follow. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a weakness in the paper's evaluation by noting that the chat-gpt baseline is rudimentary and lacks testing for a few-shot approach. It suggests that including discourse relation information in prompts, possibly using a Chain-of-Thought style, could improve the results and enhance the paper's evaluation. However, the comment does not provide specific guidance on how to implement these suggestions or what impact they might have on the paper's evaluation. While it highlights an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. The authors are given a direction to consider but are left without detailed instructions on how to execute these changes effectively. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to present the results comparing standard- vs. evolutional dropout on shallow models as a mean over many runs, ideally with error bars. It also points out that the plotted curves are from single runs and might be subject to significant fluctuations, and suggests that the models are small, making it necessary to provide statistics. The comment provides clear and concrete actions for the authors to take, specifying what needs to be done to improve the presentation of the results. This level of detail and specificity makes the feedback highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results comparing standard- vs. evolutional dropout on shallow models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, such as presenting the results as a mean over many runs with error bars and providing statistics for the models. This level of detail and clarity ensures that the authors know exactly what needs to be revised in their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs with error bars, as the plotted curves are from single runs and might be subject to significant fluctuations. The comment also suggests that the models are small, making it necessary to provide statistics. While the claim is logical and based on common practices in data analysis, it lacks specific examples or references to support the assertion about the necessity of error bars or statistics. This makes the claim somewhat verifiable, as it provides a general rationale but could be strengthened with more detailed evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides clear and actionable feedback by identifying a specific issue with the presentation of results. It suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs with error bars, as the current presentation using single runs might be subject to significant fluctuations. Additionally, it points out that the models are small, which is a valid observation. The comment is mostly helpful as it offers specific guidance on how to improve the presentation of results, but it could be more helpful if it provided examples or detailed instructions on how to implement these changes. Overall, the feedback is clear and actionable, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide more detailed information about the experimental environment, specifically mentioning the need to describe the CUDA version and the PyTorch version. This feedback is clear and direct, as it specifies exactly what additional information is required to improve the draft. The authors know exactly how to address this feedback by providing the requested details, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. This feedback is fully grounded as it explicitly mentions the need for additional details about the experimental setup. However, it does not specify what aspects of the experimental environment should be described in more detail, such as hardware specifications or software configurations. This lack of specificity reduces the comment to a fully grounded but under-specific category. Therefore, the comment aligns with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the authors need to provide more detailed information about the experimental environment, specifically mentioning the CUDA and PyTorch versions. The claim is based on the assumption that different versions of these environments can impact training and inference speeds. While the comment provides a logical reasoning for the need for this information, it lacks specific examples or references to support the claim fully. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but requires further elaboration for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the need for more detailed description of the experimental environment, such as the CUDA and PyTorch versions. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the transparency and reproducibility of the experimental setup. By addressing this feedback, the authors can improve the clarity and robustness of their work. However, the comment could be more helpful if it included specific examples of how different versions of these environments might impact the results or training/inference speeds. Overall, the comment is mostly helpful as it guides the authors towards a specific area of improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the evaluation metric should be mentioned in lines 078-079 and 08 to enhance clarity and comparability of the results. It provides a specific example of the 'labelled F-measure scores (LF1) (including ROOT arcs)' used in Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez (2020), which the authors can reference. This feedback is explicit and provides concrete guidance on what needs to be added to improve the draft, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions lines 078-079 and 08, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the evaluation metric to enhance clarity and comparability of the results. The comment provides a reference to a specific work (Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez, 2020) that uses a similar metric, offering a concrete example for the authors to follow. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that mentioning the evaluation metric would enhance clarity and comparability of the results. It provides a specific example of the 'labelled F-measure scores (LF1) (including ROOT arcs)' used in a referenced work (Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez, 2020), which supports the claim. This provides a clear rationale for the suggestion, making the comment mostly verifiable. However, it could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment is highly helpful as it identifies a specific area for improvement in the paper, namely the lack of clarity regarding the evaluation metric. It provides a clear and actionable suggestion by recommending that the evaluation metric be mentioned in the specified lines to enhance understanding of the scale of the improvement. Additionally, the comment offers a specific example from a referenced work (Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez, 2020) that uses a similar metric, which can serve as a model for the authors. This feedback is detailed and provides a concrete way for the authors to improve the clarity and comparability of their results, making it highly helpful.\", 'helpfulness_label': '5'}{'actionability_rationale': \"The review comment suggests that the evaluation metric should be mentioned in lines 078-079 and 08 to enhance clarity and comparability of the results. It provides a specific example from a referenced work (Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez, 2020) that uses a similar metric, offering a concrete reference for the authors to follow. This feedback is explicit and provides clear guidance on what needs to be added to improve the draft, making it highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions lines 078-079 and 08, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of the evaluation metric to enhance clarity and comparability of the results. The comment provides a concrete example from a referenced work (Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez, 2020) that uses a similar metric, offering a clear reference for the authors to follow. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that mentioning the evaluation metric would enhance clarity and comparability of the results. It provides a specific example from a referenced work (Fern\u00e1ndez-Gonz\u00e1lez and G\u00f3mez-Rodr\u00edguez, 2020) that uses a similar metric, which supports the claim. This provides a clear rationale for the suggestion, making the comment mostly verifiable. However, it could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment is highly helpful as it identifies a specific area for improvement in the paper, namely the lack of clarity regarding the evaluation metric. It provides a clear and actionable suggestion by recommending"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the bounds having o(1) terms and suggests that the improvement over previously known results is limited to arbitrarily long inputs. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they should consider to expand the applicability of their approach. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper, namely the bounds having o(1) terms and their impact on the applicability of the approach. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the concern about the bounds and their potential limitations, but it lacks detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the bounds having o(1) terms and their impact on the applicability of the approach. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the bounds are problematic or limit the applicability of the approach. Without specific examples or references, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the bounds having o(1) terms and their impact on the applicability of the approach. It questions the size of the inputs required for improvement, suggesting that this could limit the practical use of the approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand the applicability of their approach. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are left with a general understanding of the concern but without clear steps to improve their draft. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about the paper\\'s focus on single-token cloze queries or multi-token ones, noting that this is not clarified until the conclusion. While the comment identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify this in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the focus on single-token versus multi-token queries in the paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"single-token cloze queries\" and \"multi-token ones,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of clarity until the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about the paper\\'s focus on single-token cloze queries or multi-token ones, noting that this is not clarified until the conclusion. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim of confusion. Without additional context or explanation, the authors may find it challenging to understand the basis of the confusion and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the distinction between single-token cloze queries and multi-token ones. It notes that this clarification is not provided until the conclusion, which could be confusing for readers. While the comment highlights a potential issue, it does not offer specific suggestions or guidance on how the authors might address this confusion in their draft. The feedback is somewhat helpful as it points out a gap in the paper\\'s clarity, but it lacks actionable advice, making it difficult for the authors to effectively improve their work. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of clarity regarding the major contributions of the paper and suggests that analyzing previous work does not constitute a contribution. However, it does not provide explicit guidance on how the authors should address this issue or what specific contributions they should highlight. The comment lacks concrete details on how to improve the paper, leaving the authors with a vague understanding of what needs to be done. As a result, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the clarity of the paper\\'s contributions and suggests that analyzing previous work does not constitute a contribution. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in pointing out the lack of clarity regarding contributions and the potential misinterpretation of analyzing previous work as a contribution. However, without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where these issues are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that analyzing previous work does not constitute a contribution, which is a subjective judgment. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper's clarity regarding its contributions. It points out that analyzing previous work does not constitute a contribution, which is a crucial observation that could help the authors refine their paper's focus and messaging. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the clarity of their contributions. While it highlights an important area for improvement, the feedback is somewhat helpful as it provides a direction for the authors to consider but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature A to a vector form, specifically mentioning that A represents multiple attributes. This is an explicit suggestion that provides a clear direction for the authors to consider. However, it does not specify how this extension should be implemented or what specific attributes should be included in the vector form. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature A to a vector form, implying that A represents multiple attributes. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area needing attention. The comment is specific in its suggestion to extend A to a vector form, but without grounding, it is weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests extending the protected feature A to a vector form, implying that A represents multiple attributes. However, the comment does not provide any reasoning, evidence, or examples to support why this extension would be beneficial or how it could be implemented. Without such justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests extending the protected feature A to a vector form, implying that A represents multiple attributes. This feedback is somewhat helpful as it provides a specific suggestion for improvement, which could enhance the paper by allowing for more comprehensive analysis or representation of the protected feature. However, the comment lacks detailed guidance on how to implement this extension or what specific attributes should be included in the vector form. To be more helpful, the comment could include examples or a more detailed explanation of how this extension could be beneficial. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might differentiate their work or enhance its technical contribution. As a result, the comment lacks actionable information, leaving the authors without a clear path forward. Therefore, this comment is rated as unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the similarity between two methods, $kNN-ECD$ and $kNN-MT$, and suggests that this similarity limits the paper\\'s technical contribution. However, it does not specify which part of the paper discusses these methods or how they are compared, making it difficult for the authors to identify the exact section that needs revision. The comment lacks specificity in terms of what aspects of the methods or their comparison should be addressed. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how it affects the paper\\'s contribution. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that the technical contribution of the paper is limited due to the similarity between $kNN-ECD$ and $kNN-MT$. This feedback is somewhat helpful as it identifies a potential issue with the paper's contribution. However, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the paper's contribution. Without actionable advice or detailed feedback, the comment provides only a vague insight into the paper's shortcomings, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an example and perhaps a figure would be beneficial in explaining the definition of uniform shattering. While the action is explicit, it is somewhat vague as it does not specify which part of the paper this explanation should be included in or how the example or figure should be structured. The authors know that they need to provide additional explanation or visual aids, but the comment lacks detailed guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an example and perhaps a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its suggestion to include an example and a figure, but without explicit references to the paper, the authors may struggle to pinpoint the exact section where this explanation is needed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an example and perhaps a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning, evidence, or examples to support why this would be beneficial or how it would enhance the paper. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an example and perhaps a figure would be helpful in explaining the definition of uniform shattering. This feedback is somewhat helpful as it identifies a specific area where additional clarification could improve the paper\\'s clarity. However, the comment lacks depth and does not provide detailed guidance on how to create effective examples or figures or where they should be included. While it points out a potential area for improvement, it does not offer actionable steps or specific suggestions, leaving the authors with a general idea of what could be beneficial but without detailed guidance on execution. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point expresses a belief that the proposed transductive method is not very novel, as it is similar to common methods for incorporating unlabeled data in semi-supervised learning, such as self-training. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve the novelty of their method. Without specific suggestions or directions, the authors are left without a clear path for improvement. Therefore, this comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': \"The comment critiques the proposed transductive method, suggesting it is not novel and relates to common methods for incorporating unlabeled data in semi-supervised learning. However, it does not specify which part of the paper discusses the transductive method or how it is related to self-training methods. This lack of grounding makes it difficult for the authors to identify the exact section that needs revision. The comment is specific in its critique of the method's novelty, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point claims that the proposed transductive method is not novel, as it is similar to common methods for incorporating unlabeled data in semi-supervised learning, such as self-training methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment expresses a belief that the proposed transductive method is not novel, as it is similar to common methods for incorporating unlabeled data in semi-supervised learning, such as self-training methods. While the comment identifies a potential issue with the novelty of the method, it lacks specific details or examples to support this claim. It does not provide actionable feedback or suggestions for how the authors might address this concern or improve the novelty of their approach. Without actionable guidance, the comment is not helpful to the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. As a result, the authors are left without a clear understanding of what steps to take to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment does not specify which part of the manuscript this assumption is discussed in, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the assumption are not practical or how it could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment lacks specific examples or references to support the claim that the assumption is not practical. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the assumption among classes, stating that it is not a practical assumption. It acknowledges that the formulation or definition in the manuscript is somewhat trivial but highlights its importance in optimization and theoretical property analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential weakness, it does not provide actionable feedback or detailed advice on how to enhance the manuscript. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the effectiveness of the multi-view clustering approach and questions the usefulness of the other views. It highlights the lack of detailed analysis of differences and similarities between the views, particularly in the context of clustering paraphrases of the word \"slip.\" While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The suggestion to conduct a more detailed analysis is implicit and lacks concrete steps on how to implement it. Therefore, the comment is somewhat actionable, as it points out a specific area for improvement but does not offer detailed instructions on how to achieve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"multi-view clustering approach\" and the \"paraphrase similarity view,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the usefulness of other views and the lack of detailed analysis of differences between views. The comment is specific in detailing what needs to be addressed, such as a more detailed analysis of the different views and their differences. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the effectiveness of the multi-view clustering approach, particularly regarding the dominance of the paraphrase similarity view. It questions the usefulness of other views and lacks detailed analysis of their differences. The comment provides a specific example of how the different views help in clustering paraphrases of the word \"slip,\" but it does not offer further analysis or comparisons. While the comment highlights a potential issue, it lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some context but requires additional support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the effectiveness of the multi-view clustering approach, particularly noting that the paraphrase similarity view consistently outperforms other views and their combinations. It questions the usefulness of the other views and highlights the need for a more detailed analysis of their differences and similarities. The comment provides a specific example of how the different views help in clustering paraphrases of the word 'slip,' but it lacks further analysis or discussion of other views. While the comment identifies a gap in the analysis, it could be more helpful if it offered suggestions on how to conduct a more comprehensive analysis or what specific aspects should be examined. Overall, the comment is somewhat helpful as it points out an area for improvement but lacks depth and actionable guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not explicitly instruct the authors to include these results or provide specific guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include detailed experimental results to address the concern. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. It suggests that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or experiment. This makes it difficult for the authors to identify the exact part of the paper that needs revision. Additionally, while the comment specifies the need for detailed experimental results, it does not provide specific guidance on what aspects of the results should be detailed or how they should be presented. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.\", 'grounding_specificity_label': '2', 'verifiability_rationale': \"The review point raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. However, the comment lacks specific examples or detailed reasoning to support the claim that the scaling law does not apply to dense retrieval models or that the results on Wikipedia are not sufficient. The reference to Ni et al. provides some context, but the comment does not fully substantiate the claim or guide the authors on how to address the issue. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks comprehensive justification.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the unexpected finding that increasing the model size can hurt performance, referencing a recent paper by Ni et al. that suggests the scaling law applies to dense retrieval models. The reviewer implies that the authors should provide detailed preliminary experimental results on Wikipedia to address this issue. While the comment identifies a potential weakness in the paper's findings, it lacks specific guidance on how to present or interpret these results. The authors are left with a general suggestion to include more detailed experimental results, but without further direction, the feedback remains somewhat helpful. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include related experiments to demonstrate how the information axis tool can be applied. While the comment implies that such experiments are needed, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to design them. The action is implicit and somewhat vague, as the authors can infer the need for experiments but lack specific instructions on how to execute them. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"conclusion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is related experiments demonstrating the application of the information axis tool. This provides clear guidance on what needs to be added to the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the paper should include related experiments to demonstrate the utility of the information axis tool. However, it does not provide any specific examples or references to support the claim that such experiments are necessary. The comment lacks detailed reasoning or evidence to justify why these experiments are crucial, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by suggesting that the authors should include related experiments to demonstrate the utility of the information axis tool. This feedback is somewhat helpful as it points out an area where the paper could be strengthened by providing more evidence for the effectiveness of the tool. However, the comment lacks specific guidance on what types of experiments should be conducted or how they could be designed, which limits its usefulness. To be more helpful, the comment could provide more detailed suggestions or examples of experiments that could be conducted. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but lacks comprehensive guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what steps they might consider. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or details about the Greek issue or how it relates to the paper. Without clear grounding and specificity, the authors cannot effectively address the comment. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a request for information, expressing interest in understanding whether other multilingual pretraining setups also struggle with Greek. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment expresses interest in understanding whether other multilingual pretraining setups also struggle with Greek. While it identifies a potential area of concern, it does not provide any specific feedback or suggestions for improvement. The comment lacks actionable guidance or context that could help the authors address this issue or enhance their work. As a result, it is barely helpful, as it provides a general point of interest but does not offer concrete steps for improvement. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a specific issue with the text in lines 293-295, stating that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should address this issue by providing a clearer explanation or justification. However, it does not explicitly instruct the authors to make these changes or provide specific guidance on how to improve the clarity. The action is implicit and somewhat vague, as the authors know they need to clarify the text but may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 293-295,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the text, which is that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should provide a clearer explanation or justification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 makes the point unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples or reasoning to support this claim, nor does it offer suggestions for improvement. Without detailed justification or evidence, the claim remains unverifiable, as it lacks the necessary support to help the authors understand and address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the text in lines 293-295, noting that it makes the point unclear and difficult for readers to understand and evaluate. The comment suggests that the authors should provide a clearer explanation or justification to address this issue. While the comment highlights a potential area of improvement, it lacks detailed guidance or specific suggestions on how to enhance clarity. The feedback is somewhat helpful as it points out a specific area for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the organization and clarity of the proofs, noting that many proofs lack clean logic and are difficult to follow. It specifically mentions Lemma 3 and questions whether the result holds for any polynomial function $P(\\\\gamma)$. While the comment identifies a specific area of concern, it does not provide explicit guidance on how to improve the organization or logic of the proofs. The authors are left to infer that they need to reorganize and clarify the proofs, but the lack of concrete steps or suggestions makes the action implicit and vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lemma 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of the proof being poorly organized and lacking clean logic, and it raises a question about the applicability of the result to any polynomial function $P(\\\\gamma)$. This provides clear guidance on what needs to be addressed in the proof. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is poorly organized and lacks clean logic, making it difficult to follow and check for correctness. The comment provides a specific example by mentioning Lemma 3 and questioning whether the result holds for any polynomial function $P(\\\\gamma)$. This provides some justification for the claim, as it highlights a specific area of concern. However, the comment could be strengthened by offering more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides some support but lacks comprehensive evidence or detailed reasoning.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the organization and clarity of the proofs, noting that many proofs lack clean logic and are difficult to follow, making it challenging to check their correctness. It specifically mentions Lemma 3 and raises a question about the applicability of the result to any polynomial function $P(\\\\gamma)$. This feedback is clear and actionable, as it highlights a specific area for improvement and provides a concrete example of where the authors can focus their efforts to enhance the clarity and rigor of their proofs. However, the comment could be more helpful if it offered suggestions on how to improve the organization or logic of the proofs. Overall, the comment is mostly helpful as it directs the authors' attention to a critical area for improvement, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. While the comment implies that the authors should consider using real-world datasets, it does not provide specific guidance on which real-world datasets to use or how to conduct the experiments. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. However, it does not specify which part of the paper discusses the use of synthetic datasets or the out-of-distribution setting, making it weakly grounded. The comment is specific in its suggestion to use real-world datasets, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. However, the comment does not provide any reasoning or evidence to support why real-world datasets are more appropriate or why synthetic datasets are insufficient for the out-of-distribution setting. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand and address the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This feedback is somewhat helpful as it identifies a potential limitation in the current experimental setup and provides a direction for improvement. However, the comment lacks specific guidance on which real-world datasets to use or how to conduct the experiments, leaving the authors with a general suggestion rather than detailed actionable advice. Therefore, the comment is rated as somewhat helpful, as it points out an area for enhancement but does not fully support the authors in making the necessary changes.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a specific action for the authors to take, which is to show the smoothed GT shapes in Figures 3 and 5. This explicit suggestion provides clear guidance on what needs to be done to improve the paper. The authors are given a direct action to enhance the clarity of the reconstruction quality, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\\' understanding of the reconstruction quality. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include smoothed GT shapes, but without explicit references to the figures, the authors may struggle to pinpoint the exact sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests showing smoothed GT shapes in Figures 3 and 5 to improve the readers\\' understanding of the reconstruction quality. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would enhance the paper. The lack of justification or evidence makes the claim unverifiable, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests a specific action for the authors to take, which is to show the smoothed GT shapes in Figures 3 and 5. This feedback is clear and actionable, as it provides a direct way for the authors to enhance the clarity of their reconstruction quality. By following this suggestion, the authors can improve the readers\\' understanding of their work. However, the comment could be more helpful if it explained why showing these smoothed shapes is important or how it would benefit the readers. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional context.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a mixed usage of notations for $\\\\hat{Y}$ and $Y$ in Section 2. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to clarify the notations, reorganize the section, or provide a consistent notation throughout the paper. Without specific instructions or examples, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notations of $\\\\hat{Y}$ and $Y$ being used in a mixed way in Section 2. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the notations, allowing the authors to understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the notations of $\\\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issue and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the notations of $\\\\hat{Y}$ and $Y$ being used in a mixed way in Section 2. This is a clear and actionable feedback that highlights a potential source of confusion for readers. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending a consistent notation or providing a clearer explanation. While it points out a problem, it lacks depth and specificity, making it somewhat helpful. The authors are given a direction to improve, but the feedback could be more comprehensive with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to \"cite and discuss\" certain references related to domain adaptation in the revised manuscript. This provides a clear and direct action for the authors to take, specifying what needs to be added and how to implement the change. The feedback is explicit and concrete, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment highlights a lack of important references for domain adaptation, suggesting that the authors should cite and discuss these references in the revised manuscript. However, it does not specify which references are missing or what specific domain adaptation-related references should be included. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific about what needs to be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss these references in the revised manuscript. However, the comment does not provide specific examples of the missing references or explain why they are important. This lack of detail makes it difficult for the authors to understand the scope of the issue and how to address it. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or justification to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks important references related to domain adaptation. It provides a clear and actionable suggestion for the authors to include and discuss these references in the revised manuscript. This feedback is valuable as it guides the authors on how to improve the comprehensiveness and depth of their work by incorporating relevant literature. However, the comment could be more helpful if it specified which references are missing or provided examples of relevant works. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the SCNN\\'s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. The comment also provides a presentation suggestion. While the action of questioning the hyperparameters is explicit, the suggestion to present this information is vague and lacks specific guidance on how to address the issue or present the information. The authors know they need to address the concern about the hyperparameters, but the suggestion for presentation is not detailed enough. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the SCNN\\'s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion for presentation is specific, but the lack of grounding makes it challenging for the authors to identify the exact section needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the SCNN\\'s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. However, the comment lacks specific evidence or detailed reasoning to support the claim that the SCNN is \"lucky\" or to explain why the distance to the next best model is suspiciously large. Without additional context or examples, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the SCNN's performance on domain pricing, suggesting that it might be 'lucky' given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. While the comment identifies a potential issue with the model's performance, it lacks specific guidance on how to address the concern or improve the presentation. The suggestion for presentation is a positive addition, but the overall feedback could be more actionable and comprehensive. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully guide the authors on how to improve their draft.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment raises a concern about the SCNN\\'s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. While the comment identifies a potential issue with the hyperparameters and suggests a presentation improvement, it does not explicitly instruct the authors to investigate the hyperparameters or provide specific guidance on how to address the issue. The suggestion for presentation is clear, but the lack of detailed action on the hyperparameter concern makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the SCNN\\'s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. Additionally, it provides a presentation suggestion. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion for presentation is specific, but the lack of grounding makes it challenging for the authors to identify the exact section needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the SCNN\\'s performance on domain pricing, suggesting that it might be \"lucky\" given the hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and points out a suspiciously large distance to the next best model. However, the comment lacks specific evidence or detailed reasoning to support the claim that the SCNN is \"lucky\" or to explain"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what aspects need clarification or how to improve the motivation. The comment lacks concrete details or suggestions on how the authors might address these issues, leaving the authors uncertain about the specific steps to take. As a result, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment identifies specific areas of the experimental setup that are unclear or poorly motivated, particularly regarding corpora and datasets. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the clarity and motivation of the experimental setup, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some aspects of the experimental setup are unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. Without additional context or evidence, the claim remains vague and unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the clarity and motivation of the experimental setup, particularly in relation to corpora and datasets. While it points out a potential issue, it lacks detailed guidance or suggestions on how the authors might address these concerns or improve the clarity of their experimental setup. The comment provides a starting point for the authors to consider, but it does not offer actionable steps or specific examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model, specifically in terms of depth or number of parameters, and points out that the authors mention the number of hourglass modules but do not specify their size. This comment implies that the authors should provide more detailed information about the model\\'s size to facilitate a comparison with competing approaches. While the action is implicit, it is clear and concrete, as the authors know exactly what information needs to be added to improve their draft. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the size of the model, specifically in terms of depth or number of parameters, and points out that the authors mention the number of hourglass modules but do not specify their size. This provides some grounding as it refers to the model\\'s architecture, but it does not specify which part of the paper this information is missing. The comment is specific in asking for clarification on the size of the hourglass modules, which helps the authors understand what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the size of the model, specifically in terms of depth or number of parameters, and points out that the authors mention the number of hourglass modules but do not specify their size. This is a factual observation that does not require verification or evidence. It is a request for clarification rather than a claim or suggestion, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the size of the model, specifically in terms of depth or number of parameters, which is important for understanding the model\\'s complexity and performance. It points out that the authors mention the number of hourglass modules but do not specify their size, leaving a gap in the information provided. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the model\\'s size, which is crucial for a comprehensive comparison with competing approaches. However, the comment could be more helpful if it suggested how this information could be presented or what specific details should be included. Overall, the comment is mostly helpful as it identifies a gap in the information provided and offers a clear direction for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not give better results compared to previous theoretical results. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue or improve their work. Without specific suggestions or directions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, stating that it does not give better results compared to previous theoretical results. However, the comment does not specify which part of the paper this critique pertains to, such as a particular section or subsection. This makes it difficult for the authors to pinpoint the exact area needing attention. Additionally, while the comment provides some context by mentioning Bartlett et al. (2017), it lacks specificity in detailing what aspects of the metric perspective analysis are not working or how they could be improved. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper is based on the generalization theory of neural networks, as mentioned in Bartlett et al. (2017). It also suggests that the metric perspective analysis proposed in the paper does not give better results compared to previous theoretical results. However, the comment lacks specific examples or detailed reasoning to support the claim that the metric perspective analysis is not working. The reference to Bartlett et al. (2017) provides some context, but it does not substantiate the claim with additional evidence or analysis. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the theoretical foundation of the paper, specifically the metric learning theory, which is said to be based on the generalization theory of neural networks as mentioned in Bartlett et al. (2017). It also critiques the metric perspective analysis, suggesting that it does not give better results compared to previous theoretical results. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their work. While it points out a potential weakness, it does not provide actionable feedback or detailed advice on how to enhance the paper. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not fully support the authors in making those improvements.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential confusion in notation, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This feedback is explicit in identifying the issue, but it does not provide specific guidance on how to resolve the confusion. The authors are left to infer that they should clarify the notation or provide a consistent explanation for the use of \"r\" in different contexts. While the action is implied, it is concrete enough for the authors to understand the need for clarification. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation used in the paper, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This provides full grounding as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific because it clearly specifies the issue with the notation, which is the potential confusion it may cause. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems is confusing. This is a subjective observation that lacks specific examples or detailed reasoning to support the claim. The comment does not provide a logical explanation or references to clarify why this notation is confusing, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the notation used in the paper, specifically the use of \"r\" to denote both risk for minimization problems and primal risk for minimax problems. This feedback is clear and actionable, as it points out a specific area where the authors can improve the clarity and consistency of their notation. By addressing this issue, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it provided suggestions on how to resolve the confusion, such as proposing alternative notations or explaining the rationale behind the current notation. Overall, the comment is mostly helpful as it highlights a potential issue but lacks detailed guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific steps they should take to incorporate the corpus residual value into their analysis. The action is implicit and somewhat vague, as the authors need to infer that they should explore the use of corpus residual value to detect such differences. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. The comment suggests that this issue could be detected using the corpus residual value, providing a clear direction for the authors to consider. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate the claim that the corpus residual value could be used for this purpose. Without additional justification or references, the claim remains unverifiable, as it lacks the necessary details to help the authors understand or address the issue. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical question about the robustness of the approach when dealing with test examples that are crucially different, such as the patient in Figure 8 being \"British\" and using an American corpus for explanation. It suggests that this issue could be detected using the corpus residual value, which is a constructive and insightful observation. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or incorporate the corpus residual value into their analysis. While it identifies a potential weakness, the feedback could be more helpful with additional details or actionable steps. Therefore, the comment is somewhat helpful, as it provides a valuable insight but lacks depth and specificity.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP, as it is more popular and could facilitate direct comparison with mainstream QA research. The comment provides a clear and explicit action for the authors to take, which is to change the dataset used in their study. The suggestion is concrete, as it specifies the alternative dataset and its potential benefits. Therefore, this comment is highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment addresses the choice of dataset used in the study, specifically mentioning WebQuestionsSP and suggesting the use of the more popular WebQuestions benchmark set. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the dataset choice. The comment is also specific because it suggests a change in dataset and explains why using WebQuestions would be more intuitive and facilitate comparison with mainstream QA research. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point suggests that the authors should consider using the WebQuestions benchmark set instead of WebQuestionsSP, as it is more popular and could facilitate direct comparison with mainstream QA research. The comment provides a logical reasoning for the suggestion, stating that since NSM only requires weak supervision, using WebQuestions would be more intuitive and straightforward. However, the comment lacks specific references or examples to support the claim that WebQuestions is more popular or why it would be more intuitive. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but could be strengthened with additional evidence or references.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a clear and actionable suggestion for the authors to consider using the WebQuestions benchmark set instead of WebQuestionsSP. It offers a logical reasoning for the choice, stating that using WebQuestions would be more intuitive and facilitate direct comparison with mainstream QA research. This feedback is specific and actionable, offering the authors a concrete way to improve their study by aligning with established benchmarks. However, the comment could be more helpful if it included additional context or examples to further support the suggestion. Overall, the comment is mostly helpful as it guides the authors towards a more effective dataset choice, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment does not explicitly instruct the authors to remove or modify these claims, nor does it provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors can infer that they need to substantiate their claims, but they are not given clear instructions on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. However, the comment does not specify which part of the paper these claims are made in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its critique of the claims but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. The comment provides some reasoning by questioning the desirability of sparsity and suggesting that the authors should demonstrate its benefits. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the exact points the reviewer is questioning, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of making claims about sparsity in training and questions the desirability of sparsity. It suggests that the authors should demonstrate the benefits of sparsity or provide evidence that it leads to practical cost savings. This feedback is mostly helpful as it identifies a potential weakness in the paper's claims and offers a clear direction for improvement. However, it could be more helpful if it provided specific suggestions on how to demonstrate the benefits of sparsity or how to address the concerns about the practicality of the claims. Overall, the comment is mostly helpful, as it guides the authors towards a more robust and substantiated argument.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to provide a plot of the model illustration, a pseudo-code table, or a code repository to clarify the model design and facilitate reproducibility. The suggestion is clear and concrete, as it specifies the exact actions the authors need to take to address the issue of unclear model design. This level of detail and specificity makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the issue of unclear model design, specifically mentioning the fragmentation or absence of details regarding the model architecture and learning process. It suggests providing a plot, pseudo-code table, or code repository to clarify these aspects. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it pertains to the methodology or results sections where the model design is discussed. The suggestion to demonstrate integrated details for reproducibility is clear and specific, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the model design is unclear due to fragmented or missing details about the model architecture and learning process. The reviewer suggests providing a plot, pseudo-code table, or code repository to clarify these aspects. However, the comment lacks specific examples or references to support the claim that Neurochaos Learning is not well-known, which could strengthen the argument for the need to demonstrate integrated details. The suggestion to provide additional information is logical and reasonable, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the clarity of the model design, noting that the model architecture and learning details are fragmented or missing. It provides actionable suggestions for improvement, such as providing a plot of the model illustration, a pseudo-code table, or a code repository, to enhance transparency and reproducibility. This feedback is clear and constructive, offering the authors a straightforward path to address the identified weakness and improve the clarity and accessibility of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to present the model details effectively. Overall, the comment is mostly helpful, as it provides valuable insights and actionable steps for the authors to enhance their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the generalization to specific TSP instances in the paper, particularly in the context of the fine-tuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without meta-learning. While the comment provides a clear direction for improvement, it does not specify how to achieve these clarifications or comparisons. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take to address the suggestions. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalization to specific TSP instances, specifically mentioning the fine-tuning step in DIMES. It suggests clarifying the generalization gaps and provides a specific recommendation to compare DIMES with other methods on TSP100. However, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as clarifying the generalization gaps and comparing with other methods. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the generalization to specific TSP instances should be clarified, particularly in the context of the fine-tuning step in DIMES. It acknowledges that DIMES has advantages in direct RL training for large-scale problems and meta fine-tuning but recommends that the difference should be clearly explained in the paper. Additionally, it suggests comparing DIMES with other methods on TSP100 to assess in-distribution testing performance with and without meta-learning. While the comment provides a logical basis for the suggestions, it lacks specific references or detailed reasoning to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed support to be fully convincing.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the generalization to specific TSP instances, particularly in the context of the fine-tuning step in DIMES. It acknowledges the advantages of DIMES but suggests that the paper should clarify these advantages and provide a more detailed explanation. Additionally, the comment recommends comparing DIMES with other methods on TSP100, both with and without meta-learning, which could enhance the paper's comprehensiveness and impact. While the comment provides clear directions for improvement, it could be more helpful if it offered specific suggestions or examples of how to clarify the generalization gaps or compare with other methods. Overall, the feedback is mostly helpful as it guides the authors towards enhancing the clarity and scope of their work.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges the authors\\' claim that the readability of RC datasets does not directly affect question difficulty, but it points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. While the comment highlights a potential limitation of the claim, it does not provide explicit guidance or suggestions on how the authors might address this issue or further explore the impact of different features on question difficulty. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of various features on their analysis. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and their effect on question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or results section, but this is not explicitly mentioned. The comment is specific in detailing the dependency on features for answer detection, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges a claim made by the authors about the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not provide specific examples or detailed reasoning to support the claim that the method or features are indeed responsible for the observed impact. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further explore the impact of different features to fully understand the reasoning behind the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges a claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. This feedback is somewhat helpful as it highlights a potential limitation in the authors\\' claim and suggests that the authors should consider the impact of different features on their analysis. However, the comment could be more helpful if it provided specific examples or guidance on how the authors might address this issue or further explore the impact of features. Overall, the comment offers some insight but lacks depth and actionable suggestions, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment acknowledges a claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. While the comment highlights a potential limitation of the claim, it does not provide explicit guidance or suggestions on how the authors might address this issue or further explore the impact of different features on their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of various features on their analysis. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific claim made by the authors regarding the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not specify which part of the paper this claim is made in, making it weakly grounded. The authors can infer that it relates to the discussion or results section, but this is not explicitly mentioned. The comment is specific in detailing the dependency on features for answer detection, providing a clear direction for the authors to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges a claim made by the authors about the impact of dataset analysis on the readability of RC datasets and question difficulty. It points out that this conclusion depends on the method or features used for answer detection, such as POS or dependency parse features. However, the comment does not provide specific examples or detailed reasoning to support the claim that the method or features are indeed responsible for the observed impact. The lack of detailed evidence or examples makes the claim somewhat verifiable, as the authors would need to further explore the impact of different features to fully understand the reasoning behind the claim. Therefore, the comment is"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate that the geometry of the space is meaningful, such as whether certain operations on the vectors result in semantically coherent outcomes. While the comment implies that the authors should conduct such an analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence of the meaningfulness of the space. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaningfulness of the vector space resulting from the morphfitting process, specifically asking if the geometry of the space is meaningful. It suggests that the authors should provide evidence or analysis to demonstrate the meaningfulness of the space, such as whether certain operations on the vectors result in semantically coherent outcomes. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the results or discussion sections where the morphfitting process is discussed, but this inference is not explicit. The comment is specific in its request for evidence or analysis to support the meaningfulness of the space. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate the meaningfulness of the space, such as whether certain operations on the vectors result in semantically coherent outcomes. While the comment is a request for evidence or analysis, it does not contain a claim that requires verification. It is a request for additional information or clarification, which is not a claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a critical question about the meaningfulness of the vector space resulting from the morphfitting process. It suggests that the authors should provide evidence or analysis to demonstrate that the geometry of the space is meaningful, such as whether certain operations on the vectors result in semantically coherent outcomes. This feedback is valuable as it prompts the authors to consider the interpretability and utility of their results, which is an important aspect of their work. However, the comment could be more helpful if it provided specific suggestions or examples of how to conduct this analysis. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing quality of the paper should be improved, specifically mentioning the need to address the repetition of explaining basic memory networks and the forward model. It also points out that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not provide specific guidance on how to improve the writing quality or what aspects of the related work should be expanded. The authors are left with a general understanding of what needs to be addressed but without concrete steps or suggestions on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but lacks detailed guidance.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not specify which sections of the paper are affected by these issues, making it weakly grounded. The authors can infer that the writing quality is being evaluated in general, but the lack of specific references to sections or elements makes it difficult to pinpoint the exact areas needing improvement. The comment is specific in identifying the need for improvement in writing quality and the gaps in the related work section, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the writing quality of the paper should be improved, specifically mentioning the repetition of explaining basic memory networks and the forward model. It also notes that the related work section lacks coverage of more reinforcement learning tasks. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the exact issues and how to address them. The lack of detailed evidence or references limits the verifiability of the claim. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies two main areas for improvement in the paper: the writing quality and the related work section. It points out that the authors spend the same space on explaining basic memory networks and the forward model, suggesting that this repetition could be addressed. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks in the literature. While the comment highlights specific areas for improvement, it does not provide detailed guidance or suggestions on how to address these issues. The authors are left with a general understanding of what needs to be improved but without actionable steps to enhance their draft. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity to be fully beneficial.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not provide any guidance or suggestions on how the authors should address this question or what specific aspects of their work might be affected by this inquiry. The comment lacks any explicit or implicit actions for the authors to take, leaving them without a clear direction for improvement. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any context or guidance on how the authors might address this question or what aspects of their work might be affected by it. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about the number of different kinds of physical interactions that can be included in one simulation. It does not contain any claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the number of different kinds of physical interactions that can be included in one simulation. While it identifies a potential area for exploration or clarification, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects of their work might be affected by it. The comment lacks actionable feedback or detailed insights, leaving the authors without a clear path for improvement. Therefore, it is rated as barely helpful, as it provides a starting point for consideration but does not offer substantial guidance for enhancing the draft.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It also points out that the authors do not employ one-hot encoding for this dataset, which could negatively impact performance. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include more datasets with categorical features or employ one-hot encoding, but the comment lacks concrete steps or suggestions on how to implement these changes. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions the 'Model Comparison' section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the dataset selection, noting that only one dataset has categorical features and that the authors do not employ one-hot encoding for this dataset. This provides clear guidance on what needs to be addressed to improve the paper's contribution. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the dataset selection is inadequate because it lacks datasets with categorical features, which are generally more challenging for deep learning models. The comment also points out that the authors do not employ one-hot encoding for the dataset with categorical features, which could negatively impact performance. However, the comment lacks specific examples or references to support the claim that one-hot encoding is necessary for all models. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable, as it provides a basis for the critique but requires further elaboration to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the dataset selection, noting that only one dataset has categorical features, which are generally more challenging for deep learning models. It also points out that the authors do not employ one-hot encoding for this dataset, which could negatively impact performance for some models. This feedback is clear and actionable, as it highlights a potential weakness in the paper's contribution and provides specific guidance on how to address it. By suggesting the inclusion of more datasets with categorical features or the use of one-hot encoding, the comment offers concrete steps for improvement. However, it could be more helpful if it provided additional context or examples of how these changes could enhance the paper's contribution. Overall, the comment is mostly helpful, as it effectively directs the authors towards improving their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It suggests that this could break a significant portion of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to take. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider this aspect in their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to pruning and its impact on large networks trained in distributed settings. It highlights the potential necessity of finding global top Q values of the metric over the average of gradients, which could affect acceleration techniques like quantization and sparsification. However, the comment does not specify which part of the paper discusses pruning or distributed training, making it weakly grounded. The issue is clearly identified, but the lack of explicit reference to specific sections or elements makes it difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks trained in distributed settings and raises a concern about the necessity of finding global top Q values of the metric over the average of gradients. This claim is somewhat verifiable as it provides a logical reasoning about the potential impact of pruning on large networks and distributed training. However, the comment lacks specific examples or references to support the claim fully, making it somewhat verifiable. The authors would need to further investigate the claim to fully understand and address it in their draft.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the pruning process, specifically mentioning the necessity of finding global top Q values of the metric over the average of gradients. It highlights that this could break a significant portion of acceleration techniques like quantization and sparsification, which are commonly used in large networks trained in distributed settings. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it points out a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a valuable insight but does not fully support the authors in improving their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue, such as suggesting they check the figures or providing specific steps to correct any mistakes. Without actionable guidance, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a specific question about the subfigures in Figs 1 and 2, suggesting that they may have been swapped by mistake. This provides full grounding as it explicitly mentions the figures being addressed, allowing the authors to accurately identify the parts of the paper being discussed. The comment is also specific because it clearly specifies the issue of potential swapping, giving the authors a clear direction to investigate. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the subfigures in Figs 1 and 2, suggesting that they may have been swapped by mistake. While this observation is important for the authors to address, the comment lacks actionable guidance or suggestions on how to verify or correct the issue. It does not provide any context or reasoning to support the claim, leaving the authors without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential issue but does not offer actionable feedback or suggestions for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the potential increase in false positives due to the use of the dropout probe, which improves sensitivity and finds a causal role for syntactic representations. While the comment acknowledges the benefits of the probe, it suggests that this should be a substantial part of the discussion. However, it does not provide explicit guidance on how the authors should address this concern or what specific aspects of the discussion should be expanded. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on the potential risks of false positives. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of the dropout probe and its impact on sensitivity and the identification of causal roles for syntactic representations. It raises a concern about the potential increase in false positives due to the probe\\'s effectiveness. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the discussion section, but the lack of explicit mention of a section or specific part of the paper makes it difficult to pinpoint. The comment is specific in detailing the concern about false positives, but without full grounding, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the potential increase in false positives due to the use of the dropout probe, which improves sensitivity and finds a causal role for syntactic representations. The reviewer acknowledges the benefits of the probe but suggests that this should be a substantial part of the discussion. However, the comment lacks specific examples or references to support the claim about false positives, making it difficult for the authors to fully understand and address the concern. The reasoning is logical but lacks detailed evidence, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges the benefits of the dropout probe in improving sensitivity and identifying causal roles for syntactic representations. However, it raises a concern about the potential increase in false positives due to the probe's effectiveness. The comment suggests that this should be a substantial part of the discussion, which is a valuable insight for the authors to consider. While the comment identifies a potential issue, it could be more helpful if it provided specific guidance on how to address this concern or what aspects of the discussion should be expanded. Overall, the comment is somewhat helpful as it highlights an important consideration for the authors to include in their discussion, but it lacks depth and actionable suggestions for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the regret bound for the proposed mini-batch method, stating that it is claimed to be in the appendix but not found in the supplementary material. This comment implies that the authors should verify or clarify the location of the regret bound, ensuring it is accurately referenced or included in the supplementary material. However, the comment does not explicitly instruct the authors to make this change or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should check the appendix or supplementary material for the regret bound. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"regret bound for the mini-batch estimator,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of the regret bound in the supplementary material, despite the authors\\' claim that it is there. The comment provides a clear reference to the work by Zalan Borsos, Andreas Krause, and Kfir Y Levy, which further supports the claim. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors\\' claim about the regret bound for the mini-batch method being in the appendix is not supported by the supplementary material. The reviewer provides a specific reference to a work by Borsos, Krause, and Levy, which suggests that the authors should verify their claim. However, the comment lacks detailed reasoning or examples to substantiate the claim fully. While the reference provides a starting point for the authors to investigate, the lack of additional context or explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the absence of the regret bound for the mini-batch estimator, which the authors claim is in the appendix. This is a critical point as it questions the completeness of the paper's presentation. The comment provides a reference to a relevant work by Borsos, Krause, and Levy, which could help the authors understand the context and potential implications of their claim. However, the comment could be more helpful if it suggested how the authors might address this issue or provided additional context on why this information is important. Overall, the comment is somewhat helpful as it highlights a gap in the paper's presentation but lacks detailed guidance for improvement.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a significant issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. It lacks concrete details on which specific exploration methods should be discussed or compared, or how these comparisons could be made. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, noting that it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in detailing what is missing, namely the discussion and comparison of these exploration methods, but it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. However, the comment lacks specific examples or references to support the claim that these methods are essential or relevant to the paper\\'s focus. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out that it does not discuss or compare various exploration methods in RL literature, such as count-based methods and intrinsic motivations like RND and ICM. This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive analysis of related work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as which exploration methods should be discussed or how they could be compared. While it points out a critical omission, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but does not fully guide the authors in implementing it.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. While the comment identifies specific issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to clarify the inference process, provide the coefficient value, and ensure thorough hyperparameter tuning and ablation studies. However, the lack of concrete steps or suggestions makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several issues related to the paper, including concerns about inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. However, it does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need attention. The comment lacks full grounding as it does not explicitly mention specific sections or figures, but it is somewhat specific in detailing the issues. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. However, the comment does not provide specific evidence, examples, or references to support these claims. The lack of detailed reasoning or references makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several important concerns and questions about the paper, including the impact of inference slowing down, the coefficient of the p(L, E | X) term, missing hyperparameter details, and unclear writing. These points are relevant and could significantly impact the paper\\'s clarity and effectiveness. However, the comment lacks specific suggestions or guidance on how to address these issues, such as providing detailed explanations or examples. While it highlights areas for improvement, the feedback is somewhat helpful as it prompts the authors to consider these aspects but does not offer actionable steps for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific weakness of the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how to improve the performance of the proposed method or what specific changes should be made. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. However, it does not specify which part of the paper discusses this comparison or where the authors should focus their efforts to address this weakness. The authors can infer that it relates to the comparison section or results, but the comment lacks explicit grounding, making it weakly grounded. The comment is specific in identifying the performance issue, but without explicit references to the paper, it remains under-specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed compression method performs worse than PQ when a small code length is allowed, identifying this as the main weakness of the method. However, the comment does not provide any supporting evidence, such as specific data, examples, or references to other works that might corroborate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This is a valuable observation that highlights an area where the authors need to improve their method. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or enhance their method. Without actionable feedback or specific recommendations, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is somewhat helpful, as it points out a weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that the authors should consider comparing biases towards different languages/nationalities. While the comment suggests an area for improvement, it does not explicitly instruct the authors to conduct these comparisons or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"language/nationality\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the detailed analysis of different languages/nationalities and suggests an interesting observation to compare biases. The comment provides clear guidance on what could be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some analyses could be more detailed, specifically mentioning the \"language/nationality\" section where data includes various languages. It implies that there might be interesting observations comparing biases towards different languages/nationalities. However, the comment does not provide specific examples or detailed reasoning to support the claim that these comparisons would be interesting or necessary. The suggestion lacks concrete evidence or examples to substantiate the claim, making it somewhat verifiable. The authors would need to infer the potential significance of these comparisons, which limits the clarity and effectiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that some analyses could be more detailed, specifically mentioning the 'language/nationality' section where data includes various languages. It points out that biases towards different languages/nationalities might be different and suggests that there could be interesting observations comparing them. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a specific suggestion for further analysis. However, it could be more helpful if it included more detailed guidance on how to conduct these comparisons or what specific observations might be interesting. Overall, the comment offers a direction for enhancing the analysis but lacks depth, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physics-related continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. While the comment implies that the authors should investigate this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this topic numerically. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physics-related continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The authors can infer that it relates to the discussion of learning F^dagger or the experimental results, but this is not explicitly stated. The comment is specific in detailing what needs to be addressed, namely the conservation properties of learning F^dagger. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physics-related continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that learning F^dagger should conserve these properties. Without additional context or justification, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises an important question about the behavior of learning F^dagger in terms of conserving properties like mass and charge, which are typically preserved by solvers of physics-related continuous PDEs. It suggests that the authors should explore whether it is possible to train F^dagger to maintain these properties and provides a specific example of Hamiltonian systems. This feedback is valuable as it prompts the authors to consider an important aspect of their work that may impact its applicability and accuracy. However, the comment could be more helpful if it included specific guidance on how to investigate this issue or suggested methods for conserving properties during training. Overall, the comment is mostly helpful as it identifies a critical area for exploration and provides a clear direction for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not provide any explicit or implicit actions for the authors to take, nor does it offer guidance on how to address this expectation. The comment lacks specificity and does not provide any concrete steps or suggestions for improvement, leaving the authors without a clear understanding of what actions to take. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, it does not specify which part of the paper this feedback pertains to, such as a particular section, table, or figure. Without explicit references or detailed guidance, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment lacks specificity as it does not provide examples or detailed suggestions on how to expand the tasks or improve the importance of PE. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that it is expected to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. However, the comment does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or references, the authors may find it challenging to understand the basis of this expectation or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors should expect to see a variety of tasks beyond link prediction where personalized embedding (PE) is important. While this feedback provides a general direction for the authors to consider, it lacks specificity and actionable guidance. It does not offer any detailed suggestions or examples of how the authors might expand their work to address these tasks or improve the importance of PE. As a result, the comment is somewhat helpful, as it offers a potential area for exploration but does not fully support the authors in making concrete improvements to their draft.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point presents a critique of the evaluation method used to assess the quality of \\u003c\\\\overline{\\\\Pi}\\\\u003e. It suggests that evaluating the performance in the worst MDP would be more appropriate than the current summation method. The reviewer provides a clear rationale for this suggestion, explaining that the summation might lead to selecting a subset of policies that are good for most MDPs but very bad for others, which could be hidden by the summation but highlighted by the \\u003c\\\\min\\\\u003e operation. This feedback is explicit and provides a concrete action for the authors to consider, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"intuitive goal\" and the \"worst MDP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current evaluation method, suggesting that evaluating the performance in the worst MDP would be more appropriate than the summation method. The reviewer provides a detailed rationale for this suggestion, explaining why the summation might lead to misleading results. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point presents a critique of the evaluation method used to assess the quality of \\u003c\\\\overline{\\\\Pi}\\\\u003e. It suggests that evaluating the performance in the worst MDP would be more appropriate than the current summation method. The reviewer provides a clear rationale for this suggestion, explaining that the summation might lead to selecting a subset of policies that are good for most MDPs but very bad for others, which could be hidden by the summation but highlighted by the \\u003c\\\\min\\\\u003e operation. This explanation is logical and provides a strong basis for the claim, making the comment mostly verifiable. However, it could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the evaluation method used to assess the quality of \\u003c\\\\overline{\\\\Pi}\\\\u003e. It suggests that evaluating the performance in the worst MDP would be more appropriate than the current summation method, offering a clear rationale for this suggestion. The reviewer explains that the summation might lead to selecting a subset of policies that are good for most MDPs but very bad for others, which could be hidden by the summation but highlighted by the \\u003c\\\\min\\\\u003e operation. This feedback is highly actionable, as it provides a specific and constructive suggestion for improvement, allowing the authors to enhance the robustness and validity of their evaluation method. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': \"The review comment explicitly instructs the authors to move important content from footnotes into the main body of the paper, suggesting that much of the content currently in footnotes is actually important and should be included in the main text. It also provides a specific example of moving details about parameter settings into the appendix to make space. This feedback is clear and provides concrete guidance on how the authors can improve their draft by reorganizing the content. The action is explicit and concrete, making this comment highly actionable.\", 'actionability_label': '5', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'footnotes' and 'L468', allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the extensive use of footnotes and suggests moving important content into the main body of the paper. Additionally, it provides a concrete suggestion to move details about parameter settings into the appendix to make space. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the use of footnotes is excessive and distracting, suggesting that much of the content should be moved into the main body of the paper. The reviewer provides a specific suggestion to move details about parameter settings into the appendix to make space. While the comment offers a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that the content is important or that footnotes are indeed distracting. This makes the claim somewhat verifiable, as it provides a basis for the suggestion but could be strengthened with additional evidence or examples.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the use of footnotes in the paper, noting that they are used too extensively and are distracting. It provides a clear and actionable suggestion to move important content from footnotes into the main body of the paper, which would improve the flow and clarity of the text. Additionally, it offers a specific example of moving details about parameter settings into the appendix to make space. This feedback is clear and provides the authors with a concrete way to enhance the organization and readability of their draft, making it mostly helpful. However, it could be more helpful if it included additional guidance on how to effectively integrate the content into the main body or appendix. Therefore, the comment is rated as mostly helpful.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion about a set of few-shot demonstrations that could be drawn from, possibly with the help of domain experts. It also questions the inclusion of zero-shot generation results, suggesting that they might not be relevant to the main focus of the paper. However, the comment does not provide explicit guidance on how to address these issues or what specific aspects of the few-shot demonstrations should be discussed. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion and possibly clarify the relevance of the zero-shot results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including a discussion about a set of few-shot demonstrations that could be drawn from, possibly with the help of domain experts. It also questions the inclusion of zero-shot generation results, suggesting that they might not be relevant to the main focus of the paper. However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. The authors can infer that it relates to the experimental section or results, but this is not explicitly mentioned. The comment is specific in its suggestion to include a discussion about few-shot demonstrations and questions the relevance of zero-shot results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the inclusion of zero-shot generation results, suggesting that they might not be relevant to the main focus of the paper. However, the comment does not provide specific reasoning or evidence to support why these results are strange or irrelevant. The suggestion to include a discussion about few-shot demonstrations is also made without detailed justification or examples. As a result, the claim is somewhat verifiable, as it raises a concern but lacks sufficient evidence or explanation to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the inclusion of zero-shot generation results, suggesting that they might not be relevant to the main focus of the paper. It also suggests that a discussion about few-shot demonstrations could be beneficial, possibly with the help of domain experts. While the comment identifies a potential issue with the experimental setup, it lacks specific guidance on how to address this concern or improve the relevance of the zero-shot results. The suggestion to include a discussion about few-shot demonstrations is a valuable point, but the comment could be more helpful if it provided more detailed feedback or examples. Overall, the comment is somewhat helpful as it highlights an area for improvement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should acknowledge older works in their related works section, which is a clear and explicit action. However, it does not specify which older works should be acknowledged or how they relate to the current work. While the action is explicit, the lack of specific guidance on which works to include makes it somewhat vague. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed implementation guidance.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related works,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests acknowledging older works in the related works section, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should acknowledge older works in their related works section. However, it does not provide any specific examples or reasoning to support why these older works should be included. The comment lacks detailed justification or references to specific works, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should acknowledge older works in their related works section, which is a valuable piece of feedback. It provides a clear direction for improvement by pointing out a potential oversight in the literature review. However, the comment lacks specificity, as it does not specify which older works should be acknowledged or how they relate to the current work. This limits the authors\\' ability to fully address the feedback. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but lacks detailed guidance.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point identifies several issues contributing to the high time complexity of the proposed method, including the use of an item-oriented autoencoder, the expense of elementwise functions, and the large number of hidden units. However, it does not provide specific guidance or suggestions on how to address these issues or improve the time complexity. The comment lacks actionable details, leaving the authors without a clear path to follow for improvement. As a result, the feedback is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of high time complexity in the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of elementwise functions, and the large number of hidden units. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issues related to time complexity, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the time complexity of the proposed method is high due to the use of an item-oriented autoencoder, the expense of elementwise functions, and the large number of hidden units. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references to comparable methods or studies that might justify the assertion of high time complexity. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies several factors contributing to the high time complexity of the proposed method, including the use of an item-oriented autoencoder, the expense of elementwise functions, and the large number of hidden units. This feedback is somewhat helpful as it points out specific areas where the authors might need to focus on to improve the efficiency of their approach. However, the comment lacks actionable suggestions or guidance on how to address these issues, such as recommending alternative methods or strategies to reduce computational complexity. Without detailed advice, the authors may find it challenging to effectively implement the suggested improvements. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks comprehensive guidance.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the figures in the paper would be clearer if they specified \"pre-trained solution encoders & solution decoders\" instead of just \"autoencoders.\" This feedback provides a clear and explicit action for the authors to take, as it directly instructs them to clarify the types of autoencoders used in the figures. The suggestion is concrete, as it specifies what needs to be changed and how to make the figures more informative. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the figures in the paper would be clearer if they specified \"pre-trained solution encoders & solution decoders\" instead of just \"autoencoders.\" This feedback is fully grounded as it explicitly mentions \"figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed in terms of clarity and detail regarding the types of autoencoders used in the figures. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the figures in the paper would be clearer if they specified \"pre-trained solution encoders & solution decoders\" instead of just \"autoencoders.\" This feedback is based on a logical suggestion for improving clarity and precision in the figures. However, it lacks specific examples or references to support the claim that this change would indeed enhance clarity. While the suggestion is reasonable, the lack of detailed justification makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the clarity of the figures in the paper. It suggests that specifying \"pre-trained solution encoders & solution decoders\" instead of just \"autoencoders\" would enhance the understanding of the figures. This feedback is actionable and directly addresses a potential area for improvement in the paper, making it mostly helpful. However, it could be more helpful if it included examples of how this clarification would be beneficial or if it suggested other ways to improve the figures. Overall, the comment offers clear guidance on how to enhance the clarity of the figures, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of multiple suggestions and observations. It explicitly requests comparisons with specific NeRF-based methods, such as Zero-1-to-3 and point-e, which provides clear actions for the authors to take. Additionally, it questions the relevance of the occlusion experiment, suggesting that it may not be necessary if the method does not propose anything specific to occlusion. While the comment does not explicitly instruct the authors to remove the occlusion experiment, the suggestion is clear and actionable. The authors know exactly what needs to be addressed to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific comparisons, such as with NeRF-based methods like Zero-1-to-3 and point-e, which allows the authors to accurately identify the parts of the paper being addressed. It also questions the relevance of the occlusion experiment, providing a clear specification of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of several requests for comparisons with specific methods, such as Zero-1-to-3 and point-e, and a suggestion to remove the occlusion experiment. These requests are based on the reviewer\\'s knowledge of existing methods and their relevance to the paper\\'s approach. However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or why the occlusion experiment is irrelevant. The lack of specific examples or references makes it difficult for the authors to fully understand and address the feedback. Therefore, the comment is somewhat verifiable, as it provides some guidance but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides several actionable suggestions for improvement. It explicitly requests comparisons with specific NeRF-based methods, such as Zero-1-to-3 and point-e, which can help the authors situate their work within the broader context of related research. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it may not be necessary if the method does not propose anything specific to occlusion. This feedback is clear and provides the authors with a direction for refining their draft. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or address the relevance of the occlusion experiment. Overall, the comment is mostly helpful, as it offers valuable insights and suggestions for improvement.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. While the comment implies that a more detailed analysis is needed, it does not explicitly instruct the authors to provide this information. The action is implicit and somewhat vague, as the authors can infer that they need to clarify the extraction process, but they may not know exactly how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the extraction of parts of sentences and documents and whether the rules of extraction affect the experiment. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of a question asking for clarification about the extraction of parts of sentences and documents, and whether the rules of extraction affect the experiment. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the extraction of parts of sentences and documents, specifically asking how this extraction is performed and whether the rules of extraction affect the experiment. This feedback is somewhat helpful as it prompts the authors to clarify their methodology and potentially identify areas where the extraction process might impact the results. However, the comment lacks specific guidance or suggestions on how to address these questions, leaving the authors with a general direction but no detailed steps to follow. Therefore, the comment is rated as somewhat helpful, as it provides some insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the authors\\' approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. The comment implies that the authors should provide more discussion on this aspect and specify when the meta sampler is applied (i.e., at which epoch). While the action is implicit, it is clear and concrete, as it specifies what additional information the authors need to include. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a question about the authors\\' approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. It also asks when the meta sampler is applied, implying a specific part of the paper where this information should be addressed. However, the comment does not explicitly mention a section or provide a specific reference, making it weakly grounded. The question is specific in its inquiry about the decoupled application and the timing of the meta sampler\\'s use. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the authors\\' approach to applying the meta sampler, specifically whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. The reviewer asks for more discussion on this and when the meta sampler is applied. However, the comment does not provide any evidence, reasoning, or references to support the claim that the meta sampler is only used in a decoupled way. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the authors\\' approach to applying the meta sampler, particularly whether it is used in a decoupled manner, only updating the linear classifier when the features are fixed. It also asks when the meta sampler is applied, implying a need for more discussion on this aspect. While the comment identifies a potential area for clarification, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it prompts the authors to clarify their methodology, but it lacks depth and actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides explicit actions for the authors to take. It suggests that the authors use related fairness-aware metrics like Equality Odds (EO) and conduct more experiments on datasets like COMPAS and Drug Consumption. The comment also provides a specific reference, the AAAI paper cited, which guides the authors on how to proceed. This level of detail and specificity makes the actions clear and actionable, allowing the authors to know exactly what steps to take to improve their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the use of a \"vanilla metric\" defined by the authors and suggests the inclusion of fairness-aware metrics like Equality Odds (EO). It also recommends conducting more experiments on datasets like COMPAS and Drug Consumption, referencing a specific AAAI paper for guidance. However, the comment does not specify which part of the paper discusses the vanilla metric or the experiments, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed, but the lack of grounding makes it challenging for the authors to pinpoint the exact sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors lack related fairness-aware metrics like Equality Odds (EO) and suggests conducting more experiments on specific datasets. However, the comment does not provide detailed reasoning or evidence to support why these metrics are necessary or how they would improve the study. The mention of a specific AAAI paper for guidance is a positive step, but it does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of fairness-aware metrics like Equality Odds (EO) and suggests that the authors conduct more experiments on datasets like COMPAS and Drug Consumption. It provides a specific reference, the AAAI paper cited, which guides the authors on how to proceed. This feedback is clear and actionable, offering the authors a clear direction for enhancing their study by incorporating relevant metrics and expanding their experimental scope. However, the comment could be more helpful if it provided additional context or suggestions on how to integrate these metrics or datasets into the study. Overall, the comment is mostly helpful as it provides valuable guidance for improvement.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the content in lines 107-114 is speculative or overly opinionated and suggests that it should be stated as a remark, an aside in the Discussion section, or removed. This provides a clear and direct action for the authors to take, specifying the exact changes needed to address the issue. The feedback is explicit and concrete, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L107-114,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the content, suggesting that it should be stated as a remark, an aside in the Discussion section, or removed. This provides clear guidance on how to address the concern, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the content in lines 107-114 is speculative or overly opinionated and suggests it should be stated as a remark, an aside in the Discussion section, or removed. However, the comment does not provide specific examples or reasoning to support why this content is speculative or opinionated, nor does it explain why it should be removed or repositioned. Without detailed justification or evidence, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the content in lines 107-114, noting that it seems speculative or overly opinionated. It provides actionable advice by suggesting that this content should be stated as a remark, an aside in the Discussion section, or removed. This feedback is clear and provides a direct way for the authors to improve their draft by addressing the speculative nature of the content. However, the comment could be more helpful if it offered additional guidance on how to rephrase or restructure the content to make it more appropriate for the intended section. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. While the comment implies that the authors should include these baselines for comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines to validate their results. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or experiment. The authors can infer that it pertains to the discussion or results sections, but this inference is not explicit. The comment is specific in its suggestion to include these baselines for comparison, but it lacks grounding as it does not mention specific sections or experiments. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should consider baselines like Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. However, the comment does not provide any specific reasoning or evidence to support why these baselines are relevant or how they would improve the verification process. Without detailed justification or examples, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors consider baselines such as Rope and Alibi relative positional embeddings to verify the performance improvement obtained by the changes suggested in the paper. This feedback is somewhat helpful as it provides a specific suggestion for additional experiments that could enhance the validation of the results. However, the comment lacks depth and does not offer detailed guidance on how to implement these baselines or what specific aspects of the results should be compared. To be more helpful, the comment could include more detailed reasoning or examples of how these baselines would contribute to the analysis. Therefore, the comment is rated as somewhat helpful, as it provides a direction for improvement but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the paper lacks an analysis of the value of the neighborhood size h and its influence on the model\\'s performance. It also points out that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. This feedback is clear and direct, giving the authors a specific action to take: conduct an analysis of the neighborhood size h and its impact on performance, and provide insights into the robustness of the method with respect to different neighborhood sizes. Additionally, the comment suggests that the authors should explore the performance variations with a constant set of parameters. This level of detail and specificity makes the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"value of neighborhood size h\" and its influence on the model\\'s performance, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as providing insights into the value of h and the robustness of the method with respect to different neighborhood sizes. Additionally, it points out the use of different hyperparameter sets per dataset, which is another area needing improvement. The comment is specific in detailing what aspects of the paper need attention, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks an analysis of the value of the neighborhood size h and its influence on the model\\'s performance. It also notes that different hyperparameter sets are used per dataset, which is not ideal. The comment provides a logical reasoning for why this is important, suggesting that understanding the value of h and its robustness is essential for the model\\'s performance. However, the comment lacks specific examples or references to support the claim about the impact of h on performance, making it somewhat verifiable. The authors would need to conduct additional analysis to fully address the claim, which is why it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two critical areas for improvement in the paper: the lack of analysis of the neighborhood size h and its influence on the model\\'s performance, and the use of different hyperparameter sets per dataset. It highlights the importance of providing readers with intuitive knowledge of the value of h and the robustness of the method with respect to different neighborhood sizes. Additionally, it points out the issue of using different hyperparameter sets per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters, which is a valuable suggestion for improving the paper. This feedback is clear and actionable, offering the authors a path to enhance their draft by addressing these critical aspects. Therefore, the comment is rated as highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. While the comment raises an important consideration, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they should explore the impact of missing data on the model and its ability to leverage additional modalities. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or experiment. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its inquiry about the impact of missing data on the model\\'s performance and its ability to leverage additional modalities. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It asks whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim or suggest how the authors might address this issue. Without additional context or examples, the authors may find it challenging to understand the significance of this question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an important question about the impact of imperfect multimodal data on the model, specifically when certain modalities are missing. It prompts the authors to consider whether missing data at the input level leads to compounding effects on the polynomial tensors being constructed or if the model can leverage additional modalities to infer the missing ones. This question is relevant and could lead to valuable insights into the robustness and generalizability of the model. However, the comment does not provide specific guidance or suggestions on how the authors might explore or address this issue, such as through additional experiments or analyses. While it identifies a critical area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is explicit and concrete, as it clearly identifies what information should be included and how it should be presented. The authors are given a direct action to take, which is to include these statistics in their analysis. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely, to show statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This provides a clear direction for the authors to enhance their analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This is a logical suggestion based on the observation that the SST dataset has phrase-level annotations. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of this suggestion based on the context of the paper, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement in the General Discussion section, recommending that the authors include statistics on the times negation or intensity words take effect, such as the frequency of the word \"nothing\" and its impact on context polarity. This feedback is actionable and provides a clear direction for the authors to enhance their analysis. By following this suggestion, the authors can better contextualize their findings and provide a more comprehensive understanding of their results. However, the comment could be more helpful if it included specific examples or references to support the importance of this information. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not verified the stability of the OGE-Aug on OOD benchmarks, specifically on the DrugOOD dataset, where SPE is validated. While the comment identifies a gap in the evaluation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should conduct these evaluations, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it highlights a potential area for improvement but does not offer specific instructions on how to proceed.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the evaluation of the OGE-Aug on OOD benchmarks, particularly on the DrugOOD dataset, where SPE is validated. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in identifying the need to verify the stability of OGE-Aug on DrugOOD, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have not verified the stability of the OGE-Aug on OOD benchmarks, specifically on the DrugOOD dataset, where SPE is validated. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors have not adequately addressed, namely the evaluation of the OGE-Aug on OOD benchmarks, particularly on the DrugOOD dataset. It highlights that the stability of the model has not been verified on this dataset, where SPE is validated. This feedback is somewhat helpful as it points out a potential gap in the evaluation process, prompting the authors to consider additional benchmarks or evaluations. However, the comment could be more helpful if it provided suggestions on how to conduct these evaluations or what specific aspects of stability should be assessed. Overall, the comment offers a direction for improvement but lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameter-efficient methods like LoRA. While the comment implies that these methods are natural to consider and could provide valuable experimental comparisons, it does not explicitly instruct the authors to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer that they should explore these methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering alternative methods, such as freezing some layers of the model while training a few layers, or using parameter-efficient methods like LoRA. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors might infer that it relates to the experimental setup or methodology, but this inference is not explicit. The comment is specific in suggesting alternative methods that could be explored, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameter-efficient methods like LoRA. This is a suggestion for further exploration rather than a claim. It does not contain any subjective opinions, judgments, or requests for changes that would require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment suggests that the authors consider alternative methods, such as freezing some layers of the model while training a few layers, or using parameter-efficient methods like LoRA. This feedback is somewhat helpful as it provides a direction for the authors to explore additional techniques that could enhance their work. However, the comment lacks specific guidance on how to implement these suggestions or what benefits they might offer, which limits its usefulness. The authors are given a direction for improvement but need more detailed information to fully act on the feedback. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to expand the related work section and compare their approach to strong baselines that use coordinates. This provides a clear and direct action for the authors to take, specifying what needs to be added or improved in the related work section. The comment is explicit and concrete, giving the authors a clear path forward. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is located in, making it weakly grounded. The comment is specific in its suggestion to compare with strong baselines, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests expanding the related work section and comparing the approach to strong baselines that use coordinates. However, it does not provide any specific examples or references to support the claim that such comparisons are necessary or beneficial. Without detailed justification or evidence, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient support or evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion to expand the related work section by comparing the approach to strong baselines that use coordinates. This feedback is specific and offers a concrete direction for improvement, helping the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it provided examples of strong baselines or detailed guidance on how to conduct the comparison. Overall, the comment is mostly helpful as it directs the authors to a specific area for enhancement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the experiments in the paper should be expanded to include multiple seed experiments, which would provide a more robust evaluation of the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. This feedback is clear and direct, giving the authors a specific action to take to improve their draft. The suggestion is concrete, as it specifies what additional experiments should be conducted. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Single Seed Experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current experiments, which are limited to a single seed, making it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The suggestion to conduct multiple seed experiments provides a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments in the paper are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. While the claim is logical and makes sense, it lacks specific examples or references to support the assertion that multiple seed experiments would indeed provide a more robust evaluation. This makes the claim somewhat verifiable, as it provides a clear direction for improvement but requires additional evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the experimental design, noting that the experiments are limited to a single seed, which makes it difficult to assess the significance of performance differences and the impact of the proposed cycle consistency loss on convergence. The comment suggests that conducting multiple seed experiments would provide a more robust evaluation. This feedback is clear and actionable, as it points out a critical area for improvement and offers a specific suggestion for enhancing the experimental methodology. By addressing this feedback, the authors can strengthen the validity and reliability of their results, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on whether they should explain their choice, provide alternative distributions, or clarify the rationale behind their selection. Without specific suggestions or actions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs clarification. The comment is specific in questioning the motivation behind the choice of distributions, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point questions the use of the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector, noting that the motivation behind this choice is unclear. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this choice is unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It points out that the motivation behind this choice is unclear, which is a valid concern for the authors to address. However, the comment does not provide any suggestions or guidance on how the authors might clarify or justify their choice, nor does it offer alternative approaches or references for further exploration. While it identifies a potential area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the accessibility of the proposed method due to the requirement of a multi-GPU setup. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might make the method more accessible or suggest alternative approaches. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a concern about the accessibility of the proposed method, specifically mentioning the requirement of a multi-GPU setup for optimizations. However, it does not specify which part of the paper discusses this requirement, making it weakly grounded. The comment is specific in identifying the issue of accessibility, but without explicit references to sections or parts of the paper, the authors may struggle to pinpoint where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method requires an entire multi-GPU setup for optimizations, making it less accessible to many potential users. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential accessibility issue with the proposed method, noting that it requires an entire multi-GPU setup for optimizations. This observation is relevant and could be helpful for the authors to consider when discussing the practical implications of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make their method more accessible. Without actionable advice or further elaboration, the feedback is limited in its usefulness. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It also recommends using Ref-[2] as a strong baseline for performance comparison. While the comment provides explicit suggestions for improvement, it does not offer detailed guidance on how to implement these suggestions or what specific aspects to focus on when comparing the systems. The authors are given a clear direction but may need to infer the exact steps to take, making the comment mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It also recommends using Ref-[2] as a strong baseline for performance comparison. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs attention. The comment is specific in its suggestion to compare with another system and use Ref-[2] as a baseline, but without grounding, it is weakly grounded. Therefore, the comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It also recommends using Ref-[2] as a strong baseline for performance comparison. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would enhance the paper. The suggestion to use Ref-[2] as a baseline is not elaborated upon, leaving the authors without a clear understanding of the rationale behind the recommendation. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks detailed justification or evidence.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests comparing the current system, which captures semantics through RNN-based models, with another system that also captures semantics. It also recommends using Ref-[2] as a strong baseline for performance comparison. This feedback is clear and actionable, providing the authors with specific steps to enhance their work by including additional comparisons and baselines. However, the comment could be more helpful if it offered more detailed guidance on how to conduct these comparisons or what specific aspects to focus on when evaluating the performance. Overall, the comment is mostly helpful as it directs the authors towards meaningful improvements, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. It suggests that one of the assumptions may not be satisfied or that there are learning difficulties. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific assumptions might be at fault. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in questioning the model\\'s performance but lacks grounding, as it does not reference a particular section or figure. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the model\\'s performance in identifying true sources in the triangle dataset, but it does not provide any supporting evidence, reasoning, or references to justify why this might be the case. The lack of specific claims or references makes it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model\\'s performance in identifying true sources in the triangle dataset, suggesting that one of the assumptions may not be satisfied or that there are learning difficulties. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what assumptions might be at fault. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential area of concern but lacks the depth and specificity needed to be truly beneficial.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation of the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch, which are suitable for the datasets provided but may not be applicable in settings where task boundaries are not known or there are no hard task boundaries. While the comment identifies a potential issue, it does not provide explicit guidance on how the authors should address this limitation. The authors are left to infer that they might need to consider alternative metrics or approaches in such settings, but the comment lacks concrete suggestions or examples. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch, which are mentioned as one of the main selling points of the paper. However, it does not specify which part of the paper discusses these metrics, making it weakly grounded. The comment is specific in identifying the limitations of these metrics in settings where task boundaries are not known or there are no hard task boundaries. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch, are suitable for the datasets provided but may not be applicable in settings where task boundaries are not known or there are no hard task boundaries. This claim is somewhat verifiable as it provides a logical reasoning for the limitation of the metrics, but it lacks specific examples or references to support the claim fully. The authors would need to infer the implications of this limitation on the broader applicability of the metrics, which makes the comment somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the metrics used for evaluating continual learning, specifically the loss after switch and recovery time after switch, which are suitable for the datasets provided but may not be applicable in settings where task boundaries are not known or there are no hard task boundaries. This feedback is somewhat helpful as it points out an important consideration for the authors to address when generalizing their findings. However, the comment could be more helpful if it provided suggestions on how to address this limitation or alternative metrics that could be used in such settings. Overall, the comment offers a valuable insight but lacks depth and actionable guidance, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the user decoder\\'s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes they should make to their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the user decoder\\'s use of information from only time step t, despite the agent decoder providing information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors can infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in questioning the rationale behind the user decoder\\'s information usage, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the user decoder\\'s information usage, specifically why it only uses information from time step t instead of all time steps. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The lack of context or explanation makes it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment raises a question about the user decoder\\'s information usage, specifically why it only uses information from time step t instead of all time steps. This question highlights a potential gap in the paper\\'s methodology or explanation, prompting the authors to clarify or justify their approach. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the explanation. While it identifies a potential area for improvement, it lacks actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement this suggestion or specify how to design the controlled baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of different locations (layers) of induction heads and FV heads within the model, suggesting that this could be a confounding factor affecting ICL performance when ablating these heads. It implies that a controlled baseline should be established to ablate heads at different locations. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The suggestion is specific, as it clearly identifies the need for a controlled baseline to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the difference in ICL performance when ablating induction heads versus FV heads could be influenced by the location of these heads within the model. It implies that a controlled baseline should be established to ablate heads at different locations. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that location is a confounding factor. The suggestion for a controlled baseline is clear, but the claim itself is somewhat verifiable due to the lack of detailed evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential confounding factor in the model's performance, specifically the location of induction heads and FV heads within the model. It suggests that a controlled baseline should be established to ablate heads at different locations, which could help clarify the impact of these factors on ICL performance. This feedback is clear and actionable, providing the authors with a specific direction for improving their analysis and experimental design. However, the comment could be more helpful if it included suggestions on how to implement the controlled baseline or discussed the potential implications of this approach. Overall, the comment is mostly helpful, as it offers valuable insights and guidance for enhancing the draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that a section on synonym identification is missing under similarity measurement, specifying that it should describe how the multiple-choice task is approached. This provides a clear and direct action for the authors to take, as they are instructed to include a section on synonym identification that explains the approach to the multiple-choice task. The comment is explicit and concrete, offering a specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"a section on synonym identification,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what is missing, namely, a description of how the multiple-choice task is approached under similarity measurement. This provides clear guidance on what needs to be added or improved, making the comment fully grounded and specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under similarity measurement, specifically regarding the approach to the multiple-choice task. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this section is necessary or how its absence impacts the paper. Without additional context or explanation, the claim remains unverifiable, as the authors may not understand the significance of the missing section. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper lacks detail, namely the absence of a section on synonym identification under similarity measurement. It specifies that this section should include a description of how the multiple-choice task is approached. This feedback is clear and actionable, as it directs the authors to a specific area that needs attention and provides a clear path for improvement. However, the comment could be more helpful if it offered suggestions on how to structure this section or what specific aspects should be included. Overall, the comment is mostly helpful as it provides a clear direction for enhancing the draft, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While the comment implies that such an overview would be beneficial, it does not explicitly instruct the authors to include it or provide specific guidance on how to structure this overview. The action is implicit and somewhat vague, as the authors can infer the need for an overview but lack detailed instructions on how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not specify which part of the paper this overview should be included in, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestion that an overview would be beneficial, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. However, it does not provide any specific reasoning, examples, or references to support why this overview is necessary or how it would enhance the paper. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that an overview of the workflow and the model is needed to provide a clearer understanding of the work. While this feedback highlights an area that could improve the paper's comprehensibility, it lacks specificity and actionable guidance. It does not specify what aspects of the workflow or model should be included in the overview or how it would enhance the paper. Without detailed suggestions or examples, the authors may find it challenging to implement this feedback effectively. Therefore, the comment is somewhat helpful, as it identifies a potential improvement but does not provide enough detail to be fully actionable.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The reviewer suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment identifies a potential problem, it does not provide explicit guidance on how the authors should address it. The action is implicit and somewhat vague, as the authors need to infer that they should discuss this issue in their paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to debiasing the sketch, mentioning the need to know the statistical dimension d_lambda of the design matrix A. It points out that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. However, the comment does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in detailing the problem and its potential impact, but without explicit references to sections or figures, it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the debiasing process, specifically noting that knowing the statistical dimension d_lambda of the design matrix A is necessary. It argues that computing this dimension accurately would require the same runtime as solving the ridge regression problem, potentially introducing bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment provides a logical reasoning for the concern, it lacks specific references or examples to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a basis for the concern but requires further elaboration for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the debiasing process, specifically noting the need to know the statistical dimension d_lambda of the design matrix A. It points out that accurately computing this dimension would require the same runtime as solving the ridge regression problem, which could introduce bias. The comment suggests that this issue is not discussed in the paper and mentions a similar issue with computing the surrogate sketch. While the comment highlights a critical aspect of the methodology, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is somewhat helpful as it points out a potential weakness but does not provide detailed actionable advice, leaving the authors with a general direction to explore. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific guidance on what aspects of the experimental setup need improvement or how to address these questions. The comment lacks explicit instructions or concrete details on how to enhance the experimental setup, leaving the authors uncertain about what actions to take. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not specify which part of the paper these ablation experiments are discussed in, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestion that the experiments deserve better setup, but it lacks grounding as it does not reference a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, the comment does not provide specific examples or reasoning to support why the current setup is inadequate or what improvements are needed. Without detailed justification or references, the claim lacks verifiability, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the ablation experiments deserve better experimental setup, implying that there are many questions that arise from the current setup. However, it does not provide specific details or examples of what these questions are or how the experimental setup could be improved. This lack of specificity and actionable guidance makes it difficult for the authors to understand and address the feedback effectively. As a result, the comment is barely helpful, as it does not offer meaningful insights or suggestions for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should provide empirical evidence to test this hypothesis. Additionally, it notes that the explanation of improvements is not clear, particularly regarding the word similarity data sets. While the comment implies that the authors should provide empirical evidence and clarify their explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide empirical evidence and clarify their explanation. Therefore, this comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of empirical evidence supporting the claim that the proposed models are particularly useful for learning representations for low-frequency words. It also notes that the explanation of improvements is not clear, specifically mentioning the word similarity data sets. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the sections discussing the models and their applications, but this inference is not precise. The comment is specific in detailing what needs to be addressed, such as providing empirical evidence and clarifying the explanation of improvements. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors have made a reasonable argument about the usefulness of their models for learning representations for low-frequency words, but they lack empirical evidence to support this claim. The reviewer suggests that the authors should provide empirical evidence to test the hypothesis. Additionally, the comment questions whether the explanation of improvements is clear, particularly regarding the word similarity data sets. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the explanation is unclear. This makes the claim somewhat verifiable, as it provides a general direction for improvement but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by noting the lack of empirical evidence to support the claim that the proposed models are particularly useful for learning representations for low-frequency words. It suggests that the authors should provide empirical evidence to test this hypothesis, which is a clear and actionable suggestion. Additionally, the comment points out that the explanation of improvements is not clear, specifically mentioning the word similarity data sets. This feedback is mostly helpful as it provides specific areas for improvement and encourages the authors to strengthen their claims and explanations. However, it could be more helpful if it offered suggestions on how to provide the necessary empirical evidence or clarify the explanation. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the error analysis on the movie dataset is missing, and it suggests that other researchers need to know which cases the model fails. This provides a clear and direct action for the authors to take, which is to include an error analysis on the movie dataset. The comment is explicit and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of an error analysis on the movie dataset to provide information on cases where the model fails. This provides clear guidance on what the authors need to include to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a factual statement rather than a claim or suggestion. It does not express an opinion, judgment, or request for change. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by noting the absence of an error analysis on the movie dataset. It highlights the importance of including this analysis, as it would provide valuable information for other researchers to understand the cases where the model fails. This feedback is clear and actionable, as it directs the authors to a specific area that needs improvement to enhance the comprehensiveness and utility of their work. However, the comment could be more helpful if it provided suggestions on how to conduct or present the error analysis. Overall, the comment is mostly helpful as it points out a critical omission and offers a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some details of the proposed method are missing, but it does not provide specific guidance on what these details are or how they should be addressed. The comment mentions \"questions section below,\" which implies that the authors should refer to a specific section for more information, but it does not explicitly instruct them to do so. The lack of concrete details or explicit actions makes it difficult for the authors to know exactly what needs to be added or clarified. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"some details of the proposed method are missing,\" but it does not specify which part of the paper these details are missing from. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. The comment is specific in suggesting that details are missing, but without explicit references, it is weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that some details of the proposed method are missing, but it does not provide any specific examples or reasoning to support this claim. Without detailed information or references, the authors may find it challenging to understand what specific details are missing and how to address them. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, noting that some details of the proposed method are missing. However, it does not provide any further context, examples, or suggestions on what these details might be or how they could be addressed. This lack of detail and guidance makes it difficult for the authors to understand the scope of the problem and how to improve their draft. As a result, the comment is barely helpful, as it provides a general observation but does not offer actionable feedback. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the absence of an ablation analysis in the main paper, which makes it challenging to determine the source of the small performance gain. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this lack. The action is implicit, as the authors need to infer that they should include an ablation analysis to better understand the performance gains. However, the comment lacks concrete details on how to conduct the analysis or what specific components should be analyzed. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights the absence of an ablation analysis in the main paper, which makes it difficult to determine the source of the small performance gain. However, it does not specify which part of the paper should include this analysis or provide guidance on how to conduct it. The authors can infer that the main paper is being referred to, but the lack of specific guidance makes it challenging to pinpoint the exact section needing attention. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the lack of an ablation analysis makes it difficult to determine the source of the small performance gain. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment identifies a specific issue with the paper, namely the absence of an ablation analysis, which makes it difficult to determine the source of the small performance gain. This feedback is clear and actionable, as it highlights a critical area that the authors need to address to improve the clarity and understanding of their results. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation analysis or which components should be analyzed. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a finding in Figure 2, which shows that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this finding should be addressed or incorporated into the paper. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to Figure 2, providing a specific reference to the part of the paper being addressed, which makes it fully grounded. It also specifies the issue by mentioning the finding that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). This level of detail allows the authors to accurately identify the part of the paper being discussed and understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about the findings in Figure 2, which show that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any reasoning, evidence, or references to support the claim that the authors should use \"Th.\" as a result of this finding. Without additional context or justification, the claim remains unverifiable, as it lacks the necessary support to be understood or acted upon by the authors. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a specific finding from Figure 2, which shows that the noise rate of similarity labels is less than class labels when the number of classes is large (>8). However, it does not provide any further context, explanation, or suggestions on how this finding should be interpreted or utilized in the paper. Without additional guidance or actionable feedback, the authors are left without a clear understanding of how to incorporate this information into their draft. Therefore, the comment is barely helpful, as it identifies a potential area of interest but lacks depth and actionable advice.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on what aspects of the experiments are lacking or how they could be improved. Without explicit guidance or concrete steps for the authors to take, the comment does not offer actionable feedback. The lack of specificity and direction makes it difficult for the authors to understand what needs to be addressed or how to improve their experiments. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions that the CNN experiments are not fully convincing, but it does not specify which part of the paper these experiments are discussed in or provide any details on what aspects are lacking. This makes it difficult for the authors to identify the exact sections that need attention. The lack of specificity and grounding means the comment is not actionable, as it does not provide clear guidance on what needs to be addressed or improved. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the CNN experiments are not fully convincing, but it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without specific details or references, the authors are left without guidance on how to address the issue or improve the experiments. This lack of justification makes the claim unverifiable, as it does not help the authors understand or address the concern.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a concern with the CNN experiments, stating that they are not fully convincing. However, it does not provide any specific details or examples of what aspects of the experiments are lacking or how they could be improved. Without actionable feedback or suggestions, the authors are left without a clear understanding of what needs to be addressed or how to enhance their work. This lack of specificity and guidance makes the comment barely helpful, as it does not effectively guide the authors in improving their draft. Therefore, the comment aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively. This feedback is clear and provides a direct action for the authors to take, namely to give more attention to prompt design and its implications. The comment is explicit and concrete, offering a clear path for improvement. Therefore, it is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. It highlights the importance of discussing how to design prompts effectively. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section or table. While the authors can infer that it relates to the discussion of prompts, the lack of explicit grounding makes it challenging to pinpoint the exact area needing attention. The comment is specific in its suggestion to discuss prompt design, but the lack of grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more emphasis should be placed on prompt design, particularly in the context of the paper introducing several prompting methods to address issues in MenatQA. The comment highlights the importance of discussing how to design prompts effectively, as different prompts may result in varying performance outcomes. However, the comment does not provide specific examples or detailed reasoning to support why this is a critical area for improvement. The lack of detailed justification or references makes the claim somewhat verifiable, as the authors would need to infer the significance of the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement, suggesting that more emphasis should be placed on prompt design. It highlights the importance of discussing how to design prompts effectively, given that different prompts may result in varying performance outcomes. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their paper. By addressing this suggestion, the authors can improve the depth and relevance of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment questions the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment implies that the authors should consider using the adaptive method, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the adaptive method further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or the use of freezing, making it weakly grounded. The comment is specific in questioning the rationale behind the use of freezing and suggesting an alternative method, but it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide any supporting evidence, reasoning, or references to justify why freezing is not effective or why the adaptive method should be preferred. Without such justification, the claim remains unverifiable, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of freezing in MLS selection and suggests that if the adaptive method is effective, it should be used instead. While the comment identifies a potential issue with the current approach, it lacks specific guidance or suggestions on how the authors might address this concern or improve their methodology. The feedback is somewhat helpful as it prompts the authors to consider alternative methods, but it does not provide detailed advice or examples on how to implement these changes. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide explicit guidance on how the authors should implement this change or what specific aspects of the adaptive method should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should explore the adaptive method further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or the use of freezing, making it weakly grounded. The comment is specific in questioning the rationale behind the use of freezing and suggesting an alternative method, but it lacks grounding, as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide any supporting evidence, reasoning, or references to justify why freezing is not effective or why the adaptive method should be preferred. Without such justification, the claim remains unverifiable, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the use of freezing in MLS selection and suggests using the adaptive method instead. While it identifies a potential issue with the current approach, it does not provide specific guidance or suggestions on how the authors might address this concern or improve their methodology. The comment lacks depth and actionable advice, making it somewhat helpful. The authors are prompted to consider an alternative method, but without detailed feedback, they may struggle to implement the suggestion effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'}{'actionability_rationale': 'The review comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not provide explicit guidance on how the authors should implement this change or what specific aspects of the adaptive method should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should explore the adaptive method further. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of freezing in MLS selection and suggests using the adaptive method instead. However, it does not specify which part of the paper discusses MLS selection or the use"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the issue of robustness is addressed in the proposed knowledge-CLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) that involves adding negation or changing entities in text to test the model\\'s robustness. While the comment implies that the authors should conduct such an analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform the suggested analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the issue of robustness is addressed in the proposed knowledge-CLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\\'s robustness. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The suggestion is specific in terms of what the authors should do to address the robustness issue, but the lack of grounding makes it difficult for the authors to pinpoint the exact section where this analysis should be integrated. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the issue of robustness is addressed in the proposed knowledge-CLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model\\'s robustness. While the comment provides a reference to existing work, it does not offer specific details or examples of how the analysis should be conducted or what aspects of robustness should be tested. This lack of detailed guidance makes the claim somewhat verifiable, as the authors would need to infer the exact steps to take based on the reference provided. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about whether the robustness issue is addressed in the proposed knowledge-CLIP model. It suggests that the authors should perform an analysis similar to existing work (e.g., https://arxiv.org/abs/2104.06378) to test the model's robustness by adding negation or changing entities in text. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a specific reference for the authors to follow. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the analysis or what specific aspects of robustness should be tested. Overall, the comment provides a clear direction for improvement but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the authors should provide more explanation on how novel values in the test set are handled. This is a clear and direct action for the authors to take, as it specifies what additional information is needed to improve the clarity of the paper. The comment is concrete, as it directly instructs the authors to provide more explanation, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing more explanation on how novel values in the test set are handled. This provides clear guidance on what the authors need to do to improve the clarity of their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should provide more explanation on how novel values in the test set are handled. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or how it could be improved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide more explanation on how novel values in the test set are handled. This is a clear and actionable suggestion that can help the authors clarify their methodology and improve the clarity of their draft. However, the comment could be more helpful if it provided specific examples or guidance on how to handle novel values in the test set. Overall, the feedback is mostly helpful as it directs the authors to a specific area needing attention, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar methods have been proposed for multi-task learning and suggests that they have not been discussed in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue or what specific aspects of the paper need to be revised. The comment lacks actionable details, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"Similar methods have already been proposed for multi-task learning,\" but it does not specify which part of the paper this observation pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not detail what specific aspects of the paper need to be addressed or how the authors should incorporate the mentioned methods. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that similar methods have been proposed for multi-task learning but are not discussed in the paper. However, it does not provide any specific references or examples of these methods, nor does it explain why their inclusion would be beneficial or relevant to the paper. Without detailed evidence or reasoning, the claim remains unverifiable, as the authors are left without a clear understanding of the basis for the assertion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out that similar methods have been proposed for multi-task learning but are not discussed in the paper. This observation highlights a potential gap in the paper's literature review or discussion section, suggesting that the authors may need to include these methods to provide a comprehensive overview of the field. However, the comment does not provide specific guidance on which methods to include or how they should be integrated into the paper. While it identifies an area for improvement, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take. There is no suggestion to conduct a comparison or provide details on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the methodology section or results. The authors may infer that it pertains to the comparison section, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the computation cost should be addressed or how to compare FedMITR with other methods. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their methodology to reduce computation cost. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take, such as suggesting a comparison or providing guidance on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the methodology or results sections. The authors may infer that it pertains to the comparison section, but this inference is not explicit. The comment lacks specificity as it does not detail what aspects of the computation cost should be addressed or how to compare FedMITR with other methods. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their methodology to reduce computation cost. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to enhance their draft. As a result, the comment is not helpful, aligning with a score of 1.\", 'helpfulness_label': '1'}{'actionability_rationale': 'The review comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not provide any explicit or implicit action for the authors to take, such as suggesting a comparison or providing guidance on how to address this issue. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the expected higher computation cost of FedMITR compared to other methods. However, it does not specify which part of the paper this concern relates to, such as the methodology or results sections. The authors may infer that it pertains to the comparison section, but this inference is not explicit. The"}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also suggests trying other influential losses, such as replacing the min with a mean or NDCG. While the comment implies that the authors should consider these suggestions, it does not explicitly instruct them to do so. The actions are implicit and somewhat vague, as the authors need to infer that they should explore alternative loss functions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also suggests trying other influential losses, such as replacing the min with a mean or NDCG. However, the comment does not specify which part of the paper this relates to, making it weakly grounded. The authors can infer that it pertains to the methodology or results sections, but this is not explicit. The comment is specific in detailing what needs to be addressed, such as the choice of similarity threshold and the exploration of alternative loss functions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a series of questions seeking clarification and suggestions for improvement. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several questions and suggestions for improvement regarding the choice of 0.6 for glove embedding similarity and the potential impact of this choice. It also suggests exploring other influential losses, such as replacing the min with a mean or NDCG. While the comment identifies areas for further exploration and improvement, it lacks specific guidance or detailed suggestions on how to implement these changes. The authors are left with a general understanding of what needs to be addressed but without actionable steps to take. Therefore, the comment is somewhat helpful, as it provides some insight but does not fully guide the authors in making improvements.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests several actions for the authors to consider, including training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. It also recommends increasing the number of convolutional layers from 3 to a more appropriate number for non-synthetic tasks. However, the comment does not provide specific guidance on how to implement these suggestions or what constitutes an appropriate number of convolutional layers. While the actions are explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests several actions for the authors to consider, such as training on labeled data, incorporating input mask explanation annotations, and using modern backbone baselines for feature extraction. However, it does not specify which part of the paper these suggestions relate to, making it difficult for the authors to identify the exact sections that need attention. The comment is specific in its suggestions but lacks grounding, as it does not reference any specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests a specific approach for training on labeled data and incorporating input mask explanation annotations for a few examples. It also recommends using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction. However, the comment does not provide any evidence or reasoning to support the claim that this approach would be effective or why the current setup is insufficient. The reviewer expresses skepticism about the effectiveness of robustness and domain-invariance interventions, but this is presented as an opinion rather than a verifiable claim. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient justification or evidence to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment provides specific suggestions for improving the paper, such as training on labeled data and incorporating input mask explanation annotations for a few examples. It also recommends using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a constructive piece of advice. However, the comment lacks depth and does not explain why these suggestions are beneficial or how they might impact the results. Additionally, the reviewer expresses skepticism about the effectiveness of robustness and domain-invariance interventions, which could be valuable feedback but is not elaborated upon. While the suggestions are actionable, the lack of detailed reasoning and context limits the comment's helpfulness. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. While the comment implies that the authors should take this action, it does not provide explicit instructions on how to achieve this. The action is somewhat vague, as it does not specify the exact steps or methods to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameters and suggests that the baseline should be fully tuned with the same resources as the proposed method for a fair comparison. However, it does not specify which part of the paper discusses the hyperparameters or the baseline, making it weakly grounded. The comment is specific in its suggestion to ensure a fair comparison, but without explicit references to sections or parts of the paper, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. However, the comment does not provide specific examples or detailed reasoning to support why this is important or how it could be achieved. The lack of detailed justification or references makes it difficult for the authors to understand the significance of the suggestion and how to implement it effectively. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper regarding the thoroughness of the baseline tuning. It suggests that the authors should ensure that the baseline is fully tuned with the same resources as the proposed method for a fair comparison. This feedback is somewhat helpful as it points out a critical aspect that could affect the validity of the results. However, the comment lacks specific guidance on how to achieve this, such as suggesting which resources to allocate or how to conduct the tuning process. To be more helpful, the comment could provide more detailed advice or examples of how to implement this suggestion. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but could be more comprehensive.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies a discrepancy in the definition of perplexity, stating that it is not what perplexity is and that Eq1 does not resemble perplexity. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should correct this issue or what steps they should follow to address it. Without specific instructions or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L259\" and \"Eq1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of perplexity and cross-entropy, providing clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point consists of factual statements about the definitions of perplexity and cross-entropy, which are not subjective opinions or claims. It does not require verification as it presents clear, objective information. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the definition of perplexity, pointing out that the explanation provided does not accurately describe what perplexity is. It also notes that Eq1 does not resemble perplexity, suggesting that it might be a misinterpretation. This feedback is clear and actionable, as it highlights specific areas where the authors need to clarify their definitions and ensure accuracy in their explanations. However, the comment could be more helpful if it provided suggestions on how to correct the definitions or offered alternative explanations. Overall, the comment is mostly helpful as it guides the authors in improving their understanding and presentation of key concepts, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the evaluation of the proposed strategies, specifically noting that the authors should consider evaluating their defense against an adversarial attack that minimally alters the edge map while still misleading the model. While the comment implies that the authors should conduct this type of evaluation, it does not provide explicit instructions on how to implement this evaluation or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors can infer the need for a new type of evaluation but lack detailed guidance on how to execute it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific concern regarding the evaluation of the proposed strategies, particularly the need to evaluate the defense against an adversarial attack that minimally alters the edge map. However, it does not specify which part of the paper this evaluation should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the evaluation against an adversarial attack that minimally alters the edge map, providing clear guidance on the issue to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the proposed strategies, specifically noting that the authors should consider evaluating their defense against an adversarial attack that minimally alters the edge map. The comment provides a logical reasoning by suggesting that an adversary could potentially optimize the perturbation to maintain minimal structural alterations while still misleading the model. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the relevance of this concern and how to address it, which limits the clarity and comprehensiveness of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical concern regarding the evaluation of the proposed strategies, specifically highlighting the need to evaluate the defense against an adversarial attack that minimally alters the edge map while still misleading the model. This feedback is highly actionable as it provides a clear direction for the authors to improve their evaluation by considering a more realistic and challenging attack scenario. The comment offers a specific suggestion for enhancing the robustness of the defense mechanism, which is valuable for the authors to consider in refining their work. However, the comment could be more helpful if it included additional guidance on how to implement this evaluation or specific examples of how to measure minimal structural alterations. Overall, the comment is mostly helpful, as it effectively directs the authors towards a significant improvement in their draft.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, which makes it difficult to assess the significance of the results. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion to include standard deviations or any other statistical measures to enhance the significance of the results. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of standard deviations, which makes it difficult to judge the significance of the results. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations. This is a critical piece of information as it affects the interpretation and reliability of the results. However, the comment does not provide any guidance or suggestions on how the authors might address this issue, such as recommending the inclusion of standard deviations or other statistical measures to enhance the significance of the results. Without actionable advice, the comment is limited in its usefulness to the authors. Therefore, it is rated as barely helpful, as it highlights a potential weakness but does not offer constructive feedback for improvement.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to improve the quality of the generated images or what specific aspects need to be addressed. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not specify which part of the paper discusses the generated images or the results, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in identifying the issue of limited realism, but it lacks grounding as it does not reference specific sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the quality of generated images by the proposed method is limited, despite achieving good continuous control. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without specific details or comparisons, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. This feedback is somewhat helpful as it points out a specific area for improvement, but it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue. The comment highlights a potential weakness but does not offer concrete steps or examples for the authors to enhance the quality of their generated images. Therefore, the comment is rated as somewhat helpful, as it provides some insight but does not fully support the authors in improving their draft.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. However, the comment does not explicitly instruct the authors to make this correction or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should correct the statement and understand how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Lines 559-560,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a discrepancy in the statement about Cycle Consistency loss and provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about Cycle Consistency loss is not entirely true, suggesting that it can be iterated between two phases of reconstructions with separate backpropagation processes. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy in the statement about Cycle Consistency loss, suggesting that it is not entirely true. It provides a correction by explaining that the loss can be iterated between two phases of reconstructions with separate backpropagation processes. This feedback is valuable as it offers a more accurate understanding of the Cycle Consistency loss, which can help the authors improve their explanation or presentation of this concept. However, the comment could be more helpful if it provided additional context or examples to illustrate the correction. Overall, the comment is mostly helpful as it directs the authors to a specific area for clarification and improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a missing detail in the paper regarding the grammar over kernels, noting that it is not explained in detail. It also questions the presence of probabilities associated with the grammar and how inference is performed. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how the authors should address these issues. The action is implicit and somewhat vague, as the authors can infer that they need to provide more detailed explanations, but they are not given concrete steps on how to do so. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of detail regarding the grammar over kernels, which is a specific aspect of the paper. It also questions the presence of probabilities associated with the grammar and how inference is performed, providing clear guidance on what needs to be clarified. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure. While the authors can infer that it pertains to the methodology or results sections, this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the lack of detail regarding the grammar over kernels and the associated probabilities, which are crucial for understanding the application of the approach in practice. The reviewer questions the absence of explanations and asks for clarification on inference methods. However, the comment does not provide specific examples or references to support the claim that these details are missing or how they impact the paper\\'s clarity. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the significance of the missing details themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area of the paper that lacks detail, namely the grammar over kernels, which is crucial for understanding the application of the approach in practice. It also questions the presence of probabilities associated with the grammar and how inference is performed, providing clear areas for improvement. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to clarify these concepts. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention but could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but the proposed method worked well. It also recommends showing failure cases and analyzing the limitations. While the comment provides specific suggestions for what should be included, it does not explicitly instruct the authors to make these changes or how to implement them. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results and failure cases to provide a more comprehensive analysis of the proposed method. However, it does not specify which sections of the paper these results should be included in, making it weakly grounded. The comment is specific in its suggestions for what should be included, such as qualitative results and failure cases, and it provides a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results and failure cases to provide a more comprehensive analysis of the proposed method. However, it does not provide specific examples or references to support the claim that these additions would be \"inspiring\" or \"good.\" The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but the proposed method worked well. It also recommends showing failure cases and analyzing the limitations of the proposed method. This feedback is somewhat helpful as it provides specific suggestions for enhancing the paper\\'s analysis and presentation of results. However, it could be more helpful if it included detailed guidance on how to present these results or what specific aspects to focus on. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the title is ambiguous and recommends clarifying it to indicate that the focus is on machine comprehension of text, not human reading comprehension. The comment provides a specific action by suggesting that the title should be clarified to avoid confusion. This feedback is explicit and concrete, as it directly instructs the authors on how to improve their draft by making a specific change to the title. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the title, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and recommends clarifying it to indicate that the focus is on machine comprehension of text, not human reading comprehension. The comment provides a logical reasoning by explaining the ambiguity of the title and the distinction between machine and human reading comprehension. However, it lacks specific examples or references to support the claim, which could make it more robust. Therefore, the comment is somewhat verifiable, as it provides a clear rationale but could be strengthened with additional evidence or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the title of the paper, suggesting that it is ambiguous and recommending clarification to distinguish between machine and human reading comprehension. This feedback is clear and actionable, as it provides a direct suggestion for improving the clarity of the title. By addressing this issue, the authors can enhance the precision of their work and better communicate their focus on machine comprehension. However, the comment could be more helpful if it offered additional guidance on how to rephrase the title or provided examples of how to clarify the distinction. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment expresses confusion about the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what alternative metrics they should use. The action is implicit and vague, as the authors are left to infer that they need to clarify or justify their choice of metrics. Therefore, this comment is barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment addresses a specific aspect of the paper, namely the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation. This provides full grounding as the authors can accurately identify the part of the paper being addressed, which is the human evaluation section. The comment is also specific because it clearly specifies the issue with the use of TSS and suggests that this choice weakens the convincingness of the human evaluation. Therefore, this comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the use of an automatic metric, TSS, instead of a human metric weakens the convincingness of the human evaluation. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this choice is problematic or how it affects the evaluation's credibility. Without additional context or explanation, the claim remains unverifiable, as the authors may not fully understand the basis of the critique. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the use of an automatic metric, TSS, instead of a human metric for evaluating style control in the human evaluation. It suggests that this choice weakens the convincingness of the human evaluation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what alternative metrics they should consider. While it points out a potential weakness, it does not provide actionable feedback or detailed advice, making it somewhat helpful. The authors are left to infer that they need to justify their choice of metrics or explore alternative methods, but without explicit guidance, the comment does not fully support their improvement efforts. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review point suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TD-MPC 2. While the comment implies that the authors should expand their experiments to cover a broader range of domains, it does not provide explicit guidance on how to achieve this or which specific domains to include. The action is somewhat implicit and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is somewhat actionable.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment suggests that the experiments are succinct and effectively prove the authors' point, but it would be strengthened by including experiments across more diverse domains, specifically mentioning TD-MPC 2. However, the comment does not specify which part of the paper these experiments are in or how they relate to the broader discussion. The authors can infer that it pertains to the experimental section, but the lack of explicit reference to a specific section makes it weakly grounded. The comment is specific in suggesting a direction for improvement, but the lack of grounding makes it challenging for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests that the experiments are succinct and effectively prove the authors' point, but it would be strengthened by including experiments across more diverse domains. However, the comment does not provide any specific examples or reasoning to support the claim that the experiments are not diverse enough. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or examples to fully support the claim.\", 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment acknowledges that the experiments effectively prove the authors' point but suggests that the paper could be strengthened by including experiments across more diverse domains, specifically mentioning TD-MPC 2. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's experimental validation. However, the comment lacks specific guidance on how to expand the experiments or which additional domains to explore. To be more helpful, the comment could provide more detailed suggestions or examples of how to diversify the experiments. Therefore, the comment is rated as somewhat helpful, as it offers a direction for improvement but could be more comprehensive.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out two issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. While the comment identifies these issues, it does not provide explicit guidance on how the authors should address them. The lack of specific suggestions or concrete steps for improvement makes it difficult for the authors to know exactly what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses two specific issues: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation on only two datasets, which are standard in the RNP community. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the inclusion of confidence intervals and the evaluation on more datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, which makes it unclear whether performance gains are statistically significant. It also mentions that the evaluation is only conducted on two standard datasets in the RNP community. While the comment provides references to relevant literature, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks, ICLR 2019, and [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, it does not fully substantiate the claim with detailed reasoning or specific examples. The references are general and do not provide a comprehensive justification for the claim. Therefore, the comment is somewhat verifiable, as it provides some support but lacks detailed evidence or examples to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two specific issues with the paper: the lack of confidence intervals for results, which makes it unclear whether performance gains are statistically significant, and the evaluation being limited to only two datasets, which are standard in the RNP community. The comment provides references to relevant literature, such as [1] Diversity-Sensitive Conditional Generative Adversarial Networks, ICLR 2019, and [2] Controlling Selection Bias in Causal Inference, AISTATS 2012, which could help the authors understand the importance of these issues. However, the comment could be more helpful if it offered suggestions on how to address these issues, such as recommending the inclusion of confidence intervals or evaluating on additional datasets. Overall, the comment is somewhat helpful as it highlights areas for improvement but lacks detailed guidance on how to implement those changes.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. However, it suggests that the main contribution of the paper lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve surprisingly good accuracy, rather than proposing novel techniques. While the comment identifies a potential area of contribution, it does not provide explicit guidance or suggestions on how the authors might enhance their paper to better highlight this contribution or differentiate it from previous work. The feedback is vague and lacks actionable details, leaving the authors uncertain about how to address the critique. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the design of the LUQ and the approaches in Section 5, providing a clear indication of the parts of the paper being discussed. It specifies that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. However, it does not specify what aspects of the design or approaches are unclear or need improvement. The comment suggests that the main contribution of the paper lies in demonstrating the sufficiency of existing techniques rather than proposing novel ones, but it does not provide specific guidance on how to enhance this aspect. Therefore, the comment is weakly grounded as it does not explicitly mention the sections being addressed, but it is specific in its critique of the paper\\'s contribution. This aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the LUQ is straightforward to design and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper lies in demonstrating the sufficiency of existing techniques rather than proposing novel ones. While the comment provides some logical reasoning by pointing out the standard nature of the approaches, it lacks specific examples or references to previous literature to fully substantiate the claim. This makes the claim somewhat verifiable, as it provides a general idea but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the design of the LUQ is straightforward and that the approaches in Section 5 are standard and explored in previous literature. It suggests that the main contribution of the paper lies in demonstrating the sufficiency of a simple combination of existing techniques to achieve surprisingly good accuracy, rather than proposing novel techniques. This feedback provides a clear and actionable insight into the paper's contribution, encouraging the authors to emphasize the novelty of their approach in terms of combining existing techniques rather than proposing new ones. However, the comment could be more helpful if it offered specific suggestions on how to highlight this contribution or differentiate the paper from previous work. Overall, the comment is mostly helpful as it directs the authors' attention to a key aspect of their contribution, but it could be more comprehensive with additional guidance.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While the comment explicitly asks for training losses, it does not provide specific guidance on how to obtain or analyze these losses. The action is implicit, as the authors need to infer that they should include training losses in their analysis, but it is concrete because the direction is clear. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its request for training losses, but without grounding, it is weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a concern or how it might impact the results. Without such context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the stability of training the deep localization network with the differentiable Sinkhorn and requests to see some training losses. While it identifies a potential issue, it lacks specificity and does not provide guidance on how to address the concern or what aspects of the training process might be unstable. The request for training losses is a logical step to take, but without further context or suggestions, the comment remains somewhat helpful. The authors are given a direction to explore, but the feedback could be more comprehensive and actionable. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slower running speed. The authors are informed that this might make the comparison with other methods unfair. However, the comment does not provide explicit guidance on how to address this issue or suggest potential solutions. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider the impact of sample size on training speed and potentially adjust their comparisons accordingly. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slower running speed. It also mentions that this might make the comparison with other methods unfair. However, the comment does not specify which part of the paper discusses the training speed or the comparison with other methods, making it weakly grounded. The comment is specific in detailing the issue with the training speed and the potential unfairness of the comparison, but it lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, which could lead to a slower running speed and an unfair comparison with other methods. The reviewer provides a logical reasoning by stating that the increased sample size might affect the training speed, which could be relevant to the authors\\' claim that RegMixup is 1.5x slower. However, the comment lacks specific examples or references to support the claim about the unfair comparison, making it somewhat verifiable. The authors would need to further investigate the impact of sample size on training speed and the potential unfairness of the comparison to fully address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the training speed of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slower running speed and an unfair comparison with other methods. This feedback is somewhat helpful as it points out a specific area where the authors might need to address to ensure a fair comparison. However, the comment lacks depth and does not provide actionable suggestions or guidance on how the authors might mitigate this issue or improve the fairness of their comparison. To be more helpful, the comment could include specific recommendations or examples of how to address the training speed issue or suggest alternative methods for comparison. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific aspects of scalability they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. However, it does not specify which part of the paper this question pertains to, such as a specific section, figure, or table. Without explicit references or detailed context, the authors may find it challenging to determine exactly where this issue is addressed in the paper. Additionally, the comment lacks specificity regarding what aspects of scalability need to be addressed or how the authors should investigate this issue. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question asking about the scalability of the method as the corpus size or hidden dimension size increases. It does not contain any subjective opinions, claims, or suggestions that require verification. It is a factual inquiry seeking clarification, which is why it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size increases. While it identifies an important aspect that the authors should consider, it does not provide any specific guidance or suggestions on how to address this issue. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as barely helpful, as it provides some insight but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks the authors to consider what assumptions are needed to relax the requirement of visiting all ball-action pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This provides a clear and direct action for the authors to take, which is to explore the assumptions and potential outcomes of partial coverage. The comment is explicit and concrete, guiding the authors on how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly references a previous remark, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the action needed, which is to consider what assumptions are needed to relax the requirement of visiting all ball-action pairs with each iteration and what would happen if they partially cover them. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification or further explanation, rather than a claim or suggestion. It does not express an opinion, judgment, or request for change that requires verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a continuation of a previous remark, asking the authors to consider what assumptions are needed to relax the requirement of visiting all ball-action pairs with each iteration. It also inquires about the consequences of partially covering these pairs. This feedback is clear and actionable, providing the authors with a specific direction for improvement by exploring alternative assumptions or scenarios. However, it could be more helpful if it included suggestions or examples of how to address these issues. Overall, the comment is mostly helpful as it guides the authors towards potential improvements but lacks depth in its guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what steps they should consider to explore this possibility. As a result, the authors are left without a clear understanding of what actions to take in response to this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the paper would benefit from this consideration or how it could be addressed. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is unverifiable, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether improvements could still be observed with a better encoder, such as RoBERTa-base, instead of BERT. While it identifies a potential area for further exploration, it does not provide any specific guidance or suggestions on how the authors might investigate this question or what improvements might be expected. The comment lacks actionable advice or detailed feedback, leaving the authors without a clear path forward. Therefore, the comment is rated as barely helpful, as it provides some insight but does not offer sufficient guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without significantly impacting the performance of the predictive model. While the comment implies that the authors should include this demonstration in their paper, it does not explicitly instruct them to do so. The action is somewhat implicit, as the authors can infer that they need to provide this demonstration, but it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method description. This makes it difficult for the authors to identify the exact area that needs attention. Additionally, the comment lacks specificity regarding what aspects of the proposed method or fair policy learning are being discussed. Without clear grounding or detailed guidance, the authors may struggle to understand and address the feedback effectively. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. However, the comment does not provide any specific reasoning, examples, or references to support why this is important or how it could be achieved. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the significance of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without severely damaging the performance of the predictive model. This feedback is somewhat helpful as it identifies a specific area for improvement, namely the need to balance fairness with performance. However, the comment lacks detail on how to achieve this balance or what specific aspects of the method should be addressed to ensure fairness without compromising performance. To be more helpful, the comment could provide more context or guidance on how to implement this demonstration or what specific outcomes should be expected. Therefore, the comment is rated as somewhat helpful, as it points out an important area for improvement but lacks depth and actionable suggestions.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the authors should provide more implementation details of the proposed methods, which is a clear and direct action for the authors to take. It specifies the section where this information should be included, making the action concrete and actionable. The authors know exactly what needs to be done to address the concern, which is to add more details in Section 4.1. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Section 4.1,\" providing full grounding as it allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of implementation details of the proposed methods, which is a clear and specific issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the lack of implementation details in the paper is a significant issue, particularly in Section 4.1. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this lack of details is problematic or how it affects the paper\\'s comprehensibility or reproducibility. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for reproducibility and understanding of the work. By pointing out that these details should be included in Section 4.1, the comment provides a clear and actionable suggestion for improvement. However, it could be more helpful if it offered specific examples of what implementation details should be included or how they could enhance the paper. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': \"The review comment highlights a significant issue with the paper, noting that there is no empirical evaluation and no comparison with other methods. It emphasizes the lack of practical value and suggests that the paper is not suitable for publication at NeurIPS without addressing these concerns. While the comment identifies a critical gap in the paper, it does not provide specific guidance on how to address these issues or what kind of empirical evaluation or comparisons are necessary. The authors are left with a general understanding of what needs to be improved but without concrete steps to take. Therefore, the comment is somewhat actionable, as it points out a significant problem but lacks detailed instructions on how to resolve it.\", 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of empirical evaluation and comparison with other methods, noting that the paper does not provide a practical value for its contributions. It also critiques the theoretical contributions, stating that the paper is not suitable for publication at NeurIPS without addressing these issues. However, the comment does not specify which part of the paper lacks empirical evaluation or comparison, making it weakly grounded. The feedback is specific in identifying the need for empirical evaluation and comparison, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with the label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear what the practical value of the contribution is. The reviewer suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. The claim is somewhat verifiable as it points out a significant gap in the paper's evaluation and comparison, but it lacks specific examples or references to support the assertion about the paper's suitability for publication at NeurIPS. The comment could be strengthened with more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant issue with the paper, noting that there is no empirical evaluation or comparison with other methods, which makes it unclear what the practical value of the contribution is. It suggests that even a theoretical paper should attempt to argue for its significance, which is not the case with the current submission. The comment provides clear and actionable feedback, emphasizing the need for empirical evaluation and comparison to enhance the paper's practical value and theoretical contributions. However, it could be more helpful if it offered specific suggestions on how to conduct the empirical evaluation or which methods to compare with. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and provides a clear direction for enhancing the paper's quality and suitability for publication at NeurIPS.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It suggests that combining RL and planning has already been discussed in PRM-RL [1] and asks whether the algorithms can be applied in more general tasks. While the comment implies that the authors should consider expanding the scope of their work, it does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should explore broader applications. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRM-RL [1] as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not specify which part of the paper discusses the limitations to navigation problems or the potential applications in general tasks. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific in suggesting a potential extension, it lacks full grounding as it does not explicitly mention the relevant sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRM-RL [1] as a related work and suggests that the algorithms could be applied in more general tasks. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper is limited to navigation problems or that combining RL and planning has already been discussed in PRM-RL. The reference to PRM-RL provides some context, but the lack of detailed justification or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment acknowledges that the method discussed in the paper can be applied in general MDPs but notes that the paper is limited to navigation problems. It references PRM-RL [1] as a related work and suggests that the algorithms could be applied in more general tasks. This feedback is somewhat helpful as it points out a limitation of the paper's scope and suggests a potential area for expansion. However, the comment lacks specific guidance on how the authors might explore these broader applications or what aspects of the algorithms could be adapted for more general tasks. While it provides a direction for future work, it does not offer detailed suggestions or actionable steps, making it somewhat helpful.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of a clear definition for the proposed \"contrastive gap,\" which is central to the work. It suggests that while an intuitive example is provided, the setting of this example is less convincing, and a formal definition is still missing. The comment implies that the authors should provide a clear, formal definition for the contrastive gap to enhance the clarity and understanding of their work. However, it does not explicitly instruct the authors to do so, nor does it provide specific guidance on how to define it. The action is implicit and somewhat vague, as the authors can infer the need for a definition but may not know how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by noting the lack of a clear definition and the less convincing setting of the example on the \"idealized\" dataset. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"contrastive gap\" has never been defined clearly, despite being central to the work. It provides an example on the \"idealized\" dataset to demonstrate the concept, but the setting of this example is less convincing. The comment suggests that a clear, formal definition is still lacking. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the definition is unclear. The reasoning is based on the authors\\' perception of the lack of clarity, which is subjective and requires further elaboration to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper, specifically the lack of a clear definition for the proposed \"contrastive gap,\" which is central to the work. It highlights that while an example is provided, the setting of this example is less convincing, and a formal definition is still missing. This feedback is valuable as it points out a significant gap in the paper\\'s clarity and understanding, which is essential for the authors to address. However, the comment could be more helpful if it provided suggestions on how to define the contrastive gap or offered examples of how to improve the clarity of the concept. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement but lacks detailed guidance on how to achieve it.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including additional baselines, such as those mentioned in the related work section, would enhance the paper. It also acknowledges that the authors\\' response addressed the reviewer\\'s concerns and raised the score. However, the comment does not provide explicit instructions on how to include these baselines or what specific aspects of the paper need further clarification. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding these baselines and addressing any remaining unclear parts. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\\' response addressed the reviewer\\'s concerns. It also mentions that the unclear parts have been answered and that the authors explained why the chosen baseline makes sense. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in its suggestion to include additional baselines and clarify the chosen baseline, but without explicit grounding, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including additional baselines, such as those mentioned in the related work section, and acknowledges that the authors\\' response addressed the reviewer\\'s concerns. However, it does not provide specific examples or reasoning to support why these additional baselines are necessary or how they would enhance the paper. The mention of the authors\\' response addressing the concerns is not enough to fully substantiate the claim. Without detailed justification or examples, the claim remains somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests including additional baselines in the paper, such as those mentioned in the related work section, which could enhance the comprehensiveness of the study. It acknowledges that the authors' response addressed the reviewer's concerns and raised the score. However, the comment lacks specificity regarding which baselines should be included or how they would improve the paper. While it provides a general suggestion for improvement, it does not offer detailed guidance or examples, leaving the authors with limited actionable feedback. Therefore, the comment is somewhat helpful, as it identifies an area for enhancement but lacks depth and specificity.\", 'helpfulness_label': '3'}{'actionability_rationale': 'The review point suggests including additional baselines, such as those mentioned in the related work section, to enhance the comprehensiveness of the study. It acknowledges that the authors\\' response addressed the reviewer\\'s concerns and raised the score. However, the comment does not provide explicit instructions on how to include these baselines or what specific aspects of the paper need further clarification. The action is implicit and somewhat vague, as the authors are left to infer that they should consider adding these baselines and addressing any remaining unclear parts. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including additional baselines, such as those mentioned in the related work section, to enhance the comprehensiveness of the study. It acknowledges that the authors\\' response addressed the reviewer\\'s concerns and raised the score. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in its suggestion to include additional baselines and clarify the chosen baseline, but without explicit grounding, the authors may struggle to pinpoint the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point suggests including additional baselines, such as those mentioned in the related work section, to enhance the comprehensiveness of the study. It acknowledges that the authors' response addressed the reviewer's concerns and raised the score. However, the comment does not provide specific examples or reasoning to support why these additional baselines are necessary or how they would enhance the paper. The mention of the authors' response addressing the concerns is not enough to fully substantiate the claim. Without detailed justification or examples, the suggestion remains somewhat vague and lacks depth, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests including additional baselines, such as those mentioned in the related work section, to enhance the comprehensiveness of the study. It acknowledges that the authors' response addressed the reviewer's concerns and raised the score. However, the comment lacks specificity regarding which baselines"}
{"generated_text": "{'actionability_rationale': \"The review point highlights a potential issue with the uniform weighting of modalities, suggesting that dynamically weighting them is important. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their approach. The comment implies that the authors should consider dynamic weighting, but it lacks concrete suggestions or examples of how to implement this change. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'line 113,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform weighting of modalities and suggests that dynamically weighting them is important, referencing works in multimodal fusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the uniform weighting of modalities is not ideal and suggests that dynamically weighting them is important, referencing works in multimodal fusion. However, the comment lacks specific examples or references to these works, making it difficult for the authors to fully understand and address the issue. The claim is somewhat verifiable as it points out a potential problem but requires more detailed support to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the uniform weighting of modalities in the paper, suggesting that dynamically weighting them is more important. It references works in multimodal fusion to support this claim, which provides a basis for the authors to reconsider their approach. However, the comment lacks specific guidance on how to implement dynamic weighting or what specific changes should be made to the methodology. While it highlights an important area for improvement, the feedback could be more actionable with detailed suggestions or examples. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully guide the authors in addressing it.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment points out a potential issue with the uniform weighting of modalities, suggesting that dynamically weighting them is more important. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their approach. The comment implies that the authors should consider dynamic weighting, but it lacks concrete suggestions or examples of how to implement this change. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\", 'actionability_label': '2', 'grounding_specificity_rationale': \"The comment is fully grounded as it explicitly mentions 'line 113,' allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the uniform weighting of modalities and suggests that dynamically weighting them is important, referencing works in multimodal fusion. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\", 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the uniform weighting of modalities is not ideal and suggests that dynamically weighting them is important, referencing works in multimodal fusion. However, the comment lacks specific examples or references to these works, making it difficult for the authors to fully understand and address the issue. The claim is somewhat verifiable as it points out a potential problem but requires more detailed support to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.\", 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the uniform weighting of modalities, suggesting that dynamically weighting them is more important. It references works in multimodal fusion to support this claim, which provides a basis for the authors to reconsider their approach. However, the comment lacks specific guidance on how to implement dynamic weighting or what specific changes should be made to the methodology. While it highlights an important area for improvement, the feedback could be more actionable with detailed suggestions or examples. Therefore, the comment is somewhat helpful, as it points out a significant issue but does not fully guide the authors in addressing it.\", 'helpfulness_label': '3'}{'actionability_rationale': \"The review comment highlights a potential issue with the uniform weighting of modalities, suggesting that dynamically weighting them is more important. It references works in multimodal fusion to support this claim, which provides a basis for the authors to reconsider their approach. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their methodology."}
{"generated_text": "{'actionability_rationale': \"The review comment identifies a specific issue with the use of the word 'to meet' in the sentence 'a response candidate can meet each utterace' on line 280. However, it does not provide any guidance or suggestions on how to address this issue or clarify the meaning. The comment lacks actionable details, leaving the authors without a clear understanding of what changes are needed or how to improve the sentence. As a result, the comment is unactionable.\", 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 280,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the word \"to meet\" in the sentence \"a response candidate can meet each utterace.\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': \"The review point claims that the use of the word 'to meet' in the sentence 'a response candidate can meet each utterace' on line 280 is difficult to understand. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this particular use of the word is problematic or unclear. Without additional context or explanation, the claim remains unverifiable, as the authors may not fully grasp the basis of the critique. Therefore, the comment is classified as 1: Unverifiable.\", 'verifiability_label': '1', 'helpfulness_rationale': \"The comment identifies a specific issue with the use of the word 'to meet' in a sentence, noting that it is difficult to understand. However, it does not provide any guidance or suggestions on how to address this issue or clarify the meaning. Without actionable feedback or examples of alternative phrasing, the authors are left without a clear path to improve their draft. The comment lacks depth and specificity, making it barely helpful. Therefore, it aligns with a score of 2.\", 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific limitations they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its inquiry about the limitations of the method, but without grounding, it is challenging for the authors to determine where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. It does not contain any claims, opinions, or suggestions that require verification. It is a factual inquiry seeking clarification, which does not fit the criteria for a verifiable claim. Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the limitations of the method, specifically in the context of the graph case where the network was shallow. It prompts the authors to consider whether this is also the case in their work. However, the comment does not provide any additional context, analysis, or suggestions for addressing this limitation. Without further elaboration or guidance, the authors are left without a clear understanding of how to address the question or improve their work. Therefore, the comment is barely helpful, as it identifies a potential area for exploration but lacks actionable feedback.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the dropping rate and the number of masks generated for the dropout technique. While it does not explicitly instruct the authors to provide this information, the question is clear and specific, allowing the authors to understand what additional details are needed. The action is implicit but concrete, as the authors know exactly what information is required to address the comment. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"dropout\" and references the response letter, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the dropping rate and the number of masks generated, providing clear guidance on what information is needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a question seeking clarification on the dropping rate and the number of masks generated for the dropout technique. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the dropout technique, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it prompts the authors to provide additional details that could enhance the clarity and completeness of their work. By addressing this question, the authors can improve the transparency and reproducibility of their methodology, which is beneficial for both the authors and the readers. However, the comment could be more helpful if it included suggestions on how to present this information or why it is important. Overall, the comment is mostly helpful, as it directs the authors to a specific area that needs clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the effectiveness of the proposed two-stage optimization approach needs further justifications. It provides a clear action by suggesting that the authors should compare their approach with other single-stage attacks and provide proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms. This guidance is concrete and provides a specific direction for the authors to improve their draft. The comment also highlights the need for additional comparisons to justify the effectiveness of the technical contributions. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the effectiveness of the proposed two-stage optimization approach,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for further justifications and comparisons with other single-stage attacks and SOTA algorithms. This provides clear guidance on how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justifications, as only showing the performance drop on fusion models is not sufficient. The reviewer suggests comparing the approach with other single-stage attacks and providing proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms. This claim is supported by logical reasoning, as it highlights the need for additional comparisons to substantiate the effectiveness of the proposed approach. However, the comment could be strengthened by providing specific examples or references to similar studies for comparison. Therefore, the comment is mostly verifiable, as it provides a clear rationale but lacks detailed examples or references to fully substantiate the claim.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a critical area for improvement in the paper, specifically the need for further justifications of the effectiveness of the proposed two-stage optimization approach. It points out that merely showing the performance drop on fusion models is not sufficient and suggests comparing the approach with other single-stage attacks and providing proper benchmarks and comparisons with other state-of-the-art (SOTA) algorithms. This feedback is clear and actionable, as it provides specific guidance on how the authors can strengthen their paper by including additional comparisons and justifications. By addressing these points, the authors can significantly enhance the credibility and impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image, rather than the Images Masked by Second Masks. This provides a clear and direct action for the authors to take, which is to correct the connections in the figure. The comment is explicit and concrete, giving the authors a specific task to perform. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the connections in the figure, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, not the Images Masked by Second Masks. This provides clear guidance on what needs to be corrected. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the connections in Figure 2 should be between the Second Inpainted Images and the Inpainted Image, rather than the Images Masked by Second Masks. This is a factual observation that does not require any supporting evidence or reasoning. It is a straightforward correction of a visual representation in the figure, making it a normal statement without a claim. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific issue with the connections in Figure 2, suggesting that the connections should be between the Second Inpainted Images and the Inpainted Image, rather than the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific correction to make in their draft. By addressing this detail, the authors can improve the clarity and accuracy of their visual representation, enhancing the overall quality of their paper. However, the comment could be more helpful if it explained why this correction is important or how it affects the interpretation of the results. Despite this, the feedback is mostly helpful as it directs the authors to a specific area for improvement. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether each node can attend to its own lower-level representation, based on the description of equation 2. It suggests that only neighboring nodes are attended to, which implies that the authors should clarify this aspect. While the comment does not explicitly instruct the authors to make this clarification, it is clear that addressing this issue would help improve the clarity of the paper. The action is implicit but concrete, as the authors know exactly what needs to be clarified. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"equation 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions whether each node can attend to its own lower-level representation, based on the description of equation 2. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the functionality of nodes in the context of equation 2, specifically whether each node can attend to its own lower-level representation. The comment is based on a logical inquiry into the description of equation 2, which is a factual observation rather than a claim or suggestion. It does not express an opinion, judgment, or request for change, making it a normal statement. Therefore, it should be labeled as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the functionality of nodes in the context of equation 2, questioning whether each node can attend to its own lower-level representation. This is a relevant and constructive inquiry that prompts the authors to clarify a potential misunderstanding or oversight in their work. By addressing this question, the authors can enhance the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to resolve the issue. Overall, the feedback is mostly helpful as it directs the authors to an important area for clarification, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights the lack of clarity regarding the main contribution of the paper and the proposed method\\'s ability to cope with dynamic large-scale multitasking. It also questions the applicability of the method and the process of automation. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback is vague and lacks concrete steps or examples, leaving the authors uncertain about how to improve their draft. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, specifically mentioning the proposed method\\'s novel properties and the main idea of how it copes with dynamic large-scale multitasking. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the main contribution and the proposed method\\'s applicability and automation process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear and that the proposed method\\'s ability and applicability are overstated or not well-supported. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references to other works or detailed explanations of what aspects are unclear or overstated. As a result, the claim is difficult for the authors to verify and address, making it barely verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s main contribution, noting that the proposed method\\'s novel properties are either overstated or not well-supported. It also highlights the lack of clarity regarding how the proposed method copes with dynamic large-scale multitasking and the process of automation. While the comment points out important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to clarify their main contribution and improve the clarity of their method, but it could be more actionable with detailed advice or examples.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extract-then-generate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extract-then-generate approaches. While the comment highlights a potential issue with the paper\\'s lack of context and comparison, it does not provide explicit guidance on how the authors should address this. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a related work section and compare their system with other extract-then-generate methodologies. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extract-then-generate methodologies. It also points out the absence of a related work section and suggests that the paper lacks a comparison with other extract-then-generate approaches. However, the comment does not specify which part of the paper should include a related work section or how the comparison should be made. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific enough to provide clear guidance on what needs to be improved. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extract-then-generate methodologies. It suggests that the paper lacks a related work section and does not compare its system with other extract-then-generate approaches. However, the comment does not provide specific examples or references to support the claim that the methodology is not novel or that the paper lacks a related work section. This makes the claim somewhat verifiable, as it highlights a potential issue but lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the novelty of the proposed methodology in the context of long document summarization, particularly in relation to previous extract-then-generate methodologies. It questions the lack of a related work section and suggests that the paper does not compare its system with other extract-then-generate approaches. This feedback is somewhat helpful as it points out a potential weakness in the paper's presentation and encourages the authors to include a related work section and compare their system with existing methodologies. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of related work to include. Overall, the comment offers some guidance but lacks depth, aligning with a score of 3.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The suggestion is vague and lacks concrete guidance on how to implement these ideas. The authors are left to infer that they should explore these directions, but without specific instructions, the action remains implicit and somewhat vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, it does not specify which part of the paper this feedback pertains to, making it difficult for the authors to identify the exact sections that need revision. The comment is specific in its suggestions for alternative approaches but lacks grounding, as it does not reference specific sections or elements of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the feasibility of training a large number of models and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. However, the comment does not provide specific evidence, examples, or references to support the claim that training a large number of models is impractical or that the suggested alternatives are more effective. The reasoning is based on a subjective assessment of the feasibility and desirability of the approach, which lacks detailed justification or evidence. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient support to fully substantiate the assertion.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the feasibility of training a large number of models to test the approach and suggests alternative directions for dealing with churn, such as using unlabelled data or applying constraints. This feedback is somewhat helpful as it identifies a potential limitation of the current approach and provides suggestions for improvement. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the feedback offers a direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the authors have not proposed any quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not provide any explicit or implicit guidance on how the authors should address this issue. There is no suggestion or direction on what specific measurements or methods should be used, nor is there any hint on how to incorporate this aspect into the paper. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue regarding the lack of quantitative measurement for the extent of occupation bias relative to real distributions in society. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section that needs attention. While the comment is specific in terms of what is missing, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement for the extent of occupation bias relative to real distributions in society. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper lacks quantitative measurement for the extent of occupation bias relative to real distributions in society. This is a valuable observation that highlights a potential weakness in the paper's methodology or analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is somewhat helpful, as it points out a critical area for improvement but lacks depth and actionable advice.\", 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests using real dicom images as experiment data instead of png images and recommends the FastMRI challenge dataset for this purpose. It also suggests comparing inference speed between different methods. These actions are clear and specific, providing the authors with explicit guidance on how to improve their draft. The comment is highly actionable as it offers concrete steps for the authors to take to enhance their work.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests using real dicom images as experiment data instead of png images and recommends the FastMRI challenge dataset for this purpose. It also suggests comparing inference speed between different methods. While the comment does not explicitly mention a specific section of the paper, it is clear that it pertains to the experimental setup or methodology. The authors can infer that it relates to the data used in the experiments or the comparison of methods. The comment is specific in detailing what needs to be addressed, such as the choice of data and the need for inference speed comparisons. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using real dicom images instead of png images for experiments and recommends the FastMRI challenge dataset for this purpose. It also suggests comparing inference speed between different methods. While the comment provides a logical reasoning for using dicom images and the FastMRI dataset, it lacks specific examples or references to support the claim that dicom images are more suitable or that the FastMRI dataset is a good choice. The suggestion to compare inference speed is clear, but the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting the use of real dicom images instead of png images for experiments, which is a relevant and practical improvement. It also recommends the FastMRI challenge dataset as a suitable choice for the experiment, offering a specific and well-regarded dataset for comparison. Additionally, the comment suggests comparing inference speed between different methods, which is a valuable addition to the experimental evaluation. This feedback is clear and provides the authors with concrete steps to enhance their draft, making it mostly helpful. However, it could be more helpful if it included more detailed guidance on how to implement these suggestions or if it provided examples of how to compare inference speeds. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the current approach of using ProtPainter for binder design is empirical and lacks optimization and validation. It implies that the authors should consider further optimization and validation of the conformation estimation process. However, the comment does not provide explicit guidance on how to achieve this optimization or validation, nor does it specify which aspects of the process need improvement. The action is implicit and somewhat vague, as the authors can infer the need for optimization and validation but lack concrete steps on how to implement these changes. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of binder design, specifically mentioning ProtPainter, which provides an empirical conformation estimation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in suggesting that further optimization and validation are required, providing a clear direction for improvement. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that ProtPainter provides an empirical conformation estimation for binder design and implies that further optimization and validation are needed. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that optimization and validation are necessary. The lack of detailed evidence or justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the binder design process, where the use of ProtPainter is mentioned. It suggests that the current approach is empirical and lacks optimization and validation, implying that further work is needed to enhance the methodology. However, the comment does not provide specific guidance or suggestions on how to optimize or validate the process, nor does it offer examples or references to similar work. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not fully support the authors in addressing it.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about what happens if the original CAD model is already associated with spatially-varying (SV) BRDF maps. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what implications it might have for their work. Without actionable advice or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the implications of having a CAD model already associated with spatially-varying (SV) BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity as it does not provide any guidance on how the authors should address this question or what implications it might have for their work. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a question seeking clarification about a specific scenario related to the CAD model and spatially-varying BRDF maps. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the implications of having a CAD model already associated with spatially-varying BRDF maps. While it identifies a potential area for exploration or consideration, it does not provide any guidance or suggestions on how the authors might address this issue or what implications it might have for their work. The comment lacks actionable advice or specific recommendations, making it difficult for the authors to use this feedback to improve their draft. Therefore, it is rated as barely helpful, consistent with a score of 2.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It also provides a reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. While the comment implies that the authors should revisit and possibly revise their statement about initialization, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should make a more careful statement and consider the reference provided. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"initialization\" and references a specific work by Kunstner, Hennig, and Balles (2019), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the statement about initialization should be more carefully stated, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about initialization should be more carefully stated, referencing a specific work by Kunstner, Hennig, and Balles (2019) as a source of evidence. This provides a logical basis for the claim, as it references an external work that discusses the limitations of the empirical Fisher approximation for natural gradient descent. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it offers a clear direction for improvement but lacks some of the detailed justification needed for full verification. The score 4 aligns with this assessment.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the statement about initialization in the paper, suggesting that it should be more carefully stated. It provides a specific reference to a relevant work by Kunstner, Hennig, and Balles (2019) that discusses the limitations of the empirical Fisher approximation for natural gradient descent. This feedback is valuable as it directs the authors to a source of information that could help them refine their understanding and presentation of initialization. However, the comment could be more helpful if it offered specific guidance on how to improve the statement or what aspects of the initialization should be more carefully addressed. Overall, the comment is mostly helpful as it provides a clear direction for improvement but lacks detailed actionable advice, aligning with a score of 4.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point consists of two parts. First, it highlights the lack of clarity regarding how named entities were extracted from the datasets, which is an explicit action for the authors to address. Second, it suggests that an English-proofreading would significantly improve the readability of the paper, providing a concrete action for the authors to take. However, the comment does not specify which parts of the paper need proofreading or how the proofreading should be done. While the actions are clear, the lack of detailed guidance on proofreading limits the level of actionability. Therefore, this comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses two distinct issues: the extraction of named entities from the datasets and the need for English-proofreading to improve the paper\\'s readability. However, it does not specify which part of the paper discusses the extraction of named entities, making it weakly grounded. The comment is specific about the need for clarity in the extraction process and the potential benefits of English-proofreading, but it lacks detailed guidance on how to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that it is not clear how named entities were extracted from the datasets and suggests that English-proofreading would significantly improve the paper\\'s readability. However, the comment does not provide any specific examples, detailed reasoning, or references to support these claims. The lack of evidence or justification makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two specific areas for improvement: the clarity of how named entities were extracted from the datasets and the need for English-proofreading to enhance the paper\\'s readability. While these are valid points, the comment lacks depth and does not provide detailed guidance on how to address these issues. For example, it does not specify which sections or parts of the paper need clarification or proofreading, nor does it offer suggestions on how to improve the extraction process or English language. This limits the usefulness of the feedback, as the authors may find it challenging to implement the suggestions effectively. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks actionable details.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue or what changes are needed. The comment lacks actionable information, leaving the authors without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not specify which part of the paper these equations are located in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in questioning the inversion or division, but without full grounding, it is challenging for the authors to pinpoint the exact issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point consists of a question about the inversion of matrix determination or the division of the number of samples, specifically referring to \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any supporting evidence, reasoning, or references to justify the claim or question. Without additional context or explanation, the authors may find it challenging to understand the basis of the comment or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the inversion of matrix determination or the division of the number of samples, specifically referring to 'W4 \u2013 Mistakes in Eqs.' However, it does not provide any context, explanation, or guidance on why this is an issue or how it affects the paper's content or analysis. Without additional information or suggestions for improvement, the authors are left without actionable feedback. Therefore, the comment is not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It suggests that the authors should clarify the potential downstream applications or benefits of amodal tracking and how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment implies that the authors should address these issues, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the concerns. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the motivation or introduction section, but this is not explicitly mentioned. The comment is specific in detailing the issues with the motivation and potential applications, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies a gap in the paper, it lacks specific examples or references to support the claim that the motivation is unclear. The suggestion to clarify potential applications or benefits is a logical extension of the concern, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a concern about the unclear motivation of the task, specifically regarding the difficulty in predicting the state of totally occluded objects. It questions the potential downstream applications or benefits of amodal tracking and suggests that the authors should clarify how uncertainty in amodal predictions might be handled or utilized in subsequent tasks. While the comment identifies a significant area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out a critical gap in the paper but does not provide detailed actionable advice, leaving the authors with a general direction to explore. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This action is clear and concrete, as it specifies the exact change needed to improve the draft. The authors know exactly what action to take to address the feedback, making this comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including experiments with GPT-3.5 to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the discussion of GPT-4's cost, but without explicit mention, it remains weakly grounded. The comment is specific in suggesting a change to include GPT-3.5 experiments, which would enhance the evaluation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including experiments with GPT-3.5 to provide a more comprehensive evaluation of the proposed approach. The reviewer acknowledges the expense of GPT-4 and proposes a more affordable alternative. However, the comment lacks specific reasoning or evidence to support why GPT-3.5 would be a better choice or how it would enhance the evaluation. The suggestion is based on a general understanding of the cost of GPT-4, but without detailed justification or examples, it remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. This feedback is clear and actionable, as it identifies a specific change that could enhance the evaluation of the work. By suggesting a more accessible alternative, the reviewer offers a practical way to improve the draft, making the comment mostly helpful. However, it could be more helpful if it provided additional context or reasoning on why GPT-3.5 would be a better choice or how it would impact the evaluation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"confident\" in the context of the paper, suggesting that it might refer to model confidence or human interpretability. The reviewer implies that some rephrasing would be beneficial to clarify the intended meaning. While the comment identifies a potential issue and suggests a possible action, it does not explicitly instruct the authors to rephrase the sentence or provide specific guidance on how to do so. The action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific sentence, \"We have found it easier to be confident about applying ceterus paribus convexity,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of the word \"confident,\" suggesting that it might refer to model confidence or human interpretability. The reviewer implies that some rephrasing would be beneficial to clarify the intended meaning. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of the word \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. However, the comment does not provide any supporting evidence, reasoning, or examples to justify the ambiguity or suggest how the sentence could be rephrased. Without additional context or explanation, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the meaning of the word \"confident\" in the context of the paper, specifically whether it refers to model confidence or human interpretability. The reviewer suggests that some rephrasing would be beneficial to clarify the intended meaning. While the comment identifies a potential area of confusion, it does not provide specific guidance or suggestions on how to rephrase the sentence to address this issue. This limits the usefulness of the feedback, as the authors may still struggle to understand the intended meaning without further clarification. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': \"The review comment identifies several issues with the paper's empirical findings, including the lack of polishing of figures and empirical results, which impede clarity and confidence in the results. It specifies specific areas for improvement, such as missing axis labels, randomly masked out portions of curves, and single seed experiments. Additionally, it notes that the core findings in section one are conducted on two small-scale datasets and a single architecture type. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to address these issues. The authors are left to infer that they should improve the clarity and confidence in their empirical results by addressing these specific points. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks explicit guidance on execution.\", 'actionability_label': '3', 'grounding_specificity_rationale': \"The comment addresses the lack of polishing in figures and empirical results, which affects the clarity and confidence in the paper's findings. It specifies issues such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. However, the comment does not explicitly mention which sections or figures are affected, making it weakly grounded. The authors can infer that the issues are related to the figures and empirical results discussed in the paper, but they cannot pinpoint specific sections. The comment is specific in detailing what needs to be addressed, such as improving the clarity of figures and empirical results. Therefore, this comment is weakly grounded and specific, aligning with category 3.\", 'grounding_specificity_label': '3', 'verifiability_rationale': \"The review point claims that the paper lacks confidence in its empirical findings due to issues with the figures and empirical results. The reviewer provides specific examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. These examples provide a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim further. Therefore, the comment is rated as 4: Mostly Verifiable.\", 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies several specific issues with the paper's empirical findings, including the lack of polishing in figures and empirical results, which impede clarity and confidence in the results. It provides detailed examples of these issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the limited scope of the core findings in section one. This feedback is highly helpful as it offers clear and actionable suggestions for improvement, allowing the authors to address these specific concerns and enhance the clarity and robustness of their empirical results. By providing detailed guidance, the comment empowers the authors to significantly improve their draft, making it highly helpful.\", 'helpfulness_label': '5'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this question or what additional feedback might be beneficial. The comment lacks actionable content, leaving the authors without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the metric choice but lacks grounding, as it does not reference a particular section or table. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of metric for evaluating parallelism in the brain, specifically questioning why the number of weight updates is a better metric than the number of network updates. This question prompts the authors to consider and potentially revise their choice of metrics, which could lead to a more robust analysis. However, the comment does not provide specific guidance or suggestions on how to address this question or what alternative metrics might be more appropriate. While it identifies an area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this question or what specific scenarios they should consider. Without actionable steps or suggestions, the authors are left without a clear direction for improvement. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the real scenarios where the adversarial prediction accuracy is relevant, contrasting it with classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. The authors may infer that it relates to the methodology or results sections, but this inference is not explicit. The comment is specific in its question about the applicability of adversarial prediction accuracy, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question seeking clarification about the relevance of adversarial prediction accuracy in real scenarios, contrasting it with classical prediction accuracy. It does not contain any subjective opinions, claims, or suggestions that require verification. Therefore, it is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the relevance of adversarial prediction accuracy in real scenarios, contrasting it with classical prediction accuracy. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear direction for enhancing their work. Therefore, it is rated as barely helpful, as it provides some insight but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review point states that the contrastive learning framework is the same as SimCLR, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this observation or whether it requires any changes to the paper. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment states that the contrastive learning framework is the same as SimCLR, but it does not specify which part of the paper this observation pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine the exact part of the paper being addressed. Additionally, the comment lacks specificity as it does not provide details on what aspects of the contrastive learning framework are similar to SimCLR or what implications this similarity has for the paper. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the contrastive learning framework is the same as SimCLR, but it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this assertion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework is the same as SimCLR, which is a relevant observation. However, it does not provide any further context, analysis, or suggestions on how this observation might impact the paper or what improvements could be made based on this similarity. Without additional guidance or actionable feedback, the comment lacks depth and does not effectively assist the authors in enhancing their draft. Therefore, it is rated as barely helpful.', 'helpfulness_label': '2'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making the comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. While the comment implies that the authors should conduct more systematic comparisons, it does not provide explicit instructions on how to achieve this or which specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the comparisons. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Zemel et al. (2013)\" and \"the present paper,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the comparisons with this work could be improved by making them more systematic with respect to the tuning of each method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons with Zemel et al. (2013) more systematic, specifically by comparing the best performance of each method. However, the comment does not provide specific examples or detailed reasoning to support why these comparisons should be more systematic or how they could be improved. The lack of detailed justification or examples makes it difficult for the authors to understand and address the suggestion effectively. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or explanation to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement in the paper by suggesting that the comparisons with Zemel et al. (2013) could be made more systematic. It specifically recommends comparing the best performance of each method, which provides a clear and actionable suggestion for enhancing the paper's analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct these comparisons or which aspects to focus on. Overall, the feedback is mostly helpful as it directs the authors towards a specific area for improvement, but it could be more comprehensive with additional details or examples.\", 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly instructs the authors to estimate the time complexity of the learning algorithm to prove the scalability properties. This is a clear and direct action that provides the authors with a specific task to perform. The comment also specifies what needs to be done, making it highly actionable. The authors know exactly how to address the feedback by estimating the time complexity, which is a concrete step towards improving the scalability analysis of the learning algorithm.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the time complexity of the learning algorithm,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is estimating the time complexity to prove the scalability properties. This provides clear guidance on how to improve the draft. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be estimated to prove the scalability properties. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the scalability of the algorithm. Without such support, the claim is difficult for the authors to understand and address. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion by recommending that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This feedback is valuable as it directs the authors to a specific area that needs improvement, which is crucial for demonstrating the scalability of their algorithm. However, the comment could be more helpful if it included additional guidance on how to estimate the time complexity or what aspects of scalability are particularly relevant. Despite this, the feedback is mostly helpful as it offers a clear direction for enhancing the draft. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in a work by Steinwart and Christmann. While the comment implies that the authors should explore this connection, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate this connection. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in Steinwart and Christmann. This provides clear guidance on what aspect of the paper needs further exploration or clarification. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in a work by Steinwart and Christmann. This suggests that the authors should explore this connection, but it does not provide direct evidence or examples to support the claim. The reference to the chapter provides some context, but the comment lacks detailed reasoning or specific examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it offers a direction for further exploration but lacks comprehensive justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the connection between the third point of definition one and properties of universal kernels, referencing a specific chapter in a work by Steinwart and Christmann. This feedback is somewhat helpful as it prompts the authors to consider a potential connection that could enrich their work. However, it lacks depth and does not provide specific guidance on how to explore this connection or why it might be relevant. The comment could be more helpful with additional context or suggestions on how to investigate this connection. Therefore, it aligns with a score of 3, indicating that it is somewhat helpful but incomplete.', 'helpfulness_label': '3'}"}
